{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.23.5\n",
      "Pytorch version: 2.0.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /usr/local/lib/python3.8/dist-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.12\n",
      "Nibabel version: 5.1.0\n",
      "scikit-image version: 0.20.0\n",
      "Pillow version: 9.5.0\n",
      "Tensorboard version: 2.12.3\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: 0.15.2+cu117\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: 1.4.1\n",
      "psutil version: 5.9.5\n",
      "pandas version: 2.0.1\n",
      "einops version: 0.6.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: 2.3.2\n",
      "pynrrd version: 1.0.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, decollate_batch, Dataset, ArrayDataset\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SegResNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    " \n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    CropForegroundd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    "    SpatialPadd,\n",
    "    SpatialCropd,\n",
    "    ScaleIntensityd,\n",
    "    ShiftIntensityd,\n",
    "    ResizeD,\n",
    "    AdjustContrastd,\n",
    "    RandGaussianSharpend,\n",
    "    RandHistogramShiftd,\n",
    "    RandStdShiftIntensityd,\n",
    "    RandAdjustContrastd\n",
    "    \n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from monai.networks.nets import SegResNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import Activations, AsDiscrete\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset\n",
    "from monai.utils import set_determinism\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from monai.transforms import Transform, RandCropByPosNegLabeld,Compose, LoadImaged, EnsureChannelFirstd, EnsureTyped, NormalizeIntensityd, ResizeD,RandAffined, RandFlip\n",
    "from monai.transforms import (\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "\n",
    "    LoadImaged,\n",
    "\n",
    ")\n",
    "\n",
    "import os\n",
    "from monai.transforms import Compose, LoadImaged, AddChanneld, ScaleIntensityRanged, ToTensord\n",
    "\n",
    "print_config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  \"/home/Task07_Pancreas/\"\n",
    "images_dir = os.path.join(data_dir, \"imagesTr\")\n",
    "labels_dir = os.path.join(data_dir, \"labelsTr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image and label file paths\n",
    "image_files = sorted([os.path.join(images_dir, x) for x in os.listdir(images_dir) if x.endswith(\".nii.gz\")])\n",
    "label_files = sorted([os.path.join(labels_dir, x) for x in os.listdir(labels_dir) if x.endswith(\".nii.gz\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the images and labels correspond correctly\n",
    "assert len(image_files) == len(label_files)\n",
    "for im, lab in zip(image_files, label_files):\n",
    "    assert os.path.splitext(os.path.basename(im))[0] == os.path.splitext(os.path.basename(lab))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of samples to load\n",
    "num_samples_to_load = len(image_files) // 8\n",
    "\n",
    "# Create a list of dictionaries where each dictionary represents one sample\n",
    "data_dicts = [{\"image\": image, \"label\": label} for image, label in zip(image_files[:num_samples_to_load], label_files[:num_samples_to_load])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dicts, val_data_dicts = train_test_split(data_dicts, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToSingleLabel(Transform):\n",
    "    def __call__(self, data):\n",
    "        label = data[\"label\"]\n",
    "        # Keep only the second and third channels from the label\n",
    "        single_label = label[1:3]\n",
    "\n",
    "        data[\"label\"] = single_label\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    AddChanneld(keys=[\"image\", \"label\"]),\n",
    "    ScaleIntensityRanged(keys=\"image\", a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "    AsDiscreted(keys='label', to_onehot=3),\n",
    "    ConvertToSingleLabel(),\n",
    "    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),  # Crop the foreground of the image and label\n",
    "    Spacingd(keys=[\"image\", \"label\"], pixdim=[1.0, 1.0, 1.0]),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    # ResizeD(keys=[\"image\", \"label\"], spatial_size=[512, 512, 288], mode=(\"trilinear\", \"nearest\")),  # Resize image and label\n",
    "    # RandCropByPosNegLabeld(\n",
    "    #     keys=[\"image\", \"label\"],\n",
    "    #     label_key=\"label\",\n",
    "    #     spatial_size=(224, 224, 144),\n",
    "    #     pos=3,\n",
    "    #     neg=1,\n",
    "    #     num_samples=2,\n",
    "    #     image_key=\"image\"\n",
    "    # ),\n",
    "    RandAffined(keys=[\"image\", \"label\"],prob=0.5, translate_range=(10, 10, 5), rotate_range=(np.pi / 6, np.pi / 6, np.pi / 6), scale_range=(0.1, 0.1, 0.1)),\n",
    "    ResizeD(keys=[\"image\", \"label\"], spatial_size=[224, 224, 144], mode=(\"trilinear\", \"nearest\")),  # Resize image and label\n",
    "    # ThresholdIntensity(keys=\"label\", threshold=0.5, above=True, below=False),  # Binarize the label tensor\n",
    "    ToTensord(keys=[\"image\", \"label\"]),\n",
    "])\n",
    "\n",
    "\n",
    "# Define transforms for validation dataset\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    AddChanneld(keys=[\"image\", \"label\"]),\n",
    "    ScaleIntensityRanged(keys=\"image\", a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "    AsDiscreted(keys='label', to_onehot=3),\n",
    "    ConvertToSingleLabel(),\n",
    "    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),  # Crop the foreground of the image and label\n",
    "    Spacingd(keys=[\"image\", \"label\"], pixdim=[1.0, 1.0, 1.0]),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    ResizeD(keys=[\"image\", \"label\"], spatial_size=[224, 224, 144], mode=(\"trilinear\", \"nearest\")),  # Resize image and label\n",
    "    # ThresholdIntensity(keys=\"label\", threshold=0.5, above=True, below=False),  # Binarize the label tensor\n",
    "    ToTensord(keys=[\"image\", \"label\"]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data=train_data_dicts, transform=train_transforms)\n",
    "val_dataset = Dataset(data=val_data_dicts, transform=val_transforms)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 224\n",
      "Number of validation samples: 57\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 7/7 [00:24<00:00,  3.53s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the validation dataset with binarized labels\n",
    "threshold=0.5\n",
    "binarized_val_labels = []\n",
    "for sample in val_dataset:\n",
    "    label_tensor = sample['label']\n",
    "    binarized_label_tensor = torch.where(label_tensor > threshold, torch.tensor(1), torch.tensor(0))\n",
    "    binarized_val_labels.append(binarized_label_tensor)\n",
    "\n",
    "val_dataset_with_binarized_labels = CacheDataset(data=val_data_dicts, transform=val_transforms, cache_rate=1.0, num_workers=1)\n",
    "val_dataset_with_binarized_labels.data = [{'image': sample['image'], 'label': binarized_label.unsqueeze(0)} for sample, binarized_label in zip(val_dataset, binarized_val_labels)]\n",
    "\n",
    "# Create the data loaders\n",
    "\n",
    "val_loader = DataLoader(val_dataset_with_binarized_labels, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/model_codes/best_metric_model_bg_v4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('module.convInit.conv.weight', tensor([[[[[-7.6295e-02,  1.5965e-01, -1.7628e-01],\n",
      "           [-6.0325e-02,  7.8177e-02,  1.5152e-01],\n",
      "           [ 1.2274e-01, -4.1974e-02, -1.7796e-01]],\n",
      "\n",
      "          [[ 5.4863e-02,  1.8144e-01, -1.2793e-01],\n",
      "           [-1.1703e-01, -1.5172e-02,  1.5642e-01],\n",
      "           [ 2.3073e-02, -1.7484e-01, -4.5086e-02]],\n",
      "\n",
      "          [[ 1.1068e-01,  1.9871e-01,  1.6878e-01],\n",
      "           [ 1.6708e-01, -4.8412e-02, -1.6031e-01],\n",
      "           [ 1.5466e-01, -9.9070e-02, -2.3973e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 5.7144e-02, -7.4675e-02,  7.4302e-02],\n",
      "           [ 2.8031e-02,  6.1903e-02, -1.2611e-01],\n",
      "           [ 4.2737e-02,  3.8698e-02, -6.2146e-02]],\n",
      "\n",
      "          [[-1.4449e-01, -1.2121e-04, -1.2128e-01],\n",
      "           [ 2.9589e-02,  1.0557e-02, -1.0430e-01],\n",
      "           [-1.6143e-01, -1.3388e-01,  9.3706e-02]],\n",
      "\n",
      "          [[-1.2666e-01, -7.3792e-02,  5.4677e-02],\n",
      "           [-1.0038e-01,  5.5416e-02,  3.6903e-02],\n",
      "           [ 1.1441e-01, -1.5004e-01, -8.8113e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.9846e-03, -4.2011e-03,  3.7091e-02],\n",
      "           [-6.7131e-02,  3.1414e-03,  2.0170e-01],\n",
      "           [-4.5558e-02, -1.0339e-01, -1.3936e-01]],\n",
      "\n",
      "          [[ 2.7255e-02,  4.4611e-02, -1.5155e-01],\n",
      "           [ 1.0802e-01, -7.8382e-02, -1.2367e-01],\n",
      "           [ 1.9554e-01,  9.9291e-02, -6.0217e-02]],\n",
      "\n",
      "          [[-1.9885e-02, -1.5439e-03, -3.8371e-02],\n",
      "           [-8.4664e-02,  6.2873e-02, -1.2479e-01],\n",
      "           [-1.5706e-01,  3.0707e-02, -9.9492e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.1295e-01,  3.6679e-02, -3.0713e-02],\n",
      "           [-1.4167e-01, -4.4629e-02, -1.2493e-01],\n",
      "           [-1.5662e-01, -1.3904e-02, -6.6428e-02]],\n",
      "\n",
      "          [[-1.9429e-02,  6.3602e-02,  4.3427e-02],\n",
      "           [-1.0288e-01,  8.1285e-02,  1.5374e-01],\n",
      "           [-1.6602e-01,  1.7029e-01,  7.6600e-02]],\n",
      "\n",
      "          [[-5.8986e-02,  9.9398e-02, -4.4418e-02],\n",
      "           [ 9.4959e-02, -1.2988e-01, -1.4942e-01],\n",
      "           [ 1.4947e-01,  5.8622e-03,  3.7301e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.1835e-02,  1.0260e-01, -1.8236e-01],\n",
      "           [ 2.6202e-02,  1.1114e-01,  1.4292e-01],\n",
      "           [ 1.3692e-01, -1.4211e-01,  9.5339e-02]],\n",
      "\n",
      "          [[ 1.2935e-01, -1.2236e-01, -1.0565e-01],\n",
      "           [ 1.4169e-02,  6.5026e-02, -1.0366e-01],\n",
      "           [-1.5183e-01,  1.2095e-01, -8.3849e-02]],\n",
      "\n",
      "          [[-7.0901e-02,  7.9788e-02, -8.6497e-02],\n",
      "           [-5.9583e-02,  1.3735e-01,  1.4170e-01],\n",
      "           [ 5.3879e-02,  4.4861e-02, -1.1083e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.0941e-01,  1.2938e-01, -2.0141e-01],\n",
      "           [-1.5865e-01,  1.7941e-01, -8.0698e-02],\n",
      "           [-4.7905e-02,  1.5875e-01,  1.1240e-01]],\n",
      "\n",
      "          [[ 7.4290e-02,  7.8432e-02, -1.4396e-02],\n",
      "           [-1.0378e-01, -1.1334e-01,  9.3887e-02],\n",
      "           [ 1.7610e-01, -1.2318e-01,  4.1180e-02]],\n",
      "\n",
      "          [[ 1.4872e-01, -1.6843e-04,  3.9005e-03],\n",
      "           [ 1.1788e-01, -8.9364e-02, -1.9555e-01],\n",
      "           [-1.9269e-02, -4.3557e-02, -4.9102e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 7.6836e-02,  1.2859e-01,  8.3528e-02],\n",
      "           [-1.0891e-01,  1.1160e-01, -1.5532e-01],\n",
      "           [-4.0607e-02, -1.6860e-01, -2.1932e-02]],\n",
      "\n",
      "          [[ 1.5976e-01, -1.0615e-02,  6.5653e-02],\n",
      "           [ 1.0006e-01,  1.7103e-01, -1.4082e-01],\n",
      "           [-5.1654e-02, -1.2765e-01, -1.2553e-01]],\n",
      "\n",
      "          [[ 7.0416e-02,  6.6966e-02, -1.7438e-01],\n",
      "           [ 6.1774e-03,  4.0343e-02,  1.6238e-01],\n",
      "           [-9.7121e-02,  1.5889e-02,  1.1722e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.0321e-01, -1.0875e-01, -1.0139e-01],\n",
      "           [ 5.8640e-02, -1.4511e-01,  1.1977e-01],\n",
      "           [-3.4205e-02,  1.5737e-02,  2.6365e-02]],\n",
      "\n",
      "          [[-8.0588e-02, -1.6595e-02,  1.4478e-02],\n",
      "           [ 1.4936e-01,  4.4678e-02, -1.1301e-01],\n",
      "           [-9.8181e-02, -4.4057e-02,  6.5642e-02]],\n",
      "\n",
      "          [[-2.7717e-02, -2.3838e-02,  5.9387e-02],\n",
      "           [ 6.8834e-02,  4.2583e-02, -2.3005e-02],\n",
      "           [ 1.4700e-01, -6.0648e-02,  1.5193e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 8.8021e-02, -8.5941e-02,  6.1045e-02],\n",
      "           [ 1.8437e-01, -5.4573e-03,  1.6297e-01],\n",
      "           [-5.3577e-02,  1.2362e-01,  1.4135e-01]],\n",
      "\n",
      "          [[-1.1892e-01, -1.1965e-01, -1.8968e-02],\n",
      "           [ 1.7845e-01,  5.2237e-03, -2.5992e-02],\n",
      "           [ 3.6703e-02,  8.5699e-02,  1.6113e-01]],\n",
      "\n",
      "          [[-9.0477e-02, -9.4425e-02, -1.7945e-01],\n",
      "           [ 7.6149e-02, -1.5778e-01,  1.7845e-01],\n",
      "           [-1.7389e-01, -4.9255e-02, -1.5457e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 9.3666e-02, -4.2396e-02,  1.5372e-02],\n",
      "           [ 3.4804e-02, -9.7852e-03, -2.0588e-01],\n",
      "           [ 2.4654e-02, -2.1708e-01,  7.5703e-02]],\n",
      "\n",
      "          [[-8.8930e-02, -1.7682e-01, -1.3264e-02],\n",
      "           [-1.3332e-01,  1.8476e-01, -1.2820e-02],\n",
      "           [-7.6332e-02,  1.3940e-01,  2.1843e-02]],\n",
      "\n",
      "          [[ 1.5112e-01,  1.0054e-01, -3.9584e-02],\n",
      "           [-3.9431e-02,  1.0911e-01,  1.4823e-01],\n",
      "           [ 1.1384e-01, -6.3367e-02,  9.8511e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.7825e-01, -7.4437e-02,  1.3822e-01],\n",
      "           [-4.9842e-02,  4.5261e-02, -1.4143e-01],\n",
      "           [ 1.0300e-01, -1.3844e-01,  4.3370e-02]],\n",
      "\n",
      "          [[ 1.2286e-01, -1.7432e-02, -1.6452e-01],\n",
      "           [-2.4655e-03,  5.4346e-02,  1.4007e-01],\n",
      "           [-6.8371e-02,  4.4424e-02,  4.8796e-02]],\n",
      "\n",
      "          [[ 1.5862e-01,  1.3299e-01, -1.0754e-01],\n",
      "           [-4.0914e-02, -1.4988e-01,  6.0524e-02],\n",
      "           [-1.8037e-01,  1.5634e-01, -1.3214e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.5118e-01, -1.2443e-01, -1.2693e-01],\n",
      "           [-1.6117e-01,  5.6079e-03, -1.4634e-01],\n",
      "           [ 1.8479e-02, -1.0130e-01,  2.0776e-01]],\n",
      "\n",
      "          [[ 1.7768e-01, -1.4868e-01,  7.6131e-02],\n",
      "           [-4.9720e-02,  1.3280e-01,  3.6535e-02],\n",
      "           [ 1.9834e-01, -1.4901e-01, -1.4511e-01]],\n",
      "\n",
      "          [[-1.0108e-01,  1.6755e-01,  2.2628e-02],\n",
      "           [ 2.1098e-01, -1.1747e-01, -1.5525e-01],\n",
      "           [ 1.0893e-01,  6.7067e-02,  1.2159e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6600e-01, -2.6087e-02, -8.3265e-02],\n",
      "           [-1.1723e-01, -1.6475e-01, -6.6690e-02],\n",
      "           [ 6.3125e-02,  1.7223e-01,  5.4767e-02]],\n",
      "\n",
      "          [[ 1.1514e-01, -1.1940e-01,  7.3285e-02],\n",
      "           [-1.3466e-01, -9.0422e-02,  1.0915e-01],\n",
      "           [ 2.8917e-02,  1.4473e-01,  1.8147e-01]],\n",
      "\n",
      "          [[-1.4243e-01, -7.1975e-03,  1.6926e-01],\n",
      "           [-6.2362e-04, -4.1226e-03, -1.5744e-01],\n",
      "           [-1.5642e-01, -9.2308e-02,  1.5345e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6411e-01, -8.3851e-02, -8.4876e-02],\n",
      "           [ 1.2869e-01, -1.3049e-01, -1.4622e-01],\n",
      "           [-9.2793e-02,  6.9037e-02,  1.2865e-01]],\n",
      "\n",
      "          [[ 1.1231e-01, -7.1725e-02,  6.0311e-02],\n",
      "           [-2.1383e-02, -8.3477e-02, -1.6164e-01],\n",
      "           [-1.2575e-01,  1.8225e-01,  1.4934e-01]],\n",
      "\n",
      "          [[ 3.9421e-02,  8.9765e-02,  1.3336e-01],\n",
      "           [-1.1438e-02,  1.3529e-01,  1.0895e-01],\n",
      "           [ 1.0000e-01,  5.5363e-02,  2.7781e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.8703e-02,  3.2327e-02, -1.9203e-01],\n",
      "           [-9.4735e-02, -1.6098e-01, -1.0023e-01],\n",
      "           [-1.5389e-01,  1.8582e-01, -7.6728e-02]],\n",
      "\n",
      "          [[-8.1168e-02,  1.6973e-01,  1.0149e-01],\n",
      "           [ 1.5060e-01,  9.9724e-02,  8.8632e-02],\n",
      "           [ 1.7547e-01,  1.4621e-01,  1.6093e-01]],\n",
      "\n",
      "          [[-1.2129e-01, -9.8034e-02, -6.0942e-02],\n",
      "           [ 1.2648e-01, -3.8728e-03,  1.4266e-01],\n",
      "           [-1.1254e-01, -6.7981e-02,  1.3641e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.5753e-02,  1.3308e-01,  2.0693e-03],\n",
      "           [-9.4880e-02, -1.4326e-01,  1.0713e-02],\n",
      "           [-1.1627e-01, -4.6173e-02,  1.4584e-01]],\n",
      "\n",
      "          [[ 5.3841e-02, -1.5598e-01, -1.6271e-01],\n",
      "           [ 3.2475e-02,  2.4020e-03,  1.3186e-01],\n",
      "           [-9.0439e-02, -1.1783e-01,  1.0991e-01]],\n",
      "\n",
      "          [[-9.2768e-02, -5.0652e-02,  2.1394e-01],\n",
      "           [-6.2455e-02, -1.6739e-01, -9.8412e-02],\n",
      "           [ 4.2989e-02, -1.2606e-01, -7.4307e-02]]]]], device='cuda:0')), ('module.down_layers.0.1.norm1.weight', tensor([0.9890, 0.9812, 0.9725, 0.9872, 0.9821, 1.0022, 1.0425, 0.9945, 0.9901,\n",
      "        1.0110, 1.0036, 0.9964, 0.9790, 0.9864, 1.0023, 0.9819],\n",
      "       device='cuda:0')), ('module.down_layers.0.1.norm1.bias', tensor([-0.0204,  0.0043, -0.0106, -0.0145, -0.0128, -0.0191,  0.0009,  0.0243,\n",
      "        -0.0291, -0.0308, -0.0076,  0.0020,  0.0070, -0.0306, -0.0121,  0.0021],\n",
      "       device='cuda:0')), ('module.down_layers.0.1.norm2.weight', tensor([0.9710, 0.9899, 0.9872, 0.9856, 0.9734, 0.9820, 0.9746, 0.9867, 0.9824,\n",
      "        0.9479, 0.9969, 0.9906, 0.9743, 0.9914, 1.0144, 0.9948],\n",
      "       device='cuda:0')), ('module.down_layers.0.1.norm2.bias', tensor([-0.0151, -0.0176,  0.0067,  0.0078, -0.0066, -0.0358, -0.0075, -0.0205,\n",
      "        -0.0100,  0.0069, -0.0566, -0.0501, -0.0159, -0.0284, -0.0237, -0.0027],\n",
      "       device='cuda:0')), ('module.down_layers.0.1.conv1.conv.weight', tensor([[[[[ 1.0317e-02,  3.3532e-02,  1.0223e-02],\n",
      "           [ 4.2330e-02,  7.9563e-02,  1.8648e-02],\n",
      "           [ 1.4076e-02,  1.3480e-02, -5.8380e-03]],\n",
      "\n",
      "          [[-3.6209e-02, -3.7433e-03,  4.8425e-03],\n",
      "           [ 4.8508e-04,  3.0981e-02,  6.2873e-02],\n",
      "           [ 1.5791e-02,  1.8811e-02, -1.1705e-02]],\n",
      "\n",
      "          [[-2.6201e-02,  1.2397e-02, -2.6106e-02],\n",
      "           [ 2.6326e-02,  3.4445e-02,  5.0951e-02],\n",
      "           [ 4.5599e-02,  2.9718e-02, -1.9884e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.4872e-02, -1.2193e-02,  3.6330e-02],\n",
      "           [-5.1658e-02,  3.1154e-02,  3.5952e-02],\n",
      "           [ 1.4864e-02, -2.0138e-02,  1.3241e-02]],\n",
      "\n",
      "          [[ 2.3556e-02,  1.3011e-03, -4.0938e-02],\n",
      "           [-1.4867e-02,  5.9910e-03, -2.5651e-02],\n",
      "           [-3.5208e-02, -3.5020e-02, -4.9017e-03]],\n",
      "\n",
      "          [[ 5.8402e-03,  3.2583e-02, -1.7802e-02],\n",
      "           [-4.1708e-02,  2.3961e-02, -2.0161e-02],\n",
      "           [ 3.0951e-02,  1.7922e-02, -1.7221e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.8723e-02,  3.0312e-02,  1.5852e-02],\n",
      "           [-4.0543e-02, -5.0334e-03, -2.1709e-02],\n",
      "           [-1.1999e-02,  4.6876e-02, -1.7974e-02]],\n",
      "\n",
      "          [[ 5.3775e-03, -1.6208e-02, -3.7879e-02],\n",
      "           [ 2.5442e-03,  2.9895e-02,  2.0261e-02],\n",
      "           [ 2.8286e-02, -2.6848e-02,  2.4644e-02]],\n",
      "\n",
      "          [[-9.3787e-03, -3.4479e-02, -2.3182e-02],\n",
      "           [ 3.1755e-02, -4.3700e-02,  8.7546e-04],\n",
      "           [ 8.7802e-03,  9.2620e-03, -4.1714e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 6.0545e-02,  2.9241e-03,  1.0541e-02],\n",
      "           [ 1.7158e-02,  3.0946e-02,  1.5435e-02],\n",
      "           [ 1.1911e-02, -1.9648e-02,  8.5206e-04]],\n",
      "\n",
      "          [[ 7.7858e-03,  2.4890e-02,  3.7425e-02],\n",
      "           [ 7.8171e-03, -2.2729e-02, -3.7715e-02],\n",
      "           [ 4.9647e-02,  5.1042e-02,  3.1089e-03]],\n",
      "\n",
      "          [[-3.6855e-02,  1.3829e-03, -3.9113e-02],\n",
      "           [-2.8828e-02,  4.1921e-02, -3.7738e-02],\n",
      "           [-3.6732e-02,  7.3506e-03, -3.9283e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.3441e-02,  3.1304e-02, -1.1736e-02],\n",
      "           [ 2.7180e-02,  3.7068e-02, -2.1952e-02],\n",
      "           [-3.5108e-02, -3.8569e-02, -2.7640e-03]],\n",
      "\n",
      "          [[ 7.3756e-02,  6.6864e-02, -1.5092e-02],\n",
      "           [ 3.8059e-03, -6.9894e-03, -7.4872e-03],\n",
      "           [-1.6988e-02,  1.1384e-02,  1.2934e-02]],\n",
      "\n",
      "          [[-2.0894e-02, -3.9741e-02,  1.7940e-02],\n",
      "           [ 2.2594e-02,  1.5632e-02, -1.1318e-03],\n",
      "           [ 2.8657e-02,  4.4776e-02, -2.2949e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.3351e-02, -3.9617e-02, -3.4757e-03],\n",
      "           [ 1.3688e-02, -2.2643e-02,  3.1639e-02],\n",
      "           [ 7.3142e-03,  1.5948e-02,  3.3929e-02]],\n",
      "\n",
      "          [[-2.2821e-02, -1.8927e-02,  3.3259e-02],\n",
      "           [-3.5218e-02,  4.0965e-02, -2.1266e-02],\n",
      "           [ 2.7076e-02, -1.9884e-02,  1.7571e-02]],\n",
      "\n",
      "          [[ 1.7350e-02,  1.1317e-02, -1.8284e-02],\n",
      "           [-2.6388e-02,  1.0079e-02, -4.4501e-02],\n",
      "           [ 2.8919e-02, -4.1797e-02,  4.5000e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.1563e-02,  1.6631e-02,  1.7113e-02],\n",
      "           [-5.0269e-03,  8.0799e-03, -7.2215e-03],\n",
      "           [ 1.6076e-03,  5.0257e-03, -2.2304e-02]],\n",
      "\n",
      "          [[ 4.7836e-02, -2.4061e-02, -3.0577e-02],\n",
      "           [ 4.0334e-02,  2.4461e-02, -1.3884e-02],\n",
      "           [-1.8484e-04,  5.6270e-03, -3.3057e-02]],\n",
      "\n",
      "          [[-3.8918e-04,  2.0365e-02, -2.5133e-02],\n",
      "           [ 7.0065e-04,  3.5026e-02,  2.9793e-02],\n",
      "           [-2.7405e-02, -3.2843e-02, -2.4337e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.5290e-02, -2.8599e-02, -2.2773e-02],\n",
      "           [-1.1810e-02, -1.8427e-02, -1.7719e-02],\n",
      "           [ 4.5900e-02,  1.6371e-02, -2.6908e-02]],\n",
      "\n",
      "          [[ 1.7737e-02,  8.4279e-03, -6.7116e-03],\n",
      "           [-3.6965e-02, -3.7698e-03,  2.7962e-02],\n",
      "           [-4.4909e-02,  3.8583e-02,  6.3910e-03]],\n",
      "\n",
      "          [[ 4.2479e-02,  1.0599e-02, -1.5705e-03],\n",
      "           [-9.7540e-04,  4.0548e-02,  3.8217e-04],\n",
      "           [-2.9006e-02, -1.3106e-03,  2.8597e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.2202e-02, -3.3840e-02,  1.8911e-02],\n",
      "           [-4.1989e-02, -1.9271e-02, -5.1217e-02],\n",
      "           [-4.0597e-02, -3.2314e-02,  3.7094e-02]],\n",
      "\n",
      "          [[-1.0276e-02, -1.4827e-02,  1.1998e-02],\n",
      "           [-1.7338e-03,  1.3126e-02, -1.7390e-02],\n",
      "           [ 7.8602e-03,  3.4591e-02,  1.6925e-02]],\n",
      "\n",
      "          [[-9.3536e-03,  9.9553e-03,  1.7958e-02],\n",
      "           [ 1.9969e-02, -3.6584e-02, -2.2372e-02],\n",
      "           [ 9.6109e-03,  4.8370e-03, -2.0217e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.1755e-02, -2.3663e-02, -3.2329e-02],\n",
      "           [ 9.7516e-05,  4.1376e-02, -3.7098e-02],\n",
      "           [ 3.2742e-02,  2.9092e-03,  2.1356e-02]],\n",
      "\n",
      "          [[ 5.5635e-02,  3.3131e-02, -8.5672e-03],\n",
      "           [ 1.4609e-02, -4.2537e-02,  3.0920e-02],\n",
      "           [ 1.0540e-02,  3.7295e-02,  2.1274e-02]],\n",
      "\n",
      "          [[-9.6543e-03, -2.6857e-02,  1.9929e-02],\n",
      "           [ 4.0194e-03, -2.7136e-03, -4.5988e-02],\n",
      "           [ 1.1272e-02, -4.4618e-02, -1.0315e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 6.3650e-02,  2.4486e-02, -2.7215e-02],\n",
      "           [ 3.2442e-02,  1.0298e-02,  6.0526e-02],\n",
      "           [-1.4331e-03, -2.6257e-02, -4.2069e-02]],\n",
      "\n",
      "          [[ 3.7944e-02,  4.2507e-02,  5.7403e-02],\n",
      "           [-2.3488e-02, -1.0962e-02, -2.3989e-02],\n",
      "           [-1.4863e-02,  6.9354e-03,  8.0881e-03]],\n",
      "\n",
      "          [[-3.0356e-02,  3.6768e-02,  3.1729e-02],\n",
      "           [-4.2087e-02,  2.4802e-02, -3.4111e-02],\n",
      "           [-2.3709e-04, -5.2036e-03, -4.2409e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3462e-02, -2.2018e-02,  1.3737e-02],\n",
      "           [ 2.3081e-02,  4.6716e-02,  2.5276e-03],\n",
      "           [ 5.0218e-02,  1.8396e-02, -2.1211e-03]],\n",
      "\n",
      "          [[ 4.3768e-02,  5.1244e-02, -4.6216e-03],\n",
      "           [-3.2529e-02, -3.8111e-02, -2.9481e-02],\n",
      "           [ 4.7433e-02,  3.1587e-02,  4.1533e-02]],\n",
      "\n",
      "          [[-3.0823e-02, -1.0889e-02,  2.6785e-02],\n",
      "           [-1.7080e-02,  7.8443e-03,  4.0220e-03],\n",
      "           [ 3.8851e-02, -4.1566e-02,  1.3088e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 9.7044e-03, -1.0724e-02, -1.4856e-02],\n",
      "           [-1.8663e-02, -4.3548e-02,  2.3516e-02],\n",
      "           [-4.0109e-02, -2.7344e-02, -1.8122e-02]],\n",
      "\n",
      "          [[ 4.2108e-02, -2.0926e-02,  7.6308e-03],\n",
      "           [ 3.9832e-02, -5.0185e-02, -9.3117e-03],\n",
      "           [-4.0072e-02, -8.6472e-03, -2.0747e-02]],\n",
      "\n",
      "          [[-2.8417e-02,  2.5461e-02, -3.0210e-02],\n",
      "           [ 2.3485e-02,  3.3318e-02, -1.2101e-02],\n",
      "           [ 6.2020e-03,  4.3104e-02,  4.1388e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.0392e-02,  1.5652e-02,  2.9273e-02],\n",
      "           [-4.3437e-02, -6.6497e-03,  8.6674e-03],\n",
      "           [ 3.5738e-02,  2.9696e-02,  1.5854e-02]],\n",
      "\n",
      "          [[ 2.2602e-02, -2.2574e-02, -9.3313e-03],\n",
      "           [-3.4641e-02, -4.2290e-02, -3.7627e-02],\n",
      "           [-3.5404e-02, -1.8846e-02,  2.7412e-02]],\n",
      "\n",
      "          [[-1.2651e-02, -1.1849e-02,  4.0887e-02],\n",
      "           [-1.2469e-02, -1.9970e-02,  1.8205e-02],\n",
      "           [-1.3261e-02,  4.3900e-02,  1.4682e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.9084e-02, -3.6279e-02, -1.6321e-02],\n",
      "           [ 1.3201e-02,  1.4844e-02,  3.8332e-02],\n",
      "           [-2.1439e-02, -4.4061e-02, -3.0428e-02]],\n",
      "\n",
      "          [[-3.3742e-02,  4.8974e-02,  1.0008e-02],\n",
      "           [-4.5104e-03, -1.3239e-02,  2.8346e-02],\n",
      "           [ 1.4053e-02,  4.4174e-03, -6.4438e-03]],\n",
      "\n",
      "          [[-2.9568e-02, -1.4213e-02,  3.7795e-02],\n",
      "           [ 1.8583e-02, -6.7970e-03,  4.2729e-02],\n",
      "           [ 4.5411e-02,  1.3484e-03,  4.2299e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0285e-02,  1.3237e-02,  3.6961e-02],\n",
      "           [-4.7355e-02, -3.4309e-02,  3.0556e-02],\n",
      "           [ 2.0962e-02,  3.0451e-02, -1.1673e-02]],\n",
      "\n",
      "          [[-2.5190e-02, -2.1380e-02,  2.4099e-02],\n",
      "           [-1.1608e-03, -1.0136e-02,  5.7799e-03],\n",
      "           [-1.8323e-02,  1.2509e-02, -3.6979e-03]],\n",
      "\n",
      "          [[ 9.6843e-03, -3.2417e-02, -1.3313e-02],\n",
      "           [-4.2582e-02,  1.4772e-02,  2.5582e-02],\n",
      "           [ 4.3221e-02,  4.4569e-02, -2.6481e-02]]],\n",
      "\n",
      "\n",
      "         [[[-9.7654e-04, -4.1213e-02,  3.3720e-02],\n",
      "           [ 7.5436e-03,  2.7704e-02,  2.2175e-02],\n",
      "           [-6.4075e-03,  1.1454e-02, -4.6944e-03]],\n",
      "\n",
      "          [[-3.2856e-02,  8.1116e-04,  2.8804e-02],\n",
      "           [-2.7056e-02,  3.5624e-02,  1.1261e-02],\n",
      "           [-1.8394e-02,  5.9429e-02, -2.9049e-02]],\n",
      "\n",
      "          [[-4.1630e-02, -4.0688e-02,  3.2931e-02],\n",
      "           [-2.9280e-02, -2.4085e-02,  3.8722e-02],\n",
      "           [ 3.6963e-02, -8.5777e-03, -3.1643e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.0118e-02,  2.8468e-02, -5.7373e-03],\n",
      "           [ 7.0259e-03,  1.1042e-02,  3.3794e-02],\n",
      "           [-4.8392e-02, -4.9731e-02, -3.2319e-02]],\n",
      "\n",
      "          [[ 2.8615e-03,  2.3800e-02, -2.5798e-02],\n",
      "           [ 3.1901e-02, -1.4104e-02,  2.9531e-02],\n",
      "           [-3.6756e-02, -2.9067e-02, -1.2503e-02]],\n",
      "\n",
      "          [[ 8.1172e-03,  1.1861e-03, -1.7841e-03],\n",
      "           [-4.6203e-02,  4.4680e-02,  3.4985e-02],\n",
      "           [ 4.2099e-02, -5.0639e-03, -4.7097e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.4187e-02, -3.6096e-02,  3.1164e-02],\n",
      "           [ 7.5190e-03,  4.1023e-02,  3.1429e-03],\n",
      "           [ 1.8318e-02,  6.3624e-02,  2.1921e-02]],\n",
      "\n",
      "          [[ 1.1545e-02, -1.9837e-02, -3.5228e-02],\n",
      "           [ 2.9286e-02,  4.2518e-02,  7.3927e-04],\n",
      "           [-3.5070e-03, -1.6072e-02, -4.5553e-02]],\n",
      "\n",
      "          [[-1.9957e-02,  1.1772e-02,  2.6600e-02],\n",
      "           [ 3.9853e-02, -2.8993e-02,  2.9086e-02],\n",
      "           [ 3.4747e-02,  3.5786e-03,  2.2638e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.7156e-02, -3.7123e-02, -2.8173e-02],\n",
      "           [-3.0174e-02, -3.4384e-02, -8.8043e-03],\n",
      "           [ 4.5212e-03,  5.1533e-02,  1.4910e-02]],\n",
      "\n",
      "          [[ 1.1223e-02, -3.4877e-02,  1.9780e-02],\n",
      "           [-3.6133e-02,  2.7609e-03,  4.1948e-02],\n",
      "           [ 3.9516e-02, -3.2049e-02,  8.8561e-03]],\n",
      "\n",
      "          [[ 9.5654e-03,  8.3826e-03, -3.1859e-02],\n",
      "           [-2.9583e-02,  2.0717e-02, -3.3481e-02],\n",
      "           [ 1.1538e-02, -3.5762e-02,  4.9328e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.7341e-02, -2.7303e-02,  4.4979e-02],\n",
      "           [ 5.0434e-03, -3.6275e-02, -2.2475e-02],\n",
      "           [ 4.4590e-02,  3.6006e-02,  3.3791e-02]],\n",
      "\n",
      "          [[ 3.8956e-02,  4.9063e-02,  1.5783e-02],\n",
      "           [-2.1148e-02,  3.8996e-04, -3.2131e-02],\n",
      "           [-5.1192e-03,  1.1386e-02, -6.4539e-03]],\n",
      "\n",
      "          [[-2.8637e-02,  3.5318e-02, -3.0191e-02],\n",
      "           [ 3.4402e-02, -3.5708e-02,  2.1815e-03],\n",
      "           [-1.5249e-02,  2.8958e-02,  3.3560e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.8284e-02,  4.9802e-02,  3.5243e-02],\n",
      "           [ 2.6513e-02, -1.5723e-03, -3.6526e-02],\n",
      "           [-2.2616e-02,  2.4812e-02,  3.7719e-02]],\n",
      "\n",
      "          [[-3.4968e-02, -1.4191e-02, -7.8321e-05],\n",
      "           [-2.6027e-02,  2.1124e-02,  4.3647e-03],\n",
      "           [ 2.8871e-03, -5.3327e-02, -3.6277e-02]],\n",
      "\n",
      "          [[ 4.9854e-03,  5.2247e-03,  1.4548e-02],\n",
      "           [-4.3457e-03, -4.4993e-02, -1.2297e-02],\n",
      "           [-3.6325e-02, -2.3163e-02, -2.0532e-02]]],\n",
      "\n",
      "\n",
      "         [[[-9.3653e-03,  2.1929e-02,  5.9418e-02],\n",
      "           [-1.2612e-02, -2.5821e-03,  4.8748e-02],\n",
      "           [-1.9960e-02, -2.9018e-02, -3.0790e-02]],\n",
      "\n",
      "          [[ 5.4220e-02, -1.7257e-02, -2.1969e-02],\n",
      "           [ 4.3910e-02,  3.7398e-02, -3.7934e-02],\n",
      "           [-1.0719e-02, -8.0621e-03,  3.3843e-02]],\n",
      "\n",
      "          [[-3.9669e-04, -8.9687e-03, -3.6575e-02],\n",
      "           [-3.9448e-02, -8.6111e-04, -7.1317e-03],\n",
      "           [-3.1492e-02, -1.2163e-02, -3.3026e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4015e-02,  1.9694e-02,  1.0256e-02],\n",
      "           [-3.5846e-02, -2.9299e-04,  3.7637e-02],\n",
      "           [ 5.1065e-02,  1.7965e-02,  3.2542e-02]],\n",
      "\n",
      "          [[-2.8536e-02,  1.2276e-02,  1.8869e-02],\n",
      "           [-3.1561e-02,  2.4639e-02, -7.9457e-03],\n",
      "           [ 2.3187e-02,  6.5977e-03,  2.5664e-02]],\n",
      "\n",
      "          [[ 3.7617e-03, -1.2044e-02,  1.0956e-02],\n",
      "           [ 1.4335e-02, -2.5960e-02,  2.6220e-02],\n",
      "           [-2.1223e-02, -3.2206e-02, -1.7869e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.1703e-02, -3.4118e-02, -2.0529e-02],\n",
      "           [-1.9664e-02,  2.9688e-02,  1.7208e-03],\n",
      "           [ 4.9949e-03,  2.7102e-02,  4.5639e-02]],\n",
      "\n",
      "          [[-2.8944e-02,  3.5258e-02,  4.3862e-02],\n",
      "           [ 1.5523e-02,  2.4888e-02,  3.9563e-02],\n",
      "           [-6.1744e-02,  2.5931e-02,  4.3551e-03]],\n",
      "\n",
      "          [[ 2.4176e-02, -4.7387e-02, -3.3961e-03],\n",
      "           [-1.8405e-02,  2.0982e-02,  1.0435e-02],\n",
      "           [-6.9333e-03,  1.6478e-02,  3.6900e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.9300e-02, -3.2362e-02,  2.8699e-02],\n",
      "           [-3.1397e-02, -5.1504e-02,  1.2140e-02],\n",
      "           [-3.6163e-03, -2.2288e-02, -6.4923e-03]],\n",
      "\n",
      "          [[ 2.9436e-02, -3.1579e-02, -3.8683e-02],\n",
      "           [-3.5100e-02,  2.0606e-02, -1.7719e-02],\n",
      "           [ 3.1407e-03, -2.4490e-02, -5.5619e-02]],\n",
      "\n",
      "          [[-9.0865e-03, -9.5108e-03, -2.8225e-02],\n",
      "           [-1.1265e-02, -8.9715e-03,  2.6400e-02],\n",
      "           [ 2.3299e-02,  1.4024e-03, -4.5493e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.9042e-02, -4.8811e-03, -2.6954e-02],\n",
      "           [ 3.3248e-02,  3.8434e-02,  2.9510e-03],\n",
      "           [-2.5403e-02, -1.1747e-02, -2.9219e-03]],\n",
      "\n",
      "          [[ 4.7145e-02, -3.2765e-02, -2.4046e-02],\n",
      "           [ 4.8664e-02,  1.1140e-02, -2.8305e-02],\n",
      "           [-7.4335e-03,  1.6918e-02,  6.7420e-03]],\n",
      "\n",
      "          [[ 2.0749e-02,  3.2098e-03,  3.2932e-02],\n",
      "           [-2.3771e-02, -4.0533e-02, -2.9006e-02],\n",
      "           [-2.2426e-05,  2.9994e-02,  5.6518e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.0148e-02, -7.8991e-03,  2.2884e-02],\n",
      "           [-3.1219e-02,  4.5807e-02, -1.3517e-02],\n",
      "           [-3.8777e-02,  5.1343e-03,  1.9952e-02]],\n",
      "\n",
      "          [[-1.7065e-02,  5.5857e-02,  6.0678e-02],\n",
      "           [-6.7471e-03,  8.1505e-03, -2.3945e-02],\n",
      "           [-6.1074e-03,  2.0069e-02, -5.5239e-03]],\n",
      "\n",
      "          [[ 1.5298e-02,  9.0147e-03,  3.1648e-02],\n",
      "           [ 9.1311e-03, -1.1739e-02,  4.4845e-02],\n",
      "           [-3.0472e-02, -4.2087e-02, -4.4247e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.4544e-02,  6.6441e-02,  1.9551e-02],\n",
      "           [-3.9740e-02, -1.0147e-02, -6.3954e-03],\n",
      "           [-1.9633e-03, -6.1604e-03, -4.2462e-02]],\n",
      "\n",
      "          [[-4.6932e-05,  7.3546e-02, -3.1494e-03],\n",
      "           [ 3.8510e-02,  1.0651e-03, -2.1117e-04],\n",
      "           [-8.7401e-03, -1.4748e-02, -8.8347e-03]],\n",
      "\n",
      "          [[-1.8461e-03,  1.5314e-02, -2.2634e-02],\n",
      "           [ 2.3254e-02, -6.5983e-03,  3.8420e-02],\n",
      "           [-5.5655e-02,  3.5703e-02,  2.0911e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.8771e-02,  9.7209e-03,  3.5315e-02],\n",
      "           [ 1.5901e-02, -4.7707e-02,  3.7225e-02],\n",
      "           [ 4.1017e-04,  4.0080e-02,  1.6102e-02]],\n",
      "\n",
      "          [[-4.2975e-02,  2.2280e-03, -4.8178e-03],\n",
      "           [-3.4851e-02, -5.4081e-02, -4.9918e-02],\n",
      "           [-3.3874e-02,  3.2368e-02, -4.0426e-02]],\n",
      "\n",
      "          [[ 5.6966e-03,  2.2645e-02, -2.6725e-02],\n",
      "           [ 9.9477e-03, -1.0781e-03,  1.8250e-02],\n",
      "           [-4.5994e-02, -4.6959e-03,  8.2994e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.8698e-02, -8.5022e-03,  3.6366e-04],\n",
      "           [ 4.3242e-02, -3.8747e-02, -2.3812e-02],\n",
      "           [-3.4802e-02,  1.8525e-02,  6.2667e-03]],\n",
      "\n",
      "          [[ 4.5245e-02,  2.3457e-02, -4.9157e-02],\n",
      "           [-2.3806e-02,  3.2107e-02,  3.3380e-02],\n",
      "           [-5.4025e-03, -3.2502e-02, -1.2781e-02]],\n",
      "\n",
      "          [[ 2.0849e-03, -4.5337e-02, -3.1241e-02],\n",
      "           [ 3.9479e-02, -1.2074e-02, -1.1534e-02],\n",
      "           [-8.4564e-03,  7.6270e-03,  4.9486e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.0351e-02, -4.4381e-02, -2.8433e-02],\n",
      "           [-3.8260e-02,  2.7856e-03, -4.6725e-02],\n",
      "           [-3.5411e-02, -4.0080e-02, -9.3436e-03]],\n",
      "\n",
      "          [[-3.3768e-02,  4.0079e-02,  7.6018e-03],\n",
      "           [ 1.1832e-02,  8.4494e-03, -2.5163e-02],\n",
      "           [ 3.6489e-02,  4.2601e-02, -1.2509e-02]],\n",
      "\n",
      "          [[ 2.0971e-02,  3.8296e-02,  5.5519e-03],\n",
      "           [-4.9919e-03, -1.1692e-02,  5.3587e-03],\n",
      "           [-1.7702e-02,  2.3714e-02, -7.6488e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 4.4638e-02, -2.1726e-02, -3.4659e-02],\n",
      "           [ 2.8629e-02, -8.7634e-04, -3.4298e-03],\n",
      "           [ 1.7659e-02, -2.1565e-02, -3.1410e-02]],\n",
      "\n",
      "          [[-3.2632e-02,  1.3083e-02, -2.9677e-02],\n",
      "           [-1.3899e-02,  3.4680e-02, -4.8017e-02],\n",
      "           [ 1.5956e-03,  2.8433e-02, -5.1852e-02]],\n",
      "\n",
      "          [[-5.3743e-03,  2.7227e-02, -2.8401e-02],\n",
      "           [ 1.9605e-02,  4.2415e-02,  3.8869e-02],\n",
      "           [ 2.4472e-02, -2.3481e-02,  2.2987e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.4478e-03,  3.0464e-03,  4.3845e-02],\n",
      "           [-4.7897e-02, -4.2897e-02,  2.9962e-02],\n",
      "           [-1.1270e-02, -3.8932e-02,  4.6177e-02]],\n",
      "\n",
      "          [[-1.7526e-02, -2.3537e-02, -1.9658e-02],\n",
      "           [-3.1528e-02, -1.0884e-02, -3.9571e-03],\n",
      "           [ 5.4898e-02,  4.9144e-02,  6.6888e-03]],\n",
      "\n",
      "          [[-4.1587e-02,  7.0619e-03, -4.2141e-02],\n",
      "           [-2.5098e-02,  3.3615e-02,  4.4767e-02],\n",
      "           [ 2.7160e-02, -3.0525e-02,  1.6663e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.0744e-02,  1.1334e-02, -3.6285e-04],\n",
      "           [-5.5988e-02, -6.9089e-03,  5.4550e-03],\n",
      "           [ 1.9382e-02, -5.2942e-03,  2.5556e-02]],\n",
      "\n",
      "          [[-2.7262e-02, -6.9866e-03, -5.2662e-02],\n",
      "           [-2.1605e-02,  2.1007e-02,  1.1883e-02],\n",
      "           [ 4.1522e-02, -3.3579e-02, -1.4438e-02]],\n",
      "\n",
      "          [[ 1.2529e-02,  1.0353e-02,  4.0551e-02],\n",
      "           [-4.5412e-02,  3.3166e-02,  2.4946e-02],\n",
      "           [ 1.4505e-02,  3.8202e-02, -8.7943e-03]]],\n",
      "\n",
      "\n",
      "         [[[-8.3142e-03,  3.8591e-02, -2.2992e-02],\n",
      "           [ 1.0202e-02,  4.9991e-03, -8.8603e-03],\n",
      "           [-2.1324e-02,  1.2089e-02,  2.3795e-02]],\n",
      "\n",
      "          [[-3.3332e-02,  1.0982e-03,  3.0120e-02],\n",
      "           [ 2.7703e-02,  1.7323e-07,  4.4288e-03],\n",
      "           [-1.1479e-02, -8.5992e-03,  3.8697e-03]],\n",
      "\n",
      "          [[ 2.9188e-02, -1.8297e-02, -1.0381e-02],\n",
      "           [-3.7376e-02, -1.3731e-02,  2.0999e-02],\n",
      "           [-1.1454e-02,  2.5562e-02, -2.5929e-02]]]]], device='cuda:0')), ('module.down_layers.0.1.conv2.conv.weight', tensor([[[[[ 4.0468e-02,  5.0378e-03,  1.3045e-02],\n",
      "           [-2.4431e-02, -3.7254e-02,  8.5162e-03],\n",
      "           [-8.1097e-04, -3.6708e-02,  4.2538e-02]],\n",
      "\n",
      "          [[-4.2650e-02,  5.6434e-03,  8.0345e-03],\n",
      "           [-2.4768e-02, -7.4569e-03, -2.3589e-03],\n",
      "           [-5.2384e-02,  2.6785e-03,  4.3180e-02]],\n",
      "\n",
      "          [[-1.5652e-02,  7.6133e-03, -1.0286e-02],\n",
      "           [-1.2266e-02, -1.4660e-02,  3.7162e-02],\n",
      "           [-1.0323e-04, -3.9777e-02,  1.8930e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.8962e-02, -1.1956e-02,  7.2014e-03],\n",
      "           [ 1.7734e-02, -8.7199e-03,  2.6733e-02],\n",
      "           [-5.0973e-03, -2.0826e-02,  4.6316e-02]],\n",
      "\n",
      "          [[ 1.2540e-02,  1.8478e-02,  8.9466e-03],\n",
      "           [ 2.7658e-02,  3.1994e-02,  3.2101e-02],\n",
      "           [-2.0756e-02,  7.0449e-02,  1.6980e-03]],\n",
      "\n",
      "          [[-1.1409e-02,  4.8268e-02, -2.1993e-02],\n",
      "           [ 1.6308e-02,  4.2529e-02,  5.8167e-02],\n",
      "           [-2.3719e-02,  6.5908e-02,  5.1941e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.9867e-02,  1.0952e-02,  2.1907e-03],\n",
      "           [-1.9583e-02,  2.8969e-02, -3.9785e-02],\n",
      "           [ 4.4211e-02,  1.0773e-02,  2.2366e-02]],\n",
      "\n",
      "          [[ 2.0509e-02, -4.3104e-02, -3.7241e-02],\n",
      "           [-2.0930e-02, -1.8716e-02, -4.8918e-02],\n",
      "           [ 1.7110e-03,  1.3290e-02,  2.4576e-03]],\n",
      "\n",
      "          [[ 2.4104e-02,  4.4300e-03,  2.7447e-02],\n",
      "           [ 3.4781e-02, -2.5779e-02,  2.2482e-02],\n",
      "           [-8.4695e-03, -2.1716e-02, -2.3485e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.8255e-02,  2.8850e-03,  1.6521e-02],\n",
      "           [-6.7938e-02,  1.1628e-02,  4.4935e-03],\n",
      "           [-7.0385e-02, -6.1553e-02,  1.6164e-02]],\n",
      "\n",
      "          [[ 1.9315e-02, -2.0037e-02, -2.1262e-02],\n",
      "           [ 3.8951e-02,  2.8464e-02, -3.2855e-02],\n",
      "           [ 3.3043e-02, -3.4880e-02,  3.0317e-02]],\n",
      "\n",
      "          [[ 2.5814e-02,  2.2083e-02, -3.5584e-02],\n",
      "           [ 5.0056e-02,  1.2488e-02, -4.0972e-02],\n",
      "           [ 4.2072e-02,  1.6300e-03, -6.5204e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.6666e-02, -3.0571e-02,  1.5828e-02],\n",
      "           [ 4.5279e-02,  5.4068e-02, -3.6438e-02],\n",
      "           [-2.0340e-02,  1.6259e-02,  1.1623e-02]],\n",
      "\n",
      "          [[ 3.4094e-03,  3.9234e-02, -4.4289e-02],\n",
      "           [ 3.3859e-02, -8.3433e-03, -2.3077e-02],\n",
      "           [ 7.3149e-02,  9.4451e-03,  2.2278e-02]],\n",
      "\n",
      "          [[-3.2998e-02, -5.4170e-02, -1.9228e-02],\n",
      "           [ 4.6570e-02,  1.4776e-02, -5.6288e-02],\n",
      "           [ 4.3380e-02,  2.6639e-02, -1.9819e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.6768e-03,  2.3609e-03, -5.3089e-03],\n",
      "           [ 2.7925e-02, -5.7975e-02,  2.5341e-02],\n",
      "           [-4.3661e-02, -1.5409e-03,  3.8702e-02]],\n",
      "\n",
      "          [[-3.5112e-02,  2.5204e-02,  2.8164e-02],\n",
      "           [ 4.0868e-02, -5.1939e-03, -1.7474e-02],\n",
      "           [-8.2930e-03,  2.7774e-02, -7.0407e-04]],\n",
      "\n",
      "          [[-1.7287e-02, -2.9085e-02, -3.2707e-02],\n",
      "           [-5.2100e-02, -1.2854e-02,  2.8419e-02],\n",
      "           [-2.8822e-02,  1.9222e-02, -1.3120e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.2904e-02,  1.5691e-02,  3.8727e-02],\n",
      "           [-4.8825e-02, -2.7630e-02, -2.0990e-02],\n",
      "           [ 1.2820e-02,  3.3994e-02, -5.2044e-02]],\n",
      "\n",
      "          [[-2.9392e-03, -2.9719e-02,  2.2170e-02],\n",
      "           [-1.1741e-02,  3.9054e-02,  1.3944e-02],\n",
      "           [-1.3769e-02, -3.3940e-02,  2.2446e-02]],\n",
      "\n",
      "          [[-3.0983e-02, -1.6161e-02,  9.7242e-03],\n",
      "           [ 1.6819e-02, -8.9195e-03, -2.9830e-02],\n",
      "           [ 3.2595e-02, -4.5026e-04,  1.1624e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.6999e-02,  2.7899e-02, -2.0270e-02],\n",
      "           [ 4.8777e-02,  3.5259e-02,  4.4701e-03],\n",
      "           [ 3.7961e-02, -6.2425e-03,  6.5980e-03]],\n",
      "\n",
      "          [[ 4.4056e-02,  1.5282e-02,  2.5870e-02],\n",
      "           [-3.1908e-02,  1.7656e-02, -1.6615e-02],\n",
      "           [-2.4057e-03,  5.7922e-03,  1.1156e-02]],\n",
      "\n",
      "          [[ 1.1029e-03,  4.8273e-02, -2.1594e-02],\n",
      "           [ 2.1486e-02,  1.3863e-03, -6.2867e-03],\n",
      "           [ 2.5368e-02, -2.9495e-02,  3.9913e-02]]],\n",
      "\n",
      "\n",
      "         [[[-6.4826e-03, -3.9703e-02,  3.7272e-02],\n",
      "           [ 4.0502e-02, -1.8208e-02, -3.8157e-02],\n",
      "           [ 2.2106e-02, -9.3116e-03, -1.5551e-02]],\n",
      "\n",
      "          [[ 4.6969e-02,  1.8422e-02,  4.5163e-03],\n",
      "           [ 4.4642e-02, -4.4781e-02,  4.6720e-02],\n",
      "           [ 6.6660e-03, -1.5281e-02, -1.7587e-02]],\n",
      "\n",
      "          [[ 8.1063e-03,  5.1941e-02,  3.1997e-02],\n",
      "           [-4.5614e-02,  9.8017e-03, -1.1208e-02],\n",
      "           [-2.2748e-02, -1.9613e-02,  4.9240e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-7.5638e-03,  3.3161e-02, -4.5771e-02],\n",
      "           [ 2.8258e-03,  3.2953e-02,  3.3197e-02],\n",
      "           [ 1.2825e-02, -1.8166e-02, -2.8483e-02]],\n",
      "\n",
      "          [[ 9.0894e-03, -1.2356e-02,  1.6877e-02],\n",
      "           [ 4.1790e-02,  1.0202e-02,  3.8887e-02],\n",
      "           [-5.6288e-03,  2.7788e-02,  4.4370e-02]],\n",
      "\n",
      "          [[-4.3689e-02, -9.3115e-03, -2.9604e-02],\n",
      "           [-2.2324e-02,  7.5771e-03,  2.0546e-02],\n",
      "           [-3.7227e-02, -3.5773e-02, -2.0198e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3878e-02,  5.5897e-02, -2.9600e-02],\n",
      "           [-1.5564e-02, -6.8179e-03, -4.6983e-02],\n",
      "           [ 4.8763e-02, -1.9836e-02, -1.9584e-02]],\n",
      "\n",
      "          [[ 4.2174e-02, -2.8794e-02,  1.9511e-02],\n",
      "           [ 5.5087e-02,  6.8413e-02,  3.6263e-02],\n",
      "           [ 4.7442e-02,  2.0606e-02,  4.0077e-02]],\n",
      "\n",
      "          [[-2.3287e-02, -1.1400e-03,  2.5724e-03],\n",
      "           [ 4.0854e-02,  9.0310e-03, -4.0346e-03],\n",
      "           [-3.0644e-02,  3.5397e-02, -4.5782e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.5703e-02,  4.1639e-02,  8.9736e-03],\n",
      "           [ 3.5417e-02,  9.6144e-03, -1.6285e-02],\n",
      "           [-4.2178e-02, -4.5904e-02, -7.4667e-03]],\n",
      "\n",
      "          [[-2.9490e-02,  2.8852e-02,  3.1547e-02],\n",
      "           [ 2.4480e-02, -1.8172e-02, -3.6183e-03],\n",
      "           [ 1.1599e-02,  5.9704e-02,  7.4246e-03]],\n",
      "\n",
      "          [[ 2.8365e-02,  2.1014e-02, -2.9178e-02],\n",
      "           [ 3.8195e-02, -1.4628e-02, -9.0201e-04],\n",
      "           [ 2.8434e-02, -1.3981e-02,  6.0103e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.6626e-02,  4.9220e-02, -4.2713e-02],\n",
      "           [ 2.4420e-02, -3.9436e-02, -4.9016e-02],\n",
      "           [ 2.1267e-02,  4.5829e-02,  3.6924e-02]],\n",
      "\n",
      "          [[ 3.8751e-03,  5.1844e-02, -2.4944e-02],\n",
      "           [-2.6954e-02,  4.3130e-03,  1.2467e-02],\n",
      "           [-1.0237e-02, -4.1147e-02, -2.9053e-02]],\n",
      "\n",
      "          [[-2.2587e-02, -3.5607e-02,  3.6602e-02],\n",
      "           [ 1.4388e-02, -4.8066e-02, -3.9816e-02],\n",
      "           [-2.5136e-02,  2.7737e-02, -2.5159e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.3032e-03,  3.1374e-02, -2.0970e-02],\n",
      "           [ 5.2544e-02, -2.5387e-02, -2.3053e-02],\n",
      "           [ 2.8404e-02,  4.9810e-02,  9.1049e-03]],\n",
      "\n",
      "          [[-6.8302e-03, -2.5761e-02, -3.9658e-02],\n",
      "           [ 3.7550e-02,  2.3263e-02, -2.2051e-02],\n",
      "           [ 5.6974e-02,  4.3512e-02, -3.6506e-02]],\n",
      "\n",
      "          [[ 3.3898e-02,  2.6342e-02, -4.1780e-02],\n",
      "           [-3.4261e-02,  1.0043e-02,  9.2901e-04],\n",
      "           [-3.9250e-02, -8.1517e-03, -2.5787e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4513e-02,  3.7986e-02, -5.1790e-02],\n",
      "           [ 8.8324e-03,  1.3855e-02, -1.6190e-02],\n",
      "           [ 1.1632e-02,  2.7242e-02,  5.2550e-03]],\n",
      "\n",
      "          [[ 5.3770e-03, -2.6238e-02,  2.4998e-02],\n",
      "           [-3.8030e-02, -1.1399e-02,  5.9904e-03],\n",
      "           [-7.6134e-03, -6.6279e-03, -2.3107e-02]],\n",
      "\n",
      "          [[-3.8992e-02, -2.2424e-02,  1.7018e-02],\n",
      "           [-1.0668e-02,  4.3816e-02, -1.9441e-02],\n",
      "           [-3.5446e-02,  4.8502e-02, -2.7909e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.0056e-02, -1.7663e-03,  2.4600e-02],\n",
      "           [ 1.8400e-02, -3.0579e-02, -3.6358e-02],\n",
      "           [ 7.9762e-03,  2.7800e-02, -2.4547e-03]],\n",
      "\n",
      "          [[-6.0096e-03, -4.2977e-02, -1.3920e-02],\n",
      "           [ 7.6817e-03,  4.0228e-02,  3.8385e-02],\n",
      "           [ 4.7739e-02, -3.3602e-02,  4.0442e-02]],\n",
      "\n",
      "          [[ 4.6878e-02,  4.6388e-02,  1.9701e-02],\n",
      "           [ 8.6788e-03, -3.4908e-02, -3.5944e-02],\n",
      "           [ 1.0816e-02,  2.8463e-03,  6.0586e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.6269e-02,  3.6003e-02,  3.9044e-02],\n",
      "           [ 1.9485e-02, -2.1786e-02, -2.4530e-02],\n",
      "           [ 3.6633e-02, -1.8351e-02, -3.9372e-02]],\n",
      "\n",
      "          [[ 8.1468e-03,  3.8092e-02,  1.1404e-02],\n",
      "           [-1.3203e-02,  2.2966e-02, -3.4765e-02],\n",
      "           [ 3.0790e-02, -3.0333e-02, -6.4537e-04]],\n",
      "\n",
      "          [[ 3.1648e-02,  2.5895e-02,  3.5242e-02],\n",
      "           [-1.4335e-02, -4.2557e-02, -6.0142e-04],\n",
      "           [-4.4944e-02, -3.3823e-02, -1.8774e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.4618e-02,  3.6961e-02, -1.2565e-02],\n",
      "           [-4.8373e-02,  2.7464e-02, -2.0408e-02],\n",
      "           [ 5.1400e-03,  1.6402e-02,  2.4741e-02]],\n",
      "\n",
      "          [[ 1.7788e-02, -3.4060e-02, -4.2102e-02],\n",
      "           [-1.2326e-02, -4.4769e-02,  8.2398e-03],\n",
      "           [ 8.4898e-03,  1.6920e-02, -2.0813e-02]],\n",
      "\n",
      "          [[ 1.0256e-02, -4.8547e-02, -6.4770e-03],\n",
      "           [ 1.4112e-02, -3.6800e-03,  4.1972e-02],\n",
      "           [-1.6919e-02,  7.5074e-03,  3.7838e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.2659e-04,  2.6557e-02,  3.0089e-02],\n",
      "           [-4.8372e-02,  3.3817e-02,  3.6262e-02],\n",
      "           [-2.8176e-02,  2.8577e-02,  3.4563e-04]],\n",
      "\n",
      "          [[-1.8663e-02, -4.0660e-03,  2.3270e-02],\n",
      "           [-2.9545e-02, -9.0996e-03,  4.9966e-02],\n",
      "           [-1.6246e-02, -4.9033e-03,  4.4394e-02]],\n",
      "\n",
      "          [[-9.3018e-03, -1.8979e-02, -3.2132e-02],\n",
      "           [-1.5788e-02,  2.5504e-04,  2.4651e-02],\n",
      "           [-4.0227e-02, -1.7399e-04,  4.9012e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2671e-02,  3.7077e-02, -5.0446e-02],\n",
      "           [-3.2876e-03, -2.4640e-02, -4.3176e-02],\n",
      "           [-3.8892e-02,  5.1894e-04,  2.8092e-02]],\n",
      "\n",
      "          [[-2.3549e-02, -3.9021e-02, -3.9001e-02],\n",
      "           [-4.2545e-02, -2.9941e-02, -9.9960e-03],\n",
      "           [-2.4258e-02, -1.7999e-02,  4.3523e-02]],\n",
      "\n",
      "          [[-4.0534e-02,  2.3410e-02,  2.3663e-02],\n",
      "           [ 1.4047e-02, -3.9587e-02,  1.3712e-03],\n",
      "           [-2.9041e-02,  3.4810e-02,  5.2137e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.9170e-02, -1.1583e-02,  5.6669e-02],\n",
      "           [ 1.2909e-02,  2.7350e-02, -6.6621e-03],\n",
      "           [-1.7988e-02,  1.1521e-02, -1.8495e-02]],\n",
      "\n",
      "          [[-3.0753e-02,  5.1740e-02,  3.2269e-02],\n",
      "           [-2.8151e-02,  4.2138e-02, -2.6935e-02],\n",
      "           [ 3.3077e-02, -4.3969e-02, -2.6410e-02]],\n",
      "\n",
      "          [[ 1.6843e-02,  1.2219e-02, -3.2201e-02],\n",
      "           [ 3.0076e-02,  1.2734e-02, -9.5497e-03],\n",
      "           [ 1.5690e-02, -9.6055e-03, -4.6240e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.8642e-02,  1.9211e-02, -2.3826e-02],\n",
      "           [-4.6995e-02, -6.5209e-03, -1.4668e-02],\n",
      "           [-5.3900e-02, -1.3529e-04,  2.6296e-02]],\n",
      "\n",
      "          [[-2.6254e-02, -4.0596e-02, -3.3599e-02],\n",
      "           [-3.1273e-02, -2.8534e-02,  1.3337e-02],\n",
      "           [-4.7870e-02,  3.2993e-02, -2.0321e-02]],\n",
      "\n",
      "          [[ 3.4905e-03, -2.7983e-02,  5.1643e-02],\n",
      "           [ 4.2276e-02,  3.8945e-03,  5.8090e-02],\n",
      "           [ 5.5189e-04,  3.8933e-02,  1.3173e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.7364e-02,  8.9864e-03, -1.1616e-03],\n",
      "           [-1.6567e-02, -3.7815e-02,  2.7497e-02],\n",
      "           [ 1.8256e-02,  4.6338e-02, -1.6874e-02]],\n",
      "\n",
      "          [[-1.8300e-02,  4.1138e-02,  7.2760e-03],\n",
      "           [ 3.7505e-03,  1.9426e-02,  1.6662e-02],\n",
      "           [-4.8917e-02, -1.5069e-02,  4.3318e-02]],\n",
      "\n",
      "          [[-3.3192e-02, -2.1338e-02,  1.0515e-02],\n",
      "           [ 4.1838e-02,  3.2817e-02, -1.4009e-02],\n",
      "           [-3.9674e-02,  2.1494e-02, -3.4195e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 6.0577e-02, -1.3210e-02,  1.8254e-02],\n",
      "           [ 2.2175e-02,  4.7770e-02, -2.9296e-02],\n",
      "           [-2.8193e-03, -3.4328e-02,  3.2223e-02]],\n",
      "\n",
      "          [[-6.2326e-03,  2.5558e-02, -3.6953e-02],\n",
      "           [-1.3287e-02, -2.9819e-02,  2.6691e-02],\n",
      "           [ 3.6311e-02, -4.6322e-02, -1.5555e-02]],\n",
      "\n",
      "          [[ 4.8721e-03, -2.0970e-02, -3.7134e-02],\n",
      "           [ 2.9979e-02, -6.5571e-04,  1.0519e-02],\n",
      "           [ 2.7313e-02,  3.2230e-02,  4.1576e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.2324e-03,  3.4681e-02,  4.7278e-02],\n",
      "           [-1.4702e-02,  2.6621e-02, -1.8712e-03],\n",
      "           [ 2.0338e-02,  1.7148e-02,  2.8250e-02]],\n",
      "\n",
      "          [[ 7.8955e-03, -1.9291e-02,  3.5393e-02],\n",
      "           [ 3.0941e-02,  6.8022e-03,  5.8181e-02],\n",
      "           [ 3.4562e-02, -1.6316e-02, -8.0823e-03]],\n",
      "\n",
      "          [[-2.8880e-02, -4.6428e-03,  2.6155e-02],\n",
      "           [ 4.9433e-02,  3.0376e-02,  3.0731e-02],\n",
      "           [ 1.7966e-02,  2.0547e-02,  3.5595e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.7155e-02,  1.1193e-02,  4.0593e-02],\n",
      "           [-5.6793e-02, -2.4966e-02, -3.1779e-02],\n",
      "           [-9.5992e-03,  3.1284e-02,  4.2181e-02]],\n",
      "\n",
      "          [[ 1.8631e-02,  3.1778e-02,  2.5142e-02],\n",
      "           [ 2.1037e-02,  1.1207e-02,  2.2584e-03],\n",
      "           [-4.8723e-02, -1.7005e-02,  2.3866e-02]],\n",
      "\n",
      "          [[-3.1440e-02, -7.4420e-03, -8.7058e-03],\n",
      "           [ 4.0720e-02, -1.1023e-02, -1.6080e-02],\n",
      "           [ 2.2995e-02, -4.6932e-03,  3.8174e-02]]],\n",
      "\n",
      "\n",
      "         [[[-8.3776e-03, -1.9359e-02,  4.2239e-02],\n",
      "           [-1.3086e-02, -2.0300e-02, -5.6714e-02],\n",
      "           [-1.8213e-02,  1.7859e-02, -2.5333e-02]],\n",
      "\n",
      "          [[ 8.2742e-03,  3.2438e-02, -5.4354e-02],\n",
      "           [-5.8633e-02, -4.7811e-02,  2.4888e-02],\n",
      "           [-3.7344e-02, -2.0069e-04, -4.1683e-02]],\n",
      "\n",
      "          [[-3.2415e-02, -5.6698e-02,  1.2006e-02],\n",
      "           [-1.0627e-03, -6.7410e-03,  1.3724e-02],\n",
      "           [-1.6199e-02, -4.8113e-02,  1.8141e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.7838e-05,  2.3383e-02, -4.2593e-02],\n",
      "           [ 3.8509e-02,  2.9679e-02, -1.3480e-02],\n",
      "           [-1.7237e-02,  4.7001e-02, -1.7576e-02]],\n",
      "\n",
      "          [[-5.1541e-02,  4.5659e-02,  4.3358e-02],\n",
      "           [-3.6671e-02, -1.4889e-03,  4.3639e-02],\n",
      "           [-1.9284e-02,  4.3745e-02,  1.2254e-02]],\n",
      "\n",
      "          [[ 1.1533e-02, -1.5219e-02, -1.7544e-02],\n",
      "           [-4.4439e-03,  3.6750e-02,  4.0971e-02],\n",
      "           [-2.6127e-02, -1.1960e-02,  3.4958e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.1574e-03, -5.0899e-02, -1.5583e-02],\n",
      "           [-2.8905e-02, -4.9754e-03, -3.7245e-02],\n",
      "           [ 2.0291e-02, -3.3733e-02, -2.8112e-02]],\n",
      "\n",
      "          [[-5.2456e-02, -1.4085e-02,  7.2150e-03],\n",
      "           [ 5.6519e-02,  3.4375e-02, -3.1468e-02],\n",
      "           [ 2.9993e-02,  3.8733e-02, -2.8017e-02]],\n",
      "\n",
      "          [[ 3.3769e-02,  1.9828e-02,  2.5647e-04],\n",
      "           [ 1.8585e-02,  2.8093e-02, -1.0445e-03],\n",
      "           [-7.0101e-03,  1.8096e-02,  2.4920e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.2117e-02,  9.4882e-04,  1.0761e-02],\n",
      "           [ 2.1008e-03,  1.8350e-02, -3.3476e-02],\n",
      "           [-3.7249e-02, -4.7925e-02,  1.6478e-02]],\n",
      "\n",
      "          [[ 1.7215e-02, -2.0078e-02,  1.5011e-02],\n",
      "           [-5.1387e-02,  1.1954e-02, -4.4713e-02],\n",
      "           [-2.0091e-02, -3.9900e-02,  2.1577e-02]],\n",
      "\n",
      "          [[ 1.7732e-02, -4.1816e-02, -3.7612e-02],\n",
      "           [-5.9951e-02, -1.1112e-02, -3.6275e-02],\n",
      "           [-1.4441e-02, -2.3782e-02,  5.2559e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.7058e-02,  1.2204e-02, -2.4869e-02],\n",
      "           [ 2.3967e-02, -2.4097e-02,  1.5663e-02],\n",
      "           [ 1.3708e-02, -3.1585e-02, -1.6646e-03]],\n",
      "\n",
      "          [[ 3.4105e-02,  3.2162e-02,  2.7515e-02],\n",
      "           [ 3.6466e-03, -2.2395e-02, -3.7695e-02],\n",
      "           [ 4.0728e-02, -3.6893e-02,  4.6017e-02]],\n",
      "\n",
      "          [[ 6.5753e-03,  1.9086e-02,  7.4464e-04],\n",
      "           [-3.1284e-02,  2.8431e-03, -1.9824e-02],\n",
      "           [-1.8340e-02,  3.9941e-03,  3.2536e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1670e-02,  2.5250e-02, -8.0987e-03],\n",
      "           [-2.7572e-02,  4.8606e-02,  2.5754e-02],\n",
      "           [-2.8374e-02, -1.5345e-02,  3.6888e-02]],\n",
      "\n",
      "          [[-2.9819e-03, -1.1890e-02,  1.2203e-02],\n",
      "           [ 3.3489e-03, -4.4638e-02,  2.0168e-02],\n",
      "           [ 3.8036e-02, -4.5884e-02, -4.3269e-02]],\n",
      "\n",
      "          [[-9.1684e-04, -3.2050e-02, -3.0293e-02],\n",
      "           [ 9.5228e-03, -5.3375e-03, -3.6200e-02],\n",
      "           [-2.4390e-02, -1.6643e-02, -2.2567e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1684e-02, -2.8059e-02, -6.2375e-03],\n",
      "           [-5.3848e-03,  4.1022e-02, -3.8308e-02],\n",
      "           [ 3.6406e-02, -9.9224e-03, -2.0801e-02]],\n",
      "\n",
      "          [[ 4.2765e-03,  4.6257e-02,  6.6910e-03],\n",
      "           [ 5.1599e-02,  4.7789e-02,  2.6594e-03],\n",
      "           [ 4.1559e-02, -1.4633e-02,  2.9471e-02]],\n",
      "\n",
      "          [[-3.5048e-02, -2.9081e-02,  4.1621e-02],\n",
      "           [-3.4675e-02,  3.5665e-02,  6.9618e-03],\n",
      "           [-4.0285e-02,  2.7382e-02, -2.4218e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.7741e-03, -5.9919e-04, -3.8136e-03],\n",
      "           [ 2.5565e-02, -1.4428e-02, -7.0741e-03],\n",
      "           [ 1.0281e-02,  3.1417e-02, -3.2426e-02]],\n",
      "\n",
      "          [[ 5.1159e-02, -3.4179e-02,  2.6259e-02],\n",
      "           [-1.1459e-02, -6.6413e-03, -2.6308e-03],\n",
      "           [-3.1517e-02, -4.3114e-02, -1.4509e-02]],\n",
      "\n",
      "          [[ 1.9295e-03, -4.0041e-02, -2.9740e-02],\n",
      "           [ 3.7284e-02, -2.2136e-02, -7.6360e-03],\n",
      "           [ 1.3715e-02, -1.1144e-02, -3.6385e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1804e-02,  8.7342e-03, -2.0681e-02],\n",
      "           [-4.9492e-02,  3.1963e-02,  3.5009e-02],\n",
      "           [-1.2905e-02, -4.2167e-02, -1.8823e-02]],\n",
      "\n",
      "          [[ 2.1390e-03, -3.4360e-02,  2.9940e-02],\n",
      "           [ 2.5155e-02, -4.9930e-02,  1.7924e-02],\n",
      "           [-3.2642e-02, -3.8606e-02,  1.5892e-02]],\n",
      "\n",
      "          [[ 1.2425e-02,  3.6025e-02,  3.7096e-02],\n",
      "           [-3.9286e-02, -4.2573e-03,  4.8959e-02],\n",
      "           [-2.7741e-02, -2.3050e-02, -4.1120e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.5194e-03,  3.4064e-02,  2.3182e-02],\n",
      "           [-2.1190e-02,  4.9152e-02,  5.0301e-02],\n",
      "           [ 5.7504e-03, -2.5892e-02, -3.4176e-02]],\n",
      "\n",
      "          [[-2.7616e-02,  5.1510e-02, -2.5444e-02],\n",
      "           [-3.0881e-02,  2.2317e-03,  7.8816e-03],\n",
      "           [-2.0769e-02,  2.2218e-02,  1.2259e-02]],\n",
      "\n",
      "          [[-2.5326e-02,  1.4367e-02,  4.8512e-02],\n",
      "           [-3.7134e-02,  1.5087e-02,  4.4103e-04],\n",
      "           [ 4.6481e-02, -2.1861e-03,  2.9317e-04]]]]], device='cuda:0')), ('module.down_layers.1.0.conv.weight', tensor([[[[[ 1.5821e-02,  2.3190e-02,  6.4365e-03],\n",
      "           [ 9.3566e-03,  1.9005e-02, -3.3644e-02],\n",
      "           [ 3.4047e-02, -1.1964e-02, -4.1296e-02]],\n",
      "\n",
      "          [[-4.1677e-02, -1.2232e-02, -3.1204e-02],\n",
      "           [-3.9214e-03, -2.0391e-02,  6.8224e-03],\n",
      "           [-1.4195e-02,  3.8376e-02,  2.0919e-02]],\n",
      "\n",
      "          [[-4.8581e-02,  4.5389e-02,  3.6373e-02],\n",
      "           [ 2.1651e-02,  4.0327e-02,  1.9929e-02],\n",
      "           [ 5.0769e-02, -1.8762e-02, -3.6231e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.3355e-03, -3.4905e-02,  7.3578e-04],\n",
      "           [ 7.3328e-03, -3.3223e-02,  2.0687e-02],\n",
      "           [ 5.0406e-03, -3.2658e-02, -2.7904e-02]],\n",
      "\n",
      "          [[-3.7667e-02, -3.0683e-02,  1.7131e-02],\n",
      "           [-3.0030e-02,  1.1181e-03, -3.4841e-02],\n",
      "           [ 9.0545e-03,  2.0001e-02,  3.6863e-02]],\n",
      "\n",
      "          [[-3.6040e-02,  3.0338e-03, -1.3730e-02],\n",
      "           [-4.9538e-02,  1.6536e-02, -2.0921e-02],\n",
      "           [-2.0756e-02, -2.1557e-02,  5.2449e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.8044e-02, -1.8566e-02,  2.5596e-02],\n",
      "           [ 2.4587e-02,  2.9642e-02, -1.2782e-02],\n",
      "           [-1.6431e-02, -3.3165e-02, -4.1665e-02]],\n",
      "\n",
      "          [[-5.5501e-03, -9.4717e-03, -2.8287e-02],\n",
      "           [-1.2208e-02,  1.7798e-05,  2.0178e-02],\n",
      "           [-1.3102e-02,  2.5463e-02,  3.4030e-02]],\n",
      "\n",
      "          [[ 4.8203e-02, -1.7303e-02,  2.7682e-02],\n",
      "           [-3.1969e-02, -1.9712e-02,  2.9600e-02],\n",
      "           [-2.6415e-02, -1.9473e-03, -3.6584e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.1017e-02, -9.1325e-03, -3.7117e-02],\n",
      "           [ 4.7091e-02,  2.4809e-02, -1.3196e-02],\n",
      "           [ 5.3589e-02,  3.8999e-02, -5.1988e-02]],\n",
      "\n",
      "          [[ 6.0053e-02, -4.4606e-03, -3.4868e-02],\n",
      "           [ 3.9735e-02,  9.6283e-03, -1.8446e-03],\n",
      "           [-3.5527e-04,  1.4784e-02, -3.0991e-02]],\n",
      "\n",
      "          [[ 2.4925e-02, -4.9031e-03,  2.8247e-02],\n",
      "           [ 7.8144e-03, -8.6945e-03, -3.3717e-02],\n",
      "           [ 2.2824e-02,  1.5122e-02, -2.3423e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.2796e-03, -6.5985e-03,  3.6074e-02],\n",
      "           [-3.4721e-02, -3.7769e-02,  3.8995e-02],\n",
      "           [-1.9322e-02,  2.9518e-02,  3.5244e-02]],\n",
      "\n",
      "          [[ 3.9177e-03,  1.7908e-02,  4.9098e-02],\n",
      "           [ 4.1146e-02,  3.2841e-02,  6.5919e-03],\n",
      "           [ 1.1887e-02,  2.9149e-02,  2.5602e-02]],\n",
      "\n",
      "          [[-5.2276e-03,  3.5648e-02,  2.8501e-02],\n",
      "           [-2.7758e-02, -5.1998e-02, -1.5850e-02],\n",
      "           [ 6.0467e-03,  1.2177e-02,  1.5192e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.4441e-02, -1.0272e-02,  2.0898e-02],\n",
      "           [-2.9528e-04,  2.7983e-02, -8.9773e-03],\n",
      "           [ 1.8731e-02,  3.4988e-02,  3.7636e-03]],\n",
      "\n",
      "          [[ 3.1286e-02,  4.1040e-02,  2.9370e-02],\n",
      "           [-2.1121e-02,  2.2103e-02,  4.5540e-02],\n",
      "           [-1.8750e-02, -2.1617e-02, -4.0653e-02]],\n",
      "\n",
      "          [[-1.6425e-02,  3.4459e-02, -4.8156e-03],\n",
      "           [ 2.8279e-02, -6.7374e-03,  2.4990e-02],\n",
      "           [-2.9442e-02,  4.4735e-02, -3.1964e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.9716e-02, -2.2401e-02, -4.8987e-02],\n",
      "           [ 1.5643e-02,  3.4836e-02,  2.3490e-02],\n",
      "           [ 8.1251e-03,  4.4897e-03, -4.4457e-02]],\n",
      "\n",
      "          [[ 5.0047e-02,  2.0850e-02, -3.1133e-02],\n",
      "           [ 4.0212e-02,  6.1177e-02,  3.6641e-02],\n",
      "           [-8.1504e-03, -1.3677e-02, -3.9648e-02]],\n",
      "\n",
      "          [[ 1.9985e-02, -2.0432e-02, -3.4339e-02],\n",
      "           [-1.2751e-02, -4.5030e-03,  6.4044e-03],\n",
      "           [ 3.1470e-02, -2.6921e-02,  3.8641e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.8632e-02, -2.0124e-02,  1.2585e-02],\n",
      "           [ 1.7070e-02,  1.7579e-02, -6.8311e-02],\n",
      "           [-2.1039e-02,  1.5816e-02,  2.2635e-02]],\n",
      "\n",
      "          [[ 3.0565e-02, -1.5858e-02, -5.6659e-02],\n",
      "           [ 3.0834e-02,  1.8682e-02, -2.0859e-02],\n",
      "           [-2.5198e-02,  5.0418e-03, -2.4034e-02]],\n",
      "\n",
      "          [[-2.4300e-02,  3.2443e-02,  1.7694e-02],\n",
      "           [-7.1311e-04,  3.6754e-02, -3.9581e-02],\n",
      "           [ 3.9313e-02,  8.9388e-03, -4.9308e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.5941e-03, -2.4687e-02,  1.7163e-03],\n",
      "           [-5.2283e-02,  1.6395e-02, -3.2876e-02],\n",
      "           [ 9.4168e-03,  5.3949e-03,  2.1320e-02]],\n",
      "\n",
      "          [[-3.1883e-02,  3.9831e-02, -1.3540e-02],\n",
      "           [-4.0310e-02, -7.3244e-03, -2.4247e-02],\n",
      "           [ 4.0865e-02,  3.0229e-02,  4.7475e-02]],\n",
      "\n",
      "          [[ 9.0182e-03, -1.5141e-02,  3.4992e-02],\n",
      "           [ 3.6749e-02,  1.2323e-03,  9.2264e-03],\n",
      "           [-2.6980e-02,  3.4297e-02,  3.8377e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 6.1301e-02,  3.1192e-02, -4.9456e-02],\n",
      "           [ 3.8923e-02, -1.9443e-02, -3.6277e-02],\n",
      "           [ 3.3977e-04, -2.7126e-02, -9.3029e-03]],\n",
      "\n",
      "          [[ 5.9501e-02, -1.9454e-02,  9.5610e-03],\n",
      "           [ 2.9540e-03, -4.0310e-02, -2.7612e-02],\n",
      "           [ 1.6812e-03,  1.2773e-02,  2.1679e-02]],\n",
      "\n",
      "          [[ 1.4842e-02, -3.5233e-02, -4.6308e-02],\n",
      "           [-4.1843e-02, -4.0114e-02, -7.2491e-03],\n",
      "           [-3.7033e-02, -2.0430e-02, -1.0181e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.5564e-02,  4.2683e-02, -5.1098e-03],\n",
      "           [-2.9506e-05, -3.2230e-02,  3.3243e-02],\n",
      "           [ 4.5209e-02,  2.1040e-02, -4.1930e-03]],\n",
      "\n",
      "          [[ 2.8674e-02,  4.1821e-02,  2.6495e-02],\n",
      "           [ 1.6514e-02,  4.5072e-02,  4.2833e-02],\n",
      "           [ 1.7118e-02, -1.2156e-02,  6.2992e-03]],\n",
      "\n",
      "          [[ 3.4536e-02,  3.0919e-02, -8.3501e-03],\n",
      "           [-1.2262e-02, -4.8056e-02, -4.4064e-02],\n",
      "           [-3.2727e-02,  2.9907e-02, -1.6608e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.8810e-03,  5.4345e-03,  1.4350e-02],\n",
      "           [-3.5371e-02,  2.0730e-02, -7.2452e-03],\n",
      "           [-4.2692e-02, -2.5017e-02, -2.8063e-02]],\n",
      "\n",
      "          [[-6.0162e-03, -3.0922e-02, -3.5414e-03],\n",
      "           [-2.7076e-02, -3.7861e-02,  8.3223e-03],\n",
      "           [-2.6324e-02,  3.1817e-02,  3.9775e-02]],\n",
      "\n",
      "          [[ 5.2369e-03,  2.3375e-02,  4.7259e-02],\n",
      "           [-1.6999e-02, -2.8675e-02, -8.4902e-03],\n",
      "           [-5.0580e-03,  4.1407e-02, -2.1134e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.0687e-02,  2.0033e-02,  1.1401e-02],\n",
      "           [ 3.7280e-02,  4.3682e-02,  1.7741e-02],\n",
      "           [ 1.5998e-02,  9.6109e-03,  6.0833e-03]],\n",
      "\n",
      "          [[-1.8265e-02,  9.0451e-03,  4.3663e-02],\n",
      "           [-3.2093e-02,  1.0636e-02,  3.0250e-02],\n",
      "           [ 1.9197e-02, -4.7185e-02,  1.2953e-02]],\n",
      "\n",
      "          [[ 1.5513e-02,  5.7637e-03,  9.5554e-03],\n",
      "           [ 1.4170e-02, -2.6479e-02, -1.8578e-02],\n",
      "           [ 2.4995e-02,  2.0397e-02,  3.4083e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.3942e-02,  3.5813e-02,  1.2189e-02],\n",
      "           [ 3.7423e-02, -3.6643e-02, -2.3478e-02],\n",
      "           [-2.4709e-02, -2.0456e-02, -2.6144e-02]],\n",
      "\n",
      "          [[ 2.0495e-02, -1.4495e-02, -2.5546e-02],\n",
      "           [ 3.0871e-02, -2.0956e-02, -2.7651e-02],\n",
      "           [ 6.5420e-02, -2.1779e-02,  4.6487e-02]],\n",
      "\n",
      "          [[ 4.9870e-02,  5.9485e-03, -4.8959e-02],\n",
      "           [-2.1907e-02,  7.8300e-03,  1.5469e-02],\n",
      "           [-1.2468e-02,  5.7361e-02,  5.3433e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.2783e-03, -4.1361e-02, -2.1690e-02],\n",
      "           [-1.3078e-02,  2.1614e-02,  3.4216e-04],\n",
      "           [-5.6002e-02, -4.6124e-02,  6.0031e-03]],\n",
      "\n",
      "          [[ 1.3888e-02, -7.9512e-03,  3.8228e-02],\n",
      "           [ 2.3965e-02, -4.3860e-02,  3.7523e-02],\n",
      "           [ 7.1917e-03,  1.9085e-02,  7.8988e-03]],\n",
      "\n",
      "          [[-3.2795e-02, -2.1323e-02,  3.0306e-02],\n",
      "           [-3.1927e-02, -6.6581e-03,  3.6617e-02],\n",
      "           [-1.9435e-02, -9.1653e-03, -2.6088e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.1511e-02,  1.0803e-02,  3.5467e-02],\n",
      "           [ 9.5920e-03,  2.2608e-02, -4.4954e-02],\n",
      "           [-1.6346e-02, -2.1218e-02,  1.5073e-02]],\n",
      "\n",
      "          [[-3.1022e-02,  2.0769e-02,  2.4743e-02],\n",
      "           [ 2.9068e-02,  1.4439e-02, -2.2796e-02],\n",
      "           [-2.8224e-03,  1.3067e-02,  2.8424e-02]],\n",
      "\n",
      "          [[-1.3317e-02,  3.0917e-03,  1.1129e-02],\n",
      "           [-4.2341e-02,  3.1931e-03,  3.1577e-02],\n",
      "           [ 2.8369e-02,  7.7980e-03, -3.2731e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.6819e-02,  2.4671e-02, -2.8826e-02],\n",
      "           [ 2.2156e-02,  1.6798e-02, -2.6251e-02],\n",
      "           [ 4.3481e-02, -4.0392e-02, -3.3078e-02]],\n",
      "\n",
      "          [[-4.4040e-02,  3.1925e-02, -5.2751e-02],\n",
      "           [-2.5895e-02,  2.7558e-02,  4.6194e-04],\n",
      "           [-2.2096e-02,  4.1500e-02, -1.8432e-03]],\n",
      "\n",
      "          [[-4.5329e-03, -4.9670e-02, -1.3989e-02],\n",
      "           [-2.5685e-02, -1.6071e-02,  2.6323e-02],\n",
      "           [ 2.5352e-02,  3.2676e-02, -3.5996e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.0590e-02,  2.1075e-02,  2.7735e-03],\n",
      "           [ 3.8728e-02, -5.2225e-03,  2.6289e-03],\n",
      "           [ 1.2175e-02,  9.2309e-03, -4.1406e-02]],\n",
      "\n",
      "          [[-1.1900e-02,  3.8700e-02,  1.9071e-02],\n",
      "           [ 3.9089e-03, -2.3774e-02,  3.8918e-02],\n",
      "           [-9.4968e-03, -2.5877e-02, -1.3944e-02]],\n",
      "\n",
      "          [[-2.1320e-02,  1.6455e-02,  4.9284e-02],\n",
      "           [-1.8941e-02,  6.2789e-03, -1.1405e-02],\n",
      "           [-8.1961e-03, -3.9321e-02, -2.6536e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.9440e-02, -1.3503e-02, -2.0425e-02],\n",
      "           [-1.0045e-03, -4.8468e-02, -4.7178e-02],\n",
      "           [-3.0167e-02,  2.0284e-02,  2.8234e-03]],\n",
      "\n",
      "          [[-3.2172e-02, -2.6451e-02,  3.7439e-02],\n",
      "           [ 3.9003e-02, -1.2458e-02, -3.4249e-02],\n",
      "           [ 3.1911e-02, -1.1281e-03,  6.7345e-03]],\n",
      "\n",
      "          [[-4.2877e-02,  2.0016e-02, -2.8461e-02],\n",
      "           [ 3.3696e-02,  3.7569e-02, -4.2670e-02],\n",
      "           [ 3.7856e-02,  3.2836e-03,  3.7733e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.6907e-02, -4.7452e-02, -1.9684e-02],\n",
      "           [-1.4282e-02,  2.3970e-02,  1.7482e-02],\n",
      "           [-6.0289e-02, -4.8817e-02,  7.9493e-03]],\n",
      "\n",
      "          [[-2.6470e-02,  2.5550e-04, -5.4643e-02],\n",
      "           [-2.3081e-03, -5.6386e-02,  3.2541e-03],\n",
      "           [ 1.4871e-03, -4.3852e-02, -8.8169e-03]],\n",
      "\n",
      "          [[-1.7287e-02,  9.5958e-03, -7.5371e-03],\n",
      "           [-1.6371e-02, -3.3540e-02, -4.8199e-02],\n",
      "           [ 3.8783e-02, -5.6374e-03,  1.6562e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.3903e-02,  4.5196e-02,  4.6593e-02],\n",
      "           [ 1.3313e-02,  2.5267e-02, -6.2620e-03],\n",
      "           [-2.0029e-02,  1.9559e-02,  9.9612e-03]],\n",
      "\n",
      "          [[-4.8640e-02, -4.5750e-02, -4.9950e-03],\n",
      "           [ 4.3532e-02, -3.4635e-02,  7.1601e-03],\n",
      "           [-2.0266e-02, -2.9091e-02,  8.0656e-03]],\n",
      "\n",
      "          [[-1.4200e-02, -2.5829e-02, -5.4648e-03],\n",
      "           [ 3.6054e-03, -2.6175e-02, -3.5644e-02],\n",
      "           [-2.7432e-02, -3.8198e-03, -2.6342e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.3165e-02,  8.6940e-04, -2.7387e-02],\n",
      "           [-1.9570e-03,  1.7041e-02,  5.1850e-02],\n",
      "           [ 1.6968e-02,  4.2410e-02, -2.0776e-03]],\n",
      "\n",
      "          [[ 6.9988e-02,  3.3430e-02, -9.7359e-03],\n",
      "           [ 1.5974e-02,  4.7916e-02, -3.7421e-02],\n",
      "           [ 2.6791e-02,  2.4591e-02, -2.5566e-03]],\n",
      "\n",
      "          [[ 3.3337e-02, -2.3210e-02, -1.8205e-02],\n",
      "           [ 5.0146e-02,  1.4082e-02, -5.8654e-02],\n",
      "           [ 2.6108e-02,  7.1000e-04, -4.5695e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.2197e-02, -8.2672e-03, -1.3186e-02],\n",
      "           [-3.5571e-02, -4.5091e-04, -5.2219e-03],\n",
      "           [-2.2880e-02,  2.6089e-02, -3.0697e-02]],\n",
      "\n",
      "          [[ 9.1284e-03,  1.5682e-02,  4.2944e-02],\n",
      "           [ 9.6694e-03,  4.3903e-02,  1.6303e-02],\n",
      "           [ 1.7200e-02, -1.3924e-04,  2.4659e-02]],\n",
      "\n",
      "          [[ 1.9166e-02,  8.1154e-03,  3.6917e-03],\n",
      "           [-3.5747e-02,  1.0354e-02,  2.0892e-02],\n",
      "           [ 7.6021e-03,  2.1733e-02,  4.4990e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1409e-02,  2.3830e-02, -2.7704e-02],\n",
      "           [-5.2463e-03, -1.1124e-03,  8.5501e-03],\n",
      "           [ 1.7846e-02,  3.4368e-02,  1.2944e-02]],\n",
      "\n",
      "          [[-3.2259e-02,  2.6434e-02,  2.9789e-02],\n",
      "           [-3.9830e-02, -1.6085e-02,  1.9729e-02],\n",
      "           [-1.9117e-02, -4.3141e-02, -3.1366e-02]],\n",
      "\n",
      "          [[ 4.1241e-02, -5.0521e-02, -4.7044e-02],\n",
      "           [ 1.4943e-03, -4.8991e-02,  1.8493e-02],\n",
      "           [ 7.7606e-03,  2.4575e-02, -1.2368e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.1444e-02,  2.9459e-02,  2.3745e-02],\n",
      "           [ 1.5964e-02, -1.1301e-02, -1.3432e-02],\n",
      "           [ 1.9871e-02, -4.7350e-02,  2.5837e-02]],\n",
      "\n",
      "          [[ 1.1808e-02, -3.7043e-02, -2.2017e-02],\n",
      "           [ 3.6702e-02, -2.1273e-02, -3.3813e-02],\n",
      "           [ 3.9473e-02,  1.6134e-02,  5.8233e-03]],\n",
      "\n",
      "          [[ 2.8003e-02, -4.5575e-02, -3.0002e-02],\n",
      "           [ 1.6547e-02, -1.9775e-02, -2.7503e-02],\n",
      "           [ 3.6975e-02, -3.9549e-02, -3.2443e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.3364e-02, -2.2362e-02, -1.0842e-02],\n",
      "           [-2.1519e-02, -3.6162e-02,  4.3431e-02],\n",
      "           [-9.2577e-03,  2.5886e-02, -1.6860e-02]],\n",
      "\n",
      "          [[-4.7987e-02, -2.2509e-02, -3.6191e-02],\n",
      "           [ 3.5808e-02, -2.4009e-02,  1.1312e-02],\n",
      "           [-3.7820e-02, -1.4396e-02, -3.7263e-02]],\n",
      "\n",
      "          [[ 8.0418e-05, -1.0800e-02,  4.6082e-04],\n",
      "           [-3.8393e-02, -3.1664e-02,  1.9312e-03],\n",
      "           [-1.3908e-02, -8.6093e-03,  2.9233e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.8650e-02, -3.6939e-02,  1.4746e-03],\n",
      "           [ 1.9800e-02,  2.9846e-02,  2.6753e-02],\n",
      "           [-7.8283e-03,  1.2595e-02,  1.6671e-02]],\n",
      "\n",
      "          [[ 4.5576e-03, -5.9490e-03, -3.5306e-02],\n",
      "           [ 3.3383e-03,  1.2126e-02, -1.9068e-02],\n",
      "           [-2.4691e-02, -2.0256e-02, -1.9395e-02]],\n",
      "\n",
      "          [[ 1.2299e-02, -3.0868e-03,  3.8643e-02],\n",
      "           [-3.6930e-02, -3.8716e-02, -1.1824e-02],\n",
      "           [ 4.8218e-03,  1.8145e-02, -1.5778e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.1032e-02,  6.4147e-04,  3.5023e-03],\n",
      "           [-1.4331e-02, -4.0971e-03,  1.7616e-02],\n",
      "           [-3.1288e-02, -3.6967e-02,  8.3007e-03]],\n",
      "\n",
      "          [[-2.9807e-02, -2.7464e-02, -2.5991e-02],\n",
      "           [-1.8979e-02,  2.8734e-02,  1.0207e-02],\n",
      "           [-1.5058e-03,  1.6180e-02, -5.2768e-02]],\n",
      "\n",
      "          [[ 2.5363e-02, -1.2402e-02,  5.1216e-03],\n",
      "           [-3.2579e-02, -3.6467e-02, -1.0444e-02],\n",
      "           [-2.9396e-03, -1.2500e-02, -5.8536e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.8153e-02, -3.8087e-03,  2.4924e-03],\n",
      "           [ 1.0300e-02,  2.4018e-02, -2.5132e-02],\n",
      "           [-3.3872e-02,  1.8925e-02,  9.2510e-04]],\n",
      "\n",
      "          [[-3.5237e-02,  7.5622e-03, -3.3358e-02],\n",
      "           [-2.4243e-02, -2.9011e-02, -5.4127e-02],\n",
      "           [ 1.9487e-02,  4.1079e-02, -5.2862e-02]],\n",
      "\n",
      "          [[ 4.2249e-02, -1.0649e-02, -4.5488e-02],\n",
      "           [ 1.7792e-02,  2.6117e-02,  2.9596e-02],\n",
      "           [-7.1645e-03, -1.2953e-02, -4.5529e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2511e-02,  8.4406e-03,  3.4580e-02],\n",
      "           [-1.9469e-02, -2.5899e-02,  1.8334e-02],\n",
      "           [-2.8069e-02,  1.8851e-02,  4.7351e-02]],\n",
      "\n",
      "          [[ 1.3859e-02, -1.2353e-02,  4.0862e-02],\n",
      "           [ 4.4705e-02, -1.5946e-02, -2.3930e-02],\n",
      "           [ 1.9883e-02,  3.2771e-02, -1.4668e-02]],\n",
      "\n",
      "          [[-8.5312e-03, -8.3439e-03,  3.7322e-03],\n",
      "           [-4.1945e-02, -1.0001e-02, -3.7242e-03],\n",
      "           [ 1.5881e-02, -2.5350e-02,  4.8946e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.9460e-02, -1.1827e-02,  1.0421e-02],\n",
      "           [ 1.3129e-02,  3.8010e-02,  3.3001e-02],\n",
      "           [-2.3227e-02, -2.2505e-03, -8.7265e-03]],\n",
      "\n",
      "          [[-9.0841e-03, -1.2112e-02, -7.8431e-03],\n",
      "           [-3.0847e-02, -1.7672e-03, -3.7602e-02],\n",
      "           [ 4.5041e-03, -3.9173e-02,  4.4720e-02]],\n",
      "\n",
      "          [[ 1.8394e-02,  3.6657e-02,  4.4473e-02],\n",
      "           [-2.0325e-02, -3.2739e-02, -3.2622e-02],\n",
      "           [ 2.4084e-02, -2.3288e-02,  4.6482e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 4.9609e-03,  1.8430e-02,  2.7178e-02],\n",
      "           [-5.7269e-02,  6.5527e-03, -1.7602e-02],\n",
      "           [-1.8081e-03,  2.3134e-02,  1.1165e-02]],\n",
      "\n",
      "          [[-1.7398e-02, -2.9927e-02,  2.9849e-02],\n",
      "           [-4.2428e-02, -3.8203e-02,  1.7802e-02],\n",
      "           [-5.2028e-02, -5.1974e-03, -7.7534e-03]],\n",
      "\n",
      "          [[-4.7607e-04, -2.8199e-02, -2.5887e-02],\n",
      "           [-3.0141e-02, -4.4361e-02,  1.8635e-02],\n",
      "           [-2.1528e-02,  2.6003e-02,  2.9977e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3185e-02, -2.2699e-02,  3.7017e-02],\n",
      "           [ 1.5399e-02, -3.0669e-02,  4.1381e-02],\n",
      "           [ 3.0062e-02, -2.5174e-02,  4.0723e-02]],\n",
      "\n",
      "          [[-3.3072e-02,  1.3923e-02,  2.9691e-02],\n",
      "           [ 5.5146e-02, -3.2153e-02,  5.0015e-04],\n",
      "           [-2.3984e-02, -3.4878e-02, -4.8292e-03]],\n",
      "\n",
      "          [[-3.3970e-02,  2.5325e-03, -9.4078e-03],\n",
      "           [-3.4116e-02,  1.5867e-02,  4.5692e-02],\n",
      "           [-2.3467e-02,  3.7518e-02, -5.1191e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.5048e-02,  1.6419e-02,  4.1849e-02],\n",
      "           [-3.1631e-02,  4.4157e-02,  6.5126e-03],\n",
      "           [ 2.4338e-02, -2.3213e-02,  5.3140e-02]],\n",
      "\n",
      "          [[-1.1072e-02,  3.3099e-02,  1.1646e-02],\n",
      "           [-1.6645e-03,  1.6700e-02, -9.6673e-03],\n",
      "           [ 2.8945e-02,  4.5223e-02,  3.5292e-02]],\n",
      "\n",
      "          [[ 5.6242e-03, -3.4609e-02, -1.5756e-02],\n",
      "           [-2.7906e-02,  4.7346e-02,  1.1873e-03],\n",
      "           [ 1.6082e-03, -1.3078e-02,  3.6596e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.3890e-03,  4.2716e-02,  1.3447e-03],\n",
      "           [-8.8589e-03,  2.6217e-02, -2.6596e-02],\n",
      "           [-4.2293e-02,  1.2721e-02, -1.2551e-02]],\n",
      "\n",
      "          [[ 3.4761e-02, -7.7290e-03, -6.1817e-03],\n",
      "           [ 4.1174e-02,  3.0394e-02, -2.2634e-03],\n",
      "           [ 3.5629e-02, -1.9003e-02,  1.0287e-02]],\n",
      "\n",
      "          [[ 5.1862e-03,  1.4387e-03,  3.5462e-02],\n",
      "           [-2.3533e-02, -1.2610e-02,  2.6006e-02],\n",
      "           [-4.1914e-02,  2.5135e-02,  9.3068e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2986e-02,  3.6826e-02, -3.4364e-02],\n",
      "           [ 2.0703e-02,  3.8930e-02,  2.6176e-02],\n",
      "           [ 3.3789e-02,  1.5623e-02,  3.3437e-02]],\n",
      "\n",
      "          [[-1.0157e-02, -7.8732e-03, -3.6226e-03],\n",
      "           [ 3.1060e-02,  5.0446e-02, -1.2678e-02],\n",
      "           [ 4.8063e-02, -1.4155e-02,  3.0053e-02]],\n",
      "\n",
      "          [[ 3.7448e-02, -3.7286e-02, -1.6806e-02],\n",
      "           [-5.4743e-03,  4.5087e-02, -1.6545e-02],\n",
      "           [-6.1701e-03,  8.9105e-03,  5.2572e-02]]]]], device='cuda:0')), ('module.down_layers.1.1.norm1.weight', tensor([0.9751, 1.0173, 0.9968, 0.9732, 1.0031, 1.0042, 1.0089, 1.0009, 0.9915,\n",
      "        0.9889, 0.9939, 0.9891, 0.9906, 0.9945, 0.9859, 1.0026, 0.9808, 0.9633,\n",
      "        0.9948, 0.9902, 0.9929, 1.0012, 0.9824, 1.0065, 1.0110, 0.9924, 0.9919,\n",
      "        0.9991, 0.9782, 0.9677, 0.9925, 0.9846], device='cuda:0')), ('module.down_layers.1.1.norm1.bias', tensor([-0.0411, -0.0527, -0.0089, -0.0285, -0.0063, -0.0036, -0.0072,  0.0013,\n",
      "        -0.0307, -0.0281, -0.0114, -0.0219, -0.0265, -0.0196, -0.0355, -0.0466,\n",
      "        -0.0279, -0.0532, -0.0261,  0.0037, -0.0193, -0.0149, -0.0034, -0.0156,\n",
      "        -0.0154,  0.0006, -0.0144,  0.0103,  0.0054, -0.0358, -0.0079, -0.0012],\n",
      "       device='cuda:0')), ('module.down_layers.1.1.norm2.weight', tensor([0.9947, 1.0091, 1.0012, 0.9983, 1.0081, 0.9940, 0.9998, 1.0011, 0.9678,\n",
      "        1.0077, 0.9848, 1.0120, 0.9809, 1.0041, 0.9883, 0.9970, 1.0009, 0.9892,\n",
      "        1.0079, 1.0035, 0.9872, 1.0015, 1.0044, 0.9615, 0.9952, 1.0027, 0.9966,\n",
      "        1.0118, 0.9939, 1.0077, 0.9765, 1.0018], device='cuda:0')), ('module.down_layers.1.1.norm2.bias', tensor([-0.0049, -0.0056, -0.0070, -0.0268,  0.0030,  0.0013,  0.0012, -0.0195,\n",
      "        -0.0054,  0.0038,  0.0002,  0.0049,  0.0278,  0.0029, -0.0024,  0.0039,\n",
      "        -0.0171, -0.0165, -0.0106,  0.0033, -0.0322, -0.0302, -0.0339, -0.0407,\n",
      "        -0.0074, -0.0039, -0.0160, -0.0063, -0.0007, -0.0197,  0.0033, -0.0087],\n",
      "       device='cuda:0')), ('module.down_layers.1.1.conv1.conv.weight', tensor([[[[[-2.3743e-03,  4.0978e-03,  3.1412e-02],\n",
      "           [-3.2124e-03, -1.5436e-02,  2.0790e-02],\n",
      "           [ 2.4248e-02, -2.7702e-02,  3.3934e-02]],\n",
      "\n",
      "          [[ 2.0810e-02,  4.2460e-02, -2.2695e-03],\n",
      "           [-3.2190e-02,  2.9203e-02,  1.3128e-02],\n",
      "           [ 1.7355e-02, -3.9280e-03,  1.1086e-02]],\n",
      "\n",
      "          [[-9.4561e-03, -1.3785e-02,  6.1714e-03],\n",
      "           [ 1.6672e-02,  1.8248e-03,  3.0661e-02],\n",
      "           [ 1.2358e-02, -2.9691e-02,  3.1217e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.9845e-02,  1.1541e-02,  2.3331e-02],\n",
      "           [-2.6329e-02,  6.7081e-03,  2.0585e-02],\n",
      "           [ 6.9932e-03,  2.2362e-02, -1.7853e-02]],\n",
      "\n",
      "          [[-2.8284e-02,  1.4572e-02, -2.3999e-02],\n",
      "           [ 3.6044e-02, -2.8991e-02,  2.6837e-02],\n",
      "           [ 6.9326e-03,  8.5273e-04, -3.1580e-02]],\n",
      "\n",
      "          [[-2.5861e-02,  1.5966e-02,  3.8901e-03],\n",
      "           [-2.0890e-02,  2.5814e-02,  4.3715e-02],\n",
      "           [-2.7809e-02, -2.1418e-02,  1.2213e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.7562e-02, -5.5482e-02, -2.9435e-02],\n",
      "           [ 2.3606e-02, -5.7893e-03, -7.8736e-03],\n",
      "           [-2.5771e-02,  3.1264e-02, -3.0259e-02]],\n",
      "\n",
      "          [[-1.4961e-02,  6.9905e-03, -1.2866e-02],\n",
      "           [ 3.3451e-02, -3.0194e-02, -1.9419e-02],\n",
      "           [ 2.1371e-02, -2.8037e-02, -2.4163e-02]],\n",
      "\n",
      "          [[ 5.6187e-03,  3.4760e-02, -1.2818e-02],\n",
      "           [ 4.0111e-02,  3.6321e-03, -6.6453e-03],\n",
      "           [ 6.2297e-03,  2.2419e-02, -2.2709e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.6247e-02, -6.2144e-03,  1.1617e-02],\n",
      "           [-9.2520e-03,  2.1504e-02,  5.4944e-03],\n",
      "           [ 2.5321e-02, -1.2304e-02, -1.3266e-02]],\n",
      "\n",
      "          [[ 3.0633e-03,  7.8562e-03, -9.4169e-03],\n",
      "           [ 8.3174e-03, -2.8149e-02,  2.0149e-02],\n",
      "           [ 2.9359e-02, -2.2381e-02,  3.6574e-02]],\n",
      "\n",
      "          [[ 1.0912e-02,  2.1486e-03, -1.2779e-03],\n",
      "           [ 2.9726e-02, -2.9977e-03, -5.7788e-03],\n",
      "           [-2.4518e-02, -2.0211e-02,  3.7992e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4440e-02, -2.4212e-02, -1.8882e-02],\n",
      "           [ 1.1546e-02,  2.3070e-02, -2.4790e-03],\n",
      "           [ 7.0885e-05, -2.4758e-02,  4.9188e-03]],\n",
      "\n",
      "          [[-1.6963e-02, -2.4010e-02,  2.9061e-02],\n",
      "           [ 2.7846e-03, -1.8475e-02, -3.1503e-02],\n",
      "           [ 3.4873e-02,  8.3232e-03, -1.7424e-02]],\n",
      "\n",
      "          [[ 2.6696e-03, -2.8689e-02,  1.6268e-02],\n",
      "           [ 1.8504e-02,  2.6137e-02, -2.5559e-02],\n",
      "           [-1.8632e-02,  2.7538e-02, -2.2775e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2892e-02, -3.2723e-03,  4.6428e-04],\n",
      "           [-1.7510e-02,  5.0951e-03, -3.1636e-02],\n",
      "           [-9.7765e-04, -2.9285e-02, -3.1290e-04]],\n",
      "\n",
      "          [[ 1.3293e-03,  2.9464e-02,  3.5103e-04],\n",
      "           [-5.9848e-03, -3.2045e-02, -2.1236e-02],\n",
      "           [ 9.9124e-03,  2.7457e-02,  1.8825e-02]],\n",
      "\n",
      "          [[ 1.5684e-02,  2.4239e-02,  1.1279e-02],\n",
      "           [ 8.0166e-03,  1.1799e-02,  1.8304e-02],\n",
      "           [ 9.2223e-03,  2.0350e-03,  7.9973e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.2974e-02,  2.7248e-02, -2.6545e-02],\n",
      "           [-1.2230e-02,  2.9196e-02,  2.0533e-02],\n",
      "           [ 3.5487e-02, -1.8024e-02, -3.2938e-02]],\n",
      "\n",
      "          [[-1.9855e-03, -9.2011e-03, -5.3187e-03],\n",
      "           [-2.4742e-03, -3.3014e-03, -2.6927e-03],\n",
      "           [ 9.5700e-03, -2.9834e-02, -2.4758e-02]],\n",
      "\n",
      "          [[ 1.4552e-02,  3.7687e-02,  1.6094e-02],\n",
      "           [ 1.0008e-03, -2.1464e-02,  5.1043e-03],\n",
      "           [-3.3711e-02, -2.3617e-02,  4.3083e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.4420e-02,  4.3883e-02,  2.4821e-02],\n",
      "           [-8.1976e-03,  1.9586e-02,  2.3010e-02],\n",
      "           [-2.8569e-02, -8.1291e-04, -2.0094e-02]],\n",
      "\n",
      "          [[ 4.0315e-02,  2.4223e-02,  5.2561e-02],\n",
      "           [-1.3549e-02,  2.8859e-02,  4.3039e-02],\n",
      "           [-9.4156e-03, -2.8884e-02, -4.4310e-02]],\n",
      "\n",
      "          [[-4.4772e-03,  1.2613e-02, -4.8980e-03],\n",
      "           [-8.8730e-03,  2.6613e-03, -3.9233e-02],\n",
      "           [-1.2813e-02,  1.2874e-02, -2.3333e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0590e-02,  1.9883e-02, -1.6879e-03],\n",
      "           [ 3.8542e-03, -1.8004e-02, -2.8018e-02],\n",
      "           [ 4.1594e-02,  2.3326e-02, -2.2927e-02]],\n",
      "\n",
      "          [[-1.2306e-02, -2.9785e-02, -2.2417e-02],\n",
      "           [-2.2399e-02, -4.5833e-02, -3.5181e-02],\n",
      "           [ 3.1593e-02,  2.8351e-02,  2.9649e-02]],\n",
      "\n",
      "          [[ 3.1112e-02,  2.0713e-02,  7.6998e-04],\n",
      "           [ 2.4931e-02,  3.1026e-02,  1.4668e-02],\n",
      "           [ 6.3593e-03,  2.7186e-02,  4.0555e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.8968e-03,  2.9848e-02, -6.5053e-04],\n",
      "           [ 3.4958e-03, -2.1114e-02, -2.4016e-02],\n",
      "           [-2.1583e-02,  1.1571e-02,  2.0161e-02]],\n",
      "\n",
      "          [[ 1.6633e-02,  3.5931e-02,  8.6185e-03],\n",
      "           [-2.3799e-02, -1.1629e-02, -2.8270e-02],\n",
      "           [-2.6047e-02,  3.3613e-03,  1.0753e-02]],\n",
      "\n",
      "          [[-1.7037e-02,  3.4872e-02,  4.0449e-03],\n",
      "           [ 2.4877e-02, -3.0518e-02,  3.0456e-02],\n",
      "           [ 6.4232e-03,  1.9234e-02,  2.2134e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3660e-02, -1.0362e-02, -1.0284e-02],\n",
      "           [ 1.8886e-02, -1.5287e-02, -2.2370e-02],\n",
      "           [ 2.4725e-02, -3.7777e-03,  3.9494e-02]],\n",
      "\n",
      "          [[ 3.3332e-02, -1.1627e-02, -2.0602e-02],\n",
      "           [ 1.1663e-02, -3.3252e-02, -8.5211e-03],\n",
      "           [-1.2336e-02,  4.0753e-02,  1.1868e-02]],\n",
      "\n",
      "          [[-6.8499e-03, -2.1489e-02, -4.5594e-02],\n",
      "           [ 2.0957e-02,  1.1183e-02,  2.0144e-02],\n",
      "           [ 4.7710e-02, -1.3293e-02, -8.3448e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.9365e-02, -2.4101e-02, -1.2094e-02],\n",
      "           [-6.2462e-03,  1.5215e-02,  6.1912e-03],\n",
      "           [-1.1687e-02, -2.2294e-02,  5.9678e-03]],\n",
      "\n",
      "          [[ 2.6956e-02, -2.7590e-02,  2.6842e-02],\n",
      "           [ 2.0636e-02,  1.4850e-02, -1.5299e-02],\n",
      "           [-1.2511e-02, -1.1597e-02,  9.7060e-03]],\n",
      "\n",
      "          [[-2.2507e-02, -1.2827e-02, -3.0151e-02],\n",
      "           [-2.5277e-02, -2.7241e-02,  2.0737e-02],\n",
      "           [-2.5062e-02, -3.7041e-02,  2.8198e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.9106e-02, -4.1563e-02, -1.1754e-02],\n",
      "           [-1.8135e-02, -6.7140e-03, -8.8166e-03],\n",
      "           [ 1.2658e-02, -1.8642e-02, -1.2379e-03]],\n",
      "\n",
      "          [[-1.6619e-02, -2.0427e-02, -5.1392e-02],\n",
      "           [-1.9805e-02, -3.9766e-03, -2.9476e-02],\n",
      "           [ 8.8724e-03,  6.1601e-03, -4.5336e-02]],\n",
      "\n",
      "          [[-2.1966e-02,  3.7506e-02, -3.1144e-02],\n",
      "           [-1.5240e-03,  2.7246e-02,  1.0066e-02],\n",
      "           [ 2.9815e-02, -8.2745e-03,  1.2446e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4984e-02, -1.5164e-02,  1.5739e-03],\n",
      "           [-3.9386e-02, -8.6403e-03,  4.8569e-03],\n",
      "           [-1.0431e-03,  4.1590e-03, -3.4124e-02]],\n",
      "\n",
      "          [[ 3.5032e-02,  7.5883e-03,  1.9235e-02],\n",
      "           [ 1.2872e-02,  2.2792e-02,  4.2356e-02],\n",
      "           [-1.3560e-02, -1.2713e-02,  1.4003e-02]],\n",
      "\n",
      "          [[ 3.0240e-02, -7.3800e-03, -1.3864e-02],\n",
      "           [-2.2951e-02,  5.7842e-03, -6.0259e-03],\n",
      "           [-3.7303e-02, -9.3829e-04,  1.8146e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.6566e-02, -5.7147e-03,  2.5508e-02],\n",
      "           [-1.9025e-02, -1.5551e-02,  4.1618e-02],\n",
      "           [-2.2004e-02, -3.2125e-02, -2.2493e-02]],\n",
      "\n",
      "          [[ 1.1921e-02,  3.3467e-02,  3.4565e-02],\n",
      "           [-2.8667e-02, -3.2051e-02,  1.6551e-02],\n",
      "           [ 1.5037e-02, -2.0271e-02, -8.5136e-05]],\n",
      "\n",
      "          [[-1.3592e-02, -1.0162e-02, -2.1733e-02],\n",
      "           [ 1.0771e-02, -3.7171e-02, -3.8175e-02],\n",
      "           [-5.5505e-03,  8.4693e-03, -2.9638e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-8.9483e-03,  1.0053e-02,  1.8071e-02],\n",
      "           [ 1.5811e-02, -2.2049e-02,  6.8309e-03],\n",
      "           [ 2.8677e-02,  1.5466e-02,  2.1078e-02]],\n",
      "\n",
      "          [[ 1.3508e-02,  1.5088e-02,  6.5824e-03],\n",
      "           [-8.5982e-03, -4.5624e-02, -4.6192e-03],\n",
      "           [-8.6350e-03, -4.1768e-02, -3.0671e-02]],\n",
      "\n",
      "          [[ 1.9031e-02,  1.2745e-02, -1.0366e-02],\n",
      "           [-3.1536e-02, -1.5299e-02, -3.7882e-02],\n",
      "           [-2.0677e-02, -2.9988e-02,  1.2678e-02]]],\n",
      "\n",
      "\n",
      "         [[[-6.8532e-04,  1.3949e-03,  2.8608e-02],\n",
      "           [ 1.5833e-02,  2.9793e-02,  2.8427e-03],\n",
      "           [-2.2152e-02, -1.8786e-02,  7.2396e-03]],\n",
      "\n",
      "          [[-2.0696e-02,  1.7150e-02,  3.9247e-02],\n",
      "           [ 1.9466e-02,  6.8391e-03, -8.2585e-03],\n",
      "           [ 1.1473e-02, -3.5069e-02, -2.5342e-02]],\n",
      "\n",
      "          [[ 4.0190e-02,  2.5648e-02,  3.9453e-02],\n",
      "           [-1.8406e-02, -2.3777e-02, -3.0329e-02],\n",
      "           [ 1.1915e-02, -3.2856e-02,  1.9788e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.7075e-03,  2.3026e-02, -2.8178e-02],\n",
      "           [-2.2474e-02,  1.9024e-02,  4.5975e-03],\n",
      "           [ 1.1200e-02,  1.4032e-02,  9.3229e-03]],\n",
      "\n",
      "          [[ 2.7019e-02,  2.1724e-03,  3.0320e-02],\n",
      "           [ 1.1449e-02, -2.5456e-02, -3.7303e-02],\n",
      "           [-2.1977e-02,  3.1849e-02, -2.7989e-02]],\n",
      "\n",
      "          [[-1.3028e-02,  2.6852e-02,  3.1243e-02],\n",
      "           [ 1.3571e-02, -1.2027e-02,  4.1137e-02],\n",
      "           [ 7.4149e-03,  1.7684e-02, -2.2526e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.6658e-02,  2.2717e-02,  1.8351e-03],\n",
      "           [-5.1804e-04, -1.6031e-02,  2.4320e-02],\n",
      "           [ 1.8067e-03,  1.0568e-03, -2.0211e-02]],\n",
      "\n",
      "          [[ 2.3332e-02, -2.5455e-02, -2.3010e-02],\n",
      "           [ 1.2178e-02,  2.4442e-02,  2.8720e-02],\n",
      "           [ 1.1033e-02,  2.8200e-02, -1.4863e-02]],\n",
      "\n",
      "          [[ 1.9315e-04, -2.1392e-02, -1.6352e-03],\n",
      "           [ 7.7712e-04, -2.1441e-02, -7.7649e-03],\n",
      "           [-7.2238e-04, -2.4803e-02,  1.9496e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.6511e-02, -2.5203e-03,  3.7109e-02],\n",
      "           [-2.4887e-02,  4.2300e-02,  5.3157e-02],\n",
      "           [ 1.7113e-02,  1.4218e-02,  3.6496e-02]],\n",
      "\n",
      "          [[ 1.9359e-03,  4.7078e-03,  7.4709e-03],\n",
      "           [-3.2718e-02, -4.2473e-03, -2.2185e-02],\n",
      "           [ 4.5912e-03,  2.8158e-02,  2.4045e-03]],\n",
      "\n",
      "          [[-3.3630e-02, -1.9774e-02,  2.1052e-02],\n",
      "           [-2.1145e-02, -2.0129e-02, -3.6626e-02],\n",
      "           [ 9.1723e-03,  1.5230e-02, -3.7247e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.3310e-03,  7.6535e-03, -8.8594e-03],\n",
      "           [-2.9662e-02,  1.2003e-04,  1.0035e-02],\n",
      "           [-5.1174e-03, -5.8644e-04, -1.9841e-02]],\n",
      "\n",
      "          [[-6.9191e-03, -5.9098e-03, -4.1261e-03],\n",
      "           [ 2.6487e-02,  2.2873e-03,  9.7929e-03],\n",
      "           [-6.7225e-03, -4.8527e-03,  1.7927e-02]],\n",
      "\n",
      "          [[ 5.4282e-04, -5.5424e-03, -2.9484e-03],\n",
      "           [-1.7636e-02, -4.3115e-03,  9.8980e-03],\n",
      "           [ 4.1765e-02, -1.4085e-02,  2.1620e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.3220e-03,  9.1737e-03,  1.0716e-02],\n",
      "           [-1.1926e-02, -8.4429e-03, -1.2302e-02],\n",
      "           [-2.8779e-02,  1.7776e-02, -5.3670e-03]],\n",
      "\n",
      "          [[ 2.6494e-02, -7.8337e-03, -2.7034e-02],\n",
      "           [-3.4307e-02, -9.5377e-04, -1.5505e-02],\n",
      "           [-8.4383e-03,  6.9102e-03, -8.4627e-04]],\n",
      "\n",
      "          [[ 8.1739e-03, -3.7488e-05,  1.5386e-02],\n",
      "           [ 9.8427e-03,  2.7097e-02, -2.3785e-02],\n",
      "           [ 4.3038e-03, -1.2438e-02,  1.7035e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2389e-02,  1.0206e-03,  1.2696e-02],\n",
      "           [-2.4726e-02, -2.1135e-02,  3.7769e-04],\n",
      "           [ 2.0873e-02,  4.8141e-03,  6.4475e-03]],\n",
      "\n",
      "          [[ 3.8745e-02,  2.8878e-03, -6.1117e-03],\n",
      "           [-1.0591e-02,  5.0633e-03,  4.6217e-03],\n",
      "           [-3.2001e-02, -4.0181e-02, -8.7602e-04]],\n",
      "\n",
      "          [[-2.7420e-02, -2.6970e-02, -3.5976e-02],\n",
      "           [ 1.5281e-02, -1.9175e-02,  1.5116e-02],\n",
      "           [-1.9580e-02,  1.5601e-02,  6.2333e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 7.0858e-03,  1.0216e-02, -1.7867e-03],\n",
      "           [ 2.4646e-02,  6.7637e-04,  1.4431e-02],\n",
      "           [ 2.7669e-02,  1.5613e-02,  7.0377e-03]],\n",
      "\n",
      "          [[-1.4602e-02,  2.4827e-02, -8.6376e-03],\n",
      "           [ 2.5452e-02, -2.4984e-02, -2.3397e-02],\n",
      "           [-1.6145e-02,  1.0295e-02,  1.8234e-02]],\n",
      "\n",
      "          [[-1.2786e-02,  1.9146e-03, -9.2876e-03],\n",
      "           [-8.3476e-03,  6.0315e-03,  1.5291e-02],\n",
      "           [ 2.1793e-02, -1.4840e-02, -1.8214e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.1684e-03,  1.5489e-02, -2.6756e-02],\n",
      "           [ 1.2896e-02,  1.0613e-02,  2.3313e-03],\n",
      "           [ 2.8645e-02, -1.3910e-02, -1.8950e-02]],\n",
      "\n",
      "          [[ 3.0694e-02,  1.0469e-02, -2.3928e-02],\n",
      "           [-3.6720e-03,  4.1525e-02, -2.4913e-02],\n",
      "           [-7.5226e-03,  3.4867e-02, -2.3244e-02]],\n",
      "\n",
      "          [[ 2.8717e-04, -1.5588e-02, -2.9921e-02],\n",
      "           [ 1.9180e-02,  2.1265e-02,  4.0531e-03],\n",
      "           [ 4.1544e-03,  1.2016e-02,  1.4882e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.0965e-03, -1.0472e-02,  2.7546e-02],\n",
      "           [-3.3074e-02,  2.2189e-02,  1.3287e-02],\n",
      "           [-2.1967e-03,  2.0114e-02,  4.2367e-03]],\n",
      "\n",
      "          [[-4.8773e-02, -3.0400e-02,  5.1057e-03],\n",
      "           [-1.1237e-02,  3.8802e-02,  2.5011e-02],\n",
      "           [-3.4835e-03, -1.8719e-03, -1.3711e-02]],\n",
      "\n",
      "          [[-7.5480e-04, -3.6236e-02,  1.7454e-03],\n",
      "           [-3.4251e-02, -3.0424e-02, -1.1948e-03],\n",
      "           [-2.7695e-02,  3.2428e-02,  2.6020e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.8622e-03,  2.8600e-02,  3.6408e-02],\n",
      "           [ 2.2999e-02,  1.5403e-02,  1.3836e-02],\n",
      "           [ 9.6177e-03, -4.2738e-03, -2.4483e-02]],\n",
      "\n",
      "          [[-4.4437e-03, -2.4991e-02,  2.4044e-02],\n",
      "           [ 1.0662e-02,  2.3180e-02,  7.8810e-03],\n",
      "           [ 2.0168e-04,  1.5276e-02, -1.0247e-02]],\n",
      "\n",
      "          [[-9.9100e-03,  2.7060e-03, -2.4912e-02],\n",
      "           [ 1.4960e-02,  2.9876e-02, -8.4052e-04],\n",
      "           [ 9.4315e-03, -3.2650e-03,  2.1170e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.1514e-02, -7.4323e-03,  3.4571e-03],\n",
      "           [-1.8105e-02,  4.0230e-02,  1.2552e-02],\n",
      "           [-1.1839e-02, -8.2380e-03, -2.0392e-02]],\n",
      "\n",
      "          [[ 2.7835e-03,  7.5328e-03, -1.9051e-02],\n",
      "           [-6.4875e-03, -2.5225e-02,  2.8348e-02],\n",
      "           [ 3.9031e-02,  1.7654e-03,  1.8593e-02]],\n",
      "\n",
      "          [[-3.2632e-02, -2.9444e-02,  2.4824e-02],\n",
      "           [ 1.8339e-02, -4.2226e-03, -2.0388e-02],\n",
      "           [-1.9209e-02, -2.0331e-02,  1.4699e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.6018e-02,  2.9852e-03,  6.3460e-03],\n",
      "           [ 2.7189e-02, -1.5218e-02,  2.0280e-02],\n",
      "           [ 1.4940e-02, -1.2204e-02,  2.7406e-02]],\n",
      "\n",
      "          [[ 3.4567e-02,  1.8196e-03,  3.7883e-02],\n",
      "           [ 1.9081e-03, -9.3482e-03,  2.8058e-02],\n",
      "           [ 2.3027e-02,  2.4786e-02,  5.9420e-03]],\n",
      "\n",
      "          [[ 4.2564e-02,  2.0075e-02, -1.1374e-02],\n",
      "           [ 1.9078e-02,  3.5529e-02,  1.2115e-02],\n",
      "           [ 3.9844e-02,  4.1150e-02, -1.0078e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.3768e-02, -1.7505e-02,  3.1490e-02],\n",
      "           [ 4.3452e-03,  4.1192e-02,  2.0340e-02],\n",
      "           [ 4.3241e-02,  6.2497e-03, -1.4647e-02]],\n",
      "\n",
      "          [[ 1.9069e-02,  3.2511e-02,  7.1733e-04],\n",
      "           [ 4.3004e-02, -1.5562e-04,  2.7620e-02],\n",
      "           [ 8.0703e-03,  1.6723e-02,  4.7251e-02]],\n",
      "\n",
      "          [[-1.8748e-03,  2.6465e-02,  2.2799e-02],\n",
      "           [ 3.0711e-02,  4.0178e-02,  2.0695e-02],\n",
      "           [ 2.7174e-02,  3.4836e-02,  3.6977e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.5862e-02,  2.8575e-02, -1.1588e-02],\n",
      "           [ 3.1173e-02, -1.9521e-02,  2.9540e-02],\n",
      "           [-1.4519e-02,  2.3648e-02,  1.3469e-02]],\n",
      "\n",
      "          [[ 3.3641e-03, -2.9067e-02,  3.1123e-02],\n",
      "           [-1.6731e-02, -2.8269e-03,  6.2495e-03],\n",
      "           [-1.0892e-02,  2.0279e-02, -1.0880e-02]],\n",
      "\n",
      "          [[ 1.9512e-02,  4.2642e-03, -1.7701e-02],\n",
      "           [-4.0882e-02,  2.8367e-03,  2.3322e-02],\n",
      "           [-4.9347e-03,  1.7303e-02, -1.8448e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2248e-02,  1.9820e-02, -2.9897e-02],\n",
      "           [-7.0483e-03,  1.7782e-02,  2.7474e-02],\n",
      "           [ 1.5626e-02,  4.0734e-02,  2.6074e-02]],\n",
      "\n",
      "          [[-2.9109e-02, -2.2265e-02, -1.9400e-02],\n",
      "           [-2.0575e-02,  1.1796e-02,  2.9046e-03],\n",
      "           [ 1.9040e-03,  8.0358e-03, -1.0219e-02]],\n",
      "\n",
      "          [[-2.9295e-02,  5.3560e-03, -4.7687e-03],\n",
      "           [ 3.4635e-02, -4.2829e-02, -2.1014e-02],\n",
      "           [-7.1679e-03,  1.0590e-02,  2.7639e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.4421e-02, -3.3599e-02, -1.9863e-02],\n",
      "           [ 4.3271e-02, -8.9039e-03,  5.9361e-03],\n",
      "           [-7.1028e-03, -1.2825e-02, -6.9752e-03]],\n",
      "\n",
      "          [[ 1.1632e-03, -8.7326e-03, -3.3996e-02],\n",
      "           [-1.4209e-02,  2.8480e-02, -3.4795e-02],\n",
      "           [-1.1498e-02,  4.5901e-02, -1.4978e-02]],\n",
      "\n",
      "          [[ 1.9997e-02, -1.1752e-02,  1.6179e-02],\n",
      "           [-1.6119e-03,  3.5516e-02, -1.1006e-02],\n",
      "           [ 4.8127e-03,  1.2208e-02,  4.4490e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.2044e-02, -7.6226e-03, -2.7258e-02],\n",
      "           [ 3.6195e-02,  2.7421e-02, -1.6012e-02],\n",
      "           [ 5.9827e-03, -3.4828e-03, -4.6010e-03]],\n",
      "\n",
      "          [[ 1.0095e-02, -2.5891e-02,  1.5525e-02],\n",
      "           [-1.6975e-02,  2.2616e-02, -1.0546e-02],\n",
      "           [ 4.5887e-03,  3.7033e-03, -2.5253e-04]],\n",
      "\n",
      "          [[-8.0240e-03, -2.6342e-02, -2.3210e-02],\n",
      "           [ 1.3182e-02, -3.5673e-02, -1.6393e-02],\n",
      "           [ 3.5633e-04, -2.8996e-02,  2.0756e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.4756e-02,  3.1658e-02,  4.5010e-03],\n",
      "           [-1.8280e-02, -2.7624e-02, -3.4050e-02],\n",
      "           [ 1.6985e-02,  2.3899e-02,  2.0243e-02]],\n",
      "\n",
      "          [[-1.9477e-02, -2.8135e-02,  1.2637e-02],\n",
      "           [-2.6379e-02, -1.5164e-02, -1.8949e-03],\n",
      "           [ 1.5124e-02, -3.1580e-02, -2.6885e-02]],\n",
      "\n",
      "          [[-3.0392e-02, -4.0748e-02, -3.1023e-02],\n",
      "           [ 3.7962e-03,  2.0124e-02, -8.6093e-03],\n",
      "           [ 1.6391e-02,  5.7928e-03, -2.0503e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.9354e-02, -3.1528e-03, -9.1829e-03],\n",
      "           [-4.6778e-03, -2.7740e-03,  6.3838e-03],\n",
      "           [-5.7903e-03,  4.7300e-04,  5.9346e-03]],\n",
      "\n",
      "          [[ 2.1535e-02,  1.5243e-02,  2.5171e-03],\n",
      "           [-3.1438e-02, -2.8753e-02, -2.4905e-02],\n",
      "           [ 1.2061e-02, -1.6867e-02,  2.4709e-02]],\n",
      "\n",
      "          [[ 1.8789e-02, -1.7409e-02,  4.5092e-03],\n",
      "           [-3.4470e-02,  4.1347e-03,  8.9831e-03],\n",
      "           [ 1.7992e-02, -1.6743e-02,  1.8090e-02]]]]], device='cuda:0')), ('module.down_layers.1.1.conv2.conv.weight', tensor([[[[[-1.7098e-02, -2.6513e-02,  2.9844e-02],\n",
      "           [-1.1104e-02, -4.1211e-02, -3.3374e-03],\n",
      "           [-2.7458e-02, -1.8804e-02,  5.7544e-03]],\n",
      "\n",
      "          [[-6.4863e-03, -4.6067e-03, -1.9630e-02],\n",
      "           [-3.3410e-02, -8.8740e-03,  1.7141e-02],\n",
      "           [ 5.3900e-03,  6.6648e-03,  7.8924e-03]],\n",
      "\n",
      "          [[-1.7940e-02, -2.5928e-02,  3.3878e-02],\n",
      "           [-1.7428e-02, -1.2759e-03,  1.1356e-02],\n",
      "           [ 6.2658e-04,  1.3659e-02,  1.1637e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.4278e-02, -3.4571e-03, -1.6352e-03],\n",
      "           [ 4.9088e-03, -2.3093e-02,  3.2942e-02],\n",
      "           [ 9.8870e-03, -1.0307e-02, -4.6412e-03]],\n",
      "\n",
      "          [[ 7.1325e-03,  1.1478e-02,  4.8974e-02],\n",
      "           [ 1.2440e-03, -2.0969e-02,  1.2130e-02],\n",
      "           [ 3.1446e-02,  3.9845e-02,  3.9200e-04]],\n",
      "\n",
      "          [[-1.4222e-02,  3.8405e-02,  1.9243e-03],\n",
      "           [ 3.1863e-02,  4.4240e-02,  2.5154e-02],\n",
      "           [ 2.1168e-02,  2.3902e-02,  3.2849e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.7010e-03,  3.4327e-02,  2.5106e-02],\n",
      "           [ 8.0960e-03,  4.8255e-02, -1.8918e-03],\n",
      "           [-2.4689e-02, -1.0365e-02, -7.1857e-03]],\n",
      "\n",
      "          [[-1.0629e-02,  1.1691e-02, -7.3888e-03],\n",
      "           [ 2.6624e-02, -1.4154e-02, -2.2735e-02],\n",
      "           [ 1.7614e-02,  3.3331e-02,  2.5717e-02]],\n",
      "\n",
      "          [[-4.5810e-03,  2.7123e-02,  2.9043e-02],\n",
      "           [-2.1913e-02,  4.6778e-03,  7.9849e-03],\n",
      "           [ 2.9163e-02, -3.4278e-02, -3.8280e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.2962e-02,  3.4292e-03, -5.8044e-03],\n",
      "           [ 2.0893e-02,  6.5306e-04,  2.6621e-02],\n",
      "           [ 1.1275e-02, -1.3896e-02, -2.3530e-02]],\n",
      "\n",
      "          [[ 3.8006e-02,  3.8452e-02,  1.1920e-02],\n",
      "           [ 5.0409e-02,  1.1025e-02, -3.4732e-02],\n",
      "           [-1.6885e-02,  2.2988e-02, -3.2545e-03]],\n",
      "\n",
      "          [[-1.4476e-02,  7.0476e-03,  3.7901e-02],\n",
      "           [ 3.4022e-02,  5.4435e-03, -7.9380e-03],\n",
      "           [ 1.6145e-02,  1.7455e-02, -3.9457e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.4957e-02,  4.6814e-03,  1.7604e-02],\n",
      "           [-1.1568e-02, -4.7992e-03, -3.0417e-03],\n",
      "           [ 2.5169e-02,  1.2415e-02,  2.6002e-02]],\n",
      "\n",
      "          [[ 4.7143e-02,  4.3336e-04,  2.3151e-02],\n",
      "           [ 1.3314e-02,  2.8817e-04,  2.9781e-02],\n",
      "           [-1.3738e-02,  2.3134e-02, -1.6996e-02]],\n",
      "\n",
      "          [[-2.2101e-03,  1.3369e-02, -8.2598e-03],\n",
      "           [ 3.1602e-02, -3.2611e-02, -8.9723e-03],\n",
      "           [ 2.2983e-03,  1.3189e-05,  1.2517e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.2081e-02,  8.9205e-03, -1.8482e-02],\n",
      "           [-2.4636e-02, -3.5217e-02, -2.3800e-02],\n",
      "           [-1.1574e-02,  3.7739e-02,  1.8338e-02]],\n",
      "\n",
      "          [[-1.7974e-02,  1.7037e-02, -1.1856e-02],\n",
      "           [-1.4760e-02,  1.2412e-03,  2.2981e-02],\n",
      "           [ 7.0743e-03, -2.2601e-02, -1.4102e-02]],\n",
      "\n",
      "          [[-2.3688e-02,  7.6170e-04,  4.7786e-03],\n",
      "           [ 2.0756e-02,  2.1760e-02,  1.3060e-02],\n",
      "           [-6.3937e-03,  2.8371e-02, -2.4295e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.2706e-02,  1.3165e-02, -8.9616e-03],\n",
      "           [-4.2043e-02,  8.7755e-03, -1.7527e-02],\n",
      "           [-1.0881e-02,  2.0481e-02, -6.1014e-03]],\n",
      "\n",
      "          [[-2.1585e-02, -2.9493e-02,  4.8665e-02],\n",
      "           [ 5.5795e-03, -6.1979e-03,  6.2679e-03],\n",
      "           [ 2.1470e-03, -1.5508e-02, -2.1688e-02]],\n",
      "\n",
      "          [[-2.0231e-02, -6.3250e-03,  3.9990e-02],\n",
      "           [ 1.6610e-02,  1.2386e-04, -1.0851e-02],\n",
      "           [ 2.6357e-02, -3.6875e-03,  3.4664e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.6310e-03, -3.0666e-02,  3.5084e-02],\n",
      "           [ 8.6225e-03,  1.8293e-02,  1.9628e-02],\n",
      "           [ 1.5006e-02, -3.1465e-02, -3.0526e-02]],\n",
      "\n",
      "          [[-1.7500e-02,  2.4850e-02, -2.0621e-02],\n",
      "           [-3.7267e-02, -3.5920e-02,  3.5927e-03],\n",
      "           [-2.6054e-02, -2.7446e-02, -2.7371e-02]],\n",
      "\n",
      "          [[-4.7435e-02, -8.3884e-03,  4.0278e-03],\n",
      "           [ 1.2306e-02, -1.9589e-02, -4.0158e-02],\n",
      "           [-3.7815e-02,  1.1403e-02, -2.2788e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.3539e-02,  1.8430e-02,  2.0917e-02],\n",
      "           [ 6.8818e-03,  2.9026e-02, -1.6803e-02],\n",
      "           [ 4.2028e-02,  3.7231e-02,  1.8808e-02]],\n",
      "\n",
      "          [[-4.0898e-02,  1.0287e-03,  5.0231e-03],\n",
      "           [-4.7880e-02, -4.0855e-02,  1.1219e-02],\n",
      "           [-4.4361e-02,  2.1244e-02, -2.0282e-04]],\n",
      "\n",
      "          [[ 9.4968e-03, -4.3237e-03, -3.2722e-02],\n",
      "           [-3.6438e-02, -4.8418e-02, -8.9816e-03],\n",
      "           [-6.9507e-03, -2.6977e-02, -1.9467e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.9590e-02, -3.6451e-02, -2.1089e-02],\n",
      "           [ 1.1911e-03, -9.2306e-03, -1.9821e-02],\n",
      "           [ 5.6668e-03,  1.6878e-02, -1.3079e-02]],\n",
      "\n",
      "          [[-3.9834e-02, -2.8762e-03,  1.8254e-02],\n",
      "           [-1.7467e-02, -7.9412e-03, -2.2583e-02],\n",
      "           [ 3.6976e-02,  3.0735e-02, -4.5339e-03]],\n",
      "\n",
      "          [[-2.6523e-02,  4.7570e-03, -1.9437e-02],\n",
      "           [ 5.9373e-03, -1.2135e-02, -1.6804e-02],\n",
      "           [ 9.7811e-03, -7.5275e-03, -2.0788e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.6476e-02,  2.8290e-02,  1.0201e-02],\n",
      "           [ 4.4501e-02,  1.8600e-02,  1.8654e-02],\n",
      "           [ 1.4409e-02, -1.0524e-03,  1.1036e-02]],\n",
      "\n",
      "          [[-5.1351e-03, -2.6735e-02,  1.2379e-02],\n",
      "           [ 3.1774e-02,  2.8415e-02,  7.3658e-03],\n",
      "           [ 3.6753e-03, -1.1714e-02,  3.6138e-05]],\n",
      "\n",
      "          [[ 4.7571e-02,  1.1814e-02, -1.0995e-02],\n",
      "           [ 1.0169e-02,  6.2621e-03, -4.5888e-04],\n",
      "           [ 2.1722e-02,  6.4237e-03,  6.3864e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.3319e-02,  1.2086e-02, -8.9167e-03],\n",
      "           [-4.2895e-02,  5.4338e-03, -1.8941e-02],\n",
      "           [-5.8804e-02, -2.8545e-02, -3.0159e-03]],\n",
      "\n",
      "          [[ 1.7015e-02,  2.7959e-02, -8.3894e-03],\n",
      "           [-2.1952e-02, -9.8956e-03,  8.2262e-03],\n",
      "           [-3.2372e-02, -4.3517e-02,  2.4161e-02]],\n",
      "\n",
      "          [[-1.6832e-02,  2.5761e-02,  6.2799e-02],\n",
      "           [ 1.7962e-02,  1.8864e-02,  9.7767e-03],\n",
      "           [ 6.1194e-03,  2.8467e-02,  2.4699e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 9.8654e-03,  1.8598e-02, -1.3664e-02],\n",
      "           [ 1.6237e-02, -7.0574e-03, -2.3334e-02],\n",
      "           [-2.9662e-02, -3.4873e-03,  3.0344e-02]],\n",
      "\n",
      "          [[ 2.1397e-02,  1.6709e-02,  6.6167e-03],\n",
      "           [ 3.1479e-03, -2.9215e-05,  1.7432e-02],\n",
      "           [ 6.6376e-03,  1.3008e-02, -1.7321e-03]],\n",
      "\n",
      "          [[ 2.1838e-02, -2.1439e-02, -5.2413e-02],\n",
      "           [ 2.6742e-02, -1.2211e-02, -5.0016e-03],\n",
      "           [-1.8608e-02,  3.2325e-03,  1.2791e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.1858e-02, -5.9556e-03,  1.8157e-02],\n",
      "           [-4.6641e-03, -6.0274e-03,  2.1031e-02],\n",
      "           [-1.8311e-02,  2.1386e-02, -2.5735e-02]],\n",
      "\n",
      "          [[ 1.3878e-02,  8.0041e-04,  2.8849e-02],\n",
      "           [-1.3008e-02,  3.4123e-03,  1.0858e-02],\n",
      "           [-3.7218e-02, -2.3407e-03,  2.5362e-02]],\n",
      "\n",
      "          [[ 1.6395e-02,  4.3592e-03,  2.3917e-02],\n",
      "           [ 1.6616e-02,  8.8044e-03, -2.7089e-02],\n",
      "           [-3.1150e-04, -8.1979e-03, -2.2541e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.9214e-02, -2.5756e-02,  1.1307e-02],\n",
      "           [ 1.0037e-02,  1.0752e-02, -2.9238e-02],\n",
      "           [-1.8905e-02, -2.2706e-02, -2.0724e-02]],\n",
      "\n",
      "          [[-6.6359e-03, -2.2043e-02,  1.6835e-02],\n",
      "           [-3.2475e-02,  2.8171e-02,  1.0621e-02],\n",
      "           [ 1.0952e-02,  7.1620e-03,  3.4957e-02]],\n",
      "\n",
      "          [[-1.2067e-02,  2.6941e-02,  1.7198e-02],\n",
      "           [ 1.4822e-02,  3.8658e-02,  4.0568e-02],\n",
      "           [ 1.4141e-03,  1.7802e-02, -5.7126e-04]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.9212e-03, -6.2406e-03,  2.3170e-02],\n",
      "           [ 2.3544e-02, -1.6317e-02, -2.0625e-02],\n",
      "           [ 1.9665e-02,  2.5599e-02,  4.8652e-04]],\n",
      "\n",
      "          [[-1.3992e-02,  1.4540e-02, -2.5098e-03],\n",
      "           [-2.3063e-02,  2.9729e-02,  3.1756e-02],\n",
      "           [ 8.9765e-03, -1.5550e-02, -1.3424e-02]],\n",
      "\n",
      "          [[-3.1359e-02, -3.0859e-02,  3.1751e-02],\n",
      "           [-2.9523e-03, -2.9568e-02, -2.2338e-02],\n",
      "           [ 1.5765e-02,  3.2460e-02, -4.5081e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.7207e-02, -2.6607e-02, -3.3527e-02],\n",
      "           [-4.4197e-02, -8.5995e-03, -4.2701e-02],\n",
      "           [-3.5314e-02, -4.7795e-02, -1.9267e-02]],\n",
      "\n",
      "          [[-3.9803e-02, -3.1954e-02,  1.0005e-02],\n",
      "           [-1.5686e-02, -1.7494e-02,  2.0249e-02],\n",
      "           [-3.0127e-02,  8.6002e-03,  1.2507e-02]],\n",
      "\n",
      "          [[-2.6470e-02,  1.0029e-02,  4.0545e-02],\n",
      "           [ 3.3544e-03, -9.4007e-03,  4.4772e-02],\n",
      "           [-3.1169e-02,  2.4859e-02, -8.3778e-04]]],\n",
      "\n",
      "\n",
      "         [[[-1.3620e-02, -2.6997e-03, -3.3119e-02],\n",
      "           [ 1.9938e-02, -1.9947e-02,  1.8522e-02],\n",
      "           [ 9.7530e-03,  1.9261e-02,  2.3979e-02]],\n",
      "\n",
      "          [[-2.8274e-02,  1.0034e-02, -2.7777e-02],\n",
      "           [-1.3090e-02, -2.3141e-03, -2.0765e-02],\n",
      "           [ 3.4942e-02, -1.6454e-02,  2.1168e-02]],\n",
      "\n",
      "          [[ 1.0572e-02, -2.8898e-02, -3.4041e-03],\n",
      "           [ 3.4544e-02, -2.2056e-02, -2.0251e-02],\n",
      "           [ 3.1646e-02, -1.6323e-02,  3.9034e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.7693e-02, -1.0731e-02, -6.2171e-04],\n",
      "           [-1.5458e-02,  1.5551e-02,  3.4690e-02],\n",
      "           [-1.4364e-02,  1.2066e-03,  3.2579e-02]],\n",
      "\n",
      "          [[-2.1944e-02, -1.4484e-02, -1.4193e-02],\n",
      "           [-1.8688e-02,  3.4606e-02,  3.7548e-02],\n",
      "           [ 3.4618e-02, -1.7772e-02,  2.2431e-03]],\n",
      "\n",
      "          [[-8.0562e-03,  3.8059e-02,  9.4650e-03],\n",
      "           [ 8.9534e-03, -3.6433e-03, -1.8712e-02],\n",
      "           [ 2.7339e-02, -2.2603e-02,  1.1476e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.5416e-02, -2.9931e-02, -9.5153e-03],\n",
      "           [-2.3284e-02,  1.1370e-02,  2.4252e-02],\n",
      "           [-3.6520e-03,  1.3602e-02, -3.0537e-02]],\n",
      "\n",
      "          [[-2.1752e-03,  5.7092e-03, -2.2006e-02],\n",
      "           [ 1.7752e-02, -3.1511e-02,  1.8962e-02],\n",
      "           [-2.3513e-02, -1.3287e-02,  1.3526e-02]],\n",
      "\n",
      "          [[ 6.3630e-03, -3.2764e-02, -1.9168e-02],\n",
      "           [-4.0182e-02, -9.0007e-03,  1.8927e-02],\n",
      "           [-7.3100e-03, -2.0822e-02, -1.7099e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.2705e-02, -2.3709e-02, -1.9243e-02],\n",
      "           [-3.0438e-02,  3.9432e-02, -8.3968e-03],\n",
      "           [ 2.0409e-02,  3.1350e-02, -7.5949e-03]],\n",
      "\n",
      "          [[-1.8823e-02,  1.7774e-02,  2.5507e-02],\n",
      "           [ 6.9432e-03,  2.5784e-02, -1.2471e-02],\n",
      "           [-9.6131e-03,  3.1370e-03,  2.5475e-02]],\n",
      "\n",
      "          [[-2.8139e-02,  4.6951e-03,  3.9545e-02],\n",
      "           [ 2.6877e-03, -1.8596e-02, -2.7355e-02],\n",
      "           [ 3.7466e-02, -1.4602e-02,  2.5258e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.8388e-02, -2.3968e-02, -1.9654e-02],\n",
      "           [-2.4789e-02, -2.4860e-02,  4.0819e-03],\n",
      "           [-4.0797e-03, -1.4856e-02,  1.2101e-02]],\n",
      "\n",
      "          [[ 2.7351e-02,  1.7088e-02,  1.8755e-03],\n",
      "           [ 1.5342e-02,  3.3390e-02,  1.0882e-02],\n",
      "           [ 3.5296e-02,  2.5409e-02, -8.7670e-03]],\n",
      "\n",
      "          [[ 1.4399e-03,  3.8996e-02, -2.4375e-03],\n",
      "           [-5.9835e-05, -2.4588e-03,  6.2932e-03],\n",
      "           [-7.2736e-03,  3.1791e-02,  1.4127e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2499e-02,  1.4760e-02, -3.3295e-02],\n",
      "           [ 7.3281e-03, -1.9296e-02, -6.9166e-04],\n",
      "           [ 2.5622e-02, -2.6921e-02,  5.8544e-03]],\n",
      "\n",
      "          [[ 2.1251e-02,  2.5766e-02, -1.3338e-03],\n",
      "           [-5.7682e-03, -4.1433e-03,  1.4155e-02],\n",
      "           [ 7.0519e-03,  2.6213e-02, -1.5208e-02]],\n",
      "\n",
      "          [[ 1.9489e-02,  2.5129e-02, -4.6654e-02],\n",
      "           [-1.5998e-02,  2.2328e-02, -5.1404e-02],\n",
      "           [-6.5838e-03, -5.5199e-03, -7.5169e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.4465e-02, -2.1862e-02,  9.3539e-03],\n",
      "           [-8.9159e-04,  7.1733e-03,  2.3584e-03],\n",
      "           [ 2.5973e-02, -1.6123e-02, -1.6189e-02]],\n",
      "\n",
      "          [[-2.7118e-02, -7.3177e-03,  1.0847e-02],\n",
      "           [-6.1077e-03, -1.2298e-02, -1.0178e-02],\n",
      "           [-3.0788e-02, -1.5788e-02,  9.0238e-03]],\n",
      "\n",
      "          [[-1.8593e-02, -1.7912e-02,  3.1482e-02],\n",
      "           [-1.1482e-02, -3.4411e-02, -3.2042e-02],\n",
      "           [ 7.8934e-03,  6.4030e-03, -2.8477e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.1435e-02, -2.4187e-02,  2.0586e-03],\n",
      "           [-2.9841e-03,  3.3358e-02,  1.2680e-02],\n",
      "           [-1.0802e-03,  2.6936e-02, -3.0467e-03]],\n",
      "\n",
      "          [[-1.0060e-02,  6.4477e-03,  1.5021e-02],\n",
      "           [-4.5888e-02,  1.5222e-02,  3.1927e-02],\n",
      "           [-1.1756e-02, -8.2318e-03,  1.7751e-02]],\n",
      "\n",
      "          [[-4.3099e-02, -3.5246e-02,  1.5934e-02],\n",
      "           [-5.0321e-02, -2.5759e-02, -2.0058e-02],\n",
      "           [ 2.6277e-02, -2.3075e-02,  2.6887e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.5239e-02,  1.0537e-03,  3.2498e-02],\n",
      "           [-1.6480e-03, -7.4556e-03,  3.8087e-03],\n",
      "           [-3.6743e-02,  7.4482e-03,  5.8171e-03]],\n",
      "\n",
      "          [[-1.4390e-02,  2.5256e-02,  3.4259e-02],\n",
      "           [-2.6193e-02, -7.7234e-03, -1.5198e-02],\n",
      "           [-3.8462e-02, -1.2434e-02,  3.6794e-02]],\n",
      "\n",
      "          [[-1.4025e-02, -6.8471e-03,  3.6971e-02],\n",
      "           [-9.7435e-03, -1.8521e-02, -2.3996e-02],\n",
      "           [-1.4859e-03, -3.3041e-02,  1.9738e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 5.3493e-02,  1.1153e-02,  5.1250e-02],\n",
      "           [ 1.1687e-02,  3.9136e-02,  3.9011e-03],\n",
      "           [-2.8305e-02, -1.0582e-02, -3.4464e-02]],\n",
      "\n",
      "          [[-1.3705e-02,  3.7285e-03,  2.0558e-02],\n",
      "           [ 4.5719e-02, -9.9056e-05, -2.7126e-02],\n",
      "           [-3.2878e-03, -1.6044e-02, -4.9217e-03]],\n",
      "\n",
      "          [[ 7.5316e-03,  1.7281e-02,  1.1187e-02],\n",
      "           [-9.3110e-03,  1.0671e-02, -9.6022e-03],\n",
      "           [ 2.8298e-02, -3.4749e-02, -7.0440e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.9009e-02,  2.9739e-02,  1.9639e-02],\n",
      "           [ 3.3773e-02,  1.0031e-03,  3.2428e-02],\n",
      "           [ 3.4512e-02, -4.0849e-03, -1.6829e-02]],\n",
      "\n",
      "          [[-3.8225e-02,  9.8628e-03, -1.7950e-02],\n",
      "           [-7.5698e-03, -5.8131e-03, -2.2084e-02],\n",
      "           [ 1.8903e-02,  6.5797e-03, -1.0019e-02]],\n",
      "\n",
      "          [[ 9.2604e-03, -1.7209e-02, -7.8174e-04],\n",
      "           [-1.5674e-02, -2.3891e-02,  3.1762e-02],\n",
      "           [ 2.7189e-02,  3.2817e-02,  8.0261e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.2551e-02, -1.9025e-02, -2.1734e-02],\n",
      "           [-3.8460e-02, -1.5743e-02, -2.6645e-02],\n",
      "           [-4.4103e-02,  7.0740e-03, -6.1940e-03]],\n",
      "\n",
      "          [[-5.1509e-02, -3.3603e-02, -7.1097e-03],\n",
      "           [-5.3578e-02, -3.0140e-02,  1.9769e-02],\n",
      "           [-5.1920e-02,  6.6188e-03,  3.8126e-02]],\n",
      "\n",
      "          [[-1.3614e-02, -1.8486e-02,  8.1762e-04],\n",
      "           [-6.3148e-02, -3.9446e-02, -2.3515e-02],\n",
      "           [-8.1047e-03, -4.3900e-02,  2.6231e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.6251e-02, -4.0370e-02, -3.4187e-02],\n",
      "           [-2.8898e-02, -3.3380e-02, -2.8020e-02],\n",
      "           [ 2.2231e-02, -1.8630e-03,  2.6595e-02]],\n",
      "\n",
      "          [[-1.7398e-03,  1.5551e-02, -3.5282e-02],\n",
      "           [ 2.6995e-02,  2.4178e-03, -3.4033e-02],\n",
      "           [ 1.5084e-02,  3.4819e-02,  1.8687e-02]],\n",
      "\n",
      "          [[-3.2622e-03,  2.4369e-02,  3.1376e-02],\n",
      "           [ 4.2809e-02,  2.0422e-02,  1.5892e-02],\n",
      "           [ 2.5014e-02,  3.6547e-03,  1.0554e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.2538e-02, -1.1396e-02,  1.0926e-02],\n",
      "           [-2.0892e-02, -2.4551e-02, -1.0665e-02],\n",
      "           [-3.3837e-02, -8.5403e-03,  1.3483e-02]],\n",
      "\n",
      "          [[-2.2688e-02,  1.1107e-02,  1.9051e-02],\n",
      "           [-5.9418e-02, -2.9172e-02,  3.8540e-03],\n",
      "           [-4.6052e-02, -3.3669e-02,  3.8707e-02]],\n",
      "\n",
      "          [[-4.3701e-02,  4.2823e-03,  4.7677e-02],\n",
      "           [-1.6737e-02, -4.9201e-02, -1.1502e-02],\n",
      "           [-2.4493e-02, -4.1173e-02, -9.0468e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3719e-03,  2.6349e-02,  1.5439e-02],\n",
      "           [-2.1019e-02, -1.0928e-02,  8.5119e-03],\n",
      "           [-1.3664e-02,  1.8430e-02,  1.0698e-02]],\n",
      "\n",
      "          [[ 3.3528e-02,  4.6569e-02, -7.8960e-03],\n",
      "           [ 3.8300e-02,  2.0958e-02,  8.1575e-03],\n",
      "           [-3.3043e-03, -3.2924e-02,  3.1598e-02]],\n",
      "\n",
      "          [[ 1.3087e-02, -1.2952e-02, -3.1019e-02],\n",
      "           [ 2.0373e-02, -1.4316e-02, -1.4070e-03],\n",
      "           [-1.8841e-02,  2.4769e-02, -2.7741e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.0389e-02, -2.5726e-03,  3.9088e-02],\n",
      "           [ 3.3036e-02,  1.9469e-03,  1.5229e-02],\n",
      "           [-8.7334e-04,  2.8323e-02,  5.3774e-03]],\n",
      "\n",
      "          [[ 1.2327e-02,  1.5373e-02,  3.5416e-02],\n",
      "           [ 1.3664e-03,  2.4335e-02,  2.8265e-02],\n",
      "           [ 2.0547e-02, -1.7719e-02, -6.1296e-03]],\n",
      "\n",
      "          [[ 2.1008e-02,  4.8291e-02,  7.9465e-03],\n",
      "           [-9.6852e-04, -1.0043e-02,  3.4787e-02],\n",
      "           [-1.1317e-02,  3.6355e-02,  2.2090e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.3288e-02, -1.6688e-02, -1.7977e-03],\n",
      "           [-1.6062e-02,  3.1553e-02,  2.1468e-02],\n",
      "           [ 8.8464e-03,  2.6540e-02,  6.6918e-03]],\n",
      "\n",
      "          [[-1.1740e-02, -2.5825e-02, -2.5770e-02],\n",
      "           [-3.2697e-03, -3.1999e-02, -1.6043e-02],\n",
      "           [-2.1602e-02,  2.3283e-02, -4.6040e-03]],\n",
      "\n",
      "          [[ 3.6334e-02, -2.4754e-03, -5.6876e-03],\n",
      "           [ 3.5600e-02, -1.6046e-02, -3.6866e-02],\n",
      "           [ 3.3825e-03,  9.3789e-03,  1.5682e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2886e-02,  8.5475e-03, -1.0757e-02],\n",
      "           [ 3.0667e-02, -1.5152e-02,  1.4774e-02],\n",
      "           [-3.2611e-02, -9.1150e-03, -6.4336e-03]],\n",
      "\n",
      "          [[ 1.1419e-02, -1.7388e-02, -6.3415e-03],\n",
      "           [ 4.3023e-02,  2.0116e-02, -2.6709e-02],\n",
      "           [ 2.5830e-02, -1.1913e-02, -1.5641e-02]],\n",
      "\n",
      "          [[ 1.6144e-03,  1.3019e-02, -1.1294e-02],\n",
      "           [ 3.4545e-02,  3.0219e-03, -3.8911e-02],\n",
      "           [-2.3311e-03, -3.8546e-02,  3.4426e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.7006e-02, -2.8953e-02,  2.6379e-02],\n",
      "           [-1.1736e-02, -4.1359e-02, -5.8171e-03],\n",
      "           [ 2.7009e-02,  2.3689e-02,  2.1658e-02]],\n",
      "\n",
      "          [[-4.3503e-02, -2.6788e-02,  4.3829e-02],\n",
      "           [-4.0299e-02,  6.9255e-03, -4.2656e-03],\n",
      "           [-6.8811e-03,  8.6859e-03, -1.3296e-02]],\n",
      "\n",
      "          [[-5.6953e-04,  1.7418e-02,  1.3385e-02],\n",
      "           [ 2.5262e-02,  4.7882e-03, -2.9696e-02],\n",
      "           [ 3.8149e-02,  6.9990e-03,  2.2053e-02]]]]], device='cuda:0')), ('module.down_layers.1.2.norm1.weight', tensor([0.9614, 0.9951, 0.9761, 0.9684, 1.0025, 0.9965, 0.9757, 1.0193, 0.9718,\n",
      "        1.0095, 0.9756, 0.9727, 0.9692, 0.9918, 0.9863, 0.9918, 1.0011, 0.9914,\n",
      "        0.9781, 1.0039, 1.0380, 0.9779, 0.9700, 0.9885, 0.9549, 0.9751, 0.9730,\n",
      "        1.0025, 0.9855, 0.9865, 0.9961, 0.9973], device='cuda:0')), ('module.down_layers.1.2.norm1.bias', tensor([-0.0184, -0.0093, -0.0103,  0.0033, -0.0033, -0.0049,  0.0015,  0.0180,\n",
      "        -0.0187, -0.0133, -0.0186, -0.0125, -0.0411, -0.0197, -0.0384, -0.0340,\n",
      "        -0.0080, -0.0246, -0.0311, -0.0194, -0.0408, -0.0121, -0.0261, -0.0351,\n",
      "        -0.0089, -0.0059, -0.0148,  0.0055,  0.0062, -0.0136, -0.0006, -0.0183],\n",
      "       device='cuda:0')), ('module.down_layers.1.2.norm2.weight', tensor([0.9899, 0.9823, 0.9257, 0.9793, 0.9793, 1.0006, 0.9959, 0.9309, 0.9970,\n",
      "        0.9580, 0.9212, 0.9905, 0.9754, 1.0072, 0.9502, 0.9081, 0.9949, 0.9919,\n",
      "        1.0026, 0.8554, 0.9962, 0.9887, 1.0108, 0.9942, 0.9808, 0.9539, 0.9904,\n",
      "        1.0001, 0.9937, 0.9860, 0.9984, 0.9868], device='cuda:0')), ('module.down_layers.1.2.norm2.bias', tensor([ 0.0015, -0.0129, -0.0141, -0.0194, -0.0195, -0.0278, -0.0055, -0.0203,\n",
      "        -0.0062, -0.0093, -0.0273, -0.0007, -0.0318, -0.0136,  0.0016, -0.0167,\n",
      "        -0.0067, -0.0296, -0.0293, -0.0133, -0.0244, -0.0274,  0.0153, -0.0257,\n",
      "        -0.0377, -0.0348, -0.0170, -0.0238, -0.0267, -0.0551, -0.0430, -0.0364],\n",
      "       device='cuda:0')), ('module.down_layers.1.2.conv1.conv.weight', tensor([[[[[-2.9443e-02,  1.5132e-02, -3.0475e-02],\n",
      "           [ 4.4025e-03,  2.8653e-02,  4.3036e-02],\n",
      "           [ 1.8203e-02,  2.2086e-02,  9.2613e-03]],\n",
      "\n",
      "          [[ 3.2946e-02, -2.1854e-02,  4.1681e-03],\n",
      "           [ 1.2001e-02,  3.9595e-02,  2.8041e-02],\n",
      "           [ 3.7046e-03,  2.3747e-03,  2.4569e-02]],\n",
      "\n",
      "          [[-1.5667e-02,  3.1819e-03, -2.6315e-02],\n",
      "           [ 2.8826e-02, -1.0231e-02,  2.5703e-02],\n",
      "           [ 3.0770e-02,  2.2841e-02,  7.8364e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2117e-02, -1.6300e-02,  2.9576e-02],\n",
      "           [ 1.2418e-02, -1.4081e-02,  8.6000e-03],\n",
      "           [ 8.3662e-03, -6.9470e-03,  4.2677e-03]],\n",
      "\n",
      "          [[-3.4182e-03,  6.9534e-03,  1.9510e-02],\n",
      "           [-2.9784e-03, -9.9248e-03, -4.0996e-02],\n",
      "           [ 1.5477e-03, -4.2045e-02, -4.9147e-02]],\n",
      "\n",
      "          [[ 1.1512e-02,  2.9656e-02, -3.0761e-02],\n",
      "           [-2.5024e-03,  1.2185e-02, -3.1941e-02],\n",
      "           [ 2.4782e-02, -1.9666e-02, -3.3494e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.1140e-03, -4.4557e-03, -3.9315e-03],\n",
      "           [-2.4440e-02, -2.4869e-02,  2.4756e-03],\n",
      "           [-2.2858e-02,  2.2780e-02,  1.7542e-02]],\n",
      "\n",
      "          [[-1.5524e-02,  4.7607e-03,  2.2113e-02],\n",
      "           [-1.4854e-02, -4.0657e-02, -3.7360e-02],\n",
      "           [-1.0637e-02,  2.8583e-02, -2.2995e-02]],\n",
      "\n",
      "          [[ 1.2882e-02, -4.8689e-05,  2.1862e-02],\n",
      "           [ 2.3781e-02,  1.3356e-02,  2.2636e-02],\n",
      "           [-2.8179e-02,  3.2599e-02, -1.2950e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.0546e-02, -9.5257e-03, -9.6036e-03],\n",
      "           [-2.1001e-02,  1.5877e-02, -5.1099e-03],\n",
      "           [-2.7403e-02, -6.7171e-03, -1.9913e-02]],\n",
      "\n",
      "          [[-7.0306e-03,  1.1700e-02,  2.0949e-02],\n",
      "           [ 4.5163e-02,  4.2912e-02, -6.3925e-03],\n",
      "           [-2.4548e-02,  3.2451e-02,  1.0807e-02]],\n",
      "\n",
      "          [[-1.2719e-02,  7.6124e-03,  4.1105e-02],\n",
      "           [ 3.7055e-02,  5.1174e-02, -1.0395e-02],\n",
      "           [ 1.5911e-02,  4.4904e-02, -4.4541e-04]]],\n",
      "\n",
      "\n",
      "         [[[-2.2078e-02,  3.9437e-02,  1.4774e-02],\n",
      "           [-1.3723e-02,  1.3700e-02,  4.1293e-02],\n",
      "           [ 4.4733e-02,  1.8021e-02, -1.2656e-02]],\n",
      "\n",
      "          [[-3.1247e-03, -1.1187e-02, -1.8602e-02],\n",
      "           [ 3.9995e-02,  9.6457e-03, -1.1140e-03],\n",
      "           [-1.4009e-02,  2.5472e-02,  1.0604e-02]],\n",
      "\n",
      "          [[ 1.5285e-03, -3.1262e-04, -3.3815e-02],\n",
      "           [ 3.6679e-02, -1.0951e-02, -3.3708e-02],\n",
      "           [ 2.3407e-02, -2.3170e-02,  1.8598e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4355e-02,  4.4286e-02,  2.2943e-02],\n",
      "           [-6.0829e-03,  3.5214e-02,  1.1855e-02],\n",
      "           [ 3.1256e-02,  8.3504e-03, -6.6766e-03]],\n",
      "\n",
      "          [[ 5.0904e-02,  4.8107e-02, -7.0715e-03],\n",
      "           [-4.5883e-03, -1.0836e-02, -1.2803e-02],\n",
      "           [-2.3388e-02, -2.6044e-02, -3.3648e-03]],\n",
      "\n",
      "          [[ 1.5312e-02, -6.3197e-03, -2.4787e-03],\n",
      "           [-6.0403e-03,  1.4568e-02, -3.9298e-03],\n",
      "           [ 2.9634e-02, -2.1455e-02, -4.4473e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.2898e-02,  5.0594e-02,  4.7524e-02],\n",
      "           [ 4.8008e-04,  4.9776e-02,  3.7796e-02],\n",
      "           [-6.9648e-03, -1.1509e-02, -9.6364e-03]],\n",
      "\n",
      "          [[ 4.4730e-03,  4.3119e-02, -6.8479e-03],\n",
      "           [-1.5536e-02, -2.3714e-02, -1.1206e-02],\n",
      "           [-3.9362e-03, -6.2655e-03, -2.8955e-02]],\n",
      "\n",
      "          [[ 2.4747e-02, -1.4077e-02,  1.0777e-02],\n",
      "           [-1.3286e-02, -2.8590e-02, -8.2489e-03],\n",
      "           [-1.9236e-02,  7.5253e-03,  6.5326e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 3.9438e-02, -1.0786e-02,  3.8032e-02],\n",
      "           [-5.0933e-03,  1.0574e-02,  8.0918e-03],\n",
      "           [ 8.3933e-03, -9.5769e-03, -1.8940e-02]],\n",
      "\n",
      "          [[-3.4365e-02, -1.2275e-02,  2.0585e-02],\n",
      "           [-1.3207e-02, -2.7441e-02,  1.8715e-02],\n",
      "           [ 2.7893e-03, -1.8747e-02, -2.5966e-02]],\n",
      "\n",
      "          [[-3.0413e-02, -2.4623e-02, -4.1773e-02],\n",
      "           [-2.1884e-02, -3.3398e-03, -1.4796e-02],\n",
      "           [ 3.7487e-02, -1.9449e-02, -4.3113e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.0701e-02, -4.8716e-02, -3.8588e-02],\n",
      "           [-2.9679e-02, -9.3795e-04, -1.4571e-02],\n",
      "           [-3.5066e-02, -3.6668e-02, -3.4133e-02]],\n",
      "\n",
      "          [[-1.8011e-02, -1.7332e-02, -6.3134e-03],\n",
      "           [ 7.6462e-03, -3.9567e-02, -3.0126e-02],\n",
      "           [-1.9827e-02, -2.5400e-02, -1.9863e-03]],\n",
      "\n",
      "          [[-1.5718e-02,  2.8899e-02,  2.8135e-02],\n",
      "           [-1.2603e-02,  3.4197e-02,  4.1797e-02],\n",
      "           [ 1.5070e-02,  4.0236e-02,  3.1446e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.2490e-03, -5.8645e-04, -3.2381e-02],\n",
      "           [-7.5268e-03,  2.4091e-02, -2.9659e-02],\n",
      "           [ 5.6905e-02, -1.0068e-02, -3.0347e-02]],\n",
      "\n",
      "          [[-2.4936e-02, -6.9645e-03, -3.9265e-02],\n",
      "           [-2.6659e-02,  3.0890e-03,  7.3042e-03],\n",
      "           [ 4.7016e-02, -7.2642e-03, -3.4066e-02]],\n",
      "\n",
      "          [[-7.1123e-04, -1.7593e-02,  2.8116e-02],\n",
      "           [-2.0020e-02,  8.9201e-03,  1.6843e-02],\n",
      "           [ 4.4845e-02, -8.8237e-03, -1.6420e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.7876e-02, -4.0987e-02, -5.7445e-02],\n",
      "           [ 6.3212e-03,  5.2810e-03,  4.3784e-03],\n",
      "           [ 4.9989e-03, -5.9635e-03,  1.3497e-02]],\n",
      "\n",
      "          [[ 1.8584e-02, -1.5549e-02, -1.2919e-02],\n",
      "           [-4.5283e-03,  2.0816e-02, -2.9202e-02],\n",
      "           [ 4.1092e-02, -3.7137e-03, -8.6185e-03]],\n",
      "\n",
      "          [[-1.2164e-02, -6.2593e-03, -2.4645e-02],\n",
      "           [ 3.2972e-02, -9.6681e-03,  2.9074e-02],\n",
      "           [-2.1982e-03,  2.0013e-02,  6.7829e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.0269e-02, -1.2072e-02, -4.8408e-02],\n",
      "           [ 1.8915e-03,  7.9433e-03, -2.3425e-02],\n",
      "           [-3.5750e-03,  3.5160e-03, -6.8500e-03]],\n",
      "\n",
      "          [[ 3.0139e-02,  1.6284e-02, -1.3573e-02],\n",
      "           [ 3.5203e-02, -1.2688e-02,  1.2379e-02],\n",
      "           [ 1.6506e-02,  8.7385e-03, -2.4156e-02]],\n",
      "\n",
      "          [[-4.1860e-02, -3.7071e-02,  1.5012e-02],\n",
      "           [ 9.6336e-03, -2.9108e-02, -1.3422e-02],\n",
      "           [-3.3276e-03,  1.1951e-02, -2.5037e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.7119e-02,  7.7846e-03,  3.1463e-02],\n",
      "           [ 1.2343e-02, -2.2391e-02,  1.6498e-02],\n",
      "           [ 1.8647e-02,  2.4122e-02, -9.8672e-03]],\n",
      "\n",
      "          [[ 1.5009e-02,  3.2158e-02,  2.1005e-02],\n",
      "           [ 2.7238e-02,  7.2201e-03, -5.6256e-03],\n",
      "           [-1.7836e-02, -1.7704e-02, -7.1684e-03]],\n",
      "\n",
      "          [[-2.7497e-02, -7.8593e-03, -2.7834e-02],\n",
      "           [-2.1410e-02, -4.0388e-03,  4.3621e-03],\n",
      "           [ 2.3856e-02,  1.4308e-02,  2.1993e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.9665e-03,  1.2355e-02,  2.7337e-02],\n",
      "           [-5.9412e-03, -4.6357e-04,  1.9090e-02],\n",
      "           [-4.5632e-03,  1.6009e-02, -2.4050e-02]],\n",
      "\n",
      "          [[-2.2729e-02,  1.6847e-03, -2.7971e-02],\n",
      "           [-2.2645e-02,  1.6123e-02,  1.3896e-02],\n",
      "           [-2.8086e-02, -3.0378e-02, -2.6822e-02]],\n",
      "\n",
      "          [[ 3.3953e-02, -2.5060e-02, -2.7739e-02],\n",
      "           [ 9.5695e-03,  2.6836e-02,  1.5541e-02],\n",
      "           [-4.6093e-03, -1.7232e-02,  6.8560e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.1587e-02, -1.3038e-02,  1.4021e-02],\n",
      "           [ 6.2300e-03, -3.3083e-02,  1.7622e-02],\n",
      "           [ 5.5772e-03, -7.8395e-03, -3.4100e-02]],\n",
      "\n",
      "          [[-2.1821e-02, -1.1594e-03, -3.2655e-02],\n",
      "           [-1.6580e-03, -2.3343e-02, -1.6105e-02],\n",
      "           [-8.9558e-03, -1.9472e-02,  1.7458e-02]],\n",
      "\n",
      "          [[-3.5023e-02, -3.1845e-02, -1.0307e-02],\n",
      "           [-2.5881e-02, -1.7307e-03, -2.5325e-02],\n",
      "           [ 2.2518e-02, -3.1018e-02, -2.9098e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 6.4626e-03, -3.3486e-02, -3.8323e-02],\n",
      "           [ 2.4902e-02,  1.9639e-02,  1.4892e-02],\n",
      "           [ 2.9693e-02,  2.7993e-02, -2.3208e-03]],\n",
      "\n",
      "          [[ 2.3644e-02, -1.1936e-02, -2.5687e-02],\n",
      "           [-1.8850e-02, -1.9599e-02, -3.1556e-02],\n",
      "           [ 1.4891e-03, -3.3324e-02, -8.9199e-03]],\n",
      "\n",
      "          [[ 2.6292e-02, -1.3615e-03, -1.8162e-02],\n",
      "           [-9.1667e-04, -2.5481e-02, -1.7157e-02],\n",
      "           [-2.0804e-02, -2.3569e-02, -2.3818e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.1294e-02, -2.9714e-02, -2.1587e-02],\n",
      "           [-3.4635e-02, -5.7845e-03, -4.5093e-02],\n",
      "           [-1.5925e-02, -1.5133e-02, -2.0739e-02]],\n",
      "\n",
      "          [[ 8.8699e-03, -2.2729e-03,  9.2577e-03],\n",
      "           [ 2.4646e-02, -2.4796e-02,  1.1510e-02],\n",
      "           [-3.2607e-02, -3.9442e-02, -2.2301e-02]],\n",
      "\n",
      "          [[ 1.3761e-02, -3.6926e-02, -2.5371e-02],\n",
      "           [-3.5042e-02, -1.3168e-02, -2.4957e-02],\n",
      "           [-3.1317e-02, -2.3233e-02, -4.1636e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.5726e-02, -1.3805e-02, -1.1357e-02],\n",
      "           [ 2.6805e-02,  2.4993e-02, -1.8350e-02],\n",
      "           [-1.8973e-02, -2.0566e-03, -1.4127e-02]],\n",
      "\n",
      "          [[-1.2231e-02, -2.4490e-02, -1.6817e-04],\n",
      "           [ 2.5057e-03, -4.1985e-02,  2.6007e-02],\n",
      "           [ 1.2175e-02, -4.0844e-02,  2.1894e-02]],\n",
      "\n",
      "          [[ 9.1709e-03, -1.4529e-02,  1.2436e-02],\n",
      "           [-8.3324e-03, -1.6051e-02, -1.0254e-02],\n",
      "           [ 1.2423e-02, -1.9940e-03, -1.6507e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.4313e-02, -1.0264e-02, -8.1994e-03],\n",
      "           [-6.8681e-04, -1.7141e-02,  7.8986e-03],\n",
      "           [ 1.2207e-02, -1.7254e-02, -3.7889e-03]],\n",
      "\n",
      "          [[-3.2648e-02, -3.0725e-03,  3.0004e-03],\n",
      "           [ 1.6299e-02, -7.8665e-03, -3.4357e-02],\n",
      "           [ 3.3764e-02,  2.6312e-02,  2.4421e-02]],\n",
      "\n",
      "          [[ 2.5769e-03,  4.4057e-04,  2.1336e-02],\n",
      "           [-2.1188e-02,  6.8548e-04, -3.4243e-02],\n",
      "           [ 1.6451e-02,  2.1928e-02,  1.2239e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.8142e-02, -1.3291e-02, -1.0390e-02],\n",
      "           [ 1.7448e-02, -2.9754e-02, -2.1197e-02],\n",
      "           [-1.1185e-03,  1.0818e-02, -2.6176e-02]],\n",
      "\n",
      "          [[-9.5492e-03, -1.3685e-02,  2.4522e-02],\n",
      "           [-3.5166e-02,  3.0015e-02,  1.4541e-02],\n",
      "           [-2.7694e-02,  3.5640e-02,  1.0917e-02]],\n",
      "\n",
      "          [[-3.9182e-02,  1.3253e-02, -2.6674e-02],\n",
      "           [ 4.0979e-03, -1.1541e-02,  1.0062e-02],\n",
      "           [-2.2076e-02,  3.7742e-03,  1.2631e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.6945e-02,  7.2262e-03,  1.2464e-02],\n",
      "           [-1.2976e-02, -5.8849e-03, -4.2062e-03],\n",
      "           [-2.9403e-02, -8.5978e-03, -1.4186e-02]],\n",
      "\n",
      "          [[-1.3980e-02, -1.3955e-02, -2.0979e-02],\n",
      "           [-4.0921e-03,  3.2096e-02,  1.2239e-02],\n",
      "           [ 1.9711e-02,  2.0253e-02,  5.1490e-04]],\n",
      "\n",
      "          [[-1.1019e-02, -1.2250e-02,  1.1332e-02],\n",
      "           [ 1.5254e-02, -9.6230e-03, -1.2125e-02],\n",
      "           [ 2.5963e-02,  3.3580e-03,  7.8270e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.6889e-02, -3.6714e-02, -2.4101e-02],\n",
      "           [ 2.7488e-02, -1.3016e-02,  1.9478e-02],\n",
      "           [-2.4670e-02,  2.5731e-02, -2.8697e-02]],\n",
      "\n",
      "          [[-4.5126e-03,  1.9230e-02,  1.1151e-02],\n",
      "           [-8.7043e-03, -2.8182e-02, -2.7477e-02],\n",
      "           [-8.9119e-03,  2.0899e-02,  1.2088e-02]],\n",
      "\n",
      "          [[-1.0313e-03,  2.4608e-02, -2.9032e-02],\n",
      "           [ 1.8776e-02, -2.5621e-02,  3.1030e-02],\n",
      "           [-1.7560e-02,  2.3887e-02, -1.3971e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.1689e-03,  2.5620e-02, -3.1428e-02],\n",
      "           [ 3.9230e-02, -7.4990e-03, -6.9355e-03],\n",
      "           [-4.8528e-03, -2.3356e-02,  1.7352e-02]],\n",
      "\n",
      "          [[ 2.6528e-02,  3.1027e-02,  3.1129e-02],\n",
      "           [ 3.2745e-02, -1.5905e-02,  1.5424e-02],\n",
      "           [ 4.4509e-02, -4.6984e-03, -9.9941e-03]],\n",
      "\n",
      "          [[ 7.2081e-03, -4.3404e-03,  8.9951e-03],\n",
      "           [ 1.7299e-02,  4.4147e-02,  4.4119e-02],\n",
      "           [ 3.7965e-03, -1.7898e-02,  2.7522e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.8091e-02, -4.5279e-04, -1.0404e-02],\n",
      "           [-9.0523e-03, -1.4463e-02, -2.5217e-02],\n",
      "           [-3.3966e-02, -4.8075e-03, -4.4197e-02]],\n",
      "\n",
      "          [[ 1.3149e-02, -2.4852e-02, -5.3405e-03],\n",
      "           [-1.7014e-02, -3.7665e-02, -2.9339e-02],\n",
      "           [-3.9806e-02,  9.5549e-03, -8.9269e-03]],\n",
      "\n",
      "          [[-3.8192e-02,  2.0273e-02, -4.5676e-02],\n",
      "           [-4.0989e-02, -4.3109e-02,  1.0421e-04],\n",
      "           [ 1.5129e-02,  2.5145e-03,  5.9658e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 9.8942e-03,  1.4012e-02,  1.4908e-02],\n",
      "           [-2.1480e-02,  3.8654e-03,  3.0046e-03],\n",
      "           [ 3.7668e-02,  1.3701e-03, -1.1686e-02]],\n",
      "\n",
      "          [[ 9.8842e-03,  8.8364e-03,  7.1688e-03],\n",
      "           [-4.3661e-03, -1.0004e-02, -2.6878e-02],\n",
      "           [ 1.3724e-02,  3.2376e-03,  1.3294e-02]],\n",
      "\n",
      "          [[ 1.6237e-02,  1.2033e-02, -2.3554e-02],\n",
      "           [-3.3378e-02,  1.5952e-03, -7.5842e-03],\n",
      "           [ 2.6341e-02,  1.3686e-02,  2.1157e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 8.7074e-03,  2.9274e-02, -8.2699e-03],\n",
      "           [-1.2787e-02,  2.1710e-02, -2.0160e-02],\n",
      "           [-3.0873e-02,  3.0478e-02, -1.7736e-02]],\n",
      "\n",
      "          [[-1.7403e-02, -1.5826e-03,  1.6049e-02],\n",
      "           [ 3.5339e-03, -1.2823e-02, -1.4885e-02],\n",
      "           [ 1.6124e-02, -1.1971e-03, -2.1574e-02]],\n",
      "\n",
      "          [[-3.9007e-03,  1.8344e-02,  1.9762e-02],\n",
      "           [-2.4605e-02,  3.2953e-03, -2.3041e-02],\n",
      "           [ 2.2547e-02,  2.2495e-03, -2.0192e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.3881e-03,  3.3688e-03,  1.6060e-02],\n",
      "           [ 4.8411e-03, -1.7402e-02,  2.0910e-02],\n",
      "           [-2.6104e-02, -2.8278e-02, -1.8123e-02]],\n",
      "\n",
      "          [[ 7.5938e-03,  1.1793e-02, -8.0542e-03],\n",
      "           [ 2.0797e-02,  2.1300e-02,  3.4954e-02],\n",
      "           [ 3.0993e-02, -5.2331e-04, -1.0894e-02]],\n",
      "\n",
      "          [[-5.0414e-03, -5.4878e-03, -9.6672e-03],\n",
      "           [ 2.8480e-02, -3.7939e-04, -5.5672e-03],\n",
      "           [ 1.6554e-02,  1.5652e-02, -3.6611e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-6.1587e-03, -2.6096e-02, -1.6216e-02],\n",
      "           [-5.0761e-03, -1.2245e-02, -6.5427e-03],\n",
      "           [ 6.7431e-03, -2.6170e-02, -2.4850e-03]],\n",
      "\n",
      "          [[ 2.0392e-02, -2.6870e-03, -2.2522e-02],\n",
      "           [ 1.7884e-02,  1.3940e-02,  1.1850e-02],\n",
      "           [-1.8920e-02, -2.2574e-02,  2.4152e-02]],\n",
      "\n",
      "          [[ 3.3970e-03, -1.8461e-03, -2.8911e-02],\n",
      "           [ 5.4251e-03,  6.7957e-03,  4.8233e-03],\n",
      "           [ 5.6972e-03, -2.9754e-02, -3.0701e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.4432e-03,  3.2415e-02,  3.7911e-02],\n",
      "           [ 3.4453e-02,  3.7924e-03,  1.0402e-02],\n",
      "           [ 2.5336e-02,  1.0694e-02, -1.0854e-02]],\n",
      "\n",
      "          [[-2.5646e-02,  3.6509e-02,  4.2904e-02],\n",
      "           [ 4.2884e-02, -1.2692e-02,  4.4230e-02],\n",
      "           [ 1.4380e-02,  1.7237e-03,  5.2936e-02]],\n",
      "\n",
      "          [[ 2.2243e-02, -9.9559e-03,  1.1158e-02],\n",
      "           [-2.8413e-03,  2.5398e-02,  1.8430e-02],\n",
      "           [ 2.2341e-02,  2.1108e-03,  1.2170e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.0429e-02, -2.9422e-02, -3.9221e-02],\n",
      "           [-1.3459e-02, -2.1205e-02,  2.0967e-02],\n",
      "           [-5.4247e-03, -1.0194e-03, -3.6711e-02]],\n",
      "\n",
      "          [[-2.1925e-02, -2.3318e-02,  1.8692e-02],\n",
      "           [-3.4334e-02,  9.9059e-03, -2.0640e-02],\n",
      "           [-9.0671e-03,  2.8369e-03, -3.0312e-02]],\n",
      "\n",
      "          [[-9.7915e-04, -3.6688e-02,  6.5014e-03],\n",
      "           [ 3.5805e-03, -6.9202e-03, -3.3192e-02],\n",
      "           [ 1.8228e-02,  1.5691e-02,  7.8560e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.8266e-02,  2.8710e-02,  6.4476e-03],\n",
      "           [-1.6694e-02,  1.7850e-03,  1.7980e-02],\n",
      "           [ 2.8965e-02, -4.2540e-03, -1.7478e-02]],\n",
      "\n",
      "          [[-1.6018e-02, -2.7746e-02,  1.3060e-02],\n",
      "           [ 1.4108e-02, -3.1564e-02,  1.3242e-02],\n",
      "           [ 2.1913e-02, -4.9030e-03, -1.7486e-02]],\n",
      "\n",
      "          [[-3.9998e-02,  8.1707e-03, -2.9559e-02],\n",
      "           [-3.3737e-02,  2.8136e-02,  2.4388e-02],\n",
      "           [-3.1278e-02,  4.5073e-03,  2.1252e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.2532e-02,  1.1572e-02,  8.2490e-03],\n",
      "           [-1.9176e-02,  1.7493e-02,  4.0970e-03],\n",
      "           [ 6.7062e-03, -1.8893e-02,  2.4304e-02]],\n",
      "\n",
      "          [[-1.1359e-02,  2.2140e-02,  3.1451e-02],\n",
      "           [-2.5321e-02, -1.4167e-02,  1.2106e-02],\n",
      "           [ 8.4496e-03, -2.4715e-02, -1.0843e-02]],\n",
      "\n",
      "          [[ 2.5332e-02, -7.8372e-03, -3.6269e-02],\n",
      "           [-1.1123e-02,  5.1722e-03,  1.2746e-02],\n",
      "           [-2.2293e-02, -3.3497e-02, -1.0172e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.5786e-02, -3.1579e-02, -4.2886e-02],\n",
      "           [-2.4543e-02,  1.2652e-02,  1.4428e-02],\n",
      "           [-3.7820e-02, -2.4041e-02, -3.4897e-03]],\n",
      "\n",
      "          [[ 7.0313e-03,  2.7877e-02,  5.4275e-03],\n",
      "           [-2.1171e-02,  2.9932e-02, -2.7193e-02],\n",
      "           [-5.2577e-03, -1.8350e-02, -1.5658e-02]],\n",
      "\n",
      "          [[-1.8209e-02,  2.8918e-02,  1.3837e-03],\n",
      "           [-1.9403e-02,  2.2631e-02, -4.5840e-03],\n",
      "           [-1.9728e-02,  1.7977e-02,  5.9349e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0152e-02,  1.3815e-02, -2.8330e-02],\n",
      "           [-3.0709e-02,  1.4877e-02,  7.8405e-03],\n",
      "           [-3.5495e-02, -3.4053e-02, -2.5858e-02]],\n",
      "\n",
      "          [[ 2.1474e-02,  6.1995e-03, -8.2543e-03],\n",
      "           [-1.5964e-02,  3.3158e-02,  2.2335e-02],\n",
      "           [-2.9115e-03, -1.0991e-02, -4.6758e-03]],\n",
      "\n",
      "          [[ 7.6582e-03,  3.0118e-02, -1.5371e-02],\n",
      "           [ 4.8148e-03, -2.5309e-02,  8.3055e-03],\n",
      "           [-4.0169e-02, -1.9945e-02, -2.8265e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.0348e-02, -7.2996e-04,  1.7036e-02],\n",
      "           [ 2.1974e-02, -8.4335e-03, -2.4943e-02],\n",
      "           [ 4.8977e-03, -2.6094e-02, -3.9419e-02]],\n",
      "\n",
      "          [[ 3.2169e-02,  3.0956e-03,  1.1032e-03],\n",
      "           [ 2.9520e-02, -2.0095e-02,  1.6846e-03],\n",
      "           [-4.1846e-03,  3.0374e-02, -3.9204e-03]],\n",
      "\n",
      "          [[-1.4674e-02,  1.6285e-02, -7.4610e-03],\n",
      "           [ 6.9336e-03,  3.1654e-02, -3.2298e-03],\n",
      "           [ 1.4863e-02, -3.3212e-03, -8.2766e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 5.6226e-03, -2.1701e-03,  2.7514e-02],\n",
      "           [ 2.4678e-02,  2.1853e-02, -1.9688e-02],\n",
      "           [ 3.2745e-02, -2.0607e-02,  1.2089e-02]],\n",
      "\n",
      "          [[ 2.8944e-03, -7.1843e-03, -7.9020e-03],\n",
      "           [ 3.6301e-02, -2.4882e-03,  1.7571e-02],\n",
      "           [ 1.2086e-02, -2.8212e-02,  1.6027e-02]],\n",
      "\n",
      "          [[-2.5473e-02,  2.3519e-02, -1.9699e-02],\n",
      "           [ 1.6962e-02, -3.0719e-02,  2.3017e-02],\n",
      "           [ 1.4621e-02, -3.6802e-03,  1.4066e-02]]]]], device='cuda:0')), ('module.down_layers.1.2.conv2.conv.weight', tensor([[[[[ 5.9197e-03,  5.0707e-03,  1.1139e-02],\n",
      "           [-5.6880e-03,  2.5390e-02,  2.6176e-02],\n",
      "           [-1.8420e-02, -3.9758e-03,  6.6442e-03]],\n",
      "\n",
      "          [[-1.2084e-02, -3.4524e-03, -1.4912e-02],\n",
      "           [ 1.3473e-02,  2.8028e-02,  4.4317e-02],\n",
      "           [ 1.1168e-02,  2.6624e-02,  3.1888e-03]],\n",
      "\n",
      "          [[ 2.9666e-02,  3.6495e-02, -6.9207e-03],\n",
      "           [ 3.1787e-02,  3.5949e-02,  7.2665e-03],\n",
      "           [ 1.9483e-02,  2.4857e-02, -1.5909e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2893e-02,  1.2622e-02, -2.9047e-02],\n",
      "           [-2.0148e-02,  2.1154e-03,  7.5199e-03],\n",
      "           [-3.4824e-03, -2.5830e-02,  1.1490e-02]],\n",
      "\n",
      "          [[ 3.3667e-02, -3.4677e-02,  2.4308e-02],\n",
      "           [-2.9689e-02,  9.1247e-03,  1.1270e-04],\n",
      "           [ 1.7030e-02,  2.4057e-02, -1.0209e-02]],\n",
      "\n",
      "          [[ 4.2236e-02,  1.5320e-02,  2.8856e-02],\n",
      "           [-4.3858e-03, -2.5230e-02,  1.3039e-02],\n",
      "           [ 3.5222e-02,  1.6453e-02,  1.6946e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.0689e-02, -2.0846e-02, -1.9915e-02],\n",
      "           [ 1.9580e-02, -2.0151e-02,  4.8452e-03],\n",
      "           [-1.7184e-02, -1.6495e-02,  1.4312e-03]],\n",
      "\n",
      "          [[-8.2852e-03,  3.2377e-02, -1.3005e-02],\n",
      "           [-1.7578e-02,  2.5633e-02, -1.5865e-02],\n",
      "           [ 2.4794e-02, -1.6017e-02,  3.2213e-02]],\n",
      "\n",
      "          [[ 2.4518e-02, -9.2754e-03,  3.2242e-02],\n",
      "           [-1.3239e-02, -9.2459e-04, -2.2883e-02],\n",
      "           [ 1.1029e-02,  2.3365e-02,  1.4742e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-8.5920e-03, -2.2729e-02,  1.0584e-02],\n",
      "           [-4.0459e-02, -1.4302e-02, -5.2299e-04],\n",
      "           [-1.4072e-02, -2.6079e-03, -2.7763e-02]],\n",
      "\n",
      "          [[-3.8916e-02, -3.8325e-02,  8.6907e-03],\n",
      "           [ 1.0914e-02, -1.9830e-03, -1.6167e-02],\n",
      "           [ 1.2091e-02, -1.0592e-02,  1.9019e-02]],\n",
      "\n",
      "          [[-6.4451e-03, -4.3545e-02, -2.1089e-02],\n",
      "           [-4.2926e-02, -6.5517e-03, -7.2188e-03],\n",
      "           [ 7.2193e-03, -4.5093e-02, -3.7247e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.5187e-03,  1.7577e-02,  2.3778e-02],\n",
      "           [-3.5724e-02, -1.7475e-02, -2.5170e-02],\n",
      "           [ 1.8983e-02,  1.7452e-02, -1.9871e-02]],\n",
      "\n",
      "          [[-5.5888e-03, -4.9269e-02, -1.9773e-02],\n",
      "           [ 1.9858e-02, -2.7305e-02, -2.3941e-02],\n",
      "           [-2.0358e-02, -5.0959e-02, -4.3993e-02]],\n",
      "\n",
      "          [[ 2.1693e-02, -1.5049e-02,  9.2352e-03],\n",
      "           [-4.6665e-03, -5.1325e-02, -3.8815e-02],\n",
      "           [-1.1614e-02, -1.1609e-02, -1.9224e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2671e-02,  4.9565e-04,  3.1822e-02],\n",
      "           [-4.0374e-02, -3.3304e-02,  6.0587e-03],\n",
      "           [-1.0940e-02,  9.9052e-03,  2.0454e-02]],\n",
      "\n",
      "          [[-3.7876e-03,  2.9468e-03,  2.2533e-02],\n",
      "           [-4.1115e-02,  1.9177e-02, -2.6325e-02],\n",
      "           [-3.1352e-02, -1.4388e-02,  2.0933e-02]],\n",
      "\n",
      "          [[-1.5980e-02, -1.0663e-02, -1.0955e-02],\n",
      "           [ 1.1932e-02, -5.8183e-03, -3.4311e-03],\n",
      "           [-1.9367e-02, -3.4622e-02,  2.1105e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.0715e-02,  1.7324e-02,  1.7061e-02],\n",
      "           [ 1.6245e-02,  2.3012e-02,  2.5899e-02],\n",
      "           [-3.1502e-02,  3.3917e-02,  3.3240e-02]],\n",
      "\n",
      "          [[ 2.7739e-02, -1.2698e-02,  2.9569e-02],\n",
      "           [ 1.2995e-02,  8.8622e-03,  3.2216e-02],\n",
      "           [-2.0057e-03,  3.1403e-02,  1.2518e-02]],\n",
      "\n",
      "          [[ 1.1543e-02, -2.6192e-03,  3.7793e-02],\n",
      "           [ 3.6683e-02,  1.0521e-02,  2.4543e-02],\n",
      "           [ 3.5009e-02,  4.2939e-02,  1.1486e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.9302e-02, -2.2154e-02, -8.4507e-03],\n",
      "           [ 2.3099e-02, -1.0012e-02,  1.4527e-02],\n",
      "           [ 9.7863e-04, -1.0687e-02,  2.1925e-03]],\n",
      "\n",
      "          [[ 7.8882e-03,  2.1725e-02, -2.7151e-03],\n",
      "           [-2.2327e-02,  3.8434e-02,  5.5412e-03],\n",
      "           [ 1.9936e-02,  1.1410e-02,  7.0263e-03]],\n",
      "\n",
      "          [[ 3.9972e-02, -1.4376e-02,  3.7643e-02],\n",
      "           [-7.8582e-03, -1.9554e-02,  2.7491e-02],\n",
      "           [ 8.2222e-03, -7.7840e-03,  8.8171e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.8273e-03, -1.0588e-02, -2.8150e-02],\n",
      "           [ 7.0191e-03,  2.0474e-02,  3.0969e-02],\n",
      "           [-3.1173e-02, -2.0261e-02,  1.9406e-02]],\n",
      "\n",
      "          [[ 1.2830e-02,  2.1851e-02,  1.5013e-02],\n",
      "           [ 2.7287e-02,  1.3080e-02, -5.3703e-03],\n",
      "           [ 1.7156e-02, -2.8565e-03, -2.4552e-02]],\n",
      "\n",
      "          [[ 3.9707e-03, -4.9854e-03,  1.6903e-02],\n",
      "           [-2.6286e-03,  1.0956e-02, -1.1604e-02],\n",
      "           [ 1.8126e-02, -4.3274e-03, -1.8679e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-4.5216e-03,  7.5754e-03,  5.9953e-03],\n",
      "           [ 1.8852e-02, -3.2873e-02, -2.3217e-02],\n",
      "           [ 9.7046e-03,  1.9491e-02,  8.1785e-03]],\n",
      "\n",
      "          [[-4.4413e-03,  3.1762e-02,  2.9115e-02],\n",
      "           [-2.6123e-02, -1.9292e-02,  1.6447e-02],\n",
      "           [ 1.4751e-03, -2.9108e-02, -1.2674e-02]],\n",
      "\n",
      "          [[ 2.7976e-02,  1.4118e-02, -3.2169e-03],\n",
      "           [-1.2378e-02, -1.2481e-02,  6.3484e-03],\n",
      "           [-1.5161e-02,  2.4589e-03, -3.3682e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.3817e-02,  1.7892e-02, -1.8657e-02],\n",
      "           [-2.6285e-02, -6.3341e-04,  8.1642e-03],\n",
      "           [-2.0489e-04,  1.0690e-02,  1.2384e-02]],\n",
      "\n",
      "          [[-8.0813e-03, -7.1651e-03, -2.1290e-02],\n",
      "           [-1.4125e-02, -2.4343e-02,  1.9702e-02],\n",
      "           [ 9.5222e-03, -3.7903e-02,  1.2204e-02]],\n",
      "\n",
      "          [[-1.2154e-02, -2.2330e-02,  2.3348e-02],\n",
      "           [ 1.6244e-02,  2.1139e-02, -3.1548e-03],\n",
      "           [-2.1785e-02,  2.4844e-02,  2.2124e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.0995e-03,  2.0060e-02,  3.2455e-02],\n",
      "           [ 1.4325e-02,  2.1787e-02, -3.5652e-03],\n",
      "           [-2.9089e-02, -3.1647e-02,  2.2410e-02]],\n",
      "\n",
      "          [[-1.2996e-02,  2.3497e-02,  3.6258e-03],\n",
      "           [ 1.8128e-02, -3.3069e-02,  2.2297e-02],\n",
      "           [ 7.3853e-03, -1.9094e-02, -3.2161e-02]],\n",
      "\n",
      "          [[-1.9278e-02,  8.2692e-04, -3.3780e-02],\n",
      "           [ 1.4553e-02,  4.7011e-03, -3.3102e-02],\n",
      "           [-2.6996e-03, -2.0158e-02,  4.1958e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.8500e-03,  1.4053e-02, -6.5443e-03],\n",
      "           [-2.0561e-02,  2.7212e-02,  1.0471e-02],\n",
      "           [ 8.3049e-03,  2.2781e-02, -2.9785e-02]],\n",
      "\n",
      "          [[ 1.2469e-02, -1.0800e-02,  4.0039e-03],\n",
      "           [-1.3033e-02,  1.1783e-02,  1.8099e-02],\n",
      "           [ 4.5637e-03,  1.6514e-02, -3.9268e-03]],\n",
      "\n",
      "          [[ 3.5918e-04, -1.1946e-02,  3.2794e-02],\n",
      "           [ 3.2975e-02,  7.9017e-03,  4.5251e-02],\n",
      "           [-8.4867e-03,  1.3940e-02,  2.2697e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.5557e-03, -2.9212e-03,  5.1380e-03],\n",
      "           [ 5.0853e-03, -3.8795e-02, -1.1229e-02],\n",
      "           [ 5.1816e-03,  1.5277e-02,  2.6132e-02]],\n",
      "\n",
      "          [[ 3.6922e-03, -5.7549e-03, -2.2613e-02],\n",
      "           [-1.5241e-02,  2.7508e-03, -3.9720e-02],\n",
      "           [-1.5021e-02,  1.7795e-02, -2.0092e-02]],\n",
      "\n",
      "          [[ 3.3322e-03, -1.5785e-02, -1.6469e-02],\n",
      "           [-3.8963e-02, -2.7851e-02, -2.3228e-02],\n",
      "           [-1.4420e-02, -2.6538e-02, -1.2356e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.2589e-02, -6.3628e-03,  6.2727e-03],\n",
      "           [ 1.3465e-02, -9.4945e-03,  2.5673e-02],\n",
      "           [-3.1783e-02, -2.7347e-02, -3.6591e-02]],\n",
      "\n",
      "          [[ 1.9615e-02, -3.1590e-02,  1.9593e-02],\n",
      "           [ 3.5740e-03,  7.1300e-03,  3.6191e-03],\n",
      "           [-3.1450e-02, -2.1797e-02, -3.3824e-02]],\n",
      "\n",
      "          [[ 1.7436e-02, -1.0945e-02, -1.6655e-02],\n",
      "           [ 2.6382e-02,  1.8898e-02, -2.0553e-02],\n",
      "           [-1.2074e-02,  2.0945e-02, -2.7612e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.1940e-02, -2.5759e-02, -8.6902e-03],\n",
      "           [-7.8575e-03,  1.9454e-02, -1.8359e-02],\n",
      "           [-8.6664e-03,  1.9996e-02,  3.0831e-02]],\n",
      "\n",
      "          [[-3.5243e-02,  1.3391e-02,  3.3027e-03],\n",
      "           [ 6.1595e-03, -9.6238e-03,  3.0195e-02],\n",
      "           [ 3.0125e-02,  1.2639e-02, -3.1920e-02]],\n",
      "\n",
      "          [[-1.0258e-03, -1.4597e-02,  1.1904e-02],\n",
      "           [ 1.0999e-02,  1.5003e-02, -2.5577e-02],\n",
      "           [-7.7481e-03,  6.8564e-03,  1.3346e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.2933e-02, -9.5090e-03,  2.5966e-03],\n",
      "           [ 1.5134e-04, -1.8742e-02, -2.2648e-02],\n",
      "           [-1.1888e-02,  2.5851e-02, -2.6012e-02]],\n",
      "\n",
      "          [[-3.1831e-02, -9.0583e-03,  4.6618e-03],\n",
      "           [-8.2869e-03,  1.9128e-02,  2.0777e-02],\n",
      "           [ 2.3930e-02, -1.4062e-02,  3.1027e-02]],\n",
      "\n",
      "          [[-5.1194e-03, -1.0629e-02, -1.0541e-02],\n",
      "           [ 7.2050e-03,  2.2281e-02, -2.5132e-02],\n",
      "           [ 3.1903e-02,  4.7311e-03,  1.2786e-02]]],\n",
      "\n",
      "\n",
      "         [[[-8.5777e-04, -6.7698e-03, -1.5168e-02],\n",
      "           [ 1.6361e-02, -9.7245e-03, -2.6374e-02],\n",
      "           [-1.9994e-02,  2.6171e-02, -6.2221e-03]],\n",
      "\n",
      "          [[ 1.6178e-02,  2.4224e-02,  9.2857e-03],\n",
      "           [-1.9270e-02, -8.3298e-03, -2.6628e-02],\n",
      "           [ 3.2607e-03, -1.3949e-02, -2.7456e-03]],\n",
      "\n",
      "          [[ 4.6578e-03, -9.5034e-04, -2.2423e-02],\n",
      "           [-2.9371e-03,  3.3857e-02, -1.4237e-02],\n",
      "           [ 8.0946e-03, -1.7615e-02,  9.8720e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.1298e-02, -6.9991e-03,  1.8218e-02],\n",
      "           [-8.9167e-03, -2.1653e-02,  2.0438e-02],\n",
      "           [ 2.0744e-02, -9.3433e-03, -1.7739e-02]],\n",
      "\n",
      "          [[-1.0889e-02, -1.7435e-02, -2.2724e-03],\n",
      "           [ 2.3145e-02,  2.0323e-02,  6.7939e-04],\n",
      "           [ 3.6262e-02, -1.4715e-02, -1.8861e-02]],\n",
      "\n",
      "          [[ 2.4624e-02, -1.6184e-02, -2.5381e-03],\n",
      "           [-7.1512e-03, -1.0704e-02,  2.2315e-02],\n",
      "           [ 9.7923e-03,  3.4147e-02,  3.8153e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.8958e-02, -1.1145e-02,  3.1461e-02],\n",
      "           [ 2.2219e-02,  1.5459e-02,  4.2985e-02],\n",
      "           [ 1.0028e-02,  3.2156e-02,  1.4947e-02]],\n",
      "\n",
      "          [[-1.1363e-02,  3.9764e-02,  2.2537e-02],\n",
      "           [ 3.8971e-02, -1.6537e-02, -2.2294e-02],\n",
      "           [ 1.2280e-02,  7.2800e-03,  2.5115e-02]],\n",
      "\n",
      "          [[-1.9355e-02,  2.3623e-02, -1.5546e-02],\n",
      "           [-1.4177e-02,  2.7621e-02,  3.3429e-02],\n",
      "           [-2.0897e-02, -1.1568e-03,  2.1038e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.3750e-02,  1.2237e-02,  1.7240e-02],\n",
      "           [-1.1176e-02, -1.8661e-02, -2.9907e-02],\n",
      "           [-4.1767e-02,  1.4442e-02, -9.2398e-03]],\n",
      "\n",
      "          [[-3.7943e-02,  2.4520e-03, -1.3568e-02],\n",
      "           [-5.4997e-04, -4.1679e-02, -3.0162e-02],\n",
      "           [-1.7155e-02, -2.5916e-02, -6.0301e-03]],\n",
      "\n",
      "          [[-8.1343e-03, -2.0279e-02,  1.1233e-02],\n",
      "           [-3.1094e-02,  1.2088e-02, -1.2174e-02],\n",
      "           [-3.2564e-02, -1.9195e-02, -2.2267e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.8943e-02, -8.2423e-03,  3.3180e-03],\n",
      "           [ 4.0846e-03,  1.8904e-02,  1.8371e-02],\n",
      "           [-2.1655e-02,  2.0253e-02, -2.4608e-02]],\n",
      "\n",
      "          [[-4.4241e-03,  2.2817e-02, -1.7827e-02],\n",
      "           [ 4.1623e-02, -1.8519e-02,  6.0186e-03],\n",
      "           [ 1.9064e-02, -9.5671e-03, -1.6690e-02]],\n",
      "\n",
      "          [[ 4.2679e-02,  3.9681e-02,  3.8967e-02],\n",
      "           [-1.2767e-02,  3.0291e-02, -1.7023e-02],\n",
      "           [ 4.2264e-02, -9.5740e-03, -8.3086e-03]]],\n",
      "\n",
      "\n",
      "         [[[-7.9326e-03,  2.1675e-02, -1.4184e-02],\n",
      "           [ 2.2386e-02, -1.3619e-02,  1.2499e-03],\n",
      "           [ 2.4390e-02, -7.9248e-03,  1.9397e-02]],\n",
      "\n",
      "          [[ 4.7711e-02,  3.6088e-02, -3.6247e-03],\n",
      "           [-1.3885e-03,  3.1870e-02,  2.2745e-02],\n",
      "           [ 9.0957e-03,  2.8786e-02,  2.0350e-02]],\n",
      "\n",
      "          [[ 3.9318e-03,  1.8852e-02, -1.6329e-02],\n",
      "           [ 7.9741e-03,  1.2432e-02,  2.1843e-02],\n",
      "           [-8.6191e-03,  2.2764e-02,  2.3577e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4681e-02,  4.0054e-02,  2.5910e-02],\n",
      "           [ 5.3364e-03,  2.5020e-02,  1.1153e-02],\n",
      "           [-8.1504e-03, -2.4960e-02, -6.3533e-03]],\n",
      "\n",
      "          [[-1.4633e-02, -7.6115e-03, -1.9191e-02],\n",
      "           [-1.0819e-02,  3.1244e-02,  3.3870e-02],\n",
      "           [-1.7030e-02,  2.1360e-02, -9.6390e-03]],\n",
      "\n",
      "          [[ 4.1838e-02, -2.3640e-02, -1.3158e-02],\n",
      "           [ 4.4282e-02,  1.4972e-02,  2.3921e-02],\n",
      "           [-1.5537e-02,  3.0239e-02,  2.6004e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.2571e-02, -3.2341e-04,  3.0546e-02],\n",
      "           [ 5.9382e-03, -3.1991e-02,  4.5536e-03],\n",
      "           [-1.8932e-03, -1.7399e-02,  1.2619e-02]],\n",
      "\n",
      "          [[ 4.1725e-04,  1.1073e-02,  7.1592e-05],\n",
      "           [-3.0081e-02, -1.7774e-02,  2.2267e-02],\n",
      "           [ 1.8574e-02, -1.3409e-02,  2.7004e-02]],\n",
      "\n",
      "          [[ 7.9853e-03,  2.6980e-02,  2.6739e-02],\n",
      "           [ 2.3279e-02, -2.4098e-02, -2.2921e-03],\n",
      "           [ 1.8474e-02,  2.3056e-02, -1.3631e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.7229e-02, -2.7814e-03, -2.3009e-02],\n",
      "           [ 4.3379e-03, -3.0316e-02,  2.2256e-02],\n",
      "           [ 1.2184e-02,  3.4408e-02, -7.9425e-04]],\n",
      "\n",
      "          [[-2.3404e-02, -1.9299e-02,  1.9616e-02],\n",
      "           [-1.3676e-02, -3.2518e-02,  3.6742e-02],\n",
      "           [-3.2665e-02,  1.6631e-02,  3.4519e-02]],\n",
      "\n",
      "          [[-2.1173e-03, -1.7558e-02, -3.1300e-02],\n",
      "           [-3.3648e-02, -2.8214e-02,  5.2233e-03],\n",
      "           [-1.9328e-02, -2.1822e-02, -1.2144e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.8182e-02, -2.4861e-03,  3.0885e-03],\n",
      "           [ 1.2089e-02,  1.4437e-02,  8.9543e-03],\n",
      "           [ 7.7719e-03, -2.1637e-02,  1.6550e-03]],\n",
      "\n",
      "          [[ 1.6191e-02, -1.3142e-02, -1.1851e-02],\n",
      "           [ 2.0047e-03, -3.5090e-02, -1.2218e-02],\n",
      "           [-1.5449e-02,  4.2302e-03, -5.6024e-03]],\n",
      "\n",
      "          [[-3.6647e-02,  1.1670e-02,  1.1310e-02],\n",
      "           [-3.7222e-02, -1.8839e-02, -3.5896e-02],\n",
      "           [ 1.3098e-02, -3.8381e-02, -2.9786e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.0948e-02, -4.7205e-04,  1.4808e-02],\n",
      "           [-2.8986e-03,  2.6465e-02, -5.9743e-03],\n",
      "           [ 1.0694e-02, -1.5872e-03,  2.2341e-02]],\n",
      "\n",
      "          [[-1.1586e-02, -7.8817e-03,  3.2011e-02],\n",
      "           [-1.7988e-02,  2.1828e-02,  4.5841e-02],\n",
      "           [ 1.2806e-02,  3.2438e-02, -1.1407e-02]],\n",
      "\n",
      "          [[-3.9133e-02,  8.6948e-03,  1.7077e-02],\n",
      "           [ 1.7860e-02,  4.4828e-03,  1.9909e-02],\n",
      "           [-9.1423e-03, -2.1870e-02,  4.1641e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.4571e-03, -3.8217e-03, -6.4073e-03],\n",
      "           [ 4.6256e-03,  2.7174e-02, -2.2266e-02],\n",
      "           [ 9.9390e-03,  1.8890e-02, -1.3114e-03]],\n",
      "\n",
      "          [[-3.0197e-02,  7.0071e-03,  2.2409e-02],\n",
      "           [-1.4552e-02, -9.2655e-03,  3.9100e-02],\n",
      "           [-3.0173e-02,  2.4075e-02,  7.1082e-03]],\n",
      "\n",
      "          [[-2.5630e-02,  3.6927e-02,  1.2417e-02],\n",
      "           [ 1.9121e-02,  1.6127e-02, -1.5892e-02],\n",
      "           [ 3.5538e-02,  1.5921e-03,  3.9818e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.4357e-03, -5.3726e-03, -8.6893e-03],\n",
      "           [ 8.7408e-03,  3.5109e-03,  1.5477e-02],\n",
      "           [ 1.5413e-02,  1.9710e-02,  3.4359e-02]],\n",
      "\n",
      "          [[-3.4297e-02,  1.6691e-02,  2.2481e-02],\n",
      "           [ 2.2845e-03,  9.7664e-04,  3.4008e-02],\n",
      "           [-2.7679e-02,  1.8646e-02,  3.7154e-02]],\n",
      "\n",
      "          [[ 2.1131e-02, -5.4443e-03, -1.6192e-02],\n",
      "           [ 2.9280e-02,  3.2427e-02, -7.5485e-03],\n",
      "           [-4.4822e-03,  2.8779e-02, -1.3481e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.4080e-02,  3.4901e-02, -1.1184e-02],\n",
      "           [ 2.1422e-02, -1.4654e-03,  2.1125e-02],\n",
      "           [-1.1535e-02, -5.3035e-03,  1.1100e-02]],\n",
      "\n",
      "          [[-7.7737e-03, -6.6066e-03,  7.9004e-03],\n",
      "           [ 3.3490e-02, -1.5189e-02,  3.8335e-02],\n",
      "           [-2.0599e-02,  2.6231e-02,  5.0314e-02]],\n",
      "\n",
      "          [[-5.4357e-03, -7.0416e-03,  3.1788e-02],\n",
      "           [ 3.3530e-02,  4.7690e-03,  3.0978e-02],\n",
      "           [ 3.0311e-03, -1.6195e-02, -6.9125e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.1026e-02, -1.3340e-02, -9.7375e-03],\n",
      "           [ 1.5472e-02, -3.5882e-02,  2.9686e-02],\n",
      "           [-1.8832e-02, -1.9018e-02,  3.4745e-03]],\n",
      "\n",
      "          [[ 2.8959e-02,  2.0374e-02,  4.4284e-02],\n",
      "           [-7.7263e-03, -3.7061e-02,  1.9400e-02],\n",
      "           [-2.9109e-02,  1.6021e-02, -6.8574e-03]],\n",
      "\n",
      "          [[-1.8531e-03,  6.6436e-03,  1.3099e-02],\n",
      "           [ 3.2849e-02, -4.2492e-03,  4.2261e-02],\n",
      "           [ 1.0840e-02, -1.9526e-02,  3.8449e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.6947e-02, -2.7243e-02, -7.5368e-03],\n",
      "           [-2.6943e-03, -4.4404e-02, -2.7515e-02],\n",
      "           [ 1.1891e-02,  1.1397e-02, -4.3180e-02]],\n",
      "\n",
      "          [[-2.3785e-02, -4.3289e-02, -3.9889e-02],\n",
      "           [-3.5066e-02, -3.9835e-02, -1.6755e-02],\n",
      "           [-1.3861e-02, -3.2336e-02, -1.2714e-02]],\n",
      "\n",
      "          [[-4.9220e-02,  5.5330e-03,  5.0759e-04],\n",
      "           [-3.3134e-02,  1.3617e-02, -2.8170e-02],\n",
      "           [-4.5538e-02, -3.7003e-02, -3.1215e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.5057e-02,  2.2431e-02,  3.3104e-02],\n",
      "           [ 1.0086e-02,  1.3935e-02, -2.3910e-02],\n",
      "           [-2.0687e-02, -2.8749e-02,  5.4650e-03]],\n",
      "\n",
      "          [[ 2.1263e-02, -4.5576e-03, -1.8612e-02],\n",
      "           [-2.0685e-02,  1.9920e-02, -2.2110e-02],\n",
      "           [-2.1298e-02, -3.6447e-03, -2.6418e-02]],\n",
      "\n",
      "          [[ 9.6691e-03, -3.2520e-02,  1.5775e-02],\n",
      "           [ 2.1051e-02, -1.4194e-02, -2.3329e-02],\n",
      "           [-1.2880e-02,  2.2832e-02, -5.5700e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.0626e-02,  1.0258e-02, -7.9483e-03],\n",
      "           [ 3.2216e-03, -2.1225e-02,  1.4080e-02],\n",
      "           [-2.5224e-02, -2.7553e-03,  2.0949e-02]],\n",
      "\n",
      "          [[ 1.6129e-02,  2.1175e-02,  9.7758e-04],\n",
      "           [ 1.4694e-02, -2.0631e-02, -3.3881e-02],\n",
      "           [-2.7232e-02, -3.4162e-02, -1.1633e-03]],\n",
      "\n",
      "          [[ 2.1331e-02,  1.8275e-02, -1.5636e-02],\n",
      "           [ 3.7706e-02,  5.3802e-03, -2.2214e-02],\n",
      "           [-1.5980e-02,  3.6210e-02,  1.9671e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.0835e-04, -2.7729e-02, -8.7640e-04],\n",
      "           [ 1.1458e-02,  2.2228e-02, -1.8799e-02],\n",
      "           [-6.7250e-03,  2.2254e-03, -7.7110e-03]],\n",
      "\n",
      "          [[ 1.4011e-02,  1.8961e-02, -2.4772e-02],\n",
      "           [ 1.2403e-02,  1.8855e-02,  5.8713e-03],\n",
      "           [-1.7362e-02,  3.0249e-02,  5.9765e-03]],\n",
      "\n",
      "          [[ 1.6801e-02,  2.5192e-02, -2.9958e-02],\n",
      "           [-1.3590e-02,  1.6640e-02, -1.8531e-03],\n",
      "           [ 1.1011e-02, -2.4254e-02,  2.6937e-02]]]]], device='cuda:0')), ('module.down_layers.2.0.conv.weight', tensor([[[[[ 4.7608e-03,  1.1234e-02,  1.5489e-02],\n",
      "           [ 4.2955e-03,  6.2521e-03,  1.6728e-02],\n",
      "           [ 7.9545e-03,  2.9120e-02, -1.4727e-02]],\n",
      "\n",
      "          [[-9.3982e-03,  5.3023e-04, -1.3516e-02],\n",
      "           [ 7.9702e-03,  7.2241e-03,  1.7334e-02],\n",
      "           [ 7.8784e-03, -1.0368e-02, -8.3838e-03]],\n",
      "\n",
      "          [[-1.1644e-02,  1.9254e-02, -2.6941e-02],\n",
      "           [ 5.8783e-03, -1.1751e-02, -3.0025e-02],\n",
      "           [ 1.7037e-02,  3.3692e-02, -1.7942e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.0057e-03,  5.4906e-03, -3.2602e-02],\n",
      "           [-1.3169e-02,  1.7143e-02,  2.6276e-02],\n",
      "           [-3.9035e-02, -1.0613e-02,  9.7138e-03]],\n",
      "\n",
      "          [[-7.7927e-03,  1.6323e-03,  1.5329e-02],\n",
      "           [-6.1239e-03, -6.3731e-03, -2.8957e-02],\n",
      "           [-2.6525e-02,  1.9940e-02, -3.8527e-02]],\n",
      "\n",
      "          [[ 1.1496e-02,  9.4925e-03,  2.5635e-02],\n",
      "           [ 9.0134e-03,  2.5408e-02,  3.9960e-03],\n",
      "           [-3.4980e-02,  1.6508e-02,  1.1684e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.4162e-02, -3.4712e-02, -3.5786e-02],\n",
      "           [-1.6947e-02, -3.3621e-03, -8.0845e-03],\n",
      "           [-1.5192e-02,  3.0814e-02,  3.8188e-02]],\n",
      "\n",
      "          [[ 1.7460e-04,  4.7538e-03, -1.3188e-02],\n",
      "           [-2.1620e-02,  1.6955e-03, -2.4303e-02],\n",
      "           [ 1.8588e-02,  9.0579e-03,  2.1951e-02]],\n",
      "\n",
      "          [[-8.2210e-03, -3.9496e-02, -4.6179e-02],\n",
      "           [ 5.8819e-03,  6.9484e-03, -2.5015e-02],\n",
      "           [ 2.8450e-02,  3.5197e-02,  1.1045e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.2260e-02, -2.2597e-02,  7.9337e-03],\n",
      "           [ 3.9370e-03,  2.8500e-02, -2.8179e-02],\n",
      "           [-1.9529e-02, -2.5466e-02, -8.1033e-03]],\n",
      "\n",
      "          [[ 1.0791e-03,  4.0017e-02, -2.0957e-02],\n",
      "           [ 2.9600e-03,  3.2109e-02,  1.9183e-02],\n",
      "           [-1.4979e-02,  1.3480e-02, -2.6686e-02]],\n",
      "\n",
      "          [[ 2.7198e-02, -1.5311e-02,  3.5518e-03],\n",
      "           [-2.1267e-02,  2.0743e-02,  2.5887e-02],\n",
      "           [ 2.0908e-02, -1.3580e-02,  3.9824e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.6925e-02,  1.7714e-02,  1.3792e-02],\n",
      "           [ 6.7571e-04, -6.3698e-03, -2.9932e-02],\n",
      "           [ 1.8345e-03, -3.7627e-03, -2.4407e-04]],\n",
      "\n",
      "          [[ 1.3681e-02,  1.8012e-02, -1.3190e-02],\n",
      "           [ 2.5891e-02,  1.5530e-02, -2.4313e-02],\n",
      "           [-2.5806e-03, -3.0764e-02,  2.2455e-02]],\n",
      "\n",
      "          [[-3.0632e-02, -1.1682e-02, -3.9504e-02],\n",
      "           [ 1.8640e-02,  5.6567e-03, -2.3161e-02],\n",
      "           [ 1.2918e-02, -8.9207e-03,  2.4707e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.6461e-03, -1.6103e-02, -2.2380e-02],\n",
      "           [-1.7056e-02, -2.5777e-02, -9.6975e-03],\n",
      "           [ 1.4043e-02,  1.4003e-02,  3.1826e-02]],\n",
      "\n",
      "          [[ 3.4471e-02,  1.9468e-02,  2.8536e-02],\n",
      "           [ 2.7459e-02, -1.0443e-02, -2.3276e-02],\n",
      "           [ 1.0243e-02,  3.7348e-02,  1.9357e-02]],\n",
      "\n",
      "          [[ 1.4331e-05,  1.2932e-03,  1.1659e-02],\n",
      "           [ 1.0153e-02,  7.2827e-03,  2.1194e-02],\n",
      "           [-9.7370e-04,  4.0197e-02, -1.7782e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.3655e-02,  2.6136e-02,  2.5357e-02],\n",
      "           [ 2.5043e-02, -1.0258e-02,  2.7293e-02],\n",
      "           [ 2.7353e-02,  8.8555e-03,  2.8807e-03]],\n",
      "\n",
      "          [[-1.7434e-02, -6.8723e-03, -1.0505e-02],\n",
      "           [ 3.2385e-02, -7.7342e-03,  1.1071e-02],\n",
      "           [-1.7493e-02, -1.9704e-02, -7.6098e-03]],\n",
      "\n",
      "          [[ 1.4921e-02,  1.6107e-02, -4.6365e-03],\n",
      "           [-3.3242e-03, -2.0368e-02,  1.8302e-02],\n",
      "           [ 2.4980e-02, -4.9497e-03, -5.2575e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3106e-02, -2.1701e-02,  2.2953e-02],\n",
      "           [-2.2392e-02,  2.6226e-02,  3.1881e-02],\n",
      "           [ 2.5390e-02,  3.3956e-02, -2.1725e-02]],\n",
      "\n",
      "          [[ 1.1359e-02, -9.9581e-03, -2.0383e-02],\n",
      "           [ 5.0916e-03, -1.2884e-02, -4.1250e-02],\n",
      "           [-1.8028e-02, -1.4390e-02,  2.0468e-02]],\n",
      "\n",
      "          [[-4.3273e-02, -3.8189e-03, -1.5314e-02],\n",
      "           [-1.5559e-02,  7.3367e-03, -3.2982e-02],\n",
      "           [ 2.3183e-02,  2.4758e-02, -2.2198e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.4025e-02, -1.1063e-02,  1.6869e-03],\n",
      "           [ 2.0054e-02, -3.2042e-02, -3.1882e-02],\n",
      "           [-1.3972e-03, -2.6078e-02, -2.1161e-02]],\n",
      "\n",
      "          [[ 1.3779e-02, -1.1356e-02,  6.3870e-03],\n",
      "           [ 2.5280e-02, -1.1301e-02, -2.2704e-02],\n",
      "           [ 2.4231e-02, -2.2104e-02,  1.6754e-02]],\n",
      "\n",
      "          [[ 3.5327e-02, -1.1373e-02,  1.8233e-02],\n",
      "           [ 2.7000e-02, -1.7817e-02,  3.2571e-03],\n",
      "           [-1.1354e-02,  2.9351e-02, -2.4339e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.2634e-03, -2.5570e-02,  2.7346e-02],\n",
      "           [-4.4600e-03,  2.0070e-02,  9.1925e-03],\n",
      "           [ 4.2314e-03,  8.6884e-03,  4.7771e-02]],\n",
      "\n",
      "          [[-2.9880e-02,  9.0565e-03, -1.0858e-02],\n",
      "           [-1.1438e-02,  1.0628e-02,  6.2946e-04],\n",
      "           [-3.7660e-02,  2.3170e-02,  2.6478e-02]],\n",
      "\n",
      "          [[-2.0142e-02, -2.7196e-02, -1.4401e-02],\n",
      "           [ 1.0509e-03, -4.4762e-03, -2.2335e-02],\n",
      "           [ 1.6175e-02, -2.2929e-02,  1.6991e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.0889e-02,  4.1148e-02,  2.3662e-02],\n",
      "           [ 3.9553e-02,  4.9142e-03,  1.8272e-02],\n",
      "           [ 3.0884e-03, -1.0535e-02, -2.8281e-02]],\n",
      "\n",
      "          [[-1.5180e-02, -1.1861e-02,  2.5285e-02],\n",
      "           [ 3.2222e-02, -4.5002e-03,  2.2036e-02],\n",
      "           [ 8.9986e-03, -2.6799e-02,  8.1228e-03]],\n",
      "\n",
      "          [[ 1.6125e-02,  2.1104e-02, -1.6568e-02],\n",
      "           [ 3.1333e-02, -1.0768e-03, -1.8464e-02],\n",
      "           [ 1.0646e-02, -3.0990e-02, -4.3977e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.4139e-02, -7.4595e-03, -2.0396e-02],\n",
      "           [-1.5590e-02, -1.7292e-02, -3.6341e-02],\n",
      "           [-3.9558e-02, -3.6911e-02, -3.0304e-02]],\n",
      "\n",
      "          [[ 3.2377e-02,  3.2911e-02, -3.2944e-02],\n",
      "           [-1.4303e-02, -7.6706e-03, -3.0643e-02],\n",
      "           [-6.0464e-03, -2.9311e-02,  1.7881e-02]],\n",
      "\n",
      "          [[ 1.1699e-03,  2.8400e-02,  5.6469e-03],\n",
      "           [ 3.2799e-02,  3.5948e-03, -1.0518e-02],\n",
      "           [ 4.5572e-03, -1.5553e-02,  6.5086e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.4611e-02, -1.9099e-02, -2.4649e-02],\n",
      "           [-6.7040e-03, -3.2608e-02,  1.0643e-02],\n",
      "           [-4.1985e-03,  1.5751e-02,  1.6100e-03]],\n",
      "\n",
      "          [[-1.3683e-02, -2.3325e-02, -4.9622e-02],\n",
      "           [-2.2535e-02,  1.1980e-02,  6.0093e-03],\n",
      "           [ 2.7943e-02, -1.5590e-02, -2.5171e-02]],\n",
      "\n",
      "          [[-3.2297e-02, -2.2158e-02, -2.7756e-02],\n",
      "           [ 3.1058e-02,  2.5315e-02,  1.8880e-02],\n",
      "           [-4.7778e-03,  2.8137e-02, -3.3379e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.0559e-02, -1.1942e-02, -2.7176e-02],\n",
      "           [-3.0898e-02, -9.8008e-03, -2.9371e-02],\n",
      "           [-2.2402e-02,  4.9093e-03, -2.0741e-02]],\n",
      "\n",
      "          [[-1.7685e-02, -2.2596e-03,  3.1630e-02],\n",
      "           [ 1.2526e-02,  1.2380e-02, -1.8461e-02],\n",
      "           [-2.2792e-02,  7.2146e-03, -3.3811e-02]],\n",
      "\n",
      "          [[-7.7970e-03, -9.6842e-03, -2.3153e-02],\n",
      "           [-1.4505e-02, -2.6716e-02, -1.0096e-02],\n",
      "           [ 1.6772e-02, -8.7429e-03, -2.6820e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.8764e-02, -2.5009e-03,  2.5773e-02],\n",
      "           [-4.3968e-02,  6.8329e-03,  2.1073e-02],\n",
      "           [-2.2171e-02, -3.0451e-02, -3.5743e-04]],\n",
      "\n",
      "          [[-4.2037e-02, -1.1197e-02,  6.1399e-03],\n",
      "           [-7.5223e-03, -1.2226e-02, -2.2555e-02],\n",
      "           [ 1.8783e-02, -3.1769e-02, -1.9551e-02]],\n",
      "\n",
      "          [[-1.8428e-02, -2.9545e-02, -1.1434e-03],\n",
      "           [-4.1777e-02, -4.1819e-04,  2.6408e-03],\n",
      "           [ 2.1175e-02,  2.9966e-02, -8.4424e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.5093e-03,  1.2366e-02,  2.0600e-02],\n",
      "           [ 1.4624e-02,  2.6416e-02, -2.3710e-02],\n",
      "           [ 1.2265e-02,  2.1562e-02, -6.5326e-03]],\n",
      "\n",
      "          [[ 2.3851e-02,  3.4479e-02,  1.0336e-03],\n",
      "           [-1.7233e-02, -6.8276e-03, -1.0747e-02],\n",
      "           [-8.8741e-03, -1.7569e-02,  2.6387e-02]],\n",
      "\n",
      "          [[-2.1796e-02,  3.8305e-02, -2.5987e-02],\n",
      "           [-2.5050e-02,  1.0801e-02, -1.1571e-02],\n",
      "           [ 2.5935e-02,  3.2622e-02, -6.0734e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.5023e-02, -2.8209e-02,  1.9571e-02],\n",
      "           [-3.5215e-02, -8.8653e-03,  1.4631e-02],\n",
      "           [-1.0674e-02, -1.4583e-02, -2.3514e-02]],\n",
      "\n",
      "          [[-1.5716e-02,  1.9022e-02,  1.1898e-02],\n",
      "           [-2.2259e-02, -2.5513e-02,  1.2993e-02],\n",
      "           [ 3.3956e-03, -1.2301e-02, -6.2343e-03]],\n",
      "\n",
      "          [[ 3.3516e-03,  2.1313e-02, -4.9713e-03],\n",
      "           [-1.8360e-02,  8.0271e-03, -3.2638e-02],\n",
      "           [-1.9950e-02,  1.5720e-02,  4.7820e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.3936e-02, -2.8750e-02,  2.6646e-02],\n",
      "           [ 1.7256e-03, -2.1125e-02,  3.7207e-03],\n",
      "           [ 2.3956e-02,  2.3489e-02,  5.6787e-03]],\n",
      "\n",
      "          [[ 9.2383e-03,  2.8991e-02,  1.6908e-02],\n",
      "           [-1.2752e-03,  2.6235e-02, -1.3762e-02],\n",
      "           [-2.0439e-02,  2.3805e-02, -3.4373e-02]],\n",
      "\n",
      "          [[-3.1680e-02, -1.7253e-02, -1.2482e-03],\n",
      "           [-5.5992e-03,  9.6076e-03, -2.5929e-02],\n",
      "           [ 1.6392e-02, -3.4606e-03,  9.9811e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.6991e-02,  3.8007e-02, -9.1943e-03],\n",
      "           [-9.0447e-03,  3.1037e-02, -2.2164e-02],\n",
      "           [ 3.8771e-02, -2.2183e-02,  1.1846e-02]],\n",
      "\n",
      "          [[-2.5196e-03, -2.2667e-03,  2.5400e-04],\n",
      "           [ 2.6664e-02, -1.8521e-04, -3.2008e-02],\n",
      "           [-4.6312e-03,  6.0793e-03,  1.3664e-02]],\n",
      "\n",
      "          [[-7.3689e-03, -1.0361e-02, -2.8782e-02],\n",
      "           [-1.6912e-02, -2.5649e-03,  2.6744e-03],\n",
      "           [-6.8380e-03, -3.2471e-02,  2.5522e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.6189e-02,  3.3973e-02,  2.0278e-02],\n",
      "           [ 2.0252e-02, -1.9424e-02, -1.2010e-02],\n",
      "           [ 1.2141e-02, -1.9391e-02,  4.5389e-03]],\n",
      "\n",
      "          [[-4.4744e-03, -1.2613e-02,  2.8592e-02],\n",
      "           [-2.0626e-02,  1.1782e-02, -1.4533e-02],\n",
      "           [-3.0223e-03, -2.9472e-02,  8.4905e-03]],\n",
      "\n",
      "          [[-2.2150e-02, -1.7205e-02, -3.4050e-02],\n",
      "           [-2.2193e-03, -8.2385e-03, -2.9349e-02],\n",
      "           [ 6.7103e-04,  5.0417e-03, -2.6075e-02]]],\n",
      "\n",
      "\n",
      "         [[[-8.9720e-03,  3.2281e-02,  1.5505e-02],\n",
      "           [-4.3970e-03, -1.3834e-02, -1.2273e-02],\n",
      "           [ 6.7482e-03, -3.1645e-02,  1.3310e-03]],\n",
      "\n",
      "          [[ 3.8070e-02,  9.5487e-03, -1.0232e-03],\n",
      "           [-3.7739e-03, -2.9705e-02,  2.6154e-02],\n",
      "           [-4.4349e-03, -8.2608e-03,  2.6662e-02]],\n",
      "\n",
      "          [[-2.2614e-02,  3.2094e-03, -1.1563e-02],\n",
      "           [-1.1220e-02,  2.0129e-03,  2.9981e-02],\n",
      "           [ 9.3699e-03,  1.9266e-02, -1.3570e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.4214e-02,  9.4723e-03, -1.1467e-02],\n",
      "           [ 1.8381e-02,  3.6324e-03, -1.8675e-02],\n",
      "           [-1.9867e-03, -2.5483e-02,  2.4908e-03]],\n",
      "\n",
      "          [[-2.6267e-02, -1.7077e-02,  1.1652e-02],\n",
      "           [-4.5136e-02, -6.9757e-03, -2.4163e-02],\n",
      "           [-4.8038e-02, -4.6722e-02, -3.9628e-02]],\n",
      "\n",
      "          [[ 2.5165e-02, -2.7363e-02, -4.2881e-02],\n",
      "           [-4.6953e-02, -2.3269e-03, -3.5335e-02],\n",
      "           [-2.6056e-02, -4.4519e-03, -1.4684e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.7151e-03,  1.2544e-02,  3.8789e-02],\n",
      "           [-1.0531e-02,  4.0129e-02,  1.1553e-02],\n",
      "           [-4.2731e-04,  1.0312e-04, -3.6497e-03]],\n",
      "\n",
      "          [[ 1.2032e-02,  4.1394e-03,  2.1567e-02],\n",
      "           [ 5.7465e-03,  1.0202e-02, -1.0108e-02],\n",
      "           [ 1.2750e-02,  8.1990e-03,  2.6925e-02]],\n",
      "\n",
      "          [[ 2.2304e-02, -3.0158e-02, -8.9027e-03],\n",
      "           [-2.3358e-02,  9.5686e-04,  1.6162e-02],\n",
      "           [ 4.3360e-03, -2.7117e-02, -1.7165e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.8142e-02, -2.2806e-02,  2.6253e-03],\n",
      "           [-9.0731e-03, -3.2263e-02, -2.9115e-02],\n",
      "           [-3.7495e-03, -3.2384e-02, -1.0067e-02]],\n",
      "\n",
      "          [[ 9.2099e-03,  1.9808e-02,  1.0943e-02],\n",
      "           [ 4.2780e-03,  1.9604e-02, -1.1395e-02],\n",
      "           [-8.3775e-03, -2.5476e-02,  2.0965e-02]],\n",
      "\n",
      "          [[-2.2791e-02,  2.9578e-02,  2.9024e-02],\n",
      "           [-3.1192e-02, -3.9303e-02, -4.0500e-02],\n",
      "           [-1.2006e-02, -1.8283e-02, -5.8170e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.5200e-02, -3.4069e-02, -2.4190e-02],\n",
      "           [ 8.0916e-03, -2.2511e-02, -6.1947e-03],\n",
      "           [-2.7105e-02,  1.3841e-02, -3.5221e-02]],\n",
      "\n",
      "          [[-8.6948e-03, -2.9088e-03, -8.7794e-03],\n",
      "           [-3.7709e-02,  1.5911e-03, -4.6794e-03],\n",
      "           [-3.8392e-02, -7.4573e-03, -3.7758e-02]],\n",
      "\n",
      "          [[ 2.6627e-02,  2.5460e-02,  9.6383e-03],\n",
      "           [-3.2268e-02,  2.7889e-02,  3.3530e-03],\n",
      "           [-1.3686e-02, -2.8761e-02,  1.0332e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.0503e-02, -1.1652e-02, -3.6887e-02],\n",
      "           [-3.6372e-02,  1.1786e-02, -4.1460e-02],\n",
      "           [-1.0057e-02,  2.8075e-02,  1.4222e-05]],\n",
      "\n",
      "          [[ 2.1609e-02,  1.4743e-02, -2.7178e-02],\n",
      "           [-2.2714e-02,  1.6017e-02, -8.3068e-03],\n",
      "           [ 2.0920e-02,  4.7618e-04,  2.2751e-02]],\n",
      "\n",
      "          [[-1.2236e-02, -2.8283e-02, -4.1940e-02],\n",
      "           [-5.9801e-03,  2.0377e-02,  1.9340e-03],\n",
      "           [-5.6205e-03, -3.7500e-02,  1.6883e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1588e-02, -1.4341e-02,  2.5356e-02],\n",
      "           [ 3.0060e-02, -1.4404e-02,  3.7978e-02],\n",
      "           [-1.9939e-02,  1.2404e-02,  2.5836e-02]],\n",
      "\n",
      "          [[ 1.0016e-02,  3.8679e-02,  2.7739e-02],\n",
      "           [-2.3363e-02, -3.0171e-02, -2.6623e-02],\n",
      "           [-2.8897e-02, -1.6577e-02,  1.1216e-02]],\n",
      "\n",
      "          [[-1.2399e-02, -7.7170e-03,  6.1143e-03],\n",
      "           [ 3.2637e-03,  1.6045e-02,  2.1769e-02],\n",
      "           [-1.8676e-02,  1.3904e-02, -4.6714e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.2512e-02, -3.3134e-02, -2.6835e-02],\n",
      "           [ 1.8914e-02,  1.8838e-02, -7.1757e-03],\n",
      "           [ 1.6052e-02, -2.3197e-02,  7.2687e-03]],\n",
      "\n",
      "          [[-2.1388e-02, -4.0983e-03, -2.6252e-02],\n",
      "           [-1.5908e-02, -1.3878e-02,  1.8700e-02],\n",
      "           [-1.0218e-02,  3.2572e-02, -1.1011e-02]],\n",
      "\n",
      "          [[-1.3229e-02, -6.8222e-03, -9.7757e-03],\n",
      "           [ 2.9031e-02, -2.1135e-02,  3.1952e-02],\n",
      "           [-3.7495e-04,  1.1461e-02, -1.5363e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.2457e-02, -9.7480e-03,  1.1513e-02],\n",
      "           [-1.6989e-02,  1.7443e-02, -3.4500e-02],\n",
      "           [ 2.3620e-02, -2.2940e-02, -2.2260e-02]],\n",
      "\n",
      "          [[ 8.8948e-03,  3.1133e-02, -9.6085e-03],\n",
      "           [ 2.3627e-02, -6.9549e-03,  1.5124e-03],\n",
      "           [-4.7784e-03, -2.2288e-02, -2.9298e-02]],\n",
      "\n",
      "          [[ 6.5384e-03,  5.8445e-03, -4.4926e-03],\n",
      "           [ 9.5591e-03,  3.0083e-02, -2.4961e-03],\n",
      "           [-1.1307e-02, -1.8185e-02, -4.5223e-05]]],\n",
      "\n",
      "\n",
      "         [[[-2.1985e-02,  1.5933e-02,  1.0511e-02],\n",
      "           [-9.2519e-03,  1.1419e-04, -2.3327e-02],\n",
      "           [ 1.1511e-02, -2.0443e-02,  1.1420e-02]],\n",
      "\n",
      "          [[-2.7752e-02, -4.0371e-03,  7.3531e-03],\n",
      "           [-6.3384e-03,  4.3625e-03, -1.2667e-02],\n",
      "           [ 3.1364e-02,  1.2187e-02, -2.0070e-02]],\n",
      "\n",
      "          [[-5.3666e-03, -9.5628e-04,  3.3911e-02],\n",
      "           [-3.1428e-02, -1.2054e-02, -1.8414e-02],\n",
      "           [ 4.0299e-03,  2.0745e-02, -2.0543e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 7.4823e-03, -1.7716e-02, -2.9190e-02],\n",
      "           [ 3.1619e-02, -2.7343e-03,  1.3592e-02],\n",
      "           [ 1.8844e-02,  6.1392e-03,  2.0722e-02]],\n",
      "\n",
      "          [[-1.2595e-02, -1.9702e-02, -2.8281e-02],\n",
      "           [-1.3351e-02,  2.9332e-02, -2.3667e-02],\n",
      "           [-1.1596e-02, -1.6957e-02, -2.5673e-03]],\n",
      "\n",
      "          [[ 2.9439e-02, -2.2591e-02,  1.8109e-02],\n",
      "           [ 4.0245e-02,  6.6036e-04,  1.0728e-02],\n",
      "           [-2.1836e-02,  8.6571e-03, -2.1573e-04]]],\n",
      "\n",
      "\n",
      "         [[[-2.0478e-02,  3.3668e-02, -7.7458e-03],\n",
      "           [ 1.3569e-03,  9.5945e-03,  3.9049e-03],\n",
      "           [-2.4814e-02, -1.7872e-02,  2.6615e-02]],\n",
      "\n",
      "          [[-9.6938e-03,  4.1849e-02,  2.6364e-02],\n",
      "           [ 1.8061e-02,  3.6876e-02, -1.0408e-02],\n",
      "           [ 1.1709e-02,  3.0602e-02,  3.2426e-02]],\n",
      "\n",
      "          [[ 2.0348e-03,  3.2200e-02, -1.2434e-02],\n",
      "           [ 3.6377e-03, -1.2433e-02, -1.3869e-02],\n",
      "           [ 9.9117e-03, -2.5223e-02,  2.0925e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 6.9559e-03, -1.0363e-02,  1.6169e-02],\n",
      "           [ 1.4439e-03,  9.5236e-03, -3.0527e-02],\n",
      "           [-1.3082e-02, -8.9234e-03, -8.8709e-03]],\n",
      "\n",
      "          [[ 9.5040e-03, -3.4974e-02, -1.3279e-02],\n",
      "           [-2.7486e-02, -3.0654e-02, -1.5015e-02],\n",
      "           [ 2.6795e-02,  4.2166e-03,  1.5493e-02]],\n",
      "\n",
      "          [[ 2.2386e-02, -3.7316e-03, -1.4455e-02],\n",
      "           [ 1.1335e-02, -3.3310e-02, -3.6179e-02],\n",
      "           [ 1.5674e-04, -2.4594e-02, -1.5783e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.8802e-02, -1.0378e-02,  1.0095e-02],\n",
      "           [ 2.1080e-02, -1.8948e-02,  4.1014e-02],\n",
      "           [ 3.5597e-02,  3.6675e-02,  7.0309e-03]],\n",
      "\n",
      "          [[ 2.7049e-02,  1.8937e-02,  2.2271e-02],\n",
      "           [ 2.4560e-02,  6.2300e-03,  3.1311e-02],\n",
      "           [ 2.7118e-02, -1.9718e-02,  3.2631e-02]],\n",
      "\n",
      "          [[-7.5334e-03, -1.2254e-02,  3.2062e-02],\n",
      "           [-8.2555e-03,  2.1562e-02,  1.2203e-03],\n",
      "           [ 1.7890e-02, -2.5590e-02,  2.2154e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.2287e-02,  1.0836e-02, -2.4789e-03],\n",
      "           [ 4.0666e-03, -3.2104e-02, -3.0328e-02],\n",
      "           [ 1.7468e-02, -6.6802e-03, -1.8791e-02]],\n",
      "\n",
      "          [[ 7.4009e-03,  3.1621e-03, -3.6967e-02],\n",
      "           [ 7.7786e-04,  1.7781e-02, -2.3316e-02],\n",
      "           [-3.4513e-02,  6.7609e-04, -3.4740e-02]],\n",
      "\n",
      "          [[ 1.2805e-02, -2.7057e-02, -1.7540e-03],\n",
      "           [ 1.0873e-02, -3.6959e-02,  3.4336e-03],\n",
      "           [-1.8419e-02, -3.2393e-02,  2.9631e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.2771e-03,  2.3550e-02,  1.1013e-02],\n",
      "           [ 3.3564e-03, -4.2815e-03, -1.1321e-02],\n",
      "           [ 1.6591e-02,  1.0352e-02,  1.2482e-02]],\n",
      "\n",
      "          [[ 4.0212e-02,  6.0580e-03,  1.2260e-02],\n",
      "           [-1.7749e-02,  1.7660e-02, -1.1081e-02],\n",
      "           [-2.7913e-03, -1.0954e-02, -4.3177e-03]],\n",
      "\n",
      "          [[-1.0718e-02,  4.4497e-02,  3.8520e-02],\n",
      "           [ 1.5893e-02,  2.2336e-02,  2.0231e-02],\n",
      "           [ 2.0375e-03, -1.3257e-02,  1.7796e-02]]]]], device='cuda:0')), ('module.down_layers.2.1.norm1.weight', tensor([0.9810, 0.9983, 0.9902, 0.9620, 0.9992, 0.9355, 0.9801, 0.9559, 0.9799,\n",
      "        0.9517, 0.9606, 0.9853, 0.9561, 1.0015, 0.9797, 0.9787, 0.9822, 0.9809,\n",
      "        0.9055, 0.9792, 1.0020, 0.9330, 0.9735, 0.9784, 0.9973, 0.9870, 0.9664,\n",
      "        0.9863, 0.9237, 0.9755, 0.9823, 0.9885, 0.9594, 0.9126, 0.9774, 0.9598,\n",
      "        0.9472, 0.9649, 0.9839, 0.9567, 0.9873, 0.9737, 0.9242, 0.9566, 0.9594,\n",
      "        0.9225, 0.9733, 0.9928, 0.9929, 0.9783, 0.9731, 0.9652, 1.0046, 0.9809,\n",
      "        0.9752, 0.9332, 0.9728, 0.9627, 0.9900, 0.9937, 0.9833, 0.9643, 0.9528,\n",
      "        0.9841], device='cuda:0')), ('module.down_layers.2.1.norm1.bias', tensor([-0.0186, -0.0126,  0.0019, -0.0220, -0.0046, -0.0261, -0.0106, -0.0121,\n",
      "        -0.0273, -0.0226, -0.0164, -0.0255, -0.0261, -0.0010, -0.0102, -0.0172,\n",
      "        -0.0275, -0.0261, -0.0276, -0.0242, -0.0257, -0.0209, -0.0335, -0.0105,\n",
      "         0.0106, -0.0085, -0.0211, -0.0174, -0.0070, -0.0032, -0.0183,  0.0033,\n",
      "        -0.0352, -0.0034, -0.0139, -0.0186,  0.0093,  0.0002, -0.0081, -0.0184,\n",
      "        -0.0195, -0.0208, -0.0286, -0.0171,  0.0107, -0.0086, -0.0184, -0.0259,\n",
      "        -0.0118, -0.0145, -0.0065, -0.0232, -0.0099, -0.0070, -0.0046, -0.0154,\n",
      "        -0.0118, -0.0251, -0.0120, -0.0253, -0.0238, -0.0228, -0.0135,  0.0102],\n",
      "       device='cuda:0')), ('module.down_layers.2.1.norm2.weight', tensor([0.9897, 0.9717, 0.9493, 0.9788, 0.8494, 0.9960, 0.9584, 0.9934, 0.9624,\n",
      "        0.9843, 0.9838, 0.9714, 0.9830, 1.0018, 0.9702, 0.9020, 0.9861, 0.9808,\n",
      "        0.9740, 0.8785, 0.9692, 0.9178, 0.9949, 0.9835, 0.9826, 0.9928, 0.9687,\n",
      "        0.9849, 0.8691, 0.9773, 0.8662, 0.9822, 0.9830, 0.9693, 0.9031, 0.8946,\n",
      "        0.9517, 0.8573, 0.9833, 0.9881, 0.9854, 0.9984, 0.9709, 0.9752, 0.9924,\n",
      "        0.9112, 0.9915, 0.9633, 0.9612, 0.9870, 0.9803, 0.9384, 0.8139, 0.9656,\n",
      "        0.9698, 0.9820, 0.8268, 0.9643, 0.9923, 0.9901, 0.9783, 0.9566, 0.9679,\n",
      "        0.9718], device='cuda:0')), ('module.down_layers.2.1.norm2.bias', tensor([-0.0136, -0.0289, -0.0140, -0.0147, -0.0161, -0.0068, -0.0285, -0.0142,\n",
      "        -0.0203, -0.0143, -0.0119, -0.0096, -0.0191, -0.0115, -0.0274, -0.0332,\n",
      "        -0.0170, -0.0171, -0.0211, -0.0083, -0.0104, -0.0038, -0.0100, -0.0188,\n",
      "        -0.0131, -0.0111, -0.0116, -0.0266, -0.0256, -0.0248, -0.0259, -0.0297,\n",
      "        -0.0189, -0.0121, -0.0011, -0.0018, -0.0340,  0.0155, -0.0059, -0.0140,\n",
      "        -0.0204, -0.0175, -0.0212, -0.0301,  0.0030, -0.0288, -0.0076, -0.0168,\n",
      "        -0.0314, -0.0148, -0.0190, -0.0267, -0.0152, -0.0281, -0.0282, -0.0173,\n",
      "        -0.0289, -0.0181, -0.0138, -0.0210, -0.0187, -0.0291, -0.0201, -0.0260],\n",
      "       device='cuda:0')), ('module.down_layers.2.1.conv1.conv.weight', tensor([[[[[-1.0877e-02,  1.3544e-02, -6.9012e-03],\n",
      "           [ 1.3802e-02,  6.0210e-03,  6.7352e-03],\n",
      "           [-1.0008e-03,  1.8667e-02,  2.0173e-02]],\n",
      "\n",
      "          [[-1.0815e-02,  1.9039e-02, -1.1839e-02],\n",
      "           [-9.4871e-04, -8.4260e-03,  1.8885e-02],\n",
      "           [ 1.7373e-02, -1.1727e-03,  1.2859e-04]],\n",
      "\n",
      "          [[-8.2686e-03,  1.2786e-02,  2.0767e-03],\n",
      "           [-6.3088e-03, -1.6366e-02, -2.5328e-02],\n",
      "           [-1.6848e-02, -4.6099e-03, -2.6389e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.3513e-02,  2.8382e-02,  4.8182e-03],\n",
      "           [ 2.3416e-02,  1.9682e-02, -3.3649e-03],\n",
      "           [ 6.4821e-03, -5.0481e-03, -2.5544e-02]],\n",
      "\n",
      "          [[ 2.1469e-02, -9.8765e-03, -2.2836e-02],\n",
      "           [ 3.5852e-02,  1.4824e-02,  2.2266e-02],\n",
      "           [-6.5447e-03,  9.8027e-04,  2.5156e-02]],\n",
      "\n",
      "          [[ 3.3155e-02,  1.1727e-02, -1.1181e-02],\n",
      "           [ 4.0984e-02,  2.2335e-02,  1.6492e-02],\n",
      "           [ 1.8982e-02, -5.2671e-03, -1.0835e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.6137e-02, -5.4840e-02, -4.6360e-02],\n",
      "           [-3.8698e-02, -3.4163e-02,  1.4613e-03],\n",
      "           [ 1.9799e-03,  1.1424e-02, -3.5924e-03]],\n",
      "\n",
      "          [[-2.4382e-02, -1.0663e-02, -1.0774e-02],\n",
      "           [-3.2654e-02,  8.1948e-03, -1.9601e-02],\n",
      "           [-5.2172e-03,  1.6957e-02,  1.9861e-02]],\n",
      "\n",
      "          [[ 6.7789e-03, -1.4250e-02, -1.4432e-02],\n",
      "           [-1.2482e-02,  9.0329e-03, -4.2240e-03],\n",
      "           [-2.2726e-02, -2.5069e-02, -2.5462e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.2455e-02,  1.9635e-03, -5.1348e-03],\n",
      "           [ 2.1990e-03,  3.7352e-03, -7.3437e-03],\n",
      "           [-2.0199e-02,  6.4135e-03, -1.5934e-03]],\n",
      "\n",
      "          [[ 1.4060e-02,  1.8956e-02, -1.7903e-02],\n",
      "           [ 6.2620e-03,  1.8091e-03, -1.6395e-02],\n",
      "           [-2.4506e-03,  2.1983e-02,  1.5232e-02]],\n",
      "\n",
      "          [[ 9.4610e-03, -2.6896e-02, -2.1078e-02],\n",
      "           [ 1.5434e-02,  1.2691e-02,  5.0559e-04],\n",
      "           [-3.5071e-03, -1.0985e-02,  1.4448e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.5548e-03, -2.0364e-02, -5.3690e-03],\n",
      "           [-1.6678e-02,  7.4430e-03,  2.6260e-02],\n",
      "           [-8.5537e-04, -7.9378e-03,  1.3497e-02]],\n",
      "\n",
      "          [[-1.7418e-02, -4.5998e-04,  2.4628e-02],\n",
      "           [-1.5937e-02, -1.8575e-02, -6.7429e-03],\n",
      "           [ 9.1439e-03, -2.8298e-02, -1.5029e-02]],\n",
      "\n",
      "          [[ 7.2348e-03, -1.1599e-02,  1.1931e-02],\n",
      "           [ 1.5941e-03,  6.6382e-03,  2.0332e-03],\n",
      "           [-6.0514e-03,  1.0719e-02, -2.0094e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.2436e-02, -1.9246e-02, -1.0978e-02],\n",
      "           [-3.8757e-02, -9.2220e-03, -1.1564e-02],\n",
      "           [-6.2182e-04,  3.5743e-03,  2.9946e-03]],\n",
      "\n",
      "          [[-2.6336e-02,  1.1645e-02, -2.4978e-03],\n",
      "           [-2.3441e-02, -3.0488e-02, -1.0379e-02],\n",
      "           [-1.0256e-02, -1.6261e-02, -8.9389e-03]],\n",
      "\n",
      "          [[ 5.6584e-03, -1.2624e-02, -1.4599e-03],\n",
      "           [-2.0383e-02,  4.5759e-03, -4.6608e-03],\n",
      "           [ 7.3671e-03,  4.8005e-03, -1.1925e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.3099e-02,  1.3237e-02,  2.9238e-03],\n",
      "           [-1.6532e-02,  2.3095e-02,  3.8843e-03],\n",
      "           [-1.6027e-02, -1.1211e-02, -2.6905e-02]],\n",
      "\n",
      "          [[-6.8478e-03, -2.9567e-02, -2.3968e-02],\n",
      "           [-2.3828e-02, -1.3405e-02, -2.6023e-02],\n",
      "           [-3.1701e-04,  5.5732e-03, -2.0547e-02]],\n",
      "\n",
      "          [[ 6.8078e-03, -3.8383e-02, -8.7587e-03],\n",
      "           [-2.6486e-02, -2.6653e-02, -1.2664e-02],\n",
      "           [-3.4642e-02, -1.9330e-02, -3.6147e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.8306e-02, -2.9598e-02,  1.8405e-02],\n",
      "           [-2.3813e-02, -2.0569e-03,  3.1014e-02],\n",
      "           [-2.5146e-02, -1.5730e-02,  1.4217e-03]],\n",
      "\n",
      "          [[-4.4766e-03, -3.5823e-02, -1.6943e-02],\n",
      "           [-5.5967e-03, -2.2864e-02,  4.9321e-04],\n",
      "           [-3.9156e-03,  1.6226e-02,  2.8579e-02]],\n",
      "\n",
      "          [[ 2.3439e-03,  1.8180e-02,  2.1727e-04],\n",
      "           [-2.4042e-02,  1.5624e-02,  7.2152e-03],\n",
      "           [-3.6777e-03, -9.8316e-03, -2.9887e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.3967e-03,  1.5013e-02,  9.4600e-03],\n",
      "           [-2.2818e-02,  4.7838e-03,  1.4175e-02],\n",
      "           [-2.0804e-02, -2.6114e-02,  1.8100e-02]],\n",
      "\n",
      "          [[-2.0771e-02, -1.9427e-02, -2.7420e-04],\n",
      "           [-2.6773e-02, -1.8740e-02,  1.2537e-02],\n",
      "           [-9.9314e-03, -3.8810e-03, -1.3343e-02]],\n",
      "\n",
      "          [[-1.1828e-02,  2.6706e-02,  6.3936e-03],\n",
      "           [ 1.3066e-02, -3.3935e-03,  6.3637e-03],\n",
      "           [ 1.9779e-02, -1.3530e-03,  1.3660e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-5.1412e-03, -1.9047e-02,  1.1787e-02],\n",
      "           [-1.7260e-02, -8.1986e-03,  3.3946e-03],\n",
      "           [ 3.8180e-03, -9.8321e-03, -2.1712e-02]],\n",
      "\n",
      "          [[-2.3051e-02, -1.8414e-02, -5.0690e-03],\n",
      "           [-3.7562e-02,  8.5668e-03, -1.1719e-02],\n",
      "           [-2.6617e-02, -2.1418e-02, -5.1742e-03]],\n",
      "\n",
      "          [[-1.8567e-02,  2.0153e-02, -2.4649e-02],\n",
      "           [-3.2771e-02, -2.3854e-02,  7.9323e-03],\n",
      "           [ 5.2618e-03, -5.6540e-03,  1.6947e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.7128e-02, -2.2977e-02, -8.2350e-04],\n",
      "           [-2.2535e-02,  9.1289e-03,  2.0288e-02],\n",
      "           [ 2.8840e-02,  4.9177e-03, -1.1984e-02]],\n",
      "\n",
      "          [[-4.7477e-04, -1.2025e-03, -2.0333e-02],\n",
      "           [-6.0356e-03, -6.3840e-03, -2.3552e-02],\n",
      "           [ 9.0484e-03,  2.8505e-02,  1.6746e-02]],\n",
      "\n",
      "          [[ 1.3325e-02,  4.1250e-03,  5.3327e-03],\n",
      "           [-1.0869e-02, -1.0651e-02, -2.0581e-02],\n",
      "           [ 4.0355e-03,  1.2588e-02,  2.8438e-04]]],\n",
      "\n",
      "\n",
      "         [[[-2.3218e-02, -2.5173e-03,  1.9326e-02],\n",
      "           [ 8.7367e-03, -7.6932e-03,  1.8518e-02],\n",
      "           [ 6.9791e-03,  1.6635e-02,  9.7430e-03]],\n",
      "\n",
      "          [[ 1.0362e-04, -2.2528e-02, -1.2537e-02],\n",
      "           [-1.3643e-02,  2.3880e-03,  2.1789e-02],\n",
      "           [ 1.3858e-02,  1.8507e-02,  2.4286e-02]],\n",
      "\n",
      "          [[ 1.6515e-02, -2.6563e-02, -1.1499e-02],\n",
      "           [ 3.1456e-03,  1.4233e-02, -1.3955e-02],\n",
      "           [-3.0635e-02,  5.2121e-03, -2.2895e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.6248e-03, -1.7453e-02,  2.9273e-02],\n",
      "           [ 1.0115e-02,  7.8930e-04, -2.4345e-02],\n",
      "           [-2.0483e-03, -2.5078e-02, -2.0530e-02]],\n",
      "\n",
      "          [[ 1.6748e-02, -8.8824e-03, -3.1485e-03],\n",
      "           [-2.6431e-02,  1.0671e-02,  1.2623e-02],\n",
      "           [ 3.7560e-03,  3.0063e-03, -2.0256e-02]],\n",
      "\n",
      "          [[ 1.9073e-02,  2.7082e-02,  2.2008e-02],\n",
      "           [-4.9044e-03,  2.0009e-03,  4.5926e-03],\n",
      "           [-7.0376e-03, -2.0174e-02,  6.6962e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.1167e-02, -5.9174e-03, -1.0282e-02],\n",
      "           [ 8.1708e-03, -3.4139e-03, -1.5887e-02],\n",
      "           [-8.8774e-03, -5.1434e-03,  1.2936e-02]],\n",
      "\n",
      "          [[-7.2039e-03,  2.1880e-02,  1.3023e-02],\n",
      "           [-6.6304e-03,  1.7768e-02,  3.2456e-03],\n",
      "           [ 1.2134e-02, -8.6049e-03, -5.4234e-03]],\n",
      "\n",
      "          [[ 2.7682e-02,  2.8068e-02,  5.9903e-03],\n",
      "           [ 1.7688e-02, -9.0213e-03,  1.6843e-02],\n",
      "           [ 1.5202e-02,  4.5065e-03,  2.5402e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.5382e-02, -1.1469e-02, -4.8257e-03],\n",
      "           [-3.8312e-02, -3.0620e-02, -1.6152e-02],\n",
      "           [-4.7342e-03, -4.0726e-02,  2.1374e-02]],\n",
      "\n",
      "          [[-6.4895e-03,  9.4368e-03,  5.3903e-03],\n",
      "           [-2.6871e-03, -2.5574e-02,  2.3859e-02],\n",
      "           [-3.1604e-02, -2.4788e-02,  1.3905e-02]],\n",
      "\n",
      "          [[-5.7006e-04,  2.3381e-02,  3.9398e-03],\n",
      "           [ 4.7624e-03, -2.0005e-02,  7.5615e-03],\n",
      "           [-7.8715e-04, -1.9462e-02, -1.4822e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.3907e-04, -1.4970e-02, -1.3696e-02],\n",
      "           [-1.5927e-02, -2.3741e-02, -8.3619e-03],\n",
      "           [-1.4395e-02, -8.0284e-03,  1.3583e-02]],\n",
      "\n",
      "          [[-8.3469e-03,  2.2812e-02,  3.2070e-03],\n",
      "           [-1.3043e-02,  3.7354e-03, -2.0096e-02],\n",
      "           [-1.2978e-02, -2.7435e-02, -1.8015e-03]],\n",
      "\n",
      "          [[ 1.8660e-02, -1.3564e-02, -1.7480e-02],\n",
      "           [-1.6040e-02, -2.3408e-02, -1.7958e-02],\n",
      "           [-1.7269e-02, -1.1204e-02,  1.1507e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.7156e-02,  9.2648e-04,  1.6741e-02],\n",
      "           [ 1.7853e-02,  1.0789e-02, -5.2359e-03],\n",
      "           [ 2.1300e-02,  1.7804e-02,  4.0438e-03]],\n",
      "\n",
      "          [[ 2.7367e-02, -1.5447e-02, -1.6834e-02],\n",
      "           [ 1.5352e-03,  2.5818e-02, -1.7007e-02],\n",
      "           [ 2.3387e-02,  3.9425e-03,  4.0803e-03]],\n",
      "\n",
      "          [[ 1.6786e-02,  8.2169e-03, -8.4535e-03],\n",
      "           [ 2.1202e-02,  2.0734e-02,  6.9900e-03],\n",
      "           [ 7.8844e-03,  1.7992e-02, -7.4704e-04]]],\n",
      "\n",
      "\n",
      "         [[[-3.2564e-02,  1.0450e-02,  2.3720e-02],\n",
      "           [-3.6773e-02, -1.7241e-02,  2.5115e-03],\n",
      "           [-5.2285e-02, -1.9249e-02,  9.6844e-03]],\n",
      "\n",
      "          [[-1.3590e-02, -2.4144e-02,  1.8311e-02],\n",
      "           [ 6.3481e-03, -2.3915e-02, -1.1269e-02],\n",
      "           [-2.8173e-02,  5.5053e-03, -8.1223e-03]],\n",
      "\n",
      "          [[ 1.9526e-03, -5.0308e-03,  1.6892e-02],\n",
      "           [-7.2965e-03, -2.2858e-02, -3.7084e-03],\n",
      "           [-1.2094e-02,  1.9442e-03,  1.0668e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.9559e-02, -2.5872e-02,  3.3944e-02],\n",
      "           [ 3.0511e-02,  1.0442e-02, -4.4105e-03],\n",
      "           [ 8.2907e-04,  3.1923e-03,  1.5954e-02]],\n",
      "\n",
      "          [[ 3.2134e-03,  5.2337e-03,  4.2004e-02],\n",
      "           [ 1.0016e-02,  6.0471e-03,  3.6063e-02],\n",
      "           [-1.0452e-02,  5.8271e-03,  1.2623e-02]],\n",
      "\n",
      "          [[ 2.7260e-02,  6.0360e-03,  3.2039e-02],\n",
      "           [-9.0576e-03, -4.3055e-03,  3.7560e-02],\n",
      "           [-9.7160e-03, -1.9575e-02,  2.8472e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 6.0471e-03,  1.0657e-02, -5.7533e-03],\n",
      "           [ 2.3490e-03,  1.9609e-02,  1.7180e-02],\n",
      "           [ 4.4286e-03,  2.4471e-02,  2.4023e-03]],\n",
      "\n",
      "          [[-1.1543e-02,  9.8772e-03,  2.0373e-02],\n",
      "           [-3.6916e-03, -2.6906e-03, -5.0693e-03],\n",
      "           [ 9.1419e-03, -1.6640e-02,  1.1234e-02]],\n",
      "\n",
      "          [[-1.1074e-02,  1.1915e-02, -2.3861e-03],\n",
      "           [ 1.8038e-02,  6.7463e-03,  4.4214e-04],\n",
      "           [-2.7782e-02, -1.4361e-02, -2.6078e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.5204e-02,  1.2876e-02,  1.3501e-02],\n",
      "           [ 4.5302e-02,  2.2443e-02, -8.8818e-03],\n",
      "           [ 4.0752e-02, -1.5229e-02, -2.6774e-02]],\n",
      "\n",
      "          [[ 1.7682e-02, -1.2748e-02,  8.7825e-03],\n",
      "           [ 3.2187e-02, -1.2710e-03, -1.1125e-02],\n",
      "           [ 7.2013e-03, -8.8269e-03,  4.9749e-03]],\n",
      "\n",
      "          [[ 3.4927e-02,  1.6382e-02,  1.8451e-02],\n",
      "           [-2.7000e-03, -1.4365e-02,  3.9137e-03],\n",
      "           [-1.6920e-02,  8.3113e-03,  1.5205e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.0394e-02, -8.8760e-03, -7.8044e-03],\n",
      "           [-1.1988e-03, -6.2121e-03, -1.3912e-02],\n",
      "           [-1.9440e-02, -2.3440e-02, -8.9420e-03]],\n",
      "\n",
      "          [[-1.0775e-02, -2.5038e-02,  1.3620e-02],\n",
      "           [ 1.1119e-02,  9.6446e-03, -1.8003e-02],\n",
      "           [-2.8678e-02, -2.4917e-02,  3.2906e-03]],\n",
      "\n",
      "          [[ 1.1468e-02, -4.7980e-03,  1.2579e-02],\n",
      "           [ 2.1120e-02,  8.5612e-03, -1.0892e-03],\n",
      "           [ 2.3477e-02, -9.8487e-03,  3.8801e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1967e-02, -2.8615e-03, -1.7447e-02],\n",
      "           [-6.6229e-03, -4.9206e-03, -2.7979e-03],\n",
      "           [-1.6349e-02, -7.3894e-03,  6.8684e-03]],\n",
      "\n",
      "          [[-4.6408e-03, -7.1191e-04,  5.1452e-03],\n",
      "           [ 2.2867e-03,  2.1461e-02, -8.6799e-03],\n",
      "           [-2.2517e-02, -1.1249e-02, -7.8780e-03]],\n",
      "\n",
      "          [[ 1.2424e-02, -2.9428e-03,  1.2958e-02],\n",
      "           [-1.5731e-02,  1.7100e-02,  1.1382e-02],\n",
      "           [-1.6170e-02,  1.3800e-02,  2.0412e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.2347e-03,  2.5345e-03,  1.7238e-02],\n",
      "           [ 1.8534e-02, -1.3861e-02,  1.1732e-02],\n",
      "           [ 2.0596e-02, -1.3403e-02,  1.6310e-02]],\n",
      "\n",
      "          [[-8.1203e-03,  8.6344e-03,  2.7050e-02],\n",
      "           [-1.7256e-02, -9.0010e-03,  2.4625e-02],\n",
      "           [-7.1530e-03, -2.3528e-02, -3.9477e-03]],\n",
      "\n",
      "          [[ 3.6741e-02, -1.4971e-02,  1.4574e-02],\n",
      "           [ 1.5494e-02, -7.9764e-03,  1.2573e-02],\n",
      "           [-2.3057e-02, -2.1928e-02,  1.6256e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 5.6263e-04,  2.1321e-02, -7.6356e-03],\n",
      "           [ 1.3878e-02, -1.7734e-02, -3.6847e-02],\n",
      "           [-2.0814e-02, -2.4251e-02, -2.3704e-02]],\n",
      "\n",
      "          [[ 1.5298e-02, -6.4885e-03, -1.0760e-02],\n",
      "           [ 2.3541e-02, -2.0041e-02, -1.1396e-02],\n",
      "           [ 1.5065e-02,  1.2839e-02, -1.1429e-02]],\n",
      "\n",
      "          [[-1.3565e-02, -7.5442e-03, -1.9600e-02],\n",
      "           [ 2.2099e-03,  4.5899e-03, -1.0237e-02],\n",
      "           [-1.0936e-02,  5.4960e-04, -5.4738e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.3057e-02, -3.6976e-02, -3.8822e-02],\n",
      "           [ 4.9560e-03, -1.1739e-03, -1.6368e-02],\n",
      "           [ 6.7852e-04,  1.9589e-03, -7.6229e-03]],\n",
      "\n",
      "          [[ 8.6611e-03, -6.8803e-04, -3.9259e-02],\n",
      "           [-1.4262e-02, -1.8316e-02,  7.4621e-03],\n",
      "           [ 2.1523e-02, -1.6791e-02, -1.2281e-02]],\n",
      "\n",
      "          [[-8.7774e-03, -2.6166e-02, -3.4939e-02],\n",
      "           [-9.7149e-03, -2.3939e-02, -1.1213e-02],\n",
      "           [ 6.1324e-03,  1.2514e-02,  1.5917e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.7662e-02, -5.4284e-03, -2.0394e-03],\n",
      "           [-3.0207e-02,  1.5745e-02, -5.0555e-03],\n",
      "           [-1.8956e-02,  1.1554e-02, -1.1126e-02]],\n",
      "\n",
      "          [[-4.2904e-03,  9.4824e-03,  1.2718e-02],\n",
      "           [-4.9849e-03, -9.2123e-03,  1.6035e-02],\n",
      "           [-3.3131e-02,  4.6232e-03, -9.9828e-03]],\n",
      "\n",
      "          [[ 3.1531e-03, -9.3120e-03, -7.3530e-03],\n",
      "           [-1.4656e-02, -1.2618e-02,  1.4946e-02],\n",
      "           [-1.9644e-02,  2.1893e-03, -2.3609e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.8217e-02, -1.1949e-02, -1.5543e-02],\n",
      "           [ 1.0330e-02, -2.8546e-02,  1.0957e-02],\n",
      "           [ 9.7127e-03, -9.2332e-03,  2.1094e-03]],\n",
      "\n",
      "          [[-6.9153e-03,  2.3162e-03, -8.5816e-03],\n",
      "           [ 8.7355e-03, -5.0849e-03, -8.5940e-03],\n",
      "           [ 1.9419e-02,  5.8685e-03, -2.9546e-03]],\n",
      "\n",
      "          [[-2.9338e-02, -3.0181e-02,  3.0653e-03],\n",
      "           [-1.3217e-02, -2.9441e-02,  8.8723e-03],\n",
      "           [ 1.5085e-02, -1.0475e-02,  4.9049e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.2569e-03, -8.6692e-03, -1.5483e-02],\n",
      "           [-1.5703e-02,  3.0210e-03, -1.7753e-03],\n",
      "           [ 2.2123e-02, -1.1111e-02,  1.7586e-02]],\n",
      "\n",
      "          [[-8.9021e-04, -8.4267e-03,  3.6829e-03],\n",
      "           [ 2.5921e-02,  1.0633e-02, -6.8687e-03],\n",
      "           [ 6.4557e-03,  1.3802e-02, -1.5022e-03]],\n",
      "\n",
      "          [[-4.6241e-03,  1.0835e-02, -1.7881e-02],\n",
      "           [-9.5268e-03, -2.6064e-03,  5.3940e-03],\n",
      "           [ 1.4675e-02, -2.3995e-03, -1.5282e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2583e-02, -1.8408e-02, -9.5982e-04],\n",
      "           [-4.2240e-03,  5.6634e-03, -1.5867e-02],\n",
      "           [-3.4440e-02, -9.3741e-03, -7.7970e-03]],\n",
      "\n",
      "          [[-2.0325e-02, -8.3426e-03, -1.9863e-02],\n",
      "           [-4.3319e-03, -2.0049e-02,  3.4104e-03],\n",
      "           [-2.7361e-02, -1.2616e-02,  7.5111e-03]],\n",
      "\n",
      "          [[-2.7726e-04, -7.4375e-03,  1.7621e-02],\n",
      "           [-2.0939e-02, -6.7105e-03,  7.7028e-03],\n",
      "           [ 8.8599e-03,  1.0275e-02,  1.4017e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.5315e-03, -2.1401e-02,  1.1479e-02],\n",
      "           [-1.6197e-02,  4.8955e-03,  2.2755e-04],\n",
      "           [-4.3467e-03, -5.3570e-03,  1.3696e-02]],\n",
      "\n",
      "          [[-2.5010e-02,  2.1583e-02,  1.8648e-02],\n",
      "           [-1.1764e-02,  1.3174e-02, -5.5180e-03],\n",
      "           [-9.2742e-03, -2.6611e-02, -9.2981e-03]],\n",
      "\n",
      "          [[ 2.3091e-02,  3.3998e-02, -9.1859e-03],\n",
      "           [-6.8658e-03, -1.4268e-02,  1.3677e-02],\n",
      "           [ 1.9714e-02,  1.6537e-02,  2.1231e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3854e-02, -1.7679e-02,  3.3795e-03],\n",
      "           [-6.1913e-03, -1.5718e-02,  4.6752e-03],\n",
      "           [-2.2946e-02, -2.6411e-02,  1.7060e-02]],\n",
      "\n",
      "          [[ 1.9260e-02, -4.8539e-03, -5.5128e-03],\n",
      "           [ 2.0189e-02,  2.2090e-02,  2.6091e-02],\n",
      "           [-2.5992e-02,  1.3945e-03, -1.9464e-02]],\n",
      "\n",
      "          [[ 7.0469e-03, -8.1896e-03,  7.1556e-03],\n",
      "           [ 1.9599e-02, -9.0775e-04,  2.5461e-02],\n",
      "           [-3.2130e-04, -3.3967e-03,  2.2444e-04]]],\n",
      "\n",
      "\n",
      "         [[[-1.0217e-02, -3.8941e-02, -7.9908e-03],\n",
      "           [-1.3169e-02, -9.1814e-04, -1.8958e-02],\n",
      "           [ 3.1121e-02,  3.0427e-02, -1.3666e-02]],\n",
      "\n",
      "          [[-1.2845e-02, -1.0501e-02,  1.0879e-02],\n",
      "           [-1.2953e-02,  6.7504e-03, -1.6187e-02],\n",
      "           [ 6.3996e-03, -7.8022e-03, -2.1579e-02]],\n",
      "\n",
      "          [[ 3.2098e-02, -1.3344e-03,  1.7883e-02],\n",
      "           [ 3.4997e-03,  2.6159e-02, -1.6248e-03],\n",
      "           [ 1.8285e-02, -1.3645e-02, -3.2705e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-9.6484e-03, -1.4400e-02, -1.1089e-02],\n",
      "           [-1.5883e-02,  8.8385e-03,  3.3227e-03],\n",
      "           [-1.8344e-02, -4.0747e-02, -1.9404e-02]],\n",
      "\n",
      "          [[ 2.2767e-02, -3.3214e-03,  2.1591e-02],\n",
      "           [ 1.9309e-02, -7.2755e-03, -1.0695e-02],\n",
      "           [-5.2967e-05,  1.2397e-02,  1.2961e-02]],\n",
      "\n",
      "          [[ 1.4936e-02,  6.1410e-03, -4.8770e-03],\n",
      "           [-5.3758e-03,  2.4684e-02,  6.9775e-03],\n",
      "           [-2.4392e-02, -2.4011e-02,  7.7343e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 5.3953e-05,  5.4791e-03,  6.6505e-03],\n",
      "           [-2.0152e-02, -1.1537e-03, -5.3761e-03],\n",
      "           [-1.3438e-02,  4.0213e-03, -2.3450e-02]],\n",
      "\n",
      "          [[-7.0818e-03,  1.3582e-03,  5.9500e-03],\n",
      "           [ 1.2622e-02, -1.9238e-02, -2.7792e-02],\n",
      "           [-1.4694e-02, -2.0446e-02, -1.2107e-02]],\n",
      "\n",
      "          [[-4.1542e-02, -1.6810e-02, -5.8974e-03],\n",
      "           [ 1.2552e-02, -2.3183e-02, -2.3358e-02],\n",
      "           [-2.7468e-02,  6.4614e-03, -2.0789e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.6056e-02, -3.0933e-02, -3.4247e-02],\n",
      "           [-2.1840e-02, -5.6710e-03, -1.4519e-02],\n",
      "           [ 2.3387e-02, -6.8349e-03,  1.1581e-02]],\n",
      "\n",
      "          [[-1.0081e-02, -1.2368e-02,  7.7481e-03],\n",
      "           [-1.0323e-02, -3.4189e-02, -2.1419e-02],\n",
      "           [-1.9565e-02, -1.0274e-03,  1.1034e-02]],\n",
      "\n",
      "          [[ 1.3292e-02,  3.3352e-02, -4.7467e-03],\n",
      "           [-2.1114e-02,  6.9085e-03,  1.8828e-02],\n",
      "           [ 4.0233e-04, -1.9029e-02, -1.6798e-02]]]]], device='cuda:0')), ('module.down_layers.2.1.conv2.conv.weight', tensor([[[[[ 9.7884e-03,  6.1173e-03,  2.2735e-02],\n",
      "           [ 1.5527e-02,  6.7163e-03,  1.7328e-02],\n",
      "           [ 3.8527e-02,  4.2976e-02,  1.7638e-02]],\n",
      "\n",
      "          [[ 2.7078e-02,  3.6956e-02,  8.5824e-03],\n",
      "           [ 1.4990e-03,  3.7625e-02,  1.5589e-02],\n",
      "           [ 2.4242e-02,  9.4603e-03,  1.8193e-02]],\n",
      "\n",
      "          [[ 1.0354e-02,  2.6307e-02,  1.0568e-02],\n",
      "           [-8.8841e-03,  1.1491e-02, -2.1880e-03],\n",
      "           [ 7.3047e-03,  8.3684e-03,  3.0443e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.0926e-02, -1.7741e-02, -1.2107e-02],\n",
      "           [ 1.3045e-02,  1.7927e-02, -2.0516e-02],\n",
      "           [ 5.8888e-03, -4.5653e-03,  1.5496e-02]],\n",
      "\n",
      "          [[ 8.0391e-04, -1.7425e-02,  1.4330e-02],\n",
      "           [ 7.0534e-03, -9.0010e-03, -5.7698e-03],\n",
      "           [-2.3432e-02,  2.6362e-03,  2.6848e-03]],\n",
      "\n",
      "          [[-1.4639e-02, -9.6768e-03, -2.3540e-02],\n",
      "           [-4.6579e-03,  1.6176e-02, -2.2814e-02],\n",
      "           [ 1.1365e-02,  4.1943e-03, -3.5881e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1041e-02,  7.0939e-03,  2.1722e-02],\n",
      "           [ 2.6648e-03,  4.9104e-04,  1.3272e-02],\n",
      "           [ 1.7559e-02, -6.4591e-03,  2.4029e-02]],\n",
      "\n",
      "          [[ 3.2460e-02,  9.8896e-03,  4.1002e-03],\n",
      "           [-7.1244e-04,  1.6022e-02,  2.8725e-02],\n",
      "           [ 8.8661e-03, -1.4520e-03,  8.2483e-03]],\n",
      "\n",
      "          [[ 1.7685e-02, -5.4210e-03,  2.1629e-02],\n",
      "           [-6.6757e-03, -7.7850e-03,  2.8594e-02],\n",
      "           [ 2.3252e-02, -1.9044e-02, -1.1554e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.6035e-02,  9.1233e-03,  4.9824e-03],\n",
      "           [ 3.1648e-02,  1.6889e-02,  2.9373e-02],\n",
      "           [ 2.3592e-02,  2.2201e-02,  1.2556e-02]],\n",
      "\n",
      "          [[-7.8342e-03, -9.0045e-03, -1.1163e-02],\n",
      "           [-1.4011e-02, -2.1718e-02, -1.6532e-02],\n",
      "           [-7.2631e-03, -9.3040e-03,  1.0999e-02]],\n",
      "\n",
      "          [[-1.8613e-02,  8.0969e-03, -4.0732e-02],\n",
      "           [-4.7643e-03, -7.8055e-03, -1.7931e-02],\n",
      "           [-3.2101e-03, -2.3215e-02, -3.8737e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2028e-02,  1.8443e-02, -9.1739e-03],\n",
      "           [ 2.7485e-02,  5.9992e-03,  6.9912e-03],\n",
      "           [ 6.4062e-03,  9.9727e-03,  1.9987e-02]],\n",
      "\n",
      "          [[-6.1542e-04,  2.6747e-02,  2.2640e-02],\n",
      "           [ 2.5676e-02, -4.4642e-03,  7.4464e-03],\n",
      "           [ 3.3017e-02, -2.2971e-03,  3.2601e-03]],\n",
      "\n",
      "          [[-7.0470e-03,  1.6937e-02, -5.7948e-03],\n",
      "           [-3.3411e-04,  3.8661e-03,  1.9396e-02],\n",
      "           [-1.3725e-02,  9.2521e-03,  1.7369e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.4575e-03,  1.7989e-02,  5.3625e-03],\n",
      "           [ 1.6753e-02,  2.4892e-02,  3.0807e-02],\n",
      "           [ 2.5007e-02,  1.8400e-02,  2.9279e-02]],\n",
      "\n",
      "          [[ 1.3172e-02,  2.2786e-03,  1.0224e-02],\n",
      "           [ 1.6659e-02,  2.6895e-02,  1.2666e-02],\n",
      "           [ 1.4742e-03,  3.3590e-03,  2.2466e-02]],\n",
      "\n",
      "          [[ 9.7647e-03, -8.5864e-03, -2.4898e-03],\n",
      "           [-2.7844e-02, -2.8612e-02, -3.5901e-02],\n",
      "           [-2.2697e-02,  7.3172e-04, -3.5936e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.7816e-04,  2.8983e-02,  2.8969e-02],\n",
      "           [ 6.6708e-03,  1.7806e-02, -1.2683e-02],\n",
      "           [-2.8696e-03,  7.5409e-03, -2.7914e-02]],\n",
      "\n",
      "          [[-1.2986e-02,  4.6843e-03, -1.9007e-02],\n",
      "           [ 1.0636e-02,  1.6887e-02,  1.2073e-02],\n",
      "           [ 2.5554e-02,  2.5144e-03,  2.2620e-02]],\n",
      "\n",
      "          [[-3.1356e-03, -1.3249e-02,  4.1510e-03],\n",
      "           [-1.2760e-02, -1.6830e-02, -1.6193e-02],\n",
      "           [ 2.3339e-02,  7.2018e-03, -1.2655e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.7020e-02,  3.0529e-04,  1.2895e-02],\n",
      "           [-1.7234e-02,  1.2676e-03,  8.2511e-03],\n",
      "           [ 4.1977e-03,  9.1326e-03,  2.4621e-02]],\n",
      "\n",
      "          [[-3.2428e-02, -2.2847e-03, -1.6873e-02],\n",
      "           [ 4.8548e-03, -2.7898e-02,  2.9634e-03],\n",
      "           [ 1.2392e-02, -8.3155e-03,  1.4923e-02]],\n",
      "\n",
      "          [[ 1.2475e-02, -1.6768e-02,  1.0144e-02],\n",
      "           [-7.9530e-03, -1.9786e-02, -8.4145e-03],\n",
      "           [-5.1215e-03,  1.8911e-02,  2.8758e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0698e-02,  3.3957e-02,  2.7583e-02],\n",
      "           [-1.7456e-02,  3.1978e-02,  1.9801e-02],\n",
      "           [ 2.2516e-02,  2.4044e-02,  4.6552e-02]],\n",
      "\n",
      "          [[ 2.6887e-02,  4.0911e-02,  2.8689e-02],\n",
      "           [-5.9570e-03,  4.5474e-02,  1.8407e-02],\n",
      "           [ 2.6677e-02,  5.2958e-02,  3.9255e-02]],\n",
      "\n",
      "          [[ 3.5104e-02,  1.5368e-02,  3.6473e-02],\n",
      "           [ 3.6264e-02,  2.2386e-02,  3.0519e-02],\n",
      "           [ 2.0068e-02,  2.8243e-02,  2.8480e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-7.3907e-03, -1.2550e-04,  1.3555e-02],\n",
      "           [ 1.0501e-03,  8.9277e-03,  3.2612e-02],\n",
      "           [-1.4738e-02,  2.1995e-02,  9.0554e-03]],\n",
      "\n",
      "          [[ 3.4540e-03, -1.5850e-02,  4.1058e-03],\n",
      "           [-1.9756e-02,  1.4687e-02,  2.1518e-02],\n",
      "           [ 3.8238e-03,  2.0349e-02,  1.7013e-03]],\n",
      "\n",
      "          [[ 3.0696e-02, -2.0270e-02, -2.0049e-02],\n",
      "           [ 3.1722e-02, -2.2408e-03, -8.3922e-03],\n",
      "           [-5.6679e-03,  3.0415e-02, -1.1215e-02]]],\n",
      "\n",
      "\n",
      "         [[[-6.2221e-03,  4.3127e-03,  2.0341e-02],\n",
      "           [ 2.7804e-02, -1.2865e-02,  1.4531e-02],\n",
      "           [ 7.6692e-03, -1.8263e-04, -1.2700e-02]],\n",
      "\n",
      "          [[-7.2382e-03,  5.2294e-03,  4.1996e-03],\n",
      "           [ 1.2892e-02,  2.0839e-03,  5.7239e-03],\n",
      "           [ 2.0719e-02,  3.3433e-02,  1.9533e-02]],\n",
      "\n",
      "          [[ 1.6332e-03,  2.5182e-02,  5.5022e-03],\n",
      "           [-1.1480e-03,  2.4429e-02,  5.0638e-03],\n",
      "           [-7.8905e-03,  6.9909e-03, -9.3670e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.1821e-02, -7.8321e-03, -1.1936e-02],\n",
      "           [-2.8247e-02, -3.6956e-02, -3.5727e-02],\n",
      "           [-6.5453e-03, -1.0847e-02, -8.6399e-04]],\n",
      "\n",
      "          [[ 8.5868e-03, -5.2829e-03,  1.0762e-02],\n",
      "           [ 7.2731e-03, -3.8995e-03, -2.2015e-02],\n",
      "           [ 2.4645e-02, -1.3165e-02, -1.2625e-03]],\n",
      "\n",
      "          [[ 1.7882e-02, -9.1056e-03,  1.1303e-02],\n",
      "           [ 2.3111e-02, -9.2739e-03, -1.2782e-02],\n",
      "           [ 7.2249e-03,  2.6683e-02,  1.5134e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 5.9364e-03,  3.6110e-03,  1.6300e-03],\n",
      "           [-1.1717e-02, -2.9861e-03,  3.3350e-03],\n",
      "           [-2.5039e-02,  1.0289e-02, -1.7946e-04]],\n",
      "\n",
      "          [[ 2.4353e-02, -9.7995e-03, -2.0881e-02],\n",
      "           [ 1.2382e-02, -1.7491e-02, -6.5014e-03],\n",
      "           [-2.5088e-02, -7.6374e-04, -3.9057e-03]],\n",
      "\n",
      "          [[-9.6640e-03,  7.3715e-03,  8.1938e-03],\n",
      "           [-9.3973e-03,  1.8669e-02,  1.5661e-02],\n",
      "           [ 2.9073e-02,  2.9420e-03, -6.5344e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2193e-02, -3.1586e-02, -1.2603e-02],\n",
      "           [ 2.0118e-03,  1.6226e-02, -1.2196e-02],\n",
      "           [ 7.7607e-03,  1.8886e-02,  6.3438e-03]],\n",
      "\n",
      "          [[-1.7956e-02,  1.0831e-02,  7.5418e-03],\n",
      "           [ 7.6542e-03,  1.6906e-02, -3.8838e-03],\n",
      "           [-1.8937e-02,  1.8270e-02,  9.8409e-03]],\n",
      "\n",
      "          [[ 1.7879e-02,  2.3333e-02,  1.5674e-02],\n",
      "           [-1.6888e-02, -3.0219e-03, -1.9405e-02],\n",
      "           [-1.0497e-02,  2.4795e-02,  2.6919e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.2639e-02,  2.7763e-02,  2.8640e-02],\n",
      "           [-7.4472e-03,  2.0794e-02, -2.3465e-03],\n",
      "           [ 2.3916e-02,  1.7130e-02,  1.6753e-03]],\n",
      "\n",
      "          [[ 3.2690e-02,  1.6081e-02, -1.4324e-03],\n",
      "           [ 1.3626e-02,  3.9510e-02,  1.1630e-02],\n",
      "           [ 1.1299e-02, -3.4677e-03,  7.6747e-03]],\n",
      "\n",
      "          [[ 1.4034e-02,  7.3969e-03,  4.7257e-03],\n",
      "           [-2.7457e-03,  3.8108e-02,  4.8593e-02],\n",
      "           [ 2.7599e-02,  6.0200e-03,  1.8117e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.0664e-02,  1.3968e-02, -1.4912e-02],\n",
      "           [-1.7350e-02,  8.7899e-05,  1.3738e-03],\n",
      "           [ 2.1678e-02, -2.0262e-02,  1.2511e-02]],\n",
      "\n",
      "          [[-1.5905e-02,  1.4433e-02,  2.4191e-02],\n",
      "           [ 1.6793e-02, -1.2244e-02, -8.8072e-03],\n",
      "           [ 1.6053e-02, -2.7790e-02, -1.2786e-02]],\n",
      "\n",
      "          [[ 8.2832e-03, -1.7997e-02,  9.6896e-03],\n",
      "           [ 1.3189e-02, -1.5109e-02, -2.6375e-02],\n",
      "           [-1.9151e-02, -2.4429e-02,  9.4177e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.6730e-02, -8.9918e-03, -2.4538e-03],\n",
      "           [ 1.3441e-02,  3.2180e-02,  3.2899e-02],\n",
      "           [ 2.9384e-02, -4.1694e-03, -1.3483e-02]],\n",
      "\n",
      "          [[-1.3964e-04, -1.0627e-02,  1.9760e-02],\n",
      "           [ 2.1868e-02,  2.5540e-02,  3.1167e-02],\n",
      "           [-7.8857e-03,  9.1624e-05, -5.9157e-04]],\n",
      "\n",
      "          [[ 4.9329e-03,  1.4386e-02,  7.1524e-03],\n",
      "           [-2.6543e-03,  2.6556e-02, -6.2807e-04],\n",
      "           [ 2.8153e-02,  9.7730e-03,  2.7247e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.1816e-02,  1.0834e-02, -5.1858e-03],\n",
      "           [-2.4940e-02,  8.4947e-03,  2.2366e-02],\n",
      "           [ 2.7252e-02,  1.2806e-02,  1.1417e-02]],\n",
      "\n",
      "          [[ 7.0445e-03,  1.4245e-03,  1.4386e-02],\n",
      "           [-2.4273e-02,  2.3373e-02, -8.1548e-03],\n",
      "           [ 5.3739e-03,  1.4196e-03,  1.2972e-02]],\n",
      "\n",
      "          [[-1.6709e-02, -2.5593e-02, -1.5824e-02],\n",
      "           [ 1.6182e-02,  1.8192e-02, -2.1015e-02],\n",
      "           [-1.6217e-02, -2.2970e-02, -2.1413e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.1365e-02, -2.7788e-02, -1.0675e-02],\n",
      "           [-1.9004e-03,  4.8694e-06, -2.2697e-02],\n",
      "           [-1.2224e-02,  5.4126e-03, -2.7510e-02]],\n",
      "\n",
      "          [[-1.5571e-02, -7.5261e-03, -1.2872e-02],\n",
      "           [-4.8912e-03,  2.0794e-02, -1.2173e-02],\n",
      "           [ 2.5610e-02,  5.3741e-03, -1.4691e-03]],\n",
      "\n",
      "          [[ 2.0073e-02, -7.1082e-03, -1.1732e-02],\n",
      "           [ 3.4908e-02, -1.5511e-02, -6.5151e-05],\n",
      "           [ 1.2824e-02,  7.7481e-03, -2.6400e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2536e-02,  3.9877e-02,  3.8759e-02],\n",
      "           [ 2.1183e-02,  2.9369e-04,  2.5880e-02],\n",
      "           [ 3.9954e-03,  1.3333e-02,  9.1988e-03]],\n",
      "\n",
      "          [[ 3.1580e-02, -6.9671e-03, -3.7169e-03],\n",
      "           [-1.0470e-02,  1.5390e-02, -7.8763e-03],\n",
      "           [ 1.4328e-02,  2.4269e-02,  2.0161e-02]],\n",
      "\n",
      "          [[-5.2275e-03,  5.0716e-04,  2.2580e-02],\n",
      "           [-1.4673e-03,  1.3413e-02,  9.8469e-03],\n",
      "           [ 1.4204e-02,  6.0007e-03, -1.1407e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.5581e-04, -7.9265e-03,  1.3998e-02],\n",
      "           [-2.8388e-02, -1.8877e-02, -4.9293e-03],\n",
      "           [-4.5382e-03,  1.1942e-02,  3.4369e-02]],\n",
      "\n",
      "          [[-8.5123e-03, -1.0233e-02,  2.4345e-02],\n",
      "           [-1.3696e-02, -2.3749e-02,  2.6784e-02],\n",
      "           [-3.6871e-02,  1.8797e-02,  2.5663e-02]],\n",
      "\n",
      "          [[-1.1945e-02,  1.5547e-02,  2.5084e-02],\n",
      "           [-1.7165e-02, -7.7187e-03,  6.2465e-03],\n",
      "           [-1.3938e-03, -2.4586e-03,  1.3024e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.8007e-02, -1.7681e-02,  2.8937e-02],\n",
      "           [ 7.1821e-03, -2.5320e-02,  1.6529e-02],\n",
      "           [-4.7144e-03,  1.1893e-03, -1.9199e-02]],\n",
      "\n",
      "          [[ 1.3813e-02, -1.1690e-02, -2.9547e-03],\n",
      "           [ 1.8251e-02,  7.4817e-03,  1.3614e-02],\n",
      "           [-1.4389e-02,  1.3955e-02, -9.9975e-03]],\n",
      "\n",
      "          [[-1.8928e-02,  4.2463e-03,  1.3881e-02],\n",
      "           [ 6.4577e-03,  4.7699e-03,  9.6299e-03],\n",
      "           [-2.0049e-02, -1.1660e-02,  1.6754e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.8517e-02, -1.4733e-02,  3.7319e-03],\n",
      "           [-6.4231e-04,  1.2901e-02, -2.1787e-02],\n",
      "           [-7.6910e-03,  2.2816e-02,  4.0198e-03]],\n",
      "\n",
      "          [[ 2.2804e-02, -1.5684e-02,  4.9587e-03],\n",
      "           [ 1.7542e-02, -6.9321e-03, -2.3047e-02],\n",
      "           [ 7.7652e-03, -6.8268e-03, -5.7498e-03]],\n",
      "\n",
      "          [[-8.0497e-03,  8.0574e-03,  1.4209e-02],\n",
      "           [-5.6102e-03,  4.3058e-03,  2.5076e-02],\n",
      "           [-8.9782e-03,  1.3119e-02,  1.0249e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2216e-02,  1.7818e-02, -3.8054e-03],\n",
      "           [ 7.6453e-03,  9.7701e-03,  3.0422e-03],\n",
      "           [ 6.2571e-03, -1.2707e-02, -7.7828e-03]],\n",
      "\n",
      "          [[ 1.4149e-02, -1.9155e-02,  4.8649e-04],\n",
      "           [ 3.4277e-03, -9.0136e-03, -3.3395e-03],\n",
      "           [ 4.6410e-03, -1.4751e-02,  5.4836e-03]],\n",
      "\n",
      "          [[-5.6971e-03,  1.4619e-03, -3.0356e-02],\n",
      "           [ 1.0122e-02, -4.5367e-04, -2.5261e-02],\n",
      "           [-8.7370e-03,  1.0020e-02, -3.4885e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.2380e-02, -1.4853e-03, -5.6663e-03],\n",
      "           [ 2.7236e-02,  5.2201e-03,  6.9293e-03],\n",
      "           [ 3.0573e-02,  1.0377e-02, -8.6447e-03]],\n",
      "\n",
      "          [[-1.2331e-02,  6.9255e-03,  4.0399e-03],\n",
      "           [-7.2166e-03,  5.3432e-03, -2.3237e-02],\n",
      "           [ 8.2675e-03, -1.7838e-02, -2.4568e-02]],\n",
      "\n",
      "          [[ 4.8373e-03,  1.5729e-02, -5.0380e-03],\n",
      "           [-1.2837e-02, -4.0470e-03, -2.9044e-02],\n",
      "           [ 3.0422e-02,  3.4248e-03, -2.4262e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.3606e-03,  1.4301e-03, -3.3733e-03],\n",
      "           [-1.5335e-02, -2.0761e-02, -7.6611e-03],\n",
      "           [-2.2447e-02,  1.5373e-03, -1.6051e-03]],\n",
      "\n",
      "          [[-2.3925e-02,  1.1375e-02,  2.3825e-02],\n",
      "           [-1.7133e-02,  1.3495e-02,  1.8069e-02],\n",
      "           [-1.6461e-02,  7.0002e-04, -7.7575e-03]],\n",
      "\n",
      "          [[-9.6470e-03, -9.6257e-05,  2.1285e-02],\n",
      "           [-1.8473e-02,  1.0468e-03,  1.7603e-02],\n",
      "           [-6.1257e-04,  1.9346e-02,  2.1025e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.4987e-02, -2.0602e-03, -1.6914e-03],\n",
      "           [-1.3972e-02,  1.4827e-02,  2.0249e-02],\n",
      "           [ 1.2127e-03, -9.6029e-05, -6.9514e-03]],\n",
      "\n",
      "          [[ 4.2564e-03,  2.6345e-02,  1.6690e-02],\n",
      "           [ 1.5464e-02,  9.4204e-03,  2.2759e-02],\n",
      "           [-2.2440e-03,  1.3869e-02, -1.7631e-03]],\n",
      "\n",
      "          [[ 3.8502e-02,  1.6864e-02,  1.8994e-04],\n",
      "           [ 2.8105e-02,  2.5126e-02,  9.6547e-03],\n",
      "           [ 2.2248e-02,  1.9820e-03, -8.4821e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.1181e-02, -2.2525e-03,  2.1725e-02],\n",
      "           [-2.8037e-02, -1.4840e-02, -1.4069e-02],\n",
      "           [ 1.3279e-02, -5.0944e-03, -2.4775e-02]],\n",
      "\n",
      "          [[ 1.0634e-02, -1.6098e-03,  2.4851e-03],\n",
      "           [-1.0057e-02,  5.2216e-04, -4.6889e-03],\n",
      "           [ 7.5962e-03,  1.8226e-02,  9.4500e-03]],\n",
      "\n",
      "          [[ 1.9087e-02,  1.5715e-03,  4.2063e-03],\n",
      "           [ 4.8137e-03, -1.1349e-02, -1.3053e-02],\n",
      "           [ 8.3555e-03,  4.1996e-03,  2.0413e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.6463e-03, -2.6095e-04, -1.9349e-02],\n",
      "           [-2.6999e-02, -1.2555e-02, -4.0717e-03],\n",
      "           [ 1.7583e-02,  2.4707e-03,  1.2284e-02]],\n",
      "\n",
      "          [[ 1.9556e-02, -2.1543e-02,  1.8683e-02],\n",
      "           [ 2.3786e-03,  2.2497e-03,  1.7734e-02],\n",
      "           [-1.1209e-02, -1.9245e-02, -1.7610e-02]],\n",
      "\n",
      "          [[-1.0884e-02, -2.5654e-03,  2.2879e-02],\n",
      "           [ 6.2979e-04,  6.1262e-04,  2.1707e-02],\n",
      "           [ 1.7900e-02,  5.0257e-04,  1.0216e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.4733e-03,  2.6676e-02, -1.3644e-02],\n",
      "           [ 1.1476e-02, -2.1267e-02,  1.1282e-02],\n",
      "           [ 1.6191e-02,  5.8367e-03, -1.0526e-02]],\n",
      "\n",
      "          [[ 1.2410e-02,  1.4439e-02,  2.5554e-02],\n",
      "           [ 7.3531e-03,  3.4126e-03,  2.5291e-02],\n",
      "           [ 1.7354e-02, -2.1180e-04, -2.8118e-04]],\n",
      "\n",
      "          [[-1.0470e-02, -6.0089e-03,  2.4203e-02],\n",
      "           [-1.3304e-03,  1.8858e-02,  1.4169e-02],\n",
      "           [-2.4292e-02,  2.1247e-02,  1.2010e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.4083e-02,  4.6929e-02,  2.6660e-02],\n",
      "           [ 6.1983e-02,  4.0162e-02,  1.2183e-02],\n",
      "           [ 2.2551e-02,  1.0630e-02,  7.7746e-03]],\n",
      "\n",
      "          [[ 1.8161e-02,  4.6584e-02,  8.6612e-03],\n",
      "           [ 7.7906e-03,  3.6601e-02,  4.5640e-02],\n",
      "           [ 8.6848e-03,  2.9665e-02,  1.4694e-02]],\n",
      "\n",
      "          [[-1.6952e-02,  2.6738e-02,  2.7491e-02],\n",
      "           [-5.2677e-03, -2.0499e-02,  1.5415e-02],\n",
      "           [-9.0319e-03,  2.2249e-02,  3.7340e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.7403e-02, -1.1856e-02,  8.8129e-03],\n",
      "           [-1.8612e-02,  5.5130e-03, -2.4153e-02],\n",
      "           [-2.2144e-02,  7.1496e-03,  3.3347e-03]],\n",
      "\n",
      "          [[-1.0853e-02, -2.3340e-02, -2.2484e-02],\n",
      "           [ 1.4510e-02,  1.6438e-02, -1.7944e-03],\n",
      "           [ 1.2470e-03, -1.3090e-02,  1.4892e-02]],\n",
      "\n",
      "          [[ 2.5148e-02, -8.1530e-03,  9.6810e-03],\n",
      "           [-1.6159e-02,  1.5256e-03,  1.6560e-02],\n",
      "           [ 8.5141e-03,  4.0893e-03, -1.3763e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.5408e-02,  4.0935e-03,  1.0908e-02],\n",
      "           [ 3.2480e-03,  9.5489e-04,  1.1188e-02],\n",
      "           [ 1.4153e-02, -8.1501e-03, -3.1873e-02]],\n",
      "\n",
      "          [[ 7.1412e-03,  7.2654e-03, -1.2222e-02],\n",
      "           [-9.3906e-03,  5.9780e-03, -1.0358e-02],\n",
      "           [-9.6187e-03, -1.1514e-02, -2.6658e-02]],\n",
      "\n",
      "          [[ 1.6165e-02, -4.2462e-03, -5.7638e-04],\n",
      "           [ 1.8030e-03, -2.1259e-02, -6.3595e-04],\n",
      "           [ 1.5951e-02, -1.5408e-02, -5.2901e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.3473e-03, -2.9631e-02, -8.7247e-03],\n",
      "           [-8.0270e-03, -1.6006e-02,  2.4668e-02],\n",
      "           [ 3.5732e-03,  4.7773e-03, -3.0574e-03]],\n",
      "\n",
      "          [[-1.5394e-02, -3.3062e-02,  7.8546e-03],\n",
      "           [-1.9037e-02, -2.6828e-02,  7.0592e-03],\n",
      "           [-1.4437e-02,  5.0463e-03,  9.6218e-03]],\n",
      "\n",
      "          [[-2.6007e-02, -3.5884e-02, -2.7741e-02],\n",
      "           [-4.6255e-02, -4.0117e-02, -9.9217e-03],\n",
      "           [-2.6365e-02, -2.4752e-02, -3.0944e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.9288e-03,  8.0581e-03,  1.5601e-02],\n",
      "           [ 1.8066e-02, -6.5477e-03, -1.1809e-02],\n",
      "           [-1.9132e-02, -1.5396e-02,  4.0419e-03]],\n",
      "\n",
      "          [[-6.4470e-03,  4.7426e-03, -7.7942e-03],\n",
      "           [-4.3614e-03, -5.9193e-03, -3.3009e-03],\n",
      "           [ 2.1308e-02, -1.6428e-02, -1.5265e-02]],\n",
      "\n",
      "          [[ 1.8137e-02, -1.2404e-04,  2.2832e-02],\n",
      "           [-5.2332e-03, -1.6289e-02, -1.4299e-02],\n",
      "           [ 9.4505e-03, -1.2433e-02, -5.6790e-04]]],\n",
      "\n",
      "\n",
      "         [[[-2.4935e-02, -1.6980e-02, -8.2308e-03],\n",
      "           [ 2.3675e-02,  3.7734e-03,  8.7674e-03],\n",
      "           [ 1.2771e-02,  1.2046e-02,  2.6044e-03]],\n",
      "\n",
      "          [[ 8.5167e-03, -1.0795e-03, -1.0336e-02],\n",
      "           [ 1.2752e-02,  1.0611e-03,  5.9410e-03],\n",
      "           [-8.9442e-03, -7.1829e-03, -2.6993e-02]],\n",
      "\n",
      "          [[ 1.5122e-02,  1.1234e-02,  1.6007e-02],\n",
      "           [ 5.8297e-03,  9.4930e-03,  2.5190e-02],\n",
      "           [ 1.0159e-03,  7.6673e-03, -9.6460e-04]]]]], device='cuda:0')), ('module.down_layers.2.2.norm1.weight', tensor([0.9921, 0.9077, 0.9758, 0.9683, 0.9634, 0.9288, 0.9851, 0.9383, 0.9797,\n",
      "        0.9657, 0.9567, 0.9737, 0.9853, 0.9889, 0.9554, 0.9715, 0.9638, 0.9888,\n",
      "        0.9460, 0.9818, 0.9920, 0.9476, 0.9856, 0.9732, 0.9933, 0.9712, 0.9626,\n",
      "        0.9407, 0.9767, 0.9837, 0.9682, 0.9742, 0.9836, 0.9181, 0.9538, 0.9667,\n",
      "        0.9423, 0.9848, 0.9748, 0.9644, 0.9855, 0.9817, 0.8851, 0.9422, 0.9852,\n",
      "        0.9523, 0.9729, 0.9807, 0.9569, 0.9446, 0.9573, 0.9690, 1.0027, 0.9789,\n",
      "        0.9768, 0.9201, 0.9448, 0.9536, 0.9680, 0.9273, 0.9904, 0.9836, 0.9739,\n",
      "        0.9724], device='cuda:0')), ('module.down_layers.2.2.norm1.bias', tensor([-0.0161, -0.0023, -0.0219, -0.0199, -0.0170, -0.0092, -0.0178, -0.0132,\n",
      "        -0.0233, -0.0264, -0.0486, -0.0315, -0.0200, -0.0237, -0.0426, -0.0243,\n",
      "        -0.0171, -0.0271, -0.0018, -0.0207, -0.0235, -0.0264, -0.0219, -0.0181,\n",
      "        -0.0110, -0.0176, -0.0155, -0.0196, -0.0043, -0.0160, -0.0156, -0.0348,\n",
      "        -0.0167, -0.0138, -0.0235, -0.0291, -0.0078, -0.0091, -0.0198, -0.0194,\n",
      "        -0.0204, -0.0361, -0.0264, -0.0230, -0.0166, -0.0161, -0.0137, -0.0332,\n",
      "        -0.0147, -0.0144, -0.0161, -0.0045, -0.0135, -0.0093, -0.0147, -0.0149,\n",
      "        -0.0188, -0.0189, -0.0262, -0.0177, -0.0138, -0.0153, -0.0100, -0.0195],\n",
      "       device='cuda:0')), ('module.down_layers.2.2.norm2.weight', tensor([0.9146, 0.9899, 0.9525, 0.9136, 0.8658, 0.8247, 0.9437, 0.8001, 0.9442,\n",
      "        0.9750, 0.9774, 0.9850, 0.9104, 0.9779, 0.9583, 0.9759, 0.9988, 0.9846,\n",
      "        0.9632, 0.9140, 0.9425, 0.9678, 0.9626, 0.9688, 0.9972, 0.9793, 0.9690,\n",
      "        0.9470, 0.9874, 0.9834, 0.9561, 0.9439, 0.9437, 0.9068, 0.9700, 0.9996,\n",
      "        0.9707, 0.9624, 0.9642, 0.9734, 0.9558, 0.8284, 0.9567, 0.9803, 0.9631,\n",
      "        0.9596, 0.7707, 0.9721, 0.9848, 0.9946, 0.9697, 0.9753, 0.9826, 0.9793,\n",
      "        0.9877, 0.9442, 0.8940, 1.0032, 0.9763, 0.9783, 1.0017, 0.8982, 0.9680,\n",
      "        0.9710], device='cuda:0')), ('module.down_layers.2.2.norm2.bias', tensor([-0.0239, -0.0162, -0.0271, -0.0592, -0.0173, -0.0339, -0.0482, -0.0224,\n",
      "        -0.0506, -0.0356, -0.0417, -0.0348, -0.0360, -0.0371, -0.0460, -0.0371,\n",
      "        -0.0136, -0.0123, -0.0208, -0.0087, -0.0242, -0.0191, -0.0296, -0.0106,\n",
      "        -0.0158, -0.0278, -0.0055, -0.0106, -0.0258, -0.0044, -0.0266, -0.0266,\n",
      "        -0.0094, -0.0125, -0.0197, -0.0047, -0.0111, -0.0086, -0.0306, -0.0043,\n",
      "        -0.0160, -0.0261, -0.0296, -0.0087, -0.0296, -0.0012, -0.0166, -0.0098,\n",
      "         0.0032, -0.0108, -0.0370, -0.0142, -0.0157, -0.0258, -0.0236, -0.0263,\n",
      "        -0.0339, -0.0169, -0.0159, -0.0215, -0.0223, -0.0210, -0.0147, -0.0362],\n",
      "       device='cuda:0')), ('module.down_layers.2.2.conv1.conv.weight', tensor([[[[[ 3.6932e-03, -2.7519e-03,  1.5753e-03],\n",
      "           [-1.8600e-02,  7.4903e-03,  1.4773e-02],\n",
      "           [-1.2196e-02, -8.1515e-03,  1.7520e-02]],\n",
      "\n",
      "          [[-9.0761e-03, -1.3146e-03, -1.4243e-02],\n",
      "           [-1.5357e-02, -3.0171e-02, -1.9232e-02],\n",
      "           [-2.1408e-02, -2.1929e-03, -2.2905e-02]],\n",
      "\n",
      "          [[-7.0583e-03,  2.3984e-02, -1.8832e-03],\n",
      "           [-1.3792e-02,  9.0633e-03,  2.1673e-02],\n",
      "           [-6.6326e-03,  1.9137e-02,  6.1781e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.8786e-03,  3.4556e-03, -1.2166e-02],\n",
      "           [ 1.0336e-02,  4.5211e-03, -7.7347e-03],\n",
      "           [ 7.3919e-03,  2.8370e-03, -8.1870e-03]],\n",
      "\n",
      "          [[ 9.0435e-03,  1.1602e-02, -1.2539e-02],\n",
      "           [ 1.4937e-02,  2.5061e-03, -1.4921e-02],\n",
      "           [ 1.3493e-02,  3.5134e-03, -1.1555e-02]],\n",
      "\n",
      "          [[ 1.0885e-02,  6.6295e-03, -2.0113e-02],\n",
      "           [ 1.1303e-02, -1.7688e-03, -2.3467e-02],\n",
      "           [ 6.5553e-03, -4.4042e-03, -1.5922e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.8015e-03, -5.5141e-03, -7.1083e-03],\n",
      "           [ 2.9297e-03, -9.7257e-03, -5.1612e-04],\n",
      "           [ 1.0330e-02, -2.7093e-02,  3.1814e-04]],\n",
      "\n",
      "          [[-6.9077e-03,  6.6928e-03,  1.8516e-02],\n",
      "           [ 1.2403e-02,  1.3602e-03,  2.2792e-02],\n",
      "           [ 1.7214e-02, -1.2225e-02,  7.2598e-03]],\n",
      "\n",
      "          [[ 2.9571e-02,  2.7104e-02,  2.0770e-02],\n",
      "           [ 2.0683e-02,  9.9680e-03,  8.1876e-03],\n",
      "           [-3.8513e-04,  9.2365e-03,  1.9114e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.8431e-02,  1.6444e-02,  2.1527e-02],\n",
      "           [-5.4336e-03,  2.5849e-02, -8.5033e-04],\n",
      "           [ 2.4689e-02, -4.1249e-04, -1.4906e-02]],\n",
      "\n",
      "          [[-2.6588e-03, -1.1452e-03, -1.5881e-02],\n",
      "           [-2.2225e-03, -5.9099e-03, -2.5290e-02],\n",
      "           [ 4.5113e-03, -2.1378e-03,  9.5997e-03]],\n",
      "\n",
      "          [[ 9.7361e-03, -7.5458e-03, -5.1107e-03],\n",
      "           [-1.4651e-02, -6.3813e-04, -3.1365e-02],\n",
      "           [-1.0995e-02, -2.1592e-02, -3.7947e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.3130e-02,  7.2578e-03,  1.8173e-02],\n",
      "           [ 2.1171e-02,  3.0222e-02,  2.0502e-02],\n",
      "           [ 3.5510e-02,  1.6725e-02, -7.6224e-03]],\n",
      "\n",
      "          [[ 6.6581e-03,  9.7329e-03,  6.1455e-03],\n",
      "           [-4.4645e-03,  2.7900e-02,  2.2444e-02],\n",
      "           [ 2.7566e-02, -4.2210e-03, -2.5572e-03]],\n",
      "\n",
      "          [[-2.2876e-02,  1.0876e-02, -8.1739e-04],\n",
      "           [-9.3487e-03, -1.2103e-02,  7.0697e-03],\n",
      "           [ 8.1920e-03, -3.3918e-03,  2.2886e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.4204e-02, -8.4831e-03, -4.2464e-03],\n",
      "           [-1.3928e-02, -2.0375e-02,  3.6508e-03],\n",
      "           [-3.7152e-02, -1.6649e-02, -5.6594e-03]],\n",
      "\n",
      "          [[-1.4351e-02, -8.7434e-03,  1.4538e-02],\n",
      "           [-3.4487e-02, -1.9120e-02,  5.2634e-03],\n",
      "           [-1.6791e-02, -2.5718e-03,  8.6942e-03]],\n",
      "\n",
      "          [[-8.5166e-04,  1.2351e-02,  2.4844e-02],\n",
      "           [-1.2756e-03,  1.2839e-02,  9.5254e-03],\n",
      "           [-4.1171e-03,  9.7963e-03,  8.7513e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.6325e-03, -6.6898e-04, -4.5105e-03],\n",
      "           [-1.5591e-03,  2.5881e-02, -1.3112e-02],\n",
      "           [-4.6337e-03, -3.5487e-02, -9.4229e-03]],\n",
      "\n",
      "          [[ 5.9634e-04,  2.9577e-04,  1.8857e-02],\n",
      "           [ 9.5376e-03, -1.9510e-03, -1.0957e-02],\n",
      "           [-3.4480e-02, -1.5810e-02, -3.1179e-02]],\n",
      "\n",
      "          [[ 4.6263e-03, -2.6761e-02,  6.5459e-03],\n",
      "           [ 1.1878e-02, -1.3082e-02, -9.1512e-03],\n",
      "           [-5.7719e-03, -3.7430e-02, -1.5507e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.6734e-03, -7.5148e-03,  2.5129e-04],\n",
      "           [ 2.2422e-02,  2.0383e-04, -2.0662e-03],\n",
      "           [ 5.0218e-03,  4.2816e-03,  6.7880e-03]],\n",
      "\n",
      "          [[ 9.5919e-03, -8.2157e-03,  1.6000e-02],\n",
      "           [ 1.0402e-02,  1.6349e-02,  1.0121e-02],\n",
      "           [ 1.3529e-02,  1.9907e-02,  8.5854e-03]],\n",
      "\n",
      "          [[-7.1625e-03, -1.7581e-02,  7.9475e-03],\n",
      "           [ 4.5922e-03, -8.8980e-03,  2.0530e-02],\n",
      "           [ 5.4054e-03,  1.4481e-02,  3.7419e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.4338e-03,  4.5524e-03,  5.4471e-03],\n",
      "           [-2.5297e-02, -2.2068e-02, -6.0127e-03],\n",
      "           [ 1.2952e-02, -2.3128e-02, -1.3546e-02]],\n",
      "\n",
      "          [[ 2.3269e-02,  1.3425e-02,  4.2549e-02],\n",
      "           [ 1.8247e-02,  2.6898e-03,  1.7354e-03],\n",
      "           [-2.7866e-03, -1.1806e-02, -1.7813e-02]],\n",
      "\n",
      "          [[ 4.0556e-03,  2.2547e-02,  2.4237e-02],\n",
      "           [ 8.4785e-04,  1.0662e-02,  3.8185e-02],\n",
      "           [-2.5169e-02, -8.9292e-03, -2.6735e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.9105e-02, -1.5563e-02, -1.7546e-02],\n",
      "           [-1.8338e-02, -1.2435e-02,  1.7243e-02],\n",
      "           [-3.1861e-02,  1.8116e-02, -5.6932e-03]],\n",
      "\n",
      "          [[-2.6988e-02, -2.1852e-02,  1.9664e-02],\n",
      "           [-3.2251e-02,  8.7380e-03,  9.5549e-03],\n",
      "           [-1.2239e-02,  7.4119e-03,  1.5866e-02]],\n",
      "\n",
      "          [[-5.0848e-03, -2.7745e-02, -2.0540e-02],\n",
      "           [-3.9007e-02, -1.6951e-02,  1.7063e-02],\n",
      "           [-9.9544e-03, -2.1899e-04,  1.8820e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.7895e-03, -5.7571e-03, -1.8539e-02],\n",
      "           [ 1.7057e-02,  1.7937e-02, -1.3171e-02],\n",
      "           [ 1.2265e-02, -1.6235e-03, -2.3787e-02]],\n",
      "\n",
      "          [[-5.0322e-03, -7.5585e-03, -2.4935e-02],\n",
      "           [-9.1375e-03, -1.5467e-03,  4.2833e-03],\n",
      "           [ 2.2819e-02,  4.4028e-03, -1.6731e-02]],\n",
      "\n",
      "          [[ 5.4998e-03, -6.3823e-04, -6.2875e-03],\n",
      "           [ 2.1749e-02,  7.0349e-04,  1.1170e-02],\n",
      "           [-1.5254e-03, -7.8967e-03, -9.4952e-03]]],\n",
      "\n",
      "\n",
      "         [[[-7.3163e-03, -1.0422e-02,  5.9353e-03],\n",
      "           [-5.9268e-03, -4.3295e-03,  5.1928e-03],\n",
      "           [ 1.8778e-02, -1.5787e-02,  5.9542e-03]],\n",
      "\n",
      "          [[-1.6390e-02, -1.1273e-02, -1.5031e-02],\n",
      "           [-5.8141e-03,  1.5890e-02,  1.4689e-02],\n",
      "           [ 5.9226e-04, -1.2484e-02, -1.4596e-02]],\n",
      "\n",
      "          [[-1.7193e-02,  1.1490e-02, -1.7152e-02],\n",
      "           [ 1.3331e-02,  2.2407e-02, -8.7625e-04],\n",
      "           [-1.6116e-02, -9.3710e-03, -3.2206e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.5953e-02, -7.1986e-03, -3.3647e-02],\n",
      "           [ 4.3222e-03,  2.9117e-02,  1.5321e-02],\n",
      "           [ 2.1530e-02,  4.7766e-03, -1.0110e-02]],\n",
      "\n",
      "          [[-1.7149e-02, -9.7961e-03, -3.3166e-02],\n",
      "           [-6.4514e-03, -1.2138e-02, -6.6102e-03],\n",
      "           [-1.4147e-02,  1.5886e-02,  1.4373e-02]],\n",
      "\n",
      "          [[-3.7358e-02, -1.3088e-02, -2.4152e-02],\n",
      "           [-1.1835e-02, -1.2393e-02, -5.4459e-03],\n",
      "           [-3.7845e-02,  1.8379e-04, -2.2679e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.3069e-02, -1.3516e-02, -1.2107e-02],\n",
      "           [-1.1561e-02, -1.8671e-02, -8.6836e-05],\n",
      "           [-8.3690e-03, -1.1209e-02, -7.6096e-04]],\n",
      "\n",
      "          [[-2.2481e-02, -2.1308e-02,  4.0505e-03],\n",
      "           [-1.0192e-02, -2.3261e-02, -2.3071e-02],\n",
      "           [-9.4369e-03, -2.5268e-02, -2.2152e-02]],\n",
      "\n",
      "          [[-1.4811e-02, -3.0067e-03,  2.2745e-02],\n",
      "           [ 6.0244e-03, -5.0679e-03,  6.4510e-03],\n",
      "           [-1.9625e-04, -1.9078e-02, -1.2340e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.8805e-02,  1.5492e-02, -1.9293e-02],\n",
      "           [ 2.0625e-02,  2.6629e-02,  1.9808e-02],\n",
      "           [ 7.3734e-03,  5.9070e-03,  2.4604e-02]],\n",
      "\n",
      "          [[-2.5568e-02,  1.3800e-02, -2.5614e-02],\n",
      "           [ 1.6526e-02,  1.9371e-02,  1.2041e-02],\n",
      "           [ 1.3094e-02, -7.4674e-04,  2.2799e-03]],\n",
      "\n",
      "          [[-4.0657e-02, -1.6912e-02,  1.0552e-02],\n",
      "           [-2.0799e-02, -1.2239e-02, -2.2923e-02],\n",
      "           [-2.2284e-04, -1.2348e-02, -1.2104e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-5.6664e-03, -2.9748e-02,  4.4964e-03],\n",
      "           [-1.1868e-02,  1.7919e-02, -1.6370e-02],\n",
      "           [-1.0346e-02,  2.9225e-03,  1.6141e-03]],\n",
      "\n",
      "          [[-3.2587e-02, -3.9062e-02, -3.8788e-02],\n",
      "           [-7.9749e-03, -1.4322e-02, -9.6280e-03],\n",
      "           [-1.2269e-02, -3.7456e-02, -2.2347e-02]],\n",
      "\n",
      "          [[-1.4920e-02, -8.9463e-03, -2.6848e-02],\n",
      "           [-3.2336e-02, -1.9589e-02,  9.2670e-03],\n",
      "           [-1.5282e-02, -1.7456e-02, -2.5502e-02]]],\n",
      "\n",
      "\n",
      "         [[[-6.5146e-03,  2.0945e-02,  3.6588e-02],\n",
      "           [-2.1121e-02,  1.4876e-02,  1.4030e-02],\n",
      "           [-1.2280e-03, -9.9026e-03, -1.2263e-02]],\n",
      "\n",
      "          [[-3.1371e-02,  1.1543e-02,  2.7279e-02],\n",
      "           [ 3.1679e-03, -5.0608e-03, -1.4823e-04],\n",
      "           [-1.5798e-02, -2.4902e-03,  6.0603e-03]],\n",
      "\n",
      "          [[ 2.2027e-02,  2.5911e-02,  2.8250e-02],\n",
      "           [-7.7735e-03,  2.9679e-02,  2.1378e-03],\n",
      "           [-2.1471e-02, -4.4865e-03,  1.0555e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.3531e-02, -6.0729e-04, -6.0094e-03],\n",
      "           [-2.1204e-02,  1.8382e-03, -4.2364e-03],\n",
      "           [ 1.3631e-03,  1.5061e-02,  6.2795e-03]],\n",
      "\n",
      "          [[-3.2848e-02,  2.9612e-03, -1.0399e-02],\n",
      "           [ 2.3870e-03, -2.9888e-03, -7.7131e-03],\n",
      "           [-3.5552e-03,  1.7095e-02, -6.9351e-04]],\n",
      "\n",
      "          [[-3.7165e-02, -3.1440e-02, -3.5765e-02],\n",
      "           [-8.6055e-03,  9.5464e-04, -2.7715e-02],\n",
      "           [-3.7413e-03, -5.3572e-03, -1.8321e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.0695e-02, -1.0359e-02,  1.7297e-02],\n",
      "           [-1.5711e-02, -1.4402e-02,  7.3808e-04],\n",
      "           [-1.5033e-02, -1.2341e-02,  2.0990e-02]],\n",
      "\n",
      "          [[-4.7560e-03,  2.8929e-02, -9.1237e-03],\n",
      "           [-4.3521e-03, -2.5296e-03,  4.4799e-04],\n",
      "           [-1.2607e-02, -4.6082e-04,  4.4037e-03]],\n",
      "\n",
      "          [[ 2.1699e-02, -9.9131e-03, -1.2199e-02],\n",
      "           [-3.4206e-03,  2.4140e-02,  3.0276e-03],\n",
      "           [ 1.5918e-02,  1.9285e-02,  9.3357e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 9.1514e-03,  1.2703e-02,  7.9672e-03],\n",
      "           [ 1.1389e-02,  1.2853e-02,  6.3456e-03],\n",
      "           [ 7.3615e-03,  1.1861e-02,  3.3176e-03]],\n",
      "\n",
      "          [[ 2.1744e-02,  2.5149e-02,  1.1183e-02],\n",
      "           [ 1.5661e-02,  1.9358e-02,  9.0664e-03],\n",
      "           [ 1.2591e-02,  1.5856e-02,  1.3264e-02]],\n",
      "\n",
      "          [[ 2.5230e-02,  1.4118e-02,  8.3150e-03],\n",
      "           [ 2.1550e-02,  1.5650e-02,  4.5449e-03],\n",
      "           [ 9.8748e-03,  8.2325e-03,  4.7557e-03]]],\n",
      "\n",
      "\n",
      "         [[[-9.2754e-03, -1.8091e-02, -1.1842e-02],\n",
      "           [-3.0020e-03,  3.9998e-05,  1.4719e-03],\n",
      "           [-1.3928e-02, -2.4401e-02, -6.8633e-03]],\n",
      "\n",
      "          [[ 9.6558e-03,  2.3064e-02, -6.9282e-03],\n",
      "           [ 1.0387e-02,  1.2079e-02, -1.3670e-02],\n",
      "           [ 1.4767e-02,  4.8834e-03,  1.1679e-02]],\n",
      "\n",
      "          [[ 3.1606e-03,  1.1785e-02, -8.8428e-03],\n",
      "           [ 2.1939e-02,  1.4559e-02,  2.3192e-03],\n",
      "           [ 3.6781e-02,  4.9167e-03, -1.1949e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.9575e-02,  9.7511e-03, -1.0025e-02],\n",
      "           [ 2.7359e-02, -7.5916e-04, -1.7497e-03],\n",
      "           [-1.5806e-02, -1.6896e-02,  2.3076e-02]],\n",
      "\n",
      "          [[ 1.1678e-03, -1.5660e-02, -1.9469e-03],\n",
      "           [-6.5530e-03,  1.6388e-03,  1.0065e-02],\n",
      "           [-1.0894e-02, -2.4650e-02, -1.0982e-02]],\n",
      "\n",
      "          [[-6.4750e-04, -3.6725e-03, -1.4971e-02],\n",
      "           [-2.4656e-02, -1.0710e-03, -1.1388e-02],\n",
      "           [-1.4158e-02, -7.3087e-03,  8.1090e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.0840e-02, -1.7114e-02, -1.6669e-02],\n",
      "           [-1.5345e-02, -1.7408e-03, -2.0835e-03],\n",
      "           [ 1.6264e-02,  7.5050e-03, -2.4010e-02]],\n",
      "\n",
      "          [[ 1.0747e-03, -1.6912e-02,  1.1703e-02],\n",
      "           [ 5.0250e-04, -1.4391e-02,  1.3056e-02],\n",
      "           [ 3.6379e-03, -1.2251e-02, -2.2190e-02]],\n",
      "\n",
      "          [[-1.9805e-02, -2.0392e-02, -1.9495e-02],\n",
      "           [ 1.3220e-02, -2.1671e-02, -1.5675e-02],\n",
      "           [-3.7360e-03,  4.3357e-04, -2.4364e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.1126e-02, -1.9367e-02, -2.0612e-04],\n",
      "           [-2.3746e-02,  4.8664e-03, -1.1026e-03],\n",
      "           [-5.1317e-03, -1.7090e-02, -2.4328e-02]],\n",
      "\n",
      "          [[-4.3057e-03, -1.5939e-02, -1.4415e-02],\n",
      "           [-1.1763e-02, -5.7724e-03,  1.0314e-03],\n",
      "           [-1.0079e-02, -1.7121e-02, -7.0914e-03]],\n",
      "\n",
      "          [[-1.9951e-02, -8.8893e-03, -1.3284e-02],\n",
      "           [-1.9084e-02,  1.1097e-03,  7.5639e-03],\n",
      "           [-1.7893e-02, -1.1762e-02,  5.2234e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.9374e-03, -1.8900e-02, -9.1743e-03],\n",
      "           [-1.3546e-02, -3.0199e-03,  1.9067e-02],\n",
      "           [ 2.2013e-02, -1.1072e-02, -8.9634e-03]],\n",
      "\n",
      "          [[ 1.6731e-02,  1.1665e-02,  8.2055e-03],\n",
      "           [-5.0279e-03, -2.6574e-02, -8.1087e-04],\n",
      "           [-9.6821e-03,  4.2831e-03, -2.5321e-03]],\n",
      "\n",
      "          [[ 1.1533e-02,  5.7770e-03,  2.5427e-02],\n",
      "           [ 2.7754e-02,  6.0395e-03,  9.5078e-03],\n",
      "           [ 2.0643e-02,  3.2295e-02,  1.9407e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.9291e-02,  7.9385e-03,  1.4223e-02],\n",
      "           [ 6.3811e-03,  2.7781e-03, -2.4957e-03],\n",
      "           [ 8.5340e-03,  6.3924e-04, -9.4057e-03]],\n",
      "\n",
      "          [[-8.1391e-03,  2.0536e-02,  1.1674e-02],\n",
      "           [ 2.0514e-03,  1.3752e-02, -1.1169e-03],\n",
      "           [ 1.3147e-02, -1.3005e-02, -1.5211e-02]],\n",
      "\n",
      "          [[-3.0089e-02, -5.7711e-03, -2.1004e-03],\n",
      "           [-1.2297e-02, -2.6944e-02, -2.2566e-02],\n",
      "           [-2.4471e-02, -3.0167e-02, -1.8187e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0801e-02,  8.0305e-03, -1.4516e-02],\n",
      "           [-1.2680e-02, -2.5078e-02,  1.5542e-02],\n",
      "           [-1.3524e-02, -3.3464e-04, -1.1154e-02]],\n",
      "\n",
      "          [[ 7.5708e-03,  1.6568e-02, -1.1073e-02],\n",
      "           [ 2.1016e-02,  5.6827e-03, -2.6344e-02],\n",
      "           [ 7.0450e-03,  9.8197e-03, -1.5288e-02]],\n",
      "\n",
      "          [[-4.3518e-03,  1.9658e-02,  2.6951e-02],\n",
      "           [ 2.5788e-02, -2.0259e-03,  2.2976e-02],\n",
      "           [ 2.3814e-02,  2.0078e-02, -2.1801e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.0546e-03, -1.9184e-02, -1.1694e-02],\n",
      "           [ 7.6785e-04, -1.3599e-02,  9.9723e-03],\n",
      "           [-1.7564e-02, -5.5847e-03,  4.1227e-03]],\n",
      "\n",
      "          [[-6.6002e-03,  1.0500e-02, -8.9123e-03],\n",
      "           [-9.2352e-03, -2.4249e-03,  4.9792e-03],\n",
      "           [-1.9971e-02, -3.7471e-02, -2.1715e-02]],\n",
      "\n",
      "          [[-7.5931e-03, -2.4465e-02,  2.2424e-04],\n",
      "           [-8.8297e-03,  1.7315e-02,  2.0932e-03],\n",
      "           [ 8.1347e-03, -3.3895e-02,  2.2750e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.4642e-02,  5.9761e-03, -7.8413e-03],\n",
      "           [-3.0208e-03,  7.9223e-03, -9.5812e-04],\n",
      "           [-1.1868e-02, -6.7810e-03,  1.1669e-02]],\n",
      "\n",
      "          [[-1.0896e-02,  3.0261e-02, -1.3855e-02],\n",
      "           [-4.2591e-04, -6.6980e-03, -1.0224e-02],\n",
      "           [-4.1648e-03,  1.2625e-02,  2.0214e-02]],\n",
      "\n",
      "          [[-1.0898e-02,  2.1639e-02,  3.6664e-05],\n",
      "           [ 1.5024e-02,  6.7759e-03,  5.9707e-03],\n",
      "           [ 2.7077e-03, -9.5557e-03, -7.7401e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.6519e-02, -2.9822e-02, -8.6812e-03],\n",
      "           [-1.4538e-02, -1.3915e-02,  4.1527e-03],\n",
      "           [ 1.1912e-02,  1.5353e-02,  3.3237e-02]],\n",
      "\n",
      "          [[-1.0359e-02, -1.7911e-02, -8.5319e-03],\n",
      "           [-1.0874e-02, -1.1519e-02,  1.2692e-02],\n",
      "           [ 1.2038e-02,  3.4239e-03,  8.4630e-03]],\n",
      "\n",
      "          [[ 1.1969e-02,  5.7507e-03,  2.4847e-02],\n",
      "           [ 8.1662e-03,  2.7819e-02,  2.6046e-02],\n",
      "           [ 3.2900e-02,  2.6276e-02,  1.9930e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.2498e-02,  5.3161e-03, -1.2650e-02],\n",
      "           [ 1.0734e-02,  3.4050e-04,  1.7895e-02],\n",
      "           [-7.7514e-03,  5.0890e-03, -8.1252e-03]],\n",
      "\n",
      "          [[ 1.5446e-02,  2.4504e-02,  1.1113e-02],\n",
      "           [ 2.7141e-02,  1.5593e-02, -2.2295e-02],\n",
      "           [-2.0980e-02, -2.3650e-02,  5.9356e-03]],\n",
      "\n",
      "          [[ 1.6408e-02,  2.2828e-02, -8.7853e-03],\n",
      "           [ 1.7720e-02, -8.7713e-03, -1.8775e-03],\n",
      "           [ 2.0910e-02,  1.0518e-02, -9.6205e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.7077e-02,  1.0166e-02, -2.6815e-03],\n",
      "           [ 1.1224e-02, -4.9686e-03,  9.0301e-03],\n",
      "           [ 2.3550e-02,  9.2681e-03,  1.6834e-02]],\n",
      "\n",
      "          [[ 2.4897e-03, -8.5546e-03,  1.0188e-02],\n",
      "           [-6.9779e-03,  1.7684e-04,  6.0089e-04],\n",
      "           [ 1.6452e-02,  3.3046e-02,  1.8359e-02]],\n",
      "\n",
      "          [[-6.2432e-03, -1.7406e-03, -3.0082e-03],\n",
      "           [ 1.2268e-02,  8.6560e-03,  8.9201e-03],\n",
      "           [ 2.1850e-02,  2.6392e-02,  1.1187e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.6459e-02, -1.2224e-02,  6.1449e-03],\n",
      "           [-1.4332e-02, -2.4180e-02, -1.5838e-02],\n",
      "           [-1.4528e-02, -3.1792e-02,  3.9941e-03]],\n",
      "\n",
      "          [[-3.5259e-03,  2.2353e-03,  1.3764e-04],\n",
      "           [-7.5522e-03,  8.1081e-04, -2.1098e-02],\n",
      "           [-1.2874e-02, -1.4249e-02, -2.8419e-02]],\n",
      "\n",
      "          [[ 6.7471e-04, -3.9935e-03,  1.3923e-02],\n",
      "           [ 7.1966e-03,  9.1828e-04, -1.6389e-02],\n",
      "           [ 4.6487e-03, -3.3225e-02, -2.3767e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-7.0262e-03,  1.8741e-02, -6.3255e-03],\n",
      "           [ 6.1439e-03, -1.3181e-02, -3.2126e-02],\n",
      "           [ 3.1314e-03, -1.6973e-02,  5.0338e-03]],\n",
      "\n",
      "          [[-2.5520e-02, -1.4703e-02,  1.6258e-02],\n",
      "           [-1.3499e-02,  1.2365e-02, -9.6057e-03],\n",
      "           [-9.4543e-03, -3.1217e-02, -3.4245e-03]],\n",
      "\n",
      "          [[ 2.0336e-02, -7.6876e-03, -1.1257e-02],\n",
      "           [ 7.0507e-03, -1.0513e-02, -4.8247e-03],\n",
      "           [ 4.4178e-03,  4.7084e-03, -3.4659e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.7588e-03, -1.0629e-02, -5.5099e-03],\n",
      "           [-2.4964e-02, -2.3691e-02,  4.8358e-03],\n",
      "           [ 1.9494e-03, -2.1882e-02, -1.5691e-02]],\n",
      "\n",
      "          [[ 4.1471e-03,  7.2875e-03, -1.4290e-02],\n",
      "           [-2.2607e-02, -1.3052e-02, -1.1416e-03],\n",
      "           [ 1.2018e-02,  1.7851e-02, -1.7456e-03]],\n",
      "\n",
      "          [[-6.5991e-03,  1.5519e-02,  9.9520e-03],\n",
      "           [ 4.6333e-03,  2.7436e-02,  1.8147e-02],\n",
      "           [-1.9816e-02,  2.1844e-03, -9.7682e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.7299e-03,  1.3076e-02,  2.6903e-02],\n",
      "           [ 2.2522e-02, -7.7429e-03,  1.6279e-02],\n",
      "           [ 3.5487e-02,  6.2521e-03, -5.9743e-03]],\n",
      "\n",
      "          [[ 1.1062e-02,  1.2275e-03, -1.2934e-02],\n",
      "           [ 2.0205e-02,  1.5251e-02, -4.7741e-03],\n",
      "           [ 2.2478e-02,  4.8073e-03, -1.2213e-02]],\n",
      "\n",
      "          [[ 3.3588e-02, -8.5217e-03, -5.7852e-03],\n",
      "           [-4.4645e-03,  9.6537e-05, -1.8265e-02],\n",
      "           [ 4.3512e-03, -1.3243e-02,  1.0119e-02]]]]], device='cuda:0')), ('module.down_layers.2.2.conv2.conv.weight', tensor([[[[[-1.4058e-02, -1.4242e-02, -6.4519e-03],\n",
      "           [ 3.7750e-03, -6.7726e-03, -1.6873e-02],\n",
      "           [ 1.3192e-02, -8.7675e-03, -1.7659e-02]],\n",
      "\n",
      "          [[-1.1209e-02, -4.6429e-03, -8.8707e-03],\n",
      "           [ 1.1462e-02,  1.1342e-04,  1.7661e-03],\n",
      "           [ 1.9767e-02,  1.0088e-02,  5.9416e-03]],\n",
      "\n",
      "          [[ 2.7359e-02,  2.3941e-02, -2.6885e-03],\n",
      "           [ 2.1187e-02,  2.2243e-02,  2.4318e-02],\n",
      "           [ 2.5635e-02,  5.9579e-03,  1.5930e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.3193e-02,  1.8991e-02,  5.1106e-03],\n",
      "           [-7.0786e-03, -7.6022e-03,  1.0992e-03],\n",
      "           [ 3.8613e-02,  1.3463e-02,  1.6792e-02]],\n",
      "\n",
      "          [[-2.8378e-03,  1.2760e-02,  8.2824e-03],\n",
      "           [ 1.7427e-02,  2.2825e-02, -1.2721e-02],\n",
      "           [ 6.1526e-03,  4.2959e-02,  1.0276e-04]],\n",
      "\n",
      "          [[ 2.0332e-02,  1.7125e-02, -7.0669e-04],\n",
      "           [ 2.7094e-02, -1.5485e-02,  3.9923e-03],\n",
      "           [ 1.2112e-02,  2.2147e-02,  2.0592e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.0488e-02,  2.9838e-02,  2.2699e-02],\n",
      "           [ 5.9645e-03, -1.1806e-02,  8.8880e-03],\n",
      "           [ 3.1604e-03,  1.3037e-02, -9.0487e-03]],\n",
      "\n",
      "          [[ 3.0650e-02,  2.0344e-02,  1.2065e-02],\n",
      "           [ 4.8112e-03,  4.2577e-03,  4.2131e-03],\n",
      "           [ 2.8695e-03, -1.4249e-02,  1.2811e-02]],\n",
      "\n",
      "          [[ 2.7260e-02, -4.6630e-04,  3.1422e-02],\n",
      "           [ 2.3346e-02,  2.6606e-02,  1.2594e-02],\n",
      "           [ 2.4356e-02, -1.1973e-02, -2.5436e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.9392e-02,  8.8277e-04,  5.7718e-03],\n",
      "           [ 2.2871e-02,  1.4631e-02,  7.4817e-03],\n",
      "           [ 2.9954e-02,  9.8638e-03, -1.2791e-04]],\n",
      "\n",
      "          [[ 1.2670e-02,  1.5445e-02, -1.7661e-02],\n",
      "           [ 9.6712e-03, -1.8873e-03, -1.2775e-02],\n",
      "           [ 2.5041e-02,  2.1298e-02, -5.7985e-03]],\n",
      "\n",
      "          [[ 1.7423e-02,  6.8385e-03,  1.2950e-02],\n",
      "           [ 6.0606e-03,  2.8190e-04, -4.1183e-03],\n",
      "           [ 8.1769e-03,  1.7098e-02,  1.0971e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.4417e-02,  9.3269e-03,  6.7470e-03],\n",
      "           [-1.4051e-02, -1.1048e-02, -1.1036e-02],\n",
      "           [-9.3814e-03, -1.2081e-02, -1.6519e-02]],\n",
      "\n",
      "          [[-1.4032e-02, -1.9457e-02,  6.5099e-03],\n",
      "           [-5.9876e-03, -5.6077e-03,  1.3052e-02],\n",
      "           [-7.9926e-03, -1.4802e-02, -1.6024e-02]],\n",
      "\n",
      "          [[-1.2473e-04, -1.4897e-02,  3.7402e-03],\n",
      "           [ 1.5149e-02,  1.6664e-02, -1.5108e-02],\n",
      "           [-9.1609e-03,  1.9747e-02, -5.3300e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.8851e-03,  9.7327e-03,  2.6751e-02],\n",
      "           [-1.4499e-02,  1.4900e-02,  3.2492e-03],\n",
      "           [-1.6231e-02,  7.5983e-03, -5.9489e-03]],\n",
      "\n",
      "          [[-1.0826e-02, -1.6294e-02,  2.1719e-02],\n",
      "           [ 1.9669e-03,  1.6145e-02,  5.8862e-03],\n",
      "           [-2.5755e-02,  6.9418e-03,  1.1834e-02]],\n",
      "\n",
      "          [[-1.1297e-02,  1.4033e-02, -2.2214e-02],\n",
      "           [-2.3947e-02, -2.5233e-02,  4.0471e-03],\n",
      "           [ 8.7666e-03, -2.3980e-02, -2.3975e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-7.7874e-03, -2.7919e-02, -1.2365e-02],\n",
      "           [-1.5826e-02, -1.5682e-02,  1.0186e-02],\n",
      "           [ 2.2722e-03, -4.1104e-03,  1.0296e-02]],\n",
      "\n",
      "          [[ 9.1759e-04, -2.3406e-02, -1.5935e-02],\n",
      "           [ 1.2178e-02,  5.2941e-03,  1.8166e-02],\n",
      "           [ 9.1258e-03,  2.0849e-02,  2.5721e-02]],\n",
      "\n",
      "          [[ 1.6614e-03, -1.8683e-02,  2.2323e-03],\n",
      "           [-1.2858e-02,  2.7508e-03, -1.2000e-02],\n",
      "           [ 2.4802e-02,  6.0232e-03,  8.0573e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4771e-02, -7.5494e-04, -3.0489e-02],\n",
      "           [ 4.6569e-03, -2.3783e-02, -3.3840e-02],\n",
      "           [-5.6822e-03, -1.2840e-02, -6.0800e-03]],\n",
      "\n",
      "          [[ 7.1505e-03, -1.1088e-02, -3.6122e-03],\n",
      "           [ 7.4444e-03, -3.8838e-02,  2.4435e-03],\n",
      "           [-1.7578e-02, -7.2542e-03, -8.8805e-03]],\n",
      "\n",
      "          [[-1.2501e-02, -2.1539e-02, -7.0128e-03],\n",
      "           [-2.5296e-02,  1.3252e-02,  1.6437e-02],\n",
      "           [-7.8610e-03, -2.1455e-02,  5.6006e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 4.1483e-03,  6.4730e-04,  4.7647e-04],\n",
      "           [-4.0003e-03,  1.5571e-03,  3.4055e-03],\n",
      "           [ 1.0680e-02, -5.3491e-03, -1.1634e-02]],\n",
      "\n",
      "          [[-2.5618e-02, -8.4330e-03,  1.7053e-03],\n",
      "           [ 2.4576e-03, -2.4668e-02, -1.4984e-02],\n",
      "           [ 1.4925e-02, -1.1958e-02,  2.4913e-02]],\n",
      "\n",
      "          [[-8.3626e-03,  1.0951e-02, -7.7526e-03],\n",
      "           [ 2.0180e-02,  3.5477e-03, -9.5115e-03],\n",
      "           [ 6.0800e-05, -5.4353e-03,  5.1251e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.1213e-02,  1.3097e-02,  1.7236e-03],\n",
      "           [-4.7789e-03, -8.4056e-04, -1.0860e-02],\n",
      "           [-1.0061e-03, -1.8165e-02,  5.4584e-03]],\n",
      "\n",
      "          [[-6.1573e-03, -1.8661e-02, -1.0048e-02],\n",
      "           [ 2.0794e-03, -1.3664e-02, -1.0097e-02],\n",
      "           [-2.0490e-02, -2.1568e-02, -9.7173e-03]],\n",
      "\n",
      "          [[-2.7025e-02, -2.2365e-02, -1.4160e-02],\n",
      "           [-2.7813e-02, -9.3001e-03,  5.0470e-03],\n",
      "           [-3.3275e-02, -2.7184e-02,  1.7576e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 8.6838e-03,  5.4072e-03, -1.3216e-02],\n",
      "           [-4.7088e-03, -2.8039e-02, -1.3666e-02],\n",
      "           [-6.7848e-03, -2.5182e-02, -2.3927e-02]],\n",
      "\n",
      "          [[ 2.6322e-02, -2.6281e-03, -1.2531e-02],\n",
      "           [-1.8549e-02, -1.3282e-02,  1.5046e-03],\n",
      "           [-8.3746e-03,  8.1088e-04,  7.1083e-03]],\n",
      "\n",
      "          [[ 1.3549e-02,  1.4611e-02,  6.2165e-03],\n",
      "           [-1.3474e-03,  6.9980e-03, -5.3899e-03],\n",
      "           [ 1.0530e-02,  7.6042e-03, -1.6763e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 8.3037e-03, -2.9389e-02, -3.5577e-02],\n",
      "           [-2.8527e-02, -1.8615e-02, -1.8181e-02],\n",
      "           [ 9.0800e-03, -2.3480e-02, -1.0007e-02]],\n",
      "\n",
      "          [[ 3.1533e-02,  1.8496e-02, -2.4872e-02],\n",
      "           [ 1.8130e-02, -8.9941e-03,  1.4032e-03],\n",
      "           [-5.5087e-03, -2.8776e-02, -3.3119e-02]],\n",
      "\n",
      "          [[ 1.1988e-02, -6.8626e-03,  1.0707e-02],\n",
      "           [-1.2455e-02, -3.7796e-03, -1.5415e-02],\n",
      "           [-3.5865e-03,  8.6485e-03,  1.3722e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-9.5438e-03, -1.5901e-02,  5.9270e-03],\n",
      "           [ 8.4795e-03, -1.0800e-02,  2.7265e-03],\n",
      "           [ 1.1609e-02, -2.5348e-02,  9.0015e-03]],\n",
      "\n",
      "          [[ 1.8892e-02, -4.3522e-03,  1.6029e-02],\n",
      "           [ 8.2116e-03,  1.3909e-02,  8.4272e-03],\n",
      "           [-5.8698e-03, -1.4962e-02,  1.0907e-02]],\n",
      "\n",
      "          [[ 6.9977e-03,  2.0928e-02, -3.2180e-03],\n",
      "           [ 1.5169e-02, -1.0182e-02, -6.8731e-03],\n",
      "           [-8.7731e-04, -6.0322e-03,  9.5552e-03]]],\n",
      "\n",
      "\n",
      "         [[[-8.4306e-03,  2.3756e-03, -3.5082e-03],\n",
      "           [ 3.4431e-03, -2.3175e-02,  5.2872e-03],\n",
      "           [ 1.3555e-02, -2.0713e-02,  1.9739e-02]],\n",
      "\n",
      "          [[-2.1113e-02,  1.9092e-02,  2.0124e-02],\n",
      "           [-2.3892e-02, -1.2252e-02,  2.3548e-02],\n",
      "           [ 1.1764e-02, -3.5918e-03,  2.2831e-02]],\n",
      "\n",
      "          [[ 1.2216e-02, -2.9838e-03,  3.0563e-02],\n",
      "           [ 5.8472e-03, -1.6865e-02,  1.4793e-02],\n",
      "           [ 1.9207e-02,  8.5005e-03, -8.9901e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.5416e-02,  6.1920e-04,  2.8167e-02],\n",
      "           [-2.1144e-02, -1.5698e-02,  9.3109e-03],\n",
      "           [-2.1748e-02, -1.5979e-03,  2.2613e-02]],\n",
      "\n",
      "          [[ 1.6909e-02, -5.2306e-03, -5.6644e-03],\n",
      "           [ 1.0156e-03, -1.0600e-02, -9.8527e-03],\n",
      "           [ 1.5203e-02,  2.7619e-02,  1.5408e-02]],\n",
      "\n",
      "          [[-1.3779e-02, -6.8096e-03,  2.5747e-02],\n",
      "           [ 1.7617e-02,  2.0861e-02,  1.0043e-02],\n",
      "           [ 1.9438e-02, -3.0410e-03,  1.7402e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.2413e-02, -2.6910e-02, -2.6008e-02],\n",
      "           [ 1.6891e-02, -1.9014e-02, -3.2590e-02],\n",
      "           [ 1.5155e-02, -3.2641e-02, -3.2951e-02]],\n",
      "\n",
      "          [[ 6.2081e-03, -6.2628e-04, -2.8433e-02],\n",
      "           [ 1.6156e-02, -1.9025e-02, -7.9081e-04],\n",
      "           [ 1.6311e-02,  1.0046e-02, -1.6680e-02]],\n",
      "\n",
      "          [[-1.8152e-02, -3.1709e-02, -2.4112e-02],\n",
      "           [-1.9846e-02, -1.5494e-03,  7.2717e-03],\n",
      "           [ 4.2784e-03, -1.8202e-02,  9.6901e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.7377e-03,  1.1480e-02,  9.8809e-03],\n",
      "           [ 1.2327e-02, -1.8650e-02, -8.7905e-03],\n",
      "           [-1.3900e-02, -1.5345e-02,  1.5878e-02]],\n",
      "\n",
      "          [[ 7.9929e-03, -1.0929e-02,  2.0962e-04],\n",
      "           [ 1.5723e-02, -1.7587e-02,  1.9883e-02],\n",
      "           [-1.5175e-02, -1.4078e-02, -1.1874e-02]],\n",
      "\n",
      "          [[ 7.4922e-03,  6.4670e-03,  2.3489e-02],\n",
      "           [ 2.2629e-03,  1.9280e-02,  5.7883e-03],\n",
      "           [-8.4262e-03, -1.1397e-02,  1.9705e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.6065e-03, -1.0545e-02,  8.4070e-03],\n",
      "           [-1.9210e-02,  2.3691e-03, -2.4822e-02],\n",
      "           [-3.5920e-03, -1.4854e-03, -1.8079e-02]],\n",
      "\n",
      "          [[ 2.5096e-02,  2.3249e-02,  1.7004e-02],\n",
      "           [-1.0759e-02, -2.7207e-03, -9.4645e-03],\n",
      "           [ 2.2471e-02,  8.2667e-03,  1.2236e-02]],\n",
      "\n",
      "          [[-1.0289e-02,  2.7454e-03,  1.1347e-02],\n",
      "           [ 1.4583e-02,  1.2664e-02, -1.8195e-02],\n",
      "           [ 2.3114e-02,  1.6641e-02, -8.2992e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.9888e-03, -6.3868e-03, -1.0422e-02],\n",
      "           [-1.4404e-02, -1.3100e-02,  1.3280e-03],\n",
      "           [-1.6969e-02,  9.2738e-03, -7.5663e-03]],\n",
      "\n",
      "          [[-1.6162e-02,  1.9822e-02, -1.5634e-02],\n",
      "           [-2.1298e-02,  5.3093e-03,  4.1214e-03],\n",
      "           [ 1.1954e-02,  9.2072e-03, -2.2977e-02]],\n",
      "\n",
      "          [[ 7.4150e-03,  1.3417e-02, -8.5210e-03],\n",
      "           [-1.4945e-02,  1.1105e-02,  8.4980e-03],\n",
      "           [-1.9782e-02, -4.4465e-03,  4.7620e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 6.5747e-03,  2.3143e-02,  7.1277e-03],\n",
      "           [ 1.9158e-02,  1.5555e-02,  4.2548e-03],\n",
      "           [ 3.2220e-04,  1.5593e-02,  1.0535e-02]],\n",
      "\n",
      "          [[-5.7841e-03,  2.1475e-02, -6.6198e-03],\n",
      "           [ 2.0588e-02, -2.7241e-03,  7.5224e-03],\n",
      "           [ 2.0798e-02,  4.9576e-04, -4.8803e-04]],\n",
      "\n",
      "          [[-1.6302e-04,  5.8084e-03,  1.0819e-02],\n",
      "           [ 1.2790e-02,  9.3248e-03,  1.0724e-02],\n",
      "           [-1.0338e-02, -5.3450e-03, -4.5795e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.8650e-03,  4.3951e-03,  1.9680e-02],\n",
      "           [-7.2104e-03,  2.8767e-02,  3.9005e-02],\n",
      "           [ 1.3146e-02,  2.1635e-02,  4.3905e-02]],\n",
      "\n",
      "          [[-2.8648e-02, -1.7158e-02, -3.7032e-03],\n",
      "           [-2.4438e-02, -2.7942e-03,  1.4925e-02],\n",
      "           [ 1.9735e-02,  1.9376e-02,  1.2268e-02]],\n",
      "\n",
      "          [[-3.7108e-02, -2.7232e-02,  9.6523e-03],\n",
      "           [-1.5241e-02,  1.0939e-02,  2.3825e-02],\n",
      "           [-1.4321e-02, -6.2510e-03, -6.1147e-04]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-4.0113e-03,  1.6360e-03, -7.1788e-04],\n",
      "           [ 8.6379e-04, -1.9245e-02, -1.0622e-03],\n",
      "           [-1.1801e-02, -2.8841e-03,  1.0288e-02]],\n",
      "\n",
      "          [[-2.1555e-02, -7.4417e-04,  2.7177e-04],\n",
      "           [ 2.7768e-04,  2.7149e-03,  9.8675e-03],\n",
      "           [ 2.0402e-03,  1.5429e-02,  1.0762e-02]],\n",
      "\n",
      "          [[-2.0209e-02, -1.5160e-02,  1.1932e-02],\n",
      "           [ 1.1566e-02,  1.3448e-02,  2.3133e-02],\n",
      "           [ 6.0162e-03,  3.0504e-02,  2.3019e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.1707e-04, -3.1060e-04, -1.5427e-02],\n",
      "           [ 1.0640e-02, -1.0061e-02,  6.9845e-03],\n",
      "           [ 1.6316e-02,  3.6807e-03,  5.9503e-03]],\n",
      "\n",
      "          [[-2.8546e-02,  6.1552e-03, -1.6349e-02],\n",
      "           [-2.9239e-02,  3.2079e-03, -1.8396e-02],\n",
      "           [ 4.0105e-03,  7.1330e-03, -9.1508e-03]],\n",
      "\n",
      "          [[-2.5524e-02,  1.9323e-02,  1.7479e-02],\n",
      "           [-4.1932e-03, -1.0517e-02, -7.4326e-03],\n",
      "           [-7.2129e-03, -1.5543e-02, -2.8890e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 6.0639e-03, -2.7230e-03,  1.3999e-02],\n",
      "           [ 2.6813e-03, -1.5627e-02,  7.4754e-03],\n",
      "           [-3.4697e-04, -8.8288e-03, -1.5532e-02]],\n",
      "\n",
      "          [[-7.8361e-03,  1.0538e-02, -2.7482e-02],\n",
      "           [-3.1456e-02, -3.3897e-02,  5.1859e-04],\n",
      "           [-1.9440e-04, -1.8979e-02, -1.6762e-02]],\n",
      "\n",
      "          [[-1.1159e-03,  7.5143e-03, -3.3473e-02],\n",
      "           [-2.1943e-02, -4.1292e-02, -6.4160e-03],\n",
      "           [-6.2798e-03, -2.7294e-02, -3.9460e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.5584e-03, -9.2283e-03,  5.1245e-03],\n",
      "           [-2.4807e-03,  4.5596e-03, -1.1195e-03],\n",
      "           [-1.4394e-02, -8.0459e-03,  4.9664e-03]],\n",
      "\n",
      "          [[-1.3909e-02, -6.2242e-03,  8.7693e-03],\n",
      "           [-3.4662e-03, -2.1486e-02,  2.4887e-03],\n",
      "           [-1.2161e-02,  6.5620e-03,  9.4475e-04]],\n",
      "\n",
      "          [[ 7.2220e-03,  1.6194e-02, -1.3752e-02],\n",
      "           [-5.0641e-03, -4.5622e-03, -5.6522e-03],\n",
      "           [ 1.2244e-02, -2.2190e-02, -2.9111e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.7458e-02,  2.5769e-02, -4.1948e-03],\n",
      "           [-1.0105e-02,  1.1896e-02,  2.2487e-02],\n",
      "           [-3.2272e-02, -3.4231e-02, -1.9679e-02]],\n",
      "\n",
      "          [[ 2.8936e-02,  2.3423e-02, -1.8559e-04],\n",
      "           [-1.5563e-02, -1.2402e-02,  9.9377e-03],\n",
      "           [-3.5527e-02,  1.1053e-02, -1.9177e-02]],\n",
      "\n",
      "          [[-9.8449e-03,  2.0014e-02,  2.6146e-02],\n",
      "           [ 2.6951e-03, -6.1737e-03,  1.8944e-02],\n",
      "           [-1.0679e-02, -2.6414e-02, -1.1974e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1758e-03, -1.2846e-02, -2.2995e-03],\n",
      "           [-1.6218e-02,  1.8426e-02,  3.0793e-02],\n",
      "           [ 1.5713e-02,  1.6648e-02,  2.4350e-02]],\n",
      "\n",
      "          [[-1.2770e-02, -2.5750e-02,  1.4766e-02],\n",
      "           [-7.2536e-03,  2.6328e-02,  3.0400e-02],\n",
      "           [-1.6224e-02, -1.0208e-03,  1.3714e-02]],\n",
      "\n",
      "          [[-1.5116e-03, -3.4995e-03, -5.8553e-03],\n",
      "           [ 4.4386e-04, -8.0243e-03, -1.6998e-02],\n",
      "           [ 1.5499e-02,  1.4368e-02, -1.9465e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.9383e-02, -1.0474e-02, -1.4127e-02],\n",
      "           [-9.6303e-03,  1.2450e-04, -8.7738e-03],\n",
      "           [ 9.8703e-03,  3.1425e-03,  1.9608e-02]],\n",
      "\n",
      "          [[-5.2152e-03, -1.4376e-04,  1.3989e-02],\n",
      "           [ 5.1789e-03, -1.7068e-02,  2.1429e-02],\n",
      "           [-1.0030e-02,  2.9782e-03, -3.9792e-03]],\n",
      "\n",
      "          [[-2.6555e-02, -1.5299e-02,  1.6257e-02],\n",
      "           [ 1.3620e-02,  7.0205e-03,  2.5928e-03],\n",
      "           [ 3.3396e-02,  2.2281e-02,  9.4476e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.4868e-03,  2.5956e-02, -4.0369e-03],\n",
      "           [ 2.0889e-02, -1.1517e-02, -5.1174e-03],\n",
      "           [-1.0616e-02, -1.2324e-02,  3.0961e-03]],\n",
      "\n",
      "          [[-1.1770e-03,  4.4707e-03,  3.0792e-02],\n",
      "           [-1.0975e-02,  1.5016e-02,  2.9345e-03],\n",
      "           [-5.4435e-03, -9.7885e-03,  2.0409e-02]],\n",
      "\n",
      "          [[-9.3205e-03,  1.5810e-02,  1.6918e-02],\n",
      "           [-1.1965e-02,  1.2437e-02,  2.2525e-02],\n",
      "           [ 1.7637e-02, -1.6046e-02, -1.6172e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.0866e-02,  2.6967e-02, -8.3428e-04],\n",
      "           [ 2.8974e-02,  2.4212e-02,  1.1920e-03],\n",
      "           [-4.1262e-03,  4.2579e-03,  2.1656e-03]],\n",
      "\n",
      "          [[ 8.2770e-03,  3.4216e-02,  2.2029e-02],\n",
      "           [-5.1093e-03, -6.1915e-03,  6.9226e-03],\n",
      "           [ 2.0024e-02,  1.3356e-02, -2.3076e-03]],\n",
      "\n",
      "          [[-9.2300e-03,  1.3178e-02, -1.9079e-02],\n",
      "           [-1.6710e-02,  2.2355e-02, -1.5505e-02],\n",
      "           [ 1.5285e-02, -2.6098e-03,  2.7217e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.0993e-03, -3.6351e-02, -8.5439e-03],\n",
      "           [-2.2091e-03, -2.7127e-02, -8.8127e-03],\n",
      "           [-4.3193e-02, -4.4039e-02, -2.5615e-02]],\n",
      "\n",
      "          [[-1.7360e-02, -7.4049e-03,  3.4522e-03],\n",
      "           [ 2.4126e-03,  5.1215e-04, -1.9425e-02],\n",
      "           [-3.1355e-03, -1.8217e-02,  4.5027e-03]],\n",
      "\n",
      "          [[-9.0778e-03,  8.6559e-03,  5.2420e-02],\n",
      "           [ 7.0107e-04,  1.5134e-02,  1.7423e-02],\n",
      "           [-9.1702e-03, -6.0852e-03,  1.5139e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.5589e-03, -2.1336e-02, -1.8475e-02],\n",
      "           [ 1.2692e-02,  2.6493e-02, -8.6061e-03],\n",
      "           [ 4.2025e-02,  3.3670e-02, -6.1485e-03]],\n",
      "\n",
      "          [[ 2.9202e-03, -2.3612e-02, -1.0161e-02],\n",
      "           [ 5.5583e-03,  1.6707e-03, -1.8753e-02],\n",
      "           [ 7.1866e-03,  9.9990e-03, -3.8309e-03]],\n",
      "\n",
      "          [[ 2.1953e-02, -2.1106e-02,  5.6952e-03],\n",
      "           [ 3.2780e-02,  9.3431e-03, -1.6887e-02],\n",
      "           [ 2.5485e-02,  1.0866e-02,  8.0542e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.9475e-03,  6.5383e-03, -6.6025e-03],\n",
      "           [-3.8477e-02,  2.8881e-03, -4.2399e-02],\n",
      "           [-2.3789e-02, -4.1333e-02, -1.9309e-02]],\n",
      "\n",
      "          [[ 9.9118e-03,  6.2333e-03, -1.1502e-02],\n",
      "           [ 5.7081e-03,  8.0387e-03, -2.0590e-02],\n",
      "           [-3.2413e-02, -6.4322e-03, -2.8162e-02]],\n",
      "\n",
      "          [[ 2.6555e-02,  9.9465e-03,  3.1853e-02],\n",
      "           [ 7.3019e-03,  1.8838e-02,  2.9735e-04],\n",
      "           [-1.7637e-02,  1.8531e-02, -2.8084e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.4124e-02,  2.3617e-02,  1.0372e-02],\n",
      "           [ 4.6806e-02,  5.8098e-03,  7.6471e-03],\n",
      "           [ 1.3857e-02,  2.8276e-02, -4.1744e-03]],\n",
      "\n",
      "          [[ 8.3702e-03, -9.0847e-03, -1.4307e-02],\n",
      "           [-1.5662e-03, -9.1653e-03,  3.8052e-03],\n",
      "           [ 1.5979e-02, -1.5016e-02, -2.2032e-02]],\n",
      "\n",
      "          [[ 5.6958e-04,  3.8663e-03,  1.0671e-02],\n",
      "           [ 6.7436e-03, -1.9833e-02, -7.1090e-03],\n",
      "           [ 2.5723e-03, -2.0347e-02, -2.6408e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.3745e-03, -2.4208e-02, -3.3726e-03],\n",
      "           [ 7.8366e-03, -2.0011e-02, -1.2721e-02],\n",
      "           [ 1.0802e-02, -1.3238e-02, -3.8460e-02]],\n",
      "\n",
      "          [[ 2.2772e-03, -3.1608e-03,  7.2084e-03],\n",
      "           [ 1.6347e-02,  4.9187e-03,  4.5059e-03],\n",
      "           [-1.7865e-02, -1.3210e-02,  5.2389e-04]],\n",
      "\n",
      "          [[-1.5108e-02,  7.2029e-03, -1.6848e-02],\n",
      "           [ 2.7191e-02,  4.3435e-02,  2.2006e-02],\n",
      "           [ 3.2465e-02,  9.9398e-03,  3.5434e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.5399e-04,  8.4774e-03,  2.8899e-02],\n",
      "           [ 3.4585e-02,  1.9779e-02,  1.4282e-02],\n",
      "           [-1.2929e-02,  9.5885e-03, -3.6329e-03]],\n",
      "\n",
      "          [[-9.1765e-03,  6.7677e-03, -1.7929e-02],\n",
      "           [ 1.4228e-02, -2.4200e-02,  2.5636e-03],\n",
      "           [ 7.6151e-03,  2.7949e-03, -1.8339e-02]],\n",
      "\n",
      "          [[-2.8205e-02, -3.7747e-02,  8.0786e-03],\n",
      "           [-2.3928e-03, -1.1150e-02, -1.0239e-03],\n",
      "           [-4.2976e-03, -3.6331e-02,  9.9958e-03]]]]], device='cuda:0')), ('module.down_layers.3.0.conv.weight', tensor([[[[[-1.8177e-02,  1.9527e-02,  1.5981e-02],\n",
      "           [ 2.3054e-02,  2.0242e-02, -1.9474e-02],\n",
      "           [-1.5648e-03, -1.9340e-02,  6.9331e-03]],\n",
      "\n",
      "          [[-2.1739e-02, -1.4149e-03, -3.3918e-03],\n",
      "           [-2.4122e-02,  5.1365e-04, -8.1213e-03],\n",
      "           [ 4.0312e-03,  1.5561e-03,  2.3866e-02]],\n",
      "\n",
      "          [[ 7.8658e-03, -4.0757e-03,  1.7247e-03],\n",
      "           [ 8.3891e-03, -1.2552e-02,  1.3245e-02],\n",
      "           [ 3.1134e-03,  1.4712e-02,  1.5305e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.1084e-02, -2.8185e-02, -2.5052e-02],\n",
      "           [-3.8262e-03, -1.6816e-02,  1.1086e-02],\n",
      "           [-1.7214e-03, -6.2971e-03, -3.2594e-02]],\n",
      "\n",
      "          [[-2.4219e-02, -2.6746e-02, -3.4896e-02],\n",
      "           [-2.5350e-03, -2.4365e-03, -1.4274e-02],\n",
      "           [-2.3225e-02, -2.0079e-02,  5.7868e-03]],\n",
      "\n",
      "          [[ 1.0615e-02, -2.5830e-02, -2.8074e-02],\n",
      "           [ 1.6178e-02, -8.6073e-03, -2.1981e-02],\n",
      "           [-1.3610e-02,  2.0523e-02,  1.6890e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.5478e-02,  1.3095e-02,  7.1440e-03],\n",
      "           [-2.8096e-03,  2.0237e-02, -1.0656e-02],\n",
      "           [-1.3985e-02, -1.8583e-02, -2.3762e-03]],\n",
      "\n",
      "          [[-4.4836e-03, -1.5814e-02, -4.8533e-03],\n",
      "           [ 1.8850e-02,  2.3650e-02, -4.1897e-03],\n",
      "           [ 2.4458e-02, -8.9471e-03, -1.4963e-02]],\n",
      "\n",
      "          [[-1.1766e-02,  2.2111e-02,  1.2568e-02],\n",
      "           [-6.3288e-03,  2.2938e-03,  2.0040e-03],\n",
      "           [-2.4855e-03,  5.3096e-03,  1.4958e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.2202e-02,  8.5289e-03,  4.2970e-04],\n",
      "           [ 2.0194e-02, -7.9757e-03,  6.1581e-03],\n",
      "           [-1.2554e-02, -2.0151e-02, -2.9014e-02]],\n",
      "\n",
      "          [[ 2.3381e-02,  2.0944e-02, -1.3156e-02],\n",
      "           [-9.6279e-03,  1.2437e-02,  1.6357e-02],\n",
      "           [ 4.5824e-03,  2.3097e-02, -8.6895e-03]],\n",
      "\n",
      "          [[-1.2724e-02, -1.2177e-02, -1.4258e-02],\n",
      "           [-1.0514e-03, -2.2917e-03,  1.6961e-02],\n",
      "           [ 9.2516e-03,  3.5330e-04,  1.9492e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.6088e-02,  2.7540e-02,  4.7549e-03],\n",
      "           [ 3.6134e-03, -9.5660e-03, -1.0000e-02],\n",
      "           [-1.9021e-02,  2.9311e-03, -1.7939e-02]],\n",
      "\n",
      "          [[ 8.7874e-03,  7.7410e-03,  4.4440e-03],\n",
      "           [ 1.3646e-02, -5.6271e-03, -1.5743e-02],\n",
      "           [-1.9642e-02,  8.2900e-03,  6.9063e-03]],\n",
      "\n",
      "          [[ 1.0571e-02, -1.1144e-02,  7.7835e-03],\n",
      "           [-8.8574e-03,  1.2488e-02, -7.1591e-03],\n",
      "           [-9.9181e-03,  3.1937e-03,  6.6229e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2163e-02, -4.7425e-05,  1.0700e-04],\n",
      "           [-2.5417e-02,  7.1995e-03,  8.0362e-03],\n",
      "           [-1.7406e-03, -7.8902e-03,  1.9488e-02]],\n",
      "\n",
      "          [[ 5.2346e-03, -2.6565e-02,  1.6496e-02],\n",
      "           [-1.1106e-02, -1.9951e-02, -1.3971e-03],\n",
      "           [-7.0001e-03, -1.7663e-02,  1.1075e-02]],\n",
      "\n",
      "          [[ 1.4289e-02,  2.0835e-03,  1.4574e-02],\n",
      "           [-2.7642e-02, -5.9472e-03,  1.5523e-02],\n",
      "           [-9.5213e-03, -7.5842e-03,  2.0416e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.0049e-02,  4.5998e-03, -1.7621e-02],\n",
      "           [ 2.2029e-02,  5.7341e-03, -2.1547e-02],\n",
      "           [ 2.9879e-03,  1.4058e-02,  1.8381e-02]],\n",
      "\n",
      "          [[ 1.2687e-02, -1.7493e-02, -3.7137e-03],\n",
      "           [-6.8560e-03, -3.5947e-03, -8.0415e-03],\n",
      "           [-6.2741e-03,  4.5605e-03, -2.5636e-02]],\n",
      "\n",
      "          [[-1.3114e-02, -9.7589e-03, -3.2429e-02],\n",
      "           [-1.8431e-03, -2.9370e-02, -1.7480e-02],\n",
      "           [-1.6158e-02,  2.1226e-02, -1.9072e-02]]],\n",
      "\n",
      "\n",
      "         [[[-9.9450e-03, -1.9604e-02, -1.3101e-02],\n",
      "           [-3.6599e-02, -3.8341e-02, -3.8089e-02],\n",
      "           [-6.8250e-03, -1.8470e-02, -3.5452e-02]],\n",
      "\n",
      "          [[-2.9660e-02, -2.9827e-02, -7.2658e-03],\n",
      "           [ 6.7713e-03, -1.0107e-02, -3.3680e-02],\n",
      "           [-2.4019e-02, -2.9070e-02, -2.9508e-02]],\n",
      "\n",
      "          [[-2.0398e-02, -2.2868e-03, -6.1055e-03],\n",
      "           [-3.7637e-02, -2.4747e-02, -2.3235e-02],\n",
      "           [-4.2171e-02, -2.0645e-02, -6.4483e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.3112e-03,  1.9026e-02,  1.0792e-02],\n",
      "           [ 1.3225e-02,  2.0891e-02, -1.1940e-02],\n",
      "           [ 1.4242e-02,  1.7275e-03, -5.6905e-03]],\n",
      "\n",
      "          [[ 7.8530e-03, -8.5359e-03,  1.0902e-02],\n",
      "           [-1.7669e-03, -1.5909e-02,  2.3293e-04],\n",
      "           [-8.6134e-03, -1.2391e-02, -2.6889e-02]],\n",
      "\n",
      "          [[-4.5312e-03,  4.4100e-03, -2.1377e-02],\n",
      "           [-1.0691e-02, -7.2822e-06,  1.7929e-02],\n",
      "           [-2.0938e-02, -3.7178e-03,  9.7035e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.8936e-02,  1.3411e-02, -4.9505e-03],\n",
      "           [-4.0916e-03, -9.4605e-03, -1.1264e-02],\n",
      "           [ 8.2757e-03, -2.3610e-02, -2.1905e-02]],\n",
      "\n",
      "          [[ 1.3000e-02,  1.1424e-02,  3.3505e-02],\n",
      "           [ 1.7253e-02, -1.1732e-02,  1.2197e-02],\n",
      "           [ 1.6454e-02,  5.4240e-03, -1.0360e-02]],\n",
      "\n",
      "          [[ 2.7101e-03, -8.7218e-03,  1.2122e-02],\n",
      "           [-1.4658e-02,  1.8366e-02,  2.9612e-02],\n",
      "           [-1.4926e-02, -7.1605e-03,  1.8242e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.5023e-03,  2.8805e-02,  5.4347e-04],\n",
      "           [ 2.7437e-02, -2.2733e-03,  2.9520e-05],\n",
      "           [-7.1574e-03,  3.6811e-02, -4.2180e-03]],\n",
      "\n",
      "          [[-1.1487e-02,  1.5930e-02,  9.2288e-03],\n",
      "           [ 9.9373e-03,  2.1961e-02, -1.3542e-02],\n",
      "           [ 1.1007e-02,  2.2950e-02, -1.0057e-02]],\n",
      "\n",
      "          [[-4.5634e-03,  1.8972e-02, -1.0848e-03],\n",
      "           [-1.6244e-02,  2.4877e-02, -1.8610e-02],\n",
      "           [ 8.2698e-03, -8.0587e-03, -1.2203e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1670e-02, -1.0884e-02, -6.6739e-03],\n",
      "           [ 2.7091e-02,  2.0742e-03,  2.2889e-02],\n",
      "           [ 9.1342e-03,  2.6705e-02, -1.4855e-02]],\n",
      "\n",
      "          [[ 4.3970e-03,  2.9957e-03, -1.4350e-02],\n",
      "           [ 1.8672e-03, -7.0954e-03, -2.8935e-02],\n",
      "           [-4.3910e-03,  1.6350e-02, -1.8373e-02]],\n",
      "\n",
      "          [[-3.4821e-03, -2.5639e-03, -3.8949e-03],\n",
      "           [ 1.1572e-02, -8.9872e-03, -3.0628e-02],\n",
      "           [-2.6420e-03,  1.1305e-02, -1.7093e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.7087e-02,  1.3646e-02,  5.9961e-03],\n",
      "           [ 9.4127e-03,  1.5656e-02,  7.4790e-03],\n",
      "           [-3.1631e-03,  2.4649e-04,  1.5437e-02]],\n",
      "\n",
      "          [[-1.1392e-02, -2.1386e-02,  8.1580e-03],\n",
      "           [-6.3315e-03, -1.9334e-02, -1.1125e-02],\n",
      "           [ 4.1483e-03,  1.2846e-02,  1.3204e-02]],\n",
      "\n",
      "          [[-2.0736e-02,  2.6972e-02, -1.0409e-02],\n",
      "           [ 1.0412e-02,  9.7937e-03, -1.8151e-02],\n",
      "           [-4.1530e-03,  2.7359e-02, -1.1569e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.9681e-03, -1.4624e-02, -4.3605e-03],\n",
      "           [ 2.8218e-02,  5.9022e-03,  1.6038e-02],\n",
      "           [ 1.6222e-02, -7.8707e-03,  9.8652e-03]],\n",
      "\n",
      "          [[ 1.0872e-02, -1.2640e-02, -2.3188e-02],\n",
      "           [-1.4734e-02, -1.4949e-02,  1.4941e-02],\n",
      "           [-2.9318e-02, -2.3302e-02,  2.2868e-03]],\n",
      "\n",
      "          [[ 8.7558e-03,  8.7466e-03, -9.7690e-03],\n",
      "           [-5.0510e-03, -1.7883e-02,  1.4291e-02],\n",
      "           [-1.7665e-02,  1.4073e-02, -4.0225e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0184e-02, -2.2050e-02, -2.4067e-03],\n",
      "           [-2.5210e-02, -1.5063e-02, -1.6044e-02],\n",
      "           [-1.6807e-02, -7.7523e-03,  3.0038e-02]],\n",
      "\n",
      "          [[-4.9988e-03, -2.6423e-02, -1.3444e-02],\n",
      "           [ 2.0395e-04, -6.4484e-03, -8.3241e-03],\n",
      "           [ 1.6644e-02, -9.4041e-03,  1.3915e-02]],\n",
      "\n",
      "          [[ 1.3881e-02, -8.3775e-03,  1.3152e-03],\n",
      "           [-2.7642e-02, -2.2845e-03,  1.0394e-02],\n",
      "           [-1.4957e-02,  2.3129e-02, -3.8818e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.1965e-02,  1.2436e-02,  9.8699e-03],\n",
      "           [ 1.6800e-02, -3.4145e-02, -3.0645e-02],\n",
      "           [ 1.0947e-02, -1.4875e-02, -5.3789e-03]],\n",
      "\n",
      "          [[ 1.2589e-02, -2.2439e-02, -1.6031e-02],\n",
      "           [-2.2362e-02, -2.9713e-02, -2.3710e-02],\n",
      "           [-1.3705e-02, -8.5545e-03,  4.8047e-03]],\n",
      "\n",
      "          [[ 7.1967e-04, -9.2001e-03,  1.6222e-02],\n",
      "           [-1.5501e-02, -2.0720e-02,  1.1937e-02],\n",
      "           [-1.2803e-02, -1.6053e-02,  2.1867e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.9425e-02, -5.1632e-03,  2.1719e-02],\n",
      "           [-1.6559e-03, -4.5250e-03, -2.6281e-03],\n",
      "           [-6.0192e-03, -3.1899e-02, -1.8551e-02]],\n",
      "\n",
      "          [[-8.4310e-04,  1.9120e-04, -2.2113e-03],\n",
      "           [ 6.2432e-03, -2.0701e-02, -1.2261e-02],\n",
      "           [ 1.3431e-03, -2.1695e-02, -5.6564e-03]],\n",
      "\n",
      "          [[ 3.5754e-03,  5.0936e-03, -2.4088e-03],\n",
      "           [-1.1469e-02,  1.1520e-02,  2.5914e-02],\n",
      "           [-2.3114e-02, -1.4201e-02, -2.2496e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.7070e-02,  4.9052e-03,  1.7432e-02],\n",
      "           [-2.9815e-02, -1.7836e-02, -9.6379e-04],\n",
      "           [ 2.2771e-02,  2.5240e-02,  2.5010e-02]],\n",
      "\n",
      "          [[-2.1262e-02,  4.9032e-03, -2.9581e-02],\n",
      "           [ 1.4873e-02,  1.7223e-02, -1.5433e-03],\n",
      "           [ 2.5034e-02,  1.3668e-02, -1.4822e-02]],\n",
      "\n",
      "          [[-9.2318e-03, -6.5651e-03,  5.4811e-03],\n",
      "           [-1.4677e-02, -8.0173e-03,  2.8635e-03],\n",
      "           [ 2.5151e-03,  2.4293e-02, -3.8614e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.7470e-02,  8.4329e-04,  3.4837e-03],\n",
      "           [-1.1476e-02, -2.0308e-02,  2.4478e-02],\n",
      "           [-1.3981e-03, -2.3777e-02,  1.4791e-02]],\n",
      "\n",
      "          [[-1.7865e-02, -1.7645e-03, -1.5090e-03],\n",
      "           [ 5.4644e-03,  1.0356e-02,  1.2806e-02],\n",
      "           [-2.5908e-03, -1.1925e-02,  2.5245e-03]],\n",
      "\n",
      "          [[-1.3990e-02,  1.7672e-03,  1.3133e-02],\n",
      "           [-1.2145e-02,  1.8118e-03,  1.5505e-02],\n",
      "           [-7.5287e-03, -1.6587e-02, -9.0356e-04]]],\n",
      "\n",
      "\n",
      "         [[[-8.5282e-03, -2.7090e-02, -4.8104e-03],\n",
      "           [-3.0526e-02, -7.5211e-03,  9.2412e-03],\n",
      "           [ 4.6185e-03,  2.1703e-02,  2.3923e-02]],\n",
      "\n",
      "          [[ 1.3806e-02, -5.6312e-04,  1.5069e-03],\n",
      "           [ 9.3918e-04, -1.2489e-02, -4.3550e-03],\n",
      "           [ 4.7229e-03,  1.2727e-02, -2.4112e-02]],\n",
      "\n",
      "          [[ 1.3023e-02, -2.3168e-02, -2.8127e-02],\n",
      "           [ 1.1591e-02,  4.0084e-03, -1.1304e-02],\n",
      "           [-5.8456e-03, -1.6518e-02,  6.9441e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 6.6879e-03, -1.0091e-02,  1.5026e-02],\n",
      "           [-1.9975e-03,  1.6120e-02,  1.4096e-02],\n",
      "           [-1.4130e-02,  1.0643e-02,  9.4817e-03]],\n",
      "\n",
      "          [[-1.0488e-02,  9.8466e-03, -5.2524e-03],\n",
      "           [ 1.6970e-02, -2.1279e-02,  5.2261e-04],\n",
      "           [-6.5141e-03, -1.5048e-02,  1.4717e-02]],\n",
      "\n",
      "          [[-3.5586e-04, -1.8119e-02,  1.5934e-02],\n",
      "           [-1.6226e-03,  2.0240e-02,  1.7892e-02],\n",
      "           [-1.4918e-02,  1.3462e-02, -5.1782e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.1787e-02, -1.2647e-03, -1.0765e-02],\n",
      "           [-3.0161e-03, -2.4563e-03, -2.0601e-02],\n",
      "           [-3.0839e-02,  6.6797e-04, -1.8860e-02]],\n",
      "\n",
      "          [[ 5.5218e-04,  1.7335e-02, -9.9370e-03],\n",
      "           [-1.8012e-02,  1.4895e-02,  6.7295e-03],\n",
      "           [-3.7339e-03, -1.9115e-02, -1.4842e-02]],\n",
      "\n",
      "          [[ 1.2743e-02, -1.0671e-02,  8.7862e-03],\n",
      "           [ 1.6393e-02, -2.4039e-02,  6.7160e-06],\n",
      "           [-1.8392e-02, -2.1596e-02, -8.9916e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 6.7863e-03,  2.2478e-02,  2.9956e-02],\n",
      "           [-5.4696e-03,  4.5927e-03,  1.8428e-05],\n",
      "           [ 7.2014e-03,  2.7952e-02,  1.8115e-02]],\n",
      "\n",
      "          [[ 1.8152e-02, -1.3990e-02, -9.2336e-04],\n",
      "           [ 2.3375e-02, -7.7717e-03,  1.6246e-02],\n",
      "           [-5.9576e-03,  2.5372e-02,  1.7943e-02]],\n",
      "\n",
      "          [[ 7.6979e-03, -1.3273e-02, -1.5637e-02],\n",
      "           [-2.0547e-02, -2.8340e-03,  3.9017e-04],\n",
      "           [ 1.4764e-02,  1.1282e-02, -4.4856e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.9671e-02,  1.8922e-02,  7.0493e-03],\n",
      "           [ 9.5906e-03, -2.0513e-02, -5.5019e-03],\n",
      "           [ 1.1370e-02,  1.8073e-02,  8.7838e-03]],\n",
      "\n",
      "          [[ 7.3293e-03, -8.4399e-03, -7.8791e-03],\n",
      "           [-1.7581e-02,  9.9832e-03, -2.0263e-02],\n",
      "           [ 2.4871e-02,  2.1601e-02, -1.0801e-03]],\n",
      "\n",
      "          [[ 1.9504e-02, -2.2272e-02, -2.1842e-02],\n",
      "           [-2.0150e-02, -1.4140e-02,  9.4575e-03],\n",
      "           [-2.7460e-03, -5.2287e-04, -5.1566e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.0488e-02,  9.6999e-03,  1.4846e-02],\n",
      "           [ 2.6126e-02,  2.8153e-02,  1.1646e-02],\n",
      "           [-2.7287e-03,  3.3105e-03, -2.5545e-02]],\n",
      "\n",
      "          [[ 2.2134e-02,  1.5630e-02,  1.1477e-02],\n",
      "           [-9.1785e-03,  1.9673e-02, -2.2207e-03],\n",
      "           [ 2.2429e-02,  1.8883e-03, -2.3805e-02]],\n",
      "\n",
      "          [[-2.2153e-02, -4.7529e-03, -1.7246e-02],\n",
      "           [-1.3956e-02,  1.4230e-02, -1.6205e-02],\n",
      "           [ 2.2834e-03,  1.4335e-02, -2.9832e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.7771e-02,  4.1443e-05, -1.7257e-02],\n",
      "           [-1.6491e-02,  2.1642e-03,  1.5304e-02],\n",
      "           [ 6.9778e-05, -1.2457e-04,  2.6670e-05]],\n",
      "\n",
      "          [[-2.2724e-02,  1.2375e-02,  1.4149e-02],\n",
      "           [ 1.5292e-02,  1.8226e-02, -1.0490e-02],\n",
      "           [ 2.2893e-02, -1.9143e-02, -7.9843e-03]],\n",
      "\n",
      "          [[-3.7566e-03, -2.6051e-02, -1.9349e-02],\n",
      "           [-2.0975e-02, -6.5886e-03, -1.3710e-02],\n",
      "           [ 8.0629e-03, -2.7246e-02, -7.3811e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.2998e-02, -1.5240e-02, -2.2539e-02],\n",
      "           [-1.6145e-02, -7.3788e-03, -1.8388e-02],\n",
      "           [ 1.6705e-03,  6.4657e-03, -3.0459e-02]],\n",
      "\n",
      "          [[-1.5022e-02,  1.7973e-02,  1.7568e-02],\n",
      "           [-1.2569e-02, -2.8591e-03, -2.1425e-02],\n",
      "           [ 3.3940e-03, -8.3406e-03,  5.8283e-03]],\n",
      "\n",
      "          [[ 1.7370e-02,  5.7230e-04, -8.6553e-03],\n",
      "           [-9.5691e-03,  3.2961e-03, -8.4967e-03],\n",
      "           [-2.6258e-03, -1.7347e-02,  1.0016e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.3077e-02,  2.8300e-02,  2.4822e-02],\n",
      "           [ 1.7456e-02, -2.2337e-02,  1.4748e-02],\n",
      "           [-1.6175e-02, -1.9687e-02, -4.9533e-05]],\n",
      "\n",
      "          [[ 2.5670e-02,  1.2656e-02,  1.5362e-02],\n",
      "           [-1.9441e-03,  9.6980e-03,  2.0519e-03],\n",
      "           [ 8.1309e-03,  9.4871e-03, -3.9363e-02]],\n",
      "\n",
      "          [[ 1.7168e-02,  3.5563e-02,  3.6968e-03],\n",
      "           [ 1.0345e-02, -1.0113e-02, -7.3428e-03],\n",
      "           [-3.5759e-03,  5.9869e-03, -2.8309e-03]]],\n",
      "\n",
      "\n",
      "         [[[-6.3451e-04, -9.8059e-03,  1.4233e-02],\n",
      "           [ 2.9546e-02, -1.1986e-02,  1.3931e-03],\n",
      "           [-4.9913e-03, -2.6645e-03, -9.1963e-03]],\n",
      "\n",
      "          [[ 2.0945e-02,  1.7144e-02,  6.9676e-03],\n",
      "           [-4.6615e-03, -1.2013e-02,  2.5313e-02],\n",
      "           [ 2.8254e-02, -1.4362e-03, -5.6875e-03]],\n",
      "\n",
      "          [[-1.0274e-02,  1.7490e-02,  3.4375e-02],\n",
      "           [ 1.6638e-03,  2.3202e-02,  9.5950e-03],\n",
      "           [-3.6308e-03,  1.3472e-02,  1.7695e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.8195e-03, -1.6996e-02,  1.7078e-02],\n",
      "           [-5.6321e-03, -1.4970e-02,  1.2609e-02],\n",
      "           [-1.6918e-02,  1.0659e-02, -1.8194e-02]],\n",
      "\n",
      "          [[ 2.0169e-02,  7.7392e-03, -1.0597e-02],\n",
      "           [-3.4952e-03, -1.7248e-02, -1.8946e-02],\n",
      "           [ 1.3809e-02, -1.1426e-02, -2.2613e-02]],\n",
      "\n",
      "          [[ 1.9229e-02, -1.1087e-02, -3.5320e-02],\n",
      "           [ 1.4957e-02,  5.4968e-03,  1.3786e-03],\n",
      "           [ 2.3752e-03, -1.2662e-02, -7.4820e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.5635e-02, -1.7866e-02, -8.6750e-03],\n",
      "           [-2.0744e-02,  1.3582e-02, -5.5823e-03],\n",
      "           [-1.7432e-02, -2.6897e-02, -2.4406e-03]],\n",
      "\n",
      "          [[ 1.9033e-02, -1.5999e-03,  5.6228e-03],\n",
      "           [-8.2257e-03, -1.6496e-02,  3.6952e-03],\n",
      "           [ 4.5499e-03,  6.4883e-03,  1.6658e-02]],\n",
      "\n",
      "          [[-1.2725e-03,  2.8495e-02,  2.4795e-02],\n",
      "           [ 1.8965e-02,  2.9762e-02,  3.6156e-02],\n",
      "           [ 2.2858e-02,  1.6731e-02, -1.6968e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.0065e-02,  8.7524e-03, -2.1040e-02],\n",
      "           [-1.4168e-03,  1.6171e-02,  5.1736e-03],\n",
      "           [ 3.3254e-02, -1.3371e-02, -1.5481e-02]],\n",
      "\n",
      "          [[-3.8338e-03, -8.4183e-03,  1.6861e-03],\n",
      "           [ 2.4546e-02,  1.7456e-02,  2.3242e-02],\n",
      "           [-2.1931e-03,  1.6546e-02,  6.6275e-03]],\n",
      "\n",
      "          [[-2.5499e-02,  1.1057e-02, -9.0936e-04],\n",
      "           [ 2.5239e-02,  2.0032e-02,  2.1701e-02],\n",
      "           [-9.4958e-03,  1.2580e-02,  1.6363e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.7067e-02, -2.7198e-02, -2.8940e-02],\n",
      "           [-2.9115e-02, -3.3762e-02, -1.0991e-02],\n",
      "           [-1.5384e-02,  4.8683e-03,  1.2155e-02]],\n",
      "\n",
      "          [[-2.1119e-02, -2.6069e-02, -2.1940e-02],\n",
      "           [-4.7756e-03, -2.1084e-02, -1.1015e-02],\n",
      "           [-1.1859e-02, -1.1220e-02,  6.5244e-03]],\n",
      "\n",
      "          [[-1.0191e-02,  2.3324e-02,  2.2496e-03],\n",
      "           [-1.3837e-02, -1.4841e-02,  1.0586e-02],\n",
      "           [ 7.4919e-03, -6.6457e-03, -8.9751e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.9870e-02, -8.6839e-03, -3.6536e-03],\n",
      "           [-2.6598e-02, -2.2717e-02, -2.1040e-02],\n",
      "           [-1.2669e-05,  4.5177e-03, -1.1549e-02]],\n",
      "\n",
      "          [[ 6.6914e-04,  2.6965e-02,  3.5913e-02],\n",
      "           [-1.9475e-02, -5.2211e-03,  1.3792e-02],\n",
      "           [ 2.9659e-02,  7.2982e-03, -1.4168e-02]],\n",
      "\n",
      "          [[ 6.8289e-03, -1.9771e-03,  1.2662e-02],\n",
      "           [ 2.2909e-02,  3.1299e-03,  2.2972e-02],\n",
      "           [ 2.8203e-02,  1.8763e-02,  2.3993e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3635e-02, -2.7756e-02, -1.1346e-02],\n",
      "           [ 1.8248e-02, -2.9493e-02, -5.0130e-03],\n",
      "           [-3.6866e-02, -5.4939e-03, -3.9674e-02]],\n",
      "\n",
      "          [[-1.0508e-02, -1.0147e-02,  3.7707e-03],\n",
      "           [-1.4455e-02, -7.9092e-03, -3.9926e-03],\n",
      "           [ 9.5688e-03,  1.5802e-02,  6.3922e-03]],\n",
      "\n",
      "          [[ 1.8173e-02,  2.3225e-02, -7.2670e-04],\n",
      "           [ 3.6654e-02,  1.7315e-02,  4.7687e-03],\n",
      "           [ 1.1826e-02,  4.1459e-03,  2.9370e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.4209e-02,  1.2751e-02,  1.0105e-02],\n",
      "           [-1.7563e-02,  1.9292e-03,  9.6326e-03],\n",
      "           [-1.4463e-02,  2.5618e-02,  3.3104e-02]],\n",
      "\n",
      "          [[ 2.4581e-02, -4.6412e-03,  3.1236e-03],\n",
      "           [-1.3053e-02,  2.6658e-02,  1.8209e-02],\n",
      "           [-1.3887e-02, -7.2386e-03,  1.2248e-02]],\n",
      "\n",
      "          [[ 1.4017e-02, -6.4286e-03,  2.0488e-02],\n",
      "           [-1.0917e-02,  1.7470e-02,  9.1171e-03],\n",
      "           [ 3.1378e-03,  9.4464e-03, -1.2828e-02]]]]], device='cuda:0')), ('module.down_layers.3.1.norm1.weight', tensor([0.9745, 0.9291, 0.9496, 0.9972, 0.9488, 0.9776, 0.9803, 0.9201, 0.9334,\n",
      "        0.9761, 0.9714, 0.9657, 0.9429, 0.9310, 0.9310, 0.9012, 0.9794, 0.9172,\n",
      "        0.9553, 0.9331, 0.9853, 0.9779, 0.9388, 0.9353, 0.9082, 0.9070, 0.9675,\n",
      "        0.9210, 0.9867, 0.9866, 0.9602, 0.9880, 0.9694, 0.9320, 0.8428, 0.8990,\n",
      "        0.9274, 0.9624, 0.9483, 0.9728, 0.9532, 0.9210, 0.9145, 0.8968, 0.9288,\n",
      "        0.9503, 0.9123, 0.9785, 0.9375, 0.9767, 0.9539, 0.9898, 0.9140, 0.9869,\n",
      "        0.9485, 0.8623, 0.9401, 0.9330, 0.9628, 0.8934, 0.8754, 0.9539, 0.9078,\n",
      "        0.9799, 0.9516, 0.9642, 0.8517, 0.9274, 0.9277, 0.9486, 0.9504, 0.9252,\n",
      "        0.9423, 0.9322, 0.9796, 0.9822, 0.9664, 0.9397, 0.9393, 0.9450, 0.9381,\n",
      "        0.9300, 0.9531, 0.9276, 0.9662, 0.9343, 0.9539, 0.9410, 0.9534, 0.9717,\n",
      "        0.9356, 0.9729, 0.9193, 0.9391, 0.9498, 0.9521, 0.9074, 0.8844, 0.9647,\n",
      "        0.9724, 0.9726, 0.9334, 0.9408, 0.9192, 0.9304, 0.9861, 0.9497, 0.9536,\n",
      "        0.9140, 0.9384, 0.9282, 0.9729, 0.9627, 0.9153, 0.9259, 0.9172, 0.9772,\n",
      "        0.9697, 0.9866, 0.9785, 0.9770, 0.9494, 0.9701, 0.9331, 0.9766, 0.9593,\n",
      "        0.9457, 0.9165], device='cuda:0')), ('module.down_layers.3.1.norm1.bias', tensor([-0.0162, -0.0555, -0.0178, -0.0041, -0.0203, -0.0090, -0.0034, -0.0169,\n",
      "        -0.0261, -0.0164, -0.0188, -0.0222, -0.0146, -0.0208, -0.0239, -0.0337,\n",
      "        -0.0205, -0.0240, -0.0217, -0.0198, -0.0265, -0.0031, -0.0462, -0.0409,\n",
      "        -0.0314, -0.0355, -0.0239, -0.0369, -0.0172, -0.0042, -0.0183, -0.0223,\n",
      "        -0.0222, -0.0151, -0.0244, -0.0275, -0.0176, -0.0280, -0.0179, -0.0037,\n",
      "        -0.0109, -0.0228, -0.0298, -0.0375, -0.0265, -0.0104, -0.0324, -0.0078,\n",
      "        -0.0377, -0.0076, -0.0309,  0.0042, -0.0260, -0.0182, -0.0281, -0.0339,\n",
      "        -0.0258, -0.0229, -0.0158, -0.0248, -0.0226, -0.0219, -0.0465, -0.0172,\n",
      "        -0.0306, -0.0110, -0.0364, -0.0332, -0.0539, -0.0158, -0.0349, -0.0568,\n",
      "        -0.0202, -0.0314, -0.0150, -0.0124, -0.0186, -0.0322, -0.0222, -0.0237,\n",
      "        -0.0315, -0.0220, -0.0325, -0.0437, -0.0195, -0.0222, -0.0235, -0.0205,\n",
      "        -0.0255, -0.0175, -0.0215, -0.0212, -0.0212, -0.0416, -0.0125, -0.0225,\n",
      "        -0.0270, -0.0188, -0.0147, -0.0067, -0.0178,  0.0041, -0.0218, -0.0274,\n",
      "        -0.0237, -0.0055, -0.0247, -0.0134, -0.0218, -0.0092, -0.0137, -0.0143,\n",
      "        -0.0325, -0.0244, -0.0292, -0.0215, -0.0199, -0.0056, -0.0210, -0.0231,\n",
      "        -0.0149, -0.0420, -0.0269, -0.0366, -0.0134, -0.0319, -0.0178, -0.0268],\n",
      "       device='cuda:0')), ('module.down_layers.3.1.norm2.weight', tensor([0.9795, 0.9752, 0.9747, 0.8787, 0.8562, 0.9004, 0.8255, 0.9670, 0.8976,\n",
      "        0.8719, 0.9819, 0.8965, 0.9255, 0.8972, 0.9502, 0.9840, 0.9476, 0.9780,\n",
      "        0.7171, 0.9312, 0.8747, 0.7762, 0.9565, 0.7676, 0.9402, 0.7090, 0.7931,\n",
      "        0.9622, 0.9607, 0.9516, 0.9326, 0.9597, 0.9604, 0.9446, 0.9330, 0.9666,\n",
      "        0.9456, 0.9768, 0.9498, 0.9601, 0.9472, 0.7153, 0.8221, 0.9667, 0.9600,\n",
      "        0.9611, 0.9828, 0.9738, 0.9087, 0.9703, 0.9615, 0.9716, 0.9543, 0.9484,\n",
      "        0.6981, 0.9484, 0.8058, 0.7611, 0.9675, 0.9684, 0.7765, 0.7986, 0.9024,\n",
      "        0.9807, 0.9628, 0.9514, 0.9142, 0.8160, 0.9623, 0.8617, 0.9609, 0.9779,\n",
      "        0.9647, 0.9893, 0.8168, 0.9662, 0.9724, 0.9739, 0.7674, 0.9703, 0.9706,\n",
      "        0.9620, 0.9125, 0.9399, 0.9720, 0.9635, 0.9536, 0.7855, 0.9688, 0.9559,\n",
      "        0.8680, 0.9599, 0.8207, 0.9542, 0.9543, 0.7452, 0.9725, 0.9710, 0.9473,\n",
      "        0.9429, 0.8805, 0.9718, 0.9612, 0.9432, 0.9741, 0.9831, 0.9527, 0.9871,\n",
      "        0.7865, 0.9676, 0.9529, 0.9881, 0.9485, 0.8769, 0.8934, 0.9553, 0.9607,\n",
      "        0.9730, 0.9352, 0.9466, 0.8731, 0.9201, 0.9468, 0.8961, 0.9389, 0.8871,\n",
      "        0.9368, 0.9808], device='cuda:0')), ('module.down_layers.3.1.norm2.bias', tensor([-0.0117, -0.0087, -0.0185, -0.0428, -0.0369, -0.0223, -0.0289, -0.0186,\n",
      "        -0.0215, -0.0518, -0.0062, -0.0309, -0.0220, -0.0222, -0.0130, -0.0069,\n",
      "        -0.0212, -0.0184, -0.0457, -0.0130, -0.0206, -0.0349, -0.0239, -0.0329,\n",
      "        -0.0159, -0.0470, -0.0526, -0.0264, -0.0181, -0.0228, -0.0226, -0.0125,\n",
      "        -0.0202, -0.0288, -0.0135, -0.0200, -0.0269, -0.0193, -0.0259, -0.0180,\n",
      "        -0.0163, -0.0507, -0.0440, -0.0126, -0.0195, -0.0200, -0.0225, -0.0202,\n",
      "        -0.0226, -0.0098, -0.0209, -0.0085, -0.0086, -0.0212, -0.0421, -0.0230,\n",
      "        -0.0306, -0.0461, -0.0192, -0.0210, -0.0360, -0.0429, -0.0274, -0.0112,\n",
      "        -0.0268, -0.0190, -0.0266, -0.0326, -0.0154, -0.0361, -0.0171, -0.0247,\n",
      "        -0.0174, -0.0176, -0.0353, -0.0237, -0.0171, -0.0235, -0.0339, -0.0135,\n",
      "        -0.0230, -0.0216, -0.0163, -0.0193, -0.0165, -0.0165, -0.0284, -0.0474,\n",
      "        -0.0203, -0.0246, -0.0275, -0.0213, -0.0138, -0.0115, -0.0166, -0.0313,\n",
      "        -0.0207, -0.0127, -0.0207, -0.0128, -0.0260, -0.0219, -0.0274, -0.0305,\n",
      "        -0.0249, -0.0128, -0.0239, -0.0074, -0.0504, -0.0264, -0.0218, -0.0197,\n",
      "        -0.0162, -0.0154, -0.0051, -0.0133, -0.0094, -0.0189, -0.0184, -0.0192,\n",
      "        -0.0259, -0.0138, -0.0205, -0.0287, -0.0127, -0.0158, -0.0092, -0.0012],\n",
      "       device='cuda:0')), ('module.down_layers.3.1.conv1.conv.weight', tensor([[[[[ 1.4113e-02, -7.6934e-03,  1.9863e-02],\n",
      "           [-1.5177e-02,  1.2036e-02,  5.5519e-03],\n",
      "           [ 2.0040e-02,  1.9168e-02, -1.4908e-02]],\n",
      "\n",
      "          [[-7.4803e-03,  2.0792e-03,  4.5191e-03],\n",
      "           [-5.4976e-03,  1.1746e-02, -9.0050e-03],\n",
      "           [ 8.8396e-03,  1.9969e-02, -7.2551e-03]],\n",
      "\n",
      "          [[ 9.3763e-03, -1.6064e-03,  5.8439e-03],\n",
      "           [-4.4489e-03, -2.1355e-02, -7.9976e-03],\n",
      "           [ 8.4962e-04,  8.7719e-04, -9.0610e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.7329e-03,  4.4639e-03,  8.1344e-03],\n",
      "           [ 8.5759e-03, -3.8771e-03, -9.2357e-03],\n",
      "           [-1.9880e-02,  9.8966e-04, -1.4998e-02]],\n",
      "\n",
      "          [[-6.8475e-03, -4.1371e-03,  1.1041e-02],\n",
      "           [ 2.1898e-03, -7.8654e-03, -6.1579e-03],\n",
      "           [-3.6915e-03, -2.6634e-03, -2.1348e-02]],\n",
      "\n",
      "          [[-7.5968e-03, -8.6204e-03,  3.0047e-03],\n",
      "           [-2.0106e-02, -1.1727e-02, -9.9649e-03],\n",
      "           [-4.0849e-03, -1.8019e-02,  6.8883e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.0368e-02, -1.1359e-02, -1.8282e-02],\n",
      "           [-8.1509e-03,  2.2553e-03, -1.9524e-02],\n",
      "           [ 6.9106e-03,  1.0030e-02,  1.3506e-02]],\n",
      "\n",
      "          [[-6.6470e-03, -6.6747e-03, -2.8326e-02],\n",
      "           [ 9.5613e-03, -8.6990e-03,  3.0201e-03],\n",
      "           [ 5.9818e-03,  9.6351e-03,  1.7226e-02]],\n",
      "\n",
      "          [[ 5.5115e-03,  1.0967e-02, -2.1129e-02],\n",
      "           [ 1.9979e-02,  1.4373e-02, -1.0870e-02],\n",
      "           [ 2.1563e-03, -6.0142e-03,  1.7233e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.4163e-02,  9.9016e-03,  1.0912e-02],\n",
      "           [ 3.8211e-03,  2.6331e-02, -1.3435e-02],\n",
      "           [ 2.9229e-02,  2.2671e-02, -1.3649e-02]],\n",
      "\n",
      "          [[ 9.1909e-04, -1.0637e-02,  1.2565e-02],\n",
      "           [ 1.3171e-02,  5.9327e-03,  9.3306e-03],\n",
      "           [-7.5643e-03,  1.0019e-02, -7.8626e-03]],\n",
      "\n",
      "          [[ 2.3238e-03, -1.7276e-02, -1.9837e-02],\n",
      "           [-7.8414e-03, -9.8710e-03, -1.5463e-02],\n",
      "           [-7.6281e-03,  7.6172e-03, -7.4440e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.6318e-02,  1.4246e-02, -9.6676e-03],\n",
      "           [ 1.7140e-02, -5.3832e-03,  1.0239e-03],\n",
      "           [ 7.1329e-03, -2.0355e-02, -7.6852e-03]],\n",
      "\n",
      "          [[-1.0836e-02,  5.3780e-03,  8.6729e-03],\n",
      "           [ 3.1250e-03, -6.5172e-04,  5.6296e-04],\n",
      "           [-1.2082e-02, -5.5993e-03, -2.9221e-02]],\n",
      "\n",
      "          [[ 1.2041e-03,  1.2068e-03,  1.2713e-02],\n",
      "           [-9.4726e-03, -9.7701e-03, -8.6457e-04],\n",
      "           [ 1.9291e-03,  3.8495e-03, -1.6289e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1901e-03,  2.4622e-02, -1.0937e-02],\n",
      "           [ 1.0387e-02,  2.1238e-02, -1.2204e-02],\n",
      "           [ 4.2475e-03,  1.2750e-03, -2.8805e-02]],\n",
      "\n",
      "          [[-8.4421e-03,  4.4114e-03, -1.1678e-02],\n",
      "           [ 2.4682e-02,  1.3687e-02,  5.2645e-04],\n",
      "           [ 1.0492e-02, -8.8555e-03, -2.6927e-02]],\n",
      "\n",
      "          [[-1.0708e-02, -1.7877e-02, -1.5416e-02],\n",
      "           [ 1.0147e-02,  8.1477e-03, -8.2446e-03],\n",
      "           [ 9.7410e-03,  3.2202e-03, -7.2495e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.6509e-04, -3.3794e-03,  1.5744e-02],\n",
      "           [-1.4788e-03, -1.8811e-02, -6.6264e-03],\n",
      "           [-1.6719e-02,  3.1929e-04, -6.0540e-03]],\n",
      "\n",
      "          [[-7.3603e-03,  1.0338e-02,  3.6509e-03],\n",
      "           [ 1.0342e-02, -1.7880e-02, -2.0510e-02],\n",
      "           [ 1.4647e-02, -1.5629e-02, -1.3905e-02]],\n",
      "\n",
      "          [[ 1.6255e-02,  2.0038e-02,  3.0292e-02],\n",
      "           [ 5.6002e-03,  6.0845e-03,  1.7693e-02],\n",
      "           [ 1.7938e-02,  2.5797e-03, -1.2001e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4078e-03, -5.2029e-03, -5.7597e-04],\n",
      "           [-2.4285e-02, -1.5434e-02, -9.7808e-03],\n",
      "           [ 1.3488e-03, -1.4063e-02, -9.9250e-03]],\n",
      "\n",
      "          [[-5.0812e-03,  4.5495e-03,  6.9598e-03],\n",
      "           [-2.2011e-02, -2.4409e-02, -5.3356e-03],\n",
      "           [-1.0438e-03, -2.8606e-02, -8.1073e-03]],\n",
      "\n",
      "          [[-4.3924e-03,  1.9947e-02,  2.5658e-02],\n",
      "           [-3.0779e-03,  1.4286e-02,  5.1125e-04],\n",
      "           [ 1.1778e-02, -2.1272e-03,  1.3197e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.7097e-03, -2.2873e-03,  1.5636e-02],\n",
      "           [-9.3830e-04,  1.6266e-02,  1.6263e-02],\n",
      "           [ 9.0587e-03,  9.9997e-03,  5.3447e-03]],\n",
      "\n",
      "          [[-7.2175e-03, -5.5991e-03, -2.2140e-03],\n",
      "           [-1.2833e-03, -3.1675e-03, -3.1382e-03],\n",
      "           [-1.1137e-02, -1.7619e-02, -2.0303e-03]],\n",
      "\n",
      "          [[-1.2660e-02, -1.9276e-02, -9.6956e-03],\n",
      "           [ 9.3917e-03,  1.3626e-02,  1.1695e-02],\n",
      "           [ 9.7742e-03, -1.6457e-02, -1.2657e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.1837e-02, -1.4987e-02, -1.3431e-02],\n",
      "           [-8.7253e-03, -2.9004e-02, -3.3665e-03],\n",
      "           [-6.5253e-03, -2.8014e-02, -1.6040e-02]],\n",
      "\n",
      "          [[ 1.0837e-02,  7.0266e-03,  1.3534e-02],\n",
      "           [ 4.7461e-03, -2.8982e-03,  4.6154e-04],\n",
      "           [-2.5318e-02, -2.0239e-02, -1.8746e-02]],\n",
      "\n",
      "          [[-3.8681e-04, -2.2853e-03,  2.9011e-02],\n",
      "           [ 4.8720e-03,  2.3860e-02,  1.9592e-02],\n",
      "           [-2.2465e-03,  3.0775e-03, -3.7194e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 8.6584e-03, -1.6068e-02, -2.0480e-02],\n",
      "           [ 2.1691e-03, -2.5180e-02, -1.7728e-02],\n",
      "           [-2.4906e-02, -2.2768e-02, -1.1701e-02]],\n",
      "\n",
      "          [[ 5.6801e-04,  1.5837e-02,  1.3900e-02],\n",
      "           [ 1.4428e-02,  1.8587e-02, -1.8784e-02],\n",
      "           [ 6.4379e-03, -2.1152e-05, -2.4369e-02]],\n",
      "\n",
      "          [[-4.5340e-03,  1.8239e-03, -2.8674e-03],\n",
      "           [ 1.4574e-02, -1.4705e-03, -1.1261e-03],\n",
      "           [ 1.8332e-02, -1.6483e-04, -1.7132e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.6977e-03,  9.0833e-03,  4.8687e-03],\n",
      "           [ 1.3214e-02,  5.4497e-03, -2.0393e-02],\n",
      "           [ 2.2528e-03, -6.4897e-03, -1.9055e-02]],\n",
      "\n",
      "          [[ 1.9841e-02,  2.0606e-02,  1.6684e-02],\n",
      "           [ 1.1751e-02,  1.7302e-03, -1.5326e-02],\n",
      "           [ 2.2724e-02,  3.1335e-03,  3.3586e-03]],\n",
      "\n",
      "          [[-3.5137e-03,  7.6834e-03, -1.5033e-03],\n",
      "           [ 2.3497e-02,  9.5835e-03,  1.4504e-02],\n",
      "           [ 8.3249e-03,  1.7044e-02,  6.6691e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.2254e-02,  1.5880e-02,  1.5647e-02],\n",
      "           [-2.0113e-02, -1.0115e-02, -1.3340e-02],\n",
      "           [ 4.6861e-03, -3.1787e-03, -1.0359e-02]],\n",
      "\n",
      "          [[-7.5263e-03, -1.4564e-02, -7.2697e-03],\n",
      "           [-2.1232e-02, -1.5733e-02, -9.9866e-03],\n",
      "           [ 1.7538e-02,  1.3759e-04, -1.7672e-02]],\n",
      "\n",
      "          [[ 3.7605e-03, -4.5264e-03, -1.1987e-03],\n",
      "           [-4.7215e-03, -5.8183e-03, -1.2700e-02],\n",
      "           [-3.4849e-03,  3.1695e-03, -1.0433e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.1084e-03,  4.0721e-03, -5.4122e-03],\n",
      "           [-1.0659e-02,  5.7666e-04, -9.1705e-03],\n",
      "           [ 2.0543e-03, -1.7963e-02, -2.2310e-02]],\n",
      "\n",
      "          [[ 5.9758e-03, -1.2191e-02, -1.2803e-02],\n",
      "           [ 8.5729e-03, -8.7666e-03, -9.8048e-03],\n",
      "           [-5.6390e-03, -2.9663e-03,  4.1930e-04]],\n",
      "\n",
      "          [[-1.1354e-02, -6.8836e-03,  8.3884e-03],\n",
      "           [-8.5384e-03, -3.6320e-03,  5.5600e-03],\n",
      "           [-1.0409e-02,  4.5067e-03, -1.2741e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.7640e-03, -6.2675e-03, -1.4486e-02],\n",
      "           [ 5.8399e-03,  6.2515e-03,  4.3439e-03],\n",
      "           [ 2.5863e-03,  1.8450e-03,  4.0567e-03]],\n",
      "\n",
      "          [[ 2.8904e-03, -1.5600e-02, -1.0876e-02],\n",
      "           [ 3.2913e-03,  9.3574e-03,  9.1449e-03],\n",
      "           [-4.6727e-03,  5.5564e-04,  1.5721e-02]],\n",
      "\n",
      "          [[ 1.4749e-02,  1.5116e-02,  8.5626e-03],\n",
      "           [ 1.0063e-02,  2.3253e-02,  1.5365e-02],\n",
      "           [-2.1995e-03,  9.3461e-03,  1.0606e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.4155e-03,  2.1058e-02, -7.7822e-03],\n",
      "           [ 1.2097e-02,  5.9879e-03,  1.1022e-02],\n",
      "           [ 2.1387e-02,  1.4757e-02, -9.5417e-03]],\n",
      "\n",
      "          [[-1.8319e-02,  1.0672e-02, -2.1334e-03],\n",
      "           [ 4.5489e-03, -1.2978e-02, -2.0630e-02],\n",
      "           [ 3.9869e-03,  2.2498e-02, -5.2946e-03]],\n",
      "\n",
      "          [[ 1.0937e-03,  1.0292e-02,  6.2713e-03],\n",
      "           [-2.4045e-03, -7.0184e-03,  1.3554e-03],\n",
      "           [-4.6425e-03, -6.8762e-03, -9.2061e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.8798e-02, -1.1793e-02,  5.8935e-03],\n",
      "           [-9.0523e-03, -1.5831e-02, -1.1814e-02],\n",
      "           [ 4.0644e-04,  3.4895e-03, -1.9818e-02]],\n",
      "\n",
      "          [[-1.4802e-03,  8.7205e-03,  1.5766e-02],\n",
      "           [-1.0671e-02,  2.0801e-03, -1.9529e-02],\n",
      "           [ 8.1101e-03, -1.7538e-02, -3.7428e-02]],\n",
      "\n",
      "          [[ 5.4555e-03, -2.2224e-03,  1.3138e-02],\n",
      "           [-1.6459e-02, -1.7557e-03, -2.1328e-03],\n",
      "           [ 1.3915e-02,  2.7446e-04, -9.2603e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 7.1501e-03,  1.9777e-02,  8.8237e-03],\n",
      "           [ 1.7035e-02,  5.9357e-05, -5.4321e-03],\n",
      "           [ 1.1575e-02, -4.1902e-03, -1.9012e-02]],\n",
      "\n",
      "          [[-1.0391e-02,  6.9022e-04,  2.8417e-03],\n",
      "           [ 2.4307e-02,  6.0141e-03, -4.1907e-03],\n",
      "           [ 1.4364e-02, -4.3261e-03,  7.6272e-04]],\n",
      "\n",
      "          [[-1.6509e-02,  2.8259e-03, -1.1123e-02],\n",
      "           [-8.9670e-04, -6.5203e-04, -1.5705e-02],\n",
      "           [ 1.2092e-02,  6.9088e-03, -1.8986e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.8733e-03, -8.9735e-03, -3.4018e-03],\n",
      "           [-7.3178e-03,  2.9469e-02,  2.1512e-02],\n",
      "           [ 2.6300e-02,  3.3801e-02,  1.6797e-02]],\n",
      "\n",
      "          [[ 5.7353e-03,  4.0005e-03,  8.2424e-03],\n",
      "           [-3.2518e-03, -4.4193e-03,  1.9943e-02],\n",
      "           [ 2.6513e-02,  2.6870e-02,  1.5355e-02]],\n",
      "\n",
      "          [[ 1.2492e-03, -2.3194e-02,  1.1043e-02],\n",
      "           [-5.6500e-03, -5.8165e-03,  1.0442e-02],\n",
      "           [ 1.1138e-02,  7.9642e-04,  1.1048e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.0255e-03, -2.0549e-02, -4.7340e-03],\n",
      "           [ 1.9678e-02,  1.0593e-02,  1.1849e-02],\n",
      "           [ 6.3538e-03,  4.9325e-03, -5.1701e-03]],\n",
      "\n",
      "          [[ 6.1369e-03,  1.2351e-02,  9.3352e-03],\n",
      "           [ 9.2445e-03,  1.4347e-02,  1.6592e-02],\n",
      "           [-1.3633e-02,  3.4286e-03, -3.8809e-03]],\n",
      "\n",
      "          [[-3.0729e-02, -1.6569e-02, -1.5289e-02],\n",
      "           [-8.7681e-03, -7.7780e-03, -2.2715e-02],\n",
      "           [-1.8675e-02,  2.5057e-03, -5.7868e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.4847e-03,  1.0643e-02, -7.9719e-03],\n",
      "           [ 5.6842e-03,  7.6483e-03, -2.3945e-03],\n",
      "           [-7.2341e-03, -6.9730e-04,  2.9949e-04]],\n",
      "\n",
      "          [[ 1.8501e-02,  1.4461e-03,  1.7307e-03],\n",
      "           [-1.2099e-02, -4.7385e-03, -7.7307e-03],\n",
      "           [-2.8721e-02, -2.2735e-02, -1.2288e-02]],\n",
      "\n",
      "          [[ 2.1249e-02, -7.9657e-04,  9.9348e-03],\n",
      "           [-1.1811e-02, -1.9907e-02, -4.1923e-03],\n",
      "           [-1.8887e-02, -1.8649e-02, -2.0472e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.3420e-03, -8.9609e-03,  1.4816e-02],\n",
      "           [-1.3288e-03, -6.1370e-03,  1.1296e-02],\n",
      "           [-2.5805e-03, -4.2952e-03, -4.6742e-03]],\n",
      "\n",
      "          [[-1.5368e-02,  9.3845e-03,  6.7223e-03],\n",
      "           [-6.0810e-03,  9.7042e-03, -1.7747e-02],\n",
      "           [ 2.8762e-02,  1.3829e-02,  1.6133e-03]],\n",
      "\n",
      "          [[-6.6183e-03,  1.9035e-03, -6.6804e-03],\n",
      "           [ 1.9548e-03, -1.1822e-02, -9.8841e-03],\n",
      "           [-2.0885e-03,  5.7790e-04, -1.1181e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.3905e-03,  7.8368e-03,  1.0969e-02],\n",
      "           [-3.4755e-03, -1.6672e-02, -1.1594e-03],\n",
      "           [ 1.1224e-02, -1.2746e-03, -3.6926e-03]],\n",
      "\n",
      "          [[-6.4676e-03, -8.8675e-03, -3.4840e-04],\n",
      "           [ 5.4914e-03, -2.4853e-03, -9.6186e-03],\n",
      "           [ 2.2577e-03, -1.3021e-02, -1.9028e-02]],\n",
      "\n",
      "          [[-1.3059e-02, -2.7254e-02, -2.7476e-02],\n",
      "           [ 1.9596e-02,  3.7901e-03, -3.3316e-02],\n",
      "           [-2.1341e-03,  4.9975e-04, -1.8537e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.1754e-03,  1.1442e-02,  1.5699e-02],\n",
      "           [ 8.9787e-03,  2.3175e-03, -7.1208e-03],\n",
      "           [ 1.4373e-04,  1.9473e-03, -2.7864e-03]],\n",
      "\n",
      "          [[-6.2614e-03, -8.7282e-03, -1.0031e-02],\n",
      "           [ 1.9724e-03, -2.3837e-05, -2.0377e-02],\n",
      "           [ 1.9504e-02,  8.5622e-03, -1.4094e-03]],\n",
      "\n",
      "          [[-1.9620e-04, -1.9163e-03,  7.0107e-06],\n",
      "           [ 1.6042e-02,  1.4479e-02, -6.0932e-03],\n",
      "           [ 2.4849e-02,  2.7634e-02,  1.3110e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.8120e-03, -1.4096e-02, -1.3817e-02],\n",
      "           [-2.4258e-02,  1.1022e-02,  2.0080e-02],\n",
      "           [-1.1080e-03,  2.8875e-02,  1.3598e-02]],\n",
      "\n",
      "          [[-1.1815e-02, -2.0596e-02, -4.0380e-03],\n",
      "           [-1.0148e-02, -1.6003e-02,  1.3858e-02],\n",
      "           [-1.3798e-02,  3.6216e-02,  1.1598e-02]],\n",
      "\n",
      "          [[ 4.9092e-03, -1.4299e-02,  1.7237e-02],\n",
      "           [ 2.9776e-03, -1.9522e-02,  5.8001e-03],\n",
      "           [ 5.2953e-03,  3.9062e-03,  1.3767e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.1509e-02, -9.7879e-03,  1.9158e-02],\n",
      "           [-5.8089e-04,  2.3348e-02,  1.9944e-02],\n",
      "           [ 2.3616e-02,  1.1090e-02,  2.4194e-02]],\n",
      "\n",
      "          [[-1.6840e-03, -5.4106e-03,  1.5703e-02],\n",
      "           [-6.2749e-03,  1.0641e-02, -7.5030e-06],\n",
      "           [-8.9755e-04,  2.4405e-02,  8.6060e-03]],\n",
      "\n",
      "          [[-2.0764e-02, -3.0022e-03, -8.9602e-03],\n",
      "           [-4.3289e-03,  4.7092e-04, -1.0553e-02],\n",
      "           [-5.3423e-03, -5.5580e-03, -2.0798e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.0449e-03, -3.0566e-03, -2.4434e-02],\n",
      "           [-1.4745e-02, -1.6038e-02, -2.1924e-02],\n",
      "           [-1.1245e-02,  7.3276e-03,  5.5376e-03]],\n",
      "\n",
      "          [[-1.2350e-02, -6.2941e-03, -2.3216e-02],\n",
      "           [-9.5687e-03, -1.3887e-02, -9.4603e-03],\n",
      "           [-1.5266e-02,  5.0996e-03,  6.2272e-03]],\n",
      "\n",
      "          [[-3.3235e-03,  3.3096e-03, -9.1134e-03],\n",
      "           [-1.5415e-02, -1.5594e-02,  1.4362e-03],\n",
      "           [-1.6758e-02, -6.9712e-03, -1.0979e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.2019e-03,  3.5354e-03, -1.2694e-02],\n",
      "           [ 7.0952e-03, -1.8855e-04,  1.6459e-02],\n",
      "           [-4.4563e-03,  2.0105e-02, -2.1185e-03]],\n",
      "\n",
      "          [[-3.7374e-04, -1.7975e-02, -1.0094e-02],\n",
      "           [-1.0219e-02,  6.3114e-03, -1.5136e-03],\n",
      "           [ 5.5623e-03,  1.8447e-03, -1.3454e-02]],\n",
      "\n",
      "          [[ 1.7037e-02,  4.7907e-03, -9.4748e-03],\n",
      "           [ 1.1282e-02,  2.1657e-02,  1.5160e-02],\n",
      "           [ 2.1694e-02,  1.5357e-02, -1.9397e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.9926e-02,  4.1973e-03,  5.5168e-03],\n",
      "           [ 3.2228e-03, -8.1619e-04,  1.3714e-02],\n",
      "           [ 5.5851e-03,  4.8817e-03, -1.7722e-02]],\n",
      "\n",
      "          [[-8.6501e-03, -1.2290e-02,  1.1196e-02],\n",
      "           [ 6.8384e-04, -7.1351e-03,  2.0471e-03],\n",
      "           [ 1.8882e-02, -6.8268e-03, -2.1966e-02]],\n",
      "\n",
      "          [[-1.4924e-02, -1.7679e-02,  1.5935e-03],\n",
      "           [ 1.0160e-03,  1.5082e-03, -9.0721e-03],\n",
      "           [ 2.4340e-02,  8.5690e-03, -1.3533e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.0598e-02,  4.6999e-03,  4.9771e-03],\n",
      "           [-1.6475e-02, -3.6712e-03,  3.5582e-03],\n",
      "           [-1.3137e-02, -5.1010e-03, -7.0550e-03]],\n",
      "\n",
      "          [[-3.2715e-02, -8.3043e-03,  6.4399e-03],\n",
      "           [-2.4814e-02, -2.2247e-02, -1.3714e-02],\n",
      "           [-1.3546e-02, -1.6060e-02, -1.9725e-02]],\n",
      "\n",
      "          [[-3.6309e-02, -2.5577e-02, -9.3102e-03],\n",
      "           [-1.9232e-02, -3.8305e-03,  1.8157e-03],\n",
      "           [ 6.1745e-03,  4.5898e-03, -1.6173e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.7293e-02,  5.2695e-03, -2.1360e-02],\n",
      "           [ 4.1415e-03, -3.0585e-03, -9.2284e-03],\n",
      "           [ 5.0580e-04, -1.4719e-02, -2.5318e-03]],\n",
      "\n",
      "          [[-2.4886e-04,  4.1577e-03, -2.1930e-03],\n",
      "           [-1.6814e-02, -1.6534e-02, -1.7037e-02],\n",
      "           [-7.0615e-03, -1.0527e-02, -2.2450e-02]],\n",
      "\n",
      "          [[ 1.2564e-02, -2.3435e-03,  5.3096e-03],\n",
      "           [ 4.4789e-03,  1.6960e-03, -1.1735e-02],\n",
      "           [ 1.2185e-02,  1.6572e-04,  1.2947e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 6.4327e-03,  1.2680e-02, -8.0523e-04],\n",
      "           [ 1.1063e-02,  1.6079e-02,  1.0169e-02],\n",
      "           [ 1.2023e-03, -1.1035e-03,  1.4347e-02]],\n",
      "\n",
      "          [[ 7.0798e-03,  1.6890e-02,  1.2048e-02],\n",
      "           [-1.4653e-02,  1.9025e-03, -1.4791e-02],\n",
      "           [ 9.9854e-03, -1.4378e-02, -1.0758e-02]],\n",
      "\n",
      "          [[-9.5864e-03,  1.3903e-03, -2.4405e-02],\n",
      "           [-5.0075e-03, -3.2206e-03, -2.0077e-02],\n",
      "           [-2.0662e-02, -2.9181e-03, -1.4396e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0635e-02,  6.5736e-03,  1.0281e-02],\n",
      "           [ 8.4076e-04,  3.4735e-03, -5.6936e-03],\n",
      "           [ 1.6729e-03,  1.6633e-02,  8.8888e-03]],\n",
      "\n",
      "          [[ 4.2098e-03,  1.7471e-02, -7.0626e-03],\n",
      "           [ 1.5130e-02,  2.7416e-03,  1.2877e-03],\n",
      "           [ 1.4698e-02,  2.4931e-02,  8.7254e-03]],\n",
      "\n",
      "          [[ 2.8324e-02,  1.1978e-02, -5.4018e-03],\n",
      "           [ 5.1195e-03,  1.6408e-03,  1.3088e-02],\n",
      "           [ 1.0950e-02,  1.9318e-02,  2.7497e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.3714e-02,  5.4451e-03, -2.5361e-03],\n",
      "           [ 7.1436e-03, -1.1525e-02,  6.3381e-03],\n",
      "           [-2.3450e-02,  1.7284e-03,  3.5425e-03]],\n",
      "\n",
      "          [[-3.2116e-03,  1.5989e-02,  4.4953e-03],\n",
      "           [ 2.5816e-03, -1.2583e-04, -2.5267e-02],\n",
      "           [-1.6447e-02, -1.1073e-03, -8.8027e-03]],\n",
      "\n",
      "          [[-8.0254e-03, -2.2111e-02, -3.3946e-02],\n",
      "           [-8.4837e-03,  1.1464e-02, -1.3390e-02],\n",
      "           [ 3.3392e-03, -1.7971e-02, -4.5006e-04]]],\n",
      "\n",
      "\n",
      "         [[[-5.6704e-05,  9.4474e-03,  3.9029e-03],\n",
      "           [-1.7398e-02,  8.3222e-03, -7.3807e-03],\n",
      "           [ 2.6578e-03, -1.4138e-02, -1.5440e-02]],\n",
      "\n",
      "          [[-5.6003e-03, -2.5953e-03,  2.9737e-03],\n",
      "           [ 1.1455e-05, -1.5716e-02, -2.4759e-02],\n",
      "           [-4.7669e-03, -1.2890e-03,  4.1789e-03]],\n",
      "\n",
      "          [[-1.4376e-02,  7.3816e-03, -1.1761e-02],\n",
      "           [-1.0922e-02,  1.1409e-02, -1.6540e-02],\n",
      "           [-8.2246e-03, -2.1297e-02, -1.8940e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.3092e-03, -1.9293e-03, -1.2687e-02],\n",
      "           [ 1.8682e-02, -7.5120e-03, -4.8224e-03],\n",
      "           [-9.5537e-03, -1.2712e-02, -8.3659e-03]],\n",
      "\n",
      "          [[ 2.5305e-03, -9.9657e-03,  8.8312e-03],\n",
      "           [ 2.5311e-03,  1.1349e-03,  3.6956e-03],\n",
      "           [-4.7839e-03, -6.8617e-03, -5.6083e-03]],\n",
      "\n",
      "          [[-3.5016e-03, -4.8061e-03, -1.0997e-02],\n",
      "           [-4.8756e-03,  1.5880e-02,  8.0048e-03],\n",
      "           [-2.2942e-03,  2.1856e-03,  1.7296e-04]]]]], device='cuda:0')), ('module.down_layers.3.1.conv2.conv.weight', tensor([[[[[ 2.1053e-02,  3.5637e-05, -1.2172e-02],\n",
      "           [ 7.5165e-03, -2.3086e-03, -8.1941e-03],\n",
      "           [ 9.7003e-04, -1.8249e-02, -2.0730e-02]],\n",
      "\n",
      "          [[ 2.6751e-03, -3.3154e-03,  1.0350e-02],\n",
      "           [ 7.6860e-03, -1.1802e-02, -1.6110e-03],\n",
      "           [-9.4865e-03, -1.2336e-02, -1.3706e-02]],\n",
      "\n",
      "          [[ 5.8751e-03,  4.0846e-03, -7.6888e-04],\n",
      "           [ 8.7542e-03,  5.9294e-03,  1.3154e-02],\n",
      "           [-2.9131e-03, -2.2929e-02, -1.2746e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.7202e-02,  1.6371e-02, -2.0767e-02],\n",
      "           [ 8.0479e-03,  6.8466e-03, -8.1988e-03],\n",
      "           [ 2.2318e-02, -2.2287e-03, -1.4329e-02]],\n",
      "\n",
      "          [[ 1.8077e-02, -3.7208e-03, -9.1413e-03],\n",
      "           [ 2.5716e-02,  7.7349e-03,  9.1488e-03],\n",
      "           [ 1.0909e-02,  2.5503e-03, -6.6722e-03]],\n",
      "\n",
      "          [[-6.9638e-03, -1.3868e-03, -7.1020e-04],\n",
      "           [ 2.5816e-02,  2.2235e-03, -2.6438e-03],\n",
      "           [ 1.6003e-02, -1.8748e-02, -1.2702e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.5249e-02,  1.8213e-02, -5.4244e-03],\n",
      "           [ 1.2799e-02, -1.0852e-02, -4.7603e-03],\n",
      "           [-9.6208e-03, -8.2757e-03, -1.6667e-02]],\n",
      "\n",
      "          [[-4.9200e-03, -2.6042e-03,  8.5536e-03],\n",
      "           [ 8.8436e-03, -1.1802e-02,  1.1929e-02],\n",
      "           [-1.4578e-02,  6.0238e-03,  3.3849e-03]],\n",
      "\n",
      "          [[-1.1446e-02, -2.4183e-02, -2.1001e-02],\n",
      "           [ 6.1780e-03,  5.8769e-03, -1.2431e-02],\n",
      "           [-2.9688e-02, -2.2355e-02, -2.5881e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.9202e-03,  7.7147e-03, -1.4738e-02],\n",
      "           [-7.3390e-03, -1.0717e-02, -1.3320e-02],\n",
      "           [-2.6538e-03, -1.7343e-02, -1.2853e-03]],\n",
      "\n",
      "          [[-1.4918e-02, -1.5690e-02, -1.4481e-03],\n",
      "           [-7.9969e-03, -2.5572e-02,  1.2223e-03],\n",
      "           [-5.4320e-03, -2.8810e-02, -1.1825e-02]],\n",
      "\n",
      "          [[-3.5186e-03,  2.3239e-03,  3.9850e-03],\n",
      "           [-7.2305e-03, -1.0807e-02, -1.1431e-02],\n",
      "           [ 5.3743e-03, -2.4101e-02, -1.6112e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.3601e-02, -1.0824e-02, -1.1750e-02],\n",
      "           [ 3.7039e-03, -1.9903e-02, -1.7052e-03],\n",
      "           [-2.3001e-04, -1.2285e-02, -1.3300e-02]],\n",
      "\n",
      "          [[-1.8869e-02, -2.3061e-02, -1.3675e-02],\n",
      "           [-8.8509e-03, -1.6435e-02, -1.9494e-02],\n",
      "           [ 5.3194e-03,  5.4413e-03, -1.7715e-02]],\n",
      "\n",
      "          [[-3.9654e-03, -1.1060e-02,  1.1167e-02],\n",
      "           [ 1.0748e-03, -6.3331e-03, -3.8947e-03],\n",
      "           [ 1.8148e-02,  1.9995e-02, -5.0894e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 1.9250e-02,  4.5887e-03,  1.0230e-02],\n",
      "           [ 2.2742e-04, -4.8412e-04,  2.1892e-02],\n",
      "           [ 1.2527e-02,  8.7549e-03,  7.3799e-03]],\n",
      "\n",
      "          [[-1.8348e-03,  6.3730e-03, -1.4867e-02],\n",
      "           [ 4.5980e-03, -8.6698e-03, -4.3024e-03],\n",
      "           [ 4.8178e-03,  9.9872e-03,  2.7178e-03]],\n",
      "\n",
      "          [[-7.5048e-03, -1.7283e-02, -1.2597e-02],\n",
      "           [ 1.0487e-02,  7.7951e-03,  8.4288e-03],\n",
      "           [ 8.7963e-03, -1.1135e-02,  7.2857e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.3956e-03,  1.7130e-02,  2.0817e-03],\n",
      "           [-7.9905e-03,  1.6057e-02, -7.5157e-03],\n",
      "           [-5.9524e-03, -1.7632e-02, -2.0802e-02]],\n",
      "\n",
      "          [[ 5.9535e-03,  5.1794e-03,  5.9316e-03],\n",
      "           [ 5.5646e-03,  1.7581e-02,  2.7576e-03],\n",
      "           [ 1.4517e-02,  1.0172e-02, -1.4228e-02]],\n",
      "\n",
      "          [[-3.3135e-03,  2.0040e-02,  8.7341e-03],\n",
      "           [ 1.9920e-02,  5.7634e-03,  1.9300e-02],\n",
      "           [ 9.2353e-03,  1.4926e-02, -3.4458e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.8107e-02, -2.4899e-02, -1.9570e-02],\n",
      "           [ 8.9824e-04,  6.8393e-03, -5.6012e-03],\n",
      "           [ 1.6312e-02,  1.9307e-02, -5.1090e-03]],\n",
      "\n",
      "          [[-1.3998e-02, -1.2779e-02, -2.2422e-03],\n",
      "           [ 1.1818e-02,  2.6775e-02,  6.3205e-03],\n",
      "           [ 1.3316e-02,  9.0571e-03, -3.4154e-04]],\n",
      "\n",
      "          [[-6.4504e-04, -9.0502e-03, -1.2053e-03],\n",
      "           [-4.2879e-03,  3.1185e-02,  1.7545e-02],\n",
      "           [ 4.5383e-03,  2.1225e-02, -1.1921e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.5507e-03, -1.6533e-02, -5.7512e-04],\n",
      "           [-1.2158e-02, -6.5698e-03, -1.3204e-02],\n",
      "           [ 1.0156e-02,  1.6017e-02,  7.5194e-03]],\n",
      "\n",
      "          [[ 3.9144e-03,  1.2859e-02,  6.0889e-03],\n",
      "           [ 1.0540e-02,  4.8875e-03,  1.4073e-02],\n",
      "           [ 2.7545e-02, -1.0511e-03, -1.0735e-02]],\n",
      "\n",
      "          [[-9.3899e-03,  1.9666e-02, -7.3838e-03],\n",
      "           [-2.8168e-03,  2.2169e-02,  2.6816e-02],\n",
      "           [ 2.0971e-03,  2.0482e-02, -1.0018e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.6463e-02, -1.4014e-02, -5.8592e-03],\n",
      "           [-1.5433e-02, -1.1413e-02,  8.3223e-03],\n",
      "           [-8.1686e-03,  1.9159e-03,  5.4083e-03]],\n",
      "\n",
      "          [[-1.0458e-03, -1.4827e-02,  1.2118e-03],\n",
      "           [-1.3452e-02, -1.8445e-02, -7.8450e-03],\n",
      "           [ 4.6465e-03,  8.9299e-03,  7.0944e-03]],\n",
      "\n",
      "          [[-9.6530e-03, -8.0076e-03,  4.8607e-03],\n",
      "           [-2.0257e-03, -8.8763e-04,  2.5919e-03],\n",
      "           [ 9.7384e-03, -3.2019e-03, -3.7676e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.8411e-02,  1.2519e-02,  2.3833e-02],\n",
      "           [ 7.3262e-03,  1.0988e-02,  4.3066e-03],\n",
      "           [ 1.2856e-02,  2.6981e-03,  1.1890e-02]],\n",
      "\n",
      "          [[ 1.9581e-02,  3.1300e-03,  2.0663e-02],\n",
      "           [ 3.1899e-03,  6.2282e-03, -3.8691e-03],\n",
      "           [ 1.2813e-02, -1.7206e-02, -1.7537e-02]],\n",
      "\n",
      "          [[ 2.3788e-02,  1.3705e-02,  2.1269e-02],\n",
      "           [ 8.5067e-03,  1.2829e-02, -1.5006e-03],\n",
      "           [ 9.9968e-03, -2.0006e-02, -1.7327e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.9256e-02,  7.2163e-03,  7.2967e-03],\n",
      "           [-1.9386e-03,  1.2571e-02,  1.0199e-02],\n",
      "           [-5.1329e-03,  2.4353e-02,  1.3877e-02]],\n",
      "\n",
      "          [[ 1.9411e-02,  2.2466e-02,  1.8280e-02],\n",
      "           [ 1.7778e-02,  3.2117e-02,  1.4951e-02],\n",
      "           [ 1.5226e-02,  1.3334e-02,  2.2861e-02]],\n",
      "\n",
      "          [[ 1.8936e-02,  2.8658e-02,  7.1476e-03],\n",
      "           [ 1.7742e-02,  3.6682e-02,  1.1362e-02],\n",
      "           [ 7.7785e-03, -3.1826e-03, -9.2709e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.6399e-03, -1.7258e-02,  7.0770e-03],\n",
      "           [ 1.0297e-02,  2.1457e-03,  1.2251e-02],\n",
      "           [-9.9970e-03, -3.8380e-03, -8.9990e-03]],\n",
      "\n",
      "          [[ 4.4686e-03,  1.0050e-03,  1.0540e-02],\n",
      "           [ 4.0055e-03,  2.3238e-03, -3.0333e-03],\n",
      "           [-7.8516e-03,  1.3048e-02,  7.5222e-03]],\n",
      "\n",
      "          [[-3.3404e-03, -8.1033e-03,  1.4861e-02],\n",
      "           [ 8.0110e-03,  1.8597e-03, -1.7437e-02],\n",
      "           [-6.9345e-03, -2.9784e-02, -5.6583e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 7.8254e-03,  7.0578e-03, -3.6136e-03],\n",
      "           [ 9.3033e-03, -9.7413e-05,  1.8786e-02],\n",
      "           [ 3.0794e-03,  1.3016e-02,  1.4496e-03]],\n",
      "\n",
      "          [[-4.2012e-03,  7.1372e-03,  1.8052e-03],\n",
      "           [ 1.0373e-02,  1.7993e-03,  1.9376e-02],\n",
      "           [ 1.2662e-02,  1.5889e-02,  9.1901e-03]],\n",
      "\n",
      "          [[-5.5759e-03, -2.5816e-03, -5.6258e-03],\n",
      "           [-1.4750e-02,  8.8818e-03, -1.1577e-02],\n",
      "           [-5.2856e-03, -2.6517e-03, -2.5745e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1368e-04, -9.0940e-03, -1.3772e-02],\n",
      "           [-1.1772e-02,  6.2308e-03, -1.4322e-03],\n",
      "           [ 1.4652e-02,  2.6926e-03,  1.9903e-02]],\n",
      "\n",
      "          [[-9.7342e-03,  3.8758e-03,  2.6507e-02],\n",
      "           [-5.7822e-03, -3.9758e-03,  6.5081e-04],\n",
      "           [-1.0088e-03, -3.4058e-04, -1.5000e-03]],\n",
      "\n",
      "          [[-1.0064e-03, -2.7066e-03,  4.5813e-03],\n",
      "           [-6.6764e-03, -7.8361e-03,  1.1437e-02],\n",
      "           [-1.8411e-02, -6.2151e-03, -1.6861e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-7.9207e-03, -1.6514e-02,  1.1629e-02],\n",
      "           [-2.8034e-02, -1.8757e-02, -1.3201e-02],\n",
      "           [-2.6886e-02, -1.1227e-02, -2.8211e-02]],\n",
      "\n",
      "          [[-2.0759e-02, -4.3314e-04,  3.7420e-04],\n",
      "           [ 3.9279e-03, -6.0919e-03, -2.6946e-03],\n",
      "           [-3.6336e-03, -5.6562e-03, -2.4232e-02]],\n",
      "\n",
      "          [[ 9.3855e-03,  1.3326e-02,  5.7146e-03],\n",
      "           [ 2.3148e-02,  6.3529e-03, -1.9194e-03],\n",
      "           [ 3.7934e-02,  3.4358e-02, -7.4012e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 1.8833e-02, -5.9556e-04,  1.4480e-02],\n",
      "           [-1.0540e-02, -1.8095e-02, -5.2431e-03],\n",
      "           [-6.8790e-03, -8.2007e-04, -1.5491e-02]],\n",
      "\n",
      "          [[ 2.4329e-02,  4.9504e-03,  1.8059e-02],\n",
      "           [ 1.3064e-02,  5.1687e-04, -8.3096e-03],\n",
      "           [ 3.6687e-03,  1.2960e-02,  6.7356e-03]],\n",
      "\n",
      "          [[ 1.3481e-02,  1.6353e-03,  1.4995e-02],\n",
      "           [ 2.9455e-02,  1.3830e-02,  6.4228e-03],\n",
      "           [ 1.7385e-02,  1.7987e-02,  7.6322e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.8092e-02, -5.0516e-03, -2.9887e-03],\n",
      "           [ 4.9243e-03, -1.4459e-02,  4.9862e-03],\n",
      "           [ 4.5046e-03, -1.5464e-02, -7.9961e-03]],\n",
      "\n",
      "          [[ 2.0026e-02,  9.4251e-03,  2.4503e-02],\n",
      "           [ 7.2217e-03, -1.1177e-02,  1.3128e-02],\n",
      "           [ 6.2865e-03,  4.7029e-03,  8.7160e-03]],\n",
      "\n",
      "          [[ 3.6937e-04,  1.3262e-02,  2.3504e-02],\n",
      "           [-1.7441e-02, -1.7024e-02,  8.5137e-03],\n",
      "           [-2.6127e-02, -1.6683e-02, -2.1615e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.5723e-03,  9.2507e-03, -5.6424e-03],\n",
      "           [ 1.2338e-02, -6.1541e-03, -8.1376e-03],\n",
      "           [ 9.3755e-03, -1.3366e-02,  1.4179e-02]],\n",
      "\n",
      "          [[-4.1155e-03, -1.5203e-02, -2.0869e-03],\n",
      "           [-3.9279e-03,  7.4676e-03,  1.7480e-02],\n",
      "           [ 9.0424e-03,  2.3519e-02,  1.0161e-02]],\n",
      "\n",
      "          [[-2.7278e-03,  2.6893e-03, -1.9676e-02],\n",
      "           [-3.0375e-03,  5.8878e-03, -1.5554e-02],\n",
      "           [ 2.4948e-02,  3.2835e-03,  3.3377e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3167e-02,  2.2074e-04, -1.6051e-03],\n",
      "           [-8.4587e-03,  1.6428e-02, -8.3074e-05],\n",
      "           [ 1.7284e-04, -3.3910e-03,  1.0796e-02]],\n",
      "\n",
      "          [[ 1.2656e-04, -2.0152e-02, -1.0023e-02],\n",
      "           [-9.0433e-03,  2.8924e-03, -1.7579e-02],\n",
      "           [ 1.1747e-02,  4.1361e-06,  1.3503e-02]],\n",
      "\n",
      "          [[ 1.1540e-02, -1.6815e-02, -2.7089e-02],\n",
      "           [ 7.6644e-03,  7.9133e-03,  5.7790e-04],\n",
      "           [ 1.8295e-02,  2.6155e-02,  1.1731e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.7099e-02,  7.0559e-03,  2.3315e-02],\n",
      "           [ 1.2735e-03,  2.3567e-02,  1.5869e-02],\n",
      "           [-1.6018e-02, -3.0180e-03, -5.9307e-03]],\n",
      "\n",
      "          [[ 3.1024e-03,  2.2235e-02, -1.6183e-02],\n",
      "           [ 4.9196e-03, -1.1420e-03, -2.1737e-02],\n",
      "           [ 1.8282e-03,  5.7281e-03, -1.0329e-04]],\n",
      "\n",
      "          [[ 9.1901e-03, -1.5985e-03, -9.8760e-03],\n",
      "           [-9.3412e-03, -1.0603e-02, -1.2537e-02],\n",
      "           [ 6.8355e-03, -9.0329e-03, -7.7887e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.6554e-02,  1.1533e-02,  1.8387e-02],\n",
      "           [ 1.2675e-03,  7.3574e-03,  4.5981e-03],\n",
      "           [-3.6693e-03,  2.1398e-02,  1.0610e-02]],\n",
      "\n",
      "          [[ 1.5172e-02,  1.9457e-02,  4.3622e-03],\n",
      "           [ 3.0282e-03,  4.0431e-03,  7.6110e-03],\n",
      "           [ 3.9472e-03,  6.4583e-03,  2.6026e-04]],\n",
      "\n",
      "          [[ 1.5195e-03, -1.1728e-02, -1.1264e-02],\n",
      "           [-9.1936e-03, -3.8439e-03, -6.4113e-03],\n",
      "           [-1.8890e-02, -3.4576e-02, -1.3232e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.3156e-03,  1.8563e-02,  6.3949e-03],\n",
      "           [-1.4086e-02,  4.9350e-03,  6.8827e-03],\n",
      "           [-1.5528e-02, -1.4685e-02,  6.9067e-03]],\n",
      "\n",
      "          [[-1.3468e-02, -5.6161e-03,  8.4188e-03],\n",
      "           [-1.6880e-02, -3.5317e-05,  1.1765e-02],\n",
      "           [-2.3452e-02, -1.8891e-02, -1.0733e-03]],\n",
      "\n",
      "          [[-2.0160e-02, -5.7631e-03, -1.1177e-02],\n",
      "           [-4.0637e-02, -1.1474e-02, -7.2002e-03],\n",
      "           [-3.5348e-02, -3.0576e-02, -1.8963e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.0475e-03, -7.9174e-03, -1.1077e-02],\n",
      "           [ 1.0371e-02,  1.8073e-03,  8.3912e-03],\n",
      "           [ 3.5108e-04,  9.2894e-03, -1.3682e-02]],\n",
      "\n",
      "          [[-1.2520e-02, -1.2019e-02, -1.9450e-02],\n",
      "           [-6.6084e-03,  2.9894e-03, -2.1374e-02],\n",
      "           [-6.0298e-03, -1.1317e-02, -1.5472e-02]],\n",
      "\n",
      "          [[ 1.4940e-02, -1.7817e-04, -9.5976e-03],\n",
      "           [ 2.3358e-03,  8.6916e-03, -2.2051e-02],\n",
      "           [ 3.3413e-03,  1.1805e-02, -2.2338e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.7373e-04,  6.5315e-03,  2.7056e-02],\n",
      "           [ 9.2063e-03,  9.1520e-03,  8.4950e-03],\n",
      "           [-1.0107e-03,  1.4083e-02, -1.3561e-02]],\n",
      "\n",
      "          [[-1.3677e-02, -6.0512e-06, -1.5181e-02],\n",
      "           [ 9.9474e-03,  8.8503e-03,  1.5450e-02],\n",
      "           [ 2.5951e-03,  1.0474e-02,  1.9131e-03]],\n",
      "\n",
      "          [[ 1.1504e-02, -5.9311e-03, -1.1580e-02],\n",
      "           [ 1.5777e-02,  8.5944e-03, -6.4118e-04],\n",
      "           [ 2.7438e-02,  1.2066e-02, -7.3542e-03]]],\n",
      "\n",
      "\n",
      "         [[[-9.3424e-03,  1.4813e-02, -1.1898e-02],\n",
      "           [-2.5730e-03,  1.0354e-02, -9.0999e-03],\n",
      "           [-9.4810e-03,  6.8904e-03, -1.9098e-02]],\n",
      "\n",
      "          [[ 1.3538e-02, -1.4064e-03,  8.0689e-03],\n",
      "           [ 1.5578e-03, -9.6763e-03,  1.3477e-02],\n",
      "           [ 5.3895e-03,  1.3827e-02, -1.4194e-02]],\n",
      "\n",
      "          [[-2.3016e-02, -1.8302e-02, -2.1982e-02],\n",
      "           [-4.6311e-03,  1.2133e-02, -3.3737e-03],\n",
      "           [ 2.0656e-02,  1.3204e-02,  1.6277e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.7218e-03, -6.4211e-03, -1.4019e-02],\n",
      "           [ 1.3110e-02,  1.9906e-02,  7.2818e-03],\n",
      "           [ 1.0784e-02,  1.6731e-02, -3.3993e-03]],\n",
      "\n",
      "          [[ 1.0230e-03,  1.1820e-03, -1.7028e-03],\n",
      "           [ 1.3744e-02,  2.1841e-03, -2.1950e-02],\n",
      "           [ 4.8625e-03,  4.0478e-03, -1.3077e-02]],\n",
      "\n",
      "          [[ 1.2973e-02,  1.8196e-03, -1.0694e-02],\n",
      "           [ 2.0392e-03,  1.0942e-02, -3.2541e-03],\n",
      "           [ 1.8407e-02, -5.4925e-03, -1.2820e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 6.2754e-03,  1.4498e-02, -2.8403e-03],\n",
      "           [ 1.1965e-02,  1.2352e-02, -1.2757e-02],\n",
      "           [ 1.4810e-02,  1.6466e-03,  1.6465e-03]],\n",
      "\n",
      "          [[ 2.5809e-03,  8.0295e-03, -1.3868e-02],\n",
      "           [ 9.6773e-03,  4.2819e-03,  3.3965e-03],\n",
      "           [ 4.4144e-03,  2.2623e-02, -3.3665e-04]],\n",
      "\n",
      "          [[ 3.2974e-03, -4.5548e-03, -2.1912e-02],\n",
      "           [-3.3320e-03,  4.2784e-03,  6.9331e-03],\n",
      "           [-2.1754e-02, -1.3357e-02, -1.5032e-02]]],\n",
      "\n",
      "\n",
      "         [[[-9.6009e-03,  1.3202e-02,  1.3523e-02],\n",
      "           [-8.4718e-03,  5.7060e-03,  1.5253e-02],\n",
      "           [-5.7104e-03,  5.4683e-03,  2.1724e-02]],\n",
      "\n",
      "          [[-1.2703e-02,  9.1149e-03,  1.3649e-02],\n",
      "           [-1.5011e-02,  5.1776e-03,  1.5277e-02],\n",
      "           [-5.8721e-03, -7.5901e-03,  9.3663e-03]],\n",
      "\n",
      "          [[-1.1020e-03,  1.6290e-02, -4.9338e-03],\n",
      "           [-3.1184e-02, -5.1578e-03,  1.1274e-02],\n",
      "           [-1.9174e-02, -2.1081e-02,  4.0788e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.2134e-03,  3.5735e-03, -2.1015e-02],\n",
      "           [ 1.2756e-02,  1.0748e-02, -6.8712e-03],\n",
      "           [ 5.6940e-03,  3.7327e-03, -1.3560e-02]],\n",
      "\n",
      "          [[ 9.7524e-03,  2.2673e-03, -1.1615e-03],\n",
      "           [ 9.9164e-03,  8.2943e-03, -1.6661e-02],\n",
      "           [ 6.7131e-03, -1.3941e-02, -2.3887e-02]],\n",
      "\n",
      "          [[ 1.8248e-02,  2.4367e-02,  6.0532e-04],\n",
      "           [ 1.6850e-02,  1.2719e-02,  1.1067e-03],\n",
      "           [ 1.9805e-03,  1.6257e-02,  7.5795e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.3550e-02, -1.8247e-02, -1.2232e-02],\n",
      "           [-1.7913e-02,  4.6802e-03, -2.1647e-02],\n",
      "           [-1.1886e-02, -2.2441e-02, -1.7997e-02]],\n",
      "\n",
      "          [[ 5.3728e-03, -3.1051e-03,  1.6771e-02],\n",
      "           [ 2.7382e-03, -1.0153e-02, -5.8471e-03],\n",
      "           [-2.1274e-03, -2.3332e-02, -2.0351e-03]],\n",
      "\n",
      "          [[-1.4906e-02, -1.6136e-02,  2.0070e-02],\n",
      "           [-2.7763e-02, -2.0389e-02, -8.1952e-03],\n",
      "           [-1.5788e-02, -1.7647e-02, -9.8699e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.0156e-02, -2.1844e-02, -2.4383e-02],\n",
      "           [-2.2194e-02, -2.5572e-02, -9.3990e-03],\n",
      "           [-1.2569e-02, -2.8025e-02, -3.3929e-02]],\n",
      "\n",
      "          [[-1.5262e-02,  1.3640e-02,  2.0306e-02],\n",
      "           [-3.9719e-03,  5.5153e-03, -5.2493e-03],\n",
      "           [ 5.5846e-03, -1.3925e-02, -2.0878e-02]],\n",
      "\n",
      "          [[ 6.1197e-03,  1.9042e-02,  3.2298e-02],\n",
      "           [-1.6582e-02, -9.2992e-03,  7.3406e-03],\n",
      "           [-9.4064e-03, -2.3120e-02, -1.2917e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.6123e-02, -3.7967e-02, -1.1914e-02],\n",
      "           [-2.1930e-02, -1.5140e-02, -1.0680e-02],\n",
      "           [-9.0823e-03, -2.3384e-02, -1.3397e-02]],\n",
      "\n",
      "          [[-1.2025e-02, -2.4002e-02, -4.4591e-04],\n",
      "           [-1.0797e-02, -2.6045e-02, -1.1529e-02],\n",
      "           [-2.5548e-02, -2.2047e-02, -1.1186e-02]],\n",
      "\n",
      "          [[ 2.5702e-03, -1.7557e-02,  3.1927e-02],\n",
      "           [-1.5925e-02, -1.3304e-02,  5.9158e-03],\n",
      "           [ 1.8015e-03,  9.3611e-03,  1.8155e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.1082e-02, -1.0846e-02, -1.2347e-02],\n",
      "           [-7.0408e-03, -6.8769e-03, -6.0369e-03],\n",
      "           [-1.0339e-02, -2.9495e-03,  4.3539e-04]],\n",
      "\n",
      "          [[ 1.0838e-03,  5.7301e-04, -2.7354e-03],\n",
      "           [-3.5493e-03, -4.3181e-03,  8.3566e-03],\n",
      "           [-1.4059e-02, -4.2941e-03, -3.5968e-03]],\n",
      "\n",
      "          [[ 2.1074e-03, -6.0671e-03, -7.5741e-03],\n",
      "           [-1.1598e-02, -2.8984e-03, -1.2923e-03],\n",
      "           [-5.1817e-03,  1.0763e-02,  5.6921e-03]]],\n",
      "\n",
      "\n",
      "         [[[-9.1026e-03, -1.5177e-02, -1.3559e-02],\n",
      "           [ 8.8660e-03,  6.4564e-04, -7.8754e-03],\n",
      "           [ 1.6604e-02,  2.2137e-02, -5.0785e-03]],\n",
      "\n",
      "          [[ 4.8890e-03,  1.8808e-03, -5.5435e-03],\n",
      "           [ 1.5120e-02, -2.9108e-03,  4.8271e-04],\n",
      "           [ 8.6664e-03,  1.9161e-02, -1.0389e-03]],\n",
      "\n",
      "          [[ 1.7080e-02,  1.0939e-02,  3.6765e-03],\n",
      "           [ 1.7248e-02,  9.5180e-03,  9.7003e-03],\n",
      "           [ 2.5542e-02,  2.8842e-02,  1.0494e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 8.4646e-04, -8.9784e-03,  1.0640e-02],\n",
      "           [ 1.8085e-03,  5.9065e-04, -6.5059e-03],\n",
      "           [ 3.0976e-04, -1.1126e-02,  1.5382e-02]],\n",
      "\n",
      "          [[-5.8211e-03, -1.4915e-02,  7.2674e-03],\n",
      "           [ 2.7738e-03, -4.1891e-03,  2.1742e-02],\n",
      "           [-4.9239e-03, -1.4375e-02,  2.3419e-02]],\n",
      "\n",
      "          [[-3.4351e-03, -9.4437e-03,  1.4472e-02],\n",
      "           [ 1.7785e-02,  2.5179e-04,  3.8551e-02],\n",
      "           [-1.2526e-04, -9.9315e-03,  1.9650e-02]]]]], device='cuda:0')), ('module.down_layers.3.2.norm1.weight', tensor([0.9170, 0.9130, 0.8728, 0.9671, 0.9229, 0.9804, 0.9468, 0.9166, 0.9574,\n",
      "        0.9310, 0.9482, 0.9479, 0.8974, 0.9372, 0.9275, 0.9280, 0.9599, 0.9756,\n",
      "        0.9709, 0.9333, 0.9694, 0.9519, 0.9641, 0.9204, 0.8762, 0.9730, 0.9673,\n",
      "        0.9641, 0.9540, 0.9447, 0.9663, 0.9521, 0.9291, 0.9829, 0.7999, 0.9211,\n",
      "        0.9406, 0.9405, 0.9266, 0.9703, 0.8474, 0.9616, 0.9699, 0.9186, 0.9516,\n",
      "        0.9113, 0.9618, 0.9801, 0.8907, 0.9493, 0.9257, 0.9460, 0.9484, 0.9487,\n",
      "        0.8986, 0.8289, 0.9491, 0.9286, 0.9337, 0.9336, 0.8633, 0.9450, 0.9694,\n",
      "        0.9423, 0.9496, 0.9754, 0.8468, 0.9411, 0.9228, 0.9473, 0.8897, 0.9430,\n",
      "        0.9671, 0.8926, 0.9270, 0.9495, 0.9331, 0.9363, 0.9496, 0.9202, 0.9210,\n",
      "        0.9240, 0.9574, 0.9170, 0.8825, 0.8929, 0.9404, 0.9549, 0.9242, 0.9641,\n",
      "        0.9434, 0.9764, 0.9099, 0.9119, 0.9282, 0.9728, 0.9258, 0.8549, 0.9746,\n",
      "        0.9517, 0.9192, 0.8336, 0.9487, 0.9736, 0.9193, 0.9647, 0.9366, 0.9639,\n",
      "        0.8831, 0.9378, 0.9282, 0.9422, 0.9543, 0.9123, 0.9087, 0.8604, 0.9369,\n",
      "        0.9627, 0.9442, 0.9894, 0.9423, 0.9648, 0.9703, 0.9370, 0.9628, 0.9004,\n",
      "        0.8449, 0.8709], device='cuda:0')), ('module.down_layers.3.2.norm1.bias', tensor([-0.0211, -0.0311, -0.0137, -0.0113, -0.0318, -0.0011, -0.0260, -0.0063,\n",
      "        -0.0177, -0.0227, -0.0013, -0.0322, -0.0217, -0.0289, -0.0341, -0.0150,\n",
      "        -0.0094, -0.0103, -0.0337, -0.0300, -0.0202, -0.0292, -0.0049, -0.0364,\n",
      "        -0.0475, -0.0162, -0.0189, -0.0090, -0.0168, -0.0128, -0.0303, -0.0173,\n",
      "         0.0047, -0.0123, -0.0411, -0.0106, -0.0120, -0.0324,  0.0015, -0.0072,\n",
      "        -0.0397, -0.0062, -0.0044, -0.0191, -0.0264, -0.0186, -0.0082,  0.0091,\n",
      "        -0.0169, -0.0335, -0.0093, -0.0265, -0.0130, -0.0102, -0.0409, -0.0272,\n",
      "        -0.0184, -0.0186, -0.0064, -0.0225, -0.0130, -0.0207, -0.0099, -0.0402,\n",
      "        -0.0402, -0.0180, -0.0237, -0.0196, -0.0299, -0.0156, -0.0494, -0.0279,\n",
      "        -0.0261, -0.0472,  0.0023, -0.0191, -0.0229, -0.0370, -0.0179, -0.0154,\n",
      "        -0.0329, -0.0235, -0.0230, -0.0371, -0.0317, -0.0305,  0.0053, -0.0362,\n",
      "        -0.0317, -0.0081, -0.0256, -0.0114, -0.0212, -0.0350, -0.0174, -0.0036,\n",
      "        -0.0086, -0.0107, -0.0039, -0.0054, -0.0098,  0.0046, -0.0305, -0.0108,\n",
      "        -0.0231, -0.0103, -0.0123, -0.0098, -0.0242, -0.0143,  0.0007, -0.0085,\n",
      "        -0.0110, -0.0128, -0.0266, -0.0304, -0.0276, -0.0159, -0.0271, -0.0027,\n",
      "        -0.0326, -0.0124, -0.0077, -0.0285, -0.0145, -0.0465, -0.0435, -0.0199],\n",
      "       device='cuda:0')), ('module.down_layers.3.2.norm2.weight', tensor([0.6920, 0.9490, 0.9127, 0.9512, 0.9533, 0.6760, 0.7690, 0.9119, 0.8975,\n",
      "        0.9175, 0.9460, 0.9259, 0.6928, 0.9499, 0.7537, 0.9536, 0.9507, 0.9579,\n",
      "        0.9446, 0.8072, 0.9178, 0.9044, 0.9318, 0.6310, 0.9418, 0.6995, 0.6302,\n",
      "        0.7636, 0.8982, 0.9476, 0.9456, 0.9506, 0.9263, 0.9171, 0.9339, 0.8423,\n",
      "        0.9621, 0.8989, 0.8757, 0.8541, 0.8434, 0.9258, 0.8580, 0.9199, 0.7753,\n",
      "        0.9536, 0.9064, 0.8883, 0.9584, 0.9646, 0.7659, 0.9289, 0.7994, 0.9698,\n",
      "        0.9533, 0.9459, 0.7446, 0.8236, 0.7519, 0.8699, 0.7799, 0.9410, 0.9761,\n",
      "        0.9293, 0.9311, 0.8790, 0.9461, 0.9575, 0.9034, 0.9204, 0.9010, 0.8659,\n",
      "        0.9667, 0.9660, 0.9278, 0.9460, 0.8912, 0.9643, 0.9033, 0.8039, 0.9411,\n",
      "        0.9541, 0.9265, 0.8182, 0.8774, 0.9239, 0.9228, 0.8919, 0.9436, 0.6761,\n",
      "        0.9217, 0.6803, 0.9220, 0.9593, 0.5910, 0.7353, 0.8283, 0.9385, 0.8122,\n",
      "        0.7777, 0.9390, 0.9483, 0.7486, 0.9433, 0.7528, 0.8939, 0.7806, 0.9458,\n",
      "        0.9704, 0.8984, 0.7839, 0.9344, 0.8336, 0.8302, 0.9756, 0.9864, 0.9689,\n",
      "        0.9548, 0.9625, 0.9035, 0.8179, 0.9632, 0.8622, 0.8923, 0.8303, 0.9007,\n",
      "        0.8824, 0.9269], device='cuda:0')), ('module.down_layers.3.2.norm2.bias', tensor([-6.5306e-02, -3.3393e-02, -4.0301e-02, -3.7159e-02, -3.1880e-02,\n",
      "        -6.1858e-02, -2.6560e-02, -1.5556e-02, -2.8534e-02, -1.3547e-02,\n",
      "        -3.4208e-02, -3.0775e-02, -5.6696e-02, -3.0310e-02, -5.2390e-02,\n",
      "        -2.1751e-02, -1.7674e-02, -2.9663e-02, -3.3089e-02, -4.1048e-02,\n",
      "        -3.5602e-02, -2.7066e-02, -3.0938e-02, -7.2743e-02, -2.5085e-02,\n",
      "        -5.0127e-02, -2.3256e-02, -6.7389e-02, -4.4496e-02, -2.9215e-02,\n",
      "        -3.4714e-02, -2.1924e-02, -2.5902e-02, -1.3724e-02, -2.6894e-03,\n",
      "        -9.3346e-04, -1.2196e-02,  4.7323e-03, -1.0197e-02, -2.8164e-03,\n",
      "        -1.3885e-03, -9.7688e-03, -6.0583e-03, -1.1359e-02, -8.5358e-03,\n",
      "        -2.4257e-02,  5.8587e-03,  6.5597e-03, -3.3450e-02, -2.9556e-02,\n",
      "        -4.4967e-02, -1.8012e-02, -4.5874e-02, -3.1044e-02, -2.1815e-02,\n",
      "        -1.9360e-02, -4.6104e-02, -3.4128e-02, -4.3546e-02, -3.3844e-02,\n",
      "        -5.6883e-02, -2.7083e-02, -2.0078e-02, -2.4249e-02, -3.0607e-02,\n",
      "        -3.9953e-02, -1.1315e-02, -2.2889e-02, -4.0529e-02, -4.2198e-02,\n",
      "        -2.2932e-02, -4.8857e-02, -3.2685e-02, -3.1605e-02, -3.3016e-02,\n",
      "        -3.7773e-02, -3.3684e-02, -3.1607e-02, -2.1468e-02, -5.1616e-02,\n",
      "        -4.2310e-02, -1.5452e-02, -3.2888e-02, -4.7852e-02, -3.5909e-02,\n",
      "        -2.0158e-02, -3.7613e-02, -3.7941e-02, -2.4126e-02, -4.3883e-02,\n",
      "        -2.3813e-02, -6.8319e-02, -2.7139e-02, -1.2412e-02, -4.7667e-02,\n",
      "        -4.8908e-02, -2.4252e-02, -3.4822e-02, -2.0500e-02, -2.3430e-02,\n",
      "        -1.7395e-02, -2.3433e-02, -3.1475e-02, -3.0686e-02, -2.3400e-02,\n",
      "        -1.8034e-02, -2.3429e-02, -2.5257e-02, -1.1192e-02, -1.4025e-02,\n",
      "        -2.7572e-02, -3.1657e-02, -9.6915e-03, -1.0221e-02, -5.2029e-03,\n",
      "        -1.6933e-03, -6.3821e-03, -1.3840e-02, -8.0444e-03,  1.6946e-03,\n",
      "        -3.6985e-03, -8.5954e-03, -5.2793e-03, -2.4311e-05, -1.6200e-02,\n",
      "         2.0591e-03, -1.0270e-02,  7.3189e-03], device='cuda:0')), ('module.down_layers.3.2.conv1.conv.weight', tensor([[[[[ 3.0323e-03, -2.4207e-03, -7.2030e-03],\n",
      "           [-2.6596e-03, -9.2335e-03, -9.2175e-04],\n",
      "           [-2.4864e-03,  6.1655e-05,  7.0690e-04]],\n",
      "\n",
      "          [[ 4.1244e-04,  2.6710e-03,  4.1403e-03],\n",
      "           [-4.1967e-03, -8.5680e-04, -1.0357e-02],\n",
      "           [-4.3481e-03, -7.5570e-04, -4.4348e-05]],\n",
      "\n",
      "          [[-1.0693e-02,  3.8181e-03,  1.0811e-03],\n",
      "           [-4.3960e-03,  5.7523e-03, -4.1890e-04],\n",
      "           [-2.1127e-03,  3.7689e-03,  8.0055e-04]]],\n",
      "\n",
      "\n",
      "         [[[-2.7059e-03,  6.7389e-03, -2.9185e-03],\n",
      "           [-6.4572e-04,  4.6987e-03, -4.1729e-03],\n",
      "           [-2.6303e-03, -1.2434e-02, -8.3407e-03]],\n",
      "\n",
      "          [[ 9.0252e-03,  7.9071e-03,  7.8005e-04],\n",
      "           [-3.1524e-03, -1.0420e-03, -4.0156e-04],\n",
      "           [ 2.1380e-03,  5.8245e-03, -3.2243e-03]],\n",
      "\n",
      "          [[-4.3882e-03, -1.0508e-03,  5.1065e-04],\n",
      "           [ 5.1306e-03,  5.9052e-03,  8.0736e-03],\n",
      "           [-1.8573e-04,  1.2338e-02,  1.4030e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1554e-02,  7.2668e-03, -1.9370e-03],\n",
      "           [-2.1624e-03,  7.4006e-03,  5.4127e-03],\n",
      "           [ 1.4013e-02,  1.1152e-03, -1.9287e-03]],\n",
      "\n",
      "          [[ 6.3487e-03,  1.1660e-03,  4.6324e-03],\n",
      "           [ 4.9556e-04,  7.2416e-03, -1.0370e-02],\n",
      "           [-3.4586e-04,  8.6269e-03,  8.8684e-04]],\n",
      "\n",
      "          [[-1.9147e-05, -4.2510e-03, -5.0396e-03],\n",
      "           [ 7.3912e-03, -3.0001e-03,  3.2551e-03],\n",
      "           [ 8.7805e-04,  2.7740e-03, -7.0329e-04]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.1044e-03,  2.3775e-03, -7.1538e-03],\n",
      "           [ 8.7189e-03,  4.5344e-03, -5.2550e-03],\n",
      "           [-9.7442e-03, -8.8548e-03, -3.9734e-03]],\n",
      "\n",
      "          [[ 4.0794e-03,  8.9731e-03,  8.5415e-03],\n",
      "           [ 4.8767e-03, -4.3869e-03, -7.7869e-03],\n",
      "           [-1.1907e-02, -1.3841e-02, -1.3050e-03]],\n",
      "\n",
      "          [[ 4.0251e-03, -7.5892e-03,  1.7221e-03],\n",
      "           [-1.6270e-02, -1.5297e-02, -4.3357e-03],\n",
      "           [-8.3117e-03, -9.5099e-03, -1.5043e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.3599e-03, -6.8524e-03, -1.1144e-02],\n",
      "           [ 8.4774e-03, -4.9933e-03,  4.7781e-03],\n",
      "           [-4.2251e-03,  3.9398e-03, -1.3270e-02]],\n",
      "\n",
      "          [[-1.4941e-03, -7.4563e-03, -1.0045e-02],\n",
      "           [ 1.6980e-03, -5.7870e-03, -9.1866e-03],\n",
      "           [ 1.9716e-03,  1.6884e-03, -2.8482e-03]],\n",
      "\n",
      "          [[-7.6262e-03, -8.2609e-03, -6.6984e-03],\n",
      "           [-3.7563e-03,  4.3781e-03,  7.3774e-04],\n",
      "           [-2.5001e-03, -3.8364e-03, -4.4129e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 7.8266e-03,  5.4803e-03,  3.0739e-03],\n",
      "           [ 8.5705e-03,  4.9341e-03,  6.8739e-03],\n",
      "           [-1.3424e-03,  9.8690e-04,  6.0509e-03]],\n",
      "\n",
      "          [[-6.4033e-03,  2.2671e-03,  4.2460e-04],\n",
      "           [ 2.5835e-03,  5.2953e-03, -9.4618e-05],\n",
      "           [ 7.0712e-04,  5.7750e-03,  2.9317e-03]],\n",
      "\n",
      "          [[-8.3198e-03, -2.5294e-03, -9.9693e-04],\n",
      "           [-2.2614e-03,  6.4400e-03, -3.2879e-03],\n",
      "           [ 4.4542e-04,  3.4058e-03, -1.8160e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.9278e-03, -1.7307e-03,  1.0453e-02],\n",
      "           [-1.1768e-02, -3.9570e-03, -2.4527e-02],\n",
      "           [ 1.8936e-02, -1.3893e-02, -1.2087e-02]],\n",
      "\n",
      "          [[-5.2744e-03,  1.1888e-02,  6.1287e-03],\n",
      "           [-6.9210e-03,  4.6291e-03, -6.0536e-03],\n",
      "           [-4.3128e-03, -9.8638e-03, -2.1632e-02]],\n",
      "\n",
      "          [[-5.2489e-03, -1.2899e-02, -4.4910e-03],\n",
      "           [-6.3456e-04,  8.8699e-04,  5.7147e-03],\n",
      "           [ 1.5565e-02, -5.4046e-03, -2.7504e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.9226e-02, -1.4095e-02, -2.3013e-02],\n",
      "           [-6.1114e-04, -1.1598e-02, -3.5364e-05],\n",
      "           [ 2.1763e-02,  1.0862e-02, -6.0588e-03]],\n",
      "\n",
      "          [[-3.2297e-04, -1.2219e-02, -1.0337e-02],\n",
      "           [-3.7680e-03,  6.4054e-03,  2.1135e-03],\n",
      "           [-2.0432e-02, -7.6290e-03,  6.1924e-03]],\n",
      "\n",
      "          [[-2.1375e-02, -3.3519e-02, -1.8717e-02],\n",
      "           [-5.3370e-03, -1.7083e-02,  2.0423e-03],\n",
      "           [-9.7043e-03,  3.1582e-04, -2.8840e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2465e-02,  8.1951e-03,  1.0853e-02],\n",
      "           [-1.5025e-03, -3.6081e-03, -1.6065e-02],\n",
      "           [-1.1731e-02,  1.2990e-02, -1.2400e-02]],\n",
      "\n",
      "          [[-4.6150e-03, -6.4758e-03,  3.1260e-04],\n",
      "           [ 2.9550e-03, -1.3917e-02,  3.1446e-03],\n",
      "           [-8.4771e-03, -8.0831e-03, -6.0270e-03]],\n",
      "\n",
      "          [[ 4.9675e-04, -2.2717e-02, -7.7056e-03],\n",
      "           [-2.1099e-02, -1.1957e-04, -1.6726e-02],\n",
      "           [-9.8585e-03, -1.2545e-02, -2.2229e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.2452e-02, -9.9468e-04,  1.7290e-02],\n",
      "           [ 1.6810e-02, -3.5215e-03, -7.1460e-03],\n",
      "           [ 3.0399e-02,  2.2431e-02,  2.2630e-02]],\n",
      "\n",
      "          [[ 1.0332e-02, -1.1815e-02,  1.4682e-03],\n",
      "           [ 7.0351e-03,  3.5385e-03, -6.8890e-03],\n",
      "           [ 2.0721e-02, -6.1220e-03,  1.7493e-02]],\n",
      "\n",
      "          [[-1.6957e-02,  3.2729e-03, -1.1692e-02],\n",
      "           [ 2.5529e-03, -3.2775e-03, -1.4515e-02],\n",
      "           [ 1.5040e-02,  1.1923e-02,  1.3265e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0455e-02,  1.9911e-03, -3.2479e-02],\n",
      "           [ 2.3759e-02,  1.9606e-02, -3.1323e-03],\n",
      "           [ 6.6801e-03,  2.1093e-02,  4.0983e-03]],\n",
      "\n",
      "          [[ 1.8741e-02,  8.6987e-03, -1.2697e-02],\n",
      "           [ 8.0173e-03, -2.1434e-03, -5.5697e-03],\n",
      "           [ 1.4880e-02, -6.4525e-03,  4.9518e-03]],\n",
      "\n",
      "          [[-8.2280e-03,  1.3455e-02, -9.0435e-03],\n",
      "           [ 8.8467e-03,  1.1004e-02, -1.1043e-02],\n",
      "           [ 4.3127e-03, -3.6486e-03, -3.0990e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.7903e-02,  1.6926e-02, -9.8539e-03],\n",
      "           [ 4.1835e-03,  1.1818e-02,  1.8290e-02],\n",
      "           [ 3.2447e-03,  1.4713e-02,  1.4256e-02]],\n",
      "\n",
      "          [[ 1.4835e-02,  2.6639e-02,  2.9967e-03],\n",
      "           [ 6.7480e-03,  1.2505e-02, -3.7019e-03],\n",
      "           [ 1.9696e-02, -9.5223e-03, -7.9406e-03]],\n",
      "\n",
      "          [[-4.0366e-03,  1.3534e-02,  1.1670e-03],\n",
      "           [ 1.7401e-02,  3.1815e-03,  5.7501e-03],\n",
      "           [ 1.2143e-02, -8.8738e-03, -1.7300e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.6042e-02,  7.2033e-03, -9.3939e-03],\n",
      "           [-2.9783e-03,  1.6840e-03,  7.6598e-03],\n",
      "           [-3.1571e-03, -8.4492e-04,  1.0444e-02]],\n",
      "\n",
      "          [[ 1.9180e-02,  1.2990e-02, -2.9050e-03],\n",
      "           [-1.5911e-02, -4.9490e-03, -1.1805e-02],\n",
      "           [-3.5427e-03, -1.0040e-02,  9.3759e-03]],\n",
      "\n",
      "          [[-5.7110e-03,  1.5097e-02, -2.0654e-03],\n",
      "           [ 4.1954e-03,  2.9201e-03,  5.8823e-03],\n",
      "           [ 1.6661e-03, -1.2085e-02, -8.4764e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.9739e-02, -2.0822e-02, -2.0825e-02],\n",
      "           [-1.8404e-02,  7.8250e-03, -1.9857e-04],\n",
      "           [-2.0697e-02, -7.0596e-03, -4.1673e-03]],\n",
      "\n",
      "          [[-2.4886e-02,  8.5193e-03,  1.1156e-02],\n",
      "           [-4.4808e-03,  2.8667e-03, -3.4681e-03],\n",
      "           [-2.5218e-03, -4.1767e-03,  2.6119e-03]],\n",
      "\n",
      "          [[ 2.0916e-02,  1.9046e-02,  1.2869e-02],\n",
      "           [ 1.3927e-03,  1.0324e-02,  1.7883e-02],\n",
      "           [ 2.0639e-02,  3.8074e-03, -4.9879e-03]]],\n",
      "\n",
      "\n",
      "         [[[-7.2648e-03,  8.8888e-03,  1.8003e-03],\n",
      "           [-6.3213e-03, -9.8935e-03, -6.2212e-03],\n",
      "           [-6.9883e-03, -9.5534e-03, -9.3150e-03]],\n",
      "\n",
      "          [[ 1.9689e-03, -8.2523e-03,  1.0454e-02],\n",
      "           [-9.8214e-03, -4.3411e-03, -2.5956e-03],\n",
      "           [-1.7314e-02, -3.8369e-03, -1.1577e-02]],\n",
      "\n",
      "          [[-3.6830e-03, -3.2495e-03,  1.5463e-02],\n",
      "           [ 1.4171e-02, -2.8015e-03,  7.2265e-03],\n",
      "           [ 6.3920e-05, -2.7647e-03,  1.3951e-05]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.4614e-03, -2.7206e-03, -1.8499e-02],\n",
      "           [-5.3552e-03, -9.6630e-05, -3.9421e-03],\n",
      "           [-1.7845e-02, -2.6810e-02, -7.8919e-03]],\n",
      "\n",
      "          [[ 1.2361e-02, -2.6545e-03, -1.2282e-02],\n",
      "           [-1.0811e-02,  5.8347e-03,  6.0827e-03],\n",
      "           [ 7.3697e-04, -1.6214e-04, -2.2263e-02]],\n",
      "\n",
      "          [[ 6.2123e-03,  2.0009e-03, -1.3046e-02],\n",
      "           [ 4.0316e-03, -9.0023e-03,  2.2789e-03],\n",
      "           [-1.4965e-02, -8.4680e-03, -7.5559e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.9460e-03, -1.8087e-02, -2.4996e-02],\n",
      "           [ 3.9070e-03, -1.7727e-02, -1.0306e-02],\n",
      "           [-2.0042e-02, -9.1941e-03,  1.7408e-02]],\n",
      "\n",
      "          [[-1.4442e-02, -3.3691e-03, -1.3058e-02],\n",
      "           [-8.6480e-03,  1.1674e-02,  8.8785e-04],\n",
      "           [ 4.9576e-03, -3.8690e-04,  4.4741e-03]],\n",
      "\n",
      "          [[-1.8256e-02, -3.3612e-02, -1.7263e-02],\n",
      "           [-6.6456e-03, -2.2151e-02, -7.4824e-03],\n",
      "           [ 6.3786e-03, -1.8356e-03,  7.2422e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 4.9243e-03,  1.4682e-02,  6.2085e-04],\n",
      "           [ 5.4136e-03,  1.8736e-03,  5.8912e-03],\n",
      "           [ 8.6978e-04, -2.3179e-02, -7.2076e-03]],\n",
      "\n",
      "          [[ 9.8476e-03,  7.4651e-03,  4.2790e-03],\n",
      "           [-9.7755e-03,  1.1062e-02,  1.0649e-02],\n",
      "           [-4.2597e-03, -8.7620e-03, -1.6330e-02]],\n",
      "\n",
      "          [[ 2.1181e-03, -8.8003e-03, -7.4136e-03],\n",
      "           [ 1.1312e-02,  8.3812e-03, -2.1596e-02],\n",
      "           [ 2.2816e-02, -6.8467e-04, -2.3812e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.2249e-03, -2.4917e-02, -2.9180e-02],\n",
      "           [ 4.7735e-03, -7.4076e-03, -7.0350e-03],\n",
      "           [ 1.7346e-02,  6.4511e-03, -4.8197e-03]],\n",
      "\n",
      "          [[ 1.5072e-02,  2.1232e-03, -2.0633e-02],\n",
      "           [ 1.7596e-02,  2.8493e-03, -4.8016e-03],\n",
      "           [ 2.4018e-02,  5.2687e-03, -3.9669e-03]],\n",
      "\n",
      "          [[ 1.7695e-02,  5.9241e-03, -1.4099e-02],\n",
      "           [ 9.6852e-03,  8.4337e-03, -1.0431e-02],\n",
      "           [ 2.7374e-02,  3.3389e-03, -5.2083e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 5.0269e-04,  1.2523e-02,  1.4696e-02],\n",
      "           [ 1.0288e-03,  2.0538e-02,  2.2173e-02],\n",
      "           [ 4.8836e-04,  7.2742e-03, -5.0296e-03]],\n",
      "\n",
      "          [[ 1.3897e-02,  3.1287e-02,  2.2537e-02],\n",
      "           [ 2.5529e-02,  9.7436e-03,  8.8156e-03],\n",
      "           [ 2.1452e-02,  5.2575e-03,  1.7337e-02]],\n",
      "\n",
      "          [[ 1.4656e-02,  1.7405e-02,  3.0169e-03],\n",
      "           [ 2.1103e-02,  1.5240e-02, -4.9914e-03],\n",
      "           [ 1.6738e-02, -1.4187e-02, -1.1662e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.3599e-03,  1.2354e-03,  3.4289e-03],\n",
      "           [-2.8345e-03, -1.0783e-02, -1.6414e-02],\n",
      "           [-1.1401e-02, -3.0201e-02, -1.3622e-02]],\n",
      "\n",
      "          [[-9.3748e-03,  1.0478e-02, -6.1283e-03],\n",
      "           [ 1.8243e-02,  9.7886e-03, -3.3928e-03],\n",
      "           [ 6.6704e-03, -1.1169e-02, -3.1712e-02]],\n",
      "\n",
      "          [[-6.5607e-03, -3.8242e-03, -9.9331e-03],\n",
      "           [ 4.4271e-03,  4.3247e-03,  4.1912e-03],\n",
      "           [ 9.8660e-03, -1.7115e-02, -5.0182e-04]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-5.0895e-03,  7.4960e-03, -4.2684e-04],\n",
      "           [ 1.0375e-02,  9.9482e-03,  2.1972e-02],\n",
      "           [ 2.3455e-02,  2.7704e-02,  1.1472e-02]],\n",
      "\n",
      "          [[ 9.2866e-03,  1.4828e-02, -9.1331e-03],\n",
      "           [-5.3526e-04,  2.5598e-03, -1.0580e-02],\n",
      "           [ 1.2416e-02, -9.1689e-03, -6.3735e-03]],\n",
      "\n",
      "          [[ 1.2339e-02,  1.3227e-02,  8.3348e-03],\n",
      "           [-1.7800e-04, -1.2284e-02, -8.1575e-03],\n",
      "           [-1.6313e-02, -3.1538e-02, -2.1616e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4314e-02,  2.1156e-02,  1.1738e-02],\n",
      "           [ 6.4250e-03,  3.1549e-02,  1.0105e-02],\n",
      "           [ 3.1214e-02,  2.2765e-02,  1.3549e-02]],\n",
      "\n",
      "          [[ 2.7700e-02,  1.0821e-02,  1.6732e-02],\n",
      "           [-7.6824e-03,  1.2016e-02, -6.8409e-03],\n",
      "           [ 7.4382e-03,  1.9588e-02, -3.8485e-03]],\n",
      "\n",
      "          [[ 1.7623e-02,  2.2373e-02,  2.2377e-02],\n",
      "           [ 1.5132e-02,  3.2019e-03, -2.3589e-03],\n",
      "           [-8.3209e-03, -3.6142e-03, -1.6372e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 6.9645e-03,  2.8300e-03, -1.0323e-02],\n",
      "           [ 3.4441e-03,  1.1606e-02, -7.8744e-03],\n",
      "           [ 1.5495e-02,  9.1708e-03,  5.1311e-03]],\n",
      "\n",
      "          [[ 8.6103e-03,  6.7146e-03,  1.4827e-02],\n",
      "           [ 2.6150e-02,  2.6789e-02,  2.3054e-02],\n",
      "           [ 2.0826e-02,  5.2288e-03,  1.7098e-02]],\n",
      "\n",
      "          [[-9.0177e-05,  6.0832e-03, -2.5139e-03],\n",
      "           [ 1.3162e-02,  1.1051e-02,  2.0288e-02],\n",
      "           [-9.3700e-04,  2.7259e-02,  2.3484e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.1207e-04, -1.2626e-02, -9.3222e-03],\n",
      "           [ 2.0554e-03,  4.4889e-03,  2.4090e-03],\n",
      "           [ 1.3259e-02,  2.5912e-02,  2.6626e-02]],\n",
      "\n",
      "          [[-4.9351e-03, -3.1171e-03, -1.6651e-02],\n",
      "           [-6.3412e-03,  3.1028e-03,  3.4158e-03],\n",
      "           [-4.5853e-03,  1.3217e-02,  1.7758e-02]],\n",
      "\n",
      "          [[-1.1542e-02, -1.9055e-03, -1.2422e-02],\n",
      "           [ 1.6103e-03, -1.9343e-02, -1.4170e-02],\n",
      "           [-3.1280e-03, -5.9900e-03,  8.5010e-03]]],\n",
      "\n",
      "\n",
      "         [[[-9.2972e-03, -2.2139e-02, -1.9564e-02],\n",
      "           [ 1.6249e-03, -3.5379e-03, -4.1756e-03],\n",
      "           [-4.3526e-03, -2.4780e-03,  8.8345e-03]],\n",
      "\n",
      "          [[-2.3497e-03, -8.5627e-03, -1.3659e-02],\n",
      "           [ 4.3717e-03, -3.5355e-04,  2.4755e-03],\n",
      "           [ 4.8877e-03, -2.5982e-03,  1.3010e-02]],\n",
      "\n",
      "          [[-1.2058e-02,  2.8420e-03, -1.3134e-02],\n",
      "           [-1.1277e-02,  3.1211e-03, -1.9250e-02],\n",
      "           [-1.2086e-02, -1.6626e-02, -1.3912e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.0044e-03,  1.0014e-02, -4.2346e-04],\n",
      "           [-1.1265e-02, -2.8374e-03,  6.3973e-03],\n",
      "           [-1.6289e-02, -8.0964e-03, -1.7751e-02]],\n",
      "\n",
      "          [[ 1.0909e-02,  8.5795e-03,  1.3003e-02],\n",
      "           [-1.0228e-02,  1.5413e-03, -8.5708e-04],\n",
      "           [-1.6046e-02, -1.1908e-02, -5.5241e-03]],\n",
      "\n",
      "          [[-2.3783e-02, -4.5316e-03, -5.3547e-03],\n",
      "           [ 1.0297e-03, -8.3661e-03, -1.8483e-02],\n",
      "           [-1.7779e-02, -1.9738e-02, -2.2307e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.0191e-03, -1.3474e-03, -1.3084e-03],\n",
      "           [-9.0883e-03, -5.9001e-03, -2.7803e-04],\n",
      "           [-3.1885e-03, -3.4411e-03, -4.8140e-03]],\n",
      "\n",
      "          [[ 9.9207e-03, -5.6212e-03,  1.4505e-03],\n",
      "           [ 1.9940e-04,  4.1811e-03,  6.2564e-03],\n",
      "           [ 8.4039e-03,  5.1896e-03, -7.1870e-03]],\n",
      "\n",
      "          [[ 1.1261e-02, -1.2590e-02, -1.7245e-03],\n",
      "           [-4.3344e-05,  4.8203e-03, -6.4126e-03],\n",
      "           [-8.2169e-03, -5.5275e-03,  1.8279e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 6.3775e-03,  1.9217e-03,  3.2584e-03],\n",
      "           [ 7.1433e-03,  8.7689e-03,  6.6092e-03],\n",
      "           [ 1.9890e-03,  5.2218e-03, -5.0553e-03]],\n",
      "\n",
      "          [[ 1.0454e-02,  1.1841e-02,  8.3655e-03],\n",
      "           [ 1.3570e-02,  1.5291e-02,  1.4220e-02],\n",
      "           [ 1.0663e-02,  4.0275e-03,  1.3221e-02]],\n",
      "\n",
      "          [[ 1.1960e-02,  1.3600e-02,  1.2867e-03],\n",
      "           [ 9.4201e-03,  1.1866e-04, -7.4315e-04],\n",
      "           [-5.1240e-03, -6.1202e-03,  2.4830e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.6603e-03, -6.8444e-03, -8.0968e-03],\n",
      "           [ 1.2142e-03, -4.9781e-03, -4.0432e-03],\n",
      "           [ 9.4069e-03,  1.1749e-02,  9.8657e-03]],\n",
      "\n",
      "          [[ 2.8562e-03,  4.4343e-03, -1.0520e-02],\n",
      "           [ 7.4024e-03,  2.0562e-02,  1.6304e-02],\n",
      "           [ 7.0822e-03,  4.4433e-03,  1.1514e-02]],\n",
      "\n",
      "          [[ 6.3900e-03, -6.4218e-03,  6.0322e-04],\n",
      "           [ 1.4145e-02,  7.3462e-03,  1.5246e-02],\n",
      "           [ 5.2180e-03,  1.6682e-03,  9.5096e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.9300e-03,  1.0705e-02,  1.6472e-03],\n",
      "           [-7.5514e-03, -1.5065e-02, -1.9711e-02],\n",
      "           [-1.1971e-02, -1.1302e-02, -1.0436e-02]],\n",
      "\n",
      "          [[ 7.3203e-03, -1.3945e-02, -1.7054e-02],\n",
      "           [-1.3147e-02, -1.9451e-02, -1.3905e-02],\n",
      "           [-1.4029e-02, -4.0588e-03, -1.6951e-02]],\n",
      "\n",
      "          [[-2.3327e-03, -4.2754e-03,  1.1459e-02],\n",
      "           [-5.1976e-03, -8.6805e-03, -8.8610e-03],\n",
      "           [-3.1233e-03, -5.0646e-03, -1.0408e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.0655e-02, -8.9369e-05, -1.3507e-02],\n",
      "           [-1.1977e-02, -1.2674e-02,  4.7185e-04],\n",
      "           [-1.5655e-02, -1.7522e-02, -7.8105e-04]],\n",
      "\n",
      "          [[ 1.8693e-03,  1.5961e-02,  8.4279e-03],\n",
      "           [-2.4816e-03, -3.4816e-03, -6.3465e-03],\n",
      "           [-4.4511e-03, -1.3200e-02, -2.0560e-02]],\n",
      "\n",
      "          [[ 1.1706e-02,  1.1177e-02,  4.3360e-03],\n",
      "           [ 1.0224e-02, -1.7725e-02, -7.1177e-03],\n",
      "           [ 2.4873e-03, -3.8752e-03,  2.3414e-03]]],\n",
      "\n",
      "\n",
      "         [[[-9.0229e-04,  6.1414e-03,  3.8331e-04],\n",
      "           [ 4.6759e-04, -1.5446e-02, -1.4421e-02],\n",
      "           [ 8.2542e-03,  1.9160e-02,  2.7642e-03]],\n",
      "\n",
      "          [[-1.4292e-02, -3.5732e-03,  3.3902e-03],\n",
      "           [-7.9454e-03, -1.3196e-02, -3.5931e-02],\n",
      "           [-2.2262e-03, -3.3221e-04, -5.0321e-03]],\n",
      "\n",
      "          [[-2.1741e-02, -2.4417e-02, -1.3563e-02],\n",
      "           [-9.3638e-03, -4.7569e-03, -2.0086e-02],\n",
      "           [ 9.7883e-04, -1.2789e-02, -2.5892e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.4111e-02,  5.8514e-03,  1.6387e-02],\n",
      "           [-1.0318e-03, -1.5687e-02, -1.3856e-02],\n",
      "           [-7.4758e-03, -6.0836e-04, -1.5671e-02]],\n",
      "\n",
      "          [[ 1.1080e-02,  1.4896e-02,  5.2223e-03],\n",
      "           [ 2.0516e-03, -1.4318e-03, -6.8008e-03],\n",
      "           [-2.3117e-02,  1.3444e-03, -2.3921e-02]],\n",
      "\n",
      "          [[ 1.2948e-02,  6.0898e-03,  1.7728e-02],\n",
      "           [-1.3651e-02,  5.8935e-03, -6.3378e-03],\n",
      "           [-1.9525e-02, -2.2643e-02, -2.3501e-02]]],\n",
      "\n",
      "\n",
      "         [[[-9.6202e-03, -1.2253e-02,  4.7096e-03],\n",
      "           [-2.3639e-02, -2.5352e-03, -2.2703e-02],\n",
      "           [-1.2705e-02, -1.2724e-03, -4.0451e-03]],\n",
      "\n",
      "          [[-1.0033e-03, -1.1828e-02,  9.9379e-03],\n",
      "           [-1.2186e-02, -1.8577e-02, -6.2680e-03],\n",
      "           [-1.9053e-02, -7.2067e-03, -2.1362e-04]],\n",
      "\n",
      "          [[-1.6431e-03, -3.0580e-03,  1.1864e-02],\n",
      "           [-9.2437e-03,  3.8411e-03, -1.4368e-02],\n",
      "           [ 3.7045e-03, -3.6564e-03, -2.8518e-03]]],\n",
      "\n",
      "\n",
      "         [[[-7.0856e-03, -1.2836e-02, -5.7963e-04],\n",
      "           [-1.2686e-02, -1.4186e-02, -7.1161e-03],\n",
      "           [-1.1850e-02, -7.8300e-03, -1.0293e-02]],\n",
      "\n",
      "          [[ 1.7424e-02, -6.7480e-04,  1.3106e-02],\n",
      "           [ 1.5582e-02, -7.3101e-03,  1.1458e-02],\n",
      "           [ 3.1952e-03, -1.3790e-02,  3.0052e-03]],\n",
      "\n",
      "          [[-9.4398e-03,  1.3510e-02, -8.2346e-04],\n",
      "           [ 1.2532e-02, -2.4854e-04,  1.8804e-03],\n",
      "           [-1.1274e-02, -9.5172e-03,  4.3236e-03]]]]], device='cuda:0')), ('module.down_layers.3.2.conv2.conv.weight', tensor([[[[[ 5.3806e-03,  5.2362e-03, -3.7948e-03],\n",
      "           [ 8.2479e-03,  6.2422e-03, -5.1329e-04],\n",
      "           [ 8.9755e-03, -7.2391e-03, -5.4812e-03]],\n",
      "\n",
      "          [[ 9.6200e-03,  2.2719e-03, -8.8538e-03],\n",
      "           [-6.1466e-03,  1.4197e-03,  2.2038e-04],\n",
      "           [-3.3076e-03, -8.4934e-03,  6.0861e-03]],\n",
      "\n",
      "          [[ 1.3664e-03,  8.9517e-03, -5.2514e-03],\n",
      "           [-4.2622e-03,  1.5605e-03,  1.8862e-03],\n",
      "           [ 1.6728e-03,  9.4227e-04,  7.4705e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1343e-03, -8.9216e-03, -1.1004e-02],\n",
      "           [ 6.0705e-03, -1.5735e-02, -8.7006e-03],\n",
      "           [-1.5297e-02,  4.4072e-03, -2.1247e-03]],\n",
      "\n",
      "          [[ 2.7150e-03, -3.5954e-03,  3.8343e-03],\n",
      "           [ 1.6971e-02,  5.0853e-03, -1.9332e-02],\n",
      "           [-1.5791e-02, -5.7459e-03, -3.9951e-03]],\n",
      "\n",
      "          [[ 1.0977e-02,  4.7753e-03,  9.9124e-03],\n",
      "           [ 7.5773e-04,  1.8120e-02, -2.1648e-02],\n",
      "           [-2.5727e-03, -1.0602e-02,  2.4288e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0064e-03, -1.3323e-02,  3.6340e-03],\n",
      "           [ 1.4595e-03, -1.4288e-02,  6.7877e-04],\n",
      "           [ 7.1451e-03, -1.0358e-02, -2.0317e-02]],\n",
      "\n",
      "          [[ 2.9688e-04, -1.1214e-02,  3.9007e-03],\n",
      "           [-1.1208e-02,  9.8883e-03,  3.4053e-03],\n",
      "           [ 1.4176e-02,  2.8282e-03,  3.5938e-04]],\n",
      "\n",
      "          [[-1.8578e-02, -2.3294e-02, -1.4782e-02],\n",
      "           [-7.4611e-03, -6.2831e-04, -2.8951e-03],\n",
      "           [-3.3381e-03, -1.2653e-03, -2.8938e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-9.6156e-03, -1.1830e-02, -1.5624e-02],\n",
      "           [-9.1626e-03,  9.0147e-03,  1.7538e-04],\n",
      "           [ 6.9267e-03,  3.8421e-02,  3.5404e-02]],\n",
      "\n",
      "          [[-9.0266e-03, -2.1783e-02, -3.5842e-02],\n",
      "           [-7.7912e-03, -1.6967e-02, -2.8459e-02],\n",
      "           [-1.3960e-02,  1.0487e-03, -1.0231e-02]],\n",
      "\n",
      "          [[ 4.5594e-04, -6.1250e-04, -2.4129e-02],\n",
      "           [-7.9333e-03, -1.4333e-02, -3.0856e-02],\n",
      "           [-1.4662e-02, -1.5073e-02, -1.9125e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3672e-02, -6.8468e-03,  8.1612e-03],\n",
      "           [ 4.4289e-03,  1.1543e-03,  1.5131e-02],\n",
      "           [ 3.1042e-03, -4.7179e-03,  1.0769e-02]],\n",
      "\n",
      "          [[ 8.6014e-03,  1.2084e-02,  1.7696e-03],\n",
      "           [ 1.1928e-02,  2.2821e-03, -9.2867e-04],\n",
      "           [-1.0183e-02,  4.0346e-03,  3.0353e-03]],\n",
      "\n",
      "          [[ 5.3535e-03,  4.5809e-03,  9.9103e-03],\n",
      "           [ 1.6419e-02,  1.0737e-02,  4.0123e-03],\n",
      "           [-1.8582e-03, -9.5759e-03,  2.0460e-03]]],\n",
      "\n",
      "\n",
      "         [[[-6.2352e-03,  8.8766e-03, -1.1387e-02],\n",
      "           [-7.5852e-04,  4.1813e-03, -8.9772e-03],\n",
      "           [ 1.3392e-02,  3.2759e-03, -5.1605e-03]],\n",
      "\n",
      "          [[-6.5602e-03,  1.2610e-03, -1.5113e-02],\n",
      "           [ 1.6954e-02,  1.9974e-02,  5.9872e-03],\n",
      "           [ 4.0783e-02,  1.5464e-02,  1.6946e-02]],\n",
      "\n",
      "          [[-1.1057e-02, -1.1701e-02, -2.6300e-02],\n",
      "           [ 1.4246e-02,  2.6352e-02,  1.1322e-02],\n",
      "           [ 3.5231e-02,  3.4819e-02,  1.3332e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.4440e-03,  6.7151e-03, -7.4972e-04],\n",
      "           [ 1.4490e-02,  1.3537e-02,  4.3096e-04],\n",
      "           [ 9.9372e-03,  8.9461e-03, -2.1694e-03]],\n",
      "\n",
      "          [[-7.3960e-03, -6.1975e-03, -2.2625e-03],\n",
      "           [-8.0034e-04,  8.9859e-03,  7.7780e-04],\n",
      "           [ 1.2495e-02,  1.0039e-02,  6.6555e-03]],\n",
      "\n",
      "          [[ 6.5795e-03,  7.2343e-03,  3.9182e-03],\n",
      "           [-3.4617e-04,  1.4319e-02, -2.4541e-03],\n",
      "           [ 9.7397e-03,  6.5056e-03,  6.0137e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 7.9514e-03, -7.6431e-03, -1.3432e-02],\n",
      "           [ 1.4216e-02, -1.4915e-02, -2.2564e-02],\n",
      "           [-7.5636e-04,  1.0678e-02, -1.6231e-04]],\n",
      "\n",
      "          [[ 1.1055e-02, -1.0440e-02, -2.0892e-02],\n",
      "           [ 6.3445e-03,  5.0198e-04, -1.7334e-02],\n",
      "           [ 7.4877e-03, -1.3474e-02, -3.1255e-03]],\n",
      "\n",
      "          [[ 1.8518e-02,  1.0159e-02,  7.8355e-03],\n",
      "           [ 1.3856e-02,  1.0879e-02, -9.2220e-03],\n",
      "           [ 1.2269e-02,  8.3897e-03, -2.9548e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.6184e-02, -1.0334e-02, -1.8675e-02],\n",
      "           [-1.3425e-02, -2.6299e-02, -2.4105e-03],\n",
      "           [-3.8013e-03, -6.5358e-04,  1.0199e-02]],\n",
      "\n",
      "          [[-2.6955e-03,  4.2117e-03, -4.0576e-03],\n",
      "           [-7.2353e-03, -2.2954e-03, -2.7693e-03],\n",
      "           [ 5.1687e-04,  2.4445e-02, -2.4546e-03]],\n",
      "\n",
      "          [[-1.9368e-02, -1.0219e-02,  8.2728e-03],\n",
      "           [-3.8601e-03,  1.7223e-02,  3.1485e-03],\n",
      "           [-1.2507e-02,  4.2437e-03,  2.6670e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0197e-03, -1.1597e-03,  6.7580e-03],\n",
      "           [-6.8725e-03, -8.8440e-03,  9.5459e-04],\n",
      "           [-4.3333e-03, -8.2901e-03, -7.0055e-03]],\n",
      "\n",
      "          [[ 1.0740e-02,  3.3451e-03,  1.9046e-02],\n",
      "           [ 5.8763e-03,  5.3010e-03,  1.6107e-02],\n",
      "           [-1.3129e-02, -7.2144e-03,  2.6425e-03]],\n",
      "\n",
      "          [[ 1.1442e-02,  1.2090e-02,  1.3042e-02],\n",
      "           [ 1.5305e-02,  3.5454e-03,  5.6218e-05],\n",
      "           [-7.9647e-03, -9.3599e-03, -1.2603e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2412e-02, -2.0098e-03,  3.1991e-03],\n",
      "           [ 1.0485e-02,  1.3917e-02,  9.9752e-03],\n",
      "           [ 2.4677e-02,  2.2864e-02,  3.0976e-02]],\n",
      "\n",
      "          [[ 6.1419e-03,  6.1418e-03, -3.2514e-03],\n",
      "           [ 1.0326e-02,  8.6342e-03,  6.7354e-03],\n",
      "           [ 1.6361e-02,  1.9708e-02,  1.6714e-02]],\n",
      "\n",
      "          [[ 2.2640e-02,  5.8853e-03, -1.4775e-03],\n",
      "           [ 1.7591e-02,  9.2255e-05,  1.1005e-02],\n",
      "           [-2.0410e-03,  4.6995e-03,  1.1369e-03]]],\n",
      "\n",
      "\n",
      "         [[[-7.6571e-03, -3.2459e-03, -3.6544e-03],\n",
      "           [ 4.5584e-03, -2.5361e-03, -6.4447e-03],\n",
      "           [-1.1254e-02, -5.8624e-03, -1.0412e-03]],\n",
      "\n",
      "          [[-1.5276e-02, -7.1470e-03, -1.0973e-02],\n",
      "           [ 7.6944e-03,  7.7700e-03, -7.3142e-03],\n",
      "           [ 4.3478e-03,  1.7758e-02, -6.9377e-03]],\n",
      "\n",
      "          [[-1.9785e-02, -1.3860e-02, -1.2337e-02],\n",
      "           [ 2.5344e-03, -5.9871e-03, -5.8833e-03],\n",
      "           [ 1.3804e-02,  1.2008e-02,  5.5171e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.3416e-03,  7.5937e-03,  1.7476e-03],\n",
      "           [ 5.2030e-03,  9.3831e-03, -7.8415e-03],\n",
      "           [ 3.8749e-03,  3.4107e-03,  1.7388e-04]],\n",
      "\n",
      "          [[-6.0644e-03,  4.2750e-03,  6.8637e-03],\n",
      "           [-4.2433e-03,  2.4096e-03,  7.2967e-03],\n",
      "           [-1.3981e-02,  4.1883e-03,  3.2787e-03]],\n",
      "\n",
      "          [[-3.4571e-04,  6.5961e-03,  5.5799e-03],\n",
      "           [-8.9808e-03,  3.3061e-03,  5.4442e-03],\n",
      "           [-2.9869e-03,  8.7060e-04, -1.3062e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.6346e-04,  4.0032e-04, -1.2136e-02],\n",
      "           [ 1.5336e-02, -9.3690e-03, -1.1782e-02],\n",
      "           [-8.4542e-03, -1.1388e-02,  1.2346e-02]],\n",
      "\n",
      "          [[ 7.4885e-03,  1.1773e-02, -2.0440e-02],\n",
      "           [ 6.8113e-03,  2.4000e-03, -7.1597e-04],\n",
      "           [ 7.1269e-03, -7.6842e-03,  5.5016e-03]],\n",
      "\n",
      "          [[ 8.7988e-03, -3.1441e-03, -1.0326e-02],\n",
      "           [ 1.8623e-02,  2.0043e-02,  7.7014e-03],\n",
      "           [ 4.5584e-03,  1.2893e-02,  2.3490e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.8029e-03, -1.1259e-02, -9.7990e-03],\n",
      "           [ 5.2685e-03, -1.1348e-02,  1.6866e-02],\n",
      "           [-5.0892e-03,  9.5914e-03,  2.7609e-03]],\n",
      "\n",
      "          [[-1.9284e-02, -1.1345e-02, -1.6189e-02],\n",
      "           [-9.5831e-03, -2.1199e-03, -2.3039e-03],\n",
      "           [-1.4675e-03, -8.6483e-03,  1.7355e-02]],\n",
      "\n",
      "          [[-3.8588e-03, -1.2814e-02, -1.5873e-02],\n",
      "           [-5.5801e-03,  2.8334e-03, -6.3276e-03],\n",
      "           [ 1.1920e-04,  1.2331e-03,  2.1620e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.8443e-02,  2.7673e-02,  2.5832e-02],\n",
      "           [ 1.8109e-02,  1.9837e-02,  2.4134e-02],\n",
      "           [ 9.9011e-03,  1.0041e-02, -6.5186e-04]],\n",
      "\n",
      "          [[ 1.1146e-02,  3.4593e-03,  2.3525e-03],\n",
      "           [ 1.0531e-02,  1.9182e-03, -3.8383e-03],\n",
      "           [ 1.4261e-03, -6.3477e-03, -1.5950e-02]],\n",
      "\n",
      "          [[ 1.1746e-02,  7.6057e-03,  7.2551e-03],\n",
      "           [ 5.2988e-03, -3.6475e-03, -8.2892e-03],\n",
      "           [-1.1926e-02, -2.1694e-02, -1.9556e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.9990e-03,  1.7738e-03, -3.7952e-03],\n",
      "           [ 3.0634e-03,  1.8748e-03, -8.5387e-03],\n",
      "           [-1.4033e-02, -1.2207e-02, -1.1343e-02]],\n",
      "\n",
      "          [[ 1.4781e-02,  4.2101e-03,  2.0864e-04],\n",
      "           [ 6.6337e-03, -3.9968e-04, -5.3425e-03],\n",
      "           [-8.5109e-03, -1.4260e-02, -1.8904e-02]],\n",
      "\n",
      "          [[ 1.8631e-02,  1.1875e-02,  7.5280e-03],\n",
      "           [ 1.5229e-02,  1.0574e-02,  3.0402e-03],\n",
      "           [ 3.3198e-03, -1.2344e-02, -1.1697e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.6904e-02, -1.6990e-02, -1.3433e-02],\n",
      "           [-2.7649e-02, -1.7597e-02, -8.7823e-03],\n",
      "           [-6.8461e-03, -1.1718e-02, -1.1137e-02]],\n",
      "\n",
      "          [[-7.2427e-03, -7.2477e-03, -1.0899e-02],\n",
      "           [-1.1263e-02, -1.1935e-02, -2.3673e-03],\n",
      "           [ 2.2075e-04, -2.3527e-03,  2.4671e-03]],\n",
      "\n",
      "          [[-1.4529e-02, -1.8714e-02, -2.4981e-02],\n",
      "           [-1.0414e-02, -1.1904e-03, -6.5215e-03],\n",
      "           [ 1.6350e-03,  3.8760e-03,  6.9077e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-9.0584e-03, -7.9744e-03, -4.4415e-03],\n",
      "           [ 1.9120e-03, -9.7660e-04, -6.2729e-03],\n",
      "           [-8.6187e-03, -1.2661e-02, -1.2943e-02]],\n",
      "\n",
      "          [[ 2.3947e-03, -4.4108e-03, -6.1761e-03],\n",
      "           [ 5.0546e-04,  1.4713e-03, -8.7536e-03],\n",
      "           [-1.3562e-03,  5.9257e-03, -8.9900e-03]],\n",
      "\n",
      "          [[-3.4165e-03, -9.5492e-03, -1.4038e-02],\n",
      "           [ 2.5265e-03, -7.9846e-03, -1.4583e-02],\n",
      "           [ 4.4262e-03, -4.4272e-03, -1.2099e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.5681e-02, -4.8767e-03,  2.8212e-02],\n",
      "           [-5.2576e-03,  1.9791e-03,  1.5923e-02],\n",
      "           [ 1.5585e-03, -5.2202e-03,  1.8415e-02]],\n",
      "\n",
      "          [[ 1.2049e-02, -8.6656e-03,  2.7625e-02],\n",
      "           [-6.2560e-03,  1.2768e-02,  4.8493e-03],\n",
      "           [-3.6924e-03, -4.9355e-03,  2.2356e-03]],\n",
      "\n",
      "          [[-7.3736e-03, -1.0747e-02,  4.8366e-03],\n",
      "           [ 9.8101e-04, -1.7788e-02,  1.8876e-02],\n",
      "           [-5.7038e-03, -1.8446e-02, -5.4860e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4251e-02, -5.5624e-03, -2.9017e-02],\n",
      "           [-8.6407e-04, -1.1755e-02, -2.8628e-02],\n",
      "           [-1.7448e-02,  4.7219e-03, -1.1770e-02]],\n",
      "\n",
      "          [[ 2.4686e-02,  4.9063e-03,  7.8401e-03],\n",
      "           [ 1.6078e-02,  1.4998e-02, -9.7813e-03],\n",
      "           [-7.8179e-03, -7.9989e-05, -7.8773e-03]],\n",
      "\n",
      "          [[-2.4552e-03,  8.7163e-03,  1.6755e-03],\n",
      "           [ 2.0849e-02, -7.6818e-03, -2.2537e-02],\n",
      "           [-1.2425e-02, -2.8472e-02, -2.6756e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 9.9571e-03,  2.0545e-04,  6.4086e-03],\n",
      "           [-1.2337e-04, -1.4172e-02, -5.8007e-03],\n",
      "           [-8.5327e-04, -1.9909e-02, -3.1202e-03]],\n",
      "\n",
      "          [[ 7.0729e-03,  1.5884e-02,  1.7491e-02],\n",
      "           [-4.3157e-03,  3.3302e-03,  1.3462e-02],\n",
      "           [-6.9320e-03,  7.4985e-03,  1.6869e-02]],\n",
      "\n",
      "          [[ 5.0801e-03,  1.3682e-02,  1.1158e-02],\n",
      "           [-2.5649e-03,  1.5874e-02,  2.2322e-02],\n",
      "           [ 1.8699e-02,  2.8784e-02,  3.6159e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.3138e-03,  1.0020e-02,  1.7342e-02],\n",
      "           [-1.1177e-03, -1.7572e-02, -9.5254e-04],\n",
      "           [ 1.5668e-02,  6.8183e-03,  7.0381e-03]],\n",
      "\n",
      "          [[-1.1412e-02, -1.1765e-02, -1.4887e-03],\n",
      "           [-5.3648e-03, -9.6505e-03,  3.0041e-03],\n",
      "           [ 9.3952e-03,  1.4064e-02,  7.0342e-03]],\n",
      "\n",
      "          [[-2.3634e-02, -8.5934e-03,  1.2332e-03],\n",
      "           [-2.0856e-03, -7.0772e-03,  3.3179e-03],\n",
      "           [ 8.5001e-03,  1.7052e-02,  1.0225e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.3995e-04,  9.1123e-03,  2.0785e-02],\n",
      "           [ 9.6605e-03,  5.0043e-03,  2.4575e-02],\n",
      "           [ 1.3214e-02, -1.8641e-02, -4.6409e-03]],\n",
      "\n",
      "          [[ 1.9285e-02,  4.1556e-03,  3.2104e-03],\n",
      "           [-1.7111e-02,  9.4102e-03, -2.7921e-03],\n",
      "           [ 2.9734e-03,  6.7426e-03, -3.5941e-03]],\n",
      "\n",
      "          [[ 5.9370e-03,  9.7349e-03,  4.4534e-04],\n",
      "           [ 4.3309e-03, -1.8704e-02,  2.2175e-03],\n",
      "           [-7.6515e-03, -8.9577e-03, -2.3427e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 7.8711e-03, -5.4466e-03,  9.0541e-03],\n",
      "           [ 5.5764e-03,  1.1659e-02,  1.3651e-03],\n",
      "           [ 7.6323e-03,  1.0321e-02,  1.3257e-02]],\n",
      "\n",
      "          [[-8.3675e-03,  2.3533e-03, -1.7458e-03],\n",
      "           [ 1.8734e-03,  1.1129e-02,  2.0234e-03],\n",
      "           [ 5.8725e-03,  1.4039e-02,  6.8465e-03]],\n",
      "\n",
      "          [[ 9.8446e-03, -3.6706e-03,  1.0616e-03],\n",
      "           [ 8.2785e-03,  2.4634e-03, -8.3599e-03],\n",
      "           [ 8.3210e-03,  1.0810e-02, -4.0159e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 4.3692e-03, -1.3950e-03,  1.8918e-02],\n",
      "           [ 1.8286e-02,  1.6680e-03,  1.7105e-02],\n",
      "           [-2.3009e-03,  4.4413e-03,  9.3964e-03]],\n",
      "\n",
      "          [[-2.8388e-03, -6.4831e-03,  1.2176e-02],\n",
      "           [-1.5500e-03, -1.0125e-04,  2.6177e-02],\n",
      "           [ 8.7502e-03,  1.7870e-02,  1.8161e-02]],\n",
      "\n",
      "          [[ 1.4727e-03,  1.3744e-02, -4.1740e-03],\n",
      "           [-4.8936e-03,  2.3983e-03,  1.6488e-02],\n",
      "           [-8.0977e-03, -1.8269e-02, -2.6299e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.1185e-04,  5.7569e-03, -1.0057e-02],\n",
      "           [-1.0372e-02, -1.5788e-02, -1.1144e-02],\n",
      "           [-2.8385e-03, -9.4294e-03, -8.4421e-03]],\n",
      "\n",
      "          [[ 1.8568e-02,  4.3058e-03, -4.3126e-03],\n",
      "           [ 1.7132e-02,  1.3454e-02, -1.8188e-02],\n",
      "           [-1.8078e-02,  1.5375e-02,  2.3068e-03]],\n",
      "\n",
      "          [[ 1.7629e-02,  1.0185e-02, -2.2363e-02],\n",
      "           [ 2.2260e-03,  4.8970e-03, -1.9868e-02],\n",
      "           [-9.5320e-03, -1.9185e-02, -1.1957e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 7.2761e-03,  1.1892e-02,  1.9821e-02],\n",
      "           [ 3.8042e-03,  9.4698e-04,  5.2903e-03],\n",
      "           [-9.9690e-03, -2.3867e-02, -4.6227e-03]],\n",
      "\n",
      "          [[ 1.5099e-02,  2.6781e-02,  3.2249e-02],\n",
      "           [ 7.1263e-04,  1.4719e-02,  3.2366e-02],\n",
      "           [-4.7478e-03,  5.6110e-03,  2.1988e-02]],\n",
      "\n",
      "          [[ 7.8638e-04,  7.8026e-03,  1.2187e-02],\n",
      "           [-2.0374e-03,  1.8841e-02,  2.0379e-02],\n",
      "           [ 7.7622e-03,  2.5273e-02,  2.0989e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.9003e-03, -4.0814e-03, -7.2378e-04],\n",
      "           [-6.1526e-03, -4.2120e-03, -7.8814e-03],\n",
      "           [ 2.4561e-03, -3.5801e-03, -5.7428e-03]],\n",
      "\n",
      "          [[-1.2977e-02, -2.5003e-03, -6.8221e-03],\n",
      "           [-7.7005e-03, -1.0022e-02, -1.3424e-03],\n",
      "           [ 1.7981e-03,  1.2644e-02,  5.5003e-03]],\n",
      "\n",
      "          [[-1.9849e-02, -1.6898e-02, -1.0651e-02],\n",
      "           [-1.3447e-02,  2.6060e-03, -8.1289e-03],\n",
      "           [ 5.9422e-03,  8.8110e-03, -2.7973e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.1525e-03,  7.4819e-03,  7.8306e-03],\n",
      "           [-1.6925e-02,  4.8092e-03,  2.5395e-02],\n",
      "           [-7.9533e-03, -6.7468e-03,  5.0673e-03]],\n",
      "\n",
      "          [[-3.1905e-03, -1.3896e-02,  9.4442e-03],\n",
      "           [-2.3800e-02, -9.5988e-04,  5.8193e-03],\n",
      "           [-1.8227e-02,  6.4186e-03,  3.2228e-03]],\n",
      "\n",
      "          [[ 2.2567e-03, -8.7614e-03,  5.7077e-03],\n",
      "           [-5.1945e-03, -2.3780e-02, -1.1663e-02],\n",
      "           [-1.2027e-02, -2.0546e-02,  1.0256e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.4485e-03, -5.2372e-03, -1.9414e-03],\n",
      "           [ 6.5421e-03,  8.8911e-04, -3.0937e-03],\n",
      "           [-2.6341e-03,  1.7306e-03,  1.2506e-03]],\n",
      "\n",
      "          [[-3.5755e-03,  1.0356e-02,  3.0103e-03],\n",
      "           [ 1.4203e-03, -4.7991e-03,  8.7767e-03],\n",
      "           [-2.8567e-03, -7.3204e-03,  9.4974e-03]],\n",
      "\n",
      "          [[-2.4645e-03,  1.6376e-03, -8.4788e-04],\n",
      "           [ 1.4859e-03,  1.3224e-03, -4.9582e-03],\n",
      "           [-1.0001e-02,  2.0244e-03,  1.2238e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.8564e-02,  1.3940e-02,  5.5827e-03],\n",
      "           [-4.9071e-03,  1.2217e-03, -2.2792e-03],\n",
      "           [ 7.4318e-03,  2.6231e-03, -1.5542e-02]],\n",
      "\n",
      "          [[-1.2761e-02,  1.4998e-02,  1.0809e-02],\n",
      "           [-1.8509e-03,  6.4239e-03, -2.2261e-02],\n",
      "           [-1.5984e-02, -5.1144e-03, -9.6608e-03]],\n",
      "\n",
      "          [[-1.0588e-02,  1.8668e-02,  1.1604e-02],\n",
      "           [ 1.0534e-02,  1.1415e-02, -1.4067e-02],\n",
      "           [ 8.1907e-03,  1.0840e-02, -5.1797e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 4.2942e-03, -4.5022e-03,  3.1471e-03],\n",
      "           [-7.2343e-03,  5.5049e-03,  9.9730e-03],\n",
      "           [-6.1142e-03, -3.8021e-02, -1.2625e-02]],\n",
      "\n",
      "          [[-2.2622e-03,  5.3916e-04,  1.5372e-02],\n",
      "           [-1.8479e-02, -5.5804e-03, -7.2882e-03],\n",
      "           [ 1.2411e-02, -3.0079e-02,  6.3267e-03]],\n",
      "\n",
      "          [[-4.0732e-03,  4.5411e-03, -2.2890e-03],\n",
      "           [-3.2098e-02, -6.9898e-03,  2.0922e-03],\n",
      "           [-3.8679e-03, -2.4799e-02,  1.7689e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.6432e-03, -2.7337e-03, -1.4043e-02],\n",
      "           [ 1.8251e-03,  1.1187e-02, -1.9404e-03],\n",
      "           [ 6.5359e-03,  2.4034e-02,  8.0879e-03]],\n",
      "\n",
      "          [[-6.3322e-03, -6.6912e-03, -8.4189e-03],\n",
      "           [ 5.3216e-03, -2.6658e-03, -1.5816e-02],\n",
      "           [ 5.5335e-03,  7.4400e-03, -1.3479e-02]],\n",
      "\n",
      "          [[-7.4012e-03,  3.2323e-03,  5.3761e-03],\n",
      "           [-7.1398e-03, -6.3889e-03, -1.7014e-02],\n",
      "           [ 1.8951e-03, -8.2086e-03, -2.1331e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.9283e-03,  1.4838e-02,  3.9266e-03],\n",
      "           [ 1.0734e-02,  9.9121e-03,  1.1492e-02],\n",
      "           [-1.0896e-02,  9.9426e-03,  1.0024e-02]],\n",
      "\n",
      "          [[ 1.3145e-03,  1.3404e-02, -6.0047e-03],\n",
      "           [ 1.3628e-02,  1.0121e-02,  1.9647e-02],\n",
      "           [-2.3899e-03,  2.7249e-03,  2.1272e-04]],\n",
      "\n",
      "          [[ 2.0404e-02,  1.3430e-02,  9.8278e-03],\n",
      "           [ 7.2391e-03,  2.9011e-02,  2.2114e-02],\n",
      "           [ 2.1707e-04,  5.0642e-03,  1.9674e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4024e-02,  1.9767e-04, -8.9721e-03],\n",
      "           [ 8.3903e-03,  4.9094e-04, -3.3622e-02],\n",
      "           [ 5.0782e-04, -1.9153e-03, -1.2982e-02]],\n",
      "\n",
      "          [[-5.9784e-03,  1.2656e-02, -1.6538e-03],\n",
      "           [ 3.1640e-03,  7.4389e-03, -9.3842e-03],\n",
      "           [-6.9786e-03, -2.0597e-02, -3.6129e-02]],\n",
      "\n",
      "          [[-1.0433e-02,  1.0696e-02,  4.2125e-03],\n",
      "           [ 3.3976e-03, -1.4054e-02, -1.5671e-02],\n",
      "           [ 9.5056e-03, -2.5360e-02, -2.2225e-02]]]]], device='cuda:0')), ('module.down_layers.3.3.norm1.weight', tensor([0.8916, 0.9415, 0.8892, 0.9435, 0.8865, 0.9278, 0.9754, 0.9735, 0.9253,\n",
      "        0.8757, 0.9539, 0.9172, 0.9708, 0.9147, 0.9641, 0.8622, 0.9280, 0.9384,\n",
      "        0.9697, 0.9411, 0.9604, 0.9557, 0.9760, 0.8694, 0.8877, 0.9174, 0.9666,\n",
      "        0.9669, 0.9523, 0.9775, 0.9856, 0.9163, 0.8839, 0.9641, 0.7985, 0.9076,\n",
      "        0.9112, 0.9138, 0.9044, 0.8891, 0.8409, 0.9340, 0.9058, 0.9230, 0.9463,\n",
      "        0.8926, 0.9667, 0.9426, 0.8874, 0.9503, 0.9351, 0.9212, 0.9360, 0.9012,\n",
      "        0.8802, 0.7848, 0.8846, 0.8564, 0.9009, 0.8515, 0.8362, 0.9121, 0.9478,\n",
      "        0.9437, 0.9357, 0.9891, 0.8277, 0.9724, 0.8675, 0.8810, 0.9003, 0.9132,\n",
      "        0.9314, 0.9083, 0.9275, 0.9742, 0.9436, 0.9184, 0.9111, 0.8824, 0.9321,\n",
      "        0.9290, 0.9109, 0.9354, 0.8983, 0.9075, 0.9599, 0.9578, 0.9487, 0.9035,\n",
      "        0.9566, 0.8988, 0.8983, 0.9326, 0.9727, 0.9800, 0.9228, 0.8124, 0.9656,\n",
      "        0.9391, 0.9125, 0.8121, 0.9319, 0.9678, 0.9124, 0.9600, 0.8879, 0.9716,\n",
      "        0.8838, 0.9330, 0.9077, 0.9398, 0.9872, 0.8816, 0.9357, 0.8415, 0.9662,\n",
      "        0.9374, 0.9500, 0.9934, 0.9625, 0.9565, 0.9678, 0.8457, 0.9376, 0.8925,\n",
      "        0.8294, 0.8636], device='cuda:0')), ('module.down_layers.3.3.norm1.bias', tensor([-2.7835e-02, -1.1003e-02, -8.1196e-03, -1.0556e-02, -3.5795e-02,\n",
      "         8.0221e-03, -5.6426e-03, -1.3861e-02, -3.7953e-02, -1.8695e-02,\n",
      "         7.5100e-04, -2.9137e-02, -1.3012e-02, -2.9395e-02, -2.8391e-02,\n",
      "         9.6029e-05, -1.3979e-02, -3.4862e-02, -2.9807e-02, -2.5915e-02,\n",
      "        -3.6099e-02, -3.2911e-02, -2.4152e-02, -3.2480e-02, -3.0904e-02,\n",
      "        -7.8913e-03, -3.3783e-02, -2.1026e-02, -1.2818e-02, -1.4893e-02,\n",
      "        -3.1579e-02, -3.1098e-02, -2.9850e-03, -1.1463e-02, -4.4242e-02,\n",
      "        -1.0348e-02, -1.5935e-02, -4.6836e-02, -1.7200e-02, -1.3061e-02,\n",
      "        -9.5373e-03, -1.2974e-02, -1.5275e-02, -8.7147e-04, -2.1070e-02,\n",
      "        -2.0527e-02, -1.9097e-02, -3.3537e-03, -2.0925e-02, -3.3518e-02,\n",
      "        -1.3675e-02, -2.5967e-02, -1.7546e-02, -3.6575e-02, -2.6929e-02,\n",
      "        -6.1573e-03, -3.6144e-02, -3.6719e-02, -7.3860e-03, -1.7824e-02,\n",
      "        -2.4970e-03, -4.6070e-02,  1.7190e-03, -6.3607e-02, -4.6016e-02,\n",
      "        -1.8761e-02, -4.2819e-02, -2.6009e-02, -3.7505e-02, -1.7487e-02,\n",
      "        -3.3424e-02, -2.3123e-02, -5.1649e-02, -4.6764e-02, -4.5461e-03,\n",
      "        -1.5518e-02, -2.2480e-02, -4.5031e-02, -3.6073e-02, -3.3206e-02,\n",
      "        -2.2112e-02, -1.2932e-02, -4.5143e-02, -8.5362e-03, -2.6303e-02,\n",
      "        -1.9285e-02, -6.6823e-03, -3.6302e-03, -2.5511e-02, -1.9283e-02,\n",
      "        -3.3302e-02, -1.8435e-02, -2.9978e-02, -1.8657e-02, -1.5911e-02,\n",
      "        -1.2909e-02, -2.2130e-02, -1.2564e-02,  8.1356e-03, -1.5844e-02,\n",
      "        -1.1854e-02,  1.4673e-02, -3.8564e-02,  1.8331e-04, -1.9302e-02,\n",
      "        -2.6767e-03, -7.7648e-03, -9.8557e-03, -2.4507e-02, -9.3404e-03,\n",
      "        -4.6536e-03, -1.4096e-02, -1.8346e-02, -2.4100e-02, -2.9617e-02,\n",
      "        -2.9190e-02, -3.1904e-02, -3.4004e-02, -2.8672e-02,  8.9933e-03,\n",
      "        -1.5777e-02, -2.8556e-02, -2.6232e-02, -3.4901e-02, -2.1368e-02,\n",
      "        -3.2275e-02, -4.5672e-02, -2.0964e-02], device='cuda:0')), ('module.down_layers.3.3.norm2.weight', tensor([0.9053, 0.9280, 0.9254, 0.9472, 0.9140, 0.9403, 0.9567, 0.9627, 0.8733,\n",
      "        0.9474, 0.9491, 0.8268, 0.9299, 0.8132, 0.7877, 0.9630, 0.7504, 0.7876,\n",
      "        0.7912, 0.7785, 0.7572, 0.9288, 0.7765, 0.7860, 0.7241, 0.9257, 0.8578,\n",
      "        0.9305, 0.9012, 0.4296, 0.8010, 0.8795, 0.8223, 0.7519, 0.9307, 0.9094,\n",
      "        0.7472, 0.8418, 0.9519, 0.8824, 0.8764, 0.8760, 0.9137, 0.8543, 0.8823,\n",
      "        0.8424, 0.9268, 0.8879, 0.7765, 0.8820, 0.8952, 0.9380, 0.6928, 0.7540,\n",
      "        0.9184, 0.9154, 0.8480, 0.8811, 0.9236, 0.9255, 0.8513, 0.9331, 0.7214,\n",
      "        0.7315, 0.9546, 0.9517, 0.9177, 0.9724, 0.7977, 0.9088, 0.9601, 0.9332,\n",
      "        0.9502, 0.9194, 0.7593, 0.8015, 0.8424, 0.7720, 0.7433, 0.8413, 0.9695,\n",
      "        0.7472, 0.8867, 0.7646, 0.7714, 0.8091, 0.7871, 0.9583, 0.9705, 0.9552,\n",
      "        0.9357, 0.8247, 0.9467, 0.7765, 0.9352, 0.7674, 0.8265, 0.8086, 0.9454,\n",
      "        0.9325, 0.2396, 0.9406, 0.9390, 0.7740, 0.9237, 0.5072, 0.9015, 0.9279,\n",
      "        0.8225, 0.9243, 0.9118, 0.8226, 0.8244, 0.9793, 0.9114, 0.7185, 0.8030,\n",
      "        0.8861, 0.7948, 0.7223, 0.9475, 0.8804, 0.9617, 0.9262, 0.7746, 0.9018,\n",
      "        0.9452, 0.8616], device='cuda:0')), ('module.down_layers.3.3.norm2.bias', tensor([-3.9059e-02, -6.5152e-02, -6.1442e-02, -6.2405e-02, -4.8222e-02,\n",
      "        -6.3268e-02, -5.9944e-02, -6.2800e-02, -3.3670e-02, -6.3121e-02,\n",
      "        -5.9195e-02, -4.0338e-02, -6.1266e-02, -4.5621e-02, -4.8580e-02,\n",
      "        -6.4169e-02, -5.0269e-02, -3.1884e-02, -3.6181e-02, -4.0171e-02,\n",
      "        -5.2777e-02, -3.3320e-02, -4.4080e-02, -3.9096e-02, -5.2491e-02,\n",
      "        -4.0341e-02, -3.8106e-02, -2.1644e-02, -2.7753e-02, -3.6830e-02,\n",
      "        -4.3993e-02, -3.2891e-02, -4.6828e-03,  1.4898e-03,  2.2383e-04,\n",
      "         3.7237e-03,  5.3807e-04, -4.1458e-04,  6.2049e-03, -6.7981e-03,\n",
      "        -9.9234e-03,  5.6764e-03, -5.9123e-04, -3.9659e-03, -4.2440e-03,\n",
      "        -2.7576e-03,  8.3522e-04, -9.3352e-03, -3.6697e-02, -4.6442e-02,\n",
      "        -2.3928e-02, -2.2798e-02, -5.7534e-02, -5.4680e-02, -1.7296e-02,\n",
      "        -3.7601e-02, -3.5885e-02, -3.4471e-02, -2.6456e-02, -3.1555e-02,\n",
      "        -3.3356e-02, -3.4125e-02, -5.7195e-02, -4.8238e-02, -4.2769e-02,\n",
      "        -4.6391e-02, -4.7985e-02, -4.5754e-02, -6.0134e-02, -4.3040e-02,\n",
      "        -4.9729e-02, -5.1565e-02, -4.4067e-02, -4.9711e-02, -5.6675e-02,\n",
      "        -3.4199e-02, -5.2622e-02, -4.9644e-02, -4.6613e-02, -5.5814e-02,\n",
      "        -1.2768e-02, -1.2058e-02, -9.8405e-03, -4.7408e-03, -1.8214e-02,\n",
      "        -5.3372e-03, -1.0653e-02,  1.4379e-03, -1.0866e-02, -1.3194e-02,\n",
      "         1.7544e-03, -5.6231e-03, -1.3406e-02, -1.0430e-02, -6.9066e-03,\n",
      "        -9.6045e-03, -6.1458e-02, -6.8986e-02, -5.2036e-02, -6.2551e-02,\n",
      "        -4.3876e-10, -4.9276e-02, -5.4367e-02, -6.5684e-02, -5.3386e-02,\n",
      "        -4.7238e-02, -6.4517e-02, -6.5838e-02, -6.4911e-02, -5.2978e-02,\n",
      "        -5.8664e-02, -7.3951e-02, -7.2992e-02, -1.9020e-02, -2.7671e-02,\n",
      "        -7.3184e-02, -3.7902e-02, -3.7515e-02, -4.5387e-02, -6.3521e-02,\n",
      "        -3.7797e-02, -4.4003e-02, -2.0951e-02, -3.4188e-02, -7.5538e-02,\n",
      "        -5.1311e-02, -2.9789e-02, -6.8131e-02], device='cuda:0')), ('module.down_layers.3.3.conv1.conv.weight', tensor([[[[[ 1.1780e-02,  9.2570e-04,  5.9333e-04],\n",
      "           [-1.2834e-02, -1.1682e-02, -1.1332e-02],\n",
      "           [-3.3950e-03, -4.8439e-03,  6.1223e-03]],\n",
      "\n",
      "          [[ 1.3866e-02, -8.1018e-03, -3.1108e-03],\n",
      "           [ 1.2065e-02,  5.3982e-03, -1.2103e-02],\n",
      "           [-4.4609e-03, -1.5039e-02, -1.5814e-03]],\n",
      "\n",
      "          [[ 9.1689e-03,  1.1659e-02,  5.3215e-03],\n",
      "           [-1.1432e-02,  1.2682e-02,  5.2679e-03],\n",
      "           [-4.4532e-03, -4.5416e-03, -7.1927e-03]]],\n",
      "\n",
      "\n",
      "         [[[-8.8872e-03, -7.4492e-03, -1.4820e-02],\n",
      "           [-3.2533e-03, -6.1071e-03, -1.2716e-02],\n",
      "           [ 5.8947e-03,  8.2249e-03,  7.4608e-03]],\n",
      "\n",
      "          [[-1.4601e-03,  8.8531e-04,  3.3128e-04],\n",
      "           [ 1.5433e-02,  2.3628e-02,  7.3401e-03],\n",
      "           [ 2.5492e-02,  2.6843e-02,  1.9669e-02]],\n",
      "\n",
      "          [[-1.2047e-02, -4.1618e-03,  1.3162e-02],\n",
      "           [ 1.8399e-02,  1.7232e-02,  1.8258e-02],\n",
      "           [ 7.8859e-03,  1.3051e-02,  1.9120e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.4511e-02, -1.4671e-02,  1.0299e-02],\n",
      "           [-2.5988e-02, -1.8631e-02,  1.2871e-02],\n",
      "           [-3.2585e-03, -9.0138e-03, -4.4492e-03]],\n",
      "\n",
      "          [[-3.3350e-03, -1.3417e-02,  6.8816e-05],\n",
      "           [-2.1828e-02,  3.2332e-03, -1.1047e-02],\n",
      "           [-3.7457e-03,  1.7261e-03,  2.1211e-02]],\n",
      "\n",
      "          [[-2.3413e-03, -1.7004e-02, -2.7507e-02],\n",
      "           [ 5.3683e-03,  5.4563e-03, -5.9785e-03],\n",
      "           [ 2.2865e-02,  1.4516e-02,  2.1751e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0418e-02, -7.8316e-03,  3.2050e-03],\n",
      "           [-7.1507e-03, -7.0912e-03, -2.3307e-03],\n",
      "           [-1.4971e-02, -3.1874e-03, -1.1316e-02]],\n",
      "\n",
      "          [[-1.0761e-02,  1.1819e-02,  8.5433e-03],\n",
      "           [ 6.2462e-03,  9.9811e-03,  7.1465e-03],\n",
      "           [-3.6642e-03, -2.1310e-02, -6.9288e-04]],\n",
      "\n",
      "          [[-2.0266e-02,  4.9802e-03,  5.5113e-03],\n",
      "           [-1.2171e-03,  5.1117e-03,  2.2995e-02],\n",
      "           [-4.1095e-03, -2.1405e-02,  7.3338e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.7642e-02, -1.6183e-02, -6.9072e-03],\n",
      "           [-1.8838e-02, -1.7655e-02, -7.6660e-03],\n",
      "           [-1.5829e-03, -8.8635e-03, -1.5677e-02]],\n",
      "\n",
      "          [[-5.3293e-03, -9.4603e-03, -1.8351e-02],\n",
      "           [-1.5288e-03, -3.4351e-03,  1.7862e-03],\n",
      "           [-1.6071e-02, -2.0855e-02, -2.0620e-02]],\n",
      "\n",
      "          [[-1.3951e-03, -5.4954e-03, -1.5596e-02],\n",
      "           [ 5.5135e-03,  1.7841e-02,  1.9831e-04],\n",
      "           [ 7.7057e-03,  9.1903e-03, -1.7931e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.1159e-02,  1.4428e-02,  2.0101e-02],\n",
      "           [ 1.6664e-02,  2.2838e-03,  1.5479e-03],\n",
      "           [ 1.3703e-02,  9.7970e-03,  1.7569e-02]],\n",
      "\n",
      "          [[ 2.0784e-02, -1.9128e-03,  4.3586e-03],\n",
      "           [ 1.8404e-02,  1.4204e-03,  9.1861e-03],\n",
      "           [-7.0232e-03,  1.8789e-02, -3.3484e-03]],\n",
      "\n",
      "          [[-7.7245e-03,  7.4118e-03, -3.7899e-03],\n",
      "           [-6.9137e-03, -1.1613e-02, -1.9801e-02],\n",
      "           [-1.4088e-02, -1.2475e-02, -2.2435e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.6190e-02, -7.8780e-03, -1.7012e-02],\n",
      "           [ 6.7238e-03, -7.0853e-03, -1.9860e-02],\n",
      "           [ 1.5111e-02, -9.5769e-03, -1.6960e-02]],\n",
      "\n",
      "          [[ 1.1441e-02,  5.3209e-03, -4.4710e-03],\n",
      "           [-4.8827e-03,  1.1469e-02, -1.0516e-02],\n",
      "           [ 2.2153e-03, -9.8700e-03,  6.5140e-04]],\n",
      "\n",
      "          [[-3.4646e-03,  7.5225e-03,  3.2914e-03],\n",
      "           [ 8.6986e-03,  6.7537e-03, -2.7766e-03],\n",
      "           [ 7.7360e-03, -6.2697e-03, -5.8515e-03]]],\n",
      "\n",
      "\n",
      "         [[[-8.0921e-03, -2.0132e-02,  2.0131e-03],\n",
      "           [-4.0890e-03, -6.0262e-03, -2.0561e-03],\n",
      "           [-3.2785e-03,  7.8948e-03, -5.6232e-04]],\n",
      "\n",
      "          [[-1.9259e-02, -6.7617e-03,  2.1125e-03],\n",
      "           [ 9.6382e-03,  4.4963e-03,  1.3914e-02],\n",
      "           [ 1.4682e-02,  2.1362e-02,  1.4068e-02]],\n",
      "\n",
      "          [[-1.6769e-02,  1.2436e-02,  8.3760e-03],\n",
      "           [-3.2458e-03,  4.4676e-03,  8.2177e-03],\n",
      "           [ 1.8612e-02,  1.7020e-02,  9.7769e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.9136e-03, -1.6587e-02, -1.5720e-04],\n",
      "           [-3.4873e-02, -1.9109e-02,  4.4332e-04],\n",
      "           [-1.7175e-02,  7.3377e-03, -1.0402e-02]],\n",
      "\n",
      "          [[-2.7949e-02, -1.6082e-02, -1.7923e-02],\n",
      "           [-2.2408e-02, -1.7172e-02, -1.2005e-02],\n",
      "           [-8.0367e-03,  6.6828e-03, -4.6783e-04]],\n",
      "\n",
      "          [[-1.6185e-02, -1.5974e-02, -3.2580e-02],\n",
      "           [-1.0869e-02,  5.6564e-03, -1.3833e-02],\n",
      "           [ 2.3073e-02,  1.4813e-02,  7.8146e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.1930e-03, -2.8498e-03,  8.9239e-03],\n",
      "           [ 1.7817e-03,  9.8069e-03,  9.2813e-03],\n",
      "           [-8.5350e-03,  9.9207e-03,  1.7447e-02]],\n",
      "\n",
      "          [[-1.6138e-02,  8.5786e-03,  2.5669e-02],\n",
      "           [-1.5272e-02, -8.5532e-03,  2.1276e-02],\n",
      "           [ 3.4933e-03,  1.0433e-02,  9.5798e-04]],\n",
      "\n",
      "          [[-7.3119e-03,  2.0920e-04,  1.5133e-02],\n",
      "           [-1.3492e-02, -4.3902e-03, -9.5640e-04],\n",
      "           [-2.2590e-02, -2.3488e-02,  1.0400e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.8143e-03, -1.0149e-02, -1.3215e-02],\n",
      "           [ 7.1630e-03,  9.7684e-03,  2.8519e-03],\n",
      "           [-1.0812e-02,  4.4709e-04,  1.9092e-03]],\n",
      "\n",
      "          [[-1.0702e-02, -1.4450e-02,  4.1555e-04],\n",
      "           [-5.9968e-03, -3.0268e-03, -1.3242e-02],\n",
      "           [-4.7238e-03,  3.8149e-03,  1.1602e-02]],\n",
      "\n",
      "          [[-3.6475e-03, -7.7358e-04, -5.3398e-03],\n",
      "           [ 1.2751e-02,  1.5605e-02, -1.0030e-02],\n",
      "           [ 6.5115e-04,  7.4440e-03, -9.8501e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.7581e-03,  2.8102e-02,  2.9859e-02],\n",
      "           [ 1.4442e-02,  2.7397e-02,  4.1084e-02],\n",
      "           [ 7.2991e-03,  2.1970e-02,  2.2135e-02]],\n",
      "\n",
      "          [[ 1.5142e-02,  8.7015e-03, -1.8071e-03],\n",
      "           [ 6.7601e-03,  1.2067e-02,  2.6658e-02],\n",
      "           [ 1.6889e-02,  7.4416e-03,  9.8241e-03]],\n",
      "\n",
      "          [[ 4.6358e-03,  6.8066e-03,  7.6578e-04],\n",
      "           [ 7.6484e-03,  9.4993e-03,  4.0422e-03],\n",
      "           [-1.4998e-02, -9.5308e-03,  1.3417e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.4226e-03,  1.7525e-02,  1.1326e-03],\n",
      "           [-2.0613e-03,  1.6900e-02,  1.6016e-02],\n",
      "           [ 2.6153e-03, -4.6422e-03,  1.4263e-03]],\n",
      "\n",
      "          [[ 9.4768e-03, -8.2205e-03, -5.4932e-03],\n",
      "           [-5.5894e-03,  5.1319e-03, -1.0663e-03],\n",
      "           [ 1.8050e-02,  4.1305e-04,  7.5278e-03]],\n",
      "\n",
      "          [[ 1.4239e-02,  8.4639e-03,  2.2187e-03],\n",
      "           [-6.0547e-03, -1.2894e-02,  1.4235e-03],\n",
      "           [ 7.5806e-03, -8.9470e-03, -5.8896e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.5286e-02, -1.5966e-02, -2.4025e-03],\n",
      "           [-2.9494e-02, -2.5384e-02, -8.0081e-03],\n",
      "           [-8.5473e-03, -1.3920e-02,  5.3283e-03]],\n",
      "\n",
      "          [[-1.7223e-02, -1.5683e-02, -4.8769e-03],\n",
      "           [-9.2572e-03, -1.6753e-02, -2.7874e-02],\n",
      "           [-1.4650e-02, -1.2063e-02,  2.2138e-03]],\n",
      "\n",
      "          [[ 9.3816e-03,  2.8304e-03, -6.0487e-03],\n",
      "           [-4.5185e-03, -9.0782e-03, -1.4758e-02],\n",
      "           [-4.5718e-03,  1.8561e-02,  1.4492e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.6781e-03, -2.4263e-02, -1.6693e-02],\n",
      "           [ 6.8172e-03,  1.5643e-03, -4.4828e-03],\n",
      "           [ 4.5658e-03,  1.0192e-02,  1.9256e-02]],\n",
      "\n",
      "          [[-1.2340e-02, -3.4345e-02, -2.0194e-02],\n",
      "           [-7.1040e-03, -1.0616e-02,  1.2654e-02],\n",
      "           [ 1.5192e-02,  2.6809e-02,  1.0589e-02]],\n",
      "\n",
      "          [[-1.8676e-02, -1.8157e-02, -7.7961e-03],\n",
      "           [-5.0882e-03, -1.3877e-02, -5.7140e-03],\n",
      "           [ 4.1288e-03,  4.4702e-03,  1.0558e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-5.4637e-04,  1.0972e-02,  1.2685e-02],\n",
      "           [ 2.8684e-04,  9.3504e-03, -7.5669e-03],\n",
      "           [-1.8876e-03, -1.1317e-02,  3.9934e-03]],\n",
      "\n",
      "          [[-6.6395e-03, -2.8778e-03,  1.8779e-02],\n",
      "           [ 6.2722e-03, -9.9977e-03,  1.6332e-02],\n",
      "           [-2.7916e-03,  9.6884e-03,  1.3144e-02]],\n",
      "\n",
      "          [[ 3.4698e-03,  7.2637e-04,  1.4533e-02],\n",
      "           [-5.6024e-03, -8.7144e-03, -2.1259e-03],\n",
      "           [ 7.2611e-03, -1.3535e-02,  1.1756e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.5124e-03,  4.0813e-03,  7.1378e-03],\n",
      "           [-1.6075e-02, -1.4914e-03,  2.3855e-03],\n",
      "           [ 1.3410e-03, -3.5475e-03,  1.0438e-02]],\n",
      "\n",
      "          [[ 3.9583e-03,  4.1892e-03, -7.8574e-03],\n",
      "           [ 2.9279e-03,  3.4583e-03, -5.9179e-03],\n",
      "           [-1.3107e-02, -1.3825e-04, -6.3561e-03]],\n",
      "\n",
      "          [[ 1.7426e-02, -4.2437e-03, -1.4544e-02],\n",
      "           [ 9.7600e-03, -6.0495e-03, -1.3917e-02],\n",
      "           [ 1.4846e-02,  1.4075e-02, -2.0285e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.4101e-02, -2.1266e-02, -1.5149e-02],\n",
      "           [ 7.7321e-03,  1.4058e-02,  3.8334e-04],\n",
      "           [-1.1393e-02, -1.0034e-02, -6.7205e-03]],\n",
      "\n",
      "          [[-6.6775e-03, -1.1632e-02, -2.4784e-05],\n",
      "           [-6.5026e-03,  3.0736e-03,  1.8286e-02],\n",
      "           [ 1.5214e-02, -6.5729e-03, -1.8645e-02]],\n",
      "\n",
      "          [[ 2.3502e-02, -6.9790e-03, -1.5469e-02],\n",
      "           [ 2.9666e-02,  1.2236e-02,  1.1761e-02],\n",
      "           [ 8.8107e-03,  1.3804e-02,  1.7791e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.0314e-02, -1.8905e-02, -1.1389e-02],\n",
      "           [-7.0344e-03, -1.9603e-02, -6.4355e-03],\n",
      "           [-9.5311e-03, -6.3450e-03,  1.4574e-02]],\n",
      "\n",
      "          [[-5.6678e-03, -1.8411e-02,  2.9739e-03],\n",
      "           [-2.0585e-02, -1.5216e-02, -1.1761e-02],\n",
      "           [-8.1185e-03, -2.0889e-02,  2.6990e-03]],\n",
      "\n",
      "          [[-7.8309e-03,  4.6905e-03,  2.6591e-04],\n",
      "           [-1.3316e-02, -9.2088e-03,  5.4891e-03],\n",
      "           [-1.4915e-03, -1.6689e-02, -1.3624e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.1845e-02, -2.4181e-02, -8.9534e-04],\n",
      "           [ 1.3451e-03, -1.1697e-02, -3.2925e-03],\n",
      "           [-8.4257e-03, -3.5851e-03,  9.2727e-03]],\n",
      "\n",
      "          [[ 4.8143e-03, -1.5072e-02,  2.3247e-03],\n",
      "           [-1.1407e-02, -2.2409e-02,  6.2933e-03],\n",
      "           [-6.7336e-03, -4.2700e-04,  1.3860e-02]],\n",
      "\n",
      "          [[-3.1772e-03, -2.8555e-03, -9.5453e-03],\n",
      "           [-1.7207e-02, -1.9031e-02, -5.7297e-03],\n",
      "           [ 2.4983e-03, -8.8288e-03,  7.4338e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.2720e-02, -3.1476e-02, -1.1401e-02],\n",
      "           [-1.1752e-02, -7.5809e-03,  1.6883e-03],\n",
      "           [ 4.1917e-03, -6.3047e-03, -4.5409e-03]],\n",
      "\n",
      "          [[-1.6238e-02, -1.2879e-02, -1.5280e-02],\n",
      "           [ 1.3206e-02,  3.8715e-04, -4.3622e-03],\n",
      "           [ 3.7640e-03, -5.9660e-03, -4.8636e-03]],\n",
      "\n",
      "          [[-2.0529e-02, -2.3142e-02, -2.1080e-02],\n",
      "           [ 1.0554e-02, -3.3214e-03, -2.9623e-02],\n",
      "           [ 5.9381e-03,  1.4786e-02, -1.2163e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.1057e-02, -1.1031e-02,  8.3974e-04],\n",
      "           [ 9.9150e-03, -9.0378e-03, -1.4832e-02],\n",
      "           [ 9.3360e-03,  1.1893e-02, -9.9130e-03]],\n",
      "\n",
      "          [[ 9.5395e-03,  1.1424e-02,  1.5967e-02],\n",
      "           [-9.2628e-03, -6.2902e-03,  2.9499e-03],\n",
      "           [-1.2310e-02,  5.5585e-03,  1.5067e-02]],\n",
      "\n",
      "          [[ 7.1380e-03,  1.1246e-02,  9.3022e-03],\n",
      "           [-8.0457e-03, -5.4485e-03, -1.0179e-03],\n",
      "           [-2.3538e-04, -1.1896e-02,  1.6179e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.7311e-03, -5.5201e-03,  1.2965e-02],\n",
      "           [ 5.1835e-03, -1.9178e-03,  3.5086e-03],\n",
      "           [ 2.5131e-02,  1.6038e-02, -8.5271e-03]],\n",
      "\n",
      "          [[ 1.6234e-02,  1.2999e-02,  5.2492e-03],\n",
      "           [-1.5652e-02, -1.6448e-02, -1.2276e-02],\n",
      "           [ 1.5692e-02,  1.0746e-02,  1.7346e-03]],\n",
      "\n",
      "          [[ 1.7132e-02, -5.0677e-03, -8.1567e-04],\n",
      "           [-9.8292e-03, -2.9967e-03,  2.2986e-03],\n",
      "           [-4.0946e-04,  5.1653e-03,  1.0672e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2095e-02, -1.7481e-04, -6.3831e-03],\n",
      "           [ 3.5276e-02,  3.5777e-02,  1.3873e-02],\n",
      "           [ 1.5216e-02,  3.1754e-02,  1.2966e-02]],\n",
      "\n",
      "          [[ 1.9908e-02, -1.2557e-03, -1.0457e-02],\n",
      "           [ 8.5694e-03,  5.3451e-03, -1.6228e-02],\n",
      "           [ 1.2921e-02,  2.4124e-03,  1.1571e-02]],\n",
      "\n",
      "          [[ 1.7633e-02,  4.2061e-04, -4.3789e-03],\n",
      "           [ 1.3374e-02,  2.4660e-02,  5.0902e-03],\n",
      "           [ 6.3422e-03,  8.8473e-03, -1.5942e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 8.3141e-03, -1.4383e-02, -8.8551e-03],\n",
      "           [-1.1488e-02, -2.5637e-02, -4.0286e-03],\n",
      "           [-2.1675e-02, -1.8590e-02, -2.6393e-02]],\n",
      "\n",
      "          [[ 1.5772e-02, -4.9395e-03,  9.6535e-03],\n",
      "           [ 1.7570e-02, -9.3337e-03,  1.8338e-03],\n",
      "           [-1.4435e-02, -2.0692e-02, -3.6484e-02]],\n",
      "\n",
      "          [[ 3.0929e-02,  1.8432e-02,  4.5987e-03],\n",
      "           [ 2.4989e-02,  1.0664e-02,  6.8651e-03],\n",
      "           [-2.7373e-03, -9.5719e-03, -2.1244e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.6252e-02, -1.9210e-02, -3.6961e-04],\n",
      "           [ 7.5965e-03, -9.8674e-03,  1.2999e-03],\n",
      "           [ 3.7961e-04, -2.1882e-03,  1.7410e-02]],\n",
      "\n",
      "          [[-7.0636e-03, -6.1556e-03, -7.0303e-03],\n",
      "           [-6.8598e-03, -3.4101e-03, -2.5649e-03],\n",
      "           [-8.5899e-03,  1.8553e-02,  1.7139e-02]],\n",
      "\n",
      "          [[-2.1120e-02, -8.5689e-03, -1.7509e-02],\n",
      "           [-2.5850e-02, -2.6633e-02, -2.7536e-02],\n",
      "           [-1.0277e-02, -1.1020e-02, -2.4667e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.0903e-02, -1.9646e-02, -1.8226e-02],\n",
      "           [-8.1367e-03, -5.5176e-04,  5.4197e-03],\n",
      "           [-2.9798e-03, -5.1094e-03,  3.7770e-03]],\n",
      "\n",
      "          [[-1.8826e-02, -8.9691e-03, -2.3810e-02],\n",
      "           [ 1.4269e-02,  6.9834e-03, -1.2466e-02],\n",
      "           [ 1.3734e-02,  1.3531e-02, -4.4344e-03]],\n",
      "\n",
      "          [[-2.4714e-02, -3.3512e-02, -2.9173e-02],\n",
      "           [ 9.1722e-03, -3.3684e-03, -2.1217e-02],\n",
      "           [ 1.1054e-02,  5.5242e-03,  3.5569e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-9.9129e-04, -1.6958e-02,  1.0626e-03],\n",
      "           [ 6.9793e-03, -2.1223e-03,  2.3883e-02],\n",
      "           [ 1.3032e-02,  1.8683e-03,  2.3080e-02]],\n",
      "\n",
      "          [[-2.7213e-03,  9.0318e-03,  7.5922e-03],\n",
      "           [-1.4249e-02,  3.2716e-03,  1.8263e-02],\n",
      "           [-4.9242e-03, -2.6505e-03, -1.8229e-04]],\n",
      "\n",
      "          [[-4.0904e-03,  4.8279e-03,  9.4806e-03],\n",
      "           [ 1.3440e-03, -5.0908e-03, -3.7967e-03],\n",
      "           [-2.3816e-02, -9.4463e-04, -9.4401e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.3890e-02, -1.7386e-02, -1.2279e-02],\n",
      "           [-1.8070e-02, -8.1381e-03, -1.5533e-02],\n",
      "           [ 2.2775e-03,  1.5716e-02,  2.9034e-03]],\n",
      "\n",
      "          [[-8.2270e-03, -1.1813e-02, -1.0279e-03],\n",
      "           [-2.2394e-02, -1.0972e-02, -7.5078e-03],\n",
      "           [-1.8992e-03, -1.6553e-03, -2.0996e-02]],\n",
      "\n",
      "          [[-5.8303e-03, -3.1372e-02, -1.6983e-02],\n",
      "           [-2.3511e-02, -2.8142e-02,  8.8525e-04],\n",
      "           [-5.4549e-03, -1.6368e-02, -1.4744e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1478e-02,  1.9228e-02,  2.4697e-02],\n",
      "           [ 3.9654e-02,  5.9395e-02,  2.5542e-02],\n",
      "           [ 9.1177e-03,  4.9258e-02,  2.8403e-02]],\n",
      "\n",
      "          [[ 2.3079e-02,  1.0620e-02,  1.0200e-02],\n",
      "           [ 1.4291e-02,  8.6465e-03,  1.2213e-02],\n",
      "           [ 9.1841e-03,  1.8919e-02,  3.4244e-03]],\n",
      "\n",
      "          [[ 1.0512e-02,  1.6580e-02,  5.1808e-03],\n",
      "           [ 1.7659e-02,  8.1910e-03, -3.8597e-03],\n",
      "           [ 1.7330e-03, -6.4986e-03, -2.9928e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.5818e-02, -2.7678e-04, -5.5201e-03],\n",
      "           [-2.3152e-03, -5.7781e-04, -4.4254e-03],\n",
      "           [-2.8011e-02,  9.3097e-03, -5.2513e-03]],\n",
      "\n",
      "          [[-9.2607e-04, -3.9395e-03,  3.4245e-04],\n",
      "           [-1.9008e-02,  6.2980e-03,  8.7139e-04],\n",
      "           [-1.5191e-03, -1.3162e-03,  2.2749e-03]],\n",
      "\n",
      "          [[-1.6476e-02, -9.0394e-03,  3.0986e-03],\n",
      "           [ 9.6591e-03,  3.9030e-03,  4.4633e-03],\n",
      "           [-1.7871e-02, -7.9180e-04, -1.4678e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.0940e-02,  2.7985e-02,  2.7218e-02],\n",
      "           [ 1.4729e-02,  1.4733e-02,  6.0193e-03],\n",
      "           [ 7.8184e-03,  2.2590e-03,  1.4571e-02]],\n",
      "\n",
      "          [[ 1.3250e-02,  7.2730e-03,  2.5644e-02],\n",
      "           [ 8.6611e-03, -1.2519e-02, -4.4545e-04],\n",
      "           [-2.7269e-02, -2.2800e-02, -6.8847e-03]],\n",
      "\n",
      "          [[ 9.5229e-03,  3.8735e-03, -1.2616e-02],\n",
      "           [-2.9139e-02, -3.1784e-02, -4.3645e-02],\n",
      "           [-4.6431e-02, -4.6066e-02, -3.0467e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.3770e-02, -2.3985e-02, -2.3589e-02],\n",
      "           [-2.7883e-02, -1.6055e-02, -2.9763e-03],\n",
      "           [-2.6615e-03, -1.1845e-02, -1.3159e-02]],\n",
      "\n",
      "          [[-2.3994e-02, -2.1833e-03,  4.1009e-05],\n",
      "           [-2.4368e-02, -4.9402e-03,  5.8987e-03],\n",
      "           [-7.8068e-03, -1.4351e-02, -2.0189e-02]],\n",
      "\n",
      "          [[-5.8937e-03,  7.4656e-03,  1.4964e-03],\n",
      "           [-1.6012e-02, -1.3369e-02, -1.9805e-02],\n",
      "           [-1.6619e-02, -3.0342e-02, -3.1944e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.1208e-02,  2.1294e-03,  1.4965e-02],\n",
      "           [ 1.8578e-02,  2.0811e-02,  1.4210e-03],\n",
      "           [-6.8329e-03,  2.2959e-02,  1.1227e-02]],\n",
      "\n",
      "          [[-1.4380e-02, -1.0063e-02,  1.0653e-02],\n",
      "           [ 1.8389e-02, -1.6303e-03,  4.3019e-03],\n",
      "           [ 1.6184e-02,  2.3228e-02,  2.0838e-02]],\n",
      "\n",
      "          [[ 5.2368e-03,  1.3265e-02,  1.0798e-02],\n",
      "           [ 2.4071e-02, -4.5053e-06,  1.0654e-02],\n",
      "           [ 2.8887e-02,  1.1035e-02,  3.6756e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.7600e-02,  1.0373e-02,  5.9888e-03],\n",
      "           [ 5.5440e-03,  5.3030e-04,  7.4119e-03],\n",
      "           [ 7.9438e-03,  5.6275e-03,  5.4407e-03]],\n",
      "\n",
      "          [[-2.1624e-03, -7.9941e-03,  5.1360e-03],\n",
      "           [ 6.0479e-03, -2.3920e-03,  6.4621e-03],\n",
      "           [ 1.0910e-02,  7.7439e-03,  2.7393e-03]],\n",
      "\n",
      "          [[-1.2639e-02, -1.6506e-02,  1.2847e-03],\n",
      "           [ 7.4427e-03,  1.2012e-03, -8.3239e-03],\n",
      "           [ 3.5437e-03,  7.1846e-03, -5.8004e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.4080e-02,  1.6641e-02,  2.5296e-02],\n",
      "           [ 5.9299e-03,  1.4314e-02,  1.4906e-02],\n",
      "           [ 5.7989e-03, -7.1683e-04,  1.8279e-03]],\n",
      "\n",
      "          [[-2.4615e-02,  1.5144e-02,  1.9827e-02],\n",
      "           [-5.6091e-03, -1.8734e-03, -4.9969e-03],\n",
      "           [-3.6560e-03,  1.0095e-03, -5.9495e-03]],\n",
      "\n",
      "          [[-1.3345e-02, -6.5766e-03,  7.8877e-04],\n",
      "           [ 7.4466e-03,  2.2811e-03, -7.8818e-03],\n",
      "           [ 1.2375e-02,  4.0241e-03,  4.8488e-03]]]]], device='cuda:0')), ('module.down_layers.3.3.conv2.conv.weight', tensor([[[[[-2.5206e-02, -7.2029e-04, -6.9801e-03],\n",
      "           [-3.8055e-03,  4.0842e-04, -6.1138e-03],\n",
      "           [ 3.7710e-03,  7.8316e-03, -2.1218e-03]],\n",
      "\n",
      "          [[-9.8640e-03, -5.6319e-04,  5.7775e-03],\n",
      "           [-1.0609e-03,  2.1719e-02,  2.1499e-02],\n",
      "           [ 2.0973e-02,  3.7999e-02,  1.8566e-02]],\n",
      "\n",
      "          [[ 1.3279e-03,  4.4509e-03,  1.2540e-03],\n",
      "           [-4.4422e-03,  8.3183e-03,  1.5228e-02],\n",
      "           [-4.5436e-03,  6.5947e-03,  1.9615e-02]]],\n",
      "\n",
      "\n",
      "         [[[-9.9266e-04, -9.5048e-03, -3.6616e-03],\n",
      "           [-1.3832e-02,  3.3697e-03, -2.6858e-02],\n",
      "           [ 5.1243e-04,  1.1504e-02, -1.5364e-02]],\n",
      "\n",
      "          [[ 2.0784e-02,  1.1463e-02,  6.3822e-04],\n",
      "           [ 1.1198e-02,  4.6262e-03,  1.3752e-02],\n",
      "           [ 9.4261e-03, -5.0934e-04,  2.2893e-02]],\n",
      "\n",
      "          [[ 3.6707e-03,  2.1751e-02,  8.1856e-03],\n",
      "           [ 1.2565e-02,  2.1306e-03,  2.7628e-02],\n",
      "           [-2.2612e-02,  1.9298e-02,  1.3463e-03]]],\n",
      "\n",
      "\n",
      "         [[[-7.0262e-03,  9.8772e-03, -2.7739e-03],\n",
      "           [-3.2855e-03,  6.5065e-03,  2.4294e-02],\n",
      "           [ 3.2344e-02,  4.7294e-02,  1.0869e-02]],\n",
      "\n",
      "          [[ 4.1059e-03, -9.0233e-03, -4.7538e-03],\n",
      "           [-1.5515e-02,  1.0292e-02,  7.1245e-03],\n",
      "           [-3.9163e-04,  3.0646e-02,  1.6111e-02]],\n",
      "\n",
      "          [[ 7.5589e-03,  4.4569e-03,  1.8626e-02],\n",
      "           [-7.1146e-03, -1.3225e-02, -1.5622e-03],\n",
      "           [-4.3171e-02, -1.3523e-02,  1.9301e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.8817e-02,  2.1353e-02,  1.4668e-02],\n",
      "           [-5.7541e-03,  1.1696e-02,  1.6424e-02],\n",
      "           [ 1.8769e-02,  1.9065e-03,  3.5809e-02]],\n",
      "\n",
      "          [[ 8.4192e-03,  2.0572e-02, -8.6201e-03],\n",
      "           [-1.7978e-03, -4.8151e-03,  6.6098e-03],\n",
      "           [-1.3218e-02, -6.7839e-04,  2.4828e-02]],\n",
      "\n",
      "          [[ 3.3725e-02,  2.2920e-02,  3.7344e-03],\n",
      "           [ 1.0227e-02,  1.1303e-02,  1.3328e-02],\n",
      "           [ 1.7912e-03,  3.6523e-03, -7.4041e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.9184e-02,  5.6577e-03,  8.7684e-03],\n",
      "           [ 6.9368e-03,  3.5317e-03, -7.5556e-03],\n",
      "           [ 3.2213e-02,  1.0848e-02,  1.3615e-04]],\n",
      "\n",
      "          [[-7.6346e-03, -4.2816e-03,  8.2452e-03],\n",
      "           [ 2.1241e-02, -5.6904e-04, -1.1954e-03],\n",
      "           [ 3.0969e-02,  2.0962e-02,  4.3207e-03]],\n",
      "\n",
      "          [[ 1.6740e-03, -3.9516e-03,  1.4690e-02],\n",
      "           [-4.0249e-03,  5.5598e-03,  1.6196e-02],\n",
      "           [-2.2003e-02,  2.1458e-02,  1.6198e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.2604e-03,  7.6361e-03,  5.6174e-03],\n",
      "           [-1.0319e-02, -1.0497e-02, -1.6213e-02],\n",
      "           [-8.2145e-03, -4.8085e-03, -3.0899e-02]],\n",
      "\n",
      "          [[ 8.4940e-03,  5.0595e-03,  1.2911e-02],\n",
      "           [ 3.6478e-03, -3.6706e-03, -8.4129e-03],\n",
      "           [ 1.7176e-02,  1.0928e-02, -1.6062e-02]],\n",
      "\n",
      "          [[ 4.8548e-03,  6.0697e-03,  1.8372e-02],\n",
      "           [ 1.8044e-02,  2.1226e-02,  6.1900e-03],\n",
      "           [ 3.6558e-02,  1.8571e-02, -2.2428e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.5832e-02, -1.6082e-02,  1.5605e-02],\n",
      "           [ 2.5823e-03, -3.4031e-03, -9.0064e-03],\n",
      "           [-3.6114e-03,  8.9513e-03, -7.7188e-03]],\n",
      "\n",
      "          [[-5.5047e-03,  4.4131e-03,  2.6290e-03],\n",
      "           [-6.1408e-03,  1.2987e-02, -1.0575e-03],\n",
      "           [-1.7053e-02, -3.2629e-03,  2.2703e-02]],\n",
      "\n",
      "          [[-5.2434e-03, -1.8987e-02,  1.3052e-02],\n",
      "           [-2.5697e-02, -4.6302e-03,  1.0231e-02],\n",
      "           [-6.7032e-03, -4.8951e-03,  1.4860e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.5867e-02, -1.4456e-02,  6.4476e-03],\n",
      "           [-1.1384e-02,  8.3979e-03,  1.8814e-02],\n",
      "           [-3.6242e-03,  1.0017e-02, -1.4210e-03]],\n",
      "\n",
      "          [[ 6.1092e-03,  9.8330e-03,  2.1267e-03],\n",
      "           [ 3.0793e-03,  6.9303e-03,  1.5734e-02],\n",
      "           [ 7.0245e-03,  1.9507e-04, -4.9673e-03]],\n",
      "\n",
      "          [[-1.7197e-02, -1.2526e-02,  1.1163e-03],\n",
      "           [-2.1924e-02, -5.0337e-03, -7.0817e-03],\n",
      "           [-2.2054e-02, -7.1161e-03, -8.4785e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.7656e-04,  5.9694e-04,  9.6614e-03],\n",
      "           [-1.0731e-02, -2.1691e-04,  1.9481e-02],\n",
      "           [-2.6322e-02, -1.4722e-02, -8.1566e-03]],\n",
      "\n",
      "          [[-9.6148e-03, -9.6241e-03,  7.6428e-03],\n",
      "           [-8.6575e-03, -4.6593e-03, -4.0771e-04],\n",
      "           [-2.4826e-02, -4.4131e-03,  1.0624e-02]],\n",
      "\n",
      "          [[-2.1976e-04, -1.1918e-02, -1.0020e-03],\n",
      "           [-1.1981e-02, -6.5426e-03,  5.9550e-03],\n",
      "           [-1.5120e-02, -1.7479e-02, -1.1061e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.3388e-02, -4.9345e-03,  1.2857e-02],\n",
      "           [ 7.0954e-03, -1.4853e-03,  7.2691e-03],\n",
      "           [-9.1976e-04,  1.3949e-02,  1.1624e-03]],\n",
      "\n",
      "          [[-3.2262e-04, -3.9540e-03, -1.2970e-02],\n",
      "           [ 2.0289e-02, -3.3242e-03,  3.5287e-03],\n",
      "           [ 1.4920e-02,  5.7904e-03,  1.2086e-03]],\n",
      "\n",
      "          [[-8.1401e-03,  1.0274e-03, -1.8351e-03],\n",
      "           [ 1.3901e-02,  2.0049e-03,  3.7000e-03],\n",
      "           [ 9.3873e-03,  6.8292e-04,  3.9750e-03]]],\n",
      "\n",
      "\n",
      "         [[[-7.1675e-03, -1.9339e-02,  8.5245e-03],\n",
      "           [ 8.2916e-03,  4.8915e-03,  1.7815e-02],\n",
      "           [ 4.4265e-04, -2.3155e-03, -3.9726e-03]],\n",
      "\n",
      "          [[ 3.8074e-03, -1.3334e-02, -3.5455e-03],\n",
      "           [ 1.3129e-02, -2.1394e-03, -3.5541e-03],\n",
      "           [-3.0104e-03,  1.5852e-03,  1.0335e-02]],\n",
      "\n",
      "          [[-1.3174e-02,  1.8544e-03,  1.1651e-02],\n",
      "           [ 9.3959e-03,  6.9201e-04,  1.2285e-02],\n",
      "           [-5.9376e-03,  1.6951e-03,  2.2008e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.7181e-03,  1.0163e-02,  6.5148e-03],\n",
      "           [ 1.0603e-02,  1.6792e-02,  6.1136e-03],\n",
      "           [-4.2140e-03,  6.1396e-03,  1.4649e-03]],\n",
      "\n",
      "          [[ 6.9898e-03,  9.1594e-03,  7.9333e-03],\n",
      "           [ 1.1862e-02,  2.0780e-02,  2.4035e-02],\n",
      "           [ 1.7953e-02,  1.7228e-02,  1.2103e-02]],\n",
      "\n",
      "          [[ 2.3934e-03,  7.3836e-03,  1.3538e-02],\n",
      "           [ 7.2674e-03,  1.7775e-02,  2.8659e-02],\n",
      "           [ 1.7290e-02,  2.0830e-02,  1.4979e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.6140e-03, -4.6258e-03,  1.4197e-02],\n",
      "           [ 4.9550e-03,  5.3303e-03,  9.9942e-03],\n",
      "           [-2.1517e-02, -1.2346e-02,  6.6187e-03]],\n",
      "\n",
      "          [[-1.6891e-02, -3.9024e-03,  1.7624e-02],\n",
      "           [ 2.1561e-03, -8.5117e-05,  2.1635e-03],\n",
      "           [-2.0106e-02, -1.2145e-03,  2.3219e-03]],\n",
      "\n",
      "          [[-1.8500e-02, -1.1430e-02,  4.7492e-03],\n",
      "           [-1.2318e-02, -9.0232e-03, -1.2255e-02],\n",
      "           [-3.4677e-02, -3.4516e-02, -3.9958e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.9789e-03, -2.3116e-03, -1.5939e-03],\n",
      "           [ 9.8594e-03,  1.6710e-02,  9.9748e-03],\n",
      "           [-2.1544e-02,  1.8025e-02,  5.3304e-04]],\n",
      "\n",
      "          [[ 1.3020e-03,  9.7202e-03,  8.2326e-03],\n",
      "           [ 2.6900e-03,  4.8504e-03,  2.8046e-03],\n",
      "           [-5.2584e-03,  2.1082e-03, -1.0551e-02]],\n",
      "\n",
      "          [[-1.2879e-02,  9.3068e-03,  7.3856e-03],\n",
      "           [-2.3580e-03, -4.7171e-03,  1.0448e-02],\n",
      "           [-1.3229e-02, -4.6177e-03, -2.0844e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.3568e-03,  1.3024e-03, -3.1931e-03],\n",
      "           [-1.7980e-02, -4.1875e-03,  4.9116e-04],\n",
      "           [-6.8342e-03,  1.3400e-02,  1.4071e-02]],\n",
      "\n",
      "          [[-4.9916e-03,  2.5090e-03, -4.8930e-03],\n",
      "           [-6.0797e-03,  6.2434e-03,  3.2695e-03],\n",
      "           [-1.8530e-03,  2.5283e-02,  2.2055e-02]],\n",
      "\n",
      "          [[-2.0514e-03,  5.4936e-03,  8.5164e-03],\n",
      "           [-4.0694e-03,  2.5452e-03,  2.7231e-03],\n",
      "           [-2.2676e-03,  2.9345e-03, -9.0903e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.1170e-02, -7.4625e-03,  7.5862e-03],\n",
      "           [-7.6987e-04,  1.1973e-02,  1.8592e-02],\n",
      "           [-1.9030e-02,  1.0516e-02,  9.6893e-03]],\n",
      "\n",
      "          [[ 1.8084e-02, -8.5937e-03,  5.6799e-03],\n",
      "           [-5.3301e-04, -8.0956e-03, -5.0968e-03],\n",
      "           [-9.8166e-03, -6.7751e-03, -8.1669e-04]],\n",
      "\n",
      "          [[ 2.2310e-02,  1.5259e-02, -1.4902e-02],\n",
      "           [ 1.2592e-02, -9.4322e-03, -1.7582e-03],\n",
      "           [ 1.0015e-02, -3.5323e-03,  6.1044e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0217e-02,  9.3671e-03,  8.0326e-03],\n",
      "           [-8.9981e-03,  1.7318e-02,  2.5824e-03],\n",
      "           [ 8.4793e-03,  8.0218e-03,  2.5672e-02]],\n",
      "\n",
      "          [[ 1.7572e-02,  2.8940e-02,  8.2983e-03],\n",
      "           [ 1.0416e-02,  1.9104e-02, -7.2639e-04],\n",
      "           [ 1.7606e-02,  1.4388e-02, -3.3461e-03]],\n",
      "\n",
      "          [[ 3.9447e-03,  9.5601e-03,  1.4912e-02],\n",
      "           [ 2.7604e-02,  1.9775e-02, -3.1885e-03],\n",
      "           [-1.2925e-02,  1.5436e-02,  9.1174e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.4856e-02,  1.3296e-02, -4.4687e-03],\n",
      "           [-8.5371e-03,  7.1889e-03, -7.7454e-03],\n",
      "           [-5.6236e-03, -3.0705e-03, -1.6297e-02]],\n",
      "\n",
      "          [[-1.2308e-02, -1.4353e-02, -1.5955e-02],\n",
      "           [ 9.6736e-03, -7.1344e-03,  1.1882e-04],\n",
      "           [ 3.6504e-03,  1.0653e-02,  7.5899e-03]],\n",
      "\n",
      "          [[-6.8672e-03,  2.9543e-03, -4.0440e-03],\n",
      "           [ 1.3887e-03, -1.0686e-02,  7.2433e-03],\n",
      "           [ 1.5710e-02, -6.0797e-03,  1.5796e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.7974e-02,  9.6303e-03, -1.5904e-02],\n",
      "           [ 7.0203e-03, -1.1289e-02, -2.2429e-02],\n",
      "           [ 2.6382e-03, -7.9795e-03, -1.2020e-02]],\n",
      "\n",
      "          [[ 8.7514e-03, -5.2437e-03, -9.0089e-03],\n",
      "           [ 2.1406e-02,  1.6302e-02, -2.3768e-03],\n",
      "           [ 3.7721e-02,  1.4472e-02,  2.4358e-03]],\n",
      "\n",
      "          [[-5.2605e-03, -9.7742e-04,  1.6605e-02],\n",
      "           [ 2.5268e-02,  2.7540e-02,  1.5116e-02],\n",
      "           [ 3.2930e-02,  2.2152e-02,  2.5842e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4176e-02, -4.0777e-03, -1.1880e-02],\n",
      "           [ 2.4511e-03,  3.8343e-03, -1.0305e-02],\n",
      "           [ 2.4110e-02, -1.3583e-04,  3.5784e-04]],\n",
      "\n",
      "          [[ 7.9472e-04,  6.0784e-03, -8.0355e-03],\n",
      "           [ 2.1176e-02,  3.6138e-03,  1.0919e-02],\n",
      "           [ 3.1549e-02,  6.0431e-03,  1.6474e-02]],\n",
      "\n",
      "          [[-6.1692e-03,  1.3333e-02, -3.9272e-03],\n",
      "           [ 1.1897e-02,  2.4577e-02,  2.0301e-02],\n",
      "           [ 3.7382e-02,  4.0534e-02,  5.1187e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.4316e-04, -1.8106e-03, -1.0241e-02],\n",
      "           [ 2.4594e-02,  1.9783e-02,  1.3270e-02],\n",
      "           [ 2.7080e-02,  2.9257e-03, -6.2663e-03]],\n",
      "\n",
      "          [[ 1.3017e-02,  8.7776e-03, -1.1364e-03],\n",
      "           [-4.8288e-03,  1.9623e-03,  5.2185e-03],\n",
      "           [ 8.4900e-03,  6.3258e-04, -1.3217e-02]],\n",
      "\n",
      "          [[ 1.0696e-02, -1.4356e-02, -1.6993e-02],\n",
      "           [ 2.8161e-02, -1.3642e-02, -1.8526e-02],\n",
      "           [ 3.5293e-02, -1.3806e-02, -1.4726e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.2217e-02,  1.3649e-02, -7.0066e-03],\n",
      "           [ 2.5412e-02, -1.3014e-02,  1.3198e-02],\n",
      "           [ 5.4447e-03,  2.1930e-02, -1.1458e-02]],\n",
      "\n",
      "          [[ 9.1117e-03, -1.2339e-02,  1.5104e-02],\n",
      "           [ 9.9966e-03, -3.5190e-03,  1.5232e-02],\n",
      "           [ 1.2863e-02, -7.0718e-03, -1.9507e-02]],\n",
      "\n",
      "          [[ 2.3922e-03, -1.4790e-02,  3.3923e-03],\n",
      "           [ 1.3724e-03, -8.0216e-03,  3.4914e-03],\n",
      "           [ 1.5705e-02,  2.3900e-02,  2.2238e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.6080e-02, -7.8880e-03, -4.0366e-03],\n",
      "           [ 3.2557e-02, -1.3066e-02,  2.8054e-03],\n",
      "           [ 2.4374e-02,  1.6062e-02,  9.9968e-03]],\n",
      "\n",
      "          [[-7.2618e-04,  5.3946e-03,  5.4597e-04],\n",
      "           [-9.5017e-03, -7.4560e-04, -8.3275e-03],\n",
      "           [ 9.2780e-03, -5.7640e-03, -1.3109e-02]],\n",
      "\n",
      "          [[-1.2167e-02, -7.3559e-03,  6.4409e-03],\n",
      "           [-7.7893e-04, -8.5830e-03, -6.5178e-03],\n",
      "           [ 4.7446e-03,  1.6988e-02,  9.6303e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 6.4304e-04,  1.3910e-02,  1.5498e-03],\n",
      "           [ 6.7470e-03,  1.8490e-02,  1.5083e-02],\n",
      "           [-2.2353e-03,  1.1632e-02,  1.9982e-02]],\n",
      "\n",
      "          [[ 3.6852e-03,  2.1433e-02, -3.0812e-03],\n",
      "           [-1.1573e-02, -1.4225e-03, -5.3682e-04],\n",
      "           [-2.1506e-02, -1.3269e-02, -1.9394e-02]],\n",
      "\n",
      "          [[-3.5275e-03, -5.3049e-03,  1.0448e-02],\n",
      "           [-1.2359e-02, -2.4937e-02, -1.2254e-02],\n",
      "           [-2.9441e-02, -2.2808e-02, -1.3514e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.6429e-02, -9.6052e-03,  4.3533e-03],\n",
      "           [ 1.0387e-02, -4.5576e-03, -1.4348e-02],\n",
      "           [ 2.2479e-02,  6.7754e-03, -2.1946e-02]],\n",
      "\n",
      "          [[ 9.7622e-03,  4.7244e-04, -2.1643e-03],\n",
      "           [ 2.1991e-02,  6.6189e-03,  6.1905e-03],\n",
      "           [ 1.8613e-02, -4.0173e-03, -5.8278e-03]],\n",
      "\n",
      "          [[ 1.0692e-02,  1.0566e-03,  1.4138e-02],\n",
      "           [ 1.6681e-02,  1.3402e-03,  1.9314e-02],\n",
      "           [ 2.3636e-02,  8.5836e-03,  1.0110e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.1297e-03, -8.0678e-03, -9.6666e-03],\n",
      "           [-3.3471e-03,  1.1512e-03, -5.4437e-03],\n",
      "           [ 5.0180e-03,  1.3975e-02,  6.7226e-03]],\n",
      "\n",
      "          [[-2.8701e-03,  1.2468e-02,  3.1715e-04],\n",
      "           [ 6.3445e-03, -8.1722e-03,  5.5959e-03],\n",
      "           [ 1.0327e-02,  4.7061e-04, -1.0705e-02]],\n",
      "\n",
      "          [[-1.1095e-03, -9.4569e-03, -7.7017e-03],\n",
      "           [ 1.6729e-02,  4.6781e-03, -7.3523e-03],\n",
      "           [ 1.7385e-03,  1.9822e-03, -2.2975e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.8797e-03, -1.2788e-02, -1.7827e-02],\n",
      "           [-6.8099e-03,  1.3600e-03,  1.2618e-02],\n",
      "           [-1.6313e-02, -4.3033e-03,  4.2170e-03]],\n",
      "\n",
      "          [[ 3.8882e-03,  3.2802e-03, -1.9752e-02],\n",
      "           [ 9.1514e-03, -6.4487e-03, -5.2001e-03],\n",
      "           [-7.9977e-03, -2.1026e-02, -3.0222e-02]],\n",
      "\n",
      "          [[ 1.1596e-02,  3.8207e-03,  4.4382e-03],\n",
      "           [ 1.1641e-02,  5.1084e-03, -1.5438e-02],\n",
      "           [ 1.6656e-02, -1.6488e-02, -3.0476e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.9818e-03,  1.2773e-02, -6.3147e-03],\n",
      "           [ 5.9958e-03,  4.8130e-03, -6.9768e-03],\n",
      "           [-6.2599e-03,  7.9264e-03, -1.5292e-03]],\n",
      "\n",
      "          [[ 1.5597e-02,  9.9943e-04, -3.5387e-03],\n",
      "           [ 1.0917e-02, -6.9558e-03, -8.2765e-03],\n",
      "           [ 6.1536e-03,  6.4301e-03,  1.8361e-03]],\n",
      "\n",
      "          [[-1.7119e-02,  3.4953e-03, -7.0977e-03],\n",
      "           [-5.1245e-03,  4.9801e-03,  1.6769e-02],\n",
      "           [ 1.0478e-02, -3.0660e-03, -6.5026e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 8.0988e-03,  1.0202e-02, -1.0691e-02],\n",
      "           [ 6.8157e-03,  1.4066e-02, -1.2580e-02],\n",
      "           [-1.0686e-03, -6.8513e-03,  1.3448e-02]],\n",
      "\n",
      "          [[ 1.8661e-02, -1.5898e-03,  9.7399e-03],\n",
      "           [ 6.5920e-03,  5.9656e-03,  1.2604e-02],\n",
      "           [-5.2688e-04, -1.4030e-02,  7.2780e-03]],\n",
      "\n",
      "          [[ 1.7652e-02,  1.8275e-02,  2.9636e-03],\n",
      "           [-2.1059e-03,  2.9847e-04, -1.5359e-03],\n",
      "           [-3.4070e-03,  6.0834e-03,  3.4574e-03]]],\n",
      "\n",
      "\n",
      "         [[[-7.4138e-03, -6.5533e-03,  2.8390e-03],\n",
      "           [-1.8459e-03, -1.1172e-02, -1.6589e-03],\n",
      "           [ 9.6884e-03,  4.9539e-03,  1.2174e-02]],\n",
      "\n",
      "          [[ 2.4333e-03, -9.8032e-03,  1.6414e-03],\n",
      "           [-6.9375e-05,  8.7310e-03,  1.2324e-03],\n",
      "           [-1.7437e-02, -1.1103e-02,  1.2195e-02]],\n",
      "\n",
      "          [[ 7.3684e-03,  4.2803e-04,  7.9012e-03],\n",
      "           [-1.7610e-02, -1.7857e-02, -7.5571e-03],\n",
      "           [-3.3912e-02,  2.0673e-03,  1.2438e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.2210e-03,  1.1307e-03, -6.7096e-03],\n",
      "           [-2.3466e-02, -3.7061e-04, -1.7149e-02],\n",
      "           [-3.5034e-03, -8.4009e-03,  8.9133e-03]],\n",
      "\n",
      "          [[-1.3032e-02, -9.3899e-03, -1.1817e-02],\n",
      "           [-4.7114e-03, -1.6799e-02, -1.8915e-02],\n",
      "           [-2.2921e-03, -1.4136e-02, -2.2226e-02]],\n",
      "\n",
      "          [[ 1.5288e-02,  7.5965e-03, -9.0049e-03],\n",
      "           [-1.3703e-02,  1.9964e-03, -2.1849e-02],\n",
      "           [-1.3821e-02, -1.9819e-02, -1.7334e-02]]],\n",
      "\n",
      "\n",
      "         [[[-9.4328e-03,  3.4778e-04, -3.9462e-03],\n",
      "           [-5.1251e-03, -3.7520e-03,  5.9335e-03],\n",
      "           [-2.7149e-02, -3.5237e-03,  1.3492e-02]],\n",
      "\n",
      "          [[-3.8329e-03,  1.0004e-02, -7.5475e-04],\n",
      "           [-6.9368e-03, -1.2139e-02, -1.1943e-02],\n",
      "           [ 9.4845e-04, -1.7539e-03, -8.8453e-03]],\n",
      "\n",
      "          [[ 1.8899e-02,  9.3189e-03,  1.0127e-02],\n",
      "           [ 1.2998e-02,  5.8077e-03,  5.1302e-03],\n",
      "           [ 5.3418e-03, -3.6088e-03, -5.0100e-03]]],\n",
      "\n",
      "\n",
      "         [[[-8.7436e-03, -2.7564e-03, -8.6471e-04],\n",
      "           [-1.3759e-02, -2.1276e-02, -2.0046e-03],\n",
      "           [-2.5846e-02, -3.4412e-02, -1.5401e-02]],\n",
      "\n",
      "          [[-1.2186e-02, -1.7671e-02,  4.3501e-03],\n",
      "           [-1.2780e-02, -1.2873e-02,  3.6020e-04],\n",
      "           [ 3.9412e-03, -6.1639e-03,  1.8202e-02]],\n",
      "\n",
      "          [[-1.2169e-03,  8.2152e-03,  2.0759e-02],\n",
      "           [-2.9248e-03, -4.1334e-03,  1.2392e-02],\n",
      "           [-1.8749e-02,  7.4557e-03,  1.8340e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.6867e-03,  3.1316e-03, -4.1861e-03],\n",
      "           [-1.2249e-02, -1.0436e-03,  4.7683e-03],\n",
      "           [-8.7840e-03, -1.4914e-02,  1.5123e-02]],\n",
      "\n",
      "          [[-1.1935e-02, -9.2542e-03, -1.5105e-02],\n",
      "           [-8.1318e-03, -2.8252e-03, -2.2854e-02],\n",
      "           [-1.1554e-02, -7.3904e-03, -7.8970e-03]],\n",
      "\n",
      "          [[-1.2735e-02,  7.2583e-03, -7.7969e-03],\n",
      "           [-1.5969e-02,  4.4530e-04, -2.5689e-02],\n",
      "           [ 6.0580e-03,  5.2066e-03, -7.3458e-04]]],\n",
      "\n",
      "\n",
      "         [[[-3.0258e-02,  1.1592e-03, -1.0647e-02],\n",
      "           [-2.4919e-02, -7.3979e-03, -2.2417e-03],\n",
      "           [-3.9566e-02, -1.5396e-02, -1.7268e-02]],\n",
      "\n",
      "          [[-4.0274e-03, -1.2504e-02, -1.5699e-02],\n",
      "           [-1.4637e-02, -1.0576e-02, -7.1640e-03],\n",
      "           [-1.6756e-02,  4.1651e-04, -6.4265e-03]],\n",
      "\n",
      "          [[-1.2191e-02, -6.3056e-03, -6.4761e-03],\n",
      "           [ 4.2978e-03, -9.9045e-03, -1.1546e-02],\n",
      "           [-1.4648e-02,  5.5490e-04, -6.7467e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.9562e-03, -5.8214e-03, -2.0630e-02],\n",
      "           [-4.4566e-03, -9.7270e-03, -1.4749e-02],\n",
      "           [-6.6610e-03, -1.8348e-02, -1.9800e-02]],\n",
      "\n",
      "          [[-7.1043e-03, -6.5680e-03, -3.1131e-03],\n",
      "           [ 2.1713e-03,  9.8847e-03,  1.1726e-03],\n",
      "           [ 2.6066e-03, -6.8271e-03,  4.3708e-03]],\n",
      "\n",
      "          [[-2.3047e-03,  3.1773e-03,  2.0788e-03],\n",
      "           [-1.3559e-03,  4.0052e-03, -8.9349e-03],\n",
      "           [ 1.6050e-02,  6.6581e-03, -1.0774e-02]]]]], device='cuda:0')), ('module.down_layers.3.4.norm1.weight', tensor([0.8859, 0.8692, 0.9072, 0.9304, 0.8754, 0.9971, 0.9215, 0.9956, 0.9379,\n",
      "        0.8267, 0.9573, 0.9498, 0.9372, 0.9553, 0.9756, 0.8729, 0.9697, 0.8936,\n",
      "        0.9794, 0.8610, 0.9648, 0.9526, 0.9694, 0.9471, 0.8745, 0.9669, 0.9790,\n",
      "        0.9591, 0.9235, 0.9759, 0.9834, 0.8804, 1.0311, 0.9689, 0.8685, 0.9156,\n",
      "        0.8982, 0.9136, 1.0334, 0.9115, 0.9548, 0.9168, 0.9571, 0.9370, 0.9332,\n",
      "        0.9040, 0.9568, 0.9101, 0.8598, 0.9719, 0.9404, 0.9883, 0.9147, 0.9238,\n",
      "        0.8901, 0.8615, 0.9221, 0.8500, 0.9409, 0.8975, 0.8079, 0.9446, 0.9556,\n",
      "        0.9601, 0.9250, 0.9731, 0.8316, 0.9563, 0.8837, 0.8504, 0.9200, 0.9312,\n",
      "        0.8869, 0.9119, 0.9459, 0.9472, 0.9807, 0.9166, 0.8914, 0.8409, 0.9222,\n",
      "        0.9313, 0.9002, 0.9267, 0.9159, 0.8879, 0.9936, 0.9718, 0.9149, 0.8917,\n",
      "        0.8971, 0.8839, 0.8963, 0.8756, 0.9596, 0.9411, 0.9183, 0.7906, 0.9648,\n",
      "        0.9488, 0.8659, 0.8044, 0.9546, 0.9314, 0.8876, 0.9442, 0.8743, 0.9337,\n",
      "        0.9038, 0.9429, 0.9071, 0.9458, 0.9201, 0.8921, 0.8871, 0.8300, 0.9466,\n",
      "        0.9574, 0.9486, 0.9770, 0.9409, 0.9567, 0.9484, 0.8804, 0.9490, 0.9008,\n",
      "        0.8565, 0.8311], device='cuda:0')), ('module.down_layers.3.4.norm1.bias', tensor([-0.0371, -0.0259, -0.0061, -0.0132, -0.0558, -0.0325, -0.0244, -0.0296,\n",
      "        -0.0179, -0.0125, -0.0114, -0.0178, -0.0254, -0.0340, -0.0155, -0.0173,\n",
      "        -0.0302, -0.0360, -0.0252, -0.0314, -0.0385, -0.0364, -0.0514, -0.0266,\n",
      "        -0.0221, -0.0334, -0.0416, -0.0380, -0.0359, -0.0281, -0.0344, -0.0220,\n",
      "        -0.0178, -0.0117, -0.0240, -0.0332, -0.0286, -0.0369, -0.0179, -0.0137,\n",
      "        -0.0299, -0.0192, -0.0036, -0.0097, -0.0092, -0.0181, -0.0204, -0.0093,\n",
      "        -0.0340, -0.0223, -0.0183, -0.0115, -0.0076, -0.0252, -0.0230, -0.0103,\n",
      "        -0.0231, -0.0325, -0.0190, -0.0140, -0.0077, -0.0271, -0.0325, -0.0220,\n",
      "        -0.0494, -0.0273, -0.0601, -0.0325, -0.0240, -0.0291, -0.0365,  0.0020,\n",
      "        -0.0637, -0.0454, -0.0070, -0.0223, -0.0439, -0.0530, -0.0398, -0.0204,\n",
      "        -0.0360, -0.0305, -0.0545, -0.0045, -0.0209, -0.0313, -0.0182, -0.0039,\n",
      "        -0.0631, -0.0185, -0.0193, -0.0164, -0.0520, -0.0742, -0.0225, -0.0274,\n",
      "        -0.0084, -0.0167, -0.0060, -0.0049, -0.0095,  0.0082, -0.0185, -0.0090,\n",
      "        -0.0080,  0.0083, -0.0130, -0.0128, -0.0135, -0.0071, -0.0325, -0.0160,\n",
      "        -0.0119, -0.0087, -0.0496, -0.0512, -0.0265, -0.0133, -0.0457, -0.0359,\n",
      "        -0.0177, -0.0132, -0.0129, -0.0211, -0.0446, -0.0490, -0.0393, -0.0249],\n",
      "       device='cuda:0')), ('module.down_layers.3.4.norm2.weight', tensor([0.8108, 0.8536, 0.9307, 0.9658, 0.9330, 0.9366, 0.8629, 0.9440, 0.9593,\n",
      "        0.9361, 0.9595, 0.7773, 0.8845, 0.8064, 0.8392, 0.9228, 0.9401, 0.9109,\n",
      "        0.8513, 0.8336, 0.8075, 0.6053, 0.7876, 0.8736, 0.9218, 0.8916, 0.7088,\n",
      "        0.8787, 0.7896, 0.9442, 0.8592, 0.8318, 0.8404, 0.8542, 0.6834, 0.9581,\n",
      "        0.8623, 0.7226, 0.9507, 0.7319, 0.8598, 0.6736, 0.6686, 0.6786, 0.6751,\n",
      "        0.6970, 0.9645, 0.7002, 0.9316, 0.6571, 0.8919, 0.9240, 0.9462, 0.8631,\n",
      "        0.9081, 0.9525, 0.9648, 0.6859, 0.8437, 0.9637, 0.7156, 0.7159, 0.9178,\n",
      "        0.7228, 0.7602, 0.8011, 0.8105, 0.6482, 0.9103, 0.9079, 0.8981, 0.9484,\n",
      "        0.6987, 0.6900, 0.9060, 0.7620, 0.9425, 0.7571, 0.7535, 0.7980, 0.9520,\n",
      "        0.7640, 0.9478, 0.9575, 0.8265, 0.8149, 0.9344, 0.8015, 0.8104, 0.9268,\n",
      "        0.7944, 0.9378, 0.9261, 0.8121, 0.9477, 0.8597, 0.9676, 0.9416, 0.9456,\n",
      "        0.9273, 0.9594, 0.9544, 0.9022, 0.9472, 0.8566, 0.9544, 0.9666, 0.9483,\n",
      "        0.8521, 0.9555, 0.8866, 0.9632, 0.8537, 0.9395, 0.9347, 0.8692, 0.9087,\n",
      "        0.8340, 0.9306, 0.8356, 0.9487, 0.8638, 0.9398, 0.9429, 0.9382, 0.8494,\n",
      "        0.9268, 0.9462], device='cuda:0')), ('module.down_layers.3.4.norm2.bias', tensor([-4.6495e-02, -4.8075e-02, -4.1115e-02, -4.1450e-02, -4.6116e-02,\n",
      "        -4.3043e-02, -4.6248e-02, -4.8008e-02, -4.2164e-02, -4.0559e-02,\n",
      "        -3.7618e-02, -9.6696e-03, -2.7916e-02, -4.5534e-02, -6.3823e-02,\n",
      "        -3.7959e-02, -6.7501e-03, -1.9244e-02, -2.0052e-02, -2.0179e-02,\n",
      "        -2.3730e-02, -2.7354e-02, -1.8415e-02, -1.4971e-02, -1.4236e-02,\n",
      "        -1.7341e-02, -1.8671e-02, -1.6732e-02, -2.5880e-02, -1.8962e-02,\n",
      "        -2.9041e-02, -2.1832e-02, -1.1477e-02, -1.8237e-02, -1.7930e-02,\n",
      "        -1.7059e-02, -1.4685e-02, -1.5042e-02, -1.3971e-02, -1.6286e-02,\n",
      "        -2.2919e-02, -1.9623e-02, -1.6635e-02, -2.3364e-02, -1.1976e-02,\n",
      "        -6.7255e-03, -1.5805e-03, -1.0467e-02,  1.2732e-02,  5.2988e-03,\n",
      "         3.5718e-03,  6.2828e-03,  3.0098e-03,  5.1700e-04,  1.8491e-03,\n",
      "         2.0234e-03,  5.0867e-03,  1.1615e-02, -6.0136e-05,  7.7107e-03,\n",
      "         9.7423e-03,  1.1194e-02,  5.7383e-03,  1.3231e-02, -2.5573e-02,\n",
      "        -1.3326e-02, -1.9267e-02, -2.9298e-02, -9.1032e-03, -9.4266e-03,\n",
      "        -1.8889e-02, -1.2631e-02, -2.0382e-02, -1.9090e-02, -8.3809e-03,\n",
      "        -2.3258e-02, -1.4176e-02, -2.1952e-02, -1.7440e-02, -2.1074e-02,\n",
      "        -5.4199e-02, -4.2085e-02, -4.7454e-02, -4.4930e-02, -5.0371e-02,\n",
      "        -2.1856e-02, -6.0164e-02, -3.4516e-02, -4.7728e-02, -5.2459e-02,\n",
      "        -5.2678e-02, -6.0041e-02, -5.0031e-02, -4.5780e-02, -4.5441e-02,\n",
      "        -6.6574e-02, -6.1995e-02, -6.4825e-02, -7.1479e-02, -6.6670e-02,\n",
      "        -6.0869e-02, -6.9731e-02, -6.8181e-02, -6.0873e-02, -1.6757e-02,\n",
      "        -6.6745e-02, -5.9603e-02, -6.8173e-02, -1.8166e-02, -6.8055e-02,\n",
      "        -6.7513e-02, -6.3594e-02, -2.3358e-02, -6.0256e-02, -5.9339e-02,\n",
      "        -1.9510e-02, -5.6515e-02, -3.8464e-02, -5.6054e-02, -2.7627e-02,\n",
      "        -5.1918e-02, -4.5399e-02, -5.4692e-02, -5.2715e-02, -5.4030e-02,\n",
      "        -2.9219e-02, -6.2709e-02, -5.2709e-02], device='cuda:0')), ('module.down_layers.3.4.conv1.conv.weight', tensor([[[[[-3.8364e-03, -2.3711e-03, -2.4605e-03],\n",
      "           [ 1.3234e-02,  6.4616e-03, -1.1275e-02],\n",
      "           [ 1.1831e-02,  4.3425e-04, -1.1827e-02]],\n",
      "\n",
      "          [[-2.1640e-02, -1.3016e-02, -4.3331e-03],\n",
      "           [-1.2819e-03, -5.0161e-03, -1.5771e-03],\n",
      "           [ 2.6501e-02,  1.7781e-02, -1.8500e-03]],\n",
      "\n",
      "          [[-1.0562e-02,  5.3968e-03,  3.4887e-03],\n",
      "           [-2.6864e-03,  1.2081e-02,  5.9890e-03],\n",
      "           [ 2.7405e-02,  1.6308e-02,  5.8076e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 5.6118e-03, -6.0031e-03, -1.8901e-02],\n",
      "           [ 6.0430e-03, -2.0232e-03, -1.6026e-02],\n",
      "           [ 5.9133e-03, -1.3433e-02, -1.8975e-02]],\n",
      "\n",
      "          [[ 1.6483e-03,  5.0124e-03, -5.1552e-03],\n",
      "           [ 1.0043e-02,  1.0625e-03, -4.3888e-03],\n",
      "           [ 8.3816e-03, -6.4801e-03, -7.9090e-03]],\n",
      "\n",
      "          [[ 1.2553e-02,  1.5989e-02,  1.1118e-02],\n",
      "           [ 2.5759e-02,  1.9821e-02,  1.3927e-02],\n",
      "           [ 2.6925e-02,  1.3060e-02,  2.8118e-04]]],\n",
      "\n",
      "\n",
      "         [[[-1.3458e-02, -4.1961e-03,  1.0116e-02],\n",
      "           [-1.3724e-02, -1.0721e-02,  4.7116e-03],\n",
      "           [-2.7909e-02, -1.9923e-02, -6.5070e-03]],\n",
      "\n",
      "          [[ 2.2102e-03,  4.1572e-03, -6.4300e-03],\n",
      "           [-3.6042e-03,  7.3535e-04,  3.3449e-03],\n",
      "           [-2.3657e-02, -9.5451e-03, -8.6054e-03]],\n",
      "\n",
      "          [[ 1.7743e-03,  1.4344e-02,  6.8578e-03],\n",
      "           [ 2.0097e-02,  1.9590e-02,  6.9560e-03],\n",
      "           [ 3.3178e-03,  2.3351e-03,  1.2174e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.3855e-03,  2.0905e-02, -8.3414e-05],\n",
      "           [ 7.0543e-04,  4.0058e-03, -2.4185e-03],\n",
      "           [ 9.1141e-03, -3.2519e-03, -4.3527e-03]],\n",
      "\n",
      "          [[ 1.3377e-02, -5.7935e-03,  8.9421e-03],\n",
      "           [ 1.8099e-02,  1.4320e-02, -1.6416e-04],\n",
      "           [ 1.4314e-02, -4.0449e-03,  1.4752e-02]],\n",
      "\n",
      "          [[ 2.0475e-02,  1.8735e-03,  7.0947e-03],\n",
      "           [-4.3172e-03,  1.6510e-02, -4.4025e-03],\n",
      "           [ 5.9401e-03, -7.0973e-03, -4.3936e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2164e-02,  3.5123e-03, -2.9880e-03],\n",
      "           [ 1.0167e-02,  8.8449e-03,  6.8852e-03],\n",
      "           [ 1.3439e-02,  1.8301e-02,  1.0481e-02]],\n",
      "\n",
      "          [[ 5.7164e-03,  1.2043e-02,  5.9210e-03],\n",
      "           [ 8.2684e-03,  2.1716e-02, -8.1405e-04],\n",
      "           [ 1.7100e-02,  2.4446e-02,  5.9140e-03]],\n",
      "\n",
      "          [[ 1.8565e-02,  2.8706e-03, -7.5278e-03],\n",
      "           [ 1.6179e-03,  6.7161e-03,  8.5706e-03],\n",
      "           [ 1.7163e-02,  1.8497e-02,  1.3047e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.7122e-03, -3.6215e-03,  1.2971e-02],\n",
      "           [-1.3460e-03,  9.0324e-03,  1.2873e-02],\n",
      "           [ 9.9348e-03,  8.5480e-03,  1.5126e-02]],\n",
      "\n",
      "          [[-1.1738e-02, -4.7662e-03,  1.0428e-03],\n",
      "           [ 1.0830e-03,  3.5813e-03,  1.4300e-02],\n",
      "           [ 5.4036e-03,  9.2323e-03,  7.6144e-03]],\n",
      "\n",
      "          [[-6.8288e-03, -9.8284e-03, -7.7402e-03],\n",
      "           [-1.9605e-03, -6.1481e-03, -3.6483e-03],\n",
      "           [-2.0656e-03,  2.9847e-03,  4.5760e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.9506e-02,  2.2342e-03, -3.1731e-03],\n",
      "           [-1.8537e-02, -6.6461e-03, -9.5029e-03],\n",
      "           [-4.1655e-03, -9.9732e-03,  7.0154e-03]],\n",
      "\n",
      "          [[ 2.6417e-04, -1.2413e-02,  3.2636e-03],\n",
      "           [-1.6601e-02, -1.3338e-02,  1.1872e-02],\n",
      "           [-1.6608e-02,  1.0153e-02, -2.3909e-03]],\n",
      "\n",
      "          [[-3.0987e-02, -3.4919e-03, -2.3245e-02],\n",
      "           [-2.5456e-02, -1.5101e-02, -9.8678e-03],\n",
      "           [-1.0583e-02,  7.3393e-03, -4.3810e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.5588e-02, -7.7157e-04,  1.6323e-02],\n",
      "           [-1.0413e-02, -6.9089e-03,  3.7914e-03],\n",
      "           [-1.8722e-03, -1.2024e-02, -8.6425e-03]],\n",
      "\n",
      "          [[-1.9002e-02, -1.4805e-02,  1.0907e-02],\n",
      "           [-2.5128e-04, -5.4623e-03,  4.6989e-03],\n",
      "           [ 3.5556e-03, -1.3980e-03, -6.6423e-03]],\n",
      "\n",
      "          [[-1.0916e-02, -7.0640e-03,  6.7850e-03],\n",
      "           [-1.2519e-02,  4.4239e-03,  9.9160e-03],\n",
      "           [-2.2830e-03,  1.2684e-02,  1.2865e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.5841e-03, -1.8074e-02, -1.1124e-02],\n",
      "           [ 2.2825e-02,  8.5671e-03, -3.1294e-03],\n",
      "           [ 2.7646e-02,  1.7482e-02,  4.1234e-03]],\n",
      "\n",
      "          [[ 7.3099e-03, -7.2516e-03,  8.0681e-04],\n",
      "           [ 1.3774e-02, -2.7275e-03, -1.1264e-02],\n",
      "           [ 9.7511e-03,  7.1245e-03, -2.2851e-04]],\n",
      "\n",
      "          [[ 7.7676e-03, -1.1301e-02,  8.5637e-03],\n",
      "           [ 1.9156e-03, -1.9904e-02,  5.9179e-04],\n",
      "           [-1.8595e-02, -1.3106e-02,  1.0617e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.9188e-03,  1.6269e-02,  7.6272e-03],\n",
      "           [-1.3721e-02,  8.0706e-03,  1.3629e-02],\n",
      "           [-1.2748e-02, -1.2104e-02,  2.2372e-03]],\n",
      "\n",
      "          [[ 4.8877e-03,  6.7571e-03,  1.1726e-02],\n",
      "           [-2.4502e-03, -8.0181e-04,  1.8470e-02],\n",
      "           [ 2.3778e-04,  8.7966e-03, -6.5730e-04]],\n",
      "\n",
      "          [[-1.0891e-03,  5.1245e-03, -9.2422e-03],\n",
      "           [ 9.0460e-03,  5.3641e-03, -3.0316e-03],\n",
      "           [ 1.3336e-02,  4.6413e-03,  2.3266e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.0065e-03, -5.8463e-03,  4.0431e-03],\n",
      "           [-1.8724e-02, -1.7259e-02,  6.8566e-03],\n",
      "           [ 1.1353e-02, -5.0232e-03, -3.8202e-03]],\n",
      "\n",
      "          [[-1.9148e-02,  8.9558e-03,  9.8755e-03],\n",
      "           [-4.8692e-03,  1.5193e-02,  2.1465e-02],\n",
      "           [ 1.2767e-02,  1.0225e-02, -5.5880e-04]],\n",
      "\n",
      "          [[-9.0801e-03,  1.4150e-03,  1.9759e-02],\n",
      "           [-3.3582e-03,  2.3591e-02,  1.2807e-02],\n",
      "           [ 1.5782e-02, -3.7652e-03,  9.5641e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.2798e-03, -8.0507e-03, -3.7225e-03],\n",
      "           [ 1.4568e-03,  2.5366e-03, -8.6091e-03],\n",
      "           [-9.3969e-03, -7.2339e-03, -8.3964e-03]],\n",
      "\n",
      "          [[ 1.3200e-03,  3.1316e-03,  5.2537e-03],\n",
      "           [ 8.7691e-03,  9.9104e-03,  1.4512e-02],\n",
      "           [-8.3204e-03, -7.2375e-03,  4.4387e-03]],\n",
      "\n",
      "          [[ 1.2209e-02,  4.6034e-03,  8.3292e-03],\n",
      "           [ 3.3769e-03,  1.2301e-02,  2.2006e-02],\n",
      "           [-3.4176e-03, -1.1948e-03,  8.8010e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.5347e-02,  1.3283e-03,  1.4105e-03],\n",
      "           [-5.4534e-03, -1.4497e-02, -1.3054e-02],\n",
      "           [-3.7195e-03, -1.8265e-02,  4.4949e-03]],\n",
      "\n",
      "          [[ 4.7221e-03,  1.8368e-02,  1.3984e-02],\n",
      "           [-1.1830e-03,  1.9464e-03,  8.5486e-03],\n",
      "           [-1.8357e-03,  1.5563e-02,  4.2490e-03]],\n",
      "\n",
      "          [[-1.2909e-02,  2.4003e-03,  1.3774e-03],\n",
      "           [-2.8241e-03,  2.1957e-02,  8.1022e-03],\n",
      "           [-1.3571e-03,  1.7813e-03,  1.3158e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.6222e-04,  1.4968e-02, -1.1705e-03],\n",
      "           [ 1.6169e-02,  3.1474e-03,  2.3710e-03],\n",
      "           [ 2.9389e-03,  7.5820e-03, -1.2634e-02]],\n",
      "\n",
      "          [[ 6.3890e-04, -1.6027e-03, -2.3038e-03],\n",
      "           [ 1.8151e-03,  1.3207e-02,  1.4420e-02],\n",
      "           [ 1.2441e-02,  8.9007e-03, -4.2033e-03]],\n",
      "\n",
      "          [[ 4.1041e-03, -1.3756e-02, -1.5756e-02],\n",
      "           [-7.0706e-03, -2.3035e-02, -1.4296e-02],\n",
      "           [-1.2620e-02, -3.4390e-02, -2.0621e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.6230e-02, -1.7883e-02, -1.6524e-03],\n",
      "           [-1.2574e-02, -1.2750e-02, -1.3861e-02],\n",
      "           [-1.5964e-02, -1.1963e-02, -9.7096e-03]],\n",
      "\n",
      "          [[-2.9839e-02, -3.1508e-03,  1.4640e-03],\n",
      "           [-2.6597e-02,  5.9005e-03, -5.4693e-03],\n",
      "           [-1.2756e-02, -6.8949e-03, -2.0858e-02]],\n",
      "\n",
      "          [[-7.7995e-03,  2.6611e-03,  1.8774e-02],\n",
      "           [-1.0108e-02,  8.5890e-03,  8.1618e-04],\n",
      "           [ 1.7157e-03,  7.0315e-03, -5.3641e-04]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.3864e-03, -2.4967e-03, -4.2749e-03],\n",
      "           [-8.3403e-03,  1.1412e-02,  1.4814e-03],\n",
      "           [ 4.8382e-03,  2.1790e-02, -1.8664e-03]],\n",
      "\n",
      "          [[-5.5217e-03, -1.0658e-02, -6.5912e-03],\n",
      "           [-6.4003e-03,  1.4466e-02, -1.5038e-03],\n",
      "           [-8.1446e-05, -5.7171e-03,  1.3379e-02]],\n",
      "\n",
      "          [[-1.3556e-02, -2.3736e-03,  9.7142e-03],\n",
      "           [-2.5141e-03,  1.0340e-02,  5.7748e-03],\n",
      "           [ 1.5167e-02,  1.0350e-02, -1.3519e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.0123e-05, -3.3638e-03, -6.3035e-03],\n",
      "           [ 1.2547e-02, -1.1961e-03,  1.1771e-02],\n",
      "           [ 5.1041e-03, -2.7007e-03, -6.8836e-03]],\n",
      "\n",
      "          [[ 3.0241e-03, -1.0507e-02, -1.9287e-02],\n",
      "           [-5.3784e-03, -1.6874e-02, -9.7884e-03],\n",
      "           [-1.5052e-02, -5.9514e-03,  1.3838e-02]],\n",
      "\n",
      "          [[-1.2899e-02, -2.1679e-02, -2.7368e-03],\n",
      "           [ 1.1990e-03, -1.2717e-02, -1.0167e-02],\n",
      "           [-2.8052e-03, -1.7977e-02, -1.4741e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.1733e-02,  1.2882e-02,  2.2162e-02],\n",
      "           [-5.6140e-03,  3.5901e-03,  2.5187e-02],\n",
      "           [-4.4775e-03, -2.7456e-03,  6.0001e-03]],\n",
      "\n",
      "          [[ 5.2458e-03,  1.3166e-02,  3.5607e-03],\n",
      "           [ 1.3266e-03,  1.7938e-03,  1.6034e-02],\n",
      "           [-8.2807e-03,  7.3440e-03,  3.5753e-03]],\n",
      "\n",
      "          [[-2.1039e-03,  3.6977e-03, -1.3182e-02],\n",
      "           [-2.6740e-03,  1.1837e-02,  8.7857e-03],\n",
      "           [ 2.1384e-03,  8.9746e-03, -8.4654e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.1028e-03,  4.1749e-04, -5.7682e-03],\n",
      "           [ 5.5860e-03, -1.4395e-02,  3.9241e-03],\n",
      "           [-4.0696e-03, -1.7435e-02, -5.0547e-03]],\n",
      "\n",
      "          [[-2.2856e-03,  3.4126e-03,  6.9004e-04],\n",
      "           [-2.7984e-03,  4.4574e-03, -3.9328e-03],\n",
      "           [-4.0941e-03, -6.3442e-03, -1.9151e-03]],\n",
      "\n",
      "          [[-1.9526e-02, -4.9189e-03,  6.6653e-03],\n",
      "           [-3.1964e-03,  6.3094e-03,  8.8971e-03],\n",
      "           [ 3.0895e-03, -1.6878e-02,  9.0281e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.9501e-03, -3.8731e-03, -5.6447e-03],\n",
      "           [-7.8094e-03, -4.5974e-03, -1.0233e-02],\n",
      "           [ 4.6179e-03, -2.1402e-03, -3.1466e-03]],\n",
      "\n",
      "          [[-8.3687e-03,  3.2134e-03, -8.3246e-03],\n",
      "           [-1.1922e-02, -1.6489e-02, -5.6839e-04],\n",
      "           [-4.9213e-03, -1.3868e-03, -6.3484e-03]],\n",
      "\n",
      "          [[ 1.0811e-03,  1.2245e-02,  2.5900e-03],\n",
      "           [-1.2751e-03,  3.4201e-03, -6.8537e-03],\n",
      "           [ 1.1581e-03,  1.6869e-03, -1.1175e-03]]],\n",
      "\n",
      "\n",
      "         [[[-9.3372e-03, -8.0317e-04, -1.7733e-03],\n",
      "           [ 4.7871e-03,  6.7105e-03,  4.7239e-04],\n",
      "           [ 4.4513e-04,  9.0189e-03,  1.0126e-02]],\n",
      "\n",
      "          [[-1.2435e-02, -1.5020e-02, -1.6386e-02],\n",
      "           [-5.0031e-03, -9.8743e-03, -1.2889e-02],\n",
      "           [-1.5748e-02, -1.4980e-02, -8.5548e-03]],\n",
      "\n",
      "          [[-3.3548e-03, -1.0541e-02, -5.3656e-03],\n",
      "           [ 1.3076e-03, -1.0558e-02, -5.2817e-03],\n",
      "           [-1.5412e-02, -1.4256e-02, -6.4162e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0745e-02,  6.7716e-03,  1.3183e-02],\n",
      "           [-2.8708e-03, -1.2682e-02,  1.0740e-02],\n",
      "           [ 1.3260e-02,  8.7727e-03,  5.6633e-03]],\n",
      "\n",
      "          [[ 1.3858e-02,  2.2438e-02, -1.4911e-03],\n",
      "           [ 1.7865e-02,  8.4955e-03,  2.1150e-02],\n",
      "           [ 7.4687e-03,  2.1463e-04, -2.4170e-03]],\n",
      "\n",
      "          [[ 2.2180e-04,  9.9783e-03, -3.3828e-04],\n",
      "           [-5.9198e-04,  1.2987e-03,  1.1279e-02],\n",
      "           [ 1.6128e-02,  5.3275e-03, -3.3269e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 7.6992e-04, -1.4350e-02, -1.9945e-02],\n",
      "           [-5.4751e-03, -5.9366e-03, -2.1749e-02],\n",
      "           [ 1.6771e-04, -5.9937e-03, -2.0435e-02]],\n",
      "\n",
      "          [[-2.5828e-03,  1.7009e-02,  9.8710e-03],\n",
      "           [-1.0911e-02,  7.0902e-03,  2.9869e-03],\n",
      "           [ 1.2315e-02, -3.8496e-03, -2.1510e-03]],\n",
      "\n",
      "          [[ 6.7515e-03,  5.4051e-03, -8.5441e-04],\n",
      "           [ 1.1475e-02,  4.9847e-03,  6.2591e-03],\n",
      "           [ 2.1600e-02,  3.7298e-03,  1.2225e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.0498e-03,  1.2251e-03, -8.0386e-03],\n",
      "           [-6.7813e-03, -1.0288e-03,  1.8258e-03],\n",
      "           [-1.1140e-02, -1.3691e-02, -1.0546e-02]],\n",
      "\n",
      "          [[-4.3311e-03,  4.4314e-03,  8.0821e-03],\n",
      "           [-1.2752e-03,  2.7334e-03,  1.0133e-03],\n",
      "           [-2.3868e-03,  6.8669e-05, -3.6471e-04]],\n",
      "\n",
      "          [[-1.8052e-03,  8.0335e-03, -1.1429e-04],\n",
      "           [ 6.4383e-03,  8.3530e-03,  1.3842e-02],\n",
      "           [ 2.3219e-02,  5.1788e-03,  1.4758e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.8353e-03, -1.3811e-02, -2.2232e-02],\n",
      "           [-5.4712e-03, -1.4963e-02,  6.3628e-03],\n",
      "           [-1.2504e-02, -3.3746e-03, -6.3308e-03]],\n",
      "\n",
      "          [[-3.4538e-03, -5.5840e-03, -6.6223e-03],\n",
      "           [-1.6847e-02, -6.6859e-03, -5.8479e-03],\n",
      "           [ 7.2770e-03, -1.0905e-02,  1.3610e-02]],\n",
      "\n",
      "          [[ 3.1767e-03,  5.0386e-03,  1.0816e-02],\n",
      "           [-1.3680e-02,  1.8886e-03,  1.3831e-03],\n",
      "           [-2.7886e-03,  1.8476e-02,  8.5441e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.5489e-02, -2.4387e-02,  3.3879e-03],\n",
      "           [-9.3447e-03, -2.1052e-03,  8.0898e-03],\n",
      "           [-1.3799e-02, -1.3670e-02, -8.8562e-03]],\n",
      "\n",
      "          [[-2.6378e-02, -6.0491e-03,  8.6256e-03],\n",
      "           [-2.1473e-02, -1.0717e-02, -2.0551e-04],\n",
      "           [-1.6021e-02, -6.2790e-03,  1.0593e-02]],\n",
      "\n",
      "          [[-2.2227e-02, -4.2437e-03, -1.2453e-02],\n",
      "           [-1.8738e-02, -9.4655e-03, -1.0461e-02],\n",
      "           [-1.4524e-02, -6.2169e-03, -6.2296e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.1415e-02, -2.5273e-02, -2.1646e-02],\n",
      "           [ 1.1658e-02, -7.8197e-03, -9.7268e-03],\n",
      "           [ 5.5003e-03,  1.7232e-05, -7.5391e-03]],\n",
      "\n",
      "          [[-2.0772e-02, -1.0846e-02, -1.6067e-02],\n",
      "           [ 2.7390e-02,  2.0294e-03,  1.3890e-02],\n",
      "           [ 3.0412e-02,  1.8548e-02, -2.0742e-03]],\n",
      "\n",
      "          [[-3.5641e-03, -1.8013e-02, -2.7198e-02],\n",
      "           [ 2.2761e-02,  1.2105e-02,  9.7904e-03],\n",
      "           [ 2.7632e-02,  1.5755e-02,  1.3858e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-4.1239e-03, -6.0170e-03, -2.7512e-04],\n",
      "           [ 3.7207e-03,  1.4634e-04,  8.4130e-03],\n",
      "           [ 1.3441e-02,  1.5311e-02,  1.8602e-02]],\n",
      "\n",
      "          [[-3.0643e-03, -6.0061e-04,  9.8847e-03],\n",
      "           [ 3.7073e-03, -8.8561e-03,  3.6436e-03],\n",
      "           [ 2.3653e-03,  1.0448e-02,  3.4984e-03]],\n",
      "\n",
      "          [[ 9.9383e-03, -4.0228e-03, -2.4845e-03],\n",
      "           [ 3.7902e-03,  1.0377e-02,  3.6591e-03],\n",
      "           [-2.5618e-02, -6.7115e-03,  5.8716e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.7819e-04,  3.8068e-05, -1.6458e-02],\n",
      "           [-9.3819e-03, -1.3048e-02, -1.4077e-02],\n",
      "           [ 4.5259e-03,  5.3844e-04,  1.4896e-02]],\n",
      "\n",
      "          [[ 3.4127e-03,  1.0174e-02,  1.3313e-03],\n",
      "           [-1.5284e-02, -2.3042e-02, -1.2326e-02],\n",
      "           [-4.5899e-03,  4.9537e-03,  7.4713e-03]],\n",
      "\n",
      "          [[ 9.6392e-03,  1.7849e-03, -3.0510e-03],\n",
      "           [ 5.8890e-03,  6.0392e-03, -1.6786e-02],\n",
      "           [-3.9217e-03, -1.1175e-02, -2.3356e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1826e-03,  6.2115e-03, -4.4047e-03],\n",
      "           [ 5.9549e-03,  1.6389e-02,  3.7881e-03],\n",
      "           [-9.9518e-03, -4.5144e-03, -6.3330e-03]],\n",
      "\n",
      "          [[ 1.1906e-02,  6.6903e-03,  1.1088e-02],\n",
      "           [ 8.1202e-03,  3.4416e-03,  7.3334e-03],\n",
      "           [-1.3621e-03, -2.7604e-03, -4.2466e-03]],\n",
      "\n",
      "          [[ 1.2527e-02,  9.7132e-04,  4.3382e-03],\n",
      "           [ 2.5576e-02,  1.8324e-02,  5.7700e-03],\n",
      "           [ 2.1269e-02,  2.3775e-02,  1.7963e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.8707e-02,  1.1953e-02,  5.7777e-03],\n",
      "           [-9.9942e-03, -7.8967e-03, -2.8262e-03],\n",
      "           [-1.8045e-03,  2.3468e-04, -2.0930e-02]],\n",
      "\n",
      "          [[ 6.9385e-03, -1.5605e-02,  1.5580e-03],\n",
      "           [-6.0123e-03, -9.6159e-03, -9.4128e-03],\n",
      "           [ 9.7484e-03,  7.9798e-03,  5.3050e-03]],\n",
      "\n",
      "          [[ 1.1017e-02, -1.3350e-02,  5.0281e-03],\n",
      "           [ 4.2835e-03,  1.5833e-02, -7.7945e-03],\n",
      "           [-8.4361e-03,  7.6713e-03, -1.2538e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.1919e-04, -7.3375e-03,  2.3295e-04],\n",
      "           [-3.8701e-03, -1.3867e-03, -8.2353e-03],\n",
      "           [ 8.5322e-03, -6.9751e-03,  6.7189e-03]],\n",
      "\n",
      "          [[ 6.8815e-03, -2.6504e-03,  4.4990e-03],\n",
      "           [ 1.7234e-02, -4.2455e-03, -1.2935e-02],\n",
      "           [ 2.5998e-04,  7.7062e-03, -2.3579e-03]],\n",
      "\n",
      "          [[-6.8063e-03,  4.2928e-03, -2.3049e-02],\n",
      "           [-7.5702e-03, -4.0604e-03, -2.0665e-02],\n",
      "           [-1.0801e-03, -1.2255e-02, -1.7368e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.6219e-02, -6.5109e-03, -1.9163e-02],\n",
      "           [ 1.8748e-04, -1.3744e-02,  1.0116e-03],\n",
      "           [-1.4371e-02,  5.5225e-03,  3.3064e-03]],\n",
      "\n",
      "          [[-6.6937e-03, -3.5995e-03,  6.8781e-03],\n",
      "           [-4.5986e-03, -8.2768e-03, -3.0215e-03],\n",
      "           [-1.1149e-03,  1.1093e-03,  2.3692e-04]],\n",
      "\n",
      "          [[-4.5582e-03,  1.1814e-02, -2.4963e-03],\n",
      "           [ 1.5583e-02,  1.2312e-02,  9.6782e-03],\n",
      "           [ 1.8712e-02,  2.2820e-02,  1.9953e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 7.4099e-03,  9.0162e-03,  6.1069e-04],\n",
      "           [ 1.2611e-02, -1.7182e-02, -1.5768e-02],\n",
      "           [-1.7843e-02, -1.9107e-02, -8.6528e-03]],\n",
      "\n",
      "          [[ 1.0936e-02, -1.0402e-02,  1.3249e-02],\n",
      "           [ 6.7262e-03, -7.7998e-03, -1.2384e-02],\n",
      "           [ 4.5774e-03, -2.3227e-03,  3.0235e-03]],\n",
      "\n",
      "          [[ 3.0879e-03,  1.4207e-05, -1.2418e-03],\n",
      "           [ 9.9328e-03, -4.6024e-03, -8.4149e-03],\n",
      "           [ 1.8932e-02,  8.2895e-03, -7.0311e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.5837e-03, -1.4424e-02,  1.3722e-03],\n",
      "           [-1.8019e-03,  8.6383e-03, -4.0862e-03],\n",
      "           [ 5.1657e-03, -5.8049e-03, -3.4406e-03]],\n",
      "\n",
      "          [[-2.2000e-02, -1.3142e-02,  2.8818e-03],\n",
      "           [-2.0886e-02, -1.9135e-02,  1.2374e-02],\n",
      "           [-9.4608e-03, -7.2481e-03,  1.3942e-02]],\n",
      "\n",
      "          [[-1.0738e-02, -1.1518e-03, -2.5272e-02],\n",
      "           [ 1.9940e-03, -1.4395e-02,  1.1521e-03],\n",
      "           [-7.2901e-03,  8.9146e-03,  3.2474e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.7795e-03, -8.8926e-03,  1.1819e-02],\n",
      "           [-1.0635e-02, -7.7791e-04,  7.7441e-03],\n",
      "           [-2.1427e-02,  3.1294e-03,  1.1749e-02]],\n",
      "\n",
      "          [[-6.3725e-03,  1.1041e-03, -1.2417e-02],\n",
      "           [-1.1076e-02, -2.8573e-03, -2.2882e-03],\n",
      "           [-1.5143e-02,  3.3396e-03,  5.8970e-03]],\n",
      "\n",
      "          [[ 8.9302e-03, -1.2025e-02, -2.1028e-02],\n",
      "           [-9.0179e-03,  1.4761e-03,  3.2515e-03],\n",
      "           [-8.8472e-03, -6.5617e-03,  5.1806e-03]]]]], device='cuda:0')), ('module.down_layers.3.4.conv2.conv.weight', tensor([[[[[-2.8443e-02, -1.9194e-02,  9.1089e-03],\n",
      "           [-1.5336e-03, -1.0725e-02,  5.2588e-03],\n",
      "           [-1.5687e-02,  6.7566e-03,  7.6350e-03]],\n",
      "\n",
      "          [[-2.7455e-02, -1.3122e-02, -1.2786e-02],\n",
      "           [-1.1136e-02, -5.4071e-03, -1.2397e-02],\n",
      "           [-1.4329e-02,  9.3866e-03,  2.3979e-02]],\n",
      "\n",
      "          [[-7.3925e-03, -1.0783e-02, -1.7041e-02],\n",
      "           [-2.6300e-02, -2.4157e-02, -1.1202e-02],\n",
      "           [-1.5943e-02, -5.9522e-03, -5.7833e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 7.5832e-03, -1.0137e-02, -6.8516e-03],\n",
      "           [ 7.2590e-03,  1.5607e-04, -2.1198e-03],\n",
      "           [ 4.1427e-03,  1.6129e-02, -8.1368e-03]],\n",
      "\n",
      "          [[ 4.8503e-03, -2.1725e-03, -7.4280e-03],\n",
      "           [ 4.5897e-03,  3.8398e-03,  1.3472e-02],\n",
      "           [ 1.4240e-02,  8.3444e-03,  1.5502e-02]],\n",
      "\n",
      "          [[ 1.2469e-02, -2.7279e-03, -1.9693e-03],\n",
      "           [-1.5804e-03,  4.6594e-03,  1.1899e-02],\n",
      "           [ 1.8414e-02,  4.1160e-03,  1.4092e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.1674e-03,  5.6908e-03,  7.9957e-03],\n",
      "           [-6.5645e-03, -2.1937e-03, -1.3401e-02],\n",
      "           [ 6.8907e-03,  5.2474e-03, -1.9394e-02]],\n",
      "\n",
      "          [[ 4.8788e-03, -5.2840e-03, -1.4047e-03],\n",
      "           [-1.3773e-02,  1.3478e-02,  1.6664e-02],\n",
      "           [ 7.5700e-03,  1.4070e-02,  9.1329e-03]],\n",
      "\n",
      "          [[-1.5473e-02,  2.3655e-03,  2.3649e-02],\n",
      "           [ 1.7578e-03,  4.6009e-03,  1.0058e-02],\n",
      "           [ 1.2416e-02, -5.8613e-03,  1.5754e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.2466e-02, -2.9061e-03, -9.7322e-04],\n",
      "           [-1.9687e-02, -5.3301e-03,  3.3482e-04],\n",
      "           [-8.2323e-03,  7.8296e-03,  9.8932e-03]],\n",
      "\n",
      "          [[-4.2246e-03,  4.7620e-03, -1.8745e-03],\n",
      "           [-1.6712e-02, -9.5309e-03, -5.4183e-04],\n",
      "           [ 6.8331e-03,  1.3745e-02,  8.8621e-03]],\n",
      "\n",
      "          [[ 3.0433e-03, -1.2562e-02,  3.9125e-03],\n",
      "           [-1.2050e-02,  5.2729e-03, -1.3562e-02],\n",
      "           [ 1.2663e-02,  4.0786e-03,  1.4259e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.2577e-03,  1.8173e-02,  3.0371e-03],\n",
      "           [ 2.1740e-02,  1.8229e-02, -2.7695e-03],\n",
      "           [ 1.4158e-02,  2.5288e-02,  3.3721e-02]],\n",
      "\n",
      "          [[ 1.4307e-02, -5.7395e-03,  1.9721e-02],\n",
      "           [-9.5583e-03,  1.3725e-02, -8.6010e-03],\n",
      "           [-3.4202e-03,  9.1227e-03, -7.1640e-04]],\n",
      "\n",
      "          [[-7.1288e-03,  1.8946e-02,  2.7777e-03],\n",
      "           [-4.3782e-03, -1.1286e-02, -3.1827e-04],\n",
      "           [-2.0770e-02, -3.4180e-02, -4.0864e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 6.4066e-03,  8.1282e-03, -6.5424e-03],\n",
      "           [ 1.2023e-02,  9.2077e-03,  9.1681e-03],\n",
      "           [-7.1170e-03, -1.6075e-03,  1.5243e-02]],\n",
      "\n",
      "          [[ 2.8276e-03,  7.6717e-03,  5.2304e-03],\n",
      "           [-1.4984e-02,  1.3717e-02, -4.3022e-04],\n",
      "           [ 6.3156e-04, -2.8567e-03,  3.4755e-03]],\n",
      "\n",
      "          [[ 2.3799e-03, -2.2993e-03,  2.5897e-02],\n",
      "           [-3.7769e-03,  5.9547e-03, -1.3532e-03],\n",
      "           [-2.2575e-02,  4.6999e-03, -1.8900e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.2958e-03, -1.1248e-02, -1.4758e-02],\n",
      "           [-1.3097e-03, -1.0824e-02, -2.4318e-02],\n",
      "           [-2.5586e-03, -1.1212e-02, -1.8229e-02]],\n",
      "\n",
      "          [[-4.5239e-03, -2.0921e-02,  1.0932e-03],\n",
      "           [-1.8370e-02, -5.9069e-03, -2.4537e-03],\n",
      "           [-1.6893e-02, -3.0622e-03, -1.8785e-02]],\n",
      "\n",
      "          [[-5.6270e-03, -4.7795e-03, -8.1433e-03],\n",
      "           [-8.6451e-03, -1.8855e-02, -5.4968e-03],\n",
      "           [-1.4582e-02,  4.1927e-04,  1.1955e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.0561e-02, -1.7095e-02, -1.1404e-02],\n",
      "           [-1.3553e-02, -2.3946e-02, -1.1851e-02],\n",
      "           [-2.4423e-03,  9.2140e-03, -7.6533e-03]],\n",
      "\n",
      "          [[ 6.7205e-04, -1.1398e-02, -6.6242e-04],\n",
      "           [-3.8044e-03,  7.1917e-03,  4.4898e-03],\n",
      "           [-2.1512e-03,  1.2891e-02,  1.6305e-02]],\n",
      "\n",
      "          [[-9.9283e-04, -7.7241e-03, -6.3098e-03],\n",
      "           [ 4.9372e-03,  1.2518e-02,  2.3889e-02],\n",
      "           [ 1.4697e-02,  2.0503e-03,  1.4525e-02]]],\n",
      "\n",
      "\n",
      "         [[[-8.6244e-03, -1.4216e-02, -5.1882e-03],\n",
      "           [ 6.1840e-04,  6.6307e-03, -2.4468e-03],\n",
      "           [-1.1634e-02,  9.4354e-04,  1.1002e-02]],\n",
      "\n",
      "          [[-1.1281e-02, -2.1283e-02,  1.9398e-03],\n",
      "           [-6.1353e-03, -3.9831e-03,  6.9765e-03],\n",
      "           [ 2.0997e-03, -2.1101e-03,  1.7306e-03]],\n",
      "\n",
      "          [[-1.5004e-03, -2.3609e-02,  1.3260e-02],\n",
      "           [-1.3974e-02, -9.9354e-03, -1.4478e-04],\n",
      "           [-1.3976e-03,  1.0360e-02,  3.4031e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.2399e-03,  6.6908e-03, -1.4524e-02],\n",
      "           [-8.5032e-03,  1.0981e-02, -1.1684e-02],\n",
      "           [ 6.3736e-03, -5.3933e-03, -1.2287e-02]],\n",
      "\n",
      "          [[-1.0627e-04, -7.0677e-04,  5.2763e-05],\n",
      "           [-3.9452e-03, -3.5125e-05,  4.4213e-04],\n",
      "           [-5.2065e-03, -6.5872e-05, -1.8071e-02]],\n",
      "\n",
      "          [[ 1.6969e-03, -1.6146e-02, -1.9498e-02],\n",
      "           [ 3.5110e-03, -1.1638e-03, -1.2529e-02],\n",
      "           [-1.1647e-02, -5.1150e-03,  1.9704e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 7.4570e-03, -5.1828e-03,  9.2649e-03],\n",
      "           [ 8.2550e-03,  5.0563e-03,  1.0887e-02],\n",
      "           [-8.6376e-03,  1.5914e-02,  1.3708e-02]],\n",
      "\n",
      "          [[-2.4012e-03, -3.1519e-03,  1.2669e-02],\n",
      "           [ 3.4322e-04, -7.9204e-03,  7.3949e-03],\n",
      "           [-1.3998e-02,  4.5086e-03,  3.4616e-03]],\n",
      "\n",
      "          [[ 5.3614e-03, -1.6935e-02,  4.5181e-03],\n",
      "           [ 1.1784e-02, -5.2153e-03, -5.8248e-03],\n",
      "           [ 4.7883e-03,  2.0232e-03, -3.0080e-03]]],\n",
      "\n",
      "\n",
      "         [[[-8.3191e-03, -3.5944e-03,  1.4335e-02],\n",
      "           [ 7.1296e-03, -1.6159e-02,  4.7146e-04],\n",
      "           [ 1.6973e-02, -3.0612e-03, -1.3798e-03]],\n",
      "\n",
      "          [[-1.1382e-02, -3.0056e-03,  1.5689e-02],\n",
      "           [ 7.6685e-03, -1.6000e-02,  1.6354e-02],\n",
      "           [ 1.0587e-02, -8.1742e-04, -2.4823e-03]],\n",
      "\n",
      "          [[-2.0692e-02, -2.2610e-02,  1.1274e-02],\n",
      "           [-2.9927e-03, -1.9338e-02,  1.2182e-02],\n",
      "           [ 2.5827e-03, -1.0363e-02,  7.5160e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1018e-02,  6.8665e-04, -9.3792e-03],\n",
      "           [-2.2239e-03,  6.2549e-04,  2.3967e-03],\n",
      "           [-1.8106e-02, -1.6583e-02, -4.7486e-03]],\n",
      "\n",
      "          [[-1.7396e-02,  1.6684e-04, -1.1358e-02],\n",
      "           [-8.4678e-03,  1.0786e-02,  1.9165e-02],\n",
      "           [-1.6928e-02,  1.1079e-02,  1.3131e-02]],\n",
      "\n",
      "          [[-1.1560e-02, -6.7899e-03,  6.6662e-04],\n",
      "           [-1.1235e-02,  8.5930e-03, -5.3349e-03],\n",
      "           [-2.5173e-02,  1.0297e-03, -5.5129e-03]]],\n",
      "\n",
      "\n",
      "         [[[-9.9156e-03, -1.7810e-02, -1.1774e-02],\n",
      "           [-2.3559e-02, -9.7378e-03, -1.0732e-02],\n",
      "           [-1.6465e-02, -8.9845e-03,  6.0863e-04]],\n",
      "\n",
      "          [[-4.5593e-03, -1.8259e-02, -3.0216e-02],\n",
      "           [-3.2936e-03, -2.7010e-03, -3.0337e-03],\n",
      "           [ 4.3105e-03,  8.7504e-05,  5.6465e-03]],\n",
      "\n",
      "          [[ 1.1978e-02,  3.9997e-03, -8.1858e-03],\n",
      "           [ 1.2342e-03,  1.6867e-02,  5.2608e-03],\n",
      "           [-2.5658e-03,  1.0883e-02,  1.5400e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.7103e-03,  2.3840e-03,  3.1916e-03],\n",
      "           [ 2.3815e-02,  1.8181e-02,  4.6249e-03],\n",
      "           [-1.0018e-02, -1.3903e-02, -2.0461e-02]],\n",
      "\n",
      "          [[ 9.1284e-03,  3.8893e-03,  1.1744e-02],\n",
      "           [-6.0592e-03, -7.1568e-04,  3.4224e-03],\n",
      "           [ 5.7568e-03,  1.3321e-02, -2.2496e-02]],\n",
      "\n",
      "          [[-2.0852e-03, -4.8765e-03,  2.3322e-03],\n",
      "           [ 6.9416e-03, -3.5311e-03, -1.3769e-02],\n",
      "           [-3.4414e-03, -1.3464e-02,  4.1419e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.7979e-04, -4.9556e-03,  1.0115e-02],\n",
      "           [ 6.5445e-04,  1.7872e-02,  1.0843e-02],\n",
      "           [-2.7739e-03,  2.3226e-02,  2.3808e-02]],\n",
      "\n",
      "          [[-6.2302e-03, -1.1772e-02,  3.8101e-03],\n",
      "           [ 1.3206e-02,  9.4653e-03,  2.8628e-04],\n",
      "           [ 1.1253e-02,  1.6088e-03, -4.4389e-04]],\n",
      "\n",
      "          [[ 1.1600e-02, -1.7471e-03, -2.7004e-03],\n",
      "           [-9.2070e-03, -8.9958e-03,  5.3633e-03],\n",
      "           [ 2.1556e-03, -2.7173e-03,  2.4646e-03]]],\n",
      "\n",
      "\n",
      "         [[[-4.0715e-04,  1.1176e-02,  2.5271e-02],\n",
      "           [-1.0777e-02,  1.9559e-02, -6.7774e-03],\n",
      "           [-7.3916e-03,  1.9211e-02,  1.5894e-02]],\n",
      "\n",
      "          [[ 1.4323e-02,  1.5183e-02,  8.9420e-03],\n",
      "           [-2.3189e-03,  8.2509e-03, -1.2061e-03],\n",
      "           [-2.2852e-02, -2.6849e-03, -3.0607e-03]],\n",
      "\n",
      "          [[-6.9254e-03, -1.3532e-02,  2.8683e-03],\n",
      "           [ 3.8669e-03,  4.6958e-03, -1.2237e-02],\n",
      "           [-5.1440e-03, -1.5193e-03, -1.0565e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.3822e-03,  2.2532e-02,  9.3809e-03],\n",
      "           [ 1.0356e-02,  4.1127e-03, -9.3459e-03],\n",
      "           [ 8.0417e-03,  9.2102e-03, -1.4553e-02]],\n",
      "\n",
      "          [[ 8.4902e-03,  8.3798e-03, -6.4294e-03],\n",
      "           [ 7.1273e-03, -2.4927e-04, -2.3466e-03],\n",
      "           [-9.7097e-03,  1.0148e-02,  1.8099e-03]],\n",
      "\n",
      "          [[-1.8099e-02, -1.9222e-02, -1.2172e-03],\n",
      "           [-1.1468e-02, -6.8788e-03, -3.3897e-03],\n",
      "           [ 1.9224e-03,  7.0920e-04, -4.8503e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.0795e-03, -7.5847e-03, -1.2643e-02],\n",
      "           [ 4.0299e-04,  2.2416e-03, -1.3816e-02],\n",
      "           [ 2.8738e-02,  1.4042e-02,  8.4222e-03]],\n",
      "\n",
      "          [[-5.8775e-03, -4.8956e-03,  6.8914e-03],\n",
      "           [-8.7861e-03,  5.1847e-03, -1.5075e-03],\n",
      "           [ 1.5378e-02,  9.3732e-04, -2.8122e-03]],\n",
      "\n",
      "          [[ 9.3928e-03, -4.8255e-04,  6.6107e-03],\n",
      "           [ 1.2488e-03,  1.2450e-02,  7.2615e-03],\n",
      "           [ 1.3679e-02, -1.1463e-02, -1.4624e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4214e-03,  1.2422e-03, -5.7782e-04],\n",
      "           [ 1.8771e-02,  1.1478e-02,  1.1036e-02],\n",
      "           [ 1.8276e-02,  6.7352e-03, -4.0036e-03]],\n",
      "\n",
      "          [[ 1.6087e-03,  4.0261e-03,  9.8676e-03],\n",
      "           [-5.1267e-03,  5.1918e-03, -2.2546e-03],\n",
      "           [-1.3202e-03,  1.1671e-02, -1.0027e-02]],\n",
      "\n",
      "          [[-1.3811e-02, -7.5858e-03,  1.7749e-02],\n",
      "           [-2.2480e-05, -9.3788e-03, -3.4232e-03],\n",
      "           [-6.9827e-03, -6.0804e-03,  8.3986e-03]]],\n",
      "\n",
      "\n",
      "         [[[-7.1270e-03, -1.5652e-02, -7.1212e-03],\n",
      "           [-2.0712e-02, -1.3471e-02,  6.5683e-03],\n",
      "           [ 6.0581e-04, -1.5279e-02,  9.0095e-03]],\n",
      "\n",
      "          [[-1.4255e-02, -6.5097e-03, -1.6193e-02],\n",
      "           [-2.0553e-02, -2.4693e-04,  9.2300e-03],\n",
      "           [-1.3178e-02,  2.7218e-03,  1.1268e-02]],\n",
      "\n",
      "          [[-9.2644e-03, -2.2134e-02, -1.2145e-02],\n",
      "           [ 5.7202e-03,  6.7325e-03,  2.1751e-03],\n",
      "           [-2.2270e-02, -2.9609e-03,  9.4338e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.7926e-03, -1.5451e-02,  3.1953e-04],\n",
      "           [-3.2190e-03, -1.9456e-02, -5.5841e-03],\n",
      "           [ 5.6627e-06,  3.4587e-04, -7.8908e-03]],\n",
      "\n",
      "          [[-8.1128e-03, -1.6961e-02, -2.8510e-03],\n",
      "           [ 3.8593e-03, -1.4562e-02, -3.0064e-03],\n",
      "           [-8.2346e-03, -7.7523e-03, -1.4152e-02]],\n",
      "\n",
      "          [[-1.2969e-02, -1.6081e-02,  1.2622e-02],\n",
      "           [-4.5468e-03, -5.1009e-03,  9.6858e-03],\n",
      "           [-8.7574e-03,  2.0531e-03, -5.4688e-03]]],\n",
      "\n",
      "\n",
      "         [[[-9.4112e-04, -3.0552e-03, -2.3304e-03],\n",
      "           [-1.2307e-02, -1.5143e-02, -1.1034e-02],\n",
      "           [ 1.4117e-02,  2.0363e-02,  1.2698e-02]],\n",
      "\n",
      "          [[-1.0883e-02, -1.6270e-02, -3.9599e-03],\n",
      "           [ 4.4575e-03,  9.3018e-04, -4.3185e-03],\n",
      "           [ 1.1968e-02,  1.6207e-02, -2.1999e-02]],\n",
      "\n",
      "          [[-1.0580e-02, -1.2015e-02,  1.1871e-02],\n",
      "           [ 2.2740e-02,  1.4970e-03, -1.1156e-02],\n",
      "           [ 3.9401e-03,  1.5225e-02,  9.2226e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 8.1310e-03, -4.8630e-03, -1.6462e-02],\n",
      "           [-1.9865e-02, -1.4987e-02, -2.3611e-02],\n",
      "           [ 2.7039e-04, -4.9263e-03,  1.2622e-03]],\n",
      "\n",
      "          [[-5.2666e-04, -1.1107e-02, -8.9892e-03],\n",
      "           [-1.5686e-02, -7.9573e-03,  7.6969e-03],\n",
      "           [ 1.5209e-02,  1.3962e-03, -1.0206e-02]],\n",
      "\n",
      "          [[-1.1425e-02, -1.7268e-02,  1.1056e-02],\n",
      "           [ 1.8676e-03, -8.7700e-03, -3.3224e-03],\n",
      "           [ 1.3927e-02,  2.2986e-03,  1.2752e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 7.6133e-03,  6.7738e-03, -1.2090e-02],\n",
      "           [-1.7462e-02, -1.9422e-02, -1.6310e-02],\n",
      "           [ 2.2738e-04, -1.1456e-03, -1.0232e-02]],\n",
      "\n",
      "          [[ 1.3909e-03,  9.3056e-03, -8.2434e-03],\n",
      "           [-1.1406e-02, -7.8441e-03, -9.2648e-03],\n",
      "           [ 8.9238e-03, -1.9002e-02, -3.4400e-02]],\n",
      "\n",
      "          [[ 8.8684e-03, -3.2168e-03,  7.4385e-03],\n",
      "           [ 9.2319e-03, -1.7774e-02, -1.2333e-02],\n",
      "           [-4.2145e-03, -1.5523e-02, -2.8636e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.2600e-03,  1.1119e-02, -4.4989e-03],\n",
      "           [ 5.3734e-03,  8.0759e-04, -1.4733e-02],\n",
      "           [ 1.3698e-02, -9.2068e-03, -1.8252e-02]],\n",
      "\n",
      "          [[ 1.3015e-03,  4.2791e-04,  1.5805e-02],\n",
      "           [-9.0626e-03,  9.1972e-03, -4.4911e-03],\n",
      "           [ 2.0206e-03, -6.0096e-03, -9.0882e-03]],\n",
      "\n",
      "          [[-1.1839e-02,  6.6207e-03,  1.8021e-02],\n",
      "           [-1.0550e-02,  1.9305e-04, -4.3979e-03],\n",
      "           [-2.0683e-02, -1.3905e-04, -9.9609e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2903e-03,  1.6024e-02,  9.8654e-03],\n",
      "           [-2.4675e-03,  4.8076e-03, -3.6284e-03],\n",
      "           [ 8.8706e-05,  5.5599e-03,  1.9296e-02]],\n",
      "\n",
      "          [[ 1.6863e-02, -1.2903e-02,  2.9903e-03],\n",
      "           [-3.0392e-03, -9.9423e-03,  6.0350e-03],\n",
      "           [ 1.5534e-02, -8.8450e-03, -2.2977e-03]],\n",
      "\n",
      "          [[-5.5147e-03,  9.7813e-03,  1.8112e-03],\n",
      "           [ 1.4692e-02, -7.5980e-03,  3.4891e-03],\n",
      "           [-7.7940e-03,  9.6603e-03,  2.3414e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.8761e-03, -8.2130e-03,  7.1182e-03],\n",
      "           [-1.0688e-02, -1.7425e-02, -1.4026e-02],\n",
      "           [-1.1901e-02, -5.7952e-03, -1.2610e-02]],\n",
      "\n",
      "          [[ 6.9420e-03, -1.6926e-03,  8.4922e-03],\n",
      "           [-5.1692e-04,  2.2940e-03, -7.2606e-03],\n",
      "           [-2.0042e-02, -2.2108e-02, -1.0568e-02]],\n",
      "\n",
      "          [[ 3.0589e-03,  7.3192e-03,  1.1771e-02],\n",
      "           [-3.3973e-03, -1.4148e-02, -3.4999e-03],\n",
      "           [-1.7846e-02,  4.3001e-03, -4.4519e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 5.2799e-03, -1.3298e-02,  4.5244e-03],\n",
      "           [-2.0762e-03, -5.1205e-03,  5.9937e-03],\n",
      "           [-1.7607e-02, -1.7542e-02, -1.7412e-02]],\n",
      "\n",
      "          [[ 1.4648e-02, -3.2639e-04, -1.3216e-02],\n",
      "           [ 1.8238e-02,  1.7727e-02, -1.8209e-02],\n",
      "           [-5.9192e-03, -4.0156e-03, -2.5418e-02]],\n",
      "\n",
      "          [[-1.5388e-03, -1.1713e-02, -1.0213e-02],\n",
      "           [ 3.2191e-02,  1.2878e-03,  1.8711e-03],\n",
      "           [ 2.3362e-02,  6.8601e-03, -1.5357e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 6.4945e-03, -1.6615e-03,  4.0687e-03],\n",
      "           [-2.6648e-03, -7.4063e-03,  4.4115e-03],\n",
      "           [-1.0722e-02, -1.1222e-02,  6.8065e-04]],\n",
      "\n",
      "          [[ 1.6335e-03,  2.0104e-03,  1.4171e-02],\n",
      "           [ 8.7936e-03, -7.2097e-03, -2.6591e-03],\n",
      "           [-7.6835e-03, -2.4726e-04,  5.0634e-04]],\n",
      "\n",
      "          [[ 3.8053e-03, -1.1385e-02, -1.7008e-02],\n",
      "           [-7.3740e-03,  1.2904e-02,  2.0238e-03],\n",
      "           [ 7.0338e-04, -1.1328e-02, -1.4203e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 5.3619e-03,  1.3410e-02,  9.8545e-03],\n",
      "           [-1.0602e-02, -4.8694e-03, -9.6003e-03],\n",
      "           [-2.2771e-02,  1.5961e-03,  2.4550e-03]],\n",
      "\n",
      "          [[-7.6216e-03,  3.2196e-03, -7.8513e-03],\n",
      "           [-8.0224e-03,  4.0327e-03, -9.9305e-03],\n",
      "           [-8.4196e-05, -1.5226e-02, -5.6846e-03]],\n",
      "\n",
      "          [[ 5.4499e-03,  7.4019e-03, -1.4607e-02],\n",
      "           [-5.9798e-03, -9.2525e-03, -2.3693e-02],\n",
      "           [-1.5296e-02, -2.9928e-03, -8.5190e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.3167e-02, -1.9828e-02, -1.2391e-02],\n",
      "           [-1.2439e-02, -1.8610e-02,  1.1176e-02],\n",
      "           [-1.1574e-02, -2.4799e-02,  1.8471e-02]],\n",
      "\n",
      "          [[-1.0358e-02, -9.3796e-03,  1.2873e-02],\n",
      "           [-5.4134e-03,  4.9317e-03,  1.3072e-02],\n",
      "           [-1.6961e-02, -1.5332e-03,  5.0763e-03]],\n",
      "\n",
      "          [[-4.2669e-03,  1.0449e-03,  1.6969e-04],\n",
      "           [-1.3254e-02,  7.9962e-04,  1.1306e-02],\n",
      "           [-1.2014e-02,  8.4652e-03,  1.7775e-02]]],\n",
      "\n",
      "\n",
      "         [[[-8.4672e-03, -9.2820e-03, -8.0459e-03],\n",
      "           [ 7.6036e-04, -6.5419e-03, -3.7068e-03],\n",
      "           [-8.2759e-03, -1.3596e-02,  2.6354e-03]],\n",
      "\n",
      "          [[ 1.3339e-02, -5.5137e-03, -1.9712e-03],\n",
      "           [-1.9310e-03, -4.7915e-03, -1.2268e-03],\n",
      "           [-1.4804e-02,  5.0573e-03, -1.2080e-02]],\n",
      "\n",
      "          [[ 2.6320e-02,  1.6856e-02,  3.6975e-03],\n",
      "           [ 1.5317e-03, -1.1895e-02,  1.6236e-02],\n",
      "           [-4.3280e-03, -8.1853e-03,  2.9519e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 9.7301e-04,  9.2317e-03, -4.0721e-03],\n",
      "           [-3.5255e-03,  1.0834e-02,  5.3138e-03],\n",
      "           [ 3.7003e-04,  7.7958e-03,  1.0221e-02]],\n",
      "\n",
      "          [[-9.2370e-03,  1.2035e-02, -1.2981e-02],\n",
      "           [-7.2194e-03,  7.3996e-03, -1.7597e-02],\n",
      "           [-8.7164e-03,  3.8756e-03,  6.9546e-03]],\n",
      "\n",
      "          [[-1.0992e-02,  3.4176e-03, -3.7411e-03],\n",
      "           [ 1.1510e-02,  9.4622e-03,  9.0444e-04],\n",
      "           [ 5.6103e-03,  3.6095e-03, -5.0276e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 5.3129e-03,  6.0075e-03,  1.2002e-02],\n",
      "           [ 4.0143e-03, -4.0329e-03, -3.6091e-03],\n",
      "           [-2.8459e-02, -3.3175e-03, -2.3042e-02]],\n",
      "\n",
      "          [[-5.6770e-03,  4.1358e-04,  2.2581e-02],\n",
      "           [ 7.0857e-03, -7.0886e-03,  1.3463e-02],\n",
      "           [ 6.8039e-03, -5.8514e-03,  1.0110e-02]],\n",
      "\n",
      "          [[-9.4462e-03,  1.5315e-02,  8.0637e-03],\n",
      "           [-6.7290e-04,  2.9950e-03,  1.2579e-02],\n",
      "           [-5.4719e-03, -1.3621e-03,  1.8769e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.2901e-03,  1.7541e-02, -1.7037e-02],\n",
      "           [ 4.8958e-03, -1.9486e-03, -7.9218e-03],\n",
      "           [ 8.3511e-03,  5.4665e-03,  6.4708e-03]],\n",
      "\n",
      "          [[ 1.6886e-02,  1.3945e-02,  1.1838e-02],\n",
      "           [ 5.2261e-03, -5.6590e-03,  9.0387e-03],\n",
      "           [-3.8000e-03, -1.1435e-02, -6.5766e-03]],\n",
      "\n",
      "          [[ 1.3815e-02,  8.6883e-03,  2.9147e-02],\n",
      "           [-4.3601e-04, -3.7287e-03,  1.9950e-02],\n",
      "           [ 7.1607e-03,  1.5122e-02,  1.4856e-02]]]]], device='cuda:0')), ('module.up_layers.0.0.norm1.weight', tensor([0.9745, 0.9377, 0.9407, 0.9819, 0.9550, 0.9242, 0.9461, 0.9121, 0.9672,\n",
      "        0.9715, 0.9714, 0.9797, 0.9923, 0.9620, 0.9409, 0.9037, 0.9608, 0.9514,\n",
      "        0.9412, 0.9071, 0.9870, 0.9533, 0.9427, 0.9100, 1.0045, 0.9760, 0.9322,\n",
      "        0.9304, 0.9450, 0.9179, 0.9892, 0.9848, 0.9718, 0.9092, 0.9506, 0.9543,\n",
      "        0.9959, 0.9752, 0.9409, 0.9491, 0.8809, 0.9782, 0.8823, 0.9916, 0.9890,\n",
      "        0.9736, 0.9754, 0.9786, 0.9515, 0.9054, 0.9815, 0.9457, 0.9318, 0.9712,\n",
      "        0.9249, 0.9285, 0.9808, 0.9758, 0.9426, 0.8932, 0.9681, 0.9471, 0.9787,\n",
      "        1.0015], device='cuda:0')), ('module.up_layers.0.0.norm1.bias', tensor([-0.0356, -0.0157,  0.0028, -0.0074, -0.0349, -0.0254, -0.0348, -0.0165,\n",
      "        -0.0114, -0.0169, -0.0120, -0.0082, -0.0193, -0.0200, -0.0273, -0.0346,\n",
      "        -0.0132, -0.0144,  0.0057, -0.0256, -0.0031, -0.0276, -0.0119, -0.0098,\n",
      "        -0.0265, -0.0328, -0.0509, -0.0159, -0.0326, -0.0347, -0.0330, -0.0233,\n",
      "        -0.0094, -0.0128, -0.0234, -0.0328, -0.0138, -0.0346, -0.0238, -0.0101,\n",
      "        -0.0121, -0.0040, -0.0020,  0.0066,  0.0008,  0.0018,  0.0034, -0.0091,\n",
      "        -0.0224, -0.0018, -0.0126, -0.0154, -0.0117, -0.0092, -0.0094, -0.0163,\n",
      "        -0.0223,  0.0029, -0.0103, -0.0135, -0.0246, -0.0341, -0.0156, -0.0280],\n",
      "       device='cuda:0')), ('module.up_layers.0.0.norm2.weight', tensor([0.9874, 0.9361, 0.9265, 0.9292, 0.9785, 0.8914, 0.9878, 0.8991, 0.9143,\n",
      "        0.9730, 0.9132, 0.9166, 0.9741, 0.9536, 0.9843, 0.9388, 0.6982, 0.8229,\n",
      "        0.9500, 0.8844, 0.8864, 0.9187, 0.8790, 0.9923, 0.9432, 0.8268, 0.9721,\n",
      "        0.9671, 0.7945, 0.9210, 0.9311, 0.8494, 0.9532, 0.9759, 0.9868, 0.9720,\n",
      "        0.8800, 0.9771, 0.9327, 0.9417, 0.9376, 0.9760, 0.8434, 0.9877, 0.8517,\n",
      "        0.9645, 0.9699, 0.9764, 0.9073, 0.9473, 0.8431, 0.9737, 0.8234, 0.9712,\n",
      "        0.9702, 0.8975, 0.9342, 0.9686, 0.9420, 0.9654, 0.9137, 0.9512, 0.9785,\n",
      "        0.9537], device='cuda:0')), ('module.up_layers.0.0.norm2.bias', tensor([-0.0284, -0.0107, -0.0100, -0.0182, -0.0286, -0.0344, -0.0349, -0.0377,\n",
      "         0.0082,  0.0318,  0.0175,  0.0262,  0.0128,  0.0113,  0.0147,  0.0062,\n",
      "         0.0106,  0.0013,  0.0052,  0.0197,  0.0156,  0.0150,  0.0170,  0.0109,\n",
      "         0.0160,  0.0018,  0.0083,  0.0123,  0.0015,  0.0154,  0.0152, -0.0017,\n",
      "        -0.0006, -0.0066, -0.0007, -0.0005, -0.0077,  0.0040, -0.0148, -0.0071,\n",
      "         0.0068, -0.0063, -0.0126,  0.0196, -0.0270, -0.0242,  0.0087, -0.0291,\n",
      "         0.0140,  0.0117,  0.0109,  0.0179, -0.0008,  0.0106,  0.0209,  0.0043,\n",
      "        -0.0186, -0.0388, -0.0131, -0.0523, -0.0197, -0.0527, -0.0520, -0.0511],\n",
      "       device='cuda:0')), ('module.up_layers.0.0.conv1.conv.weight', tensor([[[[[ 1.3233e-02,  9.0197e-03, -4.3204e-03],\n",
      "           [ 1.4474e-02,  1.2516e-04,  4.8782e-03],\n",
      "           [ 1.6913e-02, -8.0865e-04,  4.9274e-03]],\n",
      "\n",
      "          [[ 1.7130e-02, -1.8352e-02,  1.9644e-03],\n",
      "           [ 2.5554e-02,  1.0387e-02,  6.0050e-03],\n",
      "           [ 2.2455e-02,  2.1118e-02, -2.2631e-02]],\n",
      "\n",
      "          [[ 5.7350e-03,  5.0418e-03,  5.4315e-03],\n",
      "           [ 1.1759e-02, -2.4321e-02,  6.7064e-03],\n",
      "           [ 1.3755e-03,  2.4676e-02, -6.8722e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.5999e-02, -6.5991e-03,  1.5903e-02],\n",
      "           [-8.1155e-03, -1.7441e-02,  9.3227e-03],\n",
      "           [-2.4845e-02, -1.5456e-02,  1.1753e-02]],\n",
      "\n",
      "          [[-1.8850e-02,  1.8235e-02,  1.1288e-02],\n",
      "           [ 9.0076e-03,  6.6859e-03,  1.1467e-02],\n",
      "           [-2.5372e-02,  4.8491e-03,  1.1371e-02]],\n",
      "\n",
      "          [[ 2.0394e-02,  1.5467e-02, -3.0251e-03],\n",
      "           [-2.0105e-02,  8.9491e-03, -9.8627e-03],\n",
      "           [-8.6626e-03,  1.6367e-02,  6.3601e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.3844e-03, -1.0979e-02,  1.1404e-02],\n",
      "           [-6.8060e-04,  8.7551e-03, -1.6903e-02],\n",
      "           [-1.3873e-02, -7.8858e-03, -1.4647e-02]],\n",
      "\n",
      "          [[ 6.7742e-03,  1.1000e-02, -1.8428e-02],\n",
      "           [-4.9109e-03,  2.0376e-02,  9.8023e-03],\n",
      "           [ 1.0335e-02, -6.0422e-03, -4.0819e-03]],\n",
      "\n",
      "          [[ 1.4136e-02, -1.7541e-02, -5.6581e-03],\n",
      "           [ 5.5043e-03,  7.4514e-03, -2.3446e-02],\n",
      "           [ 1.8712e-02,  3.2881e-03, -1.9438e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.7263e-02, -2.7721e-02, -7.5265e-03],\n",
      "           [-2.2323e-02,  7.5396e-03, -5.0988e-03],\n",
      "           [ 1.3232e-03,  3.0581e-03,  1.8464e-02]],\n",
      "\n",
      "          [[ 1.1599e-02, -2.9682e-02, -1.4599e-02],\n",
      "           [ 3.2883e-03, -1.9236e-03,  2.4277e-03],\n",
      "           [-2.6246e-03,  3.5012e-03, -8.4683e-03]],\n",
      "\n",
      "          [[ 6.4358e-03, -2.6495e-03,  2.9594e-03],\n",
      "           [ 1.0523e-02,  8.1700e-03, -1.1969e-02],\n",
      "           [ 1.6194e-02,  7.2991e-03, -1.0910e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.7849e-02,  8.1842e-03, -1.6841e-03],\n",
      "           [ 5.5874e-03, -8.1499e-04,  6.4426e-03],\n",
      "           [-5.5743e-03, -5.0549e-03, -1.1693e-02]],\n",
      "\n",
      "          [[-3.6973e-02, -3.9581e-04, -1.1183e-03],\n",
      "           [-1.4472e-02, -3.0128e-02, -3.8625e-03],\n",
      "           [-2.2335e-02,  1.6845e-03, -1.1342e-02]],\n",
      "\n",
      "          [[-2.9566e-02, -4.4943e-02, -2.9961e-02],\n",
      "           [-1.1376e-03, -3.0886e-03, -1.0305e-02],\n",
      "           [-1.1949e-02, -2.5079e-02, -5.3051e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.7047e-02,  3.4670e-03, -4.5045e-03],\n",
      "           [ 1.0566e-02, -1.2410e-02,  1.6454e-02],\n",
      "           [-1.6484e-02,  4.2095e-03, -3.2523e-03]],\n",
      "\n",
      "          [[ 9.0679e-03, -4.8287e-03, -7.7224e-04],\n",
      "           [ 2.0788e-02,  5.9936e-03,  2.3998e-02],\n",
      "           [-2.5502e-03,  1.3446e-02,  2.5248e-02]],\n",
      "\n",
      "          [[ 1.9304e-03,  9.4778e-03, -1.4533e-02],\n",
      "           [ 2.3460e-02,  3.5827e-02, -2.2448e-03],\n",
      "           [ 2.3924e-02,  4.4644e-02,  1.8778e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 6.2701e-03,  1.5113e-02, -1.0197e-02],\n",
      "           [-2.2206e-02, -8.9921e-03, -1.2633e-02],\n",
      "           [ 1.5085e-02, -1.9789e-03,  9.0446e-03]],\n",
      "\n",
      "          [[-8.5084e-03, -1.1873e-02,  2.4710e-03],\n",
      "           [ 5.6158e-04,  8.8706e-03,  2.8575e-02],\n",
      "           [ 4.5031e-03, -6.3512e-03, -2.6174e-03]],\n",
      "\n",
      "          [[ 2.1534e-02,  1.9884e-02, -1.4482e-03],\n",
      "           [-7.2803e-03,  6.5827e-03,  9.1125e-03],\n",
      "           [ 4.7555e-03, -1.0260e-02,  2.8524e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.8093e-02,  1.1808e-02,  2.0491e-04],\n",
      "           [-1.1299e-02,  2.2881e-03,  1.4395e-02],\n",
      "           [-1.1270e-02,  9.4955e-03,  8.7271e-03]],\n",
      "\n",
      "          [[ 7.0832e-03,  9.7523e-03,  1.4042e-02],\n",
      "           [ 1.9653e-02,  1.7646e-02, -3.1297e-03],\n",
      "           [-7.2236e-04, -4.4175e-03, -2.2014e-02]],\n",
      "\n",
      "          [[ 1.1651e-02,  1.9193e-02, -2.7113e-03],\n",
      "           [ 1.1226e-02,  1.7494e-02,  6.8205e-03],\n",
      "           [-5.8117e-03,  6.7414e-03, -6.6428e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.5262e-02,  2.0089e-02,  1.4883e-03],\n",
      "           [ 1.5551e-03, -2.7965e-03,  5.4399e-03],\n",
      "           [ 2.0660e-02,  3.9859e-02,  2.5065e-02]],\n",
      "\n",
      "          [[ 1.2750e-03,  6.8411e-03,  1.8529e-02],\n",
      "           [-5.6107e-03,  2.7391e-02,  5.2945e-03],\n",
      "           [ 4.1734e-02,  4.3966e-02, -2.8238e-03]],\n",
      "\n",
      "          [[-1.6455e-02,  2.9773e-02,  1.8841e-02],\n",
      "           [ 2.5334e-02,  1.6271e-02,  7.8493e-03],\n",
      "           [ 3.8039e-02,  1.9465e-02,  1.0437e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.6524e-03,  2.7633e-03, -7.7021e-03],\n",
      "           [-3.5865e-03, -5.4467e-04,  2.1740e-03],\n",
      "           [ 5.9074e-03, -4.7978e-03,  1.8669e-02]],\n",
      "\n",
      "          [[ 5.4981e-03, -1.8753e-02,  6.3300e-03],\n",
      "           [-2.5124e-02, -2.9705e-04,  9.6291e-03],\n",
      "           [-2.0925e-02, -2.3865e-02, -1.3240e-02]],\n",
      "\n",
      "          [[-2.9246e-03,  1.7851e-02, -1.2382e-02],\n",
      "           [-2.0403e-02, -1.8038e-03, -1.5725e-02],\n",
      "           [ 1.2002e-02, -2.0861e-02, -1.2930e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.6381e-03,  3.8400e-03,  2.7663e-03],\n",
      "           [ 7.8284e-03, -8.1053e-03, -4.7313e-03],\n",
      "           [ 2.1682e-02,  3.1176e-02, -7.1919e-03]],\n",
      "\n",
      "          [[ 2.6945e-02,  1.9499e-02, -3.7592e-04],\n",
      "           [ 2.2403e-03, -4.3844e-03, -5.7973e-03],\n",
      "           [ 2.7380e-02,  1.4398e-02,  4.6403e-03]],\n",
      "\n",
      "          [[ 2.0701e-02,  1.9719e-02, -7.6973e-03],\n",
      "           [-1.8545e-02, -5.2894e-03, -1.9512e-02],\n",
      "           [-8.8379e-04, -3.9427e-03, -1.1523e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.4873e-02, -3.7484e-03, -2.0439e-02],\n",
      "           [-1.5644e-02, -1.5036e-02, -3.4592e-03],\n",
      "           [-2.6682e-02, -4.9508e-02, -3.7534e-02]],\n",
      "\n",
      "          [[-2.9759e-02, -7.0658e-03,  8.8955e-03],\n",
      "           [-1.3682e-02, -1.5110e-04, -2.9265e-02],\n",
      "           [-3.9811e-02, -4.7184e-03, -2.7609e-02]],\n",
      "\n",
      "          [[-1.9103e-02, -4.6585e-03, -2.2667e-02],\n",
      "           [-3.9105e-02, -1.3400e-02, -4.9799e-03],\n",
      "           [-7.5736e-03, -3.8495e-02, -2.3979e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.6462e-02, -1.1532e-02, -4.0829e-03],\n",
      "           [-1.8745e-02, -2.0139e-02, -3.0650e-03],\n",
      "           [-3.6565e-02, -3.7100e-02, -3.9019e-02]],\n",
      "\n",
      "          [[-2.4612e-02, -6.5759e-03, -1.6465e-02],\n",
      "           [-1.8054e-02,  2.8903e-03, -2.3156e-02],\n",
      "           [-2.7898e-02, -1.2200e-02, -3.1063e-02]],\n",
      "\n",
      "          [[-9.4221e-03, -1.7158e-02, -1.1947e-02],\n",
      "           [-2.0432e-03, -5.3895e-03, -8.6740e-03],\n",
      "           [-3.5600e-03,  9.5146e-03, -2.2661e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.8652e-02, -1.2260e-02, -1.5558e-02],\n",
      "           [-1.1920e-02, -1.1226e-02, -1.5516e-02],\n",
      "           [-1.6489e-02, -3.3876e-03, -2.5217e-02]],\n",
      "\n",
      "          [[-1.4520e-02, -9.9827e-03, -7.4169e-03],\n",
      "           [ 4.5438e-03,  1.2859e-02, -2.3785e-02],\n",
      "           [ 3.7002e-03, -2.0642e-02, -2.5885e-02]],\n",
      "\n",
      "          [[ 9.9909e-03,  6.5398e-03, -2.0699e-02],\n",
      "           [-2.0255e-02,  2.4726e-03, -1.0798e-02],\n",
      "           [-1.7767e-02,  1.1673e-02, -1.0733e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.6233e-02, -1.4436e-03, -1.0451e-02],\n",
      "           [-7.0760e-03,  1.2077e-02, -5.2119e-03],\n",
      "           [-1.7093e-03,  1.5564e-02,  2.1500e-02]],\n",
      "\n",
      "          [[-3.3346e-04,  3.9289e-03,  1.3473e-02],\n",
      "           [ 5.6818e-03, -1.5907e-02,  6.7616e-03],\n",
      "           [ 1.2745e-02,  5.9200e-04,  1.1040e-02]],\n",
      "\n",
      "          [[ 1.1821e-02,  1.0798e-02,  3.5046e-03],\n",
      "           [-1.4778e-02, -9.3827e-03, -6.1282e-03],\n",
      "           [-1.6550e-02,  8.5815e-03,  9.4150e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.2310e-02,  5.7359e-03,  2.9668e-03],\n",
      "           [ 1.3990e-02, -1.3696e-02, -1.9461e-02],\n",
      "           [-1.3611e-02, -9.5945e-03,  1.5705e-02]],\n",
      "\n",
      "          [[ 2.7460e-02,  2.9222e-03,  1.4349e-02],\n",
      "           [ 1.3972e-02,  3.3814e-02,  1.5268e-02],\n",
      "           [ 2.5812e-02,  2.3768e-02,  2.1799e-02]],\n",
      "\n",
      "          [[ 3.5984e-02,  3.0721e-02,  1.5154e-02],\n",
      "           [ 9.1377e-03,  1.8478e-02,  1.7418e-02],\n",
      "           [ 3.3057e-02, -3.8800e-03,  1.4775e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.9040e-02, -6.8121e-03,  8.3484e-03],\n",
      "           [-1.3059e-02, -7.1724e-03,  9.6598e-03],\n",
      "           [-1.7552e-02,  9.4055e-03, -3.9961e-03]],\n",
      "\n",
      "          [[ 5.3396e-03, -9.9494e-03,  7.8107e-04],\n",
      "           [ 9.2839e-03,  2.4151e-03,  4.4522e-03],\n",
      "           [ 1.2660e-02,  2.3737e-02, -4.9718e-03]],\n",
      "\n",
      "          [[ 3.8331e-02,  2.1918e-02, -1.0311e-03],\n",
      "           [ 3.3117e-02,  2.8439e-04, -1.2949e-02],\n",
      "           [ 7.0443e-03,  7.6026e-03,  7.4147e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1286e-03,  1.3795e-02,  4.1750e-02],\n",
      "           [ 1.2584e-02,  4.3472e-03,  3.3416e-02],\n",
      "           [ 2.1136e-02, -2.3444e-03, -4.1305e-03]],\n",
      "\n",
      "          [[ 2.9694e-02,  8.3503e-03,  3.1392e-02],\n",
      "           [-1.3693e-02,  8.8588e-03,  2.1921e-02],\n",
      "           [-1.1094e-02, -1.3406e-02, -1.6846e-02]],\n",
      "\n",
      "          [[ 3.5372e-03,  1.7204e-02,  1.2362e-02],\n",
      "           [-7.9389e-03,  1.7926e-03, -1.3901e-02],\n",
      "           [ 1.6725e-03,  1.8095e-02, -1.6072e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.5832e-02,  1.8305e-02, -1.4283e-02],\n",
      "           [ 1.2664e-02, -9.2779e-03,  1.9096e-02],\n",
      "           [-8.7557e-03, -6.8329e-03,  4.3999e-03]],\n",
      "\n",
      "          [[ 1.2208e-03, -1.4758e-02, -1.8616e-02],\n",
      "           [ 6.7556e-03,  2.0482e-02,  6.5017e-03],\n",
      "           [ 1.5997e-02,  2.0801e-03,  2.0433e-04]],\n",
      "\n",
      "          [[ 1.7241e-02, -2.7201e-02,  1.2436e-02],\n",
      "           [-2.1059e-02, -1.4400e-02, -2.7402e-02],\n",
      "           [ 5.3007e-03,  1.1214e-02, -1.5930e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0350e-02, -1.1441e-02, -8.1253e-03],\n",
      "           [-1.4990e-02,  1.3698e-02, -1.0179e-02],\n",
      "           [ 1.3183e-03,  2.0622e-02,  2.5864e-02]],\n",
      "\n",
      "          [[ 1.2061e-02, -3.8628e-03,  1.0627e-02],\n",
      "           [-1.3852e-02,  1.2826e-05, -1.0402e-02],\n",
      "           [ 7.0069e-03,  1.0893e-02, -2.5484e-03]],\n",
      "\n",
      "          [[-7.0469e-03,  5.1855e-03, -2.9750e-03],\n",
      "           [-1.0346e-02, -1.6903e-02, -1.0733e-02],\n",
      "           [ 1.4664e-02, -1.5702e-02,  3.3647e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.1838e-02, -2.8276e-02, -1.8959e-02],\n",
      "           [-5.2383e-03,  4.5304e-03,  4.1197e-03],\n",
      "           [-2.2753e-02, -1.8992e-02,  1.3296e-02]],\n",
      "\n",
      "          [[-3.1107e-03,  1.4551e-02, -1.6065e-02],\n",
      "           [-4.2546e-03, -6.2006e-03, -1.1163e-02],\n",
      "           [-1.9037e-02, -1.8932e-02, -6.2662e-04]],\n",
      "\n",
      "          [[-1.6871e-03,  1.8502e-02, -6.8579e-03],\n",
      "           [-2.5484e-03,  1.1348e-02,  2.3478e-03],\n",
      "           [-1.9786e-02, -3.2427e-02, -9.9850e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.5817e-03,  2.5698e-02, -1.5422e-02],\n",
      "           [-5.8568e-03, -1.5235e-03,  2.6245e-02],\n",
      "           [ 2.2998e-05, -2.5007e-03, -8.9787e-03]],\n",
      "\n",
      "          [[-1.2332e-02,  1.2433e-02, -1.7431e-02],\n",
      "           [-1.7871e-02,  1.0288e-02, -1.7174e-02],\n",
      "           [-1.5654e-02, -1.8315e-02, -2.5845e-02]],\n",
      "\n",
      "          [[-1.4392e-02, -7.9292e-03, -3.0336e-03],\n",
      "           [ 1.9620e-03, -2.7020e-02, -5.4219e-03],\n",
      "           [-3.3860e-04,  5.9233e-04, -2.2833e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.1640e-02,  2.1026e-02, -1.1106e-02],\n",
      "           [ 2.8836e-03,  1.5969e-02,  1.0088e-03],\n",
      "           [-2.1227e-02, -5.8375e-03, -1.9031e-02]],\n",
      "\n",
      "          [[-1.4076e-02,  8.1918e-03,  1.3949e-02],\n",
      "           [ 9.0956e-03,  1.6123e-02,  2.2950e-02],\n",
      "           [-1.3355e-02, -1.1191e-02, -7.8992e-03]],\n",
      "\n",
      "          [[-3.1729e-02, -1.3225e-02, -1.5544e-02],\n",
      "           [ 2.3755e-03,  1.0844e-02,  4.0679e-03],\n",
      "           [-2.6879e-02,  6.8558e-03,  1.1786e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.2608e-03,  2.8460e-02,  3.0566e-02],\n",
      "           [ 2.6261e-02, -2.8397e-04,  3.0948e-02],\n",
      "           [ 1.6216e-02,  3.6516e-02,  4.5084e-02]],\n",
      "\n",
      "          [[ 2.3919e-02,  1.1394e-02,  3.2001e-02],\n",
      "           [ 8.0907e-03,  1.1045e-02,  1.9060e-02],\n",
      "           [ 5.3595e-02,  1.8658e-02,  2.3749e-02]],\n",
      "\n",
      "          [[-1.9985e-02, -1.3755e-02,  2.5826e-02],\n",
      "           [ 3.6001e-04, -1.8457e-03, -1.0454e-02],\n",
      "           [ 1.0796e-02,  2.5738e-02,  2.1721e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.2446e-03,  3.5940e-03,  2.0348e-02],\n",
      "           [ 7.0643e-03,  8.8636e-03,  1.4977e-02],\n",
      "           [ 1.8427e-02, -2.6441e-03,  1.3075e-02]],\n",
      "\n",
      "          [[-4.1937e-03, -1.8836e-02,  4.3566e-03],\n",
      "           [ 1.2829e-02,  2.0275e-02,  4.0252e-03],\n",
      "           [ 3.0484e-02,  2.2290e-02,  2.0286e-03]],\n",
      "\n",
      "          [[-8.3976e-03,  4.6322e-03,  4.6982e-06],\n",
      "           [-1.8005e-02, -1.9799e-02,  5.3342e-05],\n",
      "           [ 5.8886e-04,  2.1370e-03, -2.0092e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.7436e-03,  6.2225e-03,  1.4323e-02],\n",
      "           [ 1.6899e-02,  2.1291e-02, -1.0421e-02],\n",
      "           [ 1.6044e-02,  1.4553e-02,  2.1527e-02]],\n",
      "\n",
      "          [[-8.9431e-03, -3.5407e-03,  6.3151e-03],\n",
      "           [ 1.4004e-02, -2.3226e-02,  1.4647e-02],\n",
      "           [-7.4965e-03, -4.3507e-03,  2.8366e-02]],\n",
      "\n",
      "          [[ 1.2760e-02,  3.3302e-03,  1.0094e-02],\n",
      "           [ 2.2326e-02,  2.2235e-03,  2.6308e-02],\n",
      "           [ 7.8303e-03,  2.3302e-02,  1.7970e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.1876e-03,  8.8609e-03, -6.8791e-03],\n",
      "           [-2.2636e-02, -6.3227e-03, -1.8147e-02],\n",
      "           [ 6.5348e-03, -2.5846e-02, -3.2816e-02]],\n",
      "\n",
      "          [[ 6.5549e-03,  1.9510e-02, -1.9171e-02],\n",
      "           [-1.6787e-02, -7.5656e-03,  7.2801e-03],\n",
      "           [-8.4421e-03,  9.8083e-03, -2.7705e-02]],\n",
      "\n",
      "          [[ 1.2366e-02,  1.8492e-02, -5.5975e-03],\n",
      "           [ 5.4143e-03, -4.2736e-03,  3.0082e-04],\n",
      "           [ 1.4585e-02, -3.2382e-02, -4.1874e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.9270e-03, -1.3108e-02,  5.5000e-03],\n",
      "           [ 1.6525e-02,  7.9145e-03,  2.0126e-02],\n",
      "           [-1.5028e-02,  2.6571e-02, -1.1585e-02]],\n",
      "\n",
      "          [[-7.7142e-03,  6.5605e-03,  1.3900e-02],\n",
      "           [-1.5318e-02,  1.4885e-02,  3.0784e-03],\n",
      "           [ 2.0501e-02,  2.3380e-02, -1.6167e-02]],\n",
      "\n",
      "          [[ 7.2968e-03,  2.3785e-02,  8.9905e-04],\n",
      "           [ 1.6532e-02, -1.7089e-02,  9.5258e-04],\n",
      "           [-1.9479e-02,  2.7484e-03,  9.4845e-04]]],\n",
      "\n",
      "\n",
      "         [[[ 2.7844e-03, -2.0773e-03,  1.2698e-02],\n",
      "           [-2.6508e-02, -1.8556e-04,  2.0540e-02],\n",
      "           [-2.7590e-02, -1.9625e-02,  1.4658e-02]],\n",
      "\n",
      "          [[-1.3983e-02, -1.4397e-02,  6.3630e-03],\n",
      "           [-2.2598e-02,  1.1152e-02,  8.0013e-03],\n",
      "           [-1.5538e-02, -2.1668e-02,  9.3397e-03]],\n",
      "\n",
      "          [[-3.8237e-02, -1.7970e-02,  1.0863e-02],\n",
      "           [-2.6208e-03,  2.5932e-03,  2.2503e-02],\n",
      "           [-1.7901e-03, -1.4274e-02,  1.5900e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.3318e-02,  2.4435e-02,  1.7145e-02],\n",
      "           [ 1.6347e-02,  1.4554e-02,  5.4771e-03],\n",
      "           [ 2.0106e-02,  2.4871e-02,  3.7658e-02]],\n",
      "\n",
      "          [[-8.8680e-04, -3.6323e-03, -6.3722e-04],\n",
      "           [ 6.3448e-03,  1.5081e-02,  2.6882e-02],\n",
      "           [ 4.4773e-02,  3.6003e-02,  1.0982e-02]],\n",
      "\n",
      "          [[ 8.7607e-03, -7.3783e-03,  1.4820e-02],\n",
      "           [ 2.9269e-02,  2.2273e-02,  2.2205e-02],\n",
      "           [ 1.9314e-02,  5.2510e-02,  1.2678e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.6271e-03,  1.9885e-02,  1.6578e-02],\n",
      "           [ 1.1115e-02,  8.4978e-03, -6.2194e-03],\n",
      "           [-7.6875e-03, -2.0583e-03, -2.2719e-02]],\n",
      "\n",
      "          [[-8.5874e-04, -1.6678e-02,  2.0664e-02],\n",
      "           [-8.6412e-04,  1.1996e-02,  1.6583e-02],\n",
      "           [ 2.8739e-02,  1.9640e-02, -1.8185e-02]],\n",
      "\n",
      "          [[-7.9300e-03, -2.9728e-03,  1.4629e-02],\n",
      "           [-1.2641e-02, -6.2548e-03, -2.6778e-02],\n",
      "           [ 2.6038e-02,  4.7506e-03, -2.4523e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.9579e-02,  2.2742e-03,  1.4126e-02],\n",
      "           [-1.3987e-02,  2.1905e-02,  1.5683e-02],\n",
      "           [ 4.3360e-03, -3.7344e-03, -3.2889e-03]],\n",
      "\n",
      "          [[ 1.4660e-03, -8.2531e-03,  3.3614e-03],\n",
      "           [-8.5759e-03, -1.5062e-02,  6.9958e-03],\n",
      "           [ 1.0365e-02,  1.8240e-02,  2.1152e-02]],\n",
      "\n",
      "          [[ 2.0991e-02,  1.5942e-02,  8.1047e-03],\n",
      "           [-8.6496e-03, -1.2667e-02,  1.1546e-02],\n",
      "           [-1.8227e-02,  1.7330e-02,  1.3178e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 9.3584e-03, -1.2256e-03,  4.2506e-03],\n",
      "           [ 6.8722e-03,  1.5856e-02, -1.7645e-02],\n",
      "           [-2.8330e-02, -1.0179e-02, -1.5455e-02]],\n",
      "\n",
      "          [[-7.1972e-03,  4.3066e-03,  3.3861e-04],\n",
      "           [-2.0115e-02, -2.5275e-02, -1.4891e-03],\n",
      "           [-2.0123e-04, -3.6068e-02, -1.6227e-02]],\n",
      "\n",
      "          [[-4.8417e-03,  1.4028e-02, -2.0576e-02],\n",
      "           [ 7.3504e-03, -2.5591e-02,  1.0719e-03],\n",
      "           [-2.6934e-02, -3.9248e-02, -1.5852e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-5.8236e-03,  1.5122e-02, -8.1282e-03],\n",
      "           [-8.7705e-03,  2.4970e-02,  1.3328e-02],\n",
      "           [-1.6388e-02,  1.4524e-02, -8.7283e-03]],\n",
      "\n",
      "          [[-2.5723e-05, -5.5982e-03, -1.4758e-02],\n",
      "           [ 1.5016e-02,  1.9534e-02,  4.6119e-03],\n",
      "           [ 2.3723e-02, -5.4239e-03, -2.5824e-02]],\n",
      "\n",
      "          [[-2.1821e-02,  2.6814e-02,  1.1670e-02],\n",
      "           [-2.2814e-04, -6.4117e-03, -3.9772e-03],\n",
      "           [-1.2879e-02, -4.1394e-03,  4.0686e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 6.3060e-03, -1.3777e-02, -1.3907e-02],\n",
      "           [-8.6143e-03,  9.2130e-04,  1.6640e-02],\n",
      "           [ 6.2463e-03,  8.7026e-03,  7.9491e-03]],\n",
      "\n",
      "          [[ 1.1272e-02,  1.5428e-02, -1.1896e-03],\n",
      "           [-1.1719e-02,  1.2374e-02,  2.8695e-02],\n",
      "           [-1.5237e-02, -2.6316e-02, -2.0801e-02]],\n",
      "\n",
      "          [[-4.4339e-03, -4.0631e-04,  8.4892e-03],\n",
      "           [-3.5229e-02,  6.3923e-03,  1.0943e-02],\n",
      "           [-2.1794e-02, -1.5326e-03, -6.8922e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1241e-02,  3.8960e-02,  1.4719e-03],\n",
      "           [ 1.5928e-02,  2.8154e-02,  3.6208e-02],\n",
      "           [ 2.2971e-02,  2.9735e-02,  4.1175e-02]],\n",
      "\n",
      "          [[ 4.7997e-03,  9.9495e-03,  1.9153e-02],\n",
      "           [ 2.2056e-02,  4.3035e-02,  2.3154e-02],\n",
      "           [ 5.4258e-02,  3.9347e-02,  4.2051e-02]],\n",
      "\n",
      "          [[ 1.4242e-02,  1.4584e-02,  4.1255e-02],\n",
      "           [ 3.2641e-04,  1.5263e-02,  2.9444e-03],\n",
      "           [ 4.1652e-02,  4.9424e-02,  2.7135e-02]]]]], device='cuda:0')), ('module.up_layers.0.0.conv2.conv.weight', tensor([[[[[-1.7789e-02, -1.6032e-02,  1.0625e-02],\n",
      "           [-2.7743e-02,  5.3793e-03, -1.0558e-02],\n",
      "           [-2.2271e-02, -6.4475e-03, -4.1426e-02]],\n",
      "\n",
      "          [[-8.0060e-04,  4.1696e-03, -1.1902e-02],\n",
      "           [-2.5990e-02, -4.3859e-04,  6.7217e-03],\n",
      "           [-4.2768e-02, -1.0333e-02, -2.7335e-03]],\n",
      "\n",
      "          [[-3.7161e-02, -1.2901e-02, -3.9479e-02],\n",
      "           [-3.8524e-02, -1.1355e-02, -3.7453e-02],\n",
      "           [-3.0237e-02, -2.1242e-02, -2.0065e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.1764e-02,  5.3874e-03, -5.6563e-03],\n",
      "           [-1.9988e-02,  7.7061e-03,  1.0904e-02],\n",
      "           [ 2.1042e-03,  1.5066e-02, -2.0896e-03]],\n",
      "\n",
      "          [[-8.3104e-03, -1.4905e-02,  1.8970e-02],\n",
      "           [-1.0247e-02, -2.1331e-03,  3.6282e-03],\n",
      "           [-6.5135e-04, -1.3766e-02,  1.6821e-02]],\n",
      "\n",
      "          [[ 1.3391e-03, -1.4121e-02, -3.4837e-04],\n",
      "           [-1.9010e-02, -1.0848e-02,  4.9202e-03],\n",
      "           [ 1.1464e-02, -8.5964e-04,  1.2417e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 6.8182e-03, -1.2096e-02, -1.2551e-02],\n",
      "           [ 1.0629e-02, -8.1991e-03, -5.3328e-03],\n",
      "           [ 9.6275e-03, -6.3128e-03, -7.0525e-03]],\n",
      "\n",
      "          [[ 2.0487e-02,  1.7534e-03,  4.0037e-03],\n",
      "           [ 2.0305e-02,  1.4597e-02, -9.6902e-03],\n",
      "           [ 7.1460e-03,  1.6816e-02,  1.7738e-02]],\n",
      "\n",
      "          [[ 1.0097e-02,  8.1234e-03,  1.1489e-06],\n",
      "           [ 1.9772e-02,  1.5047e-02,  5.3712e-03],\n",
      "           [ 2.8099e-02,  1.3839e-02,  5.8412e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0991e-02, -2.2926e-02, -7.1341e-03],\n",
      "           [-1.3189e-02,  1.4776e-02, -1.5040e-02],\n",
      "           [-2.9201e-02,  4.0797e-03, -6.3607e-03]],\n",
      "\n",
      "          [[-2.9892e-03,  1.2298e-02, -2.4799e-02],\n",
      "           [ 1.4093e-02, -1.9230e-02,  1.6696e-03],\n",
      "           [-3.0584e-02, -1.6180e-02, -3.1336e-03]],\n",
      "\n",
      "          [[-2.1143e-03, -2.6186e-03,  7.1110e-03],\n",
      "           [ 1.1776e-02, -1.7940e-02, -2.5632e-03],\n",
      "           [-2.6008e-02, -2.0430e-02, -4.0970e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.2463e-03,  5.3267e-03,  7.4356e-03],\n",
      "           [ 1.8961e-02, -1.0601e-03, -2.2405e-02],\n",
      "           [-2.7457e-03,  1.1091e-02, -1.8793e-03]],\n",
      "\n",
      "          [[ 9.2051e-04,  1.1074e-02, -2.2724e-02],\n",
      "           [ 3.6026e-03, -1.3823e-02, -1.1328e-02],\n",
      "           [-3.0609e-02,  7.5550e-03, -5.2687e-03]],\n",
      "\n",
      "          [[-1.2622e-02, -1.6881e-02, -1.9529e-02],\n",
      "           [ 2.9273e-03,  6.2971e-03,  1.1419e-03],\n",
      "           [-1.1788e-02, -2.6348e-02, -2.3802e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3107e-02, -9.9413e-03,  9.1331e-06],\n",
      "           [ 1.2094e-02,  1.7299e-02,  5.9877e-03],\n",
      "           [-1.3678e-02,  4.5179e-03, -6.5990e-03]],\n",
      "\n",
      "          [[ 1.6204e-02,  1.5524e-02,  7.0102e-03],\n",
      "           [-1.3820e-02,  4.3850e-03, -2.1573e-02],\n",
      "           [-7.5212e-03, -2.1814e-02, -2.4563e-02]],\n",
      "\n",
      "          [[ 1.3007e-02,  7.3513e-04,  7.6521e-03],\n",
      "           [-8.0524e-03, -1.3533e-02,  2.7980e-03],\n",
      "           [-1.2954e-02, -3.1971e-02, -4.1032e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.2001e-02, -6.8795e-03, -9.2476e-03],\n",
      "           [ 1.8286e-02, -1.1533e-02,  3.3524e-03],\n",
      "           [ 2.3721e-03, -2.3335e-02, -1.2163e-02]],\n",
      "\n",
      "          [[ 1.9933e-02, -6.7671e-03, -7.8270e-04],\n",
      "           [ 1.7306e-02, -3.4537e-05, -3.2238e-03],\n",
      "           [ 3.2145e-03, -7.6562e-03, -1.5518e-02]],\n",
      "\n",
      "          [[-4.3092e-03,  1.2354e-02,  2.1756e-02],\n",
      "           [ 1.2539e-02,  2.5450e-03,  1.2415e-02],\n",
      "           [ 1.8700e-02,  7.5518e-04,  1.4142e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2752e-02, -3.1640e-02, -8.7388e-03],\n",
      "           [-9.3135e-03, -2.2966e-02, -3.8392e-03],\n",
      "           [-1.7489e-02, -2.4535e-02, -1.6259e-02]],\n",
      "\n",
      "          [[-3.8751e-02, -1.2619e-03,  4.6043e-03],\n",
      "           [-1.4605e-02, -1.5439e-02, -1.1829e-02],\n",
      "           [-1.4416e-02,  4.0692e-03, -8.2923e-03]],\n",
      "\n",
      "          [[-9.7937e-03, -7.2383e-03, -1.3181e-02],\n",
      "           [-2.2228e-02,  6.8431e-03, -8.5386e-04],\n",
      "           [-1.7487e-02, -1.2869e-02, -1.3936e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3519e-02,  1.7846e-03, -5.7660e-03],\n",
      "           [ 2.2886e-03, -1.8117e-02, -1.8664e-02],\n",
      "           [-7.9163e-03, -5.2292e-04, -3.2469e-02]],\n",
      "\n",
      "          [[ 2.4417e-03,  1.0667e-02, -1.7733e-02],\n",
      "           [ 1.1512e-02, -1.0369e-02, -1.2269e-02],\n",
      "           [-1.9061e-02, -2.7913e-03, -1.6162e-02]],\n",
      "\n",
      "          [[-1.0358e-02, -2.0276e-02, -2.0011e-02],\n",
      "           [ 4.0224e-03, -4.3003e-03, -2.3194e-02],\n",
      "           [ 1.0013e-03,  1.6453e-03, -1.1116e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.4033e-02,  1.3504e-02, -1.4870e-02],\n",
      "           [ 8.5365e-03, -9.7774e-03,  8.4474e-03],\n",
      "           [ 1.3390e-03, -1.7447e-02,  1.0503e-02]],\n",
      "\n",
      "          [[-7.2550e-03,  3.5272e-03, -2.4356e-02],\n",
      "           [ 9.4527e-03, -6.2908e-03, -5.7334e-03],\n",
      "           [-1.2607e-02, -1.1146e-02, -8.0650e-03]],\n",
      "\n",
      "          [[ 1.9578e-02,  1.1987e-02, -5.3227e-03],\n",
      "           [ 2.0841e-02, -6.8732e-03,  9.9846e-03],\n",
      "           [ 1.3539e-02,  1.6806e-02,  1.4931e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0024e-02,  1.4713e-02, -2.3500e-02],\n",
      "           [ 2.0484e-02,  3.9258e-03, -3.8423e-04],\n",
      "           [ 1.5000e-02,  3.0732e-03,  1.1690e-02]],\n",
      "\n",
      "          [[ 8.2691e-03, -2.9447e-03,  7.8022e-03],\n",
      "           [ 1.1308e-02, -2.3804e-02, -7.0907e-03],\n",
      "           [ 3.9683e-03,  1.3956e-02,  1.8021e-02]],\n",
      "\n",
      "          [[ 2.6779e-02, -9.4183e-03,  4.9858e-03],\n",
      "           [ 4.5883e-03, -2.0118e-03,  1.1555e-02],\n",
      "           [ 6.7861e-03,  3.4495e-04, -6.4258e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4028e-02,  1.0884e-02, -2.1007e-02],\n",
      "           [ 1.4824e-02, -1.8153e-02, -3.8351e-04],\n",
      "           [-2.4693e-03, -1.5150e-02, -9.8017e-03]],\n",
      "\n",
      "          [[ 1.0748e-02, -6.6503e-03, -1.3474e-02],\n",
      "           [ 9.2924e-03, -4.0639e-03, -7.5708e-03],\n",
      "           [-1.3526e-02,  1.5605e-02,  1.7552e-02]],\n",
      "\n",
      "          [[ 7.5115e-04,  2.2074e-02,  1.3272e-02],\n",
      "           [-4.6270e-03, -2.5066e-03,  1.5452e-02],\n",
      "           [-1.4949e-02,  5.5890e-03, -1.6213e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.3419e-02,  1.9765e-02, -3.6481e-03],\n",
      "           [ 2.3283e-02, -4.3764e-03, -4.4863e-03],\n",
      "           [ 3.5921e-02,  1.0255e-02,  1.6884e-02]],\n",
      "\n",
      "          [[ 3.8665e-02,  2.8865e-02,  2.8722e-02],\n",
      "           [ 3.9519e-02,  2.0367e-02, -8.9073e-04],\n",
      "           [ 3.1346e-02,  1.6899e-03, -1.3440e-02]],\n",
      "\n",
      "          [[ 3.7604e-02,  1.6184e-02,  3.9272e-02],\n",
      "           [ 1.6155e-02,  3.2876e-02,  1.8573e-02],\n",
      "           [ 4.2515e-02, -2.8213e-03,  1.9419e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2031e-02,  2.9991e-03, -1.3680e-02],\n",
      "           [ 1.0918e-02,  1.4722e-02, -4.3295e-03],\n",
      "           [-1.6980e-03, -3.4592e-03,  1.0182e-02]],\n",
      "\n",
      "          [[ 4.5781e-03, -8.2262e-03, -4.1469e-03],\n",
      "           [-1.6055e-02, -3.3488e-03,  7.9648e-04],\n",
      "           [-7.1388e-03, -6.8864e-03, -2.1749e-02]],\n",
      "\n",
      "          [[ 8.1373e-03,  1.5288e-02,  1.0310e-02],\n",
      "           [-1.1447e-02, -9.5944e-03, -2.0970e-02],\n",
      "           [-1.5995e-02, -1.8153e-02, -3.3101e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.5150e-03, -9.5986e-03, -3.1342e-02],\n",
      "           [-8.4472e-05, -5.8424e-03,  1.7072e-03],\n",
      "           [-1.8053e-03,  1.2333e-02,  4.4343e-03]],\n",
      "\n",
      "          [[-6.7823e-03, -1.5495e-02, -3.0636e-03],\n",
      "           [ 9.3155e-03, -1.1376e-02,  1.2667e-02],\n",
      "           [-1.9732e-02, -3.1900e-03, -1.4258e-02]],\n",
      "\n",
      "          [[ 8.4081e-03,  1.4718e-02,  1.9154e-02],\n",
      "           [-3.6260e-03,  1.2332e-02, -5.4302e-03],\n",
      "           [-7.3852e-03, -7.4565e-04, -8.8407e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-8.7122e-03,  2.6577e-02, -6.4722e-03],\n",
      "           [ 2.6015e-02,  2.5503e-02, -4.2016e-03],\n",
      "           [ 3.5415e-02,  3.8431e-02,  2.3090e-02]],\n",
      "\n",
      "          [[ 9.4258e-03,  9.9884e-03,  6.6478e-03],\n",
      "           [ 2.6402e-02,  1.7999e-02, -1.1282e-02],\n",
      "           [ 1.8068e-02,  3.1695e-02,  7.2066e-03]],\n",
      "\n",
      "          [[ 4.1685e-03,  3.7168e-02,  8.5167e-04],\n",
      "           [ 3.0758e-02,  6.5508e-03,  1.2984e-02],\n",
      "           [ 2.2789e-02,  2.9191e-02,  2.4914e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.7213e-03,  1.0813e-02, -2.3396e-03],\n",
      "           [ 1.7023e-03, -1.1723e-03,  3.3463e-02],\n",
      "           [ 5.4617e-03,  3.2244e-02,  3.0672e-02]],\n",
      "\n",
      "          [[-1.5831e-03,  2.8914e-02, -1.7513e-03],\n",
      "           [ 2.5233e-02,  4.7327e-03, -3.4555e-03],\n",
      "           [ 2.4075e-02, -4.0491e-03,  2.4759e-02]],\n",
      "\n",
      "          [[ 2.2576e-02,  2.0747e-03,  1.0241e-02],\n",
      "           [ 2.0002e-02,  2.4901e-02,  1.2777e-02],\n",
      "           [ 2.4059e-02,  6.5226e-03,  9.9157e-03]]],\n",
      "\n",
      "\n",
      "         [[[-8.2430e-03, -7.3033e-03,  2.9303e-02],\n",
      "           [ 9.0813e-03,  1.0467e-02,  3.2695e-02],\n",
      "           [ 3.1699e-02,  1.2507e-02,  3.0829e-02]],\n",
      "\n",
      "          [[ 3.4846e-02, -7.2539e-04,  6.7375e-03],\n",
      "           [ 7.9705e-03,  2.6904e-02, -6.9873e-03],\n",
      "           [ 4.8674e-03,  3.6181e-02,  3.2540e-02]],\n",
      "\n",
      "          [[ 3.8660e-02,  3.1918e-02,  3.2726e-02],\n",
      "           [ 3.1973e-02,  2.7607e-02, -9.0968e-03],\n",
      "           [ 1.0215e-02, -1.1908e-02,  1.7844e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1141e-03, -9.0326e-04,  6.6398e-03],\n",
      "           [-5.3726e-03,  9.6835e-03,  8.6537e-03],\n",
      "           [ 8.9688e-03, -5.9743e-03, -2.3957e-03]],\n",
      "\n",
      "          [[-6.6061e-03, -1.4630e-02, -8.6510e-03],\n",
      "           [ 2.3028e-02,  6.1849e-03,  3.2479e-02],\n",
      "           [ 1.9295e-02, -1.5876e-02, -3.6368e-03]],\n",
      "\n",
      "          [[ 1.8708e-03,  2.0404e-02,  6.5862e-03],\n",
      "           [ 2.4381e-02, -1.2514e-02,  2.5241e-02],\n",
      "           [-1.2188e-02,  1.4480e-03,  1.7098e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.2841e-03,  1.1996e-02, -8.5931e-03],\n",
      "           [-4.0325e-04,  1.2742e-03,  7.6897e-03],\n",
      "           [-9.1310e-03,  1.3872e-02, -1.2616e-02]],\n",
      "\n",
      "          [[ 1.1716e-02,  4.6475e-03,  1.5280e-02],\n",
      "           [ 3.5521e-03,  1.6339e-02, -1.0784e-02],\n",
      "           [ 7.8237e-03,  5.9286e-03,  1.6805e-02]],\n",
      "\n",
      "          [[-5.9206e-03,  8.3410e-03,  4.1380e-03],\n",
      "           [-1.9925e-02,  1.1095e-03, -1.0631e-02],\n",
      "           [-3.5311e-03,  1.5432e-02,  1.7259e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.5701e-03,  1.6496e-02,  5.4526e-03],\n",
      "           [ 1.8477e-02,  1.6044e-02,  6.6351e-03],\n",
      "           [ 5.9381e-03, -1.0962e-02,  3.4328e-03]],\n",
      "\n",
      "          [[-6.5989e-03,  9.6082e-04,  8.1934e-03],\n",
      "           [ 1.2495e-02,  6.4687e-03, -1.5531e-02],\n",
      "           [-2.3478e-03, -1.4203e-02,  1.0042e-03]],\n",
      "\n",
      "          [[ 4.2383e-03,  4.8557e-03, -1.1383e-02],\n",
      "           [ 1.6869e-02, -2.1649e-04,  7.3676e-04],\n",
      "           [ 2.0873e-02, -1.3016e-02, -7.5399e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.2680e-02, -1.2456e-02,  8.6351e-03],\n",
      "           [-1.1610e-03, -7.9491e-03,  1.8915e-02],\n",
      "           [-3.5510e-03, -9.1643e-03,  1.0220e-02]],\n",
      "\n",
      "          [[ 1.6928e-02, -1.4190e-02, -3.3098e-03],\n",
      "           [ 7.3506e-03,  7.3464e-03,  1.1711e-02],\n",
      "           [ 1.9537e-02,  1.9919e-02,  5.9754e-03]],\n",
      "\n",
      "          [[ 7.2043e-05, -1.3434e-02,  1.9900e-02],\n",
      "           [-1.8426e-02, -8.8494e-03, -9.2631e-03],\n",
      "           [-2.3376e-02, -1.1089e-02,  2.5647e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.5818e-02,  1.8540e-02, -3.3683e-03],\n",
      "           [ 1.3056e-02, -1.9498e-03,  8.1524e-03],\n",
      "           [-2.7373e-03,  1.7084e-02,  8.4320e-04]],\n",
      "\n",
      "          [[-3.8494e-03, -2.2530e-02,  6.8492e-04],\n",
      "           [ 9.1094e-03,  8.8861e-05,  1.6912e-02],\n",
      "           [ 1.1689e-02,  2.1260e-02, -2.3407e-04]],\n",
      "\n",
      "          [[ 6.8561e-03, -8.1066e-04,  1.1463e-02],\n",
      "           [-1.5108e-02,  2.5136e-02, -1.0878e-02],\n",
      "           [ 2.8145e-03, -1.9604e-02,  9.9829e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.1955e-03, -1.9229e-02,  5.0661e-03],\n",
      "           [ 1.1836e-02,  1.4844e-02, -2.2456e-02],\n",
      "           [ 1.4702e-04,  4.6240e-04, -7.7332e-03]],\n",
      "\n",
      "          [[-3.8087e-03, -2.3851e-02, -1.0618e-02],\n",
      "           [-8.9868e-03,  1.9907e-02,  5.5956e-03],\n",
      "           [ 1.5522e-02,  2.5812e-03, -2.4612e-03]],\n",
      "\n",
      "          [[-8.5718e-03, -1.1571e-02, -1.2864e-02],\n",
      "           [-2.0971e-02,  1.5289e-02,  2.3117e-02],\n",
      "           [-2.3235e-02,  7.8532e-03,  5.2217e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.6306e-02, -2.9889e-02, -3.6841e-02],\n",
      "           [-3.1536e-02,  1.0529e-02, -2.8784e-02],\n",
      "           [-1.4715e-02, -1.3541e-02, -1.3979e-02]],\n",
      "\n",
      "          [[ 1.3028e-02,  4.9036e-03, -3.2821e-02],\n",
      "           [-1.2725e-02, -2.1710e-02, -3.0810e-02],\n",
      "           [ 1.0832e-02, -9.6141e-04,  1.3406e-02]],\n",
      "\n",
      "          [[ 3.2186e-02, -2.4738e-03, -1.6751e-02],\n",
      "           [ 2.1392e-02, -3.5612e-03, -2.3446e-02],\n",
      "           [ 8.3954e-03, -2.1922e-02, -2.4668e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.4507e-03, -2.8942e-02, -2.8266e-02],\n",
      "           [-1.6566e-03, -1.4345e-02, -1.0716e-02],\n",
      "           [ 7.2547e-03,  6.3187e-03, -1.7888e-02]],\n",
      "\n",
      "          [[-2.2292e-02, -2.7533e-02,  9.2938e-03],\n",
      "           [ 1.3086e-02,  1.1643e-02,  1.9765e-02],\n",
      "           [ 1.6694e-04,  1.8298e-02, -1.2665e-02]],\n",
      "\n",
      "          [[-1.1190e-02, -1.1509e-02, -5.0498e-03],\n",
      "           [ 1.7793e-03,  9.3865e-03, -1.1197e-02],\n",
      "           [ 7.3773e-03,  2.2245e-02,  3.4549e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.4937e-02,  2.8645e-02,  2.9878e-02],\n",
      "           [-9.5140e-03,  1.7515e-02, -2.2398e-03],\n",
      "           [-1.4607e-02, -1.0653e-02, -7.5166e-03]],\n",
      "\n",
      "          [[ 2.6137e-02,  7.2034e-03, -3.6853e-03],\n",
      "           [-6.2810e-03, -8.4977e-03, -1.4613e-02],\n",
      "           [-2.6528e-02, -1.4570e-02, -1.9047e-02]],\n",
      "\n",
      "          [[ 9.7267e-03,  1.6476e-02, -1.9400e-03],\n",
      "           [-4.6255e-03, -1.0670e-03, -1.7230e-02],\n",
      "           [-2.4455e-02, -2.4816e-02, -2.8308e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.0737e-02, -1.6807e-02, -2.6502e-04],\n",
      "           [ 6.6548e-03, -1.7975e-02, -1.2322e-02],\n",
      "           [-1.3186e-02, -2.4952e-03,  7.6300e-03]],\n",
      "\n",
      "          [[ 2.2181e-02, -9.4868e-03, -8.6966e-03],\n",
      "           [ 2.5061e-03, -1.1104e-02,  1.5168e-02],\n",
      "           [ 8.9582e-03,  6.5494e-03, -5.7218e-03]],\n",
      "\n",
      "          [[ 2.1211e-02,  1.4347e-02, -3.1322e-03],\n",
      "           [-9.6298e-03, -1.8208e-02,  1.3039e-02],\n",
      "           [-1.4048e-02, -6.9374e-03,  3.1473e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.2737e-02, -1.0237e-02,  9.3014e-03],\n",
      "           [-9.4903e-03, -2.7638e-02,  5.4332e-03],\n",
      "           [-8.5802e-03,  1.1986e-03,  1.4147e-02]],\n",
      "\n",
      "          [[ 2.7717e-04, -4.9696e-03, -7.4458e-03],\n",
      "           [-2.7435e-02,  1.1197e-02, -1.0876e-02],\n",
      "           [ 1.8081e-02,  5.2733e-03,  4.7903e-03]],\n",
      "\n",
      "          [[-2.5585e-02,  7.3600e-04, -3.1548e-02],\n",
      "           [-2.7960e-02, -1.1366e-02,  1.1694e-02],\n",
      "           [-3.0881e-03, -1.3566e-02, -1.4395e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.5368e-02,  5.3520e-03, -4.4135e-03],\n",
      "           [-8.7645e-04, -1.5134e-02, -6.0381e-03],\n",
      "           [-2.2203e-03, -1.3362e-02, -2.0961e-02]],\n",
      "\n",
      "          [[ 1.0352e-02,  1.1715e-02,  2.0693e-03],\n",
      "           [-3.3255e-03, -9.7562e-03,  1.0107e-03],\n",
      "           [ 1.1110e-02,  1.9521e-02, -1.8901e-02]],\n",
      "\n",
      "          [[-3.6144e-03,  8.8503e-03, -4.2916e-03],\n",
      "           [ 1.8615e-03, -1.8901e-02, -2.1218e-02],\n",
      "           [ 1.8049e-02, -1.9059e-02,  2.1959e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 7.7408e-03, -1.1977e-02, -2.1023e-03],\n",
      "           [-6.3750e-04, -8.7443e-03,  7.1268e-03],\n",
      "           [-8.9640e-03, -9.7649e-04,  3.7043e-03]],\n",
      "\n",
      "          [[-3.7585e-03,  2.0720e-02, -4.1807e-03],\n",
      "           [-4.8872e-03,  1.9562e-02,  1.4632e-02],\n",
      "           [-1.1257e-04,  1.0509e-02,  1.2573e-02]],\n",
      "\n",
      "          [[-1.6835e-02,  1.7773e-03,  4.4140e-03],\n",
      "           [-5.0532e-03, -1.2725e-02,  1.2419e-02],\n",
      "           [ 2.1863e-02,  2.7569e-03, -7.1988e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1338e-02,  7.4537e-03,  2.3122e-03],\n",
      "           [ 1.1199e-03,  1.9338e-02,  3.2229e-03],\n",
      "           [-1.3337e-02,  1.2825e-02, -2.5345e-04]],\n",
      "\n",
      "          [[ 1.5892e-02, -5.9554e-03,  2.0866e-02],\n",
      "           [ 1.4972e-02, -1.0773e-02, -2.4957e-02],\n",
      "           [-1.2299e-02, -1.9606e-02,  6.4855e-03]],\n",
      "\n",
      "          [[ 2.9509e-02, -1.2541e-03,  1.6988e-02],\n",
      "           [-1.7012e-03, -1.1243e-02,  6.8515e-03],\n",
      "           [-1.1642e-02,  4.4646e-03, -2.5305e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.3420e-02, -8.3731e-03, -1.8375e-02],\n",
      "           [-9.1249e-03, -6.1212e-03,  1.3658e-02],\n",
      "           [ 1.1855e-02,  1.4964e-02,  1.8308e-02]],\n",
      "\n",
      "          [[ 6.5071e-03, -1.9194e-02,  2.2461e-02],\n",
      "           [-1.8478e-02, -1.1864e-02,  1.5640e-02],\n",
      "           [ 2.6992e-02,  3.6933e-03,  1.5292e-02]],\n",
      "\n",
      "          [[ 9.0385e-03,  2.6666e-02,  6.4614e-03],\n",
      "           [-1.7833e-02, -1.1756e-02,  8.1851e-03],\n",
      "           [-1.3724e-02,  1.3992e-02,  3.1229e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.2127e-03, -2.3112e-03, -1.4124e-02],\n",
      "           [-1.5896e-02, -1.1479e-02,  1.0700e-02],\n",
      "           [ 7.4073e-03, -1.5195e-02,  6.8158e-03]],\n",
      "\n",
      "          [[ 1.2568e-02,  1.9045e-02,  1.5404e-02],\n",
      "           [-2.2145e-02,  1.9645e-03,  6.4820e-04],\n",
      "           [ 2.3813e-02, -1.5581e-02, -3.4003e-03]],\n",
      "\n",
      "          [[ 8.6151e-03, -1.3306e-02, -7.7557e-04],\n",
      "           [ 1.6429e-02,  1.8915e-02, -2.2549e-02],\n",
      "           [ 1.9043e-02, -4.7070e-03,  8.0416e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.3767e-02, -4.7005e-03,  1.8100e-02],\n",
      "           [-9.6769e-03, -1.8359e-02, -6.7379e-03],\n",
      "           [ 1.3795e-02,  2.4943e-02,  6.5514e-03]],\n",
      "\n",
      "          [[-2.3474e-02,  8.8274e-03,  1.0740e-02],\n",
      "           [-8.3312e-03,  1.8001e-02, -6.5371e-03],\n",
      "           [ 1.9943e-03,  4.2416e-03,  2.1181e-02]],\n",
      "\n",
      "          [[-7.3647e-03, -1.2401e-02, -1.9932e-02],\n",
      "           [ 3.6044e-03,  1.7159e-02, -2.1351e-02],\n",
      "           [-2.8636e-03,  1.0605e-03, -1.8295e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.9016e-02, -1.8621e-02, -1.2465e-02],\n",
      "           [ 3.0336e-04, -1.4762e-03,  1.9001e-02],\n",
      "           [-2.2739e-02,  4.8589e-03,  2.2576e-02]],\n",
      "\n",
      "          [[-7.3707e-03,  1.8746e-02,  1.1636e-02],\n",
      "           [ 1.8942e-03, -1.1569e-02, -1.5425e-02],\n",
      "           [ 2.6133e-02,  2.0861e-02, -1.2412e-02]],\n",
      "\n",
      "          [[ 3.1574e-03,  1.9688e-02, -7.9577e-03],\n",
      "           [ 1.2981e-02,  1.2615e-02,  1.1192e-02],\n",
      "           [ 2.3105e-02, -3.6352e-03, -1.6063e-02]]]]], device='cuda:0')), ('module.up_layers.1.0.norm1.weight', tensor([0.9292, 0.9438, 0.9158, 0.9918, 0.9726, 0.9771, 0.9861, 0.9850, 0.9306,\n",
      "        1.0409, 0.9441, 1.0112, 0.9463, 0.9492, 0.9092, 0.9400, 0.9988, 0.9964,\n",
      "        0.9748, 0.9154, 0.8735, 0.9287, 0.9630, 0.9898, 0.8174, 0.9602, 0.7855,\n",
      "        0.9706, 0.9885, 0.9617, 0.9821, 1.0350], device='cuda:0')), ('module.up_layers.1.0.norm1.bias', tensor([-0.0104, -0.0420,  0.0062, -0.0200, -0.0360, -0.0157, -0.0046, -0.0112,\n",
      "        -0.0591, -0.0225, -0.0394, -0.0197, -0.0499, -0.0182, -0.0391, -0.0076,\n",
      "        -0.0362, -0.0472, -0.0318, -0.0388, -0.0369, -0.0455, -0.0335, -0.0110,\n",
      "         0.0108, -0.0029,  0.0190, -0.0317, -0.0313, -0.0361, -0.0547, -0.0413],\n",
      "       device='cuda:0')), ('module.up_layers.1.0.norm2.weight', tensor([0.9849, 0.7920, 0.8615, 0.9849, 0.9995, 0.9057, 1.0197, 0.8890, 0.9704,\n",
      "        0.9839, 0.9851, 0.9781, 1.0080, 0.9833, 0.9749, 0.8992, 1.0041, 1.0588,\n",
      "        0.9274, 0.9905, 1.0010, 0.9604, 0.9463, 1.0445, 0.9864, 0.9478, 0.8340,\n",
      "        0.9806, 0.9449, 0.9739, 0.9889, 0.9779], device='cuda:0')), ('module.up_layers.1.0.norm2.bias', tensor([ 0.0390, -0.0151,  0.0050,  0.0565,  0.0302,  0.0254,  0.0459,  0.0163,\n",
      "        -0.0597, -0.0723, -0.0734, -0.0677,  0.0491,  0.0292,  0.0562,  0.0503,\n",
      "        -0.0050, -0.0673, -0.0102, -0.0147, -0.0400, -0.0368, -0.0210, -0.0602,\n",
      "         0.0186, -0.0028, -0.0131,  0.0274, -0.0710, -0.0262, -0.0312, -0.0303],\n",
      "       device='cuda:0')), ('module.up_layers.1.0.conv1.conv.weight', tensor([[[[[-1.9050e-02, -1.7190e-02,  1.9307e-02],\n",
      "           [-9.5210e-04, -7.1632e-03,  1.4978e-02],\n",
      "           [-2.2734e-02, -3.3682e-03,  1.7055e-02]],\n",
      "\n",
      "          [[-7.0264e-03, -1.9176e-02,  4.5328e-03],\n",
      "           [ 7.8848e-03,  2.4487e-02, -3.1022e-02],\n",
      "           [ 2.1919e-02, -1.8546e-02, -3.3599e-02]],\n",
      "\n",
      "          [[-1.8416e-02, -2.5078e-02, -3.2662e-03],\n",
      "           [-1.7302e-03, -3.6126e-02,  1.7068e-02],\n",
      "           [ 7.8565e-03, -5.8902e-03, -2.3472e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.0602e-03,  3.3732e-03, -3.0041e-02],\n",
      "           [-2.9496e-02, -1.4230e-02,  1.5203e-02],\n",
      "           [-2.1610e-02,  2.1569e-02, -8.3288e-03]],\n",
      "\n",
      "          [[-1.0826e-02,  4.6433e-03,  1.0041e-02],\n",
      "           [-3.0730e-02, -1.4932e-02,  1.0266e-02],\n",
      "           [ 1.7718e-02,  1.6689e-02, -2.6485e-02]],\n",
      "\n",
      "          [[ 1.0292e-02, -3.0350e-02, -2.6445e-02],\n",
      "           [-1.7303e-02, -1.2283e-02, -9.6065e-04],\n",
      "           [ 1.1116e-02, -3.8234e-02, -3.4491e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2205e-02, -1.3199e-02,  6.3446e-03],\n",
      "           [-7.1416e-04,  5.6788e-03,  2.7192e-02],\n",
      "           [ 1.4858e-02,  6.9066e-03,  3.7399e-02]],\n",
      "\n",
      "          [[ 1.6965e-02,  2.5423e-02,  8.3381e-03],\n",
      "           [ 1.6272e-03,  2.6397e-02, -1.6177e-02],\n",
      "           [ 2.1821e-02,  2.6083e-02,  2.4980e-02]],\n",
      "\n",
      "          [[-9.6321e-03,  3.4088e-02, -1.2664e-02],\n",
      "           [-2.3257e-02,  2.4453e-02,  3.5688e-03],\n",
      "           [ 2.9737e-03,  2.6885e-02, -5.0518e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.6900e-02,  7.9470e-04, -3.5822e-03],\n",
      "           [-4.2755e-03,  3.7974e-02,  3.6528e-02],\n",
      "           [ 3.5008e-02,  4.3465e-02, -1.2884e-02]],\n",
      "\n",
      "          [[-8.4650e-03,  6.3251e-05,  2.9210e-02],\n",
      "           [ 5.7168e-03,  1.8009e-02,  4.3655e-02],\n",
      "           [ 3.4281e-03,  9.6890e-03,  5.1372e-02]],\n",
      "\n",
      "          [[ 7.8683e-03, -6.1305e-03,  3.5159e-02],\n",
      "           [ 2.4967e-02,  4.3929e-02,  2.4405e-02],\n",
      "           [ 2.7079e-02,  2.1660e-02,  3.2013e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.5600e-03, -4.5180e-03,  4.2075e-02],\n",
      "           [ 3.9011e-02, -1.9088e-02, -4.5081e-03],\n",
      "           [ 1.4167e-02,  4.0845e-03,  1.1833e-02]],\n",
      "\n",
      "          [[ 8.0544e-04,  2.4625e-03,  7.3891e-04],\n",
      "           [ 6.4534e-03,  2.2617e-02,  3.5031e-02],\n",
      "           [ 3.1637e-02,  3.3088e-02,  3.3425e-02]],\n",
      "\n",
      "          [[ 5.0101e-03, -1.0267e-02,  7.8092e-03],\n",
      "           [ 1.9645e-05,  2.6613e-02, -2.3606e-02],\n",
      "           [-1.3013e-02,  1.6489e-02,  1.4547e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.9850e-02, -3.7533e-02, -2.4791e-02],\n",
      "           [-4.1079e-02, -2.7366e-02, -3.1388e-02],\n",
      "           [ 2.9217e-03, -5.4430e-03,  1.8446e-02]],\n",
      "\n",
      "          [[-4.8022e-02, -2.6791e-02, -1.7600e-02],\n",
      "           [-2.2281e-03, -2.0049e-02, -6.7531e-03],\n",
      "           [-1.4029e-03, -2.9119e-03, -2.6768e-02]],\n",
      "\n",
      "          [[-2.9457e-02, -3.2036e-02, -2.7010e-02],\n",
      "           [-2.7269e-02, -5.5951e-02, -3.6931e-02],\n",
      "           [-3.6571e-02,  2.5595e-03, -1.5251e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.3066e-02,  3.0304e-02,  4.8840e-02],\n",
      "           [ 2.1938e-02,  2.9058e-02,  2.2720e-02],\n",
      "           [ 4.5744e-02,  3.9676e-02,  5.8196e-02]],\n",
      "\n",
      "          [[ 1.8779e-02,  3.5005e-02,  3.3803e-02],\n",
      "           [ 2.3449e-02,  5.3764e-02,  5.5843e-02],\n",
      "           [ 2.0689e-02,  4.7640e-02,  2.7876e-02]],\n",
      "\n",
      "          [[ 3.6021e-02,  2.6832e-02,  3.2188e-02],\n",
      "           [ 3.9850e-02,  3.0427e-02,  2.9368e-02],\n",
      "           [ 2.4828e-02,  3.8790e-02,  3.0543e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.7571e-04, -2.0133e-02,  2.5819e-02],\n",
      "           [ 6.6757e-03, -4.4890e-04, -1.5020e-02],\n",
      "           [-2.1212e-02,  2.5392e-02,  2.6305e-02]],\n",
      "\n",
      "          [[-2.0333e-02, -2.1742e-02, -2.5775e-02],\n",
      "           [-5.4834e-03, -1.4351e-02, -9.5464e-03],\n",
      "           [-2.4551e-02, -3.8002e-02,  7.2920e-03]],\n",
      "\n",
      "          [[ 3.1865e-02,  1.8081e-02, -1.1430e-02],\n",
      "           [-4.6395e-03,  2.0960e-02, -2.6238e-02],\n",
      "           [-1.3911e-02,  1.2204e-02, -3.7135e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2262e-03,  1.3340e-02,  1.4758e-03],\n",
      "           [-1.4489e-02, -1.1898e-02, -3.0696e-02],\n",
      "           [-1.4606e-02, -8.9424e-03, -3.0869e-02]],\n",
      "\n",
      "          [[ 1.1151e-02, -1.6051e-02,  4.8192e-03],\n",
      "           [-2.9955e-02, -1.3903e-02,  7.4936e-03],\n",
      "           [-1.7319e-02, -3.2476e-03, -1.3901e-02]],\n",
      "\n",
      "          [[-1.9153e-02, -8.4298e-03,  3.6610e-03],\n",
      "           [ 5.1617e-03, -2.2050e-02,  1.0754e-02],\n",
      "           [-1.1206e-02, -9.8968e-03, -2.2244e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.6154e-02,  7.8221e-03,  1.2414e-02],\n",
      "           [-2.2189e-03, -2.5971e-02,  1.3557e-02],\n",
      "           [-2.6337e-02, -3.0277e-02, -2.4211e-02]],\n",
      "\n",
      "          [[-3.3904e-02, -9.2744e-03,  1.2479e-02],\n",
      "           [-1.2495e-02, -3.7153e-02,  1.7088e-02],\n",
      "           [-1.2570e-02, -1.7237e-02, -1.1063e-02]],\n",
      "\n",
      "          [[ 1.4666e-02,  1.4753e-02,  1.8652e-02],\n",
      "           [-3.1008e-02, -6.6760e-04,  1.7909e-02],\n",
      "           [-1.2237e-02,  1.4799e-04, -1.7538e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.8016e-02,  2.4504e-02,  1.2265e-02],\n",
      "           [-1.4149e-02,  1.5858e-02, -1.4579e-02],\n",
      "           [-3.2797e-03, -2.0767e-02,  1.4757e-02]],\n",
      "\n",
      "          [[-1.5904e-02, -3.3873e-02,  2.1151e-02],\n",
      "           [ 4.5364e-03, -3.7648e-04,  8.0884e-03],\n",
      "           [ 6.9741e-03, -3.3727e-02,  1.8969e-02]],\n",
      "\n",
      "          [[-9.7298e-03, -2.1446e-02, -1.4134e-02],\n",
      "           [ 2.0683e-02,  2.1030e-02, -3.2563e-02],\n",
      "           [ 1.3598e-02,  5.9725e-03, -1.8703e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.4505e-02,  2.3894e-02,  4.7061e-02],\n",
      "           [ 4.3542e-02,  6.3021e-02,  4.7561e-02],\n",
      "           [ 2.6533e-02,  4.3239e-02,  4.0090e-02]],\n",
      "\n",
      "          [[ 5.8184e-02,  6.4659e-02,  6.9315e-02],\n",
      "           [ 4.4080e-02,  4.7503e-02,  5.3475e-02],\n",
      "           [ 9.4498e-03,  1.4902e-02,  2.2127e-02]],\n",
      "\n",
      "          [[ 1.8610e-02,  3.3969e-02,  2.0843e-02],\n",
      "           [ 1.7709e-02,  5.1444e-02,  4.8738e-02],\n",
      "           [ 2.2251e-02,  1.7991e-02,  5.7771e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.1305e-02,  2.0796e-02,  5.3941e-02],\n",
      "           [ 2.1532e-02,  3.2315e-02,  2.2063e-02],\n",
      "           [ 3.7702e-02,  2.8352e-02,  6.4655e-02]],\n",
      "\n",
      "          [[ 2.4084e-02,  2.0312e-02,  2.2021e-02],\n",
      "           [ 2.9412e-02,  5.4852e-02,  3.0284e-02],\n",
      "           [ 6.5747e-02,  3.5614e-02,  6.0973e-02]],\n",
      "\n",
      "          [[ 6.5921e-03,  1.8948e-02,  3.5239e-02],\n",
      "           [ 4.0113e-02,  4.4771e-02,  3.4937e-02],\n",
      "           [ 3.8040e-02,  3.6080e-02,  4.9449e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.6848e-02, -2.3497e-02, -3.5839e-02],\n",
      "           [-2.0574e-02,  2.2243e-02, -3.2116e-02],\n",
      "           [-6.0013e-03, -2.9147e-02,  1.8649e-02]],\n",
      "\n",
      "          [[-1.7912e-02,  2.8538e-03, -2.5686e-02],\n",
      "           [-3.9944e-03,  1.9055e-02, -2.0491e-02],\n",
      "           [-5.9050e-03, -2.3943e-02,  7.4464e-03]],\n",
      "\n",
      "          [[ 2.0477e-02, -1.1944e-02,  2.5344e-02],\n",
      "           [-3.0364e-02,  2.5104e-02, -1.5841e-02],\n",
      "           [ 2.3429e-02, -3.5059e-02, -3.7222e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.0458e-02, -1.0917e-02,  2.7744e-02],\n",
      "           [-5.1874e-03,  2.1457e-02,  6.3339e-03],\n",
      "           [ 6.9954e-03,  1.0383e-02, -1.8080e-02]],\n",
      "\n",
      "          [[ 1.4513e-02,  1.8546e-02,  1.8446e-02],\n",
      "           [-1.7700e-02,  1.1970e-02, -8.5590e-03],\n",
      "           [-1.0458e-02, -1.7653e-02, -1.1622e-02]],\n",
      "\n",
      "          [[-6.2849e-03,  1.2597e-02,  3.2530e-02],\n",
      "           [ 2.5793e-02, -1.6784e-02, -1.3514e-02],\n",
      "           [ 9.5826e-03, -4.4642e-03,  2.4934e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.3459e-02, -3.3061e-02, -1.5440e-02],\n",
      "           [ 2.8413e-02, -3.0947e-02,  1.6962e-02],\n",
      "           [ 2.7206e-05,  1.3729e-02,  1.6171e-02]],\n",
      "\n",
      "          [[-1.2987e-02, -5.4440e-03, -2.9212e-02],\n",
      "           [-1.5586e-02, -4.1220e-03, -2.1739e-02],\n",
      "           [-2.9338e-02, -3.6800e-03,  4.4655e-04]],\n",
      "\n",
      "          [[-3.4130e-02, -3.2239e-02,  2.2043e-02],\n",
      "           [ 1.7553e-02, -2.6152e-02, -3.3421e-02],\n",
      "           [ 2.0168e-02,  3.0559e-02,  1.9793e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.5396e-02,  1.0549e-02,  3.0263e-02],\n",
      "           [ 2.4547e-03, -1.9454e-02,  7.0298e-03],\n",
      "           [-1.3885e-02, -2.9310e-02, -1.9399e-02]],\n",
      "\n",
      "          [[-1.7248e-02,  1.1815e-02, -2.5619e-02],\n",
      "           [ 3.3271e-02, -2.1480e-03,  5.5012e-03],\n",
      "           [ 4.0788e-03,  5.5261e-03,  1.3196e-03]],\n",
      "\n",
      "          [[-1.8149e-02, -2.6391e-02, -1.5444e-02],\n",
      "           [-1.2296e-03,  1.9317e-02, -1.2332e-02],\n",
      "           [-3.1137e-02,  3.0129e-02,  8.3848e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.8141e-02,  4.1805e-03,  4.5679e-02],\n",
      "           [ 5.0334e-02,  4.3639e-02,  3.7441e-02],\n",
      "           [ 3.3969e-02,  3.4974e-02,  1.4861e-03]],\n",
      "\n",
      "          [[ 2.2850e-02,  6.1131e-02,  4.3742e-02],\n",
      "           [ 7.9741e-03,  4.1732e-02,  2.1741e-03],\n",
      "           [ 7.3038e-03,  5.1458e-03,  2.9924e-02]],\n",
      "\n",
      "          [[ 4.0889e-02,  1.6910e-02,  5.4470e-02],\n",
      "           [ 4.0786e-03,  4.8710e-02,  4.8169e-02],\n",
      "           [-1.4210e-03,  1.9085e-02,  3.7291e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-4.5343e-03,  1.9458e-02,  1.4541e-02],\n",
      "           [ 8.0691e-03, -1.3353e-02, -3.4289e-02],\n",
      "           [-2.8610e-02, -1.1847e-02, -2.6708e-02]],\n",
      "\n",
      "          [[ 1.5209e-02,  2.2166e-02,  1.5085e-02],\n",
      "           [-2.3025e-02, -2.4219e-02, -3.7884e-02],\n",
      "           [ 2.6484e-03, -1.5965e-02, -3.1925e-02]],\n",
      "\n",
      "          [[-1.7784e-02, -1.5912e-02, -6.1342e-03],\n",
      "           [-5.3679e-03,  6.3191e-03, -3.8792e-02],\n",
      "           [-1.9610e-02,  1.6206e-02,  3.2929e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.1647e-03,  2.6053e-02, -2.4988e-02],\n",
      "           [-2.6104e-02, -2.0161e-02, -2.4507e-02],\n",
      "           [-1.5527e-02, -5.0040e-03,  9.5415e-03]],\n",
      "\n",
      "          [[ 2.3253e-02, -8.4960e-03,  3.1743e-02],\n",
      "           [-3.0956e-03,  3.8551e-02,  2.6676e-02],\n",
      "           [ 1.9785e-02,  1.1471e-02, -7.7632e-03]],\n",
      "\n",
      "          [[ 7.8149e-03, -2.3031e-02, -1.5153e-02],\n",
      "           [-6.4267e-03, -1.9619e-02, -2.6133e-02],\n",
      "           [ 2.1854e-02,  3.0249e-02,  1.7854e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.3523e-03, -9.9833e-03, -1.9386e-02],\n",
      "           [ 7.7466e-03, -1.9148e-02, -1.6176e-03],\n",
      "           [-6.8479e-03,  1.4442e-02, -7.2583e-03]],\n",
      "\n",
      "          [[-1.3439e-02, -3.1104e-02, -1.6620e-02],\n",
      "           [-4.4725e-03, -8.4432e-03,  2.0703e-02],\n",
      "           [-5.7262e-03, -2.8560e-02,  6.4238e-03]],\n",
      "\n",
      "          [[-1.4423e-02, -2.6122e-02,  2.2750e-02],\n",
      "           [-1.5085e-02, -5.9252e-03,  1.7022e-02],\n",
      "           [ 5.7440e-03, -2.3417e-02,  3.1567e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.4485e-02,  2.1310e-02,  1.3572e-03],\n",
      "           [-1.3885e-02,  2.9077e-02,  5.1048e-03],\n",
      "           [-2.8195e-02,  1.2131e-02, -3.3505e-02]],\n",
      "\n",
      "          [[-2.0475e-02, -2.4877e-02,  1.0703e-02],\n",
      "           [ 1.6484e-02, -3.0136e-02, -2.3754e-02],\n",
      "           [-3.4359e-02,  3.2399e-03, -4.4994e-02]],\n",
      "\n",
      "          [[ 2.2559e-03,  2.8222e-02,  1.7556e-05],\n",
      "           [-1.7100e-02, -1.9167e-02,  1.3624e-02],\n",
      "           [-1.4631e-02, -1.6758e-02, -1.9805e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.2252e-02, -2.9735e-02, -1.3923e-02],\n",
      "           [-3.6484e-02, -1.9841e-02, -9.7915e-03],\n",
      "           [-1.4262e-02,  3.3582e-02,  4.2134e-03]],\n",
      "\n",
      "          [[ 1.9865e-02, -9.7932e-03,  1.7107e-02],\n",
      "           [-9.4820e-03, -1.5203e-02, -1.1670e-02],\n",
      "           [ 4.5306e-03,  2.0387e-02,  1.6440e-02]],\n",
      "\n",
      "          [[ 6.4893e-03,  2.5896e-02, -1.2189e-02],\n",
      "           [ 2.7302e-02,  2.1584e-02, -2.0333e-03],\n",
      "           [ 3.6838e-02,  1.4492e-02,  3.9098e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.1869e-02,  1.8525e-02,  2.1428e-02],\n",
      "           [-2.9335e-02,  3.8003e-02,  3.3318e-02],\n",
      "           [-3.1145e-04,  3.3995e-02,  2.8839e-02]],\n",
      "\n",
      "          [[ 8.9652e-04,  3.2969e-02,  1.0907e-02],\n",
      "           [ 7.0963e-04, -2.2499e-03,  3.4048e-03],\n",
      "           [ 2.6630e-02,  2.6146e-02, -1.0187e-02]],\n",
      "\n",
      "          [[-1.3261e-02, -1.2023e-02,  3.5209e-02],\n",
      "           [ 4.2079e-02, -8.7485e-03,  5.7786e-03],\n",
      "           [ 4.3344e-02,  2.1731e-02,  2.6800e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 8.6015e-03, -2.5280e-03, -5.3936e-03],\n",
      "           [-8.4600e-03, -1.4743e-02, -6.8818e-03],\n",
      "           [-2.7192e-02,  1.4498e-02,  1.7359e-02]],\n",
      "\n",
      "          [[ 2.6747e-02, -1.4902e-02,  5.2866e-03],\n",
      "           [-1.4936e-02,  2.0925e-02,  6.7978e-03],\n",
      "           [ 6.3246e-03,  5.1382e-03, -3.2210e-02]],\n",
      "\n",
      "          [[ 2.6017e-04, -3.7459e-03,  2.6240e-02],\n",
      "           [ 2.0886e-02, -1.9285e-03, -2.3926e-02],\n",
      "           [-3.3807e-02,  7.9177e-03, -1.6911e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.5350e-02, -4.2968e-03,  7.1430e-03],\n",
      "           [-1.2433e-03, -3.2914e-02, -2.3214e-03],\n",
      "           [ 1.5452e-02, -1.2222e-02, -7.2976e-03]],\n",
      "\n",
      "          [[ 2.2022e-02, -3.1228e-02, -2.0489e-02],\n",
      "           [ 2.0447e-02,  2.4496e-02,  2.6553e-03],\n",
      "           [ 9.3708e-03, -2.0022e-02, -1.8913e-02]],\n",
      "\n",
      "          [[ 1.8472e-02,  2.6928e-02, -2.3470e-02],\n",
      "           [ 2.3697e-02, -7.6775e-03,  1.9311e-02],\n",
      "           [-2.6576e-03, -3.1123e-02, -1.6944e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.5529e-02,  5.0380e-03, -1.7979e-03],\n",
      "           [ 1.2698e-02, -3.4783e-02, -7.9925e-03],\n",
      "           [ 2.7036e-03, -2.2146e-02, -1.3576e-02]],\n",
      "\n",
      "          [[-4.2085e-03, -2.0675e-03,  6.1390e-03],\n",
      "           [-3.3893e-03,  2.4703e-02,  1.1926e-02],\n",
      "           [ 1.2170e-02,  2.3414e-02, -1.9923e-02]],\n",
      "\n",
      "          [[-5.7084e-03,  2.3416e-02,  2.2396e-02],\n",
      "           [-4.8720e-03,  2.5707e-02, -1.2924e-02],\n",
      "           [ 1.0720e-02, -2.5431e-02, -1.6263e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.6413e-02, -1.7027e-02,  5.3455e-03],\n",
      "           [ 1.9731e-02,  4.7999e-03, -1.5885e-02],\n",
      "           [-2.7899e-02, -3.1672e-03, -2.0412e-02]],\n",
      "\n",
      "          [[-2.0117e-02,  2.4895e-02, -5.1673e-03],\n",
      "           [ 3.8246e-03, -1.7941e-02,  9.1216e-03],\n",
      "           [ 6.8605e-03,  2.1447e-03, -3.7084e-02]],\n",
      "\n",
      "          [[-3.2066e-02,  8.7406e-03,  1.4750e-02],\n",
      "           [-4.7370e-02, -4.8736e-02, -3.6661e-02],\n",
      "           [-4.9438e-02, -1.7227e-03, -5.3676e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4646e-02, -1.4664e-02,  9.7277e-03],\n",
      "           [ 2.3431e-02,  2.3121e-02,  3.5862e-02],\n",
      "           [-4.4134e-03, -8.6918e-03,  3.1778e-02]],\n",
      "\n",
      "          [[-9.4965e-04,  1.9228e-02,  3.4665e-02],\n",
      "           [ 1.6627e-02,  9.7756e-03, -1.2651e-02],\n",
      "           [-2.3556e-02,  2.8448e-02, -7.6076e-03]],\n",
      "\n",
      "          [[-1.6253e-02,  1.4716e-03, -1.6267e-02],\n",
      "           [-2.5524e-03, -1.1724e-02,  1.6699e-02],\n",
      "           [ 2.3923e-02, -1.6422e-02,  4.0036e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.3014e-02,  4.9658e-02, -8.9444e-03],\n",
      "           [ 3.3150e-02, -8.2188e-03,  4.7759e-02],\n",
      "           [ 2.5902e-02,  2.2561e-02,  1.6336e-02]],\n",
      "\n",
      "          [[ 5.6822e-03,  2.0253e-02, -9.3105e-03],\n",
      "           [-4.4112e-03,  4.5986e-02,  2.2718e-02],\n",
      "           [ 2.6318e-02,  4.2643e-02,  2.9492e-02]],\n",
      "\n",
      "          [[ 2.3802e-02,  8.1452e-03,  1.2410e-02],\n",
      "           [ 6.5825e-03,  5.3657e-02, -1.4622e-02],\n",
      "           [ 3.3927e-02,  5.7741e-02, -1.1738e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.1995e-02, -1.7890e-02,  1.6434e-02],\n",
      "           [ 2.8003e-02,  7.4939e-03,  1.9660e-02],\n",
      "           [ 1.9032e-02,  5.6400e-03,  1.7470e-02]],\n",
      "\n",
      "          [[-2.0118e-02, -1.1645e-02,  2.8977e-03],\n",
      "           [ 9.0586e-03,  1.7771e-02,  1.3887e-02],\n",
      "           [-7.9491e-04, -1.2110e-02,  3.1423e-02]],\n",
      "\n",
      "          [[-5.4501e-02, -3.8303e-02, -4.8761e-02],\n",
      "           [-4.7560e-03, -4.0963e-02, -2.0768e-02],\n",
      "           [-1.1508e-02, -2.7491e-02,  6.6747e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.0592e-03,  1.5077e-03, -1.2783e-02],\n",
      "           [-1.3303e-03, -1.2146e-03, -1.4443e-02],\n",
      "           [-7.4574e-03, -3.2388e-03, -3.4691e-02]],\n",
      "\n",
      "          [[-9.9822e-03,  4.4976e-03, -1.0257e-02],\n",
      "           [ 2.9416e-02, -4.7268e-03,  1.6194e-02],\n",
      "           [-3.7139e-02,  7.0838e-03,  1.9840e-02]],\n",
      "\n",
      "          [[ 9.8592e-03, -3.2794e-02, -8.8866e-03],\n",
      "           [-1.9717e-04, -3.0595e-02,  9.4688e-03],\n",
      "           [ 3.0828e-03,  1.6851e-02, -3.7497e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.0908e-02, -1.5686e-02, -1.4638e-02],\n",
      "           [ 1.8301e-02,  1.1643e-02, -1.9850e-03],\n",
      "           [ 1.6586e-02,  9.3562e-03, -3.6699e-02]],\n",
      "\n",
      "          [[-7.2050e-03, -3.4254e-02,  4.1159e-03],\n",
      "           [-3.5276e-02, -2.7184e-04, -3.6461e-02],\n",
      "           [-2.0440e-03, -3.2226e-02,  9.1732e-03]],\n",
      "\n",
      "          [[-3.2172e-03, -2.7475e-02,  2.4660e-03],\n",
      "           [ 6.4184e-03, -1.0906e-02, -3.2367e-02],\n",
      "           [-1.1156e-02, -1.3769e-02,  7.9341e-03]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 2.7583e-02, -1.2499e-02,  1.8583e-02],\n",
      "           [-1.6162e-02, -9.5419e-04,  1.9746e-02],\n",
      "           [-2.2201e-02, -2.8367e-02, -3.3137e-02]],\n",
      "\n",
      "          [[-1.8608e-02,  1.8679e-02, -4.1208e-02],\n",
      "           [-2.0896e-02, -9.8067e-03,  2.2705e-02],\n",
      "           [ 5.5592e-03,  1.9905e-02,  2.9006e-03]],\n",
      "\n",
      "          [[ 1.3666e-02, -4.1441e-02,  1.2382e-02],\n",
      "           [-3.9891e-02, -3.3746e-02, -4.4434e-02],\n",
      "           [-1.7513e-02, -1.0084e-02, -3.9755e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.7993e-02, -1.7621e-02,  1.3455e-02],\n",
      "           [-1.8660e-02, -1.5328e-02,  1.9966e-02],\n",
      "           [ 1.1136e-02,  3.7476e-02, -2.4919e-02]],\n",
      "\n",
      "          [[ 8.8657e-03, -3.2804e-02, -3.5767e-02],\n",
      "           [-1.0535e-02, -1.6282e-02,  2.7205e-02],\n",
      "           [ 1.3459e-02, -1.6003e-02,  2.0541e-02]],\n",
      "\n",
      "          [[-4.0502e-02, -4.6370e-02, -4.5425e-02],\n",
      "           [-3.2200e-03, -3.8778e-02,  2.7911e-03],\n",
      "           [-1.8239e-02,  6.2931e-03, -2.4557e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 4.0293e-03,  4.6079e-02,  2.1539e-02],\n",
      "           [ 4.1508e-02,  5.0820e-02,  5.7432e-02],\n",
      "           [ 3.9828e-02,  5.1921e-02,  1.9976e-02]],\n",
      "\n",
      "          [[-1.8001e-03,  3.2095e-02, -2.9221e-02],\n",
      "           [ 1.4139e-02,  5.2135e-02,  3.2268e-04],\n",
      "           [ 4.3129e-02,  3.3333e-02,  2.9200e-02]],\n",
      "\n",
      "          [[-4.2426e-02, -2.4408e-03, -2.4056e-02],\n",
      "           [-2.1770e-02, -1.5560e-02,  2.7941e-02],\n",
      "           [ 8.3332e-03,  3.3242e-02, -3.0806e-03]]]]], device='cuda:0')), ('module.up_layers.1.0.conv2.conv.weight', tensor([[[[[-2.8535e-02, -8.4687e-03,  2.0720e-02],\n",
      "           [ 7.4594e-03,  2.1613e-02,  2.1126e-02],\n",
      "           [-3.4647e-02, -3.6177e-02,  1.9411e-02]],\n",
      "\n",
      "          [[ 1.5347e-02, -2.0705e-02,  1.8434e-02],\n",
      "           [ 1.7814e-02,  1.6119e-02, -7.5077e-03],\n",
      "           [-3.5948e-03, -1.1395e-02,  2.2749e-02]],\n",
      "\n",
      "          [[ 1.4969e-02, -1.5720e-02,  4.5782e-03],\n",
      "           [-1.1479e-02,  5.4439e-03,  4.8023e-03],\n",
      "           [-3.0294e-02, -2.0957e-02, -2.8258e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.6452e-02,  1.6159e-02,  2.2452e-02],\n",
      "           [-4.5377e-03, -3.1201e-02, -2.6964e-02],\n",
      "           [-1.7905e-02, -2.3415e-02,  2.5917e-02]],\n",
      "\n",
      "          [[-9.5782e-03, -1.0521e-02,  2.9691e-04],\n",
      "           [-1.6363e-02, -2.0167e-02, -5.6147e-03],\n",
      "           [-2.0453e-03, -2.6616e-02, -2.2506e-02]],\n",
      "\n",
      "          [[ 5.3060e-04,  1.0927e-02,  2.4097e-03],\n",
      "           [-8.4831e-03, -2.0654e-02,  9.6825e-03],\n",
      "           [-1.1028e-02, -3.3720e-02, -1.0937e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.3364e-02, -4.2415e-02,  4.1969e-03],\n",
      "           [-6.8748e-03, -5.9376e-03,  5.5447e-03],\n",
      "           [ 7.5201e-03, -4.2506e-02, -3.1314e-02]],\n",
      "\n",
      "          [[-1.0085e-02, -4.2928e-02, -1.2343e-02],\n",
      "           [-3.9828e-02, -4.6975e-02, -4.6110e-02],\n",
      "           [-4.1779e-02, -3.8656e-02, -7.1979e-03]],\n",
      "\n",
      "          [[-9.8819e-03, -1.3907e-02,  1.3783e-02],\n",
      "           [-2.6292e-02, -2.3953e-02, -1.6676e-03],\n",
      "           [-1.9541e-02, -2.1735e-02, -3.5836e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 3.0280e-02, -6.3923e-03,  1.5941e-02],\n",
      "           [-2.4050e-02,  1.7560e-02,  1.9052e-02],\n",
      "           [ 3.2937e-02, -2.5722e-02,  1.5831e-02]],\n",
      "\n",
      "          [[ 3.8335e-02,  4.1420e-02, -1.9601e-02],\n",
      "           [ 2.0667e-02, -1.8800e-02,  1.2827e-02],\n",
      "           [ 2.3348e-02, -3.8057e-03,  9.1944e-03]],\n",
      "\n",
      "          [[-1.4542e-02,  9.4182e-05,  1.8990e-02],\n",
      "           [ 2.4827e-02, -1.3204e-02,  2.9643e-02],\n",
      "           [ 1.8914e-02,  1.5882e-02, -1.7832e-02]]],\n",
      "\n",
      "\n",
      "         [[[-5.0177e-03, -4.4125e-04,  3.9364e-02],\n",
      "           [ 1.4769e-02,  3.5656e-02,  1.5059e-03],\n",
      "           [-7.4324e-03,  3.7517e-03,  3.2931e-02]],\n",
      "\n",
      "          [[ 2.1146e-02,  2.1836e-02,  1.2769e-03],\n",
      "           [ 1.6227e-02,  4.3959e-02, -9.3946e-03],\n",
      "           [ 1.8480e-02, -8.0401e-03,  2.0708e-02]],\n",
      "\n",
      "          [[ 2.6158e-02,  1.0257e-02,  4.3922e-02],\n",
      "           [ 3.6983e-02,  3.8263e-02,  5.9638e-03],\n",
      "           [ 4.1013e-02,  1.3299e-02,  1.4774e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.7468e-02, -1.5673e-02,  3.7409e-02],\n",
      "           [-1.3841e-02,  2.9722e-02,  7.2667e-03],\n",
      "           [ 3.9676e-02,  2.4863e-02,  2.7793e-02]],\n",
      "\n",
      "          [[ 1.3625e-02, -8.4690e-03,  1.7749e-02],\n",
      "           [ 1.1126e-03,  3.0475e-02,  4.7748e-02],\n",
      "           [ 4.3763e-02,  5.2774e-02,  8.0382e-03]],\n",
      "\n",
      "          [[ 1.4778e-02, -2.0348e-02, -2.5396e-02],\n",
      "           [ 2.3277e-02, -5.7110e-03, -1.5028e-02],\n",
      "           [ 7.1703e-03,  3.4855e-02,  4.2758e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.3380e-02,  8.8794e-03,  1.3516e-02],\n",
      "           [ 2.7174e-02,  3.2559e-02,  3.0235e-02],\n",
      "           [ 3.9777e-02,  1.4729e-02,  7.4837e-03]],\n",
      "\n",
      "          [[-2.0698e-03,  3.9212e-02,  1.2642e-02],\n",
      "           [ 4.9300e-02,  2.1678e-02,  4.8648e-02],\n",
      "           [ 2.2773e-02,  8.2376e-03,  3.8946e-02]],\n",
      "\n",
      "          [[ 3.7864e-02, -5.6242e-03,  2.8973e-02],\n",
      "           [ 7.0203e-03,  2.7932e-02,  2.8448e-02],\n",
      "           [ 3.3877e-02, -1.7035e-03,  3.0446e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.1761e-02,  3.7350e-02,  3.0517e-02],\n",
      "           [ 1.6722e-02,  2.7990e-02,  2.0626e-02],\n",
      "           [ 1.9682e-02,  3.7375e-02,  2.1155e-02]],\n",
      "\n",
      "          [[ 1.1430e-02,  4.0275e-02,  3.2119e-02],\n",
      "           [ 3.3667e-02,  3.8045e-02,  3.4586e-02],\n",
      "           [ 1.9711e-02,  4.0036e-02,  2.0668e-02]],\n",
      "\n",
      "          [[ 4.0070e-03,  3.1618e-02,  3.2413e-02],\n",
      "           [ 2.6366e-02,  3.9396e-02,  2.5932e-02],\n",
      "           [ 1.8487e-02,  3.0906e-02,  2.2645e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.6168e-03,  2.4271e-02,  4.2543e-02],\n",
      "           [ 2.9064e-02,  5.2518e-02,  2.8695e-02],\n",
      "           [ 4.8366e-03,  3.5872e-02,  3.7765e-02]],\n",
      "\n",
      "          [[ 1.2109e-02,  4.6790e-02,  4.8304e-02],\n",
      "           [ 3.8483e-02,  1.8089e-02,  2.5012e-02],\n",
      "           [ 2.0895e-02,  2.8457e-03,  2.9203e-02]],\n",
      "\n",
      "          [[ 7.9611e-03,  4.6881e-02,  4.4816e-02],\n",
      "           [ 2.1734e-02,  2.3219e-02,  4.2120e-02],\n",
      "           [-1.0617e-02,  1.9458e-02,  2.5513e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 8.3542e-04,  1.7575e-02,  8.8985e-04],\n",
      "           [-4.2693e-02,  2.1193e-02, -1.9076e-02],\n",
      "           [-2.7856e-02, -4.4690e-02,  1.4176e-02]],\n",
      "\n",
      "          [[-4.0846e-03,  2.6081e-02, -8.0940e-03],\n",
      "           [-3.9980e-02,  2.7272e-02, -9.9475e-03],\n",
      "           [ 5.4902e-03,  1.6236e-02,  6.0856e-03]],\n",
      "\n",
      "          [[ 1.5280e-02, -2.3782e-02,  9.5748e-03],\n",
      "           [-2.5220e-03,  4.4401e-04,  1.4830e-02],\n",
      "           [-2.6011e-02,  8.4819e-04,  4.2131e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.7048e-02, -4.3110e-03, -4.2256e-03],\n",
      "           [-1.9820e-02, -3.1506e-02,  1.8738e-02],\n",
      "           [-3.3494e-02,  1.5247e-02,  1.0051e-02]],\n",
      "\n",
      "          [[-1.1376e-02, -2.0837e-03, -1.0383e-02],\n",
      "           [ 6.4052e-03,  2.8955e-02,  1.0556e-02],\n",
      "           [-2.0331e-02, -3.5057e-02, -1.6365e-02]],\n",
      "\n",
      "          [[ 4.4293e-03,  1.8034e-02, -2.1972e-02],\n",
      "           [-1.6415e-02,  2.0517e-02, -2.5514e-02],\n",
      "           [ 1.7371e-02, -4.0569e-02, -3.6941e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.6627e-02,  4.9855e-03, -3.7360e-02],\n",
      "           [-3.3455e-02, -4.1184e-02, -2.6024e-03],\n",
      "           [ 1.2506e-02,  3.2610e-04,  5.7223e-05]],\n",
      "\n",
      "          [[-2.4212e-02, -5.4087e-03, -2.8572e-02],\n",
      "           [ 4.9856e-03,  7.0767e-03,  8.4623e-03],\n",
      "           [ 1.0014e-02, -3.9335e-02, -4.7400e-02]],\n",
      "\n",
      "          [[-2.0386e-02, -7.0404e-03,  3.5290e-02],\n",
      "           [-3.0391e-02, -1.2063e-02,  5.2984e-03],\n",
      "           [ 8.5946e-03, -1.0706e-02, -1.8409e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.0054e-02,  1.3039e-02, -3.7614e-02],\n",
      "           [-4.0085e-02, -4.2480e-02, -2.9293e-02],\n",
      "           [ 7.0949e-03, -4.2732e-02, -4.3973e-02]],\n",
      "\n",
      "          [[-2.6252e-02, -8.7076e-03,  1.5264e-02],\n",
      "           [-4.1703e-02, -2.6255e-03,  3.8242e-03],\n",
      "           [-3.8615e-02, -3.2310e-02, -1.8628e-02]],\n",
      "\n",
      "          [[-6.2310e-03, -1.2631e-03, -3.1421e-02],\n",
      "           [-1.4389e-02, -1.2042e-02, -1.1201e-02],\n",
      "           [-4.3706e-02, -5.1776e-02, -3.3246e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.9289e-02,  1.0954e-02,  2.1406e-03],\n",
      "           [-1.9247e-03, -2.0351e-02, -8.0155e-03],\n",
      "           [ 2.9306e-02,  1.4771e-02,  2.0616e-02]],\n",
      "\n",
      "          [[ 5.7559e-04,  1.6804e-02, -1.6807e-03],\n",
      "           [-1.2521e-02, -1.5593e-02, -5.8525e-03],\n",
      "           [ 2.5843e-02,  3.9043e-03,  3.4660e-02]],\n",
      "\n",
      "          [[ 1.9835e-02,  2.5063e-02, -1.9325e-03],\n",
      "           [-8.7195e-03, -2.9041e-03,  1.3130e-02],\n",
      "           [-2.4083e-03,  1.8489e-02,  4.0462e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 9.0687e-03,  3.2327e-02,  1.0369e-02],\n",
      "           [ 2.5841e-02,  9.1184e-03,  5.0776e-03],\n",
      "           [-8.3317e-03, -9.6412e-03,  3.1331e-03]],\n",
      "\n",
      "          [[-9.0272e-03,  2.6403e-02,  5.6393e-03],\n",
      "           [-2.0161e-02, -3.1017e-02, -3.0383e-02],\n",
      "           [ 3.5146e-03, -2.2107e-02,  2.4029e-02]],\n",
      "\n",
      "          [[-4.1675e-03,  1.5491e-02,  2.7971e-03],\n",
      "           [ 2.6035e-02, -6.3055e-03, -2.4721e-02],\n",
      "           [-9.3509e-03,  3.3138e-02,  1.5438e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-3.9962e-03, -3.4460e-02, -4.3956e-03],\n",
      "           [ 1.4353e-02, -2.1624e-02,  2.4413e-02],\n",
      "           [-2.0159e-02, -3.3713e-02, -2.6634e-02]],\n",
      "\n",
      "          [[-1.2230e-02,  9.3549e-03,  2.5721e-02],\n",
      "           [-1.5706e-02,  2.2827e-02, -3.7723e-02],\n",
      "           [-1.4032e-02, -2.9593e-02, -1.9066e-02]],\n",
      "\n",
      "          [[ 1.5246e-02,  1.9090e-02,  1.4470e-02],\n",
      "           [-6.2897e-03, -2.9431e-02,  6.7083e-03],\n",
      "           [-1.4939e-02,  4.3042e-03, -1.7946e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.5214e-03, -1.9167e-02,  9.4758e-03],\n",
      "           [-1.8402e-02, -3.5760e-02,  2.4129e-03],\n",
      "           [-2.6929e-02, -3.1847e-02, -2.2017e-02]],\n",
      "\n",
      "          [[ 1.1445e-02, -3.2555e-02, -3.0004e-02],\n",
      "           [-2.4517e-02, -2.7543e-03, -2.2985e-02],\n",
      "           [ 6.1248e-03, -3.4353e-02, -3.1654e-02]],\n",
      "\n",
      "          [[ 2.4487e-02, -2.5035e-03, -6.4677e-03],\n",
      "           [-3.2139e-02, -1.3264e-02, -4.0530e-03],\n",
      "           [-3.4880e-02, -3.3894e-02, -3.4680e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.6858e-03,  3.4626e-02,  3.0320e-02],\n",
      "           [ 3.0366e-02, -9.1978e-03,  3.0510e-02],\n",
      "           [-1.5698e-02, -1.1803e-02,  3.7161e-02]],\n",
      "\n",
      "          [[ 2.9527e-02,  7.8239e-05, -1.6499e-02],\n",
      "           [-1.4300e-02, -1.7679e-02, -7.0242e-03],\n",
      "           [-1.0335e-02,  3.2593e-02,  1.0264e-02]],\n",
      "\n",
      "          [[ 2.0648e-02, -3.7520e-02, -4.2523e-03],\n",
      "           [-2.5457e-02, -3.1934e-02,  4.6425e-03],\n",
      "           [ 9.4138e-03, -9.9785e-03, -6.1373e-04]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.8553e-02, -3.7355e-03,  6.1980e-03],\n",
      "           [-2.4861e-03,  1.0751e-02,  2.4260e-02],\n",
      "           [-1.3468e-02,  3.7773e-02, -7.3040e-03]],\n",
      "\n",
      "          [[ 4.3431e-03,  6.0839e-03,  2.6112e-03],\n",
      "           [ 3.2729e-03,  3.9118e-02,  2.3908e-03],\n",
      "           [ 3.4466e-02, -1.1774e-03,  3.5026e-02]],\n",
      "\n",
      "          [[-1.1151e-02, -8.4931e-03,  4.3245e-02],\n",
      "           [ 2.9634e-02,  3.5089e-03,  4.3215e-02],\n",
      "           [ 3.2589e-02,  3.5309e-03, -9.5963e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 8.4396e-03,  1.1990e-02,  4.1289e-02],\n",
      "           [ 3.9493e-02,  4.4313e-02,  4.5450e-02],\n",
      "           [ 1.9717e-02,  4.5805e-02,  3.3603e-02]],\n",
      "\n",
      "          [[ 1.9692e-02,  3.1826e-02,  2.8548e-02],\n",
      "           [ 4.0754e-02,  2.4056e-02,  3.5713e-02],\n",
      "           [ 4.3900e-02,  3.6532e-02,  1.7194e-02]],\n",
      "\n",
      "          [[ 1.2363e-02,  1.7913e-02,  1.0114e-02],\n",
      "           [ 1.7170e-02,  4.4971e-02,  2.4498e-02],\n",
      "           [ 2.7966e-02,  4.3708e-02,  6.7356e-03]]],\n",
      "\n",
      "\n",
      "         [[[-5.6639e-04, -2.5086e-03,  2.6690e-03],\n",
      "           [-3.3954e-03,  1.0342e-02,  9.6864e-03],\n",
      "           [ 2.4609e-02, -1.6840e-03, -6.4681e-03]],\n",
      "\n",
      "          [[ 1.7611e-02, -2.1351e-03,  1.7366e-02],\n",
      "           [ 7.8846e-03,  7.8864e-03,  1.9230e-02],\n",
      "           [ 1.1730e-02,  1.0515e-02,  2.9193e-02]],\n",
      "\n",
      "          [[-5.3982e-03,  1.3807e-02,  1.9560e-02],\n",
      "           [-1.3066e-02, -1.2458e-03,  2.7610e-02],\n",
      "           [ 1.7634e-02,  6.4196e-03,  1.5987e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-8.5556e-04,  3.3346e-02, -6.3822e-03],\n",
      "           [ 2.3162e-02, -2.7404e-02,  1.6428e-02],\n",
      "           [-3.1228e-02,  2.6135e-02,  2.6019e-02]],\n",
      "\n",
      "          [[ 2.8399e-02,  2.4146e-02,  7.2519e-03],\n",
      "           [-1.4182e-02,  6.7028e-03,  3.4134e-02],\n",
      "           [ 1.8808e-02,  8.0909e-03,  2.2704e-02]],\n",
      "\n",
      "          [[ 1.8044e-02, -2.1212e-02,  3.1168e-02],\n",
      "           [ 2.6738e-02,  2.8522e-02,  1.4675e-02],\n",
      "           [ 1.0019e-02, -1.9722e-02,  1.8365e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 6.5708e-03,  1.7430e-02,  1.8103e-02],\n",
      "           [-2.5287e-02,  3.3600e-02,  2.3433e-02],\n",
      "           [ 2.4352e-02,  2.2172e-02, -6.1060e-03]],\n",
      "\n",
      "          [[ 4.1290e-02,  1.9475e-03,  2.2859e-02],\n",
      "           [ 8.9166e-03,  2.3469e-03,  1.3391e-02],\n",
      "           [ 6.9181e-03,  1.3922e-02, -3.1521e-03]],\n",
      "\n",
      "          [[-4.5057e-04,  2.7884e-02,  4.2074e-02],\n",
      "           [-1.9976e-02,  3.0891e-02,  2.8569e-02],\n",
      "           [ 5.3459e-03, -1.7486e-02,  1.2095e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.2454e-02,  1.5966e-02, -5.9505e-03],\n",
      "           [ 9.9500e-03,  2.2740e-02,  3.0934e-02],\n",
      "           [ 3.9987e-02,  4.1108e-02,  1.5130e-02]],\n",
      "\n",
      "          [[ 8.9239e-03,  4.1684e-02,  3.4719e-02],\n",
      "           [ 2.4150e-02,  2.3279e-02,  1.3393e-02],\n",
      "           [ 5.0318e-02,  2.0210e-02,  1.5078e-02]],\n",
      "\n",
      "          [[ 3.6118e-02,  2.6229e-02,  5.0372e-02],\n",
      "           [ 3.1009e-02,  2.1738e-02, -1.9710e-02],\n",
      "           [ 2.5303e-02,  1.7202e-03,  1.6178e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.7824e-02,  4.9237e-03, -8.3028e-03],\n",
      "           [ 1.3291e-02, -2.4090e-02, -4.6356e-02],\n",
      "           [-3.6740e-02, -3.5444e-02, -4.1933e-02]],\n",
      "\n",
      "          [[-6.3197e-04, -1.5187e-03, -4.0606e-02],\n",
      "           [-3.5325e-02, -4.9404e-02,  6.7901e-03],\n",
      "           [-4.9806e-02, -3.8922e-02,  2.6746e-03]],\n",
      "\n",
      "          [[ 2.0314e-02, -2.4550e-02,  5.6165e-03],\n",
      "           [-3.7735e-02, -4.4582e-02, -4.4805e-02],\n",
      "           [-4.6908e-02, -1.0255e-02, -3.1347e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.3148e-02,  2.4895e-02,  1.8982e-02],\n",
      "           [ 8.4402e-03,  3.5240e-03,  5.7468e-03],\n",
      "           [ 2.1377e-02,  2.0465e-02,  2.0646e-03]],\n",
      "\n",
      "          [[ 1.3361e-02,  3.2500e-02,  8.6474e-03],\n",
      "           [ 5.3422e-03,  1.5456e-02,  2.8259e-02],\n",
      "           [ 2.5127e-02,  3.0952e-02,  2.4259e-02]],\n",
      "\n",
      "          [[ 1.5938e-02,  1.8103e-02,  1.5481e-02],\n",
      "           [ 1.9514e-02,  1.7642e-02,  3.0707e-02],\n",
      "           [ 2.0938e-02,  2.0400e-02,  1.4265e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.6460e-02, -2.5991e-02, -4.8447e-04],\n",
      "           [-8.1471e-03,  1.1535e-02, -6.4477e-03],\n",
      "           [-2.7337e-02, -5.6691e-03,  1.1612e-02]],\n",
      "\n",
      "          [[-1.4937e-02,  2.4290e-02, -4.5096e-03],\n",
      "           [-6.4710e-03,  9.0894e-03,  1.7999e-02],\n",
      "           [-2.1253e-02,  6.0190e-03, -5.0886e-03]],\n",
      "\n",
      "          [[-9.9375e-03,  1.6477e-02,  2.9392e-02],\n",
      "           [-9.8041e-04,  2.8973e-02,  3.6465e-02],\n",
      "           [ 1.9269e-02,  1.3036e-03,  1.4145e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 5.7042e-03, -3.2172e-02,  2.1463e-02],\n",
      "           [-3.9199e-02,  6.0054e-03, -9.9796e-03],\n",
      "           [ 1.2132e-02, -1.5538e-02,  2.5268e-03]],\n",
      "\n",
      "          [[ 1.3399e-02,  2.0562e-02, -1.9734e-02],\n",
      "           [-1.1919e-03,  2.2182e-02,  2.7856e-03],\n",
      "           [-1.7686e-02,  1.2163e-02,  4.5287e-04]],\n",
      "\n",
      "          [[ 1.2646e-02,  2.2007e-02, -9.0707e-03],\n",
      "           [ 1.2131e-02, -1.0462e-02,  3.2251e-02],\n",
      "           [ 1.8540e-02,  1.6991e-02, -6.4446e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.8605e-02, -1.8878e-02,  7.6462e-03],\n",
      "           [ 8.3569e-03, -3.5784e-03, -1.3516e-02],\n",
      "           [-4.3393e-02, -1.7794e-02, -5.4227e-03]],\n",
      "\n",
      "          [[-1.4276e-02,  1.9714e-02,  3.0977e-02],\n",
      "           [-2.4430e-02, -3.1101e-02,  2.1554e-02],\n",
      "           [-5.0425e-02, -1.3900e-02,  1.5700e-02]],\n",
      "\n",
      "          [[ 3.1072e-02,  4.1869e-04, -1.9911e-02],\n",
      "           [-6.7114e-03,  2.3194e-02,  3.1896e-03],\n",
      "           [ 3.0217e-03,  2.6366e-02,  2.8471e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4075e-02,  3.8297e-02,  9.5043e-03],\n",
      "           [ 1.5680e-02,  2.5281e-02,  2.1079e-02],\n",
      "           [ 1.7288e-02,  4.2909e-02,  3.5606e-02]],\n",
      "\n",
      "          [[ 2.1435e-02, -1.0577e-02, -5.8255e-04],\n",
      "           [-8.9073e-03,  9.7517e-03, -6.4492e-03],\n",
      "           [ 1.1530e-03,  3.1036e-02, -7.0361e-03]],\n",
      "\n",
      "          [[ 2.5009e-03,  3.5298e-02,  1.2447e-02],\n",
      "           [ 2.0163e-02, -4.6394e-03,  1.9737e-03],\n",
      "           [-2.2939e-02, -7.5093e-03,  1.9101e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.1676e-02,  2.5670e-02,  2.9230e-02],\n",
      "           [-2.0340e-03, -2.7698e-02,  1.5332e-02],\n",
      "           [ 5.7702e-03, -2.7481e-02,  1.6623e-02]],\n",
      "\n",
      "          [[ 1.2521e-03,  3.1909e-02, -4.7576e-04],\n",
      "           [ 3.3853e-03, -7.7063e-03,  8.6575e-03],\n",
      "           [ 9.2772e-03,  6.0917e-03,  1.5444e-02]],\n",
      "\n",
      "          [[-1.0750e-02, -1.9919e-02, -1.0465e-02],\n",
      "           [-4.1705e-03,  2.9605e-03, -2.8309e-02],\n",
      "           [ 1.0493e-02,  1.2130e-02,  1.4776e-02]]],\n",
      "\n",
      "\n",
      "         [[[-9.7964e-03, -3.1737e-03,  5.4330e-03],\n",
      "           [-2.0021e-02, -1.7139e-02, -1.5245e-02],\n",
      "           [-7.2147e-03, -1.7280e-02, -4.1062e-03]],\n",
      "\n",
      "          [[-1.4438e-02, -3.2683e-02,  7.7622e-03],\n",
      "           [ 1.2848e-03, -3.4218e-02, -1.1412e-02],\n",
      "           [-1.6392e-02, -2.5324e-02, -6.0182e-04]],\n",
      "\n",
      "          [[-1.5692e-02,  6.8275e-03, -2.2200e-02],\n",
      "           [ 3.2477e-03, -3.2046e-03, -1.1724e-02],\n",
      "           [-1.9364e-02, -3.6903e-02,  8.0400e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.2807e-02, -2.5193e-02,  1.6109e-03],\n",
      "           [-2.1927e-02, -3.7756e-02, -2.3414e-02],\n",
      "           [-2.2636e-02, -5.4559e-02, -4.2552e-02]],\n",
      "\n",
      "          [[-3.7636e-02, -4.3902e-02, -3.2080e-02],\n",
      "           [-2.0687e-02, -4.3894e-02, -3.6801e-02],\n",
      "           [-1.8639e-02, -2.0508e-02, -5.7572e-02]],\n",
      "\n",
      "          [[ 1.3630e-02, -8.8092e-03, -3.5554e-02],\n",
      "           [-2.8880e-02, -4.4034e-03, -1.5623e-02],\n",
      "           [ 4.6550e-03, -1.9585e-02, -1.2735e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.2446e-02,  3.5215e-02, -6.7320e-03],\n",
      "           [ 1.8785e-02,  1.1743e-02, -7.0228e-03],\n",
      "           [ 1.9864e-02,  1.5686e-02, -1.3051e-02]],\n",
      "\n",
      "          [[ 2.4165e-02,  3.0790e-02,  1.2754e-02],\n",
      "           [ 1.0653e-02,  3.4432e-02, -8.7171e-04],\n",
      "           [ 1.6972e-02, -2.9130e-03, -3.3564e-02]],\n",
      "\n",
      "          [[-3.2962e-02,  2.6728e-02, -2.1381e-02],\n",
      "           [ 2.8612e-02, -2.4871e-02,  1.1009e-03],\n",
      "           [-9.1998e-03,  2.6834e-02,  8.4315e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.3710e-03, -1.0363e-03,  9.8312e-03],\n",
      "           [ 2.4365e-02,  3.2090e-02,  2.5402e-02],\n",
      "           [-9.4683e-03,  3.4465e-02,  2.1575e-02]],\n",
      "\n",
      "          [[-1.7855e-02,  1.6608e-02, -2.1753e-03],\n",
      "           [ 2.4829e-02, -7.1212e-03,  1.9795e-02],\n",
      "           [ 1.4057e-02, -6.7292e-03, -8.0890e-03]],\n",
      "\n",
      "          [[ 2.5608e-02,  9.4536e-03,  2.2441e-03],\n",
      "           [-2.9678e-03, -8.3715e-03,  2.4811e-03],\n",
      "           [-1.1368e-02, -1.2744e-02, -1.4585e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.5385e-02,  6.8447e-04, -5.7268e-03],\n",
      "           [-2.4230e-02, -1.2433e-02,  5.3310e-03],\n",
      "           [ 1.6030e-02,  1.0726e-02,  1.4952e-02]],\n",
      "\n",
      "          [[ 2.5792e-03,  1.0267e-02,  2.2505e-02],\n",
      "           [ 3.8206e-02,  4.0175e-02, -5.5290e-03],\n",
      "           [ 3.6910e-02, -3.2779e-03, -9.6843e-03]],\n",
      "\n",
      "          [[-1.9338e-02,  2.4588e-02,  6.9085e-03],\n",
      "           [ 3.6191e-02,  3.9598e-02,  2.3272e-02],\n",
      "           [ 1.7700e-02,  6.4614e-03,  1.4461e-03]]]]], device='cuda:0')), ('module.up_layers.2.0.norm1.weight', tensor([0.9799, 0.2383, 1.0260, 0.9689, 0.9349, 1.0471, 0.9767, 0.9808, 0.2235,\n",
      "        0.9589, 0.9718, 0.2279, 0.3325, 0.9752, 1.0168, 0.9618],\n",
      "       device='cuda:0')), ('module.up_layers.2.0.norm1.bias', tensor([-0.0249,  0.0080, -0.0949, -0.0424, -0.0675,  0.0106, -0.1264, -0.0770,\n",
      "        -0.0002, -0.0339, -0.0288,  0.0064,  0.0299, -0.0227, -0.0029, -0.0219],\n",
      "       device='cuda:0')), ('module.up_layers.2.0.norm2.weight', tensor([1.0418, 1.0228, 1.0358, 0.9645, 1.0083, 1.0442, 1.0325, 0.9989, 0.9659,\n",
      "        1.0356, 1.0186, 1.0462, 0.9990, 0.9670, 1.0312, 0.9916],\n",
      "       device='cuda:0')), ('module.up_layers.2.0.norm2.bias', tensor([-0.0005,  0.1071,  0.1163,  0.0396, -0.0236,  0.0953, -0.0243, -0.0790,\n",
      "         0.0623,  0.0458,  0.0477, -0.0929,  0.0203, -0.0389, -0.0729, -0.0171],\n",
      "       device='cuda:0')), ('module.up_layers.2.0.conv1.conv.weight', tensor([[[[[ 6.1416e-03,  1.5966e-02,  2.0158e-02],\n",
      "           [ 1.0824e-02,  2.8300e-03, -4.9212e-02],\n",
      "           [-7.0587e-02, -5.3096e-02, -6.5820e-02]],\n",
      "\n",
      "          [[ 1.0932e-02, -6.1418e-02, -1.5466e-02],\n",
      "           [ 1.7282e-02, -6.9301e-03, -6.2730e-02],\n",
      "           [ 1.9690e-02,  8.5427e-03, -2.4048e-02]],\n",
      "\n",
      "          [[ 1.9072e-02, -1.0946e-02, -4.0410e-02],\n",
      "           [-3.6999e-02, -3.1953e-02, -4.6789e-02],\n",
      "           [-4.3817e-02,  1.8286e-02,  1.9149e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.3918e-03, -1.3257e-03, -1.2543e-03],\n",
      "           [-1.4686e-03, -1.4085e-03, -1.3320e-03],\n",
      "           [-1.5802e-03, -1.5279e-03, -1.4513e-03]],\n",
      "\n",
      "          [[-1.2485e-03, -1.1969e-03, -1.1660e-03],\n",
      "           [-1.3997e-03, -1.3371e-03, -1.2674e-03],\n",
      "           [-1.5267e-03, -1.4560e-03, -1.3796e-03]],\n",
      "\n",
      "          [[-7.1520e-04, -7.2429e-04, -8.0814e-04],\n",
      "           [-1.0977e-03, -1.0771e-03, -1.0785e-03],\n",
      "           [-1.3098e-03, -1.2701e-03, -1.2327e-03]]],\n",
      "\n",
      "\n",
      "         [[[-3.1516e-03,  2.5088e-02, -1.6205e-02],\n",
      "           [-4.4070e-02, -6.4723e-03, -2.2978e-02],\n",
      "           [ 5.6449e-02,  5.3682e-02,  2.8434e-02]],\n",
      "\n",
      "          [[-8.3212e-03, -4.7159e-02, -5.7777e-02],\n",
      "           [ 5.6858e-03,  2.2786e-02,  3.6089e-02],\n",
      "           [ 9.3250e-03,  5.3698e-02,  5.0030e-02]],\n",
      "\n",
      "          [[-1.1267e-03, -6.7735e-02, -4.9633e-02],\n",
      "           [-1.8377e-02,  3.6550e-03,  1.1371e-02],\n",
      "           [-4.3799e-02, -4.1185e-02, -2.3156e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-9.4100e-03,  1.2210e-02, -3.8422e-02],\n",
      "           [ 5.2858e-03, -5.0863e-02, -2.8194e-03],\n",
      "           [-1.3582e-02, -5.2277e-02,  2.6419e-02]],\n",
      "\n",
      "          [[ 3.4569e-02,  2.6726e-02, -3.0387e-02],\n",
      "           [-1.4707e-02, -3.6382e-02, -1.6778e-02],\n",
      "           [-2.3225e-02,  2.8835e-02,  2.5180e-02]],\n",
      "\n",
      "          [[ 1.6164e-02, -4.1553e-02,  1.7170e-02],\n",
      "           [ 2.8337e-02, -5.1840e-02, -9.2894e-03],\n",
      "           [ 1.7910e-02,  1.4357e-02, -3.7607e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 5.7593e-02,  1.1101e-02,  1.5341e-02],\n",
      "           [ 3.9727e-02,  1.0972e-02,  6.3784e-02],\n",
      "           [-1.0627e-02,  5.3834e-02,  7.0906e-03]],\n",
      "\n",
      "          [[ 1.5870e-03,  3.4747e-02,  2.6887e-02],\n",
      "           [-1.8517e-03,  5.2422e-02,  1.1307e-03],\n",
      "           [-5.9576e-03,  3.7919e-02,  9.3267e-03]],\n",
      "\n",
      "          [[ 1.8798e-02,  5.0390e-02,  5.2492e-02],\n",
      "           [-1.7512e-02,  2.8277e-02, -3.1043e-02],\n",
      "           [ 4.9016e-02,  2.7569e-02, -1.5698e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.9224e-02,  2.2943e-03, -3.2537e-02],\n",
      "           [-1.9713e-02, -2.8900e-02,  3.3142e-02],\n",
      "           [-3.7761e-02,  1.2109e-02,  3.7417e-02]],\n",
      "\n",
      "          [[ 1.3509e-02, -4.2116e-02, -3.4401e-02],\n",
      "           [-3.6233e-02, -2.0305e-02,  2.1240e-02],\n",
      "           [-1.7205e-02,  7.1670e-03,  4.0498e-03]],\n",
      "\n",
      "          [[ 2.7851e-03, -3.6467e-02, -4.4456e-02],\n",
      "           [-2.6443e-02, -2.4867e-02,  3.3530e-02],\n",
      "           [-2.7569e-02,  1.7573e-02, -3.8711e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.1209e-02, -3.5912e-02, -1.3252e-02],\n",
      "           [-5.2772e-02, -3.0655e-02,  3.2213e-02],\n",
      "           [ 8.5490e-05, -4.6517e-02, -1.4506e-02]],\n",
      "\n",
      "          [[ 3.2061e-03, -2.8369e-02, -4.7803e-02],\n",
      "           [ 2.5231e-02,  2.8313e-02, -4.5229e-02],\n",
      "           [ 4.0960e-02,  3.0257e-02,  3.7040e-02]],\n",
      "\n",
      "          [[ 2.5444e-02,  3.8644e-02, -3.0213e-02],\n",
      "           [-1.2101e-03,  2.3608e-02, -7.3892e-03],\n",
      "           [ 2.0094e-02, -2.9436e-02, -9.7034e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 2.2172e-03,  2.5921e-03,  2.8993e-03],\n",
      "           [ 2.5048e-03,  2.8338e-03,  3.1347e-03],\n",
      "           [ 2.5668e-03,  2.8615e-03,  3.1490e-03]],\n",
      "\n",
      "          [[ 1.9268e-03,  2.3807e-03,  2.7314e-03],\n",
      "           [ 2.2094e-03,  2.6413e-03,  2.9561e-03],\n",
      "           [ 2.3211e-03,  2.6896e-03,  2.9731e-03]],\n",
      "\n",
      "          [[ 1.6873e-03,  2.1427e-03,  2.4735e-03],\n",
      "           [ 1.8419e-03,  2.2869e-03,  2.5945e-03],\n",
      "           [ 1.8406e-03,  2.2434e-03,  2.5357e-03]]],\n",
      "\n",
      "\n",
      "         [[[-2.6461e-02, -1.7444e-02, -1.3091e-02],\n",
      "           [ 2.9011e-02, -1.0188e-02, -2.4763e-02],\n",
      "           [ 3.0457e-02, -3.7018e-02,  4.1217e-03]],\n",
      "\n",
      "          [[ 5.4778e-03,  3.7468e-02,  9.7234e-04],\n",
      "           [ 3.5937e-03, -1.1893e-02,  3.4251e-03],\n",
      "           [-5.9769e-03,  2.8564e-02, -2.7330e-02]],\n",
      "\n",
      "          [[-5.0196e-02, -1.3957e-02,  1.0908e-02],\n",
      "           [-1.1647e-02,  3.2590e-02,  3.4522e-03],\n",
      "           [-2.9248e-02, -2.1921e-02, -2.0202e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-6.5041e-04,  3.3762e-02, -2.9217e-02],\n",
      "           [ 4.0299e-02, -1.5369e-02, -3.3163e-02],\n",
      "           [ 1.5743e-02, -3.1188e-02, -4.0669e-02]],\n",
      "\n",
      "          [[ 1.7887e-03, -3.2082e-02, -3.3045e-02],\n",
      "           [-4.4305e-02,  5.4111e-03,  1.0256e-02],\n",
      "           [ 3.2118e-02, -2.7069e-02,  1.1433e-02]],\n",
      "\n",
      "          [[ 1.8919e-02, -4.5779e-02, -7.9206e-03],\n",
      "           [-3.9903e-02, -4.5131e-02, -3.2527e-02],\n",
      "           [-1.7234e-02,  3.1429e-02, -2.8402e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.3945e-03, -3.1784e-02, -2.2535e-02],\n",
      "           [-1.8005e-02, -2.5105e-02,  8.7120e-03],\n",
      "           [-4.8857e-02,  2.1368e-02,  1.2661e-02]],\n",
      "\n",
      "          [[-3.8833e-02, -1.1867e-02,  4.7591e-02],\n",
      "           [ 6.0801e-03, -1.1790e-02,  3.9453e-02],\n",
      "           [ 1.6361e-02, -5.8854e-03, -2.7980e-02]],\n",
      "\n",
      "          [[ 3.2200e-02, -3.8318e-03,  4.0291e-03],\n",
      "           [ 6.3998e-04,  3.0984e-02, -6.8399e-03],\n",
      "           [ 3.6059e-02,  1.7002e-02, -3.0828e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2050e-02, -4.3305e-02, -4.1141e-02],\n",
      "           [ 1.5547e-02, -1.4032e-02,  3.4102e-02],\n",
      "           [-6.2456e-02, -2.0150e-02,  1.5292e-02]],\n",
      "\n",
      "          [[-5.8206e-02, -1.9539e-02, -1.5561e-02],\n",
      "           [-3.7815e-03,  1.1763e-02,  3.2998e-02],\n",
      "           [-5.2452e-02, -4.0218e-02, -3.0977e-02]],\n",
      "\n",
      "          [[-1.7378e-02, -7.4549e-03, -1.8362e-02],\n",
      "           [-4.4196e-02, -5.4044e-02,  3.4650e-03],\n",
      "           [-6.1755e-03,  1.3347e-02, -6.2589e-03]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.1210e-02,  2.5693e-02, -3.0556e-02],\n",
      "           [-3.4162e-03,  1.5824e-02,  2.8298e-02],\n",
      "           [ 2.2652e-02, -3.3537e-02, -5.0929e-02]],\n",
      "\n",
      "          [[ 4.9711e-03, -2.5317e-02,  1.1617e-02],\n",
      "           [ 9.7206e-03, -3.5576e-02, -8.3589e-03],\n",
      "           [-4.0008e-02, -5.5037e-02, -5.2624e-02]],\n",
      "\n",
      "          [[-5.7924e-02, -2.8634e-02, -2.6320e-02],\n",
      "           [-2.6342e-02, -1.9390e-02, -2.9206e-02],\n",
      "           [-1.1828e-02, -1.1460e-03,  2.6883e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 2.7505e-03,  2.9299e-03,  3.0159e-03],\n",
      "           [ 3.3045e-03,  3.4573e-03,  3.4933e-03],\n",
      "           [ 3.7879e-03,  3.8735e-03,  3.8401e-03]],\n",
      "\n",
      "          [[ 2.0967e-03,  2.4562e-03,  2.6296e-03],\n",
      "           [ 2.7285e-03,  3.0967e-03,  3.2191e-03],\n",
      "           [ 3.3447e-03,  3.6678e-03,  3.7282e-03]],\n",
      "\n",
      "          [[ 1.4500e-03,  1.7121e-03,  1.9213e-03],\n",
      "           [ 1.9433e-03,  2.2426e-03,  2.4099e-03],\n",
      "           [ 2.5293e-03,  2.7990e-03,  2.9231e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.7932e-02,  5.1536e-02,  1.4803e-02],\n",
      "           [ 5.4211e-02, -8.7214e-03, -6.4321e-03],\n",
      "           [-2.9275e-02,  1.6863e-02,  1.9850e-02]],\n",
      "\n",
      "          [[-3.5466e-02,  3.2531e-02, -2.8054e-02],\n",
      "           [ 1.1418e-02, -3.3749e-02, -1.9114e-02],\n",
      "           [ 3.7253e-02,  2.5116e-02, -3.2541e-02]],\n",
      "\n",
      "          [[-5.0119e-02, -5.6652e-03, -4.5013e-02],\n",
      "           [ 4.8305e-03,  2.0856e-02, -1.9517e-03],\n",
      "           [ 4.1438e-02, -2.5430e-02,  1.4490e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.1334e-02,  2.5882e-02,  1.5009e-02],\n",
      "           [-2.1116e-02, -2.2265e-02,  2.7509e-02],\n",
      "           [-4.0215e-02, -3.9332e-02,  2.2813e-02]],\n",
      "\n",
      "          [[ 4.9294e-03, -2.5594e-02,  2.7520e-02],\n",
      "           [ 1.2094e-02, -1.3978e-02, -1.3726e-02],\n",
      "           [-9.1894e-03,  2.5574e-02,  1.5694e-02]],\n",
      "\n",
      "          [[ 2.2732e-02, -2.9250e-02, -3.6184e-02],\n",
      "           [-5.0370e-03, -3.8094e-02, -2.7115e-02],\n",
      "           [ 2.8608e-02,  2.5605e-02, -1.4398e-02]]],\n",
      "\n",
      "\n",
      "         [[[-2.2734e-02, -4.0616e-02, -1.0324e-02],\n",
      "           [-1.6366e-02,  1.4981e-02,  2.0533e-02],\n",
      "           [ 4.0041e-02, -3.0472e-02,  3.9063e-02]],\n",
      "\n",
      "          [[ 7.9593e-03,  1.6015e-02,  2.0408e-04],\n",
      "           [ 1.6823e-02,  2.4270e-02,  2.6631e-02],\n",
      "           [-1.0385e-02,  1.9714e-02,  3.6535e-02]],\n",
      "\n",
      "          [[-1.3213e-02, -3.0904e-03,  3.1524e-02],\n",
      "           [-1.3027e-02,  3.5097e-02,  3.0311e-02],\n",
      "           [-1.2430e-02,  2.1776e-02, -1.5891e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.7355e-02,  7.0122e-03, -5.0520e-02],\n",
      "           [-8.3657e-03,  1.1321e-02, -1.8673e-02],\n",
      "           [ 7.2035e-03,  2.0826e-02, -4.8260e-02]],\n",
      "\n",
      "          [[-4.1325e-02,  6.1470e-03, -1.1017e-02],\n",
      "           [-1.1974e-02,  6.4782e-03,  1.0771e-02],\n",
      "           [-7.6378e-03, -1.2737e-02, -4.6505e-02]],\n",
      "\n",
      "          [[ 1.9650e-02,  1.4877e-02,  1.2331e-02],\n",
      "           [-5.7024e-02, -4.0461e-02, -5.0749e-02],\n",
      "           [ 1.4241e-02, -7.7135e-03,  2.5712e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.6550e-02,  3.4875e-02,  2.4737e-02],\n",
      "           [-2.0924e-02,  3.2005e-02, -2.7162e-02],\n",
      "           [-5.2988e-03, -5.9465e-03,  6.1280e-03]],\n",
      "\n",
      "          [[-4.1212e-02, -3.7676e-02,  3.9906e-02],\n",
      "           [-2.9807e-02, -1.1634e-02, -1.8625e-02],\n",
      "           [-1.6312e-02, -2.6205e-02, -2.1190e-02]],\n",
      "\n",
      "          [[ 7.0561e-03,  3.8351e-02,  2.7890e-02],\n",
      "           [ 3.6054e-02,  8.8011e-03, -3.1914e-02],\n",
      "           [ 8.5480e-03,  1.3333e-02,  3.7910e-02]]],\n",
      "\n",
      "\n",
      "         [[[-3.6546e-03, -3.8617e-03, -3.9376e-03],\n",
      "           [-3.6579e-03, -3.8500e-03, -3.9109e-03],\n",
      "           [-3.2508e-03, -3.4162e-03, -3.4826e-03]],\n",
      "\n",
      "          [[-3.3899e-03, -3.6303e-03, -3.7356e-03],\n",
      "           [-3.3749e-03, -3.6286e-03, -3.7334e-03],\n",
      "           [-2.9814e-03, -3.2516e-03, -3.3783e-03]],\n",
      "\n",
      "          [[-3.2123e-03, -3.4143e-03, -3.4701e-03],\n",
      "           [-3.1131e-03, -3.2698e-03, -3.3121e-03],\n",
      "           [-2.6713e-03, -2.8491e-03, -2.9006e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 8.0410e-03, -1.6283e-02,  4.7167e-02],\n",
      "           [ 1.1386e-02,  2.8781e-02, -4.4781e-02],\n",
      "           [-1.4793e-02, -2.7224e-02, -3.6794e-02]],\n",
      "\n",
      "          [[ 1.0107e-02,  4.1626e-03,  4.1358e-02],\n",
      "           [-3.3056e-02,  3.1758e-03, -5.6911e-02],\n",
      "           [-1.4384e-02, -3.5474e-02, -4.6312e-02]],\n",
      "\n",
      "          [[ 4.8547e-02,  3.7913e-02,  3.0032e-02],\n",
      "           [-3.0512e-02,  4.8263e-03, -5.2407e-02],\n",
      "           [ 3.4333e-02,  2.9221e-03,  1.0605e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.5276e-02,  4.4082e-02,  3.5048e-02],\n",
      "           [ 2.2090e-02,  4.2348e-02, -5.0226e-03],\n",
      "           [ 2.4240e-02, -9.5479e-03,  1.1724e-02]],\n",
      "\n",
      "          [[-3.3582e-02,  2.4105e-02, -3.3219e-02],\n",
      "           [-7.9751e-03,  3.9781e-03,  3.6194e-02],\n",
      "           [ 2.6402e-03, -5.7553e-03, -9.8145e-03]],\n",
      "\n",
      "          [[-1.2262e-02,  1.1068e-02, -4.6429e-02],\n",
      "           [-1.1027e-02, -2.7102e-02,  5.1055e-02],\n",
      "           [ 3.7434e-02,  4.2494e-02, -5.5002e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 1.0752e-03,  5.1456e-02, -1.3747e-04],\n",
      "           [ 1.3052e-02,  1.1731e-03, -9.0168e-03],\n",
      "           [ 5.1260e-02,  2.1706e-02,  4.0437e-02]],\n",
      "\n",
      "          [[ 6.2172e-02,  6.4039e-02,  2.2425e-03],\n",
      "           [ 2.0666e-02, -1.0036e-02,  2.8764e-02],\n",
      "           [ 2.7979e-03, -2.8315e-02, -8.8999e-03]],\n",
      "\n",
      "          [[ 4.3683e-02,  5.3741e-02,  2.8756e-02],\n",
      "           [ 1.6724e-02, -5.2246e-03, -3.1853e-02],\n",
      "           [ 4.6685e-03,  1.5598e-02, -3.7117e-02]]],\n",
      "\n",
      "\n",
      "         [[[-6.6812e-02, -5.8216e-02,  2.5023e-02],\n",
      "           [ 1.6064e-02,  3.2328e-03, -2.4098e-02],\n",
      "           [ 8.8691e-03, -4.0468e-02, -6.0706e-02]],\n",
      "\n",
      "          [[-6.2206e-02, -6.6328e-02,  4.5304e-03],\n",
      "           [ 1.3020e-02, -5.1854e-03, -2.9120e-02],\n",
      "           [-2.6471e-02, -4.7871e-02, -5.0294e-02]],\n",
      "\n",
      "          [[ 1.4684e-02,  2.5222e-03, -1.9542e-02],\n",
      "           [-4.3083e-02, -4.5059e-02, -1.2906e-02],\n",
      "           [-1.5621e-02, -3.6758e-02, -3.4215e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.0673e-02,  3.6046e-02,  3.0469e-02],\n",
      "           [ 5.6079e-03, -1.8231e-02,  4.1274e-02],\n",
      "           [ 6.4113e-03, -3.5952e-02,  2.0882e-02]],\n",
      "\n",
      "          [[ 3.8700e-02, -2.8081e-02,  1.7028e-02],\n",
      "           [ 3.6008e-02, -1.3352e-02,  8.2315e-03],\n",
      "           [-7.2408e-03,  4.0393e-02,  3.7542e-02]],\n",
      "\n",
      "          [[ 4.2024e-02,  5.6926e-02, -2.0332e-02],\n",
      "           [ 1.7737e-03,  3.5327e-02,  5.0948e-02],\n",
      "           [-2.5094e-02,  4.6144e-02,  3.6101e-02]]],\n",
      "\n",
      "\n",
      "         [[[-4.0052e-03, -4.3828e-03, -4.5544e-03],\n",
      "           [-5.1390e-03, -5.4869e-03, -5.5401e-03],\n",
      "           [-6.1338e-03, -6.4325e-03, -6.4493e-03]],\n",
      "\n",
      "          [[-3.5287e-03, -3.8555e-03, -3.9995e-03],\n",
      "           [-4.5112e-03, -4.8645e-03, -4.9274e-03],\n",
      "           [-5.7256e-03, -6.0272e-03, -6.0136e-03]],\n",
      "\n",
      "          [[-3.1261e-03, -3.2888e-03, -3.2765e-03],\n",
      "           [-3.7857e-03, -4.0193e-03, -3.9811e-03],\n",
      "           [-5.1117e-03, -5.3470e-03, -5.2383e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 3.6685e-02,  1.9845e-02, -1.8869e-02],\n",
      "           [-1.2356e-02,  4.2554e-02,  5.8731e-02],\n",
      "           [ 3.1202e-02,  1.1309e-03, -4.6270e-03]],\n",
      "\n",
      "          [[ 6.4475e-02, -2.0328e-02,  1.1065e-02],\n",
      "           [-9.1049e-03,  4.7639e-02,  4.6723e-02],\n",
      "           [ 6.4505e-03, -7.8595e-03,  1.2346e-02]],\n",
      "\n",
      "          [[ 6.8671e-02,  5.9595e-02,  3.6532e-02],\n",
      "           [ 5.9368e-02,  5.7399e-02,  1.3215e-02],\n",
      "           [ 5.2361e-02,  4.2137e-02,  2.1657e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.8255e-02,  1.8756e-02, -3.3013e-02],\n",
      "           [ 1.5223e-02, -1.4599e-02, -3.6235e-02],\n",
      "           [-3.2987e-02,  2.6384e-02, -3.3175e-02]],\n",
      "\n",
      "          [[-2.2274e-02,  2.3911e-02, -3.7148e-02],\n",
      "           [-1.5355e-02, -2.3793e-03,  1.4004e-02],\n",
      "           [-1.8493e-02,  3.7639e-03,  3.4911e-02]],\n",
      "\n",
      "          [[-2.0086e-02, -2.7585e-02,  9.8213e-03],\n",
      "           [ 8.4011e-04,  4.1952e-02,  2.4812e-02],\n",
      "           [-2.4751e-02,  5.0921e-02,  3.0513e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 7.1710e-02,  1.0236e-01,  1.0625e-01],\n",
      "           [ 7.7019e-02,  9.8088e-02,  2.2030e-02],\n",
      "           [ 8.7402e-03,  9.6283e-02,  9.2489e-02]],\n",
      "\n",
      "          [[ 6.2406e-02,  1.0194e-01,  3.1779e-02],\n",
      "           [ 8.0362e-02,  6.0033e-02,  8.3134e-02],\n",
      "           [ 1.5141e-02,  7.2368e-02,  6.2786e-02]],\n",
      "\n",
      "          [[ 4.0304e-02,  1.1257e-01,  1.1192e-01],\n",
      "           [ 3.2735e-02,  4.7990e-02,  3.6294e-02],\n",
      "           [ 4.4007e-02,  5.5366e-02,  1.0358e-01]]],\n",
      "\n",
      "\n",
      "         [[[-1.2417e-02, -4.2433e-02,  1.3697e-02],\n",
      "           [-3.8682e-02,  2.5969e-02,  6.9536e-03],\n",
      "           [ 3.5363e-02, -2.1618e-02,  4.6882e-03]],\n",
      "\n",
      "          [[-2.8988e-02, -3.3601e-02,  9.5201e-03],\n",
      "           [-3.5755e-04, -2.0537e-02, -3.1764e-02],\n",
      "           [ 2.4487e-02, -3.9237e-02, -3.7015e-02]],\n",
      "\n",
      "          [[-4.2686e-02, -2.8082e-02, -6.4251e-03],\n",
      "           [ 1.1177e-02,  2.2273e-02, -3.9036e-02],\n",
      "           [-3.6630e-02, -3.1788e-02,  3.5091e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-2.1458e-02, -1.0532e-02,  2.5864e-02],\n",
      "           [-3.6438e-02,  1.8608e-02, -3.0150e-02],\n",
      "           [-4.0260e-02,  1.3378e-02, -1.2313e-02]],\n",
      "\n",
      "          [[ 3.7922e-02,  4.4730e-02,  1.7718e-02],\n",
      "           [-5.2195e-03, -2.3614e-03,  1.7226e-02],\n",
      "           [ 4.0727e-04,  2.5342e-02, -1.2889e-02]],\n",
      "\n",
      "          [[-4.5478e-02, -1.7358e-02,  2.0765e-02],\n",
      "           [-1.2984e-02, -3.3876e-02, -9.1398e-03],\n",
      "           [-1.6926e-02, -3.2116e-02,  1.0455e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 3.0240e-03,  2.9026e-03,  2.8237e-03],\n",
      "           [ 3.0752e-03,  2.8835e-03,  2.7872e-03],\n",
      "           [ 3.3539e-03,  3.1542e-03,  3.0964e-03]],\n",
      "\n",
      "          [[ 3.1814e-03,  3.1546e-03,  3.0630e-03],\n",
      "           [ 3.4661e-03,  3.3521e-03,  3.2236e-03],\n",
      "           [ 3.8246e-03,  3.6957e-03,  3.6105e-03]],\n",
      "\n",
      "          [[ 2.8549e-03,  3.0121e-03,  3.0480e-03],\n",
      "           [ 3.5133e-03,  3.5632e-03,  3.4749e-03],\n",
      "           [ 4.0425e-03,  4.0162e-03,  3.9024e-03]]],\n",
      "\n",
      "\n",
      "         [[[ 4.8843e-02,  4.6896e-02,  6.8250e-02],\n",
      "           [ 6.3027e-02,  1.7370e-02,  2.2161e-02],\n",
      "           [ 1.7769e-02,  8.0795e-02,  5.5461e-02]],\n",
      "\n",
      "          [[ 5.7209e-02,  8.5597e-02, -3.5424e-03],\n",
      "           [ 6.2006e-03,  4.1480e-03, -3.3613e-03],\n",
      "           [ 3.5778e-02,  7.6371e-02,  7.7076e-02]],\n",
      "\n",
      "          [[ 8.9583e-02,  8.4512e-02,  6.6875e-03],\n",
      "           [ 2.4537e-02,  2.6292e-02,  3.5057e-02],\n",
      "           [ 4.5994e-02,  7.4535e-02,  7.1940e-02]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 4.4218e-02, -1.4920e-03, -5.6197e-03],\n",
      "           [ 4.0554e-02, -4.0420e-02,  3.5037e-02],\n",
      "           [-3.7485e-02,  7.0245e-03,  1.1118e-02]],\n",
      "\n",
      "          [[-3.4177e-02, -2.1986e-02,  2.3403e-02],\n",
      "           [ 3.8569e-02, -2.3497e-02,  1.0894e-03],\n",
      "           [ 2.5055e-03,  2.2657e-02, -1.8866e-02]],\n",
      "\n",
      "          [[-4.2196e-02,  1.5252e-02,  3.8221e-02],\n",
      "           [ 3.6185e-02, -3.4538e-02, -1.5748e-02],\n",
      "           [-1.5832e-02,  4.0559e-02,  4.0625e-02]]],\n",
      "\n",
      "\n",
      "         [[[ 4.9187e-02,  1.5382e-02,  1.6016e-02],\n",
      "           [ 8.4410e-02,  4.6494e-02,  6.8649e-02],\n",
      "           [ 7.5915e-02,  5.1241e-02,  4.1541e-02]],\n",
      "\n",
      "          [[ 2.5060e-02,  1.4324e-02,  7.6446e-02],\n",
      "           [ 7.3362e-02,  3.9333e-02,  8.4165e-02],\n",
      "           [ 1.0086e-01,  2.1668e-02,  3.0169e-02]],\n",
      "\n",
      "          [[ 4.8208e-02,  3.6118e-02,  8.2239e-02],\n",
      "           [ 2.0854e-02,  6.6627e-02,  6.7518e-02],\n",
      "           [ 4.7396e-02,  4.3869e-02,  3.6854e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.2073e-02, -3.3314e-02, -2.1765e-02],\n",
      "           [-3.5491e-02, -3.3761e-02,  9.0136e-03],\n",
      "           [ 2.5049e-02,  5.0885e-02, -1.7692e-03]],\n",
      "\n",
      "          [[ 2.2636e-02,  6.6549e-03, -2.6734e-02],\n",
      "           [ 1.6999e-02,  3.9076e-02, -1.2331e-02],\n",
      "           [ 2.5737e-02, -3.6714e-02, -1.3887e-04]],\n",
      "\n",
      "          [[-1.2928e-02,  3.7451e-02,  4.5101e-02],\n",
      "           [ 2.0691e-02,  2.5946e-02,  5.2916e-02],\n",
      "           [ 2.3939e-02,  4.9778e-02, -2.3839e-02]]]]], device='cuda:0')), ('module.up_layers.2.0.conv2.conv.weight', tensor([[[[[ 0.0380,  0.0182,  0.0402],\n",
      "           [-0.0688, -0.0407, -0.0739],\n",
      "           [-0.0489, -0.1016, -0.0514]],\n",
      "\n",
      "          [[ 0.0555,  0.0737, -0.0060],\n",
      "           [-0.0482, -0.0237,  0.0065],\n",
      "           [-0.0738, -0.0105, -0.0455]],\n",
      "\n",
      "          [[ 0.0011,  0.0080,  0.0124],\n",
      "           [-0.0148,  0.0264, -0.0083],\n",
      "           [-0.0008, -0.0285, -0.0943]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0328,  0.0172,  0.0267],\n",
      "           [ 0.0461,  0.0285,  0.0309],\n",
      "           [ 0.0580,  0.0239, -0.0173]],\n",
      "\n",
      "          [[ 0.0635,  0.0635,  0.0555],\n",
      "           [ 0.0087,  0.0652,  0.0446],\n",
      "           [ 0.0778,  0.0038,  0.0499]],\n",
      "\n",
      "          [[-0.0087,  0.0270,  0.0349],\n",
      "           [ 0.0288,  0.0794, -0.0241],\n",
      "           [ 0.0173,  0.0518,  0.0520]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0819,  0.0463,  0.0731],\n",
      "           [ 0.0740,  0.0647,  0.0647],\n",
      "           [ 0.0402,  0.0783,  0.0513]],\n",
      "\n",
      "          [[ 0.0952,  0.1023,  0.1055],\n",
      "           [ 0.0437,  0.0889,  0.0570],\n",
      "           [ 0.0216,  0.0376,  0.0052]],\n",
      "\n",
      "          [[ 0.0588,  0.0646,  0.0919],\n",
      "           [ 0.0182,  0.0714,  0.0908],\n",
      "           [ 0.0043,  0.0486,  0.0676]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0833, -0.0882, -0.0890],\n",
      "           [-0.0494, -0.0446, -0.0231],\n",
      "           [ 0.0130,  0.0197,  0.0015]],\n",
      "\n",
      "          [[-0.0572, -0.0768, -0.0787],\n",
      "           [-0.0396, -0.0300, -0.0308],\n",
      "           [-0.0118,  0.0137,  0.0014]],\n",
      "\n",
      "          [[-0.0656, -0.0704, -0.0830],\n",
      "           [-0.0550, -0.0500, -0.0197],\n",
      "           [-0.0134, -0.0005, -0.0207]]],\n",
      "\n",
      "\n",
      "         [[[-0.0245,  0.0027,  0.0299],\n",
      "           [-0.0413,  0.0250,  0.0050],\n",
      "           [-0.0460, -0.0104, -0.0035]],\n",
      "\n",
      "          [[ 0.0223,  0.0344, -0.0190],\n",
      "           [ 0.0467,  0.0231,  0.0358],\n",
      "           [-0.0276, -0.0236,  0.0375]],\n",
      "\n",
      "          [[ 0.0042, -0.0430,  0.0090],\n",
      "           [-0.0435, -0.0212, -0.0056],\n",
      "           [-0.0009, -0.0453, -0.0526]]],\n",
      "\n",
      "\n",
      "         [[[-0.0356, -0.0330,  0.0324],\n",
      "           [-0.0134,  0.0433, -0.0046],\n",
      "           [ 0.0155, -0.0130,  0.0440]],\n",
      "\n",
      "          [[ 0.0242, -0.0359,  0.0399],\n",
      "           [-0.0059,  0.0176, -0.0327],\n",
      "           [ 0.0300, -0.0288, -0.0197]],\n",
      "\n",
      "          [[-0.0312,  0.0054, -0.0157],\n",
      "           [ 0.0420,  0.0328, -0.0231],\n",
      "           [-0.0261, -0.0398, -0.0326]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0006, -0.0246,  0.0341],\n",
      "           [ 0.0316, -0.0173,  0.0240],\n",
      "           [ 0.0206, -0.0052,  0.0317]],\n",
      "\n",
      "          [[ 0.0358,  0.0136, -0.0102],\n",
      "           [-0.0072,  0.0259,  0.0086],\n",
      "           [-0.0111,  0.0158, -0.0328]],\n",
      "\n",
      "          [[ 0.0388,  0.0166, -0.0236],\n",
      "           [-0.0294,  0.0310, -0.0336],\n",
      "           [ 0.0012,  0.0297, -0.0155]]],\n",
      "\n",
      "\n",
      "         [[[-0.0465, -0.0572, -0.0272],\n",
      "           [-0.0480, -0.0626, -0.0078],\n",
      "           [-0.0289, -0.0326, -0.0390]],\n",
      "\n",
      "          [[-0.0437, -0.0062, -0.0234],\n",
      "           [-0.0495,  0.0123, -0.0419],\n",
      "           [-0.0251, -0.0112, -0.0152]],\n",
      "\n",
      "          [[ 0.0285, -0.0304,  0.0139],\n",
      "           [-0.0100, -0.0081, -0.0313],\n",
      "           [ 0.0163, -0.0307, -0.0449]]],\n",
      "\n",
      "\n",
      "         [[[-0.0350, -0.0330, -0.0238],\n",
      "           [-0.0221, -0.0303, -0.0264],\n",
      "           [-0.0508, -0.0381, -0.0304]],\n",
      "\n",
      "          [[-0.0604, -0.0608, -0.0594],\n",
      "           [ 0.0006, -0.0503, -0.0153],\n",
      "           [ 0.0089, -0.0034, -0.0432]],\n",
      "\n",
      "          [[-0.0083, -0.0100, -0.0554],\n",
      "           [-0.0480,  0.0114,  0.0085],\n",
      "           [-0.0193, -0.0068, -0.0206]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0033, -0.0073, -0.0083],\n",
      "           [ 0.0111, -0.0063, -0.0053],\n",
      "           [ 0.0009,  0.0115,  0.0044]],\n",
      "\n",
      "          [[ 0.0107, -0.0053, -0.0002],\n",
      "           [ 0.0032, -0.0067, -0.0013],\n",
      "           [-0.0078, -0.0079,  0.0065]],\n",
      "\n",
      "          [[ 0.0253,  0.0265,  0.0203],\n",
      "           [ 0.0180,  0.0008,  0.0011],\n",
      "           [ 0.0022,  0.0217,  0.0022]]],\n",
      "\n",
      "\n",
      "         [[[-0.0377, -0.0245, -0.0100],\n",
      "           [-0.0213, -0.0220,  0.0156],\n",
      "           [ 0.0311, -0.0313,  0.0386]],\n",
      "\n",
      "          [[ 0.0340,  0.0423,  0.0384],\n",
      "           [-0.0084,  0.0139,  0.0288],\n",
      "           [-0.0015,  0.0159, -0.0347]],\n",
      "\n",
      "          [[ 0.0107, -0.0040, -0.0411],\n",
      "           [-0.0225, -0.0134, -0.0406],\n",
      "           [-0.0037, -0.0193, -0.0266]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0047,  0.0516,  0.0266],\n",
      "           [ 0.0397,  0.0498, -0.0080],\n",
      "           [ 0.0121,  0.0356, -0.0277]],\n",
      "\n",
      "          [[ 0.0343, -0.0135,  0.0330],\n",
      "           [-0.0272, -0.0128,  0.0099],\n",
      "           [-0.0134,  0.0082, -0.0331]],\n",
      "\n",
      "          [[ 0.0404, -0.0056, -0.0138],\n",
      "           [ 0.0144, -0.0217,  0.0307],\n",
      "           [-0.0005, -0.0376, -0.0322]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0773,  0.0871,  0.0936],\n",
      "           [ 0.0154,  0.0851,  0.0856],\n",
      "           [ 0.0175,  0.0387,  0.0181]],\n",
      "\n",
      "          [[ 0.0457,  0.0770,  0.0740],\n",
      "           [ 0.0227,  0.0679,  0.0417],\n",
      "           [ 0.0909,  0.1018,  0.0894]],\n",
      "\n",
      "          [[ 0.0454,  0.0430,  0.0425],\n",
      "           [ 0.0534,  0.0276,  0.1007],\n",
      "           [ 0.0633,  0.0991,  0.0759]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0191,  0.0389, -0.0261],\n",
      "           [ 0.0157, -0.0363,  0.0432],\n",
      "           [ 0.0356,  0.0342, -0.0220]],\n",
      "\n",
      "          [[-0.0326, -0.0155, -0.0380],\n",
      "           [-0.0369,  0.0247, -0.0105],\n",
      "           [-0.0263,  0.0086,  0.0344]],\n",
      "\n",
      "          [[ 0.0286,  0.0325, -0.0398],\n",
      "           [ 0.0366,  0.0347,  0.0502],\n",
      "           [ 0.0317,  0.0373,  0.0300]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0287,  0.0041,  0.0264],\n",
      "           [-0.0192,  0.0487,  0.0082],\n",
      "           [ 0.0078,  0.0364,  0.0548]],\n",
      "\n",
      "          [[ 0.0004,  0.0521,  0.0528],\n",
      "           [ 0.0649, -0.0242,  0.0397],\n",
      "           [ 0.0171, -0.0058,  0.0181]],\n",
      "\n",
      "          [[ 0.0425, -0.0251,  0.0354],\n",
      "           [-0.0148, -0.0245,  0.0303],\n",
      "           [-0.0246, -0.0151,  0.0328]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0289,  0.0333,  0.0306],\n",
      "           [ 0.0417,  0.0474,  0.0467],\n",
      "           [ 0.0429,  0.0471,  0.0489]],\n",
      "\n",
      "          [[ 0.0247,  0.0316,  0.0254],\n",
      "           [ 0.0495,  0.0572,  0.0457],\n",
      "           [ 0.0525,  0.0585,  0.0524]],\n",
      "\n",
      "          [[ 0.0171,  0.0175,  0.0155],\n",
      "           [ 0.0387,  0.0428,  0.0328],\n",
      "           [ 0.0519,  0.0541,  0.0580]]],\n",
      "\n",
      "\n",
      "         [[[-0.0217,  0.0371,  0.0416],\n",
      "           [-0.0231,  0.0082, -0.0303],\n",
      "           [-0.0303,  0.0164,  0.0034]],\n",
      "\n",
      "          [[ 0.0401, -0.0239,  0.0345],\n",
      "           [ 0.0373, -0.0409,  0.0202],\n",
      "           [-0.0060, -0.0242,  0.0450]],\n",
      "\n",
      "          [[ 0.0405,  0.0063, -0.0026],\n",
      "           [ 0.0118,  0.0155, -0.0006],\n",
      "           [ 0.0512,  0.0125, -0.0213]]],\n",
      "\n",
      "\n",
      "         [[[-0.0831, -0.0899, -0.0906],\n",
      "           [-0.0475, -0.0669, -0.0766],\n",
      "           [-0.0487, -0.0387, -0.0783]],\n",
      "\n",
      "          [[-0.0719, -0.0395, -0.0479],\n",
      "           [-0.0571, -0.0862, -0.0956],\n",
      "           [-0.0846, -0.0774, -0.0553]],\n",
      "\n",
      "          [[-0.0567, -0.0401, -0.0460],\n",
      "           [-0.0523, -0.0485, -0.0528],\n",
      "           [-0.0172, -0.0230, -0.0934]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0121, -0.0081, -0.0459],\n",
      "           [-0.0233, -0.0424, -0.0890],\n",
      "           [-0.0971, -0.0342, -0.0912]],\n",
      "\n",
      "          [[-0.0032, -0.0048, -0.0247],\n",
      "           [-0.0034,  0.0202,  0.0146],\n",
      "           [-0.0229, -0.0477, -0.1128]],\n",
      "\n",
      "          [[ 0.0232,  0.0463, -0.0274],\n",
      "           [ 0.0220, -0.0084,  0.0130],\n",
      "           [-0.0367, -0.0653, -0.0662]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0080,  0.0212,  0.0654],\n",
      "           [ 0.1009,  0.1017,  0.0498],\n",
      "           [ 0.0763,  0.0364,  0.0164]],\n",
      "\n",
      "          [[ 0.0634,  0.0708,  0.0076],\n",
      "           [ 0.0507,  0.0153,  0.0660],\n",
      "           [ 0.0550,  0.0141,  0.0671]],\n",
      "\n",
      "          [[ 0.0639, -0.0040,  0.0123],\n",
      "           [ 0.0409,  0.0402,  0.0299],\n",
      "           [ 0.0454,  0.0177,  0.0568]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0312,  0.0077,  0.0716],\n",
      "           [ 0.0290,  0.0318,  0.0418],\n",
      "           [ 0.0524,  0.0571,  0.0116]],\n",
      "\n",
      "          [[ 0.0655,  0.0374,  0.0124],\n",
      "           [ 0.0703,  0.0706,  0.0520],\n",
      "           [ 0.0327,  0.0539,  0.0091]],\n",
      "\n",
      "          [[ 0.0714,  0.0732,  0.0681],\n",
      "           [ 0.0290,  0.0787,  0.0538],\n",
      "           [ 0.0043,  0.0697,  0.0220]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0659, -0.0524, -0.0724],\n",
      "           [-0.0317, -0.0089, -0.0468],\n",
      "           [-0.0162, -0.0108, -0.0090]],\n",
      "\n",
      "          [[-0.0724, -0.0680, -0.0606],\n",
      "           [-0.0438, -0.0237, -0.0362],\n",
      "           [-0.0107, -0.0118,  0.0042]],\n",
      "\n",
      "          [[-0.0748, -0.0699, -0.0773],\n",
      "           [-0.0357, -0.0416, -0.0234],\n",
      "           [-0.0160, -0.0313, -0.0075]]],\n",
      "\n",
      "\n",
      "         [[[-0.0408, -0.0357,  0.0266],\n",
      "           [ 0.0098, -0.0218, -0.0222],\n",
      "           [ 0.0383,  0.0039,  0.0445]],\n",
      "\n",
      "          [[ 0.0152, -0.0197, -0.0144],\n",
      "           [ 0.0140,  0.0161, -0.0072],\n",
      "           [-0.0219, -0.0329, -0.0201]],\n",
      "\n",
      "          [[ 0.0101, -0.0261, -0.0188],\n",
      "           [ 0.0328, -0.0094,  0.0265],\n",
      "           [-0.0368,  0.0324, -0.0155]]],\n",
      "\n",
      "\n",
      "         [[[-0.0361,  0.0078, -0.0276],\n",
      "           [-0.0423,  0.0010, -0.0212],\n",
      "           [-0.0238,  0.0150, -0.0137]],\n",
      "\n",
      "          [[-0.0046, -0.0256,  0.0447],\n",
      "           [-0.0167,  0.0380,  0.0044],\n",
      "           [ 0.0095,  0.0172,  0.0416]],\n",
      "\n",
      "          [[-0.0342, -0.0164,  0.0305],\n",
      "           [ 0.0382,  0.0362,  0.0025],\n",
      "           [-0.0099,  0.0061, -0.0112]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0246, -0.0247,  0.0359],\n",
      "           [-0.0061,  0.0216,  0.0339],\n",
      "           [ 0.0220, -0.0035,  0.0045]],\n",
      "\n",
      "          [[ 0.0038, -0.0223,  0.0125],\n",
      "           [ 0.0077,  0.0041,  0.0165],\n",
      "           [-0.0207, -0.0077,  0.0181]],\n",
      "\n",
      "          [[-0.0224, -0.0341,  0.0122],\n",
      "           [-0.0029,  0.0345, -0.0051],\n",
      "           [ 0.0131, -0.0004, -0.0030]]],\n",
      "\n",
      "\n",
      "         [[[-0.0649, -0.0791, -0.0208],\n",
      "           [-0.0760, -0.0995, -0.0211],\n",
      "           [-0.0503, -0.0768, -0.0530]],\n",
      "\n",
      "          [[-0.0760, -0.0798, -0.0829],\n",
      "           [-0.0249, -0.0641, -0.0478],\n",
      "           [-0.1006, -0.1062, -0.0378]],\n",
      "\n",
      "          [[-0.0213, -0.0582, -0.0128],\n",
      "           [-0.0882, -0.0974, -0.0270],\n",
      "           [-0.0466, -0.0324, -0.0582]]],\n",
      "\n",
      "\n",
      "         [[[-0.0894, -0.0551, -0.0207],\n",
      "           [-0.0351, -0.1153, -0.0914],\n",
      "           [-0.0628, -0.0723, -0.0822]],\n",
      "\n",
      "          [[-0.0475, -0.0665, -0.0846],\n",
      "           [-0.0323, -0.0837, -0.0979],\n",
      "           [-0.0521, -0.0787, -0.1030]],\n",
      "\n",
      "          [[-0.0887, -0.0459, -0.0836],\n",
      "           [-0.0461, -0.1114, -0.0705],\n",
      "           [-0.0698, -0.0970, -0.0379]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0281, -0.0278, -0.0080],\n",
      "           [-0.0130, -0.0432, -0.0320],\n",
      "           [-0.0412, -0.0268, -0.0089]],\n",
      "\n",
      "          [[-0.0375, -0.0118, -0.0296],\n",
      "           [-0.0174, -0.0184, -0.0388],\n",
      "           [-0.0194, -0.0094, -0.0363]],\n",
      "\n",
      "          [[-0.0445, -0.0147, -0.0178],\n",
      "           [-0.0338, -0.0183, -0.0286],\n",
      "           [-0.0116, -0.0249, -0.0342]]],\n",
      "\n",
      "\n",
      "         [[[-0.0282, -0.0061,  0.0108],\n",
      "           [-0.0152, -0.0024,  0.0434],\n",
      "           [ 0.0044,  0.0054, -0.0083]],\n",
      "\n",
      "          [[ 0.0205, -0.0471,  0.0333],\n",
      "           [-0.0011,  0.0410, -0.0138],\n",
      "           [ 0.0016,  0.0110, -0.0289]],\n",
      "\n",
      "          [[-0.0049,  0.0292,  0.0240],\n",
      "           [-0.0224,  0.0261,  0.0431],\n",
      "           [ 0.0288, -0.0273, -0.0148]]],\n",
      "\n",
      "\n",
      "         [[[-0.0310, -0.0411, -0.0614],\n",
      "           [-0.0639,  0.0040, -0.0507],\n",
      "           [-0.0488, -0.0330, -0.0223]],\n",
      "\n",
      "          [[-0.0404, -0.0246, -0.0122],\n",
      "           [-0.0285,  0.0045, -0.0556],\n",
      "           [-0.0159, -0.0231, -0.0266]],\n",
      "\n",
      "          [[-0.0399, -0.0094, -0.0352],\n",
      "           [-0.0013, -0.0636, -0.0184],\n",
      "           [-0.0325, -0.0636, -0.0069]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0206,  0.0079, -0.0233],\n",
      "           [-0.0202,  0.0244,  0.0264],\n",
      "           [-0.0437, -0.0174, -0.0325]],\n",
      "\n",
      "          [[ 0.0304, -0.0073,  0.0070],\n",
      "           [-0.0073, -0.0050,  0.0427],\n",
      "           [ 0.0215,  0.0137, -0.0420]],\n",
      "\n",
      "          [[ 0.0167,  0.0680, -0.0178],\n",
      "           [ 0.0548,  0.0392,  0.0375],\n",
      "           [ 0.0024,  0.0334, -0.0115]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0645,  0.0048, -0.0016],\n",
      "           [-0.0092,  0.0096,  0.0665],\n",
      "           [ 0.0660,  0.0632, -0.0215]],\n",
      "\n",
      "          [[ 0.0466,  0.0395,  0.0604],\n",
      "           [ 0.0597,  0.0739, -0.0126],\n",
      "           [ 0.0346,  0.0133, -0.0088]],\n",
      "\n",
      "          [[-0.0126,  0.0507,  0.0235],\n",
      "           [-0.0122, -0.0205,  0.0222],\n",
      "           [ 0.0512,  0.0556, -0.0104]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0023,  0.0123, -0.0175],\n",
      "           [ 0.0586,  0.0363,  0.0568],\n",
      "           [-0.0332,  0.0028, -0.0114]],\n",
      "\n",
      "          [[-0.0201,  0.0642, -0.0096],\n",
      "           [-0.0196,  0.0406,  0.0589],\n",
      "           [ 0.0563,  0.0347,  0.0014]],\n",
      "\n",
      "          [[ 0.0309,  0.0015,  0.0138],\n",
      "           [ 0.0613,  0.0020,  0.0046],\n",
      "           [ 0.0125, -0.0160,  0.0323]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0074, -0.0005,  0.0006],\n",
      "           [-0.0112,  0.0068,  0.0072],\n",
      "           [-0.0024, -0.0044,  0.0141]],\n",
      "\n",
      "          [[-0.0075, -0.0089, -0.0089],\n",
      "           [-0.0027, -0.0036,  0.0057],\n",
      "           [ 0.0006, -0.0100,  0.0086]],\n",
      "\n",
      "          [[-0.0028,  0.0018,  0.0023],\n",
      "           [ 0.0032,  0.0025,  0.0042],\n",
      "           [-0.0123, -0.0017, -0.0076]]],\n",
      "\n",
      "\n",
      "         [[[-0.0350, -0.0425,  0.0005],\n",
      "           [-0.0204,  0.0292, -0.0087],\n",
      "           [ 0.0157, -0.0395, -0.0228]],\n",
      "\n",
      "          [[-0.0149, -0.0142, -0.0494],\n",
      "           [ 0.0263,  0.0128,  0.0227],\n",
      "           [-0.0397,  0.0053, -0.0550]],\n",
      "\n",
      "          [[-0.0428,  0.0308, -0.0180],\n",
      "           [-0.0016,  0.0355, -0.0200],\n",
      "           [ 0.0031,  0.0047,  0.0115]]],\n",
      "\n",
      "\n",
      "         [[[-0.0473, -0.0105, -0.0552],\n",
      "           [-0.0280,  0.0019, -0.0548],\n",
      "           [-0.0057, -0.0472,  0.0174]],\n",
      "\n",
      "          [[ 0.0020,  0.0097, -0.0069],\n",
      "           [-0.0004, -0.0167, -0.0262],\n",
      "           [-0.0348, -0.0311,  0.0036]],\n",
      "\n",
      "          [[-0.0341, -0.0433,  0.0267],\n",
      "           [ 0.0145, -0.0030, -0.0407],\n",
      "           [-0.0488,  0.0016, -0.0324]]]]], device='cuda:0')), ('module.up_samples.0.0.conv.weight', tensor([[[[[ 0.0466]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0696]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0673]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0396]]],\n",
      "\n",
      "\n",
      "         [[[-0.0207]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0692]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0760]]],\n",
      "\n",
      "\n",
      "         [[[-0.0176]]],\n",
      "\n",
      "\n",
      "         [[[-0.0019]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0677]]],\n",
      "\n",
      "\n",
      "         [[[-0.0009]]],\n",
      "\n",
      "\n",
      "         [[[-0.0577]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0155]]],\n",
      "\n",
      "\n",
      "         [[[-0.0419]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0578]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0088]]],\n",
      "\n",
      "\n",
      "         [[[-0.0377]]],\n",
      "\n",
      "\n",
      "         [[[-0.0697]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0004]]],\n",
      "\n",
      "\n",
      "         [[[-0.0459]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0685]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0221]]],\n",
      "\n",
      "\n",
      "         [[[-0.0190]]],\n",
      "\n",
      "\n",
      "         [[[-0.0402]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0763]]],\n",
      "\n",
      "\n",
      "         [[[-0.0240]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0467]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0186]]],\n",
      "\n",
      "\n",
      "         [[[-0.0052]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0284]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0249]]],\n",
      "\n",
      "\n",
      "         [[[-0.0610]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0499]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0031]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0595]]],\n",
      "\n",
      "\n",
      "         [[[-0.0095]]]]], device='cuda:0')), ('module.up_samples.1.0.conv.weight', tensor([[[[[-0.0020]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0752]]],\n",
      "\n",
      "\n",
      "         [[[-0.0199]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0920]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0566]]],\n",
      "\n",
      "\n",
      "         [[[-0.0499]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0148]]],\n",
      "\n",
      "\n",
      "         [[[-0.0168]]],\n",
      "\n",
      "\n",
      "         [[[-0.0789]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.1005]]],\n",
      "\n",
      "\n",
      "         [[[-0.0426]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0312]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0441]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0456]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0317]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0161]]],\n",
      "\n",
      "\n",
      "         [[[-0.0064]]],\n",
      "\n",
      "\n",
      "         [[[-0.0305]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1055]]],\n",
      "\n",
      "\n",
      "         [[[-0.0344]]],\n",
      "\n",
      "\n",
      "         [[[-0.1174]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-0.0096]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0628]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0099]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0972]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0152]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0895]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0480]]],\n",
      "\n",
      "\n",
      "         [[[-0.0386]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0813]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0605]]],\n",
      "\n",
      "\n",
      "         [[[-0.0618]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0505]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 0.0328]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0903]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0265]]]]], device='cuda:0')), ('module.up_samples.2.0.conv.weight', tensor([[[[[-0.1444]]],\n",
      "\n",
      "\n",
      "         [[[-0.0016]]],\n",
      "\n",
      "\n",
      "         [[[-0.0497]]],\n",
      "\n",
      "\n",
      "         [[[-0.1490]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1371]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1376]]],\n",
      "\n",
      "\n",
      "         [[[-0.0915]]],\n",
      "\n",
      "\n",
      "         [[[-0.0709]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0755]]],\n",
      "\n",
      "\n",
      "         [[[-0.0668]]],\n",
      "\n",
      "\n",
      "         [[[-0.1244]]],\n",
      "\n",
      "\n",
      "         [[[-0.0683]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0679]]],\n",
      "\n",
      "\n",
      "         [[[-0.0302]]],\n",
      "\n",
      "\n",
      "         [[[-0.0201]]],\n",
      "\n",
      "\n",
      "         [[[-0.0016]]],\n",
      "\n",
      "\n",
      "         [[[-0.0168]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0221]]],\n",
      "\n",
      "\n",
      "         [[[-0.0052]]],\n",
      "\n",
      "\n",
      "         [[[-0.0575]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0081]]],\n",
      "\n",
      "\n",
      "         [[[-0.0391]]],\n",
      "\n",
      "\n",
      "         [[[-0.1410]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0277]]],\n",
      "\n",
      "\n",
      "         [[[-0.1066]]],\n",
      "\n",
      "\n",
      "         [[[-0.0906]]],\n",
      "\n",
      "\n",
      "         [[[-0.0723]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0151]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0395]]],\n",
      "\n",
      "\n",
      "         [[[-0.0825]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0402]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0293]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0755]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0975]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0350]]],\n",
      "\n",
      "\n",
      "         [[[-0.0187]]],\n",
      "\n",
      "\n",
      "         [[[-0.0035]]],\n",
      "\n",
      "\n",
      "         [[[-0.0554]]],\n",
      "\n",
      "\n",
      "         [[[-0.1141]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0920]]],\n",
      "\n",
      "\n",
      "         [[[-0.0594]]],\n",
      "\n",
      "\n",
      "         [[[-0.0075]]],\n",
      "\n",
      "\n",
      "         [[[-0.1236]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1311]]],\n",
      "\n",
      "\n",
      "         [[[-0.0512]]],\n",
      "\n",
      "\n",
      "         [[[-0.0346]]],\n",
      "\n",
      "\n",
      "         [[[-0.0463]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1534]]],\n",
      "\n",
      "\n",
      "         [[[-0.1217]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0277]]],\n",
      "\n",
      "\n",
      "         [[[-0.1866]]],\n",
      "\n",
      "\n",
      "         [[[-0.1624]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0684]]],\n",
      "\n",
      "\n",
      "         [[[-0.1525]]],\n",
      "\n",
      "\n",
      "         [[[-0.1409]]],\n",
      "\n",
      "\n",
      "         [[[-0.0385]]],\n",
      "\n",
      "\n",
      "         [[[-0.0707]]],\n",
      "\n",
      "\n",
      "         [[[-0.0003]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1399]]],\n",
      "\n",
      "\n",
      "         [[[-0.0208]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1492]]],\n",
      "\n",
      "\n",
      "         [[[-0.0294]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0882]]],\n",
      "\n",
      "\n",
      "         [[[-0.0622]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1322]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0471]]],\n",
      "\n",
      "\n",
      "         [[[-0.1160]]],\n",
      "\n",
      "\n",
      "         [[[-0.1391]]],\n",
      "\n",
      "\n",
      "         [[[-0.1578]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0156]]],\n",
      "\n",
      "\n",
      "         [[[-0.0977]]],\n",
      "\n",
      "\n",
      "         [[[-0.1637]]],\n",
      "\n",
      "\n",
      "         [[[-0.1444]]],\n",
      "\n",
      "\n",
      "         [[[-0.0973]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0090]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0902]]],\n",
      "\n",
      "\n",
      "         [[[-0.1186]]],\n",
      "\n",
      "\n",
      "         [[[-0.0317]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0315]]],\n",
      "\n",
      "\n",
      "         [[[-0.0627]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0940]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0178]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1660]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1566]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0009]]],\n",
      "\n",
      "\n",
      "         [[[-0.0465]]],\n",
      "\n",
      "\n",
      "         [[[-0.0224]]],\n",
      "\n",
      "\n",
      "         [[[-0.0669]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1556]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0563]]],\n",
      "\n",
      "\n",
      "         [[[-0.0014]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0525]]],\n",
      "\n",
      "\n",
      "         [[[-0.0934]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1791]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0572]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1026]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.1116]]],\n",
      "\n",
      "\n",
      "         [[[-0.0213]]],\n",
      "\n",
      "\n",
      "         [[[-0.1623]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1460]]],\n",
      "\n",
      "\n",
      "         [[[-0.0132]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0729]]],\n",
      "\n",
      "\n",
      "         [[[-0.1263]]],\n",
      "\n",
      "\n",
      "         [[[-0.1531]]],\n",
      "\n",
      "\n",
      "         [[[-0.1145]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1417]]],\n",
      "\n",
      "\n",
      "         [[[-0.1468]]],\n",
      "\n",
      "\n",
      "         [[[-0.0195]]],\n",
      "\n",
      "\n",
      "         [[[-0.1612]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0389]]],\n",
      "\n",
      "\n",
      "         [[[-0.1394]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0273]]],\n",
      "\n",
      "\n",
      "         [[[-0.1060]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0173]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0891]]],\n",
      "\n",
      "\n",
      "         [[[-0.0510]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1239]]],\n",
      "\n",
      "\n",
      "         [[[-0.0300]]],\n",
      "\n",
      "\n",
      "         [[[-0.1068]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0884]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0612]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0553]]],\n",
      "\n",
      "\n",
      "         [[[-0.1572]]],\n",
      "\n",
      "\n",
      "         [[[-0.0338]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0749]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0637]]],\n",
      "\n",
      "\n",
      "         [[[-0.1251]]],\n",
      "\n",
      "\n",
      "         [[[-0.0163]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.1216]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0350]]],\n",
      "\n",
      "\n",
      "         [[[-0.1739]]],\n",
      "\n",
      "\n",
      "         [[[-0.0300]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0144]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1637]]],\n",
      "\n",
      "\n",
      "         [[[-0.1429]]],\n",
      "\n",
      "\n",
      "         [[[-0.0650]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0870]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1348]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0089]]],\n",
      "\n",
      "\n",
      "         [[[-0.0161]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1156]]],\n",
      "\n",
      "\n",
      "         [[[-0.0222]]],\n",
      "\n",
      "\n",
      "         [[[-0.0857]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1550]]],\n",
      "\n",
      "\n",
      "         [[[-0.1096]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0334]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1213]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0597]]],\n",
      "\n",
      "\n",
      "         [[[-0.0278]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0157]]],\n",
      "\n",
      "\n",
      "         [[[-0.0771]]],\n",
      "\n",
      "\n",
      "         [[[-0.1206]]],\n",
      "\n",
      "\n",
      "         [[[-0.1200]]],\n",
      "\n",
      "\n",
      "         [[[-0.1123]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0091]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1766]]],\n",
      "\n",
      "\n",
      "         [[[-0.1592]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0674]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0188]]],\n",
      "\n",
      "\n",
      "         [[[-0.1045]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1518]]],\n",
      "\n",
      "\n",
      "         [[[-0.0317]]],\n",
      "\n",
      "\n",
      "         [[[-0.0583]]],\n",
      "\n",
      "\n",
      "         [[[-0.0854]]],\n",
      "\n",
      "\n",
      "         [[[-0.0599]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0169]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1515]]],\n",
      "\n",
      "\n",
      "         [[[-0.0622]]],\n",
      "\n",
      "\n",
      "         [[[-0.0417]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1631]]],\n",
      "\n",
      "\n",
      "         [[[-0.0472]]],\n",
      "\n",
      "\n",
      "         [[[-0.0165]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0050]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1248]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0312]]],\n",
      "\n",
      "\n",
      "         [[[-0.0503]]],\n",
      "\n",
      "\n",
      "         [[[-0.0280]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0894]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1360]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0793]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1552]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0958]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1297]]],\n",
      "\n",
      "\n",
      "         [[[-0.1586]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1785]]],\n",
      "\n",
      "\n",
      "         [[[-0.0272]]],\n",
      "\n",
      "\n",
      "         [[[-0.0995]]],\n",
      "\n",
      "\n",
      "         [[[-0.1965]]],\n",
      "\n",
      "\n",
      "         [[[-0.1424]]],\n",
      "\n",
      "\n",
      "         [[[-0.1236]]],\n",
      "\n",
      "\n",
      "         [[[-0.0837]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1295]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0310]]],\n",
      "\n",
      "\n",
      "         [[[-0.0703]]],\n",
      "\n",
      "\n",
      "         [[[-0.0232]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1563]]],\n",
      "\n",
      "\n",
      "         [[[-0.0395]]],\n",
      "\n",
      "\n",
      "         [[[-0.0930]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0526]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0837]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1166]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1016]]],\n",
      "\n",
      "\n",
      "         [[[-0.0538]]],\n",
      "\n",
      "\n",
      "         [[[-0.1505]]],\n",
      "\n",
      "\n",
      "         [[[-0.1977]]],\n",
      "\n",
      "\n",
      "         [[[-0.0810]]],\n",
      "\n",
      "\n",
      "         [[[-0.0579]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0172]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0935]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1036]]],\n",
      "\n",
      "\n",
      "         [[[-0.0314]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0609]]],\n",
      "\n",
      "\n",
      "         [[[-0.0971]]],\n",
      "\n",
      "\n",
      "         [[[-0.0792]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1038]]],\n",
      "\n",
      "\n",
      "         [[[-0.0313]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1420]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0824]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0893]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0720]]],\n",
      "\n",
      "\n",
      "         [[[-0.1413]]],\n",
      "\n",
      "\n",
      "         [[[-0.0343]]],\n",
      "\n",
      "\n",
      "         [[[-0.1095]]],\n",
      "\n",
      "\n",
      "         [[[-0.0236]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1693]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0090]]],\n",
      "\n",
      "\n",
      "         [[[-0.1052]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1582]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0463]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0786]]],\n",
      "\n",
      "\n",
      "         [[[-0.0212]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0109]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0158]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1460]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0231]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0897]]],\n",
      "\n",
      "\n",
      "         [[[-0.0276]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0110]]],\n",
      "\n",
      "\n",
      "         [[[-0.1126]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1361]]],\n",
      "\n",
      "\n",
      "         [[[-0.0184]]],\n",
      "\n",
      "\n",
      "         [[[-0.0119]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0118]]],\n",
      "\n",
      "\n",
      "         [[[-0.0474]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1296]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0953]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1857]]],\n",
      "\n",
      "\n",
      "         [[[-0.0177]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0596]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0045]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0470]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0314]]],\n",
      "\n",
      "\n",
      "         [[[-0.0164]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0746]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0753]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1113]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0964]]],\n",
      "\n",
      "\n",
      "         [[[-0.1710]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0380]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1160]]],\n",
      "\n",
      "\n",
      "         [[[-0.1336]]],\n",
      "\n",
      "\n",
      "         [[[-0.0343]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1399]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1654]]],\n",
      "\n",
      "\n",
      "         [[[-0.1037]]],\n",
      "\n",
      "\n",
      "         [[[-0.1069]]],\n",
      "\n",
      "\n",
      "         [[[-0.0009]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1720]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0988]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0333]]],\n",
      "\n",
      "\n",
      "         [[[-0.1397]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0713]]],\n",
      "\n",
      "\n",
      "         [[[-0.0502]]],\n",
      "\n",
      "\n",
      "         [[[-0.0817]]],\n",
      "\n",
      "\n",
      "         [[[-0.1647]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1126]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0211]]],\n",
      "\n",
      "\n",
      "         [[[-0.1024]]],\n",
      "\n",
      "\n",
      "         [[[-0.1369]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0132]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1089]]],\n",
      "\n",
      "\n",
      "         [[[-0.1800]]],\n",
      "\n",
      "\n",
      "         [[[-0.0023]]],\n",
      "\n",
      "\n",
      "         [[[-0.1131]]],\n",
      "\n",
      "\n",
      "         [[[-0.0864]]],\n",
      "\n",
      "\n",
      "         [[[-0.0818]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1370]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1517]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0128]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1147]]],\n",
      "\n",
      "\n",
      "         [[[-0.0813]]],\n",
      "\n",
      "\n",
      "         [[[-0.0304]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1126]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0780]]],\n",
      "\n",
      "\n",
      "         [[[-0.0759]]],\n",
      "\n",
      "\n",
      "         [[[-0.0893]]],\n",
      "\n",
      "\n",
      "         [[[-0.0467]]],\n",
      "\n",
      "\n",
      "         [[[-0.1373]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0206]]],\n",
      "\n",
      "\n",
      "         [[[-0.0612]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1490]]],\n",
      "\n",
      "\n",
      "         [[[-0.1540]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0047]]],\n",
      "\n",
      "\n",
      "         [[[-0.0655]]],\n",
      "\n",
      "\n",
      "         [[[-0.0176]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1455]]],\n",
      "\n",
      "\n",
      "         [[[-0.0944]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0907]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1015]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1105]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1533]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1473]]],\n",
      "\n",
      "\n",
      "         [[[-0.0353]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0046]]],\n",
      "\n",
      "\n",
      "         [[[-0.1615]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0851]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1144]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1482]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0310]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1051]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0896]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0240]]],\n",
      "\n",
      "\n",
      "         [[[-0.0948]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0554]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1779]]],\n",
      "\n",
      "\n",
      "         [[[-0.1587]]],\n",
      "\n",
      "\n",
      "         [[[-0.1900]]],\n",
      "\n",
      "\n",
      "         [[[-0.1054]]],\n",
      "\n",
      "\n",
      "         [[[-0.0147]]],\n",
      "\n",
      "\n",
      "         [[[-0.0357]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1061]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0301]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0080]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1568]]],\n",
      "\n",
      "\n",
      "         [[[-0.1212]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0527]]],\n",
      "\n",
      "\n",
      "         [[[-0.1204]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0456]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0858]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1038]]],\n",
      "\n",
      "\n",
      "         [[[-0.0420]]],\n",
      "\n",
      "\n",
      "         [[[-0.1326]]],\n",
      "\n",
      "\n",
      "         [[[-0.0378]]],\n",
      "\n",
      "\n",
      "         [[[-0.1909]]],\n",
      "\n",
      "\n",
      "         [[[-0.1077]]],\n",
      "\n",
      "\n",
      "         [[[-0.0669]]],\n",
      "\n",
      "\n",
      "         [[[-0.1563]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0412]]],\n",
      "\n",
      "\n",
      "         [[[-0.1627]]],\n",
      "\n",
      "\n",
      "         [[[-0.0542]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1650]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0095]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.2072]]],\n",
      "\n",
      "\n",
      "         [[[-0.1444]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2349]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0550]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0360]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0851]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1616]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1520]]],\n",
      "\n",
      "\n",
      "         [[[-0.1778]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1635]]],\n",
      "\n",
      "\n",
      "         [[[-0.1125]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0012]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0575]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0845]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0017]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1740]]],\n",
      "\n",
      "\n",
      "         [[[-0.1990]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0184]]],\n",
      "\n",
      "\n",
      "         [[[-0.1119]]],\n",
      "\n",
      "\n",
      "         [[[-0.2286]]],\n",
      "\n",
      "\n",
      "         [[[-0.0981]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0836]]],\n",
      "\n",
      "\n",
      "         [[[-0.0991]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0803]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1218]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0398]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0039]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0475]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0729]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0236]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1603]]],\n",
      "\n",
      "\n",
      "         [[[-0.0576]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.0186]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0580]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0383]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0508]]],\n",
      "\n",
      "\n",
      "         [[[-0.0901]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1134]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0481]]],\n",
      "\n",
      "\n",
      "         [[[-0.0977]]],\n",
      "\n",
      "\n",
      "         [[[-0.1936]]],\n",
      "\n",
      "\n",
      "         [[[-0.0610]]],\n",
      "\n",
      "\n",
      "         [[[-0.0272]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1512]]],\n",
      "\n",
      "\n",
      "         [[[-0.0516]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0916]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0266]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1751]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0974]]],\n",
      "\n",
      "\n",
      "         [[[-0.1213]]],\n",
      "\n",
      "\n",
      "         [[[-0.1366]]],\n",
      "\n",
      "\n",
      "         [[[-0.1331]]],\n",
      "\n",
      "\n",
      "         [[[-0.0695]]],\n",
      "\n",
      "\n",
      "         [[[-0.0745]]],\n",
      "\n",
      "\n",
      "         [[[-0.1469]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0372]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0715]]],\n",
      "\n",
      "\n",
      "         [[[-0.1404]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1168]]],\n",
      "\n",
      "\n",
      "         [[[-0.0411]]],\n",
      "\n",
      "\n",
      "         [[[-0.0539]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0093]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0054]]],\n",
      "\n",
      "\n",
      "         [[[-0.0183]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.0188]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1585]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0029]]],\n",
      "\n",
      "\n",
      "         [[[-0.1275]]],\n",
      "\n",
      "\n",
      "         [[[-0.0002]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0618]]],\n",
      "\n",
      "\n",
      "         [[[-0.1257]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0120]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0195]]],\n",
      "\n",
      "\n",
      "         [[[-0.0221]]],\n",
      "\n",
      "\n",
      "         [[[-0.1009]]],\n",
      "\n",
      "\n",
      "         [[[-0.1255]]],\n",
      "\n",
      "\n",
      "         [[[-0.1058]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0566]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0400]]],\n",
      "\n",
      "\n",
      "         [[[-0.1655]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1095]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1906]]],\n",
      "\n",
      "\n",
      "         [[[-0.1215]]],\n",
      "\n",
      "\n",
      "         [[[-0.1459]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0202]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1240]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0529]]],\n",
      "\n",
      "\n",
      "         [[[-0.0702]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0238]]],\n",
      "\n",
      "\n",
      "         [[[-0.1180]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1331]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1505]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1472]]],\n",
      "\n",
      "\n",
      "         [[[-0.0159]]],\n",
      "\n",
      "\n",
      "         [[[-0.1714]]],\n",
      "\n",
      "\n",
      "         [[[-0.0373]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.1281]]],\n",
      "\n",
      "\n",
      "         [[[-0.0245]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1238]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0596]]],\n",
      "\n",
      "\n",
      "         [[[-0.0955]]],\n",
      "\n",
      "\n",
      "         [[[-0.1040]]],\n",
      "\n",
      "\n",
      "         [[[-0.0372]]],\n",
      "\n",
      "\n",
      "         [[[-0.1052]]],\n",
      "\n",
      "\n",
      "         [[[-0.1430]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0714]]],\n",
      "\n",
      "\n",
      "         [[[-0.0747]]],\n",
      "\n",
      "\n",
      "         [[[-0.1444]]],\n",
      "\n",
      "\n",
      "         [[[-0.1260]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0379]]],\n",
      "\n",
      "\n",
      "         [[[-0.0344]]],\n",
      "\n",
      "\n",
      "         [[[-0.0930]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1496]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1002]]],\n",
      "\n",
      "\n",
      "         [[[-0.0180]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1637]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0746]]],\n",
      "\n",
      "\n",
      "         [[[-0.1143]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0338]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0574]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0232]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1064]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0816]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0140]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0167]]],\n",
      "\n",
      "\n",
      "         [[[-0.0242]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1021]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0641]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.1286]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0350]]],\n",
      "\n",
      "\n",
      "         [[[-0.1029]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0622]]],\n",
      "\n",
      "\n",
      "         [[[-0.0260]]],\n",
      "\n",
      "\n",
      "         [[[-0.0347]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0206]]],\n",
      "\n",
      "\n",
      "         [[[-0.1291]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1142]]],\n",
      "\n",
      "\n",
      "         [[[-0.0020]]],\n",
      "\n",
      "\n",
      "         [[[-0.1204]]],\n",
      "\n",
      "\n",
      "         [[[-0.0742]]],\n",
      "\n",
      "\n",
      "         [[[-0.0064]]],\n",
      "\n",
      "\n",
      "         [[[-0.0123]]],\n",
      "\n",
      "\n",
      "         [[[-0.1691]]],\n",
      "\n",
      "\n",
      "         [[[-0.1997]]],\n",
      "\n",
      "\n",
      "         [[[-0.0765]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1106]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0917]]],\n",
      "\n",
      "\n",
      "         [[[-0.1271]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0615]]],\n",
      "\n",
      "\n",
      "         [[[-0.0700]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0483]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0477]]],\n",
      "\n",
      "\n",
      "         [[[-0.0497]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0474]]],\n",
      "\n",
      "\n",
      "         [[[-0.0355]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0323]]],\n",
      "\n",
      "\n",
      "         [[[-0.1299]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1106]]],\n",
      "\n",
      "\n",
      "         [[[-0.1225]]],\n",
      "\n",
      "\n",
      "         [[[-0.0317]]]]], device='cuda:0')), ('module.conv_final.0.weight', tensor([1.5985, 0.6670, 1.0318, 0.9851, 1.5690, 1.0496, 0.9877, 1.0410, 0.5683,\n",
      "        1.6227, 1.4581, 0.6264, 0.4791, 1.6010, 0.7898, 1.4992],\n",
      "       device='cuda:0')), ('module.conv_final.0.bias', tensor([ 0.5566, -0.0013, -0.1604, -0.2161,  0.5351,  0.0522, -0.1744,  0.0331,\n",
      "        -0.0011,  0.5522,  0.4518,  0.0034,  0.0009,  0.5485, -0.0197,  0.5073],\n",
      "       device='cuda:0')), ('module.conv_final.2.conv.weight', tensor([[[[[-0.6685]]],\n",
      "\n",
      "\n",
      "         [[[-0.0430]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1554]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0285]]],\n",
      "\n",
      "\n",
      "         [[[-0.3756]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2044]]],\n",
      "\n",
      "\n",
      "         [[[-0.0192]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1999]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0201]]],\n",
      "\n",
      "\n",
      "         [[[-0.4665]]],\n",
      "\n",
      "\n",
      "         [[[-0.3680]]],\n",
      "\n",
      "\n",
      "         [[[-0.0050]]],\n",
      "\n",
      "\n",
      "         [[[-0.1487]]],\n",
      "\n",
      "\n",
      "         [[[-0.6943]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0450]]],\n",
      "\n",
      "\n",
      "         [[[-0.3801]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.5756]]],\n",
      "\n",
      "\n",
      "         [[[-0.1144]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0251]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0704]]],\n",
      "\n",
      "\n",
      "         [[[-0.5016]]],\n",
      "\n",
      "\n",
      "         [[[-0.0303]]],\n",
      "\n",
      "\n",
      "         [[[ 0.1858]]],\n",
      "\n",
      "\n",
      "         [[[-0.2084]]],\n",
      "\n",
      "\n",
      "         [[[-0.1357]]],\n",
      "\n",
      "\n",
      "         [[[-0.6789]]],\n",
      "\n",
      "\n",
      "         [[[-0.2471]]],\n",
      "\n",
      "\n",
      "         [[[-0.0529]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0107]]],\n",
      "\n",
      "\n",
      "         [[[-0.7722]]],\n",
      "\n",
      "\n",
      "         [[[ 0.2235]]],\n",
      "\n",
      "\n",
      "         [[[-0.5216]]]]], device='cuda:0')), ('module.conv_final.2.conv.bias', tensor([-0.4715, -0.4824], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49meval()\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs = batch['image'].to(device)  # Assuming you have GPU available\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Get the first sample in the dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m first_sample \u001b[39m=\u001b[39m train_dataset\n\u001b[0;32m----> 5\u001b[0m image_shape \u001b[39m=\u001b[39m first_sample[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mshape\n\u001b[1;32m      6\u001b[0m label_shape \u001b[39m=\u001b[39m first_sample[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mImage shape: \u001b[39m\u001b[39m{\u001b[39;00mimage_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Get the first sample in the dataset\n",
    "first_sample = train_dataset\n",
    "\n",
    "\n",
    "image_shape = first_sample['image'].shape\n",
    "label_shape = first_sample['label'].shape\n",
    "\n",
    "print(f\"Image shape: {image_shape}\")\n",
    "print(f\"Label shape: {label_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABP8AAAIQCAYAAAD+XMs2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOz9e5BtaV0ejj/7vtZea9/7fq4zZ2aYGRhABx0QA0QRMQkpIgmJlgbMRcoAViRYChXFIV8zFStVYglRU5WSVAmaUMHcDEShBI1KrCAqIMPcz5xz+vRld+/72mvff3/07/n0Z6+z+5zuc+3u83mqurp7995rvetd7/v5PL2ez/u8sclkMoHBYDAYDAaDwWAwGAwGg8FgOHaI3+kGGAwGg8FgMBgMBoPBYDAYDIZbA3v4ZzAYDAaDwWAwGAwGg8FgMBxT2MM/g8FgMBgMBoPBYDAYDAaD4ZjCHv4ZDAaDwWAwGAwGg8FgMBgMxxT28M9gMBgMBoPBYDAYDAaDwWA4prCHfwaDwWAwGAwGg8FgMBgMBsMxhT38MxgMBoPBYDAYDAaDwWAwGI4p7OGfwWAwGAwGg8FgMBgMBoPBcExhD/8MBoPBYDAYDAaDwWAwGAyGYwp7+Gcw3GX4+Mc/jlgshhdeeOFON8VgMBgMBoPBYDjyMH59MHzhC19ALBbDF77whQN/9p3vfCd837+p7XnDG96AN7zhDTf1mAbDYYM9/DMYDAaDwWAwGAwGg8FgMBiOKezhn8Fwl+GHf/iH0e12cebMmTvdFIPBYDAYDAaD4cjD+LXBYDjssId/BsNdhkQiAcdxEIvF7nRTDAaDwWAwGAyGI4+7lV+/4Q1vwDvf+c473QyDwbAP2MM/g+EuQ9ST5OzZs/hbf+tv4Qtf+AJe9apXwXVdPPLII+LB8elPfxqPPPIIHMfBo48+iq985StTx/vLv/xLvPOd78S9994Lx3GwtLSEf/SP/hG2trauODfP4TgOzp07h1/7tV/Dz/3cz80kSr/xG7+BRx99FK7rolwu4x/8g3+ACxcu3PT+MBgMBoPBYDAYbgSzPP+MYx8Mf/iHf4i/9/f+Hk6fPo1MJoNTp07hJ37iJ9Dtdme+/7nnnsP3fu/3wvM8rKys4MMf/jAmk8nUe8bjMT7ykY/gpS99KRzHweLiIt71rnehVqvdjksyGA4Vkne6AQaD4c7jmWeewQ/+4A/iXe96F37oh34I//bf/lu85S1vwa/+6q/igx/8IP7ZP/tnAIAnnngCb3/72/HNb34T8fiOdvB7v/d7eO655/AjP/IjWFpawte//nX8+3//7/H1r38dX/rSl4R0fOUrX8Gb3/xmLC8v4/HHH8doNMKHP/xhzM/PX9Gen//5n8fP/MzP4O1vfzv+yT/5J9jc3MQv//Iv43Wvex2+8pWvoFgs3ra+MRgMBoPBYDAYrgfGsfePT33qUwiCAD/2Yz+GSqWCP/3TP8Uv//Iv4+LFi/jUpz419d7RaIQ3v/nNePWrX41f+IVfwGc/+1l86EMfwnA4xIc//GF537ve9S58/OMfx4/8yI/gx3/8x/H888/jox/9KL7yla/gj/7oj5BKpW73ZRoMdw4Tg8FwV+HXf/3XJwAmzz///GQymUzOnDkzATD54z/+Y3nP//7f/3sCYOK67uT8+fPy+q/92q9NAEx+//d/X14LguCKc/zmb/7mBMDkD/7gD+S1t7zlLZNsNju5dOmSvPb0009PksnkRIeiF154YZJIJCY///M/P3XMr371q5NkMnnF6waDwWAwGAwGw51ElF9PJncHx379618/ecc73nHgz/3+7//+vq73iSeemMRisam+esc73jEBMHnve98rr43H48nf/Jt/c5JOpyebm5uTyWQy+cM//MMJgMknPvGJqWN+9rOfveL117/+9ZPXv/71B74Og+EowZb9GgwGPPzww3jNa14jvz/22GMAgO/6ru/C6dOnr3j9ueeek9dc15WfwzBEtVrFq1/9agDAn/3ZnwHYUec+97nP4a1vfStWVlbk/ffddx++7/u+b6otn/70pzEej/H2t78d1WpVvpaWlnD//ffj93//92/WZRsMBoPBYDAYDLcMx4ljDwaDqc9Vq1UMBgP0er0rXh+Pxwfqp+j1djodVKtVfMd3fAcmk8kVS6IB4D3veY/8HIvF8J73vAf9fh+f+9znAOxUEhYKBXzP93zPVNseffRR+L5v/1MY7jrYsl+DwTBFPgCgUCgAAE6dOjXzde2Tsb29jccffxy/9Vu/hY2Njan3NxoNAMDGxga63S7uu+++K84dfe3pp5/GZDLB/fffP7OtVp5vMBgMBoPBYDgKOE4c+4/+6I/w1//6X7/i9T/+4z/Gb/3Wb0299vzzz+Ps2bNXPV4UL774In72Z38W//2///crPPl4vUQ8Hse999479doDDzwAAOK7+PTTT6PRaGBhYWHm+aJ9ajAcd9jDP4PBgEQicaDXJ8pM9+1vfzv++I//GD/5kz+JV77ylfB9H+PxGG9+85uvS/Ubj8eIxWL4zGc+M/P8vu8f+JgGg8FgMBgMBsPtxnHi2K94xSvwe7/3e1Ov/Yt/8S+wtLSEn/zJn5x6fWlp6UBtG41G+J7v+R5sb2/jp37qp/Dggw/C8zxcunQJ73znO6/7ehcWFvCJT3xi5t9neSIaDMcZ9vDPYDBcN2q1Gj7/+c/j8ccfx8/+7M/K608//fTU+xYWFuA4Dp555pkrjhF97dy5c5hMJrjnnntEwTMYDAaDwWAwGO4WHEaOXSqV8MY3vvGK15aXl694/aD46le/iqeeegr/8T/+R/zDf/gP5fXow0ZiPB7jueeem7qOp556CgCk4vDcuXP43Oc+h9e+9rVTS4oNhrsV5vlnMBiuG1QNtUoJAB/5yEeueN8b3/hG/Nf/+l+xuroqrz/zzDP4zGc+M/Xe7//+70cikcDjjz9+xXEnkwm2trZu4hUYDAaDwWAwGAyHC3cbx551vZPJBL/0S7+052c++tGPTr33ox/9KFKpFL77u78bwE7l5Gg0wr/6V//qis8Oh0PU6/Wb1HqD4WjAKv8MBsN1I5/P43Wvex1+4Rd+AYPBACdOnMDv/u7v4vnnn7/ivT/3cz+H3/3d38VrX/ta/NiP/RhGoxE++tGP4mUvexn+/M//XN537tw5/H//3/+HD3zgA3jhhRfw1re+FblcDs8//zx++7d/Gz/6oz+K97///bfxKg0Gg8FgMBgMhtuHu41jP/jggzh37hze//7349KlS8jn8/gv/+W/XOH9RziOg89+9rN4xzvegcceewyf+cxn8Du/8zv44Ac/KMt5X//61+Nd73oXnnjiCfz5n/853vSmNyGVSuHpp5/Gpz71KfzSL/0S/u7f/bu38zINhjsKe/hnMBhuCJ/85Cfx3ve+Fx/72McwmUzwpje9CZ/5zGemdhwDgEcffRSf+cxn8P73vx8/8zM/g1OnTuHDH/4wvvGNb+DJJ5+ceu9P//RP44EHHsAv/uIv4vHHHwewY4z8pje9CX/7b//t23ZtBoPBYDAYDAbDncDdxLFTqRT+x//4H/jxH/9xPPHEE3AcB3/n7/wdvOc978ErXvGKK96fSCTw2c9+Fj/2Yz+Gn/zJn0Qul8OHPvShqSXSAPCrv/qrePTRR/Frv/Zr+OAHP4hkMomzZ8/ih37oh/Da1772dl2ewXAoEJtEa34NBoPhNuKtb30rvv71r1/hYWIwGAwGg8FgMBiuD8axDQaDhnn+GQyG24Zutzv1+9NPP43/9b/+F97whjfcmQYZDAaDwWAwGAxHHMaxDQbDtWCVfwaD4bZheXkZ73znO3Hvvffi/Pnz+JVf+RX0ej185Stfwf3333+nm2cwGAwGg8FgMBw5GMc2GAzXgnn+GQyG24Y3v/nN+M3f/E2sra0hk8ngNa95Df71v/7XRkoMBoPBYDAYDIbrhHFsg8FwLVjln8FgMBgMBoPBYDAYDAaDwXBMcUc9/z72sY/h7NmzcBwHjz32GP70T//0TjbHYDAYDAaDwWAw3ACM3xsMBoPBcPhwxx7+/af/9J/wvve9Dx/60IfwZ3/2Z3jFK16B7/3e78XGxsadapLBYDAYDAaDwWC4Thi/NxgMBoPhcOKOLft97LHH8G3f9m346Ec/CgAYj8c4deoU3vve9+Knf/qnr/rZ8XiM1dVV5HI5xGKx29Fcg8FgMBiOLCaTCVqtFlZWVhCP39Gif4PBcIxxI/ye7zeObzAYDAbD/nAQjn9HNvzo9/v48pe/jA984APyWjwexxvf+Eb8yZ/8yRXv7/V66PV68vulS5fw8MMP35a2GgwGg8FwXHDhwgWcPHnyTjfDYDAcQxyU3wPG8Q0Gg8FguBnYD8e/Iw//qtUqRqMRFhcXp15fXFzEk08+ecX7n3jiCTz++OO3q3kGw12DWCyGeDyOeDyORCKBRCKBeDyOZDKJRCKBVCqFTCaDfr+PbreLyWSC4XCI8XiMwWCA8XiM0Wh0KK4B2FE+AFzxeyaTQTwelyqCZDKJeDyOwWCA0WiEWCyGWCyG8Xgsn4nFYkgkEkgmkxiNRuj3+xiNRhiNRvKeZDKJbDaLXC6H+++/H67rolAoIJlMSh+6rot4PI5+v4/JZCJt4XH6/T7G47G8n/egVquhXq9LW/gVj8eRSqXkHmjwumOxGEajEVqtFgaDAWq1GobDodw73nO+v16vIwiCqf5jG3ntvV4Pk8lEvq73PmUyGelXAHK9vBe9Xk+u63rPZdgbuVzuTjfBYDAcUxyU3wPG8Q2GWwXj+MbxAeP4dxP2w/HvyMO/g+IDH/gA3ve+98nvzWYTp06duoMtMhiONhj4c7kcXNeF67pCAIbDIXq9HoIgQBiGqNVqmEwmksgYqO9E0NZLgDSpSafTU787jgMACMMQAFCpVJDJZOA4zlSyrtVq6Ha7GI1GGA6HcmzP8+C6LnK5HMrlMtrtNra2thAEAWq1mhAifu/1etjY2IDneUin03AcB67rIpVKwXEcxGIxDIdD+Qyws7RJf3meB9/3hVSk02mk0+mp9wAQEjcej9Hv96UvksmkXBeTuu/7GA6HKBQKAHYIUjKZhO/7SKVSQkYuX76MZrOJbrcrRAUA2u022u02giBAu93GeDyW64iSkmuBYygMwymik06nkUwm4TgOUqmUjEH2Vb/fx2AwMJJwk2DL6AwGw2GCcXyD4ebCOL5xfOP4dyf2w/HvyMO/ubk5JBIJrK+vT72+vr6OpaWlK96fyWSQyWRuV/MMhmMHHYh1Ak2lUkin00ilUqI0URlj8Keadbvaqb8DswmIVseYEGcRA4KJXidrJtdkMinXTbUwl8vB930Ui0UhBtlsFp1OB67rSt8Mh0N0u92pJMs28BrYdk0k+H0ymUwpq1qti6qd8XhcEvZewZ3nB3YUSxKBRCIBAPB9H+l0GsViEZlMBul0WlTgRqOBbreLXq8nbWw2m3AcB+12G6lUSsYDxwTbr+/VtaDfT+VVf1ZfP4+vv4wcGAwGw+HEQfk9YBzfYLhRGMc3jg8YxzfsD3fk4V86ncajjz6Kz3/+83jrW98KYGewfP7zn8d73vOeO9Ekg+FYgkTA8zykUilRgxj4WVbebrelJFt/3YpAHE2YTAJMaiQrhF6OMB6PZalCNpvF/Pw8fN/H8vIy4vE4er3eVPINggAAsLy8DNd14TiOJP9YLIZKpYLRaIR8Pg/XdbG4uIhKpYJSqYRisQjHceA4DobDofQPVdNms4kwDLG1tYXBYIBOpyOqly7X14rWZDKRvycSCSndH4/HCMNwanlGs9lEs9mUUn7eSypoo9EIQRAIwSDBIYHgcgX2VSaTwYkTJ+B5HpaWlpDNZkWR4/IOfqcS1+l00Ol0UKvVUK1Wsb29jUuXLmFzcxPPPfccut0uWq3WFUlbE4arjR8uiYjFYhgMBnLtJHeZTAau6wIAut2uXO9BFUmDwWAw3HoYvzcYbh+M4xvHN45vOCju2LLf973vfXjHO96BV73qVfj2b/92fOQjH0Gn08GP/MiP3KkmGQzHBtoXgqoPE24mk5nyXuD3brc7VXp+qxBV/pioWQpPtUpfC0vEAUz5lPi+j0KhgLm5OcTjcUkcvC5+nksfqJLpY8fjcZTLZfi+j9OnT2NxcRHlchmlUknaxETH5ByGoaho1WpVCEKv18P29raQLbaFSZN+Krpt7PPhcIh+vy9tYnImGeE91SqaLpsfjUZIpVJIJBJyLvZnLpeD4zioVCrI5/NYXFyU5QskKDwmCcJgMJBkXK/XUa1WsbGxIcsVms3m1DIBEiBNEg6iEvK7vgat9A6HQ3k9Ho/bEgGDwWA4hDB+bzDcWhjHN45vHN9wvbhjD//+/t//+9jc3MTP/uzPYm1tDa985Svx2c9+9gqTYIPBcG1ElTWWvGvPhVgshna7jWaziV6vJwlKG/zerEDLgK4Ndvm7LkNPJBIolUrwfV/K9rk8gUmmVqthfX0dvV4P7XYbmUwGhUJBVMF8Po+FhQUAEBWNyZj+GHNzc8hms9IGnoMJc35+HoVCAfPz8yiVSuIdAuwmYJ3Mk8kkyuUyxuMx5ufnMRwOEYYhwjBEvV5HGIa4fPkygiDA+fPnEQSB7GgYhiGGw6GY4rLvqQxqc1ySIJ6XqqnjOOKbwfMCO8oZ/VGy2SxOnTqFfD6PU6dOwfM8nD17FrlcDtlsVkyOqToyEWvlMZfLiZfJYDBAEARoNpuo1WqiDn7zm99Eo9HAhQsXREHs9Xqo1+tT4+paY4t/51KL0WiETqcj5AyAqJj0SSExIikxGAwGw52F8XuD4ebCOL5xfMA4vuHm4I5u+PGe97zHlgEYDDcI7fHBZKt3vtK+EvRzIDG4FcpK9Jz8nQmP/iNUpIrFIgqFAnzfl4TF8na2LQgCSWRUuVzXRTabFZ8PAJIsWWrPc2azWTiOI8mPxrM8Z7FYRLFYRC6Xg+d5Qqqiih2vhwk7lUrB8zwhV/1+H47jiJEyr5PLALirFtuYSCSmlD0AU4RK+4JEyZ/2BGEpP5cacEmAXj5BjxMuD6FhsG4TrzvqF8N7SNLVbrcxNzeHtbU1TCYTbG9vYzweo9VqYTKZoNPpyHIMvavXfsAxSWWSS1j07mpUBakW0sjZyIHBYDDceRi/NxhuDozjG8c3jm8c/2biSOz2azAYpsFAzQBPtcTzPPFW0KXxTBr654OW/kd9PKKGtNGgzC3t2bZcLod0Oo3l5WVR41KplJTqM8BTWfN9H77vI5FIIJvNSom64zgolUpIp9NCDqgKptNpUa94jbFYTHwxuGSAiYU+KPl8Hp7nydKIZrOJVqslJIqvaU8Sx3HgeR5OnjwJx3FQLpflO4+VzWZRq9XgOI7sOEYSwLZpUA2jAglAfo8SvX6/j1arhcFgIJ4cw+FQdvoKwxCrq6sIggC5XA79fh+FQgGj0QiFQgGpVAqdTgfdbhcXLlxArVaTds3NzYkRcrlcFkN2qrqFQgGu62JhYQGnT58WFbBer+Ob3/wmNjc38ad/+qeo1+t48cUXEYbhFcpdlJRGxw9/Z59wuQSXt5DYcVxw7NhSAYPBYDAYDEcVxvGN4xvHN45/q2AP/wyGI4ZZKqDeSp3EgAmICfdGfD6iCYxt4M977dSVSCSkzL9YLCKbzeLEiRMoFotwXVeUwXg8jna7jU6nIyXzwO629SQOvV5PiEEikRDDWypzest4TQzoOcLkORqNEIvFZOkA/TSo7LXbbWxtbSEMQ3S7XXQ6HdTrdUnS7OtSqYR8Pg8Acr28Hu4Yls1m0e/3r1AatcrIL7ZhMBhI/7JEnucAIGXwnU4Hw+FQiBCJAd/XaDQQi8XQarWQTCZFXfV9X0yAe72eLLsIwxC9Xk8UOS4voUJJlTGdTsNxHOTzeczNzWE8Hgs5SKfTuHz5MlZXV5HJZFCtViVZk/DMIgGzxhGvNQpeI5eX6P7hvTdyYDAYDAaD4SjBOL5xfOP4xvFvJezhn8FwyKGTLMuiuaMVk0+tVpvyhdDE4GYY/GqvCF2mzhJ1AOItwtdKpRJc18WpU6dQKBRw+vRp5PN5nDhxQkrx6eswHu/s2tXtdrG1tYWtrS24rgvP8zAYDBCGIfr9vvhDMEFxtyh6ZnieJ+RAG9SyX9hPTCxUJxcXF6d2PuM10JQ4nU7D8zxpK8vsPc+TXcTYT1Swtre3Ua/XcenSJdRqNVy4cAGNRkMIh16Sof1SqN7y3pOMsP+Z8EgOSAj0ccIwRCaTwWQyQS6Xw2g0QqlUEuNjAPB9X3xPzp49i1KphHq9Ln0chiGq1So6nY6c23VdWVZAs2THcYRAlMtlvOxlL8PZs2cxPz+P7e1tfPnLX8bW1ha+/vWvo9VqoV6vyz3S41L7hlxN2RsOh+h2u7K8hf0ej8dRKBSmDJe5FMNIgsFgMBgMhsMG4/jG8Y3j78I4/q2HPfwzGA45mKSYqGj0yu9MMv1+/4oS65sVFLVyFfWoYFLWKiGXJ/i+jxMnTqBUKuHcuXMolUpYXFyE7/uiFlK17Ha7ktCocmYyGfR6PaRSKYRhKKXxVN5YHq5NfgGIzwb7gUsk2u22kASqhFTGmEyYrHh8Xlc2m5U+JTFwHEeUTZIGJqxms4l6vY5arYZarSZEoV6vo9frCWnT52R79T3T91Crs3sl0Fgshn6/jzAMEYvtGEDncjl0u10sLy8DAIrFIgDIMoZKpQLXdYVwURVst9sIgkDuke/74p3iOI4QM97zRCKBlZUVWX7QaDQwHo+xvr6O7e1tpNPpqWSulz5Er2mvsauXt9DDJJVKCUkhMSAxBHDFeQwGg8FgMBjuNIzjG8c3jr8L4/i3Hvbwz2A4hNCJN5PJTO1iNR6P0Ww2AewmQL3VPD9/NWVFJ/roe5lgU6nUlKKolTJd/s5lCEyk3HXr3LlzyOfzeOSRR1AqleR1bj/P7d614e5wOMTp06el1J3q2sWLF0WtG493d8wCIGXw7Jder4dqtSrJkYl3OBxifX0dQRBIeb7runAcB4PBAJcuXcLCwgLK5bK8TnNgtiUMQzSbTbTbbVSrVfGiICEYDAbY3t5Gp9PBc889h06ng2q1ijAM0Wg0ZDcwrUDu1xdjFmb9TR+z2Wyi2+0CAFzXRRiGKBaLuHDhAorFIs6ePYtCoSD3ZHl5GSsrK6LCcolAEARCEOr1uih6nuehXC6LrwvHQDKZRKFQQCaTwbd8y7egXq8jlUqhWq3iG9/4Bur1unixkOzQM4Tfaai8F0kgsSBJ4FjiGKVfCJcr8B6ZX4jBYDAYDIY7BeP4xvH3+v1afzOObxz/RmEP/wyGQ4ao3wfVPwBS5k9TWwbMaMn/rMCnFSWeI+pRwfMy0DOhElyGoBOAVpNYXl4oFPDwww+jXC7jkUceQbFYhOd58hmtLuo2M9iPRiMEQYBWqwUAqFar6PV6iMViot7ptrdaLYxGI2xvb0spe6/XE8WUCtHa2hq63e4VJsrAjndGo9HAwsIClpeXsby8DMdxUCwW0ev10Ol0pM+73S42NzfRbrexurqKMAxRq9UQBAEuXbqEIAhw+fJlUf50MrodSYn9GASBGAen02lZIhCGIUqlEiaTCebn53Hq1Cnx9/A8D91uF71eD81mE81mcyq50nskHo9jMBggnU7LznN6p65sNit+Lp1OB/1+X5ZDbG9vC1EiwaNi2263hWzxXs/qO92n2kCZajKJK+eGVn2NGBgMBoPBYLjdMI5vHP9GYRzfOP6NwB7+GQyHBHqbcypyVKPq9ToASLnzftQNbdgbLSmnWSzVPU0IUqkU8vk8SqUSRqPRlLkug27UHDiTyWBlZQXFYhHf9m3fhlKphFOnTsH3fczPz4t/iSYDDOQs16eHh2637/vI5/MoFAqSZFluT+WIaiEVOe7cxZJxtn08HovaGF3W0G638eKLL4pPSbFYRD6fl/7gfej3++JFEQSBlM1zF6rhcCi/02D4dhKCWaAaNhqNsLa2JksTHMfBU089Bc/zsLS0hHw+j5WVFZTLZRSLRRQKBWSzWTE8XllZuWLsMelzOQd3CUskEshkMgAgnionT56U+1ir1XD+/Hm02225r4VCYUod3trakiUUVCKpRs4a+3rpB/1BUqkUYrGYLKVJpVLiE6I9VAwGg8FgMBhuFYzjG8e/FTCObxz/oLCHfwbDHQaToPb7yGQykliYhDSuZe4bJQDa5Db6dwZQ+ik4joO5uTkxyNWGs9ogF4DsQsUdvhYXF/Gt3/qtqFQqqFQqsnxAm9hG/R7ojcEydJIj13VlCUEul0Oz2RSjXZblr62tifrH5QM6Ge8XW1tbU/3B+0CvkJthqHwnQWWX13n58mUAEFW0UqnA8zzcd999WF5exv33348zZ87g9OnTYpjsOI7sxsalEfRxicVi4uXCncKoyvF+LiwsiDEx7+X29raQA8dxxM8FAPL5PLa2tpBMJmV8ULmetaOYVpT1LmZ6uQKJAUmBVrwNBoPBYDAYbiaM4xvHv9Uwjm8c/yCwh38Gw20GVS8GTL11PJMog5tWQQ4CkgAeT5MPblFPxUT7YrBsmrtuMbAPh8Mps1suVchkMqKgnTlzBvPz8+ItQbWR7dEEg54e/X5fiAGvkYmZKtzGxgbOnz+PCxcu4Nlnn0Wr1cLGxgZ6vR4ajYYE+ptR7k3CwrYe9xJyXl+j0ZAy/MuXL+PixYuoVCqyNKJSqWBhYQH5fB6VSgXJZBL5fB7AdHKmakwFGNg1XabSHSWhJL2cB/SJKZfLMo4cx0Gn05FlBNovZi/SplVCYFolZ/tSqdQVaqLBYDAYDAbD9cA4vnH8wwLj+MbxZ8Ee/hkMtxlM2FSedKkyg5P2sLiRYMWSfyY3Bt1cLodsNiuv83f6P9CXgbtdMfgyCeu2Ly8vo1wu4+zZs+L7QX8IbTSsS/qHw6GchwRBH5Nb2dN348UXX8SLL76I5557ToiB3unpZkErljf72IcRTJo0l97a2kIsFpMdvubn5zE3N4czZ87gvvvuw5kzZ/DII48gn8+jXC4LcQSmlWpNSLW3DZeVkEA4jiN+IEzU3F0tHo8LyfR9H41GQ74DELU2upMawYQPQEyH6QPD3eb0/T7OBNBgMBgMBsOth3F84/iHBcbxjePPgj38MxhuE6jI+b6PTCYzFZS0aS1fvx5SoE1+WRKdSCSuOA4VSH4xUbfbbbTbbQm2/X5ftpXvdDpi/pvJZMQ7w/M8uK4rBIdkQKsxvH5gtww9Foshm82K+knCQCKwtraGCxcuYHV1Fc8++yy2trbETPZGCZNhNtin7N/t7W0px6/VanjhhRfw/PPPo1gsYmVlRXxC0uk0PM+b8gFhoqXPS61WQxiGWF1dRafTweXLl8VLZDQaTZlT088jkUjA8zwZy/SH8TxPVELusqYNgWddFwm39oLh+UgYtPpt48tgMBgMBsN+YBzfOP5hh3F84/iAPfwzGG4bkskkUqkUyuUycrmc7HjErdZZAn+90EsAqP5xly4mZypz2gckkUhIgG61Wmi1WmKom8vlZCepMAzh+74QAZrF8jWqOQzsTC48P8kK4XmemPiORiMxf718+TKef/55fO1rX8P/+3//D+12W8xg6QlxNwftWw3eu8FggG63i62tLVy6dEl8NXzfR6lUwpkzZ7CysoJXvepVQhAymQzy+Twmk4kQOCbvixcvIggCbG1tyS5jHO86WWvPmkQiAd/34fu+LPtoNpuoVqtot9vY2NiQ5QxM6rPGBl+j/wd9RUicafpMD57oDmQGg8FgMBgMe8E4vnH8owDj+Mbx7eGfwXCLQIUum82KCkaFrdVqodPpCCFgIDootOcCS51p2Kv9Rah60I+j1+thOByKeas24s3n85LwC4UCKpUKwjCU3aOo7jF5MGFvbW2h0+mg0+lMlYSzTVQM9XbvNJUNgkD6ZGNjA5ubm7h48SK2trbEM2Sv0m/DrQWVa+52RsV3PB6jVquh0+kgm81ibm4OmUxGdgKjr00QBOj3+9jc3Jzy8qACTm+OIAhk165kMinn1YSSyTyfz8t7UqkUgiCQsaTNfvcCiQFJqR6vnKvJZHJqmc7dShIMBoPBYDBMwzi+cfzjAOP4dx/Ht4d/BsMtAkuOS6WS7OzFnZNarZaoJtercukSahoLM2A6jiO7M43HYziOI6a+k8lEgjNL+ZngPc9DoVBAsVhEpVJBsVjEwsIC6vX6lHIDQHbJ6vV6AIBLly4hHo9LEg/DEACQy+WQTqeRy+WQTCZx4cIFNBoNPPvss9jc3MSlS5ewtbUlpeMM7PR6uBFQYSLYz3u9bpgNJkguDdne3sbFixcRj8fxJ3/yJ0ilUuIDUywWRR1MJBJCAoIgkCQbi8XgeZ74f1CVGwwGYhJMYqsNggeDAbLZrKiF+XweuVwOw+FQlrKwjcDe95UEk+OL5IRGxtztjkr91ZYbGAwGg8FguLtgHN84/nGBcfy7i+Pbwz+D4SYjGmSoanDnIibOg+wypcukiUQiIYpjJpMRogBAAjDPRTNW7qrE9rCMP5vNiuJCRZAKoDYmpkcI25JKpdBqta4IplSRAMhxuBU71UOWc9frdQRBID4M2o8haipLIkSCEiUrwK6KpT+v+0UrTfxcdNcv3p/9JIS7mVRolbbb7coykGQyKTvJcSySpPL+DQYDpNNpjEYjuK4r90vfSw1N6ng/AcD3fVQqFTiOI6SX3h/cYe5a94jXwTFOIkKFkKbCHFsGg8FgMBjuPhjHN45/t8A4/vGEPfwzGG4iaFqaSqWQz+elFB+A7GxFlWG/0D4JPNZkMkEmkxHFMZfLyXbuenv0drst6l0ymUSlUoHrupIEWX6dy+VEpWFQJNkIggDdblfa3m63ZVmBLg/nzkxUHjWJ0cGZyZff+cWEwfdps2LuHsVt4dlGLn3gblQ8F5VKEgmSoSAIhBDxmIlEQpZIULnVO5TxOqPJJaow8ve7jSiQyDF5cqcuXcYP4Ir7yl2+FhYW5Bi6/H8vkhAdD/w5DEOUSiXU63WMRiNR33VZ/7WugfPS932kUikh+d1uF8AusTQYDAaDwXB3wTi+cXzj+Mbxjzrs4Z/BcINgwqbvRSaTEdVNewkw6Vxv4uA5AIhyAUDKoKnYcVclqixMolQR8/m8HJOv0+BXkwoG1clkgna7je3tbUmaPKdO8FSEGDipqDDpa0KgSYFui07w6XRaSJb+zjazP/hdE5FoG0kMHMeRrehZbs4+GgwGU0satILFr73AxKj7Y9Y13g3g9XIc7vUeEslms4nhcIhqtYrRaIR8Pg/XdWXHOT0u2J9UBdnHvL8ce/Pz8wiCAIlEQpYI7FfhjcViMg9ITmigTUXybvUJMRgMBoPhboJxfOP4xvF3YRz/6MMe/hkMN4h4PI50Oo25ubmpZF2v19Hv96XM+EZ8P1h+n8vl5PjxeFxKn5vNJsbjMTqdjpAGTSSonCwuLko7E4mEBFKqK9VqFbVaDY1GA7VaTXYE04QhSm6i6g+DqTYO1oRAl47rz9EHgr/TiDibzaJcLiOdTsP3/SmVlNfFHct4TTSgXV1dRb/fn2oLAPEb4XHozVKv19FqtabMYEkkUqmUXIdWrEiKSKR4bPbX3UoQgNkKKZMziUO320UymUQQBPB9HydOnEC5XMb8/DzS6bTsQNbv9+XeJxIJ6VPOufF4DM/zUCwW4TgOgiDA5cuX0el0cOnSJfR6PTEzvlabuTufHmdUo9PpNHq9nixj4dIXg8FgMBgMxwvG8Y3jG8efDeP4RxP28M9guE5QIchms1JKz52+6KHBxHI1UqBL4fV7or4XVMOAXfWCyhVVLip+0VJ5vl/vykVzYBq1DodD1Go11Go1tNttdDodWU6gr0F7c1BR09+jSh2Nh8Mw3HOrdq0e6aUAVF6owgyHQ1Ebo4mZoNIUhiEajQZ6vZ60hZ9h0tbeFMPhUHYji947rSjpa9f+JJlMBqPRSMgJSQSJVPT+3q1LCAj2B+8xfTy2trYk2ZK4plIp+Zn9r5cRpNNpUQvj8bgYT3e7XaRSKTSbTSF6+n5crW08fywWm7r3nHe893z/9RJ/g8FgMBgMhwvG8Y3jG8e/fhjHP7ywh38GwwGhE2Mmk8HS0pKQApY2c4esq3kHRBMsg1aUEDABpdNpCYC6DJ8Gv+l0WtrCJM3dmJrNJgaDgXiU0A+DSXB1dRXr6+toNBpoNBoYDAaiwrCtui3JZBKu6yKVSol3AneAKpVKotoMBgM8/fTTaLVasvvZLG8GEiMqmul0GuPxWHYTA4BMJiM7ReXz+SlFhrtAjUYj9Ho9XL58GUEQYGNjQ66DBIoeJ1wCoD1ISAhmeZlQDeS1l0ol8RphUuI9HA6HYqRMEhK95ihpPC5J5aDgPdza2sL29jaq1SrS6TROnDiB+fl5nDlzBsAOOSDpTKVSsuSDqjD7cDgcinKXzWZlBzKOEfq8XCuR63vCMcF5QANujovoEhmDwWAwGAxHD8bxjeMbx795MI5/+GAP/wyGA0ArcEzAVLoAyI5ZB/H9IDnQvwMQ9Y5/Z1Lje7gUIZ1OiylwsViUEmn6fLCUfTAYiEoYBAEAoNVqiWkqkyU/y/J8LkfQW6STqCSTSVFFC4UC0uk0isUiYrEYWq2WJG+tss3qF62gabWPgX44HCKTyYjCxyUFuhybn+/3+9je3ka/3xe1k6CSQ4UyupxBkxat+GhiAOyoimEYSqk4PwvsLq/Q1xVVBSeTiXi3DAaDqfNGv0eJw3ElEJxD2o8mmUzC8zxkMhlks1nkcjm4riuqIO8hxzz7KZlMYjKZwHVdADvLS7jsoNvtCiEmed9Pn+r7QTJAcC7uV3U0GAwGg8FwuGAc3zg+YBz/VsA4/uGBPfwzGPYJJkiqYK7rYjwei0kufT8OSgqoMBBMJgyGBMkB/SnoQeL7Ps6ePSvvj8VishMWS6Pz+TyGwyEajQbCMMTFixel9L/b7YpSwkBMI14mx2KxiKWlJbiui7m5OQC7ag4VsWw2K0Sh3+9jY2MDW1tbaDabaLVa0j9RMIhGPRj0EgiWYHMpA5U4nfT5O9XEve4FS7r3QpQY6NcAiGLa7/eRSqUQhqEopslkEuVyWfxDWJ5OxZBtnEwmaDab6PV6smxBK1B6ScGsZRls/1FOPnuBxPry5cvY3NzE+vo6nn76aSwuLuLEiROoVCpYWVkRFTiTycBxHADT4yQWi6FYLMLzPJkTc3NzCMMQq6uraLfb2NzcRLfbveZOYQTHKskcz8V4EPWFMRgMBoPBcPhhHN84PmAc/1bDOP6dhz38MxiuAQZ9JiWqgpPJRFQdEoODqAFadWKQYSk9Vb+oTwhL8rkEoFAowPM8ZLNZMU5loub7qezxXFqp47moZOkdthhsgd1dvViuT0ID7BoT85z9fh/dbhftdltMefdDlrRypq+bCZHLJnSSjQZ0JtXormTXg73aq/uQ16uvn/1BoqBVQmBXVQIgBE6b1Ood5EhyeK36nvFYuu+OCzTJo4KdyWRE5XNdd2qJir7PumyfxyLJzeVySKfTaLfbiMfj6Ha7UyrxfscL7w29Qrhb2GQyuULVPm73xmAwGAyG4wLj+Mbxo68bx7+1MI5/Z2EP/wyGq4Cl79lsFpVKBePxWBJdvV4Xk9v9lhXrJM3ARpWJpc8AJMBQfRgMBnBdF7lcDrlcDmfOnIHjOKL6Ufmg8kZCwEDHcv9eryeGutx5C9gJuul0Gv1+H71eT0gCzw1ASvy5NMDzPAngo9FIyqzr9Tra7TaeffZZNJtNtNvtAwddTQr0z/RL6Xa78t7oZ2e9frPBcUAiQhWTO6xREQR2iAL7i6QS2FFaR6ORkCeCu8fxmmu1GqrVqixD0KXp7Ne9DIePMkigaNDcarWwtraGcrmMtbU1FItFnDx5EuPxWHZ6Ixmges6+cF0XmUwGvu9jOBwil8shCAJ4nodGo4H19XW02225p/uBHvucw/QIYvvpT6PJoMFgMBgMhjsP4/jG8WfBOP6th3H8Owd7+GcwzID2waACxyf/VGeYtA9CCvTPJAYMGjyOJg8ARJF0HAee5yGXy6FYLCKdTssOV7p8nKRCK4H6mDqRaXWD79WqoU6ATD4kEdq/gZ8dDAay1CAIgj3Nf/eDaJLX37WB750Ex4NuD8v7qfixf5gwot4jHAvsT95HDb6HyiPPR0VM30sqiACOBVng3GC/6iU0+Xwek8kEvu+LTw2wO3+1tw6wq6pTVczn84jFYmi321f4tuy3z9jvus/ZBr2Mh3PTYDAYDAbDnYNxfOP4+4Fx/FsP4/i3H/bwz2CYAQafXC6HxcVFDAYDtNtthGGIWq02MxBEoZO7fo2EQAcyJl5uW86y+1gsBs/zkM/nUalUcO+998L3fSwtLUm5dL/fl63Te70eYrEYFhcXp47veZ4oUGxHLBZDp9NBv99HvV4HAPEFodcCSYJeFkF1y3EcKb1mIqTnSL/fR6vVOpA3yixcrSz/TkMneGCXGDF59Xo9pFIptNttpNNp5HI5pFIpUW6pELK/WZbebrfR6XSuUGZjsdiUITPvCbDrzcKf2fckd3q5ylElClTg+v0+arUaCoUCarUa5ufnAQC+72N+fl5IsV4yoH8HduaD67pwHAeDwQCe56FWq+HixYuo1+sHNvTWSxhI1HivHMfBaDQSn5D9qo4Gg8FgMBhuPozjG8e/Fozj314Yx799sId/BoOCTtpUvxKJBAaDwdTXfgPGXuSAX9qvgwGbyTedTsN1XXieh3K5jFKphKWlJTiOA9/30e/30el0JFiy5J+JejKZyK5KDEjcCSkMQyEBXNJABZBLHhgYqXrpJQqJREJMcFmGzc9xCQADJftgLyVP/x04et4WWq1kEmZyGA6HSCQS4hmi+5DJnX3Fvu90Ouh0OuI/w+PqvgZ2d5/i3/gaj8WESLVLK8/7VbIPE6JLQ5LJJJrNJtLpNOr1Okajkcwb3U96rul+isfjcF1XSNtwOEQ2m5VlF7q/9gtd9q+X5mhja17LUVoiYDAYDAbDUYdxfOP4B4Vx/NsD4/i3D/bwz2BQoOcGS++pcnW7XfH/uFagiCZ9YLeMHYCoQQxSOmjF43GcPHkSjzzyCM6cOYOXvvSlcBwHxWJRvEl6vR62trawvb2N5557Dp1OR9rG0vBut4ter4e1tTV0Oh1sbm4iDEPU63VJQNEt6KMJQytIvCYmMf4dwBXkhqXb+pp130T7jwbEVME0+TrMwZPQpI7KIPspFouh1WohHo+LisoxxH7TO4Qx6Wkyxr5lcqHfCH1q9N9JaLPZLMbjsZC0IAimlF4u1TiKBAHYGXtBEGB1dRW1Wg0bGxuoVCp4+OGH4fs+lpeXxbib5tm8Tr0Eh8RrcXERuVwO8XgcxWIR1WpV5r3epW0/YJ8GQSBkIJFIoFAoYDKZiPrLe2AwGAwGg+HWwzi+cfyDwjj+7Ydx/FsLe/hnMGB6t69MJiOKDMvse72eJNGrQQdzftf+ABpa/YrHd3bf8jwPc3NzOHXqFM6ePYv7778fruvC930AkGDf6XREbaLyp88RhiEAoNFooNVqoVqtotvtyhIAHRy1D0K0nZok8HUmNn3OqL/IQVTTaPk2VUwqikctcbFf2GckCNwxSvuA7KXa6XvB/plF3pj4tNcLSRYTHwAxJ+b5eK/0/T1q4BjhFwDUajUMh0MUi0XxyuHYivap/kqn0wAgZsHdblfUXV3qv19QTWc7dTzgPWGbjgL5NRgMBoPhqMI4vnH8mwXj+LcHxvFvHezhn+GuBhWpfD6PXC4nqgt9PwaDAYIgkACxV0k7EyPLtHXAp7GrThj6c8lkEq7r4uUvfzle8YpX4BWveAUee+wx5HI5VCoVABAFkT+nUikAO7tz9ft9FItFCTSDwQDPPvssOp0O1tbW0Ov10G63Ra2KtmPWNUVf08lJq4j6OqJq4kHBPk4kEvA8T9TBm+mhoFXaa73nWu/TxGjW+3TA53jY67173QutNrJ/2N8kenr8ZTIZGYMA5P2O4yAWi0l/krD0er0ptfCogeOdffMXf/EXyOfzCIJA1MFMJiM7hWmVToPeHUtLSygWiygWi+h2u1hdXcXGxgaCIJA4cJB+omcP1WAqulQj9T0wGAwGg8Fw82Ac3zj+Xu+51vuM4995GMe/NbCHf4a7GlRQqMhpA9wgCMRjA7i2chI1HwUwMxkwsDDZs4R7eXkZ9957L86cOYOTJ08inU5LKbNOttrrgOQj6lvSaDTQbDbRarVE1TyIuenVkmM08c/6+0Ghr5FJjurgQZXGa+FqSmOU5Oy37ft5z420X/cNQaWRP1NxpIEwr4PLEagExmIxIZb8/FEkBQQTLADxBaE6mM/np7xXCH2f9ZhjPwE787LVak157nAO7fdekkjTJ2Yy2fH74fkAHKnlLwaDwWAwHBUYx58N4/jG8Y8KjOPffNjDP8NdCQZSz/Pg+74EhG63i2aziV6vh263e82ENKukPZlMiuoymUxEjeCxmOxyuRyy2Sxe9apX4WUvexle+cpX4hWveAVyuZxsc05SwiBGQ9/t7W0EQYBcLgcAKBaLGI1GuHDhAprNJtbX19FsNsV7YL+JVfuSMNHoXab0dV+NHBwEVKWY9BzHmfJyoG+Jfv/1bqmuy8CvdV+ZMG4WIbkZiPa5/p1EIRaLyY5wHHvsTxrlsl9TqZQYOB9VbxBiNBqh2+1iOBzim9/8JlzXRaPRQKFQwIMPPgjXdSUpRwm7JtvsK8/zEIvFUCwWsb6+jmq1ik6nM7XL2n7A+6SXFSUSCWSzWbk39Ae53nFtMBgMBoNhB8bxZ8M4/u77jOMfLRjHv3mwh3/HDHrNP3A01/nfakTL95mIAExN0GtN/CgpiPqAMNFRjdAl9MCO8XChUMDp06fx8MMP47777sPp06fl+LoUnoGciiVVPsdxAOz4PbA8OgxD2fHroIGG7dfl0ywr122PJqRZ/RJVsfZCtByeCUorJ/yb3jkr2o79Xt9+2nStYxyWeTWLKERJjVbNuFyF5JVqmVayD8u1HRS8zvF4jHq9jjAMkc1mReHnWIqadFM5BTA15hKJhBgE93o92TGPO4XtlxgQXE6giQmXCOgd4o46QTMYDAbDrYFx/GvDOP7Vr8k4/rWPcVjmlXH8XRjHv3mwh3/HBKlUCqlUCisrK8hkMrKG/TDvNnMnwNL5QqGAbDYrAaHT6aBarU4FgL3AQMqdnUgyNNkAdhOq3uFpMpmI2fC3f/u345FHHhFVMJ/PA5j2xaCKAQD9fh/b29uym1c8HsfS0hL6/T7a7TaCIJgqYb5acNHBUYOKEQkTx48OoFETU02IaGo8q/yaXwy8XHLBna94zOFwiE6nI+oME1kul8PCwgKCIMDa2hr6/T46nc6Bgui1CHOUpERxo6TieqBNpfcal5qkAtPXqdXpXq8nfjK8z67rCoFk2ftRBsvvx+MxVldX0Wg04DiO+IM4jiMEibHR8zzZoY8JfDgcIpVKiRG353mo1WrwfR+NRgObm5vX5VXDeNBqtUR95Jzh2O/3+3ecHBgMBoPhcMA4/v5gHH/3GozjXwnj+MbxjePbw79jAQbOTCaDubk5eJ4n5q/c7t2AqafwDBQMhDTMvVaprw7AJBlMXtGdfrgMANhVH8bjMVKpFLLZLE6ePImHH34Y99xzD06cOCHn0AFB79g0Go3Q6XQkWcdiMfi+jzAMUa/XxffjWkFFJ/HoOfm3ZDIp5eKaCPD69O9UlKgkep43dfyoQsr+isViCMNQ7oH2sOASAH1cx3FQLpeRTCZRr9cBYF/LNjT2877DRAr0eLsaWdXv43jRKiGJJHcBI1zXlXvN+30cwDHBOb2xsYFut4tcLid/4/wkQeC45Oe5c1s6nRbiQPLU7/dlnh9UxeNcpgkwj814QsX/MKiDBoPBYLizMI6/PxjH370G4/gHf49x/KMD4/g3Bnv4d8QRi8WQyWTwwAMPYG5uDm94wxvg+z4+8YlPoFar2T+P/3/QC8D3fVHtms0mut2uJKdZCVUnAwbfVCqFTCaDUqkkSVF7KlBhoeLFSU418LHHHsPZs2fx1/7aX8MjjzyCubm5qYBOsgFAgtvW1hYajQYuXLiAfr8/1Q7uNtRsNrG5uYlmsymJlUmAbWcioILJhNzv96XdXBbBdvMa4/E4stks5ufnkclkkM/n4TgOisWiEJhkMolisYh0Oo18Po9EIiGJnz4K+XweqVQKm5ubaLfbqNVq6HQ6ci82NzdRrValdHo8HqPf78NxHDSbTUwmEywtLSEIAkl6VAd5v/Ryhps1B273XGKypuLM5R4cJ9G26aUK+rteajEej6eU3WQyCd/3MRwOZV4clrL0GwUTcBiGWFtbk539fN/H6dOnryCwnHvxePyKWEAFlWPadV2k02kEQSDH7Xa7B+ozKuGtVgthGMpuZFQJgyBAv98/VCbBBoPBYLh9MI6/PxjHN45/ozCOf7RgHP/6YQ//jjiYIBYXF3HixAk8/PDDyOVy8H3/yE/smwX6HjiOg2w2C8dx0G63EYahJKRZgTDqgaHVNCqLTOCDwQDNZnNKVWRi5bGpBp49exYvf/nLce7cOZw8eVLK/jUxoP8HA9v29jZqtRo2NzcB7Jbuc0vxfr+PbreLVqslBAXYLSdn2x3HkfJjBkD6EOhdjviaXurAoDU3Nyfl1Z7nYWlpSdqbTCZRLpfhOA4WFhaQTCYlwG1ubiIMQ8zNzcFxHFy+fFmMi+v1uixrGAwGqNfrcj/YDzRoTqVSyOVycux4PI4gCCQ56mUH11oawft6GOeKLt3XCvNeuNpyBn6WKhjVXi674PKYdrs9RVKPOkh0m82mzJlOp4NKpYJUKiVkiHNU+/qQRGmlnMQa2BlbjUYDYRgiFouh2+0euG2c34PBQEgg/4Hgrn6HdXwaDAaD4dbCOP61YRzfOP61xsdhnCvG8W8cxvGvD/bw7wgjFovBcRzkcjnce++9WF5exubmpuwCdTMVkaMIlq8nEgmUSiVZ1z8ej2XHr6uV3jJQaGVNl8t7nieTmYlZLy3gUgxO9HPnzmF+fh6vfOUr8bKXvQwLCwtTSZpt4HG2t7dx+fJlNBoNrK+vo9frodPpSHk8sBOc6vU6zp8/j1qthna7LYoGy5k1OWB7GYyYdNlW9pfjOHBdF/l8HpVKBZlMBp7noVgs4p577oHruiiVSshkMqhUKtJ+Ko+pVAqFQgHxeFyWK8RiMQwGAxSLRVFAut0ulpeX0e/3xb9meXkZCwsLaDabqNfroniORiNsbW3JtdMPhcSD10MiqJcWXG2M8Pthmyt6KUW0zD8KTaKuBr6PXjXst3Q6jXQ6jU6nsy9PnKMGEkSOp+effx6+7+PkyZPwfV9iBUml7/tTvjYk/IPBAL1eT+YIFe5WqyU71PV6vQOrg+PxWP5ZIfkgaeEyH4PBYDDcPTCOf3UYxzeObxx/9vuM4xvHvxrs4d8RBgO967pYXFzE/Pw8ms0mWq0WgiDYlyJyXKHVIS4FKBQK4qfBRL6f42hfC72teiaTkTX8DBTaSJSB1XVdOI6D5eVlnDx5EmfPnsXZs2dRLBZlBy9gJ2iPx2P0ej00m02sra3hqaeeQqvVQrVaBQC5HgDyXqqFTMBUEjg+tP+DLnkOgkDOG+0vkoLFxUUpny4WiyiVSrjnnnuQyWSQy+WQSqWQz+eniAGJTjabFQVK77SWz+eFGOidynhf2Mb19XVpF5VbEgSqu+zDarUq18Xr1EsEeP+uNh8OKzkAcFVSQOxXyaMaxSUhw+EQnuchnU5foUgdF/CaOf/X19fRbrdRKpXgOI6MfZLoTCaDTCYj448Eistj0uk0stks0um0KKzb29vyXp5zP2CcCMNQlGCq/QCOjUeLwWAwGPYP4/h7wzi+cXzj+Hu/zzi+cfyrwR7+HWHwSTaDcy6Xw+rqKqrVqhjGHqcn+/sFJ3YymRTliiXp7XZbSsuvBqqBOtHxST2XXND3wnEc9Pt9tFotURjH47GUWy8uLqJQKODkyZOyUxs9OLrdLur1OlqtFtbX17G+vo5ut4sgCLC5uYkLFy6ID4RuA02AqRrS7JSJlkGO7eHOSDSFZfDyfR+u68LzPDiOg1KphHK5jEqlgoWFBfi+j1KpJDtGUQ3UCZcBk4SFCiCXOrAMnUlHm6hytyV+Nh6P4+zZsyiVSlhfX8fq6iouXLiAJ598UrxDgiBAtVoVchCLxbCysoJer4dqtSom2CRpHBP8rgkAd39iQqCHC3D7/T+i0GSNfiAHhfa60N9pdssvEttsNgvf92V8HpelAQTnJs3SNzY2MBwOUSwW4bquqKocp8ViEb7vy1ymUt3tdmX5BL1UeNzLly+j3++Ld8t+wblKVZHKPGMRSb/BYDAYjj+M48+GcXzj+Mbxd2AcfxrG8feHm/7w74knnsCnP/1pPPnkk3BdF9/xHd+Bf/Nv/g1e8pKXyHve8IY34Itf/OLU5971rnfhV3/1V292c441SAy4U002m0Wn00GtVpNdZu5G8Kl9Op1GoVBANpvFxsYGOp2OlN1eSx2KEgO9g1g+n4fv+5JMPc9Dr9dDNpuViUtiwJL5ubk5LC4uYnFxUXZcGgwGiMfj2Nrawvr6Or7xjW/gqaeekqDSaDREDWS5MpXIMAzRbrclYW5vb8sSEK1w6GBDk9+oclcsFlGpVFAsFnHq1CmsrKxgaWkJJ0+elPFFtYLkZDgcigcHE2kmk8FkMhHSwaDGviZRYL+SGJAwsO0rKys4ffo0FhYWUC6XkUqlsL6+jslkgs3NTQyHQ9nhrtfrIZPJYGFhQfxdYrEYgiCYuSQmSgyo8LK/qB4dpmSofUH2iygR0jvSAdPEgF41mUwG2WwWYRiKz8pxMAWOYjweo9PpoN/vi2E6l0DwetPpNJLJJAqFAhYWFuB5HjzPQ7Vaxfr6OhqNhoxXEoN4PI5arYZGo4FYLHbgpQEkYSS1PKe+Z/bwz2Aw3EkYx799MI4/G8bxjeMbxzeOvxeM418bN/3h3xe/+EW8+93vxrd927dhOBzigx/8IN70pjfhr/7qr+B5nrzvn/7Tf4oPf/jD8ns2m73ZTTn2iMfjcF0X2WxWEgeD491ICuh/kUqlRLHjDl/tdntKNdsLTBQs+eUOQDqRzs3NIZPJAIAk6F6vN7WtN0vmHccRbwr6eWxvb8u5YrEYLl++jI2NDTz33HN44YUXRBUMggDtdnvKG0ATjjAMsbW1NeX/AewkAwZ8x3EkmU8mE+RyOWQyGTH0XVlZQaVSQS6Xg+d5mJ+fx9zcHAqFAsrl8pSyxsBFhZFjjooa7wHnOV/Xu3JRgdKJiwRB75pGwrC0tIROp4P77rsPFy5cwMbGhpSr8/p935e+npubkx3Fer3eVGLT5fUkOY7jCCnRSyOIO5kUmQjYHwfxhNDXQqIMXLkzGndRC8NQkqHv++h2u+j3++JFcdzIAQltvV7HcDhEtVoVIkC/GZLfZrM55f/hui46nQ7m5+dRq9XEXJz/jDQaDbTb7ev2B+E9oq9QIpFANpuV45HUGQwGw+2GcfzbB+P40zCObxzfOP4OjONfHcbxr46b/vDvs5/97NTvH//4x7GwsIAvf/nLeN3rXievZ7NZLC0t3ezT31WIx+PwfR++74vi0u1270piwADoui4ymYwQg2q1KuW7V5ugTAZU/7LZrCRR13XlfdwJi8pSr9eT5ByGobwHAMrl8pTiRbVla2tLytYHgwHW19dRrVbxwgsv4Pz58+h0OlPmoiQpVPV4DfQ3AHaTMMkBl4NwtyMmiuXlZeRyOdx///1YWFjA6dOnhehQRc3n8+INwWULTExMUlrd018kUuyfyWQytVtatEQf2PVqoFKqkxmXPjCAP/XUUwB2CFkYhqLqUDmrVCrodDqoVqtS1q6TvV4KQJWX/he8rui4uFNJURMm4Pp8ITgmGB94XN4HLt/gNvTcZY3GzFqJOk7kgGOu2WwiDENsbm4KKcpkMtL33F3PdV2Mx2Pkcjnk83mZyxsbG7IUgAS+1Wqh0WjILoMHJVZUa1utFrrdLkqlEjzPE6JG02uDwWC43TCOf/tgHH8XxvGN4xvHvxLG8WfDOP7Vccs9/xqNBoCdIKnxiU98Ar/xG7+BpaUlvOUtb8HP/MzPmDJ4QCQSCRQKBTFE5QSnEfDdAq3uFAoFSWhUSOmNMmtyMmloE1B6IhSLRSSTSXieJwGSPiOj0UiWXjSbTQBAsViUxAxAFDkmeG5t7ziOBCYGlWaziXa7jXa7jSAI0O12rygRZrDi6/qaossYSAho5Mt2z83NwfM8nDp1CqVSCcvLy6hUKlPboFN1YABiEtHkg0ojPUaA6a3mgV0VkUof28bXSMK0wTI9OQaDgSTvbDaLSqWCarWKSqWCZrMpfi70dmm1WlPGyp7nie+JTmy6vJpEBNhRx5iEo33Ke3g75pQmJlH156DePnqMzNpOnmM6FrtyRzB+0Zz5sC2TuFkg2dra2gIAFAoF8fxxHAe+70t1AMdGMpmE67pSLQAA9XpdiGar1YLjOFNLkDiHDwKOUZp2j0Yj8b9hPLgb/Z4MBsPhgXH8Wwfj+Dswjm8c3zj+lTCOf20Yx5+NW/rwbzwe45//83+O1772tXjZy14mr//gD/4gzpw5g5WVFfzlX/4lfuqnfgrf/OY38elPf3rmcVhuTTAQ3+3g9vblclmUGCpgd8sOkVSiaAw7NzeHZDKJtbU1SRhXeyqvE2oikYDrumL2q01wqRDonZJoutxut5HJZHDPPffA8zzxwWCy4ftqtRq63S5c1xWVDoAYjDYaDTSbTfR6PQRBIG2LLmOIJgydwJhgGdDOnTuHcrkspcwseeYygJWVFZTLZdk9LpFIyPHpdcCxxCDIvuIuSFQqSSKiBIFJhW2jOsglHDTk5U5qVCBd1xWVamFhAY1GA4uLi+KhwnMnEgnU63VRcKmWJ5NJUVejiY39x4BNvxRegyY/bPOtJgazliPoeXw9iVl7XETVUU06wzDEYDCA4zjylclk0Ov1xCflOD5o4j3nzmBzc3PikVMoFCQWJJNJiSPJZFL+Ecnn85ifn5ed6DzPQ7fbFTW7VquhWq0KCbsedZDkIpvNyu56VNGP4z0xGAxHA8bxby2M4xvH19dgHN84fhTG8a8O4/izcUsf/r373e/G1772Nfyf//N/pl7/0R/9Ufn5kUcewfLyMr77u78bzz77LM6dO3fFcZ544gk8/vjjt7KpRwpMhplMBuVyGeVyeWrL6IMOwKMKqniZTGbKZDcMQ3S7XXS73SuUM2KWmqYNV0kIMpmMmP2yHHdtbU1K0ulbQWKSzWbheR4SiQQ6nY4E23g8jnw+Lwqd9sOgT0gQBHIOrV5ptY+v6dJ6+hik02nk83lkMhkp/X/44YdRKBRk2YjjOJLs9BjhsbUKSKWZ72Vi5HcmFxrp8rpo1KuVRg0eL5FIYDKZiIcLr10va+DOZblcDqVSCQsLCxiNRrh06ZIsVxiNRgiCQNRE3T8kI2yrJi26j3V7ZxGt25EUrzVnb2ROj8fjKWKg+4HXToWUxI9zQffVcQWX81SrVaRSKSwsLCCdTotRNnero9pMUsWlPSRwVOQzmYzsqJbP55FMJtFoNK5LXeXc4xd9iRh/jvu9MRgMhxPG8W8NjOPvwDi+cXzj+PuDcfyrwzj+NG7Zw7/3vOc9+J//83/iD/7gD3Dy5Mmrvvexxx4DADzzzDMzicEHPvABvO9975Pfm80mTp06dXMbfIRAr4RsNovl5WUsLy+LUsU148fxCX4UVAN938fZs2eRSCTwzDPPoNVqiboWLWcndNKiXwITVHR3tXw+L2v72+02VldXJSgkk0lRDpiAS6WSHJcEIpVKYX5+Hvl8Xsp62R6qB61WC51OZ6p0ne9jkqZSxyDOhDw/Pw/f93Hy5Enkcjk89NBDKBaLOHfuHHK5nJQv87rr9foVO6JpFZBJgcqYVtY0QaBKwqUTfF0vX+ByBAZPlv7znNlsVnwUOp2O3KvRaIQwDBGPx1Eul9HtdnH27FkAwHPPPSdLYEajERqNhiQzmmQDmDL6ZXuj1xAtlScx4HWl0+mZ77sVuFXH12NKQ6uj2lSayzF0+flxxWQykaVDFy9eRLfbxQMPPADHcTA/P4/Tp09LXGBfaELAkn8AohgOh0MUCgXE43HMz8+j2WzKznkHVZf1fBoOh7JMhlUgvAaDwWC4XTCOf+tgHH8HxvGN4xvH3/9xjePPhnH8K3HTH/5NJhO8973vxW//9m/jC1/4Au65555rfubP//zPAQDLy8sz/07lx7ALTt58Po9cLifKEs0nj/NEplLFCZJOp9FutwFgT/+P6MTRSpYmBSQaPC5VLvpOcIcuAOIJUCqV4DgOer2e7BikfTlY2s5zUFVgOTKPu9fSBb5X+5bocvl8Po+XvvSlyOVymJ+fRzabxcLCArLZrAR3qp4MMjrZ8TuV5WifMYlr5UPfC/4eNY1lMkqn0+KnwKBI4kRVVCcmKt5UDRlMZykgVProW8FjcvyzbPpqgVMvz9Dt5uei/XAryYFux60+16xzkCS7rgvf99FqtYQkHmePId5vkn8qblTlAcjSEarPJAZ8TRNKqoiO4whBqNfr8s/CQfuSMYBLNIDde8W5YTAYDLcaxvFvD4zjG8c3jm8c/2bAOL5x/Chu+sO/d7/73fjkJz+J//bf/htyuRzW1tYA7Jgsuq6LZ599Fp/85CfxN/7G30ClUsFf/uVf4id+4ifwute9Di9/+ctvdnOOJTgAWQpfqVRQr9exvb0tyspxnsT0jnAcRwx7q9UqBoOBGPRGl0VEVRH6HbiuO1Umn8/nUalU4Hme+FMEQYB2u416vY52u41GowHHcbCwsADP87CysoJEIiHbzwOQnbRYpj8ej+H7vhgBTyYTeX+9XsfW1paoBhpazdIJnoTwnnvuwcLCAl7/+tcjn8+jUCjItTBIsT0kAyxnJlhmTOVQG/2yv+kZwaTNBKzbGyUG/DzJF8v29TKCWCwmgTiZTIrPCD/PgEj1JbpjF/8ehuGU0qiXFeyliEWhr4eJgiXzVMtuZXk8SVa0bP96jkPsd5kB73kmk5Fklkwm0W63Zae74xxTOM/oH9NqtaSqQBtkkzgMBgP0ej1ZtsId57RPDpcCLS0tIZfLoV6vizqul6fsF/SkoW8RFUi9JMFgMBhuJYzj33oYxzeObxzfOP7VjkMYx98fjONP46Y//PuVX/kVAMAb3vCGqdd//dd/He985zuRTqfxuc99Dh/5yEfQ6XRw6tQpvO1tb8O//Jf/8mY35diCSwK0fwWJAQfrcV0Gxifhvu9LAhkOhzJZ92PaSh8Rz/OQz+fh+768nsvlRHHjU/hmszmlNvI9/K6THH9mWTo9JdgmHnM4HMpW4QxCs9qtFVDHcWRJAc1877nnHpTLZZRKJfi+j1wuJ6oj+wvAFYFIe17MWoLAQKmvh0oniYT2KGGCBjA1Bnksnlsrbjxf9PdoYud5SHb4t6sl0VnEZS/FNarE6TZp01V9vluBKDE4yBKEva5hv+ckMdC7slHJTqfTorwed3B+0uRb7+JFctzpdMSwGtgde+l0WnYLHI12du0Cdv4JoS9IPB6XZT8H9W3imGQbx+OxEHi9XMFgMBhuFYzj33oYxzeObxzfOH70s9HfjeMfHMbxd3BLlv1eDadOncIXv/jFm33auwo0g/Q8T4xOX3zxRayurqLVaokh6nEDg5frurIjVBiG6PV62NzcFOXiamOQgTCfz2Nubg4LCwuoVCri7+E4DnK5nDz139rawosvvii/ZzIZrKyswHVdLCwsTJEz/sygWiwWZTtwlhAHQYB6vY5Op4P19XVsb2/j0qVLaDabV2zVrtXfXC6HSqWC+++/H4VCASdOnEA+n8eZM2fgeZ6Yl5LkBEEgHh7Aru8FEyYTO7CbrPV5Gbi4rEH7YtCgVxsKs1x6PB6j2WxiMtn1CWHA4ntnGTRrBZJLAZiQqbRQCeE1kIgxgUePM2uZwyxoJVATI7aZx9aJe9YYI2EhDjoHNemJtmUWNIGYRVhI4q4GPcYcx5HlGyTdjDMslz+u/3AQVJ63t7exsbEhc5XKdKvVQqPREE8eKnP0JuI/FzQDpwqYSCSwsrKCVquFVqsly1YOouZxjlJddxwHvu/LHCBhMBgMhlsF4/i3HsbxjeMbxzeObxz/5sM4/g5u6W6/hlsDBut4fGeLeD7BpjJ2HEkBgzzL6jmhuHsWvSauRQoY+JjsdBl61PiWPhUs86dfyOLiIlzXRbFYRDwen0ocWl0BplUw+rVsbGyg0+lgY2MDrVZrzx3LuGQhl8thYWEB8/PzOHfunBAB/o1eOQwOOknohKmJQTSZ6ETI90fVRaoe2rdEq306WZMYaEWUim7UZ4Ova7Vvlqqn+3NWmf8sBVCrefp6Zn02mlyjCqZ+7VZAq6HE1eayVl1vxrl5/XpJiDZYvtpnjwth4P2t1+tYXV0VckBwR8DRaCRLYNhPvH96SQAVO3qsjEYjeJ6HyWQi8+h6vEEYo3hu7la4l6eQwWAwGI4GjOMbxzeObxzfOP7Nh3H8HdjDvyMIlptnMhlJLGtra1hfXxcTy+METrhsNotTp05hMpmg2Wyi3+9je3t7X6SAigvL+H3fF8NZALJEgESAZKvRaKDdbsN1XczNzWFpaQnf+q3fKkbBg8EAnU4HAEQV0MmYXgFhGOLChQvY2trChQsXsL29LcsMdKLUSaxQKMhObw8++CBOnDiBV77ylbIcRKti0Z2cmFiplLJtuqxeJ+DxeHcbePaXBs1NgyAQvxkuv6B6SK8T/T0ej4tSQY+UIAhkjE4mu+a/OjHFYjG5r+xTKjF8Pao2Evp33guqg1ECFP1cVInjOdi2axHPGwETMtvAfrta4t2L6BwUJMta2da+OzTA3gtRknmUMRqN8Mwzz6BWq8kym2w2C9d1JS5oc+psNgtgV9H2PA+JRAL9fh/pdBr9fl92pMtms6IMskogSj6vBY5JnoPm34xVt9KzxmAwGAy3FsbxjeMbxzeOr9tjHP/mwTi+Pfw7kmCAZ7npaDQSVfC4kQJg+nqZJKhOMUHsNRF0aThNND3PExUQ2FXAWPLOJMl1+77vC5mgV4hOsEyoTNY8Rr1ex2QyQavVQhiG2N7eFkPhbrcraiavkeoLg/HS0hLOnj2L+fl5LC4uolQqibGuNvulGhglGDzuXkqgTqz80r4mbA+Px9e0LwgTuz42VUEeC5g2nSUZ4+uaqETvO5MiCQHHO7+iKt0stZPf9et7Jdv9KI63CkwQTNAARHXmtd5sxV/3vSalTGQca7xn11IAjzopIMIwRLPZxOrqKp555hlUKhWUy2XxHNLEUVcFAJDlMyTIrusK0RuPx8hmsxgOh8hkMnK86wHjlN5h727Ytc1gMBiOM4zjG8c3jm8c/2bAOP5s3O0c3x7+HUHwyTMVlsFggIsXL+Ly5cvH0vOJ5r+ZTEbUL/qezNoaXoMKBz+/uLgo6/Xj8d0drjzPg+/7crxWq4XLly8jl8vhgQcekPL8fD4vATSdTk8lHCbpIAjQ7XbxzDPPoNlsotFoIAxD1Go1hGGIIAjEYFQnVtd1ZcnBysoK7r//fjz66KOy7j+dTgs54vmKxeKUQqeDOwAJTlR7+NnBYIButysKI/tQq0OZTEZMT/k+KntUROPxODzPA7C7cxe9JDQpYD+R+Ohye77Oe8JrYYLq9/vo9XrodDrStyx/jnp1MDCyLUykemmAXqYwiwBEA/2s910LUbKyn2Mw+Xueh1wuJ693Oh0h/UxKNyMBx2IxuaeaaJI0JxIJ5HI5+L6PdrstJPFaCuVxABW2L37xi/jqV7+Khx9+GA8++KCQdv6jMBgMEASBzBv6grBqoNfrIRaLiaqaSqWwtLQEz/NQq9XER+d6EjnnCWMWDYiHw+Fd4d1iMBgMxxHG8Y3j83zG8Y3jXy+M4++Nu53j28O/IwitcjFR7idJHjXoJMeSbiYE/SR8P8fIZDLIZrPyReUO2AloTDw0A9Wl6rlcTsxodVJj8qUpLidpr9dDt9tFvV4XYtDv99HtdmUya0Khg3CpVMLS0hJOnjyJ5eVlzM/PT5Vq8zNsv06qGjoR82edoKPl9DqB8iuqRmnywDbwXPwePZe+DwTbpJVMvhY1BeY1MynSj0G3Zz9j/kbnxbXUMJ5Dq5L7+Uz08/r9VOw412+Fz4/2xmFfa9IGYGqHsFlz7jjFHILjvt1uAwC2trawvb2NfD4/VY2hfUGo5ALTO+3xZz3WOad1dcJBwXtEg25gd8zo8xkMBoPh6MA4vnF84/jG8W8GjOPPxt3O8e3h3xEDA0U2m0Umk0GtVhOV5FqeGEcNnECZTEYUqo2NDYxGI4RhuC91hCoQS3rn5ubgeZ7s8MP3bGxs4IUXXpDPDYdDef/S0pIoc/yb9m6Ix+Po9/uo1+vodrvY3NxEq9XChQsX5LWoSa9O5PR2eeihh/DII4/g5MmTuOeee1CpVLCysiLXyyAwHA5lp69yuSzqDsvHSVK0OsjPsr90KbFO8FxqwcRMEgpAEjK3NSdB02SA/QnsEgdNaLQ6x2vhuVjyr5NUKpXCcDiUEu3NzU00m80pUsG26+9sB9ulFdPo0oDo56LjZ79Bln9nf80i6lc7BgM97wHVOip1JGw3C7FYDNlsFr7vw/d9eJ6HWCwmvjJMYrlcDs1mU0rY74YlpRwzrVYLQRCI58fJkyeRyWQkNnEOcce06BIOHmcwGIh3E7AzJxhP+I/D9dzbyWQin6XhMIm0Ji0Gg8FgOPwwjm8c3zi+cfybAeP4e+Nu5/j28O8IggGTwfRmlgkfFjChMzgCu+vftaK3n2NQ+dCBVm9RT1POVqslJe+u68rk5Wez2ayU8FJZ00/0del6p9MRBUuXuGvvBf5Mw9G5uTksLi6iUqmgWCyKb8lgMJhSbHQy0yqaVu+iCZDnZj+yf/S4SSQSQhhIXPSOZgx2WmnUx4uqG9HfrzZGtaIYfZ1KaxiGUzunzRoD0f6Z9be91MqrzR9NMq4Gzk0eb7/JXLeD41yrO7P8Um4EenkEiZg+B5Mbz03yRoJ1nGLN1cD5xLEXhqEQWs5praRrlV3PQT0W+Nl0Oi1Lbag0Xi85GI1GU54t/Pm4VYoYDAbDcYdxfOP4gHF84/jXD+P4+8PdyvHt4d8Rgi6Pd133im3Zb2bguJPQyme5XJ4yvRwMBvuaPAxkruuKATCV1FQqhVwuh0wmg2q1io2NDTSbTbRaLSwvL2NlZQXlchlLS0vyZD2TyWB+fh7D4RCNRgPj8RidTgfxeByZTAaj0QiNRgP1eh0XLlxAu91Gq9USw1+tWpHU+b4Px3Hw0EMP4b777sP999+P+++/H47jiKeANtzV5cV8LQiCKS8Nqo/07GCpMMcLkyrJEokRfQ4ajQY6nY6ojAwyk8kE3W5XlkmQWFGxBKaNeLWaSG+CaGJm39EQlW1iUiIZ2NrawuXLl3HhwgU8++yzCIIAvV5vZuKfNTY0AYr6hzDp7RVAdX9f7Rz6eubm5gAAtVoNg8FAFN29QC8OtrHb7SIMQ0kaemnEzcIswszXkskkgiAQ02oaVmcyGUwmE+n7W7FE4bCB96TVamFtbQ3FYhGdTkfmGNVBvicWi4kXCP/xiBpo12o12cErk8mg0WggFovJ7mAHTeS8F5w3sdiOt5COl3cLkTMYDIajCuP4xvGN4xvHvxkwjr8/3K0c//oWIhvuGBjQuJ5cq4LHBSQGDFq6XHy/g5wBnyofn7wD0ypWtLQ9mUzKEgQmU308BgJ6gHBC0ly32+0iCALZ6l4nFAASOLLZLIrFIhYWFrC0tITl5WXMzc0hn8/DdV1ZbqA/x+9aUeT95zn0135BpS+qPGoVk+/Tr5OM7HU+rURqxVKXTF8t2ZEcdDod1Go1NBoNdLvdqZL1WddykOveC9F26T6PKq6z3r9fkHhpTw4qoSRMurz8ZpED/U8GiYm+Rq1e6fky69rvBtCLhnNcl/BzjLOv9NgmQdDEi9UDnHdc9sT5dz39y/HBNmkycjfeL4PBYDiKMI5vHN84vnH8G4Vx/IPhbuP4Vvl3xEA1qFgsIpPJYHNzE/V6fcrE9iiDT9uZILmzTb1e37ffSTy+s9sUd/7yfR+lUgme58nkZtALwxDD4VB8ESqVCvL5PBKJBJrNpkz0MAxRrVaRTqeRy+VEFRwMBtje3kaj0cALL7yAer2OtbW1qeDBIJHJZJBOp3Hvvfdibm4OL3/5y3HmzBksLy+jUqnIrkuc4Ez8vCYmVRKYyWSCIAjk2MB0CbAmE1yiwIQO7JYt8zVdGp7JZOD7viR3Bp5kMgnHcURNpNLB82giwYCpVTV+bjQaiXeBXqpAxTKZTEqfP/vss/jSl76E9fV18UHZaxzMSqBXIxCapLCtur26D9lPvD9R4jeZ7HgzbG5uAsA11TMe0/f9KYPqVquFTqcjx9d9p5d+3AjYx57nIZ/Pw3GcKYJA8DpJsgeDwV1JDuiFc/nyZTiOg5MnT6JYLAKA/POgiS+wO3by+TxSqRTK5TKAHZW81WrJWGf/c65f785gJNL8x4Nxgbv5HfXcYDAYDMcdxvGN4xvHN45vHP/24m7j+Pbw74iBwYkqAneY2q9HxmEGAw7LzumroBWK/R5Dq4pMmjxOdPtsBj1u782SXpbT83M0ydU+F+PxGEEQyFbt7XYbYRhOLdPgF5VGLjc4efIkzpw5g1KpJEsUqPTyXkZ9BXiNVDTpG8HgRHBpQNSYVpf6RxVGfR6tEvJrlioVVT21d8VeClq0fJnn4+tsU7/fR7PZRL1ex9bWlgTTm6X87fX3Wdeor0OrtdH30S8GwDXHK49HBYd9EFVStafIXuee1fZrvY9zjeeedRx9/r3u590AxoBut4tGoyFLlTg2omq8Jqic0/zHAIDM3dFoJISMMf16DZf1Pw5RInutcWMwGAyGOw/j+Ps7hnF84/i6XQf5u3F84/hR3G0c3x7+HSEkk0nk83n5AiAeFMdhV0cqFVTner0e6vU6giDY96DmZKDXxnA4FHNeql2JRELUwHQ6jUqlgkqlglKpJP4h3W4XzWZTSAqJQSwWQ7vdxnA4RLvdRrPZxDe+8Q3UajVcvHhRvCrG4/FUEk4mk3jggQcwPz+P7/zO78S5c+ewtLQkO3kxMGvjW5YKa7KjlzWwf+LxOLLZrAQX/m08HotnARVKz/OEMAEQ9TQWi4nnii7b18sCSEaolmrVczKZiGJEYqXJBdtMbxcGv0QiMWV6TALY6/Vw/vx5/N//+39x/vx5bGxsTPmKEHslwv2OF0169iq5Z1LkcaNtiJ6TSXyvdkbPwXLzqCLHY+gyc00a+F0ned5X3seoshi9dhJk/U8F7x0NahuNhpjgRknS3QL+48WYUCwWEYYhXNeV2Mtd7BhjOFdJ+AqFAsbjMXK5nJDe8XiMUqmEVColajuXP13PwzrOMc5b3/fFM+qo/+NoMBgMxxnG8a8N4/jG8aM/Xw3G8Y3j7wd3G8e3h39HCExsjuOIUaw2Az7qYHCjosdrY6nsfsBkpNVArQT6vo9MJoN+v49+v49MJiNbeHPXLyYKPeE5qZi0qBDQq4IEhuW8OjFyx59yuYz5+XksLy/jxIkTKBQK8Dxvqixdl5vzib4uT9dl9jT61OqeTk66zF0nF60aMBnxvDrhaCWKYGLn2JtVsj4ej6/YWYrH1EqXbqdeFsCg2Gg0sLGxgVqtNnPJy9WSrT6nhk7w/D2qmMz6OfraXvPtaipjtL08DpOz9lfhsXR7OT9isdgViVyTAwBTfazPF21HdEmEbivvpSaM0fMdh7izXzAmcJ5HPYq0ShhV2LXPENVBkmuOf8Y9TaYPqoBros5/JjRRsAeABoPBcDhhHP/aMI5vHF/DOP70+aLtMI6/f9xNHN8e/h0hZDIZnDp1CouLi/A8D2EYSnI6Dv/UUYFj0guCAM1mc9/bY1NhchwHy8vLyGazMonphzEej5FOp+WY6XQapVIJ2WxWJhHLcbPZ7FRgjMd3doza3t5Gu93Giy++iEajgRdffBFBEMjSDGA3wCaTSZw7dw5zc3N45JFHsLS0hFOnTqFcLot6xmRIAkHSwonNZKFJAQMLzZKpRDBYaTLAduikQeUR2EkO3HWK5HM83vGlSKfTcF0XwG7JMf08wjAUFRDYJVBsJ6+Br+vERcVK3zsGyrW1NaytreGrX/0qvvGNb6DT6chuWloVY/LSCTOq3mnlkveFfT6Z7O6wppfUzFLcou09KDmIvq5JF0kPz8WlKAzmmmA6jiPjWZfqRwke+3zWvNGEQ3tFcHmA3iFsNBqh3W7LWOR40P16HGLPfsG4VKvVsL6+juFwiFwuN7W0IkrmOTZzuRwmkwnm5+cBQPqVcy+bzQKAxID9LoPSmEx2dmrb2tpCKpWC53kAIHObc95gMBgMhwvG8a/9eeP4xvH5d+P4xvFvNu4Wjm8P/44QWC7v+74MtuO0ExifjAMQpWS/a+MZVFlGT6WPE4wJnkEX2AnOyWQSruvKxGFiBSDr+LVqMh6PhYxtbW2hXq+j1WrNLJlmIJ2fn8fS0hIWFhYwNzcnyqRWzfRTfK0Y6SDDIKyTof6a5euhVUN9LgZ1+oZoxZFJml4jWsHTyYAEZJaqRhKhryXqORG9PpKORqOBtbU1VKtV1Ot1ISK8z/p+kzil0+kp/wOqXdGlMrof+Duv8VpKzCxVbT+IHjfaVxxj7B893nV7SQAnk4mQMn0Nuk/3IgVRaPKolWwSEvalNosmgb7bVEEAU3Gk0+nIP2gcf1HCqO8NKxUYm/gPCucvl/ywn6/HE4RtJJEmqSchNxgMBsPhhHH8vWEc3zi+cXzj+LcadwvHt4d/RwBMeI7joFAoIJvNotPpoNFooN1uT6lRRxGcDMViEXNzc6JE0LPjWgGO/ZNKpVAoFGRnJcdxUCqVpHyXnhNBEGBubg7FYlESNgMwkxONe3UCbLfb6Pf7qNfrqNfruHz5sihWumSau2W97GUvw/z8PL7ru74Lp06dmvIICIIA2WxWvEaoxKRSKeRyOQC75fIkAaPRCN1uV5QZLjOgyscgPplM4LqulDDrcnN+bjKZiMLEXcu63a60g+SHbe73+wiCYEq57fV6khzoPcA+5H3RiY3fScRIaKlivPjii1hdXcXXvvY1fO1rX8P6+jra7fbUsgGtWjmOg2KxiHw+jzNnzsBxHPi+j+FwiPPnz6PZbOLJJ59Eu92WfomWyUdJDxFVERngNanaT2LUZI9tiM7VWYRB339+0ShWe3zopSr6M1oJnYUoISCJ5bF4fa7rolgsSkk7fXJisZ3d5e42kBjUajU8//zzGI/HWFlZucLAXP+DQGJAtf3EiRPIZrNotVpoNpvwPA+JREJ2IeS80GP/IARME/cwDBGP7+yMOJlM7sp7ZjAYDIcZxvGN4xvHN45vHP/O427h+Pbw7wiAg4sJJ5lMSkl3v98/8qpgPB6XQO/7vpj36rX2+zkG+4d9pPvLdd0p41PHcZDL5ZDP5+H7viQGqkj8LFUblk6HYTi18xe3pdcl3gyi3O3rvvvuw8mTJ9FqtUSV5D3jvaW6xr6gySh3lWLZ+mAwkCf8nPCj0QhBEEiwj8Vi4oVCRY1JWZeXJxIJUU2pDrquKwlQl/ID07uLRVU0ljZrzFLPeJ80ERsMBgjDEPV6HdVqFaurqzh//rwQMU0uouXx5XIZpVIJ586dg+d5KJfL6PV6GAwGU8scogF2lkI6a5zNUjSjqs+s16PXrEnIXoSC/Rg9N/spatw7SzXe7z8I0etlv+q26X9I6GFBRZLj8m4D+43jtVwuTxlba/UtqkCT0OZyOYzHY/ECogcIyYXrugiCQJTf64ntmhwwHhkMBoPh8ME4vnF84/jG8Y3j33ncLRzfHv4dETBpcI3+X/3VX6HRaKDb7R7p9fixWAzZbFbUvFQqJU+vqXTt5xi6LJ6gkpJIJGStfT6fRzwex/LyMubm5rC4uCi7gJVKJXS7XXS7XSECvV4P7XYbrVZLdl17/vnn0Wq1ZEcwff5UKoWzZ8+iVCrhoYcewsrKCrLZrKhwVAa4GxaXHfB8bDd39GIgYtk4S+C1z4cua+frVO6oDnKZgzaO1kGL5Iafoz+Bbgf7lv1DEsWEpJOLXgpA8sHzRRMxDX+/+tWv4plnnsELL7wwc3c7BjuOdy6RmZ+fx4MPPohcLgff9xEEAdbX10Ud5RzRCZQ/X6u0XZfjkxDtRSL2WlKgf9+LEOifo4ojzxkEgRhAa5XzehMH5wfVLCYm+tSk0+kpRZ1jo9lsTrXrbgSXrtTrdTQaDem/ZDIJz/NkLgC7u7JxnjL5z83NIZPJyH1lxUClUhHD93Q6LV5DB+1rVgvwH6GDLmUxGAwGw+2BcfyrH8M4vnF84/j7h3H8G8Nx5/j28O8IQJeWMlCvra2h0WgcaUWQ15VOp2V9PBMclZ39HoPKWhScnCRULMMnGWAyWVxcxMmTJ0VtbbfbqNfrYrpKw9YgCFCtVhEEgRii6rLxTCaDubk5LCwsYHl5GYuLi6KmsFyYwZZKDwO9JhlRrxAmdu2/ocvUeX6t1pFIMgnwfPocPL5OMvw7gx3Hl/aH0Iotz8dkxd3UeGy+X79OTCYTNJtNrK+v49KlSzh//jyq1aoEwiiJ0cmIiczzPCwuLspSkFarJT/zGrQyGMVeiX7WGIu2Rf9+NbVPf5+Fa/2N94dzYi8Ssl/oe0qyycRGck5z7TAMxRy41Wpd0a67EdwJkIbsVK/pR6THCL84jrj8wvd9TCYTiXUcY57nIZlMotvtyj8QTPAH6W/GjetVFg0Gg8Fw62Ec/9rHMI5vHN84/v5hHP/GcNw5vj38OwLgk2SWcU8mE1GvjrIiSCXNcRzZdWt7exvNZhO9Xm9mebNOLDqBFYtFedruOA5c1xVFjMlqMpmIn8rKygoWFhZw+vRpLC8vo1AooFgsShJrtVpwHAebm5vY3NzEYDBAp9NBEARi/qvL6B3HwenTp1EsFvHoo49ibm4Op06dQqFQgOM4U0mYQZgBgX/TaiHfy2UJTAzRMnxglwDQxFcHAW2urBN4Op2eMh7WpsJUi0hC6DfDtpKgsrSZaib9Qfg+KhE8FxVDEqFGo4EgCPDUU0/hqaeewrPPPovLly/PHNfR69akpdfrYX19HdVqVTwW/uIv/gJbW1totVrSn9rY+FrJWhMBvo8kLtrH+1H9ol+zoO/p1aBV1/28N3oOYFfl9H0fxWJRlnNwPmmVmLvr+b6Pdrt9zfNci2Tx+1GOXfTmqdfruHDhAgDg9OnTiMViU/NCE27+7rouEomE7Ay2ubkpZuIkY8ViEfF4HLlcDmtra0IUut0ugP0TQs61u3UJh8FgMBx2GMffhXF84/jG8Y3j32kcd45vD/+OAPgkmV80rL2eJ8WHCVQk6O3A0nuWyOpAqZUvQhMDBq9UKiXKBo12mQgBIJvNIpfLoVwuY35+HsvLyzh9+jQymYysmSeRGI1G6HQ68nR9MBig2+1OKYL0pvA8D2fOnMHc3BwefPBBOb7jOJJwo6XB9BFgSTaDCBU3KjF8TS8FiPYJfS/Yb0zqTMZa3dN9p4mBToZMHHo3NnoL8H1UWnldVC65PECrTVRnNckJggCNRgOrq6t49tlnsba2hnq9PjWm90o4WtWkOetkMsGFCxdQr9fxwgsvoNlsSsCNHutq4PXpscc26yUJUVwt4evjXAv7USj587WON4sY8PoSiQRc10U2m5X7w3HBOKN9eriD3V7nuBY50Or5ftt/WMExxR0Bc7kcwjCUJT8krJyLk8lE5iZJvOu6Ekf4N5qi06Mok8mI7xMT/EEJlVaTDQaDwXC4YBzfOL5xfOP4bJtx/DuP487x7eHfEYBWBYHdUs+jTAoAiOktlwIMh0O02+09fUCirzHAURX0PE921RmPx+JbAQC5XA6JREJUwYWFBZw6dQrlchmZTEbUM52cORkTiZ1duGq12tSuUvQZOX36NObm5vAt3/ItmJubw5kzZ5DNZkWFymazSCaTsrxAL33QKhUTPJU13mcqUvp9TIq6FDmZTCIIAgAQI1ya+9LLgn4SsVhM/EWoPEb7WicyktNZSwl0qTOw4xdCkhL1aAEgZdTPP/88VldX8eKLL6JWq11V5daEiAGy1Wrh4sWL2N7elvuysbGBMAyxvr6OXq8nyy+i1xUdR1EiElUN90sqouB4mnWs/YzxaDsPmkyjhJo/M/nzi/eIqm8ymZS+Ivmm0lssFjGZTNBoNK7whZkFkk6O7f3s7nfYwTnZ7XaxsbEBz/NQq9UQi8VQKpWmluNQASU51/NF777Gv3MJAP18KpWK/LNDtTEMwwO1lcq9wWAwGA4XjOPvwDi+cXz+bBx//+c3jn/zcdw5vj38OwLgINNbTOuAc1Shd+qiasY18Bo64MwK6olEAvl8XogB1TMdgIrFIrLZrPiBlMtlLC0tIZfLifkpj6/9OTihR6ORGABrYsAdv5aXl/GSl7wEc3NzWFpaQjKZRKvVEmWFT/fpi0G1j+oBy+gZkJkI2ZbodWvFLpFIwPf9KfLAc3A5AlVO7lzG6yTppPJH6GTGYBZdNqCJKY+jCRlJTdQHpN/vIwgCXLp0Cc8++yzW19fRaDQQhuEVymW0DWwbCQ77bW1tDcPhEPV6/Qql8mrzZJaipc+517g7CKK+IdeDvUr79wPdd/zO+xglBnyPVglJ+IAdk+lCoYB+vy9JLargR9tNBZI+GUf9HxpiMtnZEWx7exvFYhHNZhPpdBphGIp5Mq+X/aCvm2a/AKbGKP8pIRErFArIZDLo9/tSpXBQYmCVfwaDwXA4YRzfOL5xfOP4Gsbx7zyOM8e3h39HBJys3FWKprVHkRxQefB9H5VKBYlEQjw2BoOBBPW9oFWNbDYL13WRSqUkAVE5obrHSek4DhYXF1EsFlGpVMSAeFbSqtVq2NzcFH8S3T4mu3K5jLm5ObzkJS+R47K8Wisx/ByTmS7rJQmIlsHrQE3vCyoCDDD6s51OR97La6d5sQ5ITAT0W4mW7LMfdZv0+XhcXh9JK7BrfBpNqAxmJLbcVW19fR0XL15Eo9EQrwS9dIB9ER0Luh9IZoIgmOrbqKoZhb5HVEij/jPREvdZBO0gmEV6DvLZ/XxmlqoZVT05F6hc0+slFotJP5Is8HNBECAIAmxtbYlJNpfbRPuEn9Oxib/rsR1dXnEUyQKVwXa7jWq1inh8Z5dBAHBdV4gBgClCTSI9HA7FT4iEljGJ/zSRYJCQ0UuI8W2/OIr9azAYDHcDjOPvwji+cXzj+LNhHP/24rhyfHv4d0TAp/Oe52E4HAoxOIqTicnI932Uy2V0Oh20221JoNciOyQG3Kre87ypHZ84GbWPBifY4uIilpeXMT8/LwqiBkvN6/U6Njc3Ua/X0Ww2EQTBFcSgUqlgeXkZDzzwAObn5+XpvVZUAMgTfAZRKlX8u07CumSbiY1tJ2FiMNeJOAgCGSM60TFwkDSxfUzEvBfsPwZuXbqtEwsVBgY2HpuJM5pcSVpGo5EEyk6nI8Tg0qVLaLfbkpi4dCE6rvXvmpywjbwvVyMD0fFDgqqD917nvNnz7HqOp+/B9Z4rasDNa+c4CYJgKlkxkXW7XVSrVWxvb6PRaKDdbs9UXLX6pdsbJQYcoxpHUS1kJUOr1UK1WkUqlUIQBFfMJY453V+ZTEbmheM4aDab6Pf7QggAyNzncibGD753v2T1qPWrwWAw3E0wjr8L4/jG8Y3jX9+5jOPfXBxXjm8P/44A0uk0KpUKisXiVNI7ihMJ2B3s3IWISuC1BrkO6Cx3r1QqyGazUztbMcFMJhOZVJ7nIZvNiiLIUvmo8tPv99FsNkUJ3NzcxAsvvIC1tTW0Wi0Mh0Pk83mUSiU88MADWF5extLSkuxExlJ/Xqe+X0zmPC+TMq+Nr3OJRLRdWhnSxqI0hwZ2FVeek2ajPGY+n0cmk5FzMyFQtdQ7bMViMVEoNBEdj8fiPwJAEoS+TgCSCNgnJBjNZhPb29uydICf0/3Cz2vCNCtRz1IAo/c0Oob4up4/d3IeaSX7am3RSvNe79HkUr/G1zk+qAR2Oh3x4qH6NJns7FbF3aeazSZqtZqQgk6nI+RwlloZJWecD1qFjl4zgKlEd5TiGonT2toaEokE6vU6YrEY5ufnp1R3vRSH1xeP7+z21e/3Zacvevzo3fjo7QPs/KMRBIEQ7Ki6ajAYDIajA+P4OzCObxxf9wnfYxx/F8bxbz+OI8e3h39HAFSzyuUygN3y5OhT9aMAJgrHcZDP5zE3Nzf1hPtqA5y+FonEzu5bNPXlU3WdTJm0qBjmcjl4nje1Q1c0eHKC1+t1+bp8+TKefPJJ1Ot1NBoNIWlLS0t42ctehqWlJZw6dUrOQ6WKymEqlZKlG1TpGBi1xwuDpiY/DOS9Xg/tdntKLWRJPNVCbs+uPRpGo5EYtjI4aePjZDIpBIPjiWRK9zeJBM16aSIcNVDm9fE4NDh1HEfa1O/30Wg0sLm5KWpglBDqpBFN9tHkOUsJnPV5fQySNf2eaIK7nYlpLyXtau+/2t+j16Lfz0RFQ+Vmsyn3gEorj5FKpdDr9bC9vY1qtYrNzU00m020222Mx2OZb3upgNHfSfi4ExbHqsZBlK7DAF5bp9PBxYsXAQBbW1tCuvlPEEm6JrTAjkpL8+DNzU0AkHJ/bcDMGJbNZqf8Qjjv7eGfwWAwHE0Yx9+BcXzj+MbxjeMfJhxXjm8P/44A+FQYAJrNJhqNxpGaPAQDYC6XQ6lUQiqVkifhNMS9GphsmCC5O04mkxGVj2SJwadYLMJ1XSwsLMhuYZxwGtxdp9PpyNP2zc1N2f2L6/A9z8OpU6ewtLSEcrmMfD4/5ZvAQKGf/DMpU62jiS8NexmM+TceQwcVYNcUmktC2AfR5KeVQR6br7GN/LtWFCeTyVSipurI99E0WAdvqhcApnYhI/FhGfR4PJaksrq6iosXL+5ZVs7+04ogry2avKNJ8mqqmT6W7qO9ErImJdeaa7MUu4PMT51Mr5X0bxSTyUR8crhcJZlMYjQaiUEt1cJGoyEeIY7jYDgcolQqyW5VHC8cI3tdu54T3OUqWjZPFX3WVvfXUkPvNEi06A1Cc+6oQq4rAehjlMvlMB6P4XmeKK6dTgeO48j855yNxWLIZrMoFAoYDofiU3QQXxCDwWAwHB4Yx9+BcXzj+MbxjeMfRhw3jm8P/44AqKzEYjExqGWp92GdKLPAiVEqlXDq1CkxAWb5/bWIARMn/T00KaC3AQNdLpeD4zhYXl6G7/s4ffo0isUiisXiFQbAAEQNrNVqqNfrqFaruHDhAtbW1lCr1WRHr1KphIceeggLCws4efIkfN+/QoFioORkzWaz4uUCANVqFd1uF67rTiVsBheW5/PvWkFwHGcqIOsdxTQp0Mdl32ujXb6XJIMBi0GGCp/rurKkgCXJVBn5OtVQ9oHrulM7P/X7fQwGA2xvb2NzcxNPP/00nn/+edRqtZll4NofRSfn/ZTEa5J1tXGolVedzEhIoiTkWudkYuMx2Ib9zM9rkYFrnX8/741eT7/fF9WKY8lxHFHYWfrPZQCxWExIted56Ha7snsbd33TSXAWOB9ISkjQtdKvlysQ0ft00L64HRiNRuJrVK/X4bouBoOBEC5g2sdImy13u12k02mUSiWEYYj19XW02214nieKoO4j/jMCAO12G4lEQhR7g8FgMBwtGMffgXF84/jG8fcH4/i3F8eN49vDv0MOTiAOBpbwHkWfJ52wqPDNSgL7OQ632XZdV0w1deCj4sZgl8/nUSgUpnYLAyBBjeX/1WoVjUZDlgBQuUqlUvB9H3Nzc1hZWUGlUkEul5NzDwYDUTl4b6hy8Fp5v3QS0Ttg8YukYjwei1cKCREDOrAbjIDdna2A6cRPY1H2da/Xm+on+nBoM2CtXtCclyXgyWRSjslxyPvJYKWvBdghXUEQYHNzE+vr66IO6hJpTWrYZ2ynVj+pms5aDqPJD/thr5/1vdBJR48N/V3PN00+dF/RPJekXS87uBpmqZsHxUFUMz0etSn0eLxj3EzCTY+dXC4n94aKNr1xSPw4LnU/XastmtBqTxhNzDhXuIyBY38/CurtBMcUl++QJIzHY1lSw8oOXiO/qPzRG4lxZzAYIAxDWX7D643H4xLTSqUSYrGYVIocxWoRg8FguFthHH/2cYzjG8ePwji+cfw7hePG8e3h3yFHLBYTP5DhcIjt7e2pMtyjBAZ4YHc3J5ak72eSM1AkEglks1n4vi/JnmXL/Hs6nYbruvB9H/l8XnxASAyIMAwRhiEuXryIZ555Bo1GA7VaDWtra1hfX0ej0UCv10M2m8WpU6dw9uxZPPTQQygUCpibmxMlkh4ZDJ6TyUQSKAMnz0tiMxrtbCGeTCbFG4SJmGpZp9OZWipAnwEmyVarhUQigVwuJ14hWkVkuXG9Xke/30en0xFyEIvFpN1MBP1+fyoI8TwMTvT20G3neXlvSTJSqRTG47H06XPPPYfV1VVRWnmNBBMskxDJRSqVguM4GAwGslOVHjO6XJrBV/9Nq378zvnDtkbJqS7dZj/xPHoJiB5vuVwOk8mO2XE0SV4L1xvMNZHjvd8PEaEPDLDrC0P1aTAYIJ/PI5vNim8P7z9L/+v1OgDIEhWtLuplLVdrM/uGpJ73kMmfY4vLFLhsR1/nYfFEYjzr9XrY2tpCKpXCxsaGJG/+I8O5Auz4flCNTafTOHHiBDzPw8bGBqrVqvgIafKZSCTgui7K5bKMz1QqJZUi3W4XwOFTTQ0Gg8FwJYzj78I4vnF84/jTMI5vHP9WcHx7+HeIwdJ3KgaDwUC2pT9qpADYvR5gN7EwMe/naTafrFPtS6fTV3xGq1nRL10iz88x2TB5c+cjfvX7fVFl6QPieZ486dfH4xevUatbLHWmuqaTEZUWLgHgdUTVKU0QaKTKIMlzRA2JGYS5DILn06oLVQq925g+J+8Nk50O7FrVjRITLm1otVpoNBrY3t7G1taW7ACmkzATLEkSy8P5OtvJJQi+78v1kyDphHEt1YhJh8SAJe1RTwvdBn6OyzA0OeHv0T651dD3cT9gm/TY08pur9cTPw5N0nRiYpLOZrOYTCYIw1DK0mlqrZVtfd5ZbdnrZ014tMn0YVMECbaTu+aFYSjLYtiXfJ9uP/uVRr/aByQMQ/R6vSmVFthVpEnqc7kcut2ukLPDQpgMBoPBMBvG8a/8vHF84/jG8XdhHP/w4DhxfHv4d4hB9YjKUrvdxvnz51Gv14+kwTsTOrDzRLxWq6FWq4nSc7WJzkngeR5yuRwKhQJ835en8XqS6eSSyWTkabxOtlQU6HlAU81GoyGK4Pr6uvgfrKys4NWvfjXK5fKUp4ie5AywTPBMEDwvy/s9z0M6nUYYhkL2Op0OyuUyUqmUJFkGfN5rBgq2KZHY2XJcXzt9Y6iSMqF5nofhcCgkiEFKl/dz6QPJhVY4R6MRgiCQ5Ez1hwmRr+uESbK1traGtbU1PPfcc7h48SIajYZ8JuoHQb+DfD4v5yVxAnZ2xfM8D4uLi3IfgyDAxYsXEYYhWq3WTJKpf4/FYkIsaVgchuEV3iRR4kJ1MpfLYTgcinErPTEajYa0WZOLW4UouduPSsaEQsWSihwVUu4sRbWd/5hoUkbS1uv14LouYrEYWq0Wer3elDdIEART1Qs64Wvo+aP/rseaXmYx6736WHcC7Pt+v49mswnXddFoNCQWkSAAmCKP4/FYdjFkXGFsoxEz/6nJ5/Oy7IT3mfNlZWUF9XpdYoo9/DMYDIbDDeP4uzCObxwfMI6vYRzfOP6t4vj28O8Qg34OTGwAxFj1sD0R3w9Yps9EwIkUNYPdC1o54nb2TDBMwHp3rahiohWtIAgQhqGQk2azKTuAcfev0WiEbDaLcrmMUqmEQqEAz/NkojJI8Um9Dlj8PZogNDHRQY2TnVux85hEVI3TZcK6nJrjhMGH59SBPdqnJAk68OpgzeNEr4/tj6pgfF+v10MQBNja2sLW1hba7bYowNFr0/3FcaH/xrY7jiPLPHgOerFoD5JoctcKK/tq1pcG5182m4XneVOl8WEYyr3IZrPST/Rc0WNZl6/rPpo13kk294trHS8KTQyibZxFqNhfWq1mH3BZi+d5srREt0WrYPv5Pqsf9JjUBOhqxO9GEB0H+yV4eryRHDFWcxdBPff1Z/T8mkwmSKVSyGaz4ifCpQbaC4Wf4X1wXVcqGNhXRzFHGAwGw90C4/jTMI5vHN84/jSM42PPY1wPjOPvwB7+HWKk02kUi0Xk83l5Es8S0aNGDGKxGPL5PCqVipCD8XgsfhfXWuLAoEBlMZ/PI5FIyC5FrusinU7L7jksT2fyZIkyJ8zGxgY2NjZw6dIlbG5uYnNzE9VqFS+++CKeeuopdDodTCYT5HI5PPTQQ7j//vtx6tQpIWqTyURISTabBQAppWa5vlYwdKDUREgvVRgMBuh2u2JgDOyWGWslj0EmkdjdbYvXycDAgMTj02+EKiP7nKXxbJf2G9HK0WSya1isCRqVSrZTe52sra2hXq/jySefxOrqqvirUIliu6n8MeF0Oh3xGqEHSTable3Ps9ksSqWSKMvs8/F4LObMuuRdkzDuPsUEw37TZAHYNa4ulUo4efIk7rnnHrziFa9Ar9dDo9FAtVrFU089BWBHqaTiSj8IElUAopLRWJrQJfOauPC+XwuzSMFen9NEL5o0oslJL3XhvWb/kBik02n4vi/jKpVKYWtrC71eTz6XSqXkuJpwzprrOhlrwqnbzjGnKwiiBPBGocmlbvd+YhT7kcsCgiCQncH6/b7ELJ24SW5jsZgYKudyOczPz6PRaGA4HKLb7WIymcDzPPmHhP9AMNZxHm9tbSEIAtkZ7KjlCYPBYLhbYBx/+vPG8Y3jG8ffhXF84/i3iuPbw79DDKpD+onyUQSDCxU7YDdY7mdSM2BzzTwnQzweF/WIpfA8B5NCt9uVUmetojUaDTQaDXS7XfEBabVaEtxZTs9k5Pv+1G5ZbBdwpeLH69Ll0ACmzq+DMyd2LBYTZYmBiF+8Xp2c2SdUeXSS4RePxeNr5ZBt0n4POknw79HP6JJmHeR0UOSORtxRjd4q0USoAzs/z+TERKSTfK/XE4I8mewYLlOZIunhEgJ9bPYfl2NQVSY4HrW6yARI4+lcLifLJ0hUYrEYstmsfDaVSknbtALL36mCj8fjfS+F0Zilhh2ETOz1vug8ZH9rbwmOM/6s+4jkQPc3P68/c7U28p6TzM4iEbfyHyLdj9HlQwfpW5Lybrcr8YX/COm5OktNZ7Kn5xDJN31aSPY5V/lZVkS4rivznfPJYDAYDIcPxvF3P28c3zi+cXzj+Mbxbw/Ht4d/hxR64jEoM1AeNZLAoMGdu7jNNdXN/RCDRCIBz/Nw4sQJ5HI5ZLNZDAYDNJtNxGIx2QnL931kMhlRTy9duoRqtSq7GzFpr66uYnt7W0w7t7a2cOHCBWxubqLb7SIej8P3fVQqFdx7771YXl6WAMhkxfvCJ/RUU3hdPBc/47quTPTxeNc8Vpvb8lj8mf4fuVxuSpXhd5qGcjkBsOsjM5lMxB8jFouJsqxVH22Ky7YHQSDqK0vxqaoy8DFJU5HlZ8MwxMbGhnh01Ot1PP/88/IaEyj7UJd805ODxqd8HwkevVscx0Gz2RSDZvpz8Ny8Bi4tmEwmohqfOnUKhUJBlPa1tTW0Wi1RILX6nEqlUCwWMT8/j2KxKB4sNDmen59HMpmU5Qn0xGB/UDXL5XIAgEuXLqHT6chubGtra7LduyZjmmjqr71UnoMkrr1IhF6WwXvZarVEueQY4TiOxWJTS5Wy2Szy+bwQM3rL8PP6GvdS13ScoJ9Gq9WSds9S52apibOuL3rdehkMf9cEl7GX74/uWjcLnBuMSaurq+j3+1hZWQEAWU40GAxk/kcJdjKZFF8g7pjXbrfRbDbhOI740ZAQc07yn5gTJ06g0WjIGJu1zMNgMBgMdxbG8XdhHN84vnF84/jG8W8fx7eHf4cUHMh6wB7Ff+I42JmUAMh23tdSRKLHiKpnTFB8j+4zBhHuOqV3T2MS4qSMxWKShBnAuCafahAnolb0ospFVL3VHgq65FyX2fNzLJ9mewgdyDT54Hn1+GB5Ps/B92vVLUoutYozmUyErGhFTYO/z1JrSBZqtRparRaq1Srq9boYEEeTzywlShMF3mNeg1ZLM5mMEJd4PI5KpYJOpyPmqVxGoc/BZMYlJY7jyLbpWvmiCW4mkxFCQYLCPkwkEmLUzXtHMua6riiW9DCJxWLwfV8UR+6Qxjmwl7oXJQe3GppkDgYDJJNJ9Ho9SZJUfKPKbTKZhOu60kckB/qzennGrGtk35Ag8HdNiPTYJHTfXUtFnfWZWe/V4/Bqx5l1XKrS/KcjDEOk02mpNuA4JkHg9VOljnrbkJSHYYh2uz1FuPTY4T3o9XqyREar6gaDwWA4HDCOf+UxjOMbxzeOf2thHH+3H+5mjm8P/w4pOPGojnCyHbVKDip2VBKCIJjaDn4vhUB/ngOeE6Lf78ta+TAMp0gDJyb7KwgCIQI6mUSf/A+HQ0lig8EApVIJp0+flq9MJoN2uy1tSSQSQhaoAmYymakSe60gApgiRixt5/v0PdbLGqKqMIMqPQK0AetoNML58+cB7Kg0VFIBiKGoJi+6bSRvDPpU1PT9YeJmUGJSYJCjavf1r38dW1tbeOaZZ9DpdFCr1SRJa6JytaA9Go3Q7XYRBIG8rkkBr4VeIadPn0YQBMhkMuI5EgSB7JrHvuf9W15eRrFYRDabRbPZxNbWFhqNhpyf5CCfz8PzPEwmE2xvb0sfJBIJ5PN5AJi6f7pUm0ojx8Hi4qLMXxJa13VRrVbR6XRkPGgCxKDPe0ZiovuKYyP62tXmVDQp8vd+v49OpyNt1uOG88ZxnCmyS6VwcXFR2jwYDIR4US3WSVMnK/YfSZjruuKJw/NHKwhmXXeURHEc7UVwo0RAg/90XGusRjEajSQm1Wo1xONxVKtV9Pt9UeY5ZzknuNyIBJTvJ1llnOM4icY8kipNYsvlsryXJM1gMBgMhwPG8Xc/bxzfOD5gHB8wjm8c//ZwfHv4d4jBwEdz1WjAOOxg0KCnAicrg8O1SmwJqg4MsgBEteDf6WfB/uHfu92uqHyc/Ax6VBe5XT0nYzy+swMUjZhZCh5VNPZSyDQ50Iou38f7pwN/9PgMaDqI6yDFY0UDfJQ4kggwMESDHMcVjYKjiqB+r1ZBtXJHNbLVaqHVaqFer6Ner6PdbqPT6Ugi0Lja+NXH15+johKPx8UbgYmSRqm+74tCp3cTY3Dk0gLurET1l8sb2Gccb1yeAEAURPaT9hPh6xyH7C/2MQA5JtvkeR7CMJw6LoCpsnod0GcpWbMQVd2if9M/azUtOs44j7Qiynmi5yKXuegd0RKJhBgzc9kKkztNuQnd31HfGpbQ71UZMYsg6N9nKa37wUEJgYZW8Uhu9XXo9+n2cj7pnb/0XGC800qjJgY8DuMt57WOJwaDwWA4HDCOvwPj+Mbx+bpxfOP4Gsbxbw3Ht4d/hxie5+H++++H4zjo9XpiLMkBctjBiV0ul1Eul6fK+KOK07WO47ou8vk8SqUShsMh1tfXRe3hrkS6JHlrawthGKLZbEpgpi8Dg1UqlUKj0cDGxgbW19dRr9cxmeyUci8vL+PRRx/F6dOnUalUJNEzWE4mEynx1UmXE5PvpbrFBKzLfhlkqXhygvd6PTSbTaTTaVGFGaipLmhFRgcwelGwpDidTksi08mGXhtUbRiUuVRClymz7J5to4kt1Rr6FXzjG9/A9vY2nn32WbRaLWxvb0vy1kltr+TGayDZ0O/VpKTf76PVaqHZbKJer4vSl06ncfLkSfi+j2q1KuodAARBgDAM8eSTT8qW6QsLC1hYWEA+nxeFz3VdZDIZaRPnXRiGWF9fRywWE2LJHeG0aS4JA1/nVzweRy6XEwUMAFZWVmRMs09HoxFarRY6nY54hVwtSen+0X0Y7WP9Wa2c6Z3ReL/5fiYjfX4qgEw+JFbArqEyfV0Gg4GUwlOdp0eFXsqTzWZl+QXVWACysx+vbdYyj1nXp3/n3DloYrzef7w4Rnu9HjY3NxGGIUqlEkqlEsrlspAsto3zMBaLyf3mzoSNRkPGRSwWm/LqSafTKJVK8k8LySvbffLkSfEF0WPLYDAYDIcDxvF3j2Mc3zi+cXzj+Mbxbw/Hj1/7LQfDz/3cz11Rmvnggw/K38MwxLvf/W5UKhX4vo+3ve1tWF9fv9nNOBZIJpNT287zCfFRUQWZTLi+H9hVoQ76xJ0TiJOIAZdjTCswmnzwCTqDO9UkHcSYNEi4GOyoCLL9DFo8J+8FrzWqmBFaZeH7qWBqjwT9fh5De3dEj6XBSa+9BNgn7B8d9PXxZpWgA5g53vh+EoMwDFGr1VCr1bC9vY1arSbbkEeXsOz3nkffF40n7HvtO6EVX5Ip3QdsN1XBdruNdrstChZ3X3JdV8iBVkpZKh8EgYwXnl+rymyLbptWnDXhcRwHvu8jn8+LAp3L5eD7vrRFG+5G+0j3D8dJVOWLfkUVOC6p4HXTBJkl51GPG84vfkWTDc+h572+JySZ0fbqca2XDUSX11xNFZ01zvQ5bhVmkTAuFaJa3m63ZWcweqpwPGjvFL6n0+nIeAKmiR8VR/3PVZTcua6LbDY7pUQbDAbDjcI4/s2DcfxdGMe/8lgaxvGN4xvHN45/szj+Lfmv4KUvfSk+97nP7Z5ENewnfuIn8Du/8zv41Kc+hUKhgPe85z34/u//fvzRH/3RrWjKkUU0AXCiHjSh3ilQHeNW1olEQlS669mhRgdhbQKs19EDkGAfXUu/urqKzc1NzM3NyRbuqVQK29vbUr4eBAGKxSIKhQJKpRLm5uZkhy6qj9rPodvtIhaLiaLEMt4wDBGPx1EsFqV9VIZ0EGfwoB8Ar49qDYMoy6/3UlGZuADAcRwpxyaBohrJc2tPiWjC4OfpWaJLvFOplBiShmEoROCrX/0qms0mLly4IP4fLP+mOholIzx3FCQmuk3sA5IUrVayPRsbGwAgyjmPT3IaNVbtdDpoNptSps3jcRkJCQDf1+l00Gg05JiZTEZ2vqLqy2NRJWMfUJ2cTHY8Y0g2K5UKEomEeNBw/JDEbm1toVarYWtrC+vr61MKtJ5nvN9axdP3VveF7/tTyXlhYQGe500l+MlkglwuB8/zppaIUPEkie71eshkMpLYWq2WeNBMJhPxtHEcB8DOzmgk50yO4/EY7XYb8XhcvvN82my5UCiIasZ4sNdc0OOI455K7X7iTiy295KKWZj13vF4LOPi/Pnz2N7eFpWzXC4jnU5LfOA1bW9vyw56m5ubqNfrslyEMS6R2DGS3t7eFqWZqqomZXx/oVAAANTr9SPzD6XBYDjcMI5/4zCOPw3j+MbxjeMbxzeOf3s4/i15+JdMJrG0tHTF641GA//hP/wHfPKTn8R3fdd3AQB+/dd/HQ899BC+9KUv4dWvfvWtaM6RBJOHLiE+KqSAiCoQTO4HUQWjql9UpdLKDwB52q4TOIMlgxYDow7C+j3cbpuBKaoy0PiVr+nzM3jrhKjJAN+/lyKij8lAEFV2dL8xcUeTPT9P1ZHgufT5dXuYhBl46QHB62FQp3LB0n96gbAvoyX9GlEV9Fr3XrdNK6WTyUSUXyYVrRDqvtD3Tqtsus+45IHEgH4mVAHpGcJ2cAcwmloPBgMhUCRl7G8m7Xg8LgSCYy0W29mJjkmCx6DyphNm9P5r8kPSpPtOjx+ejzGFiSOXy8k947imIa+eb/r8epkHk3wQBLLz2SxVl+3k2ORY0MspqMLq+aZJ8n6hFcJon+i/3wiudiytnvMfiFqtJsskGGNI6ieTydRSEKqCJJXa74Nji/9IcNcvfa/5j4z+x+mghMdgMBhmwTj+jcM4/g6M4xvHN45vHN84/u3l+Lfk4d/TTz+NlZUVOI6D17zmNXjiiSdw+vRpfPnLX8ZgMMAb3/hGee+DDz6I06dP40/+5E/2JAYMRkSz2bwVzT40YEn6wsIC7rvvPvR6Pbz44ouybfhR8G6KxWKyxp8lxwCm/CH2cwxgpz+4axMAUdOSySQKhcLU6yQCtVoN3W4XtVpNdsOJx3e9DDie1tfXsba2hjAM4bouyuUyzpw5g/n5ednxqNvtIh6Py45IVDp1IAOm/SyGwyGazSZSqdSUoSwACc5UAIfDIba3t+UYDKA6GDJI8FxUKJvN5pRa1u12xcQW2DVqZYk+FdlsNjtFfADIEguWb6fTaXS7XbRaLSEIvV4PjUYDrVYLly5dQqPRQLValRLl0Wgk7deq9qz7yiAWTQT8HBMrlcwomZxMJvj6178O3/fRarXEwFmbRFNV4rXm83nxeykWi7Krm1aVSXTa7bb0bSKRQC6Xk36hCjiZTIRIMbkyuesgzeukqp1MJpHNZq9I1PwcVeLJZIJ2uy3K8ixSkEql4LrulDLJUvxyuSyqfCwWg+/74uWRyWSwsrKCXC4nSzl4v+ivQwWeY6rb7aLdbksb+v0+tre3MRgMRBUMw1DuI9VDTRY5JvnaXsuc+BrnE8f4fhM8P7vX+Nvrs/tRDUluSKb2gp57Tz75JDKZDJaWluB5HhYXF+E4jvTD5cuXZfyRbJJEcEnVZDKRZU39fh/1eh3ArtcR7zPJpe/7GA6HEg/CMLzqtRkMBsO1YBz/xmAcf/cYgHF89ptxfOP4xvGN498Ojn/TH/499thj+PjHP46XvOQluHz5Mh5//HH8tb/21/C1r30Na2trUgqpsbi4iLW1tT2P+cQTT+Dxxx+/2U09tGBAy2QyU6Wwutz3KCCZTE49kdZq3X6hBzknB7Bb+qu9Bvi6TmLai4GBiuSKpeGdTkeCn+M4Umar1R0GAaoeewUn/TPLt7UhL6GTFu8tEwOvmwEoGjz1udmne6mmhPan0PdAq1z62AwwVPmovtHjgN9Zfs/7DewQHyYpnmuWb8Sse637cZZaqvuQpsAA0Ol05Dqj10YyR8LNL9d1pWSc7yfp5LjRiYjqNscFgyzvkYZWL6NeNlSr9XVrZZakijFAE0vdj3oMOY4jy1F4D2iSrcvJ6RGRz+dlWYPnebIsgX2uiQoAWd5D8shr1P4gYRhK2/lZ7c8z63p5HH1vo2MjOgYOAq2Uzjr2jUDPw73+Dux6eLTbbfR6PXieh+FwKKbU7B+9NIm7ren7q4/LucrPz5r3JI0kxUfhH0qDwXC4YRz/xmEcfxfG8Y3jG8c3jm8c//Zy/Jv+8O/7vu/75OeXv/zleOyxx3DmzBn85//8n0UZOig+8IEP4H3ve5/83mw2cerUqRtu62EFn5g7joOzZ8/i8uXLolIcFWIQi+34Ivi+L0/FaYgZ9TS42jF0QNVl8gxUfGruui7i8ThardZUQtIEIpFISDu2trbQ6XSwvr6O7e1tuK6LXC6H+fl5nDp1CgsLC8jlcpIsOPm4I5njOJifn8dwOESj0ZhK2r7vTxEBXU7OLxp9MpDq6yOxoTLIcmn+DdgNolREGcB53a1WSwII+4GKH/t21nIBEgi2s9frodVqod/vizqay+XERLbf7+Pee+9Fr9dDvV6XtlMVDYIA3/zmN2VHNl2qrVW+vUgWf48qMHrJjO/7OHnypCR8jrHhcAjf9+H7Pubm5uC6LjzPQyaTkR3AWE6tCShVMyZHkoBOpyPXx3vCtmhPDraRvh+FQmGqNJvHZHJuNpsIw1DGEJVtXtvi4iKAnSVV29vbcj89zxM/j3K5jOFwiI2NDcRiMZRKJVFJk8mklJ1zTGnCQKV4PB6j2WyKshyPx+F5HjzPE58U7ccxmUwQBAGq1aoQRwCS0IrFIkajEer1+tSc16RgFthHVDMBTCmwUXJ7LUTfF1UWo2NtP9DLJGZBK7YcSxxPnU5HvF+08q/VQAAynj3PQzabvUKJpNH5YDBAvV6XndT0MiHGomKxKEtnDAaD4XphHP/GYRx/9xjG8Y3jA8bxAeP4xvFvH8e/5dsAFotFPPDAA3jmmWfwPd/zPVLGqJXB9fX1mf4hBJ+M323gBHYcR1Suo0QMqApykPLp936vIUoGNPQTcwY7nQiJaJBhYA+CQLbJ7na7suuS53myzICTjEGJyYbHzWQyoqhps19Odpbx8zNsI1/XhEC3lUE6qgBq5Yk/s1+YlGjgq70oeGyt9gGzgyHVBfY5r58l2VxWQTLGv/f7fTHHpU9BrVZDu93G+fPn0el0Zpb+62ucNS74d/6sVR7eA+6o5TiO9DHPxWUdhUJB2s1gTePjWX1EhZP3h/3JftcKlm4Px4ImGhxbHC/8YmKmEslj6GUIsVgMnudJvGTi4LKOSqWCbDaLxcVFSTaJRAJzc3Oi+nFZC+8fEz6XpXC8jcdj8UPRCqVWpKJjkD4gWpHkeMxmsxiPx7IkR8fwWUpdVM3V4yJ6j24E0Xmlz73fz+/nM1pN1sQAgPyDomMXFT5+jmogd2njeOJ5tTlyv9+XeMV/ZiaTiSi5UY8Wg8FguBkwjn/9MI5vHN84vnF84/jG8W83x7/lD//a7TaeffZZ/PAP/zAeffRRpFIpfP7zn8fb3vY2AMA3v/lNvPjii3jNa15zq5tyZJDJZGQXqvF4x0OAitr1lsbeTnBic1AzsfArWj49C3yizu3QWVbfarUwHo/liTnVD20mGo/HJbHzb9ydisa2VBYY/PL5PJaXl3Hy5Encc889yOVyktATicRU2X6z2ZRy7clkgnw+L0/px+OxJEHeK27lzqf2mmAAkC3OSXSCIJB7zDZ3u92p4Mhz6xJtJnO9PIJEgW3ge6ncsb/Yd/y7XoaRSqWQz+dRLpfhOA4KhcJUwKaS2Gg0pDS83+9jbW0N29vbePrpp8VrQgf5WWrNLETLnZPJJDzPQ6VSwYMPPohcLid+GZubm2i322g2mxgOh+LrsrS0BMdxEIYhJpPJFFlkspxMJpLISWi5IxiTLskBy+3ZPt4jkiL2Ga+TihZVSL5OT5darYZ8Pi8kgufnvZufn5f3kIhRDeTYZQJgf7FtAKb8aDQZpbKkd1Cj+S4TFk1+ufSGZIb3lJ4TJN6cW1tbW0LE9Zzn33l8xgTeY61+cb7yfiWTSRnTWiXeL/Qc0mNulip9MzCZ7BhWZzIZVCoVWZoCABsbG0LCGJOA6WUtiUQCvu+jVCqJws0x2Gw2Zdc1AKKY6vvL8VYqleC6Lp577rmben0Gg+HuhnH8g8M4vnF84/i7MI5vHN84/u3l+Df94d/73/9+vOUtb8GZM2ewurqKD33oQ0gkEviBH/gBFAoF/ON//I/xvve9Twb0e9/7XrzmNa+xXcAUaBSayWTkyTsNNQ87KQB2Aw/L9rWqtB9ioxWJdDo9ZVpLo1H+zXGcK0qxGUSA3YnBXaq0TwXBRJvL5VAoFFAqleTpuy4f5jkY6LS6o9VDvasSsLscQaukWu3SpCCdTouZLADpu6jvBvuR5IbHZPKneqITsSYGwLQKM+se6KSZzWYxPz+PbDaLYrF4hVo5HA4laXU6HenrWCwmah2D1bXuvf55Folg+b3neVLqzwTTbDbFNHsymcDzPLmvvE+6FJtfvA593TS21SXoTHwcf/o1lvJr1Zdt573hfdV/6/V6CIIA2Wx26t4xAXOcUzli+b3jOFIu7nnelDdHu90WdZTXovuT/cz2auKrxyMTm1bl+TP7mIa2TEqc5/xHhgmP3zUBiPYF26bnG1/jPwv0v7nRWHg1ZfJmgdcwHo/lH6VsNovRaIS1tTVR9YBdr5eoes4lKvl8HsVicUq5533jkiPOOa1w62UJBoPBcCMwjn/jMI5vHN84vnF84/jG8e8Ux7/pD/8uXryIH/iBH8DW1hbm5+fxnd/5nfjSl76E+fl5AMAv/uIvIh6P421vext6vR6+93u/F//u3/27m92MIw1OzMFggNXVVVlvf5By+jsJ7anguq6oB7rU/VqIxXZ2EiuVSsjlcuIrsrGxgWQyibm5OdnmmgE8DENsbW0hCALZcpsTYjQaIZVKyfb1LGNmYmfZtS4t194ZTDx8es/rocFqLBaTCa8TBANDIpGQsm8SByaK4XBnhy4qW2wrQRWMaoAu12eAZGCgwsjP6+TN9uhExSDDL5Ywj0YjMUnm/WRZO5OUTnJaDbx06RKazSbOnz8v90EnYp0Yoslfjw1NntgPjuMgn8/jxIkTmJubw9zcHCaTieze9dxzz4mRaiaTQblcRi6XE6WPyZymuFS6er2eqIntdlvUUN03VGG73a7cU3p2MHkDmPK/0WMM2DWG5njhNdG3odfriRk1xxEJcTweR6lUQq/XQ6fTkUSTSCTkXlGR1gbAehzQ+4NqG/0kNKnmOOR45VhhG6n4FwoFGd9cYsPr1fcwSgSoxup5pKH9b7R6x37idWhCfFBwrOt23kzwuoHd3bfCMEQ6ncbS0hKSySTa7TZqtRrq9Tp6vd7UPxqxWEw8ikqlEubn55HP51EoFOQcHNOMd4SeUySw+Xzedvo1GAw3DOP4Nw7j+MbxjeMbxzeObxz/TnH8m/7w77d+67eu+nfHcfCxj30MH/vYx272qY8NdHBmoOK6/cMOBg69gw2Vgmjgv9ox2Acs/c9kMgjDEEEQSHm7Vq0YYIIgQKvVQq1Wkz5jkiSB0LuD8TzpdFrKsVl6TGUR2Akk/F0rQQzsnIBMGAxYWg2laqPJUTwev2LXKWBX+WMAo0JM5YX9TOVI+5RMJpOpHa7YfmA36DJRa6LARKzVBr5Xf+lt69kf7N/JZIJarYbt7W2sr69LaT7bGlViomqMHh8McLpPXNeF7/sol8solUrIZrMIwxCtVgv1eh3VahXj8Rjz8/Ni/ksDYC7LYMLk91QqJb4wQRBMmdpG26YJVrfblT7XfcP3MrGSSFAhZ/9xHGgSyr6i0kYlkOOKCijVQt5nqrAcRyQ80T4mCeB40MbZmqxpc1+2Kzo36TERHddaSed5o+NL9yvfx/utlw9Ex1cmkxHix/ddb4KPxqNZ6viNgNdCgsdYQDPxXC4n/li8v1qpZsUDTdV93xdTYPYvCRTHGHNEtK+1p4vBYDBcL4zj3ziM4xvHN45vHN84Pq4YX8bxbw/Hv+Wef4aDQ0+ofr+PTqeDjY0NNJvNKybNYUMikUCxWITneVLGT08LHYSuBqpafCrueZ4EOpYtM4hRYWCpsOu6U8pEp9ORknatTGm1LpVKoVKp4MSJE1PLAXq9ngRtHbQYWPl3KkjA7g5oNOFkebgOZjogsQ2+78uyAb6Hywx43EQiAc/z5HWqgFEiwjbH43HxTtClx8BuAGWfcKc53/eFIAGA7/vI5XKiYkwmO2X2DNI8ZxAE2NzcxObmJp588klsbm7i2WefRavVEt8DKlK6ZFm3ZS/iy3u0tLSEhx56SHwwgJ0qhF6vJ7tpOY6DdDqN+++/H/l8XjwYuCSAyZLJll9BEKDT6aDVaqHZbIonRxAEaLfbU6qZ67py30nMSKBY+k0Vix4N4/EY1WpVyA3HC9vkeZ70ieM4YlrsOA46nY4sE+G5OUY6nQ6AXeKay+XEi4RtGwwGuHjxIgaDgZgiM8FQRec40UtAHMdBEATodrtYX1/H2tra1NIIrZhSzeKSkfF4jO3tbRn30YoAEiLO6VnVAhzzerc/x3Fk3kXHi/78XssNZr03SlZnved6oOf5YDBArVbDeDxGEARIJBKYn5+X+dxut2Xssh1LS0uYn59HqVSC53lTy58AiDKbSqXkHyftyUOCqImZwWAwGO4sjOMbxzeOPz2mjOMbxzeOf/s4vj38O8Rg0O31erJr1WEmBgz4nuchn89LgmVi1GrE1RBVFanosBxfq3UMHtpvg8EW2C3H1QoKsKvsMQGw9JZJj/4ObAtL45lImGz5fTKZSKLgDlk0LubXXslZq6f6aT8wrcZo5ZHHYoCkMsovBl0mG7ZRJ2RNLEh0SMKocg2HQ7iuK54ViURCzG61D0oYhmJqe+nSJWxsbMgOYFqxYELQZeNsDxVQHcw5ptLpNEqlEs6dOyfLElqtFs6fPy87uw0GA2QyGbiui+XlZTHXZdk+xxGwQxhJVofD4ZQpLv+WSqXkdd4X3gPdvxwPHIepVEqUM94fzmPeWy5nYVLVqg3/pv04eK/4Gn1jgiAQNTCbzYo/Cg2b2Tc0E6cpbC6Xk6UEPD77m9fIcdPpdNBsNrG9vT21TIFfo9EIuVwOp0+fhuu6qFQq0iYaZLOPo/4eAKTfoomeJIWJj/2i+16PEz2eDprgo4rgzXxQxuvnzl+9Xg/ZbFZ2HGw0GrLsh4kcAEqlkixT4vXragGOM85F+vAAQBAEErs45/QyI4PBYDDcWRjHN45vHN84vnF84/i3m+Pbw79DBl3uPRgMhBDotfGHFdofIZvNSuDd3t6WEv1rQS8p0Mmdpf48B01QmdgYHLhuPpFIoNvtotlsot/vi0qmFRkGZO0rwgTJgMTXgN3Exd18SDSiQYUqEBWcVqslnhi6XJuBlQSDfchJTKKjEz7L0fUyiGhp9GQykSBED5lMJjOVdAEIoQB2y+1jsZiouCQBTJbb29tIJpNYXV1FoVDAPffcI+2gR0W/30c+n5edqthGTeh43VohnaVcsC9INHO5nCR3kpF6vQ4AYoxbLBanVK9arSbqGYkbAFFrqSY2m03x8WCyZ3LTnij0a2FAZqLnF/uS44DjTIP3m6SA7WKioF8Nr7/VaqHVagmBDMMQ7XZbjp1Op2WXNu4UdfnyZfR6Payvr8uSk0wmI/3IpJ1IJMTHhsRDL5fgZ1qtlqh9WhXkcXzfx6lTp+B5HpaWljCZTJDL5dDtdnHx4kV0u10h9rp0nfNKVwvsVZof7eNZS0z02CKuleT3UiP1vb1RojAejxGGIZLJJDY3NzEcDoWcVSoV+L6PYrEoyywAoFKpiBcSyQGXREwmVxp/x2IxdLtdIWPArnEz57bBYDAY7hyM4xvHN46Pqb4wjm8cn+8zjn97OL49/DukiMV21vy3Wi2ZVBwIh3H5FicTfQI8zxNlTW/Lfq1jRIkBy9rr9boYmLJEmE/JGXjj8R2zVD4FD8MQ6+vrEvCB3WTDiUPVkSoIVS4qEZxYDDhM7ADkCX70uhg02T6W6TLp0HOEQYdLB0j+WPpMgsAERRLBvmKg1UGQ44NKFv9GosG2aSWL946JTp+DSajZbGJ9fV2C7sLCAiqVivRbv99Hr9fDcDiUXYscx5HXdVDSpsRXC7wcByx9ZnDUilOr1UIymUSxWEQmk5kKoADQbDZFPdMBlFhfXxc1hcmTvh28NyQGVOTYNyR60WvgeOTnoyooj60V63g8jlwuh3Q6LR5AbEu73ZbfAYhSybnAJS30tOn1etjc3ESj0cCzzz6L0WiEEydOTPmjMIFwCcJoNJryeuEX/+Z53pQZMJVpkrN8Po+FhQXZMS4Wi6FYLIoiSYVZ71ql+y06BnR/6ddJprQqOAsHjZFRUsJzaAP2G4m7VHe73a4Y93KeF4tFADtEQBMDLi3yPO8KM2uSU10RAUCWFnGOEfxHxGAwGAx3HsbxjeMbxzeObxzfOP6d4Pj28O8Qgjeca8hbrdahJAMaTJh6INdqNSkHPwiYDPjFxMkSfiYe3/fFHFeTA6pgAFAul9Hr9VCtVoVgJZNJ2VWHAV8rTlqtiiYAekfo1xmkGOAYXKiAUIlkECeZ4IRmuTjJUBiGVyhnVN+63e6UIhUt8WeiBqZ3/+L72UdMhDwG1VytVPLvVPfy+bwk2eFwiHq9Dtd1RYlbXFxEJpPB1taWlPCzv6P+G/RB0csvCAZlqntcLtHtdnHp0iWMRiN0u110u11RM6moFItFxONxWSLQarXEUwfYVQOLxSLS6bQQFxI3lunrMnWSRW5rD+ya/TI5k9Cx9H0y+f+x92ahtmdbff939c1vdbs/XdWtunWvV2MXiCCBkBg0+UeDpJGAxAcTg4YEHxIfEgQNKAFDyIMYAr4Ek6A+Bh+FmIB5CXZEb/RerrerqlPnnH12s/q++/0ftp+xx5pn7VPnVHP2Ku8csNl7r/Vb8zfnmGOO8V2/75hjpjZX1KLxAIHAulqtjJ1D39jFanV1Ght2z3oArCKFQsH00ev1bAvRdDq1k/BOTk4ssC+XS6s3ApNLkObUPsAytlGtVjfu6ft4fHxsNVcKhYKx/zBXjUbDrqXuCPPJ+vWBywM41iA2wfr0xbz9+vdA48OIbxd78GzxB/HH9IuC5uiHdY/fZAwAA74EAfixWb5IoD8Y3EKhYMW8YQj9NqIoUaJEiXJ7EjF+xPgR40eMHzF+xPi3hfHjw78dFG+QHG/+SQAGMGk87fb1Cl7k8whsBD/T6dROVaJIcLPZtHvwec8UkGZN4OU4elLjqRWBs4GR8an6flzeKcAwkXbO+/4zXI8T9mnGLFJYmPF4/AxT5muRSLItIgQR7wy8fnHmONwwEANmqBPha0+QbsxWjvF4bLUjAAYUhwUYrFYrHR4eKp/P6/j4WJVKRZeXl8rlcsZ2MAcAivF4bPOMo/dsNwwlKe6wqNPpVE+ePLEaFbQNIKBI8Gq10rvvvqvxeGxbQtAtR9VLUqPR0Gw2MzbTs3h+S4p3qj6IzWYz62sul7MaHQR57KRUKtlcMjewRP5kLg8MfC0S2mZtMWe+Ns1kMjEgtFgs1O/3laaprUWAAfen/oiv1ULQorbIarWybTd+jaZpakfL+61K+CyAAeuCAsXY72w2M2YLvW4DBpI2Ajy6kWRzRgCn7gX9+7BMnvfBrPF8Pr+xfeeDtA0bPJlMDBiENWtCYAAbiO4ABt728AWsca4FpIbbMKJEiRIlyu1IxPgR40eMHzF+xPgR498Wxo8P/3ZQMGzv1D+qfekfl2SzWTUaDSVJIkkWWIbDoRUPfZ74J+SVSsUCN0GDAAjT5gsFp+lVvQcYBPrj0/JJlcY5E8jz+bwxmdyThYgzoD2YRpyQPynMMxm8j4OkT7AJviYC7XMSFO3wN+Pwqf/bwIhnRSQZSCKo+7F4XROQaQfmhoCFM/Z6hFEjEL399tuaz+d69OiRBoOBvvzlL6vf72/U2CAIoBPP8vhxeoc+n881GAzMyVEbgzGSAs8WDT4nXaVbo1dYFQAhYIZTtkhR9+yb1zOBESYXMEN/6RuMHQ6btcDcwORgJwRD1jc1Vzg1DZAGUGEdYIOIB9X0ATaIvrA+sFXszTPf2A26BUjQPwIjLCJtwzzCeNMGuqhUKspms6rValbfBiDjx3+TX6CtxWKhbrdrzCV9D20YnXh/8KJ+k+sAb9vAxsu26YV59sw8+vFjwT94wOrvzw/zwjriiwxfHmgLW4oSJUqUKLcrEeNHjB8xfsT4EeNHjH9bGD8+/NtBCUEBjvXDprl+XIKTazabqtfrkmRBA1bmRfpOAKpWq1bclPYJRJwmRE0Q0tV5PUwjJpW2Xq9bYPYLmvvVajU1Gg1rF5bMMx44z0KhYNsUvHPyfc1kMlbvASHtnAKzvO8BVaiPbDZr7FGaphZQw0K0OHlfcwSnzHW8jzMhoMIYki6Ow4JFoD4GQRLGCObryZMn6vf7+sIXvqDBYKBHjx49U5R0vV5bsPPAhPH4ueEHVgz2lNfz+byq1arq9bqOjo4s2HEfScb4snZgptADc9vr9Sx1P5vNGhNNW4AP6o8w/z4tXZLVb8ExYwc4awCEJNsiAOAAPPX7fWMUSelmbugvn6Vt6sigQ0lWd8Jvu4Dt84WvGYekje0tmcxVjZB6vW6sKe9RzwO9VqtVY8cBLbSJPdFn6oGwRWQ4HNp62CY++AN2sCEPkr2EAfyDBG8P3n2mAQKI/SDtr9fXJwSOx2M7Ecx/YQm/ELJlhvn17Ch68KBssViY3fF5GMIoUaJEiXK7EjF+xPjoI2L8iPEjxo8Y/1Vj/Pjwb0fF7+HedWDgBTYnTVPr+7an9S/SDuzUeDw2o67VaqpUKkrTZ0/7IV3fs2ikHIcpzAQCAqh/Ku/b9GwZAd3XdSD4wLwxRj7DIpVk7A6BB2dN255xWq1W1j8AAa/z2+vSs5feuSCeJQjHCLjA2eHEw9dJVyal3t+bgJPNZq02hT/2XZIFGRz+YrEwNm4b4xKCOF4HnNTrde3v79vx6dJV8V/pOqige+q90HdAB0DDO2PfH4A5QDG0ZQACQZo++5R2dMBnR6PRM8xvJpOxmiPYvZ8bHyToi2/Tp+MDDGDuaBuWE6BAHRF/Mlmn07H+0Zav7wEwYPyARMAaOstkMvYlwQcvbBHbLpfL1odwzXmGbjqdboAlhPllLj5q8Xa4DYyEfuhl2vRri3WAvmGgsSNfR2g2m9lJf/gUaZMt9F8gsIMQ4ESJEiVKlNuRiPEjxo8YP2L8iPEjxpdePcaPD/92UHAEPDH34GBXxaefUvcBB4eTftF2JFnaMMFzOByqXC5rf39ftVrN9OMX2WKx0OXlpRaLxUZdjDRNn6ktgT49SEA8w+SDPDUoCEIsVlK9YVZw0jhRgARsY6VSUT6f19OnT40pWa/XG6dQzedzu9YDA3TsayHQF4J6mqY2BwQY7gmb4PvpU91x2L5ALAG8UqlsOGbPiC2XSwNZbAUBpJH6TuFZ9OHvETI5BGfWgrd9Dwru379velosFrq4uDAWmDEWCgUDEMz7w4cPN+aTvniWClZrtVpZzRG2KSAEY1hMD7p4fzab2TaWbDZrbNje3p7K5bLZIAGX4IBzB8AMBgNdXl7adhhYdM9+0//hcGisliQDZNJVYK7Vama/PrC12207eezi4sJ8j9+S4oNYtVrVeDw2YIC9lEolPXjwQPl83uaXejvUSalUKlqtVhoOhxvgI2TcKObsmTJvLyGgD/1JCIa5z/tJyFJ7hpK14/vyoj7O27XXKbqmkLXvO7qCTWy325bR4L+QeKDpswKm0+lGwe0oUaJEiXI7EjF+xPgR40eMHzF+xPi3hfHjw78dFOou+JRmjP9Fje9VCk+m+fFP718GFEjX6bikHWPoME/+VJzVamVsIU/APdMiXYMsnDPFURFfd8EHCs9OkOLvGSsfhFlw/Ga+ABDeMdHvTCZjAS3c/uHBAqCAlHCAjmd5tvWJYExqOEyhL3gMk0lhWcZPOxROBoRgkzA4PvU9l8vp9ddfV6PR0GAwUKfT0Ve/+lXbFhA6UP9/yFZ4loT/mWNY1SRJVK1WN+q3EPDW67WBD8aOTQFWR6ORRqORsXDbQDd9DFkf7IsAxr2Zfx84/PgI0t7WuS9bOrind/LYlgdp3h/wOvYzm81smwH3hKH1rChsKH3hdcAstsy9sVv0yYl4/X7fbAh2Lk1T9ft9A7uerapWq1bclmLYIRhEd9h6aDfbgrW3HT+H20DDi/ilkKH27fvPMncvCjZY62wzCWt9hGyxnwf/wxz5ueHzAILhcGhfCEL7ixIlSpQor14ixo8YP2L8iPEjxo8Y/7Ywfnz4t4NSLBbVbDbtiTmOGUe3S0Jwwjnn83n1+31L4Q2DwvsJjmAwGGzUTFgul1ajoFqt2nXD4dBYEfqyXq9tUXlmNZvN6uDgQEmSqFQqqVAo6OLiQrPZzJ60r9drO84dNo16Bz4tnyfuLHDYQfoJuCsWixuMDMxTmqbWh36/bzUXGBd9hlVLkkTT6dSYNk4CgonEARIQCQD+pKt8Pm9sGXMCOOl2u+r3+zZeUs5zuZwmk4nVLZhMJrZ9AQDC8fJ37tzReDxWs9nU06dPdXl5qfPzc7s/NhBuZ/BbMiQ949h5LZ/PK0kS1et1NZtNNRoNO3oe9okAxf1oC0AwHA41m83shD1YZ29/3Je59s5c0sYWgnw+b+MPwRpBnPH51G3u4QOCvz+f4wQt2udkMK5BjwR+tjp0u11bB54lhl2DwfXBOE1TY66xMb9+GW8ul9NsNtNoNDJA4osH4w9gwu/cubNRb+Tg4MD0SDFmD6QAkwRbtpfgA719AJwBUB6EedAeginY8m2BPgTy3IN2/L1C/b2In/PMLdtUQqDsU/oZB1kG+AbP6i4WCwv++XxejUbDimezzgFYUaJEiRLl9iRi/IjxI8aX6YvXIsaPGD9i/FeD8ePDvx0SjDSXy1l6LQ4Bx7drwABWhOOqKfSJIwoZlRdpDyfqi576IE16u2dFYCBD58sR29QcGI1GtqBgnkJH7dkoFiWBHIfJZz174X9L1zU4/NYFWCrPZuAEcAiwbdls1o5M5z7lcnmDWcQh8BkWP2Pw6cIEch9I/bUEHJwdn/HsLn2mf34rAdcfHx8rk8no6OhI6/Val5eXG04YfXtni/BayLqgl3K5rGq1qkajYbUoPGjz7aHz9XptdUJgYWCC/WfC+Sawwu4SnAAfYY2VMDCgN1/IOAQC/M38hUGJvrAmYL6ZI5/m7etmwA7TDp9jXKHNMxYP8LGfbfrkf8AIumILA/efz+dWZDtcK4AKdIwtAVi2pduHLJ8Hm16foWCfIevKvPu+bft86Bf8OvBz7dvaJt5fwd4S6D1r59cJXyaYc9+GZwml66LOnlXcNp4oUaJEifJqJWL8iPEjxo8YP2L8iPFvG+PHh387JpnM1Sk8h4eHkmR1AXwh1hd58vyqJJu9OlKcn1wup+FwqE6n80wx2FDCBe6ZENgJAmGlUlG9Xrfj20nrh9Fh0SRJotVqZU/9OWHrvffe02g00sXFhUajkY6Pj20x++0DBA2erq9WK00mE5VKJTUajY26LD5t3ztMxuZrNMBEwLIwz34rhS+oixPv9XobLAF9wBnDDpbLZWUyVynA3nlSOwU2kRoCnpkD6JTLZWvTO2TPjjEuWNH1em1zwNx97nOf08nJif70T/9UtVrNWNPw5DQcF/NAUAjZMkBBpVJRs9nUwcGB7t+/b4zrNgDq58TXieE9apMwLgIvLC99g/Wbz+fqdrtKkkQHBwfKZrO2HcW3gXi91Go15XI5DQaDZ5gZAGcYtHxBZm8jsLXUDvFBDtZvvV5vFOb1faNAL8Cd+/o5xQ7YQkNbrDc+620atop1kcvl1O/3Va1Wbb0y7wAtXx/GM+iA1tDXhWvM6xqAARD270nX23pCffg5C0GZXwPYKHMEgMJuPZgMAeK2/i6XS/V6PdNDpVKRdA3E8AOAfZ9lgX+Dnc3n85pOp6bnbVsKXiYzI0qUKFGifDwSMX7E+BHjR4wfMX7E+LeJ8ePDvx0SFjjOG6PmCf0uime2fLHZDwJecrmcLbjw+HoPGjzDwX24LynxfgH7vuGwp9OpisWiAQjG4hk6FjoLGRaDdGM+g4MAZIQOImQh0E/4hD9kqLivBwq04VPfJVk6OnryLAEBzztz2vBsC+3jCH3AhKH0DATXhLYgXTnio6MjLRYLPXnyROv12oCir5fh9ej17YEIdkGquV8PXq9el5ymRPDxQYg58OwT/SEob7Nv9ORP6kIPvOdZGPRIkVevX//jmVAAm3+NPnm9EBh8qj3bFEjd94HStwdY5bXVamV1dgDk4TYWH0CxKYIQ88MWmfF4bNcy74B7mLRMJmPbEubzuQFTagm9jIQg1r+O/kKd+/7dxJrxuW338X7H+5yQubupv9jRZDLRaDRStVq1djzL7f0I88yXCK5nHCF779lB73uiRIkSJcqrl4jxI8anzYjxI8bntYjxny8R43/0GH93I843oDDxlUpFh4eH9uSY48d3LXsD44O943Qi70hfpi2Yt/39fZ2cnFiNDhwjdTFwKCwcSeakqGUgXS2WJEmsjgTBYrFYqNfrGStCoOfz5XLZHDpP5QmsjNcHEBYcASJN0416HghsCO0RJDm23bN7BHeYJz7PfTnVCuZoNBopl8up2Wwqk8mo2+0qTVO1Wi0LqFw/HA7NkXun4x3HfD7XbDazOZnP5+r1esay4bgADv7zbGn5lm/5Fp2cnGg4HOrJkyfGZPoTwwgKtOd17YNOrVZTrVazk49g7ur1+gabCCjo9XqaTqe6uLjQdDpVv9/XarVSvV43p8r2FYI8fSsWixtbTPwWgPl8bnVj6KMPID7QY2uMka0spIMTKHH26Bzgi2AXsJiLxcKY6mq1avpDbwSnQqGgVqtloCFNUwv42ANbJFqtliqVigWRwWCgyWSyASRZg7DZ1LOhfkyj0dBsNtPZ2Zn1Y71eq9PpqFQq2fh9rRBJKpVKG1sZqHsRgqznCfPna7v4tQkwC8Gsv+55gZM14kEkOsa30HcAsD/dzAu2Q+bE2dmZsYvo2c8n98LfwPR7UMyaDBlt/CE+LUqUKFGi3I5EjB8xfsT4EeNHjB8x/m1j/Pjwb8fEB1vpeh+7Z412SfxiCp/Iv0wbHmDgcCSZs/AO1DNv4b3Dp9/+Os+0ece1Xq/tNKNisahGo7HBDobOn/RjgoBnQrcxWyFIImD4OfYMjR9T+NkQIKI7H5h43bNkIaPB6+H4PGuEUwqdpg98IYuBraZpag6s2WxqNBpt1HbxY/Cs5za7oH/YCDbgg4wfO22G9RX8bxw9zKhfX34sXAtbHzI+OHT0wWsebHn2j75ms1cp/Ng080HRZq7xzCzBIBzrtoAWgtXQdmiTe/m/vf74YVz8JugA3Dw7CbAJTy3jnrzvU/6ZC9a+ZzlfVNB5+Lfve8gKvghTFl4TMnV+XN7HsA62faFjjcFYl8tlTafTjVPTfF/9fbiXdM1Khsz1i4wjSpQoUaK8WokYP2J8P6aI8SPGjxj/xSRi/I8O48eHfzskGAT7471zg73YJQkXni+S+6LAAGeZy+VUr9d1cnJiDMVwOLS98vv7+1ZbIJPJWHo6wmlCnHQlaaO2g0+l9j+DwcDqhOTzeX3zN3+zisWi6vW6Dg4ObBF6RgEGj7mC3fCAAIaLJ/Iwj+v1WsPhUOPxWLlcboNZYRw+GHqHK12zG7Bg9IP5YLx8fjKZmC74XDabNXYIRofx4dCm06kmk4kFLekqeMBOcI0HBtI1I5qmqc3le++9p2KxqHfeeUfD4dCK8OL0vVOlDdr0ac9slaF2BCfDoTfmIJPJGHtIzQWADsAC0NNoNOxEOE5CQ+ewhTAu9Xrd5tafLgeQAPzA1JVKJWP76D9jAhxiw4VCQdPp1NglXxy3XC5bvYiQLWO8zCt/o7fhcKhMJmOMMqwrzB5t0Ff6BBAqlUoqlUqWvo4t1Ot13blzZ4O5po5MkiSmo0wmY2A/SRJVq1XTz/n5uSaTiWazmVarq9PJ6vW6er2e3csX0t4mHhRjO+HfIWC4SXwQ9u0T7D3oD0EUW5nQrS/KHdYN8utktVrp9PRU4/HYahfV63WryeLvwQ+AwoNjX/8FfxqC+fBLRpQoUaJEeXUSMX7E+BHjR4wfMX7E+LeN8ePDvx0SAgHOazabaTqdbhRn3SVhwfGkOmRF3q/PGC6G7Pe50z7BI2SmPNMX/iaw4rA9S8NnSTsmABJYut2uFeBtNBqSrgNiODba8+MOmdGQvQwdFwuZYs/+Pt4Z4AAJ8J45wnGFbXr9eX3xnneWvq/h3DEughB69QyWb4s+EmwqlYqSJFGlUrFjz33dhOc5fS9h3/zcEmjDmi04a4J96BxJbQ9rMXgdcz+u8bU4vHhWhnnZ5pDD15gv3vMMD2CO18JaNT5YSVfp9YzX6ywMMtv6sS0w+tf99TB32BHz4mtSAGb9OvEp+2zRCe8Fswjb5ZnBFwnw2+TD+k8PQMJ1g26ZJwo2+9PdPDvv1ypfqMbjscbjsQF1gH/oDyRtsIM+Xvj1wFYUAJ0vYh4lSpQoUV69RIwfMX7E+M/ah+9HxPgR4/s+vahEjP9yGD8+/NshIR29VqupVCqp2+3q3Xff1dnZ2cYC3CXJZrPG4k0mEzPIF2UGYSxgPmArWDS++KwkS4sO0+39CVrSlYPMZrPWF0kbzrLX66nf72swGBgb4xm1+/fvK5u9OuVsb2/PPkefs9mssYWDwcAYOnTiHTuggz7iPHiPehcwMgAWQA4/FLf17Bw1PTxbhU4lGeNCQPEsJzYF88K4uB7HRr/YnkFtAZhFHKJ3dACDTCZj9USOj4+1XC71+PFjS/f2RWkBHuiNPgHkSJ8ulUp2Whu6p7bI5eWlstmsjo6OVCgUVK/XN7aX0C6Bu1wuq1qtql6vG5DAVmA/F4uFMWS+DgM6Z35h8qgbEwZe7Jh58K+jR+a0UqmY7WMzpMxjq8yND8D7+/sbQXowGNhayWSutxqF68UDKg+EV6uVseA+UwFdMGd+rQ6HQ+VyOdVqNWt/tVrZ3IxGow1mkhosi8XC6trALGLTfjsEY32RLx8v6oM8+OE1b4e85lPwAaTT6XRjmwonx3kbX62uiiRjTx5U9Pt9zWYznZ6e2nuwpMVi0dqHeeQebKFiTliTZDv0+3299957Zp9hrZQoUaJEifLqJGL8iPEjxo8YP2L8iPFvG+PHh387JDgT72jH47FN7K6JD5CFQsGePvun2S8itOFrEvjTk6TNE75CJpDXpWdP9mFx+gAryRYrp4LBEg6HQ/V6PdVqNfV6PaVpatsQPNPj748D430/rm268PMb1qHwzsczgtLmSVEhQ+HH5vuI8/Gp9V62saa04dPMQ6bIv++Drf9Nu5VKRbVazVLDt9VZCZmfUJee/QI8EYQJHrBM6Na3BctCcPbsKDr1OqI/2E/YP4Isqd/cj376/oe6I4B4ps7rlN8eXIcg0ffTBzUPfv29/fx6O/C2HP7cNN/00esGO/Zsb8jio3u/LcEznVzDGg5tmv6+CCB4GfFthf0OZdtaxAbCOfWAzbPp4Rc8wMJ0OrUT69CDt3kAmwedIZPNPSaTiSaTicbjsQH6kIGNEiVKlCivTiLGjxg/YvyI8SPGjxj/tjF+fPi3Q4IBwbykaarLy0t1u90XZtleldBPalmUy2VNJpMNJ/GiQh2Aer2uarWq6XSqp0+fqt/vG/tFYPHH3SMwFyyQXC5nwAI2S5IdJZ/P523RUJuDdPKnT58qm72qozCZTLS3t6d79+4pSRIdHBwol8sZ+xM6Ll5jUcMeECDpNynoy+XS6h54RgYGyI/PBz7vTLEJmD4fVD0jAauA4yDQweT6vvptCjAT/l68DwMFa+EZONiy9Xqt+/fv6+DgQH/8x3+swWBgRYIlWQD0jKxnpnzQo81+v6+zszM1Gg2r0dHv9634LOOiz96RErhhpMbjsQaDgdkHuptMJhoOhxu69qwKdiDJ2B7ACjoIAyNC7QYCpAe/tBsCFD+n2WxWlUrFWL9s9upUrUKhYEwcdjgajey+aZqajRJwAKmwhH57gQfcHhgQAGEcPcsVAvFsNrsxL9iVdFX3grUgydYDevH39gAPu/Y6/qC+0X+OgO3BWAjM6JNnA+fzuYEc1jp+y4+Nk/D8/XhvvV6r3W5rOp3q4OBAzWbTmPD5fG5bW0JQhH17JheGsdfr6fLyUuv1WrVaLT78ixIlSpRblIjxI8aPGD9i/IjxI8a/bYwfH/7toDDBOGnPSOyKePaK2gCSNoz3RRcrzsYHOx8EuYcPTp49RE8+4PE3i066XkQ4R67ztSR4Ms+iWq1WKhaLms/nVriX9nz6Lm155pDXPWPkdUffWLA4TL/QCWTbGKZtbBpjC3Xvx+sDJPbF5zyb6J25Z9Zw/Dgrr+OwDwRhxkcg8MygH4MHUF5nCIEL4OeZE/rqPwtDSN9DxofARr0Qfui7vy4Eu/TfyzanHdqDZ/18IAnv7e3Ws6y0kc1mbftBGNB8W77tbYyXZ2j9NX68nn1CHyHwRgAbXM/WEgAPvoL0dgKqn7vQj7yfL/mwACH8rF9DXn/oxQMh9LCN2Ub8GvJ+jPYkWSFozwpiI/7nJuYSvzmdTu0LD8Wjd+lLZZQoUaJ8I0vE+BHjR4wfMX7E+BHj3xbGjw//dkyY3F6vZ0+dw6KjuyC53NXJXY1GQ0mSqFAomJN4GQYTJ+kLsq5WV3vnCSqc/ASjxz745XJpbNBoNDInlMvljKH0hTDTNN0oNlwqlTSdTjdqcEhXAb/dbuvx48dKkkT7+/va39/Xpz/9aVWrVR0cHKhSqajX620EVPTAaWSdTucZRgTdeUdGX2u12gbgwlH6oEWQk65ZFK7xjBLO2rM9vi++EOu2e8JG0Ff6MJvNrCZHs9ncqNcCs+dToXGI+XxezWZT+/v7evr0qSaTienbp4RvSwdHT7CHsLLck7lEx7BkzAlAZjqdGjMDsKCOCHaTJInK5bKNH+C0WCzs9Db0RAD08+MDIUGbvvT7fUvt5n1/GhhtTadTjcdj0yH2PR6PNRqNNtLmaZv5D3XF9ZxqF65NxkDfaQNGinVXKBQMCLLG6ft0OrU1nMlkbJ3y2VarZTVv/FYH5ns8Hmu5XNqpbk+fPrV5oZ4NATHccuCBrJcP+7ArBAn8DsGKBwPe1mHJ1+u1nXznax2xbhgX12UyGfX7ffN71IXhdL3FYqFSqWTblOjDYrFQv9/Xw4cPdX5+ri9/+cuaTCZ2Ot3h4eFGpkGUKFGiRHn1EjF+xPgR40eMHzF+xPi3ifF3L+J8gwuGjuHsasYGwYJATbB9GQaTBUdKsq/HgLMkkPun6Z7l8c4Cho3XQhaGv9frtQqFwgZrxxP4+XxuYIIn7Bz5niSJkiQxh4wOCCowUDgtn7rMOD1I2Mb+huwPbZKGjR7otz+KfhvrE7IT9C8sNOtZn5Cd8qyMd+i07UEO1/l70l4IPvgM74f38p8NGRnEs5Hoywc7b6PMhe+/Zxk9q8zY/Hj5jB8jP+Hc+LEBBEKmcZvQJ+qaMP9+i0to1zfpyK8Hz+re5FMYQ9hOaFueCfZztl5fb4NhvQGUKGTs2XBYdXTlt62EeueabfraxuZ9ECbsReV5THW4rvnt52DbOvU+C1DG3HlgQDucHOhZQ+oZ8TObzbRcLg1I72osiRIlSpRvFIkYP2L8iPEjxo8YP2L828T48eHfDkmpVLJTtdbrtabTqdrtttXF2BXBaZbLZQuWPg34RYUn6PV6XcfHx2o0Ghs1K2ASWq2WMQa9Xm9je0ClUrHaGjAUONdMJqO9vb0NcNHpdIxxwPl6gfHwLE8+n1e1WtXDhw9VrVZ1dHRkv/2c3b9/X9Vq1bYPwDjCzOAgcbTU2kBgUWCr2ILATyaT0Xg83gA60nU9FOrIwKx6Boi26BOMS6VSMcYHu8PB01a327Ugw/yv11f1ILxdcj/PnngAwZYLgNa2IOnZHuaA/sFWesAMywQ76k+QYu4YP1sf6Ku3w9lsZs4X3Xn2j1OYWJecXpfP5602B2OieHe5XN5YE7DPsHMETdg0anoQZMrlsp0q1ev1DLRyT4QA4cEWNW4IRN7Wwq0IAGJJBnKZ63DLBNf6rQCwTR74AGbSNFW/37cxw3otl0vTD59Bz379EtC8HXkwGIJS7CIMvB9WQsAe/masAEFsydvg80CBb6Pf76tQKOju3bvKZDJWD4o5bLVatsb9tiROjux0Oup0Ospmr09p9PVCokSJEiXKq5eI8SPGjxg/YvyI8SPGv22MHx/+7ZBsS+0NHeGuCAvAA4IXYT3CNrxzxCmx+Hn6zYLAYWez13UQQp35tjOZjBUqxgnxpJxAG0rIdNAO80DwJFWX9PFqtWqggN8wOJPJxAqG4qwJONu2e7DQfYALGbWQCfEMKePwThL2ivYJJr4dz3IVi0XTAU4OnfuU9rDfoYP29+MHvdBH79zD+dvW923MM30jgHg9eH145tWP2zM7BDx07VPlpWsAFNqeb9uzvx4ocR1j9OuH357hpBZNmCXgA6YPll5HBGK/fcGvU/Tl5873HfHrwbftbZPx+N+MM1xzw+HQQJRfh6HdhOLbf5X+8P1YRj+vfixsqQnZ9m3gQNqsYcRWCNYd22cymYwxxGQtsKaGw6FGo5FtMcK3wgq+TMZGlChRokT5aCVi/IjxpYjx/fxFjB8xvrcJfkeM//Fi/Pjwb4cEp0ugJA38ZYLtqxJYwWKxaEwaqagvCmS802LMMCM4xXq9rlarpcPDQ61WKwvM/lSmbPbqVCpJG046k8no/v37SpLETqmqVqvqdDqaTqfq9/u2QPP5vEql0kZ9C+l60c/nc/X7fY3HY00mExWLRV1cXBhDUy6X9bWvfU1JkujBgwc2Du/omcdms6lyuaxqtWrznM/nN9hDAsJoNFKSJDo6OtJ6vbY6KKPRSLlcTq1Wy9rGafsgQhCHrSLwwXR6dmE6nZrTqVQqSpLE6mLwOp/DuflgS7Dw6eBpmmowGGg6nWowGGg0Gmk4HGowGFhwCLcIeEDkgzP39Cnno9FIq9XVKVwwUblcTpVKRdlsVu12W6vVSpeXl9YHXxcFWyNdHdDpt3oUCgXTG2xYpVJRo9Ew/QCesCXAFToASORyOU2nU6XpNaMN4wjjBkPoGTP06ZllAgg1aDwjz+dgdpkrdAkTOZ1OjS1FpwRsz7bDdHo78P0nOHnmjhPWhsOhjVuSzs/PrXaMJFUqFeVyOQNAzKkHj9v8But8G6D4qIFDyDaGQCEEVbzv9QIz51P0AckerOJfut2ukiQxHVcqFTvpbTwemz0zPxQAlqSTkxMVCgUdHByoVCrZF5koUaJEiXI7EjF+xPgR40eMHzF+xPi3jfHjw78dEs+AvGx6/asUz9bwtBmn5vf4v2g7ftw+GOCUi8Wi7X+HucERh47OA4NsNqtaraZ6va5ms6lisajRaKQ0TVWtVjdYNh98fP88G+KPJ8dpElTy+bwFDJw+Dq9UKimbzW7ohnb4jHTFnuBcYBun06mNjfF5ZwOrgm5oA2fjmSBpszYB9sVnvTOmbd73jIfXmXdoIYDlel9XBRu5aUsA4h1xyKT4ezMnvg6MD3IEPuojeB0zRnThQRT3ASCs12tjYHwKOzbkAUC4jhkPKeH01bfDOuI1Pzd+PYXMIUHat+F1xz2ZP/oPG43OPOuKfdA+9oquEQ+cPLvI3FAEN9QvtsBnGAMghHohPuCHLFq4Nl+1PI8h9OAW3XvmFt16u6Y95oM1M5lMlCSJ+RjWOz4QsE+ha+a5Wq0amGBL1C5+wYwSJUqUbxSJGD9i/IjxryRi/IjxI8a/PYwfH/7tiPjgRC0Gf0x2+BT6NsX3M5vNbtQHYFHf9Dl+ZzKZDcPF2DkBLEkSS+fnKbgHDpKMHfQMDO3T7uHhoZrNpprNpkqlkqrVqiaTibLZrJrNpmazmTFH3Dt0Qn7REswJRjBQfs9/p9PZCBr1et2YE0k6Pj42wFIul9VsNlWr1czBc2oTTnk2m+ni4kK5XM62G8AeMRbvyOkb/ZFkzKPXG9f5gMQYOZ0JtjZNUwuql5eXVgeFgEQg8ELQpf7K+fm5Hj9+vHECmNcvAkDx7AnOFTas3+9vFEj1tSlgW9I0tZPi0AFBjKBNsELf3GO1WpmjxbYJitTVYFwEutFoJEkG9EK21AMyHHhoa+iD+zNXBPNwawLp4rDE6Iti18zn5eXlBnsa2rYHONgSoMLPrwcN/kQw3yeCFvf0tlcqlXR0dGRtp2mqdrut8Xhs7DEAGh/DXG4Do6/aJz7vfvTRs3swuR4EoE8v3g7wQ4PBQMPhUI1GQ81m07IPYNYBA4vFwgqYU6ScbVTNZnODpY8SJUqUKK9eIsaPGD9i/CuJGD9i/Ijxbxfjx4d/OySedfH793fxS5tn4HiS7wPM8z7nF4gHPjwNx7HhCHnPOwdJFgA868U9fIHbWq2mWq1mi2U+n+vOnTuaz+cbBYh9nQYvoSP1LBpjIJhmMhlLhZau5rLVatkx9bRNMCGIeAavXC6r0WhsBL3xeGxHg5N2z3uwogQU5kLSM6n1pCX7VGrPPPl7LpdLVatVS6+HdaLwrmeofJ/82Gl/ubwqcMyWEW8H/v7esfo+hW1SDwEw4llLxk0gXCwWG4WWATz03bNs/A7ZOG9/rEfqXDA+thp4Bja0oRAc+z6Hc+BBAWMH+DC/Hqz6+/lxpel1cWDAHfdgfYW1fXK5q4LAMNL+nh7QYWvePghYk8nEAA0FcrPZ7AbgT9NU3W7XAA5ryPvCcG1us4tdkW3suwc0BG1/behvSPH39u0Lmq/Xa00mE2PX+cFv5nI5+2IJUIhbfqNEiRLldiVi/IjxI8aPGD9i/Ijxbxvjx4d/OyQsDpw9C8ozAbct3qHhfHCKBMybFizOKFz4hULBUulphz3w1NXwwWC9Xttr7H8n6CdJsgGk2AvPE3VOhHr99ddVqVT0ta99Te+8846Wy6UGg8HGGBhHCDz83wQF+pfJZDZOlErTVJPJZAME9ft9O9GHeieNRsPaOjg40PHxsSqVioGKer2uJElUKBTsRKhMJmM1PcItATh8tkAQDEkV9sDAM4iwSQTxNE1Vq9XsWhx7Pp/XeDy2eYKZ9anzzOfZ2Zk6nY4FClgjTiHzwYUAz/34H5DXaDRUrVZ1eHgo6ZpBDAESTDX2lSSJtevnB1vBCROImC8PvqrV6kbQHgwGBj74PAHVB3PmByABE4kT5x4Aa8/Epmlqdsv84CcIFugH21wul1Zwl1O36BM1ZxBskvojsE9+/TCvHngwj/TFZwVQyNZv0wAYMu5qtWpjT5LEPp/NZq0d/B72zJzgB8K1uEviAQI2jK15QOC/YHkWVrpiB7vd7kadj2w2q8lkosFgsAHGACDYFH4BxtYDuyhRokSJ8uolYvyI8SPGjxg/YvyI8aXbxfjx4d8OCYsaByxdO5ZdkvAptq8j8SILNWTwSNXGIcBW4AhZKDhhHCGBBKcr6RlgQBsUXMXZ7u/vK5u9KiJMaj6fC1kp/1Q/HAdBwrNZgBt+02dA3mg0Ujab3UgnJ70cpz4YDLS/v6/1eq1qtWr9gOUiCPm+4YQAVpLMSQOkKC7q08c94+VZzslkomq1akGBcfqaBDARjM8HagLecDhUr9czfRAo+IwPOiFLxutskyFwNZtNrVZXdT64pweeBEIcMtsLAC30z7OW8/l8Qzder2HR2zRNN05h8un/BAJeYywE6HK5/Mwc+J9c7qoQNteXSiXVajWbG4CNn3/AB+OazWa2VcAz59iPZ2T5EsL8e9YKdt7PhQcypKNjwzD7zBlz4RlEgA99Anzwug+mnt30YM1nBjxPXvS692sj9FnP+x8J2Uv67fvvv2QB0rADdDudTjWbzcwGWf+sCc/4AxY9UOT3roKoKFGiRPlGkIjxI8aPGD9i/IjxI8a/bYwfH/7tkCRJotdee017e3uSZAt2F4GBZzvYmz6ZTIyVep6QdkzAlmTpytSKwFngDPgpl8vmjCVpb29vg4Eg9ZkF1O/3rQ6IZzdKpZKazaaOjo50//59nZ+fb9Q1YJxewqf6AKFwOwSv48x84PNOr91uazgcqt/vq1qtWiA4OzuzbQGHh4eq1Wo6ODhQs9nU2dmZ6QQGz7OqOE76D6jASdN/gBUnCqE3GChS5qmXwnz5IARD64O6Bxq9Xk+TyURPnjzR+fm5Li8v1ev1NupKwPKEDtLXp8BOWq2W3njjDWNL5/O52R598gwy7cIW5vN5tVotrVYrOxHM18yAiQL8cHoSIMMXWg7thJ9isaiDgwNls1mNRqMNhrZSqWxsXaBdir22Wi1jzMrlsvr9vgaDgZ3+xQ8MqbdR5oPaNoPBQLPZzAL9nTt3lM/njS30Y5dkwJmtMwBqwDrri3vDOPngBDvF+wS5yWSiQqGgz372s2o2m/r0pz+tJEl0cXGh8XhsbXLKHYCJ8QFeGOOLbD1CPooHXtu+ELzIPTz48n9TywdWzwM8D2qpL/PkyROt12sdHR1ZgOdEMD7P/FUqlWdsgjW0a3EkSpQoUb6RJGL8iPEjxo8YP2L8iPFvG+PHh387JOVyWYeHh2o0GvbarrGCHhRggDy5htV6kSf1Pu1akj3pns/nG07Q10TxwZBU91qtpsVioV6vZ6whwQqnRGFbghbOOkkSNZtN7e/v21YBv0ARgrx/ku+f7BMofM0Cz2aEoMEHhmw2q+l0aoDHP72v1Wq6vLxUo9FQr9dTs9m0VPr9/f2NVHwfSOmzpI16Dv51X/chk8nYqUL5fF5Jktj7BJlyuWzMFGnIvgh0OLewisPhUJ1Ox0AQzJHXU8iQ5PP5jfopAIUkSWyrBPOez+c1mUw0mUw22DjPUGNngAPfZ28Ty+XSdIqzZc6wUc8Co2u/Jtg6ADCgDzhndOcZRO7VaDSsCDZt8D4sIn2StMH+LJdLTSYTjUYjW4+LxcLaOjo6UrVa1Wg0svoyvng3IBxQAEAcjUYb7CcByKe5c2LcfD63AtzYFVsgCoWC7t+/r729Pd25c0elUkm9Xm+DBWWMrJswM8Kz3h9nFttNLN/LthEykp75lWTMaMgGcu10OlWapup0OrbOkySRJGPrpeui27zvARQ+xttNlChRokR59RIxfsT4EeNHjB8xfsT4t43x48O/HRFSY5vNpjnm9Xqtfr+v8Xj8sS6ElxGYLpxSoVCwwpQv8lmE8eIMOfbeF7+UZHoYjUbGQITOFmeMwyZoTadTnZ+fa71e6/DwUJVKxY6DZxvA3t6eHjx4oP39fQvO3vG8Xyqtf8+zcT7YAX54HefrAQNBDlaLwNHv940tTZJE/X5f9Xpd9+7dU6VSMcYF9ojgjS4AML5Y7GQyUaPRUKlUsnopMJu+bkO9XjcWarVaqdfrqVgsql6vm0MneNFf9LBYLDQajTQYDOxEI1g6n65MijqfJaAA3ghW1PMYDAYG6rLZqy0ds9nMgAK1OSj6PJlMJF0fZ+9ZTOzHs86AAhw19k6dixCk+2C6WCws+DNOX3OEeWV9o7fDw0Pt7e2p0WgYq5PJZKwOC+sNIEFffK0O9Agr9+abbyqTyejw8FDlcll379612jqSdHZ2ZoywZz79VhzsNp/PbxTqhR08OjoyPbD1o1Kp6LXXXtsovnx6eqpsNmsn4AFC/f0BHtihB4+wvOHa9O+HPuaD+ku/bm9q5/3uEb7v2XJ/jWekPUjGPvky0+v1JMnAGkXBAUwAK5hUf69yubzRpyhRokSJ8uolYvyI8SPGjxg/YvyI8XcB48eHfzsk+XxetVrNCnOu12tbPLskHhhks9mNegg3yTamDYfvHRb73CUZOwDDRFq7D3gAg3K5vLHQKJ7Z7XaVyWQMvIxGI43HY1UqFeXzeTWbTZ2cnKjZbKpUKlm69PvJNkDg//cOhj4ynkqlomKxaM58vV5vAAMcA+wn7Fq5XNZgMFCz2VQ2m1WSJErTq5oNw+HQUvl9GwQ5jrTn+lqtZvUXSFGWZLqWrpiHQqGgcrms4XCodrutSqVizITf7oDeCX6epULnOEACMOwF9uN15Bk9+gDTRsp8uVxWvV7XfD5XqVTSbDZTv983NgU2y7N+vhCuT1uHkeK3n0euIWB5BgcAkM/nbQ6xUeada9EVDn42mylNU+3t7enk5MS2BmAXgAT6NJ1ObSsD9s2cwfCxFu7fv69isah79+6pXC6r1WqpXC5bHZx3331X/X5fw+HQtlZgB4AhD3AkbWy9AFCiM+rYJEmiT3/60xa85vO5Ae6DgwMVi0WNx2MDu9Sr8fMT2oNnbm8K1GEQ/jDMXhhEQ+AR+rHwszcBh3DrjF830vVaRdAD7HKSJLb2sA3Wh6/hgs1jC4CQKFGiRIlyexIxfsT4EeNHjB8xfsT40u1i/PjwbwcEY8IIVqvVRk2GXcragEmBUctkMjo/P38uMPBPvHG0OM5arWZO1Ttu0relzaK7PpXbOwMYFAL7xcWFZrOZLi8vtV6vjX2QrhdgJpOxuhsAFBgW2vVBPgQD7+d4+Cxj5uSrSqViBV793NZqNXO2uVzOmBP0js6r1ar1t1gsKpPJmLMFXJBuTCFiHPB0OjUACqMHE+kF5+KZslzuqnDteDzeqJdBIePBYCBJFhCePn2qdruti4sLdTodS29nzD4AbNv6Qfp5kiQGpvz71WpVBwcHGwVwS6WSbU/xxXs9aFytVlaQFzYlSRKNx+MNVhLdANQJUNgRaxbgTgAH7MGEAmpw0ui02Wwqn8/r4OBAe3t7BjBgvmezmc0bjB/t1+t1FYtFNZtNWxPci75ls1mzg9FopPl8bvU+YIWr1arm87nq9boBG/rH9hsYYWqNUDcGZhYg1Ww2jQ1k7WSzWbVaLS2XS52fn2u5XBp463Q6G8DAM/Fez57R3rbGtv3/YbIo/LoN2yUY+4Dur7/JV4SvYTv+HqF/9Oz0dDo1Vp51xPYRfx06I3ZQH4gtIlGiRIkS5dVKxPgR40sR40eMHzE+6yZi/NvF+PHh3w4IxuADGOm+oYHethDQYRowdtJXb3pq7w3eB2UMG1CA8RIE/OLzQdsvVGpFZLNZq4UAI9Vut5WmqdWLkK7ZxkwmYwG6Wq0aIxMyVDi5l3U2njli2wJsFoU7GWc2m1WtVlOSJCoWiyqVShoOh+p2u9YerA76h02FycMxFAoFKyxLP0ipxuE0m01zHlwnXQMCfuPcvfOBVW21WpJkqfedTsfamc1mOjs70/n5udrttgaDgdbr9QbQZb4BgeiB8WMfHhigS4DJwcGBFSWmVgpbEdANrBfgc7VaqdlsqlqtWqBsNpsbQarb7VobpF+vVisL1vSVsdJvwBh1VNbr61PEfM2LTCajRqOharWq/f19A9mSbFvBfD43BnA4HKpYLBpogMmE1fVzxZpI09TeG41GBiqoPZKmqQED2FlsyjPUaZqq3W6r0WhoMBjo8vLSgIFfR/V6fQN005+9vT1Np1N96UtfUr/fV7vdNlZwvb6uRcL6xPb89oAXXXvbWLrnvX/T572d+i8HnqkMA75n9BjHtj7wmXArANdyD+aBWklsDZC0kQHA9X6LETYUbiWJEiVKlCivViLGjxg/YvyI8SPGjxh/VzB+fPi3A4KzpmhnvV63CcaZ7JKw6F90qwILxwcmmARJ5phIkZauF5k/Th4d+boZOBdqFbA4isWi1U0YDAb2VNyzT+v11clR9XpdrVZLh4eHStNUw+HQ9tgvl0sLPD7Qe11sYwIk2Tj9KUs+yMHs1et1S/elCCwBZjabWXCiCLAkYxSq1apWq5UajcZG4MVhwKiQqk69jG63a+xzsVi0o9wZI0AC5w7ryP/T6dTYt3a7rfF4rNPTU61WK52dnVlgROcwRV7C06dgdJmjMKASRBuNxgZo88EIgMlWhF6vZ3VIsBnmnbnh6HnfjrdXPg876BmY1WqlyWSyYdNcU6/XJckYyCRJjLEtFAra29uz19gqAJPJXNKuLwY8n881Go0seAAymBts0W8twVZZE4ATArQH3ovFwnRL8EH/tO2BEWNuNpsb+qHOi0/99wwa9/RbAfgMOrhpG8CLiv8C4f3KTe9j/yELiPgg7K9hrmA0/b22MZeMP7z3er02/4A99Pt9q3XT6/WMuZVkW5vYtuFBmdcfDG+UKFGiRHm1EjF+xPgR40eMHzF+xPi7gvF3K+J8gwpGVa/XdffuXWPbeNruU2xvW/yiBhjclK7rxS82nLJPd6V+BAuOxQirQbo3wKBWq1l68mq10nA4tLapVwBbRtukicNAERgbjYb29/d1cnJiBYRh7Waz2Y2MZ+hswmtw5jBczWbTQADMTLVa1b1793R0dGTBH1aEeyRJosPDQwuM8/nctjpI13VDVqvN07n4n6BDTQm2SgwGA+vDeDzWZDLZ6rRhqylKjfODtaLex7vvvmvggs+Qyg5QQU/SdcDc399XrVYzJo75CevFVKtVnZyc2HYGz6jwPw6UIsRsRWi1WhsgGyYSB+zZbmorLJdLY5g9CKNwNaea+ULVjDGTyajVam3YCGn8OP7Dw0MDRWmaGlicTCa2lcMXKq5Wq6rX63aiGkwkPwQxdI8NsbVDugba9BWA5/WH/a1WK9XrddO3BzaLxcJAOXO1t7dnc7dYLNTv960vrEP/5QBwhT0ADD0b+FE/sPL27YXx43/8FxRfH8Z/qfCBHRtkTHzW32fb3x7M0ab/EoGtUReIujqAJ59hkM/nN4pJS7IaL5VK5SPVY5QoUaJEeTGJGD9i/IjxI8aPGD9i/F3B+B/5w7833nhD77zzzjOv//N//s/1n/7Tf9L3fM/36Ld/+7c33vun//Sf6pd/+Zc/6q58YoSnt5IMBJAG6gPTLkgul7MUehYSrN5NqbvbnszjQKTrI8xhJBg7bAQLhoKjnLgUsleedYJNob3BYKBut6uDgwOrmcDT8mq1qjt37uizn/2sxuOxvv71r1s79BVnEi5un8rLb5wfToTPksJN/REWfrPZtBR1mBfuzaKmWDE1RfxT//V6rSRJzJGu19fFYWHFSGvPZK4KI/s0fK7rdDqmS9qtVquWLj8YDGzMBM3pdGq1V9rttiTZNo+DgwNrbzgcajAYbNRaYYsE4yE4e9BIKjMBy+uTPsDcAkS41jNOnk0BsKVpqtFotHGCWJIk5tix8ZAl8kAkm81usIKFQsFYS8bBnLENg9cJ5vQZXdBnfAJbLviikKbpM18YGC+B3wcu7kUA90wXbBHBGEDpgzPAh3nydXrQSS6X02g0Mp34mjzMuz+tDADjvxCMRiPzd77/H4XvC/2DB5b+f8bj7+0ZWr+uQ6CLnXhw6O3HA4Cwb75f+Am+KNRqNdMTTHy/3zdgmySJ9vb27EQ6Pu/H7ccaJUqUKB9UIsZ/eYkYP2L8iPEjxo8YP2L8XcH4H/nDv9/7vd/beJL7x3/8x/obf+Nv6B/8g39gr/34j/+4fv7nf97+987wG1FwcplMxpwFThcWZ1ckn89rb29PtVpN0hXjAKP0fvv2MVKMl8WI8wAQwEDxxJvFCRNDLQxps1Co1x+ODMffbrf19OlTNRoNq38Be1gsFvXmm29qOp2q3W7rd3/3d63POFPvrMKF7Z0K45SuT0xDeHrPse8EgsPDQx0eHhoD4/VDsKFIMM6ZbSPhHn/6hoO/vLw0NpTASzo5rNB8PtfFxYUePnxorCLjbTQaOjw8tJoaOBgc+XA41Fe/+lUtl0sLQA8ePFC1WtX9+/dtLP1+X2dnZxv3rtfrajabFoiYMxww9gUDxT0AXwBFtgAQfGBCPWgdDodK09RO24LZYQsCrHGz2TQWrNFoGCikjzj5NE0t4E+nU7O9crmso6Mjs7F8Pq/j42Pb+pHP5zWbzTZADqfUYQ+MA1saj8fq9/vG5qVpurF1JGSBfeDHDrm3H89qtbJUcgA34AobQJ+NRsMKFsNAAUwIeGE9mMePH9uWA7ZOrFbPFoTudrvGGvrtAB/1lyHfHn1AH36rwLZ+eKAHaAVc8kXgJpaQ98O+cD3vA1g5RQ1mkC1OFxcXxgxOJhM7IXB/f9++QGB3HtTGh39RokT5qCRi/JeXiPEjxo8YP2L8iPEjxt8VjP+RP/w7Ojra+P/f/bt/p7feekt/7a/9NXsNFibKlWBE6/XaTnPCYDHSXWEFpc1aAzho2IjnCYbpnTYOmSLApVLJUuhhrtDDYrHQZDLRer1Wv983ZkG63qcfnrZEYLi8vFSlUtGdO3fUaDQ20rclqdFo6N69e/Z0XdJGertnFbal+vqn/gjj5H3YlTt37iiTuS6GTEDwtR/oH6+F4AOb8QFAkv2fzWatTgigU7o+rcnP4XQ6NRaCOQGkeaCB7gENBGTSlEnxPzk5UaPR0MHBgSTpvffe29iqwHg4lczXg+B+udxVMVxYEm9r4/HYighTBJk+d7tdq2/BfABiAAKAq0qlYtszmGOfak2Bae7r+5PNZjdA1nq9ti0FnPC1XC6Vy+U2Tm1jPtM0NbtnLhkbumDOAay8xtzBaIfbM9ChD0rz+dxYJM9WE4hgyCuVygagYs5Yi+v12sYc1tbx9WQmk4kGg4FlNiwWC/V6PWNAV6uVOp3ORq0QdB+urQ8qPhiGDGPI6DMWv3bC7QF8BgBMwWWfBeD/Zy367T1pmhow9NkePoDj/7HP1eqqODlfinzGyHA4VD6fV7vdNtC7Wq2MmQ+ZyShRokT5MBIx/stLxPgR40eMHzF+xPgR4+8Kxv9Ya/7N53P96q/+qn7qp35qw6n92q/9mn71V39Vd+7c0Q/+4A/qZ3/2Z5/LDPqn5JLU7/c/zm6/csEYVqurAqrs78c5EjRvW3xKqzdo2MuQLfPiFykOGrZjOBxqNpupUqmoXC6rVqsZI8NJR2w5GAwGFqD86UP0D1aNI8Z5cv7OO+9oPB4bMMCpIicnJ0qSRH/wB3+ger1upy/hAAk0nhXywWTbU/ewlgFFc19//XVJUq1WM4aV49NxCLA+nkG56bf/24MT2COCECwQ6cWkZ8OAoat+v2/sQ7/fV7fbNUfGceQ4R4IWAaZareqzn/2sDg4OVKvVNJvN9PnPf16j0cgYSJwwTBQsFAEXILBarQw8+P/Z4gFjS82V1WqlbrdrAAMHD2CYz+emq+l0qiRJdHx8rHq9vhEEcKywefl83hhpTo5ja8dkMtHe3p4561KppLt379r4MpmM9vf3LZU/k8lYWv7FxcUG2EA/CIV4B4OB3nvvPdVqNQNCAJvDw0Ot12sLsOfn58bm+WBDPRgYPWxuf3/fWPb1em3AZTwe25pmvfo1y9ojAHrWD4BzeXlprOJyudT5+bmm06k6nY6154MV9wqD+QcRxo1vYK36H64D5MHK+S01/NAfmHUYetr2aw5/wPseGACsGDt259d0sVhUtVo1Jhabg7Xt9/sajUamZxhzTv+r1+sb/pN+Pc8/R4kSJcrLSsT4LyYR40eMHzF+xPgR40eMvysY/2N9+Pcbv/Eb6na7+kf/6B/Za//wH/5DfepTn9K9e/f0+c9/Xv/6X/9rfelLX9J//+///cZ2fuEXfkE/93M/93F29VbFGybOwBetxcHdtoRP2cPF7dNin9cGQvo/T7j9qUO+bgL/UwxYut4KkKapBVMcJCwI/SOQFItFOyGq0Whs9IdFRLAmeHimKHz678FR6Gz8QvTAbrFY6OzsbKOAK2nW0jW7CWtDmyHjuO1Jv08B9vPlGTKK8hI42e6QJIkajYY5lUzmujAs6doAwMFgYG1xDXUwkiSxQHF+fq7RaKTLy0sLzNwX+5Fk+mXupWdrJuC0GQ9Bi7oInLrFHFE0GhYFlo4C1sPh0O4JE5/NZs1eAJUwewB17ARGKJvNGjO3XC4N4AHGJJkTZ174ksMJdZ5Zy2azxqLBKp+enqrb7Vp6PVIulzdsdDqd6vT01NhB6fpUMvpP2vjJyYmBT0BVmqYb23D85/z2JBgz5g+d+cLbBCuuAxx4P+Zt2K+XjyIDAtvH7kOwwfry/ghfgr2hV89W+pogfltByF7j06VrYMC64MtOr9ezLz1eB56RZQsFLHWz2TQ/B2PLlpdsNms1fVqtloFaz45HiRIlykclEeO/mESMHzF+xPgR40eMHzH+rmD8j/Xh33/+z/9Z3//936979+7Zaz/xEz9hf3/7t3+77t69q+/93u/VV7/6Vb311ltb2/npn/5p/dRP/ZT93+/39dprr318HX/FQiputVq13xwJz7Hft80MhguNNGsCcZiaHopnKPiZz+dWC4B0V7YD+JT9QqFgqds4qcvLS61WK7XbbeXzeR0dHalcLqvdbiubzWowGNjpOZPJxOpinJ2d6eDgwPbQMzbaPj4+1mc+8xm99957xlZ6Z+xrckibhZw9OwgDQGCdz+caDAbKZDL6whe+oCdPnti48/mrU55qtZoFQJ9e7J1b6OC4t58fDwR4nXRunHEulzPGI5PJmMOivYuLC63Xaw2HQ0uzRx+9Xs/mk+BRrVZ19+5d7e/vK5u9KpD7xS9+Ue12W3/6p3+qy8tLO60MlpUAQmDM5XKqVquWBYDjxTESkCeTidUiubi4UKlU0p07dzZO8trb29NyudTl5aUkWZ8pTLteX9VY6Ha7KhaLOjo6smPsJRloo18w1iEwzmSuT/zyQZgaN6TxA3ozmettPqTIk8rN5y8uLtTtdtVut9XpdOxEMwIVQY3tB9jkZDLRw4cPjbkl0PttJaytb/u2b9P+/r663e7G2j04ONioHVKv1+30sX6/b7U9CEgEzel0anbS6XRsCwVMog92bPNhzXiQ7/3Ei/olfm8Dyj6Qh/7Irw8+S5FlQCo6x48g2AV1XijK67dK+M8zX9ToGY/Heu+99zQejw0gcB1rbTwem99jqwbAc7FYaDgcGpPP7/l8rv39fasnwhYQSRuMc5QoUaJ8WIkY/8UkYvyI8SPGjxg/YvyI8XcF439sD//eeecd/dZv/dZz2T5J+u7v/m5J0le+8pUbgQE1Iv68in8inKappfTieF50kbwK8Q7Q7+1/Xs2S8Ml72BYLd1sxWNiSkOliMZP+3e/3NZvNzMHilLyDIoW23++r3+/bovOnL5EuDXvin6SH8xRujQgZOP+eZzzG47EymYzOzs6MueI9ArhnBrfN/zYn6HV0k74BDgRnAgDBA+a1UqmoVCoZ+xA67rAvtJ+mqdrtttbrtU5PT9Vut61QL/PIPDebTXOWq9XKWAyCKSwcwdSzS5nMVcp1rVZTuVxWq9WyYrzFYlGtVkvL5VJ7e3sbbAlz7etXzOdzmwPYPcASgIC58GOmnoNniwG8MN3L5fUpZN5BExCZA9qBTQUcAJwpZhwyThSzJosAnfr+AWIABtLmSXmMeb1eK5/Pa7FYWHv0k5PcAFY+7R0QjC1zAhwsGJ+5vLy0lPbFYmEFjj37fZN9ewl9gbe9kE2m/RAgeP8SMnuAAs9EMzY+BxgjaIcFuwGIHrCz7SKbzWo0GtnWNmrAYH8UQx8Oh5apgD+AHaROiLcL2OzxeKzxeGzgn7W+C5klUaJE+fMhEeO/uESMHzE+70WMHzF+xPgR4982xv/YHv79yq/8io6Pj/W3//bffu51f/iHfyhJunv37sfVlZ2X1eq6mCeptRcXF5bmGaaH35Z4A/fsDDUawv5tc6YEGBZbmI7Mk2zfhg/A/O3TqCn2iyMrlUq2T57fBJXz83Njl6bTqQ4ODtRsNg045HI5nZycaDgcKkkSSVcL16cFhwDBjy8ELn7cBLlOp6NOp6PJZKKvfe1reuedd3Tv3j1927d9m771W79Vh4eHxnIBiD1z4++Njj2I8E6V3zhEzzbi2AkCuVxOtVpNx8fH5tB9TQgcLKzoNnucTqf6whe+oPF4rD/6oz/SYDDQcDg0p5TNZs2xfed3fqfu3bunTqej4XBo7Ab3I9BnMhkNBgMVCgX1ej2bp3q9bizWa6+9ZqCAmgjcE10Xi0VzpAS3wWBgzG2lUlG9XrffHK9OzQ22o3jwzjYDD/zW66vaKZxud35+buDH2xNp2xTbRQ/vvPOOHj9+bKwpfgEhWHiGjfoRd+7c0WKx0OXlpSaTycZpXGmaGnsFC93r9SwIzWYzXVxcbLCrgA7WOlslCJQwk5lMxooew9DDlsLOf+1rX1Ov19O7775rvwEJ3lafBwhCUOBrAREcPUAgEMP6cwocQMAX5M1kMgaIed//z2ueGeZz6BW9sE2JjAZ83Xq91vn5uem7XC6bPQDSut2uFdgejUY6OjrS/v6+crmcGo2G2VE+nzcmkLorgI3z83MtFgsdHByoUChovV7v1ImSUaJE+WRLxPgvLhHjR4wfMX7E+BHjR4y/Kxj/Y3n4t16v9Su/8iv60R/9UdsjLUlf/epX9eu//uv6gR/4AR0cHOjzn/+8/uW//Jf6q3/1r+o7vuM7Po6ufGLEGxmOhWAVBqDbEgIQjI1nmW7qn2eRtgVRFilHX/sTh1i4sCW+cCZshHfSsBCerYTtAxhQ16Db7Vr7BCMYO1ghtmOENSrCugUhUxbqgqDKmPy9pKtFnKap6vW6OYr1eq1araZWq7WRLo6+b7oX8+QBDCwg70nXjhTmzbcPYwQ74kEYYMTfF9BB4OB0MAIboAqnSsBn+wvsEKAYkMz8UN+iXC4bu0j/Go3Ghp4IAEmSaLlcql6vW52OsMYDbeM06Zu3P9LdPWMNIwc7RyACbBDsut3uRp0Mgriv/5DJZExP3W7XGGsKxnrW3bNazCk6rFarBvJWq5UB3/V6rfF4rHa7bQGF34yXPgHIACPT6dTGC7jwrCk2gL0QeGHFWK/4MdYtgJe/c7mcrfEX8XMefHvWjb74NRcy2PgbUuV9fOJLT1iLCP+Eb8L3+DVIcXFsgs/wOusMgLlerw1YcT9ADQzhZDKxwsuwj74tvzbpB1kQw+FQuVxOo9HIPh8lSpQoH4VEjP/yEjF+xPgR40eMHzF+xPi7gPE/lod/v/Vbv6V3331XP/ZjP7bxerFY1G/91m/pF3/xFzUajfTaa6/ph37oh/QzP/MzH0c3PjHin2IT3IbDoTlYX4/itgSDhzEgddinM4fC4gwXuwcSuVzOjk0/OjrS3t6epW1z7Wq1eialPEkS+5vUbZ7wz+dzYytxuoPBwJ64J0liJ0n5uivFYlEPHz40h16r1STJiqD6FGsvnqmQNh0vgICxsIgl2SlbT58+VS6X05e//GX97u/+rt566y198zd/s15//XV9y7d8i5rNpo6Pj80p+XvRtneOXsf0OWSXfd2LNE3NeeCkuBdMLQyXD/B+68Z6vdbXv/51SbLaK7CBngnOZrNqNpvG5lUqFSuM+vTpU7XbbbOnUqmkSqWi8XhstTUAT0mSqFar6d69e2o0GnrjjTdsDPSPwMpx6hTUHY/HNp8EQ+mqSC96Ojw81P7+vtlMp9PRu+++q3q9rqOjIyVJosPDQwuIs9lMZ2dnmk6nevvttzUej3V+fm5ASZIODw+tjzj2fD5vxX5hBXu9nvr9/gbwRt++tke1WtUbb7yhWq2mo6MjW5+eFT09PVW/39f/+3//T4PBwNLFsdGDgwNjg8fjsfUFm/drGXuBqYXpgsmv1WpmX2Q2UIgb9pTtBrCSrG/ACf16HkDwX1AAW8w5J67hPyQZSKHP9NWDPdrBprELAnetVrPaKM1m08ANtgrzSJYCoAvw5tuEDT4+PpYkY4DZ7gLDt1qtjNEeDAa6d++ebenwTD72kKbpBnhrNpuqVquq1+t68ODBRmZBlChRonxQiRj/5SRi/IjxI8aPGD9i/IjxdwXjfywP//7m3/ybWyf2tdde02//9m9/HLf8RIs3bO+U2ce9C4ygF880hWn/267d9mTeL8ZtbCMLDseBDvz9cAQAAwIBdT8mk4nVVYHd89dkMld1Jth3XywW1e/37T3ABg4A9mIbCHre+PntP5fJZGxcsMD9ft8cCSebVatVK7ALM4BDDvW7TdfcyzOE0nXdC98/z5Sho7Aeit8ewL0AsxwDDwvGvUMGZT6fG+ORz+eNDWO+PNhYrVbWPv3xfQoDJoyN1204F+HWDj822LDRaKRer2d98EKdGBiaXC5nzFuv17MAjy0xJphB+j2fz5XNZi0I++BL4Mrn85by7VlVAhNriPmazWYqFotmH4ArGFVfg2I0Gm2wcowVptwXv/U+CfaeterT8AnKsKJsjYCd50uPBwF+Lv0XidCWt/2P7wjrfQCguQ5dohv8DWMCAHgwv16vjWlNksS2iVQqlQ0dS9dsI4wsDKjvG+Jt1c+ht1MP6ieTiQqFggaDgZIksdMTYSPTNDVQAthl60av19uYoyhRokT5sBIx/stJxPgR40eMHzF+xPgR42OLt43xP9bTfqO8mORyOXvaDuPRarXUarU2mJxdEIwOo/QszE19DBc6TBP1G3DIHmywMD0zQXCkH7nc1clRaXpVUHU0GumrX/2q+v2+Hj16ZM6Pawm+nNyTz+d1dnZmDAz3wFH4o9IHg4Glqof76kPw5lN0EYJVyBj6wNnr9TQYDHR2dqYvfvGLOjo60uuvv64HDx7oO7/zO63eQ6PR0GuvvWbOyQMDwAE/gMswwE0mk43gTzDsdru6uLhQp9NRr9czJw4jyLV+rDjI4XBorAj2IcmYQRwXRYJPT0836mCgH9gOnJ4kC6iLxWJj64cHMt7BwqZTwNafWuXnxOuO+iDUx3j33Xc3mPBaraaLiwu98847ajabarfb9vl+v68vfvGLGg6HevTo0QYwIkUcp01goEAxJ2zBTFMLBsb68vJST58+Nd2WSiUlSaJGo6FM5mpLQbvdNja8WCzqwYMHqlQq2tvbU7FYVKPR0Hq91sOHDzUej/X1r39d3W5Xb731llqtls03NtjtdtXr9ayve3t72tvb09HRkR48eGCBa72+qm8xmUx0fn5u7N9sNlOn07ET0TyYZJ6w1xBo+7XIWiJYe5bZb18h8BNofe0WPp/P59VqtZTL5aw+Cj7s5OTE6nb4rUjMHacH+m0C3jb8GqeIu6/D4bcF0W6tVtNsNtv4guSFtUl9EHSMbmAY2QbACXBsA1kul/r617+uvb09Y3+jRIkSJcqrlYjxI8aXIsaPGD9ifO8nIsa/PYwfH/7tmLBItj1N3jXxi/pFwAtBy7NLfitEuLedQMFixAFIMrYIY2eB8j8BHEdCAKGugXSlYxYUTodT5wAHq9XKCq8ShAl8N43vea95HfjXvePD6cJaZDJXR803Gg0tFgs7+p1ghZPyLEcIFsLtDKQg80MAZZsCNSlgIHy9CM+oMU+Snkmx92P0Y/UMhU/R9zYFoAl1BwAADPi6B9hEmqYaDod2nDrj4B5+6wSC42YMOHkCB2nf2BI1RujfYDBQu902QALA4V78Xq/Xxk55G4JpymazdhId2x5gokajkUaj0Qbg80zsfD5Xt9tVsVi0LQFJkmww6vQBpmk0GlntEMblGT7uBRih9gg2Qb2T0WhkW0Fg4nu9ntVyYR3Davq1flMdkBA8exaQQO/9ht8mwD38GGA0AZar1WrjCxnMoP9iAgNK3Rn6hX/GPratbYABP75d7AMb2ebn/dplzXqG09czwV+EjDrz3O/3N5jSKFGiRIny6iVi/IjxI8aPGD9i/IjxbxPjx4d/OyAsxMlkom63K0lWzBRjD5+c34bwJJ7AifNlkYTs2E1t4MxY1Ht7e2q1WhbkSBknPbtarVrNEJw0adb8UJPg+PhYxWJRjx49knTtXGAyLy4ulMlkdHh4aE//SYEej8dWq2Bvb0/NZlNJkmh/f1/tdluSLGDiOJHnsRwePG1zAH4cPq338vJSg8FADx8+1Be+8AWr+0AdjHq9rtdff91OY4LJLJVKlq6OcxwOh8aipelVIeLFYqGLiwv1+32dn5+r3W7r8ePHevz4sUajkTGCBB0AlAcEHgTg4NHLfD7fGJ8Hfb5OCYwj13KN/wxs0+XlparVqpbLpXq9ns7Pz1Wv1zUajWz7hCQ7cv7s7MyYOlg8to94IMO8+ft7VjqXy+ny8lKr1crqPXzxi1+0OYQt9SymrwfhnXKj0VCz2dTh4aGq1aqSJNkovIzd1et11Wo1C7zvvvuu/uRP/kSXl5d69913NRwOjSUC1HQ6HSu0i558PQwCWb/f13g8VpqmG7YCyGNbAj/379/Xpz71KTslrdPpGHMIA396emo69aCOv3nd1/zwIMT/+LXha6eEXxC8ECgLhYJtnWEO8C3UMuFUrsPDQyVJYusHYI0+7ty5o4ODg4159ltp6JNf5xSyBmRwoiCfheGrVqu2LSPcFuCFgtBpenWCHaCRueRLD+ALfbP9Yrlc6otf/OJOf8mMEiVKlD+vEjF+xPgR40eMHzF+xPjb5DYwfnz4twMSMiwY9/HufAABAABJREFUkE+jvW3xCxYH9iJAYJswPlJZpevilgChkDHzqb9sIeA9/z5p8tRMkK4ZH5z3cDhUvV634psEKuo1EPAAQaVSSbPZTLVazVLSvUN7GQnZ0+fNLSnBsJmcDpUkiebzuer1utbrtR25TsArl8uq1+vmJDOZjPr9vo13vb4+7en8/FzdbleXl5fqdrtqt9vqdDpWSJlaKvSFvvvfYV0HxLNRBHlAZMjMeWDlfzyrAlCUtJFGjS6ooZKmqRX+HQwGBmC31UQIgxG/vZMN16U/yStsC5shLZ3CvKTll8tlHRwcqNVqGTCgGDVBr9lsWu2JJEk0m82MPa3ValZnBFuWrlhxv12FWh7j8Xgj4DMX6HQymShN040T+BgH6401QB0N7sOWm7DIMIHppjoXBFAPKv3v0C78GifQ+61BSJiqDzBgDGQOAKLSNDW7ARQADPhN0WKfXeBt1fvCkLX09u7Fv+63R9wk6Ax2kHo0IYjxX9D4HEB2OBzuRByJEiVKlG80iRg/YvxtEjF+xPgR40eMfxsYPz782wFhAnlanaaper2exuOxGTuB8Db7iGFy4g9sEe+/aJDEeVA/Yn9/X6VSyY6GJ013Op0aU+ef+OO0ccKSjPWD1bt//76azaYFNWoTdDodO5nJ1y6QNp0mhVUrlYoajYY5zSRJ1G63LXASMNL0+nStkOFCfPs4Xx8g0SEOA4dAcOZErFwup69//eu2LSCfzxsrii739/dVLpe1v79vqd/+WHnu1+v1NBqN1O/3bUsAx9j7AEhQxEEzHs+mhePHWeLMkySxuc3n8xawPegglZltAbArMHSDwcBYH14rlUo6PT21uffAEsc4Go2swO22QrTedrF1/xpj9fUofFAibb5UKlltibfeekuNRkOf/vSnVavVdHx8rEqlYnNEQLi8vNRoNLIaOY1Gw3RFuwQAnPzjx4+NqcXW0jQ18EMNFOk6YHpbBUBj/wRG5gP9sy4zmYym06nVWGm32xvMJPbC/Xy6On3y6erbvvSEICIEi9nsdUHsWq1mOvG1Y+h3kiQbuuM3IO34+FiFQkGtVst8LveAOeYLBl8SPFCi73594KMrlYrZrR8/a4858HViPDO+TbBJv7WC7SN+7gDKnvGez+fGHkeJEiVKlFcrEeNHjO91GDF+xPgR40eMH9rnq8T48eHfjggLAQPGeG7aK34b4gOX79fLsoM+APjUcB8o2QbBCV4hixTqxbOoOIZsNmuLZDQaWQ0D2EF/YpWkjSf0gAOe/JdKJdXrdU0mE0snxhF8mO0a3rnc9Dq6gtnMZDIaj8cbbCjOodfrqVQq2W8CKQwfDgjHNhgMNJlMNBwOLfWc4EBRU8aIg/ROfhvLyTXMkS+a6k+5Qr/Uj2Bs2IivB+PHj/NfLpcGLmB/cLa+VgQsFo7Vp6Bvs01/f29jniXcNuZKpWLbEijY3Gw29alPfUr1el3Hx8cbNVzoU7vd3gBHjBtbZS7YtkJKOfPp5wFbYcvMZDKxuiXMu2e7/dHzPhvBr0/uTW2Vbre7cXob9U+wD8/sb9PXTb7CA4UQOHuw7dlBf5IXuvNAgC8V/I2dABCSJFGpVLJ1Qb99XaBtc81vzxSGbGC4hsOtD9vs7nkSghDv8zwjyvpAb2ma3ljDKEqUKFGifPwSMX7E+De9HjF+xPgR40eM/yoxfnz4twOCE6jVanrrrbfM4VWrVZXLZVuYt/nlLXQ6gJfnOdmbBGOWNlP6peuilixughALkIKYxWJRq9VKvV7PAj0s33q91snJid1rsVhoPB4bMJjNZrq4uNB8PjcGplwuK5vNmtMtlUq2Vz9NU5XLZb322msqFAp65513NBwOrXYJxU63pZyHzEHIfPhtBfz2oCTcdhDqmjYJBP1+X9lsVo8fP7YAkM1mrT2Cj7+XZ7vCgrB+DDfZBe0wr56JyefzG6xvPp/X3t6eSqWSms2mJpOJzs7O7LQj5s8zGoALalHw93g8troW7777rjlA6bqYdqPRUDZ7dZIbzJW325v0yti9g+czPoARcJrNpr71W79V+/v7+o7v+A4dHBzo27/92421AcBhy6vV1QlPw+FQb7/9ts7Pz40RZzsL9xwOh+r1evrqV7+q//t//6/6/b56vZ7NjWfg6LtnXP39CYSAlfPzc41GI52fn5tNZ7NZKwJ9cXEhScaQASJ8sW3ANeuY0/kmk4mN1YNJ9IweeZ36GQA6+gwbWa1WN1L+C4WCBXC2wGDv6A+gAEuIblutlp266Iv5AjTYQoBQ+LhUKqlSqZjPZlzYmqQNRpn36RP+k+0Y+PXwi8/zxNvwarVSpVJRq9UyO5zP58Yg9/t9W0tRokSJEuXVS8T4EePzP32OGD9i/IjxI8bfJq8C48eHfzsgOACYhdlstlEc9GWM5uOWNE03ggyL/oO0I107Nun69BqchXd4/sm6rwvCIvEFM6XrtFzahDXDmZFOTQo5DoETr2BpWICkIlO/gSBEUJY2HcL7jZu/vQPZ9l54zU3t8RuGgvTgkB0I2/SOmaCFE3kek3NTX8K5gw2EEfT1JSqVijKZjL0PKPHp+swffWJdMF9cw/wTjCTZ+wA4bx9+3NskdOwewPrPUWC2Vqvp5ORER0dHevDggQ4PD/XgwYON4+hhnmDzBoOBer2e2u22Li8vn2G6mIter6dOp6OHDx/q7OzM2ET6E84ndsBvzxyiP04ZAzCxlvBDrA8CP/PpgYAH+F5CJjkMSttsx+sXRtdvg0DwFVzPtRTGpbAxW2qo30NxYNr0NU7ws+gHAAFz7UEzYCEE+gBirvXj9iDSC/7Fj+dFxDN9k8nEbEWSjRt2ECY7SpQoUaLcjkSMHzF+xPgR40eMHzH+i8irwPjx4d8OCEY3Go309OnTjYK2L2MwH6d4JwQjASPzQcHBNkEXLFT24+O8KNgL08FC5fpqtWqLFAc3n8/tNJ9Hjx5ZkODpOWxVPp83VsrXnqDmAifwfO5zn9NgMNB7772nyWRigYdjz70+bmJMCcLhezg+HEbo8P3n/fu85kEkjnHbdfy8iOP2ffAOEUfngQDtekaGa+lbp9PZsGtOYYIlI92ZIrj8jWPO5XIaj8daLpe2TrCdUqlkaylNr04880GGewIafZDdNnaAebVatbowbAnBAbdaLd2/f1/f8z3fo729Pd2/f98KzHpwenFxoclkYvU//uAP/kBPnjzR22+/rXa7vTEPPojMZjPbDtDr9TYYWJw/nwFsIdybwriclEaQx/5brZZyuevT/WazmQEFD8q3gZCQpabeTshA+8+EduVfo6+s6UqlYsHcs9ieCfU2R30czy62Wq0Nv4F/4IsOWwS2teeL8LI9BSaP9gEXsH7ojHnhywcADD/GZz04eRFfytoejUYG/gA0ntFmvZCx4LdARYkSJUqUj18ixr+WiPEjxo8YP2L8iPGfLx83xo8P/3ZEmDRO8GFh7Ir4oAMb5k/S+iDAIAQ9nh2FjfHBByfn9eIXJowhgCKTuTrxB+dHSrFvizZgmjxDCahYLBaWYpzP582JdrtdS58mWPFZxvM8QW+eWcAxhGyfd8JebzeBDl4P+xKyKs/r5/s5dP8eDA269dfj8Pgs4AtGhvRuz07xN+nTgENYGl941o8Z+6BQMzUTfK0GnLrvW6h7r3ccLAViK5WKrVdO9jo8PNTdu3fVbDbVbDbN/nDgsICDwUDn5+fq9Xp699139fDhQz169EjdbtfGFtqDLxYLiAnnmHH7bQf8pi3Akc80IE0dQAXQ37bdx7O1YR+8bRB8bgIFoS2FoNdvC4Cpw77ot287BMPYhbetJEmMofYAkbR+vmR4sM490CWfC5nlMHPDgyg/Zg+SPRAIQeuLCvaA8CUpXHv8/qi+vEWJEiVKlJeTiPEjxo8YP2L8iPEjxn9R+Tgxfnz4twPijRJmKU1TK9AKK3WbggHjICXZU20WR8guvUibLA7PPhCQuRdshy8cTBo+DoQn+j4ArddrAwykDHsWyRfUzGazVrOC9PTLy0ut12s7ip3PUVvg/v37ms1marVaxjyOx2Odnp5aDYMX0UnIqrzfNV5vpAB7B4GOQnDAZ3G26NGDh+c5/HDuEJ+i7FlWAiQOixRzTmWjNgXH3gO6COiDwUDdbtccLUGZQMgcY5c4ctgt33eARMhgo29S5Qni6MCzZq+//rrpZzabqd/v26lSe3t7Bkxg06hB884776jX6+lP/uRP1G639ejRIw0GA52enmowGGg8HhuTFM6znwsfaML5YG3AgnJC3mKxMFvI5XJqNpsb240ODg4MdKGL9zuVKrQB3xd04MUHwG2g1dskffMgxmcA+GLPnCrHlygPjPx6IBBjh9QPQie53FVhaX/yXRi4+bz3ddgSQIq1BNvK1iH8uQe5mUxGSZKo2Wxa3adQP+8n2L8H0X77BO+jg/jwL0qUKFFevUSMHzE+EjF+xPjhXEWMHzH+Nvk4MX58+LcDAiuFEREYYUc+ypT7D9tP+sr/IbP3srKNbWLxeAYHdpB7hgvfP3GXZMCB9n3qrd/THz71xwEtFgs7Lcyn/fvPNxoNLRYL5fN5K8ZbqVQsbZsAsU22zedNLNxNemM+cE7bWMabWEPvRLe9/7x+hn328+YBJE7bs2MUT4ZBXa1WFqzQKzrzjpwUalKefe0Kv34YVy6X22AnfdDbBoD4HKybZ3UAB/V63WyT9ggA1IKgpgkM/3g81jvvvKPLy0t98Ytf1OXlpR49eqThcGjbGny9k21zwXyFevdzzP+MD73TJ94vl8sbx94DdingjK4+jL/ZBm68vYVAIrzGM7jYkmeQfao/IAI7YL79VgjuwVrBFgGbudxmYXM+7/vlgYHXO/YAQ+e/kABWmROu4/N8UQHsfBA/6n0YgCVkBbHhXYghUaJEifKNJhHjX0nE+BHj044UMT5zETF+xPjP0/XHgfHjw78dkEKhYMVE33rrLUlXqaqwVNRDuE1wALNC+rBnKj6osPB88OaEL2pBzGYzq8HANdL21HbfHxYajpGiv+PxeCO1OJPJqNvt2pP91WqlJEnMqQCC6BuLmL8BC5wSNJvNlM1mNRqN9O6772o0GmkymTyzD/95T/99ICBI+cDhmQicXRhYbgo03gGiH39f/9nnza1nf2gLJ0VwHQwGBuI8i0JABFTB6rZaLWMIG42GJpOJRqOR1cNgnMzpeDy2GhtnZ2cbxYSZJ/rG34PBYCtgY3uLD9Ke9RoOh3r06JGBkuVyaQWXLy4utFwu9ZWvfMUKyM5mMzsx7p133rHTtqbTqcbj8QYj/Tw7CIHNTeAR3dA3D9JWq5VtOYD19qCQbASvm/A+LwNaucZv52FbBYH+piDt11i1Wt04Gc3P6Xq9VqVS0dHRkemHMdE/mH5OMJNkgImgTZFwCjHTJw9OCLgwieE48QOckJgkiSRpPB7bnEjX4AumNgQ67wfo309Cmw7tYxe+XEaJEiXKN5pEjB8xfvhexPgR40eMHzH+y8hHifHjw78dEFJ4a7Wajo6OrLAsi4EFdpvimSfS7Hn9g8g25+JTuyUZQMCR4Fx8GzcBAwIrQZWFD7ODUDjWs1LeUXjGwZ/UJMkWNtsXSF8GXFxeXlqQeL+xh+97Fsg7UcZI3YgQoG1jXbzQzk3MzIs6kLA/OFP+9kVRh8PhRh0L2BOCME6y0Wjo6OhIx8fHOjo6MhZxPB5rNBppsVjYSV+LxUL9ft8YF19DBBv1OikWi9aXsP+h/raNdTqdWnD1/Z9MJhoOh8pkMnr69KkkqdfraTgc6gtf+IJ6vd7G6V3b9L9NvF1vu35bEPE6ZU5hsmBhqTfE67BZvvDyi/bR9+UmJtD/D4tHkWQE4Py8lH9ep34JhaDr9bql+IdzByAEHHmdYR8+MHtWzYMLbNbrhvF4gEURc7Z3AYB9m/7HM6U+w+LDfNnatv0n/AIQJUqUKFFenUSMfyUR41+/HzF+xPgR40eM/7LyUWH8+PBvB2SxWGg4HGq1Wtnx9ePx2OofUHz3wxjMhxW/yKTrU2YIiC/CFCAswkqlonq9bqfyLBYLc2A+bT+TyVitCe7PYsPBURMgdJKkkGezWS2XS6vdwN55WLtSqWQsRLVa1Xq91ltvvaWjoyN95jOfUalUUpIkmk6nOj8/tyDFPdANWwkkqdVqWd8BKD4Ih/q9KSWZ9xkXss1587nnBbpQtrUdfm6b7XkHmc/n7TQlxu2PmF+v1zZ3rVZLxWJRR0dHqtfrevDgge7cuaNqtSpJ6na7Gyd4TadTjUajDZBwfn6u0Wikdrut4XCowWBgzA92kcvl1Gg0bD3BaGNrYRD1Ng5rCftHvQivd2p/wLY9evRIaZpafY+nT59awA3T7J+nXwLF89b7TeCPdrEDxnl6eqpCoaDhcGgMu3TNEg8GA9v+4nXi59n3LbwfduCDHcx8qNtarbaRBs/rrCP+528fSDOZjGq1mvkOTv6r1WqSrrd2JEmyAUJgk3mfMfKDnmCpmddwnvB5tIf+KDqOzv22Jg/CuBYWE7DjMxU+KknTzWyB24wfUaJEifKNKhHjR4wfMX7E+P69iPEjxv+w8mEwfnz4twNC7YDlcmmBDIMpl8sWLG9T/ML3TI5fuC8qLM5isahKpWJp9zzdh5XDsNN083QhaTMAhk//eV+6PhGI+5bLZUmyQsur1cpO+mJrBoGrWq3q7t27+pZv+Ra7V7fbVafTMcYKBsqPi9oQlUpFq9VV8VufbhyyA17C1O/nAYObxF9zk7O5KdDfJNuAKWPB+dXrdSucK8mK4XoHnM1mlSSJkiTRwcGBGo2GDg8Ptb+/b2Mcj8fqdruqVCqqVqtWlwUg1+129ejRI83ncw2HQwN3OH5sk3vlcjljvHDSIaPJOFh32I93/PP5fIM9gvmkXszFxYXSNLV70Sd/j1Cn2/Tv7eL95vum97kn4yANfTqd2rYFwI2fH1gs3z/fTw8M/JhgzbEFdBkCCdYgjF8+n98ACp6JD8eCVCoV7e/v2/YG1h3Xsp2AwOvnkf4wh+iIIE9wD9l877PYYkCbHgRI14WZAcN8yUG3HnjR7getB/J+ctPWoChRokSJ8mokYvyI8ZGI8SPGjxg/YvyPSj4oxo8P/3ZAMMzxeKynT59asKIgcFhL4jbEMy3S9elPLIAPYoAEdIJwqVQyxoIU3nK5bI6ZxeyFRchWAhyIX+g4Ia6HHZKuTqfytVdarZbu3Lmj/f193b9/X81mU3fu3LFg0mg0JF2lfX/1q1/dODXJb2eYTqcaDAYqFApqt9sWKLyDwwniKDn1jZRnaTOF/0VAQRhQYFLCGg/P+6x3UDcxWT6QcpJRo9GwornooFwuK03TDVaXmh97e3u2RaPf72s8Hlu9jPF4vOG0vVOdTqfq9Xp2GtdsNrN5AID5+i5+XJ7FDMEOWw24Z6h/H1iwXcZGyrhn5bz+s9msqtWqCoWCWq2WSqWS2d5gMLC/w3l/v/nyW1+2STi+6XS6ERRDdpHXCZ4hePX39EDY1/nwv2GLYehyuZyd7ue32uAHWA8U5F4sFlbAeDabmU0BJugHvokf/medE7jpu2eE6RP+h74VCgUDeduCNuvKgw4/d36MXgCnfGkB4NDnF13rUaJEiRJl9yVi/IjxI8aPGD9i/IjxdwXjx4d/OyA4svF4rMvLS3NaOJtdAAZ+oSP+CfcHMWQcNEGZff8EAt7zzt0zJ7AYnt3gOl9rwtf3mEwmVmNEuq79wU+tVtPBwYFee+01ffM3f7OKxaIV95SkWq2mTOaqAOyTJ0/MoUubhUZns5kuLy+Vpqkqlcozjp/xFwoFVatVS21er9dbweBN+r2JafKsA+2+iISMlA+e4d8waACDWq2mcrmsJEm0Xq9Vr9dVKBQ0nU430sVrtZoajYbq9bpqtZrW67WGw6Ha7bZ6vZ56vZ76/b6dpBXqi/mmbg7p+378gILQNnHSsIY+QHhAsS1o+jYAnNgqbCCBzuuTAFCv11WpVPT6668rSRIb4+npqc1RWHPCtxPaACDHM5zPAwj0MWwjvI7XPagJbYN7F4tF1ev1DVYQdo+1dXJyYrU7tmUR8L9nCUulkgFlbGU0Gqnf79sXCd8XfJOvNQIw8LrzQMqn9GPH+AmuxSaex9iFLKr/f9tY0QFrgq1f2OTHwQ5GiRIlSpTbkYjxI8aPGD9i/IjxI8bfFYwfH/7tgJD6T6qudHVqzHK5tNT1235KDGNCWrb0bArzi/YR51Gv13V0dKRms7lxIg9sXpqmxmIAGHC+LHhksVhsLDrPGLDFgnbW67UVbCXoe8ai1WpZkAtTdSlau1wudXh4qOFwqLOzsw0GCifZarWUy+XMMZbL5Y0T3QhIbIUgKHideib0efrd9h5tcy8vocPaxhr6gHPTPWHF0jTV6emppcb7fhMwYO8uLi6shod38N1u1+x9MpmYvfk+k7KdyWSeCeAeIFKD5ezszOq0hLURYG58gIE1DkHRtnF7YOzfgyGibeyaE84+/elPa29vT51Ox7Y6MFaKG8PMeZbIs5U+6IRs1E199/PtdbYtEHFvfrBFD4qSJLEi5oVCwYIb8811R0dHFsx9TSH0zJg8S84WnUajoUqlokqlYnqkdo+fs8VioVwuZ6+zfYP6L9ioByFpmm6cMsbnpCtGmxoh4VoJ558vIL4Oir8OcOvBSTabtS1DjA+9RIkSJUqUPz8SMX7E+BHjR4wfMX7E+Lsi8eHfDkg+n7dFxb59FvZwONx6/PSrFhg4ajDAqEjPBpn3ExgDTn4ilRz2JJ/PG+szHo8NOKVpag6AQM6Te88K4WBwQt758TmcCTUkcCBsC6C2xbZ0XtLYDw8Plc/nN4CBZ0darZbK5bJ6vZ5KpZIxZDhE6mXwWc8Ieb3epNttr4d2whyF4lOVw0DyfoDAvwdgpKA1beVyOe3t7W2wrjCjFxcXymQyxoDjUKnt4XWxjXUm4Gx73/9PcWmCs09X9+ngno1hftDH88CBZxT9nPA/7TL+Vqulvb09vfHGGzo5OVG73dZoNNLTp09tS4QHVPTNs31+Pr1tbGOwQhbX/74JBPp2AfDojP4UCgWr5wIwKJVKajQa5stoI5/P6+joSIVCwdLtWbfYvi+eK8kYPlL0uSfsGcwz8z0ej3V+fm6Agbn369pnCUiytQ1zjeATALGsaa8nDwj52wMngAEsL1/ssAd+ADG1Ws3ql0SJEiVKlD9fEjF+xPgR40eMHzF+xPi7IvHh3w4IjpSU1kqlYgVTSa/2jNFtiGdccBQUMA4d9/sJi0jaTJ/1DhCdUMeDWgDU2OApOu/jGENHziKlngQsYy6XM+eSyWTMeedyOXMijBtnijOg/6VSybYB+LGEKcGkQjebTaXpdbFYQJ/fLrBarYwV8ywPASJk+cJ0ZPr8fuJ17T/zImCAe2EPngEqFAoGCKrVqrLZrDEsAEsCg6QNVs6DNl8TBzbM9xH2zAfmkJ3zr/s5BQCy3nwtCtji8Xj8vmy8twfaxW59UMI2u92ulsulvvKVr+jy8lLdbte2BPT7/WcKJ4c1SUJmN1wv/A6D/PPmMBQPCvw1gHmCc61Ws6AK412r1TaAAWxbs9k0Ns+3C9Pv9UnwzmQyBqY90+ZrfaD7UqmkZrNpwGO9XtscePBGOwRvbNCzy/6EOIQsBTIKJpPJhl6wW/rqt1AAPgDQfj79nLzfvESJEiVKlE+mRIwfMX7E+BHjR4wfMf6uYPz48G8HxDtWQEG9Xle9XleSJFoul5aGf1vigQHBkAV0Uw2CmwRnmclknnFsPIVnEWcyVym/FIjt9/sqlUpqtVoGEHBmACjEt8GCx/nisLjOAwNARAgKvBNj+8BkMnkG1PgARPFX5rNUKmk0Gmk2m6nX62k8HqvT6ajf75suh8Oh+v2+BUb0hXPxQHEbMGC+nid+zm5ivp4nPtj6wJ4kid544w1VKhXr85MnT4w55KQ3gI4PqgQXQAS69QVymRcfRMPxbguiFHQFyDQaDVWrVe3t7Vk9k1KppNPTU7XbbaVpeuMJfCEQ5DWfMk+AzGazBmI6nY4Gg4Gkq9OssIMnT56o1+s9A3L82to2P8yBD7Yh6xcCcB+AQtYQ3YRsNK/DujUaDSVJomazuTHWRqNhDD7rA6BIQW7WaZqmxsB6QO7rsYT1h1jL4VaJbRkFAE5vO/gDv22BtYSu8RNeJ6vVyvoyn881m802wCRAxRck5358AVmtVgYMPeDjN9fvCjCIEiVKlCgfjUSMHzF+xPgR40eMHzH+rmD8+PBvB4Qjp6kHgHGmabrxZPxlnfdHKd5ZhOyH9GJMFOIX4Xw+t2PefUotKd8sTF8g16dxz2azDWdD32BiZrPZhoPldfrsU5UzmYxms5k6nY6SJNlwAKGjhEEgiElSvV63tN71em3BC3aCNqrVqiqViorFomazmTlV+gUIgglFlsul1Q3hiHnqi2AvPiXeB07Gty3YvMjc+fEz58wXTpN5Gg6HtnUDAYjBKJXLZR0cHFhxZVikXC5nTCmngtFH1gkngS0WC00mk40U7W1j8c6WsWN71WpVh4eHVgOmUqmo2Wwa602ger8g7fXh7QRACdu1Wq3U7/c3mGDe8/O37T4h+PFjCj/jA3x4TTifPiixpgHKBNIkSYwJ3N/fNxAIs0qmAJ8ljZ8fH8h9QOeeBHG/pQFhGwFBnDWLD/FB2AN4/8XA+wX04b+YMA/cL1zr/jPoxNc14XN+3v17ntXmOnRUqVTslDjPZkaJEiVKlE++RIwfMX7E+BHjR4wfMf6uYPz48G8HZLFYaDQa2THoPH1O09TYg10QFj6Lyy+OlwUGOPnxeLzhgHA0AANSw0kr90/1c7mcBQ7AU7iox+OxlsulXR861Hz+6hh7HOdoNNKTJ09UrVY1Ho/N6TF+D1YIUjgn2A9eo0Bx6OhIX8YRjkYjSzPGQRL0BoOBOTtqbkynU3U6HdMfqfa+tgL9xEH5oqg+0L0MKEC3OFjm37PEnIAGoEXnxWJRx8fHymazOjk5Ua1W0927d9VsNq1N5p2TwNAvNUUmk4l6vZ46nY7eeecdDYdDC9x+i0DY99D2YKQkqdFo6P79+7p//74ODg50fHysy8tLrddrtdttLRYL28IRpnR7Js7rJ2S82dbAtRcXFxugabVaGbC6aU62sUXbgFAY4D2zFTKCsGLSNZBgTqm7wXqjlkmr1dLJyYmBc0744h58dhsw8HaZyWSsiDDCFyMYO0Aw2xCm06nW67UVVmaNeLDh9efHEwIm9I4eWa+MOdwSwfWwoyFYoR1szP/PFz3u579YUV/IF0QPT2uLEiVKlCifXIkYP2L8iPEjxo8YP2L8XcH48eHfDggGPZ/PNZlMbI85rMguGIr0bNq+P0HnZQVH4h05i4w0eJ76E2DRC8ese+ccpmfzvy/AyWe2/aB7hBOM9vb2nqljwH1JV+50OhvBhnERsGCgYDQIqjiOYrG40X/SqnGItLdcLtVqtTQajVQoFMwxch/YwvV6bc5wNBppvV4rSRIVi0Vj7Ah23mF5VtUHDxwYBVTpP//zmwDHdg1e93rLZrOWhl+v160gqp8rnz6OfkgvxwYKhYKGw6HK5bIxkWyd2QZ6+KxP487n87Y1g9oW/X5fw+FQ8/l8IzCgj5uAFPYcMqewmYxdkukdxioEj+F9PMu97X9/LfeQNgMUNuvZMe7j3/O6YY6pUVQul1WtVpUkibFZbAeAEfZba/jNfQBvnv3KZrMbKfnS9Wlc2ISfV/85xujn2+s6XPPb2EZfC8RfC1PrmUS/JhiP/wzbTrxN8DrthXPk59hnO0SJEiVKlD8fEjH+lUSMfyUR40eMHzH+tU1EjP/qJT782wHBqZDqvF6vzUm12207YWkXhCBKWu5yuXxpQ/ZP7z048AEOJoWFnslkNo4Spw3+Dvf98wPD4Nkyn6bNQh+NRqbrbrer0WikfD6vT33qUzo4ODCWA4EdkKTHjx9rtVrpwYMHG2OZz+e25WE6nVoBY/qFEOhwcDAZODf6i6MZDAZ69OjRxpH1ABDsp1KpKE1TPX78WLPZTCcnJyoWi7q8vNR4PNZgMHiG1UzT1MbpWQvqQOzv7xsooM4JRX8l2elLnAhFMWAYMM/+ASrz+fwz2xjQKzool8u2ZcLXe+n1evryl7+s4XCo09NTjcdjPXnyxNgl9JnJZGwLBswtrDv1ObLZrDGavV5Po9HomUCyjZnzNg2AxQY80Mxkrk8jA+gTWL1ubgIFntnytSe8TXMPvmT4YEtbIVD2a4BgTuFe6rNQO4U6RQA7z+gSvD1gYLzohBMNfRZALpez7VD+C9JyuVSSJKpWqxoMBhoOh6pWq8YkMhfMMwB3Npspm83ayVpeNx4A+NT7kFXkiw/iMw38eLkXNswXGp8psVqtzA7Qh59L769gv3cBGESJEiVKlI9GIsaPGD9i/IjxI8aPGH9XMH58+LcD4p88w9CQduqd/y4IwTpkyJ7HmITCIpzNZhoOh1bwmM+jC1gJ2EEcWxg4/YL3T9VZmL7AKPr0zAx6hlUbDAa6vLzU48ePVa1WjX0ChDBHlUrF6iMQsGA0VquVbfEgDR8m1esN58RrOCavTxwbOq9UKtrb29sAUL4uiXSV6k5wn81mFqzTNLVaDjg3z24QGKTrQFIoXB37vr+/bzr0dSA84MnlroqfeueHs/POdbVamS78mBHmGQnTqbPZrCqVig4ODuz+4/HYHPRoNLIi0mmamr2gY5iaXq9nNVXYijAajexkLr/+PDsUgtHQvv1v7NQXvYUdy+fzBswQxucZWLbBAHBqtZqNw7PBfmy+Bg3+hLlhK4nXK/fiRDfS3j0bxtgBxqwHAJwHfMyvB+H+XtvYaOwBFo0fbMvX4GDsPvj74uAerHkbxP58X+gr40a8f6Gf2Db26dnXkIn0wGybsObIAgiZ1ChRokSJ8smWiPEjxue1iPFl8xgxfsT4EePfjsSHfzsgGGY2m7Vj0lutliqVij0x3wXB0Akkksz5+IX+foLT6vf75jBh+1j8uVzOTmqiXgrBlDoE3gHwHqcvUUsAtgHxr1MnpFgsWmAdDAY6PT01p7ler/VN3/RNVsgWQJOmqQXKv/AX/oL1j5oF8/ncGDhYIB9EcWQwCp4lhVFEDzgjH3jr9fpGKjz9rdfryufzOjk5UaFQsADJ+Or1utXYADT4AEIKOH3BWddqNR0eHmo8Hqvdbm8wmK1Wy4IVc7larXR6eqrFYqFSqWRMnyTrEyCO7QnMP8HJn3o2m83sPeytXq/rrbfeMkZ9PB5bH8/PzzdYQsbLmFhXnU5Hy+VygyXixwcd7g0j5wt2b2N4PMhhHmG0AAKcmDWbzcymCDi+ngYM3f7+vl577TU1Gg2dnJzYlpDJZKKzszPLKhiPxzbf1Og4Pj5WpVLR0dGR8vm83n77bfX7fQM4BEiYQIK7tzsCJvrg1DbYQEAHjBwBdDAYbPgJ2mWrjHTNsnsGmTlDB9gF64wf//lms6n1eq3xeKzV6qrWTi6X2yj4LV1vy8DvkIkRfiEDGDDf9Ic1Sa0i7NT7wW2gwPsi/q7X61oul2o2m+p0Oup2uxtfvKJEiRIlyidXIsaPGD9i/IjxI8aPGH9XMH58+LcD4h0JT5ZJy8VBvmjQ/TjFBy8cqaRnHOH7Cc52Pp/bqVcU3q1Wq+aIPIvg62eET8y9Y6aOA07as0DSNZtAOzhEHL93BL1eT71eT91u15wH2xZw4oVCQXfv3jUGEIaGoEGQ8eLTib0OGYNnaDyLiKCfbQwG+uOezJNnVP18eecL61SpVGw7AzoCiEmyoEN9E8+EAkJCBmW1Whkz4wMAzjf8n/4CNgiiHhh4ffJ/q9WyU6Kq1epGEeltNhoykgAebJ00ec+M+TkI0+49i+Vfy+VyxujRBvfw8wuDRS0YGNx6va6DgwOdnJwYG83nZrOZjbXT6WgymahUKlmtE0l2+hp6pI6KB6h+HgBFISvqmUGAs2fAstnsxjYDr0vPNGaz19t0EG+b2A3XsB4IvPSL632mgAdr3v4lbZzOF36Z8ayx36oUip8rP8/8TZuhvXn9+M8w3/h79BAf/EWJEiXKJ18ixo8YP2L8iPFpN2L8iPFvG+PHh387ICwEScZQNJtNNRoNtVotSTLW4LYER0C6MU/RWXjeYdwk3vmmaarhcKjZbGZpsEdHR1aUlbRkScZWsGClZxcfC7rb7Uq6coQ4l+VyaQECgYmF/SiXy6rX68ZejUYjPX78WM1mU1/5ylc0n8+t3gcns8FOftd3fZdms5kePnyo0Wik09PTZ3Tm04M5vYxAIV3XHIAVwkmUy2Vjf7wefSqzZ2A41azb7SpNUzUaDdNnmqZqt9uSZLpAB/v7+xt1H/r9vjqdjvWFz4zHY11cXBijw3sU7wUoYNMEgNVqpSRJzAHC2DD/pVJJk8lEs9nMQFi1WlWr1bLg6IMN4LRUKmk6ner09NTsaLFY6OjoSNPp1NhTAkmn0zEmiTnyAMDXpYBlhrUJa2z42hvYFHPiQQRAHx03m03l83k9efJE/X5/Yz5g25rNpvb397W3t6fDw0PduXNHjUZDBwcHFpAqlYrVaFmv16aHyWSiy8tL9ft9/cmf/Ilms5kxt5VKRdLVaXR+fmDdfOANmWvP2KdpatsQAGb87a/xjD1H3QO0/HYU9MQ9YU/H4/EGEC6XyxqPxwa+AYvUIAl9DIGW/vT7fa1WK1sXrCs+67caAFI9GGRN019/Lz8PsPfS5jYhD1o8+JVktgFw9tdGiRIlSpRPpkSMHzF+xPgR42MHEeNHjH/bGD8+/NsB8U+iKeoKc8Vx6rf9lNgvcp6Yw3i9HyMYvu8XLw53MpnY3n2caiaT2WAd+Kz/nyf59NGn43rHjADAYGcIrMVi0VKE6/X6xv2Hw6HG4/EzBYp9cMpkMva5y8vLDSfq2TJS/WnbO1L6zfU4B8bg2VLPyPg+8R4p0dL1VgScvk/Pxtnyg72RHs1ceeaF1wgI/nj2fD5vRVH9PUMWifnyLBzzw8lTnhmj4LAHBjCM5XLZChsDTLg/p575lO7pdKp8Pm+/uR7bg6nJZDJqNBra39/XdDrVaDQyW93G5oUMEeuWVPZaraYkSSwAk06OfgjUgJF6va5Go2HgANtk/L52C33hlK5M5mp7x9nZmcbjsb3GXEnXwNYzbtiRnxtsxjN8nmn3LDZMqV+X2AwgPNRTeL9QtyHT6tcBf9MuIPAmRo/P+DXg++O/+LCePNPo/XDoh8JxhX6Pa7xf8uw5rL23xShRokSJ8smWiPEjxo8YP2L8iPEjxt8VjB8f/u2ArFYrOzFqPB7bCWAUcZ3NZjvxRRDnjjNbr69rg/jgi/iF7Nk7/zR9vV7baUyNRkOSNoLtTbVQ/KKVrhe075e/hsBbLpeNHYGdWq1WFjx98BiPx8rlcjo9PVWlUrF9+oyflPiTkxNVq1Xdu3dvozYDBXepTdHtdlUoFFSv11WpVIxRqlarKpVKBj58kV70xhgAMBRz5dQrgACg8smTJ8aw5XI53bt3T5VKRcPhUJPJxFjXVqulg4MDJUlitUpgNGBuOIWp0WhosVioXC5LkvX34uJCuVxOw+HQ5qNUKukzn/mMpZ6n6XUdFeadYM1YASknJyc6Pj62VHhYQx9A/FYCWMD5fG7FfWEuP/WpT23oi+D++PFjDYdDXVxcaDweq9PpWP9h5ev1uu7evasHDx6o0+no9PRU3W7XgMFNaeMEHepqAGzu37+ver1uNTsuLy91fn6u0Wik1Wpl2zFOTk507949HRwcaG9vTw8ePNAbb7xhgI35ZpsMQXq1uqoHk8lkdPfuXc1mM1UqFfV6PT18+FDD4VCPHj3SdDo1hq5erytNU2PN2doCewsQmkwmmk6nVrskn8/bthbAZK1Ws3n2gRW7grljrQImPGvugYkHE9gxgLlWqz0TPKfTqS4vL43B9EwlbGO5XLYsgTRNbcsJwji5L8ATptszg34c/kuAvz/jkDZPAkP4PCAdRjAEGi8q3s9GiRIlSpTbl4jxI8aPGD9i/IjxI8bfFYwfH/7tgPhFQR0G0qNZ8LsgnhVk4WDYftH4671x+/f8taRM+6fiIRPoWQbP3sCuEWRw1N5psBj9/b3D8CwJR87jdAEJsE44KEl2whcghOAFuwZblSSJOUEYIM9+TCYTzedzKxocji1c7N5Wer2eFTH26cyDwUDz+dwAADpuNpsGjnK5nPb397W/v69qtWoB3zOAzHGlUlGSJJpMJhasQ/FOM5fLGaAldZx0cOaJQsT0BxawVqupXq+rWq1aYdlCYfPYe5wnv2G3YMtg11lDkgxoLRYLS4lfLBbK5XK23gCKgFP0F57WxHio/4KdeV2gR8aXpqkFXwCKZ3NhDwESlUpF1Wr1mVOs/LYDzyJnMhkD1HyGtHQKb5dKpQ3WDPvHbkJ/E2754TPcE/tg/MyNt9fwi4Ff2yHbT1v+C0T42W1gjMAcsueI9zUADP8e6wwdcG/sYdv8+t/+dfTlZdtnw9e9PW/7ohUlSpQoUT55EjF+xPgR40eMHzF+xPi7gvHjw78dEALbZDJRr9dTu93W2dmZzs/P1W63NRwOb0xxfdXiA6lniWA2Q/EOIFxEOJBms6n79+/r8PDQgqg/4QeHiQMjyEmyVPtut2vMCqCFeg1pmm4UYZ3NZsbs4EhgNgh6o9HIalx4prbRaOjOnTsbQefi4kLlcln3799XsVjUwcGBcrmcRqOR1bSgn15P6LLT6ajf72tvb097e3sWHLxzYhz5/NWx8cPhUP1+X1/60pfMbnBisDzSVXHcarWqZrOpe/fuqdFoWNvZbFatVstYSgIqAZJTnrrdrkqlkmq1mhqNhrEfnnWZTqd6/PixAag0TXV+fq5sNmt9q9VqloLPmLLZrF5//XU7aezo6MhYQebGM4nMPwCSVHDPTK3Xax0cHGixWOj8/NwC93w+t7oyAL5qtarBYGDB9vLy0the9AR4aDQaymSuCy3n83kNBgO98847kmQ2SfsAXerMtNttrVYrYyTRC8EgSRKrAbS/v6+joyMdHByoXC5rMpkYg8a2ARhVfpfLZR0eHlqf8/m8Dg4OVK/X1Wq1TA+Xl5d6+vSpbXWBhSYoEiQBas1m007MAnyxnSGfz9s6JSgCgvz2AYKuf4314GtxYFe0BfCAgQQcePbQn5bWarXsHh6A+O1Gvtgu96XoMF8C1uu1jW2xWNj2C//Fg7Xpi4N7cMa11DXyNh/6QuyP+wA6PYB5EYkZf1GiRImyWxIxfsT4EeNHjB8xfsT4u4Lx48O/HRHYFFK6efIOc7BL4pkZ6Xq//vuJBwee4SAQEtC5B4uLH88KeIYSJsOn13pGkPtms1lzpJ4JhCXwzsnXZJFktTxwZDgkggT3IF15tVpZECUNudfrbTCJPth54OeZBfTqnSknqA2HQw0GA00mE43H4w3QRrAhlb9Wq6lWqxkDSNsUAMYh4ewBMsxBoXB1zDtp534uYcb6/f5GvQccIvqiCDJzgCP0NgA7yWd9IN4mngWCVUHy+bwBTVhXdMT9V6uVFSLmdZhdb4vo1AMG0vNDmw6dMwwVafej0cjux+cYiwcUMF1+HYS68AGKNYPNoFf0gz6m06mBOm/rYTo+QZQf2GXPDobMPX1lbTJ+/g+/KNz0E9bT2eYHwiwD3wfvH5DQ/6A33vPXeibT35trw9dCm9wmHvD4e3gGPtRxlChRokT55EvE+BHjIxHjR4wfMX7E+Lcp8eHfDgnsCs4qk8mYE9mVjA6e0PvUaJ/Kv82Je+fBbxwrTA71F2AYfeD0iy9cnBQRZtH7FHi/CCnkS90HAhDMA7UthsOhRqORBoOBut2unRDGPMBsUQcENtezVJ/+9Kc1m83sc5x49fbbb6vb7Wo4HGo4HJpj4Ih3QAzjy+fzqlarBhDn87k6nY56vZ6+9rWvaTAY6Pz8fKMoK3Px4MED1Wo1fdM3fZP29vb0uc99Tvv7+1ZUli0YFENGV9wHdrDRaOjk5MT0SZ0QmKRsNmt1IyqVimazmQaDgdI0tdoU1L/4/Oc/r8vLS6t/8eabbxpYuXv3ro6Pj3VwcKBKpfKMY/TBGf145ogUebYOEIySJNF6fVVzhm0Cq9XmiWDr9VoPHz7U+fm53nvvPT19+tSCZiaTsbkC5O3t7VltFklWV8YH+DCYZzIZYyipWcK1YXAFIAAEYbdph+uxj+l0ql6vp2w2a7ZIW9iPdAVuHzx4oHK5rKdPn6rf7xvQRC/cm0AFYIOx9AWjmQ+/ncMDXU7xAoQAXLA5D4A8a0j79GM2m2k0GhkbStD3ffVfGvADjNmDCG9XaXp1GuFyubQtMgBkD8oymYzZDsKaxI95mwzvwbyxvcWDfeYIhn48HqtcLm9cFyVKlChRPvkSMX7E+BHjR4wfMX7E+LeN8ePDvx0R/wRakjluafe2coXshDfgbaxIKP5pOIGcYL7tOu4pXS8+GAZe90xIWI+Av3FaHF/POFjk0+lU0+nU6nPglD2DgPPCifiUcfoL4IANJBDCTJF2jPOh9kMIgHxgIVDDBPb7fXNqaZpaPQxJlr7fbDa1t7enVqulWq1mxWZx7jhlr3df38E7X5wrp1T5MeNIm82mjUuSqtWqOVXYHFhuv7WDoALYpF0PkvwP8+GdvWeomSuYW/TJ3KNPWGgCqiRj7rAFArx0XXMCXRPcPBPphfkjODH3sHDeZkI7pf+eBQ+F+fH3IwgRjD3Dls1ebTtg+4BPXecHUBMy04AvArZn30M78m0gzGf4mv/tXw/ZR88MsmaZE3+NZ+fRj2cTfV+8rtEb9ufvv42FDLMQQnv0/28bI695cMu2Br8GXsSfRokSJUqU3ZaI8SPGjxg/YvyI8SPG3wWMHx/+7YB49ipNU9vXv7e3Z6wGzuW2Zb1eG3PEkeJhqi8SLnwWF4ug2Wyq2Wxa8d31er1xGhOBI7y/dJ3KSwFegAWnDoWLmRogOAACBYGbE7Jw3tJVnZJaraajoyMrhDscDtVut40pgZmB3QE0wGb0+339/u//vk5PT3V6eqrRaGRjwwmQso8NwILMZjONx2NjkobDoZ4+farBYKD33nvPHF+lUtH9+/et1kahUND9+/ftCPtGo6F6va4kScyRepvzc+SLPPsf3i+VSlYHZjQaWXHbNE3tJCh+CMQwrf4Etkwmo+PjY52cnFjdCwoA+20FzDmADEDBOLCDcPsBgQC7YBsD2xGopwFAqlar6nQ6Vjuj3++r1+tpNBqp3++bnReLRbVaLRs/rM5sNrM6L9gCTPTFxYUkGTMJ6GT+PLjAHjudjorFopIksdoQAGkvjJ+59FuK6DPjl6TXXntNrVZLl5eXqlarGo1Gtp2E7S6esQO41Wo1Y66xX+pwJEmiUqlk/WA7BUGNOfDgH/vwwZQT4dh6wQlytMG2GkAytUpWq5VtsaB2B4CeLxGMcVvAl2SAtV6vq16vW9/Cmhx8OeALAFtE8Iuhv/MMJeCTLxT4Mr4AYlf4HcApbb2MbAMnUaJEiRLl1UvE+BHjR4wfMb4UMX7E+LuB8ePDvx0T/3Sao7gnk8lOZYD4J+rSNVsi3cwK+tcJSjwFx2Gk6WYNgRAw8fo2NtC3y6LzQSpkBngdUMOCT9N0g/XwjCU1Mubz+cZ4fc0Gz4iwOKfTqW0DGI1GlvKM82Uc3BcHCXvFyVEUkJ1MJuacqtWqarWaWq3WBjBotVoGONgC4Bmd5zEynq3wDLAfK+nR/jQr2mUup9OpBRnGRwAnoCZJYgDJb+UIgWY4l9wD5xsyayGL49kj7rFery2IJUmi5XKpRqOh0WhkIISgg31gt5I2gijX+/7QV3TlgVbIcvp5ISBxnb8+XId+fLlczubKB13P7gGIkiRRvV7fyDwIQT0/fosA8+vXZzhnfMZvGwAAEajDNch8huPbxv55Jg92zgfvbTZMe6GteNY7k8kY2EGX3tdwf/857/vwRdt8nZ9vr2vuK8nujW+4iW2OEiVKlCifTIkYP2L8iPEjxo8YP2L828T48eHfjkiapnbCE2nVSZLo7t27yuVy6vV6GwZ628JT8Vwup+PjYwt6PpBg9OGTeP4ul8tqNpuqVCoWPPxn0jQ1XVSr1Y1F6p0KrJV3gCw8X/zXOwV/rXRdfJi0eYJ5sVg0QDCdTjUej9XtdrVYLIzJoy++WHA+n9fx8bEqlYo+85nPWF0G9JbP540Fg9nE0Y3HY3U6HQtMsITUJMnn8/rMZz6jWq2m119/XUmS6OTkxLaRFItFvf7666pWq3ayGewSTg99M5fb5tc713DucPTL5dJquOCcqV9B8AAA1Ot1Y8pyuZxOTk70+uuv2wlwmUzGxuedItf7fvF6WH+GuYZ1IzjRZw9stgXPVqtlwT+Xyxno4kS0SqVirCjsZrPZtG0m3kbRHQERAMF6oK+At729PWNwYSsJ3B5ceJBFqn6r1bI5gj3LZrPa39+3osfoEZaP+jsUNWYN0AYBG1aLOkAAI2x2NpsZoGYO8vm8ms3mM8A9TVMDtvSJOYRpR/dcQ00S5n21WpnN9Xo9axt2F0Yen7per20bR6VSUTabtXvTDtkEnJxHv2B7+Qnn1QM6b5feDphDfgNE8E28RnFsvjDRtv9C86KyK18io0SJEiVKxPgR40eMHzF+xPgR4+8Gxn/paoP/+3//b/3gD/6g7t27p0wmo9/4jd94pkP/5t/8G929e1eVSkXf933fpy9/+csb17Tbbf3Ij/yIHXn9T/7JP9FwOPxQA/kkC5OIQ/N7zWFMdk184MCYwwVy0/X8kE5LkNr2ufDpesi4IZ6d4HpJFtTDp/nhU33YP4r/kppOIPFt+oUaslH+PpVKRUmSaG9vz1LeqctBPQZOaoIB9DVDACIc0S7JHDuFfe/du6d79+7pzp07unPnju7fv6/79+9bqj3soD9pjTHdNFfhvHm2zwMwXyyW9j3bGeqWHxhA9MP/kjaYnucxVV7n/pqQdfNsr2/Xs0q+jkShULBC0dQpYc78GAiQ/LDdwddcIWijH/QR6hygtq0ujmfBSE/3tTHQC3r3wdNvF0Af3Is+s/Y8s+f9EZ8P//fXAiTC/nkA6tduyPQyPoK7B+ywzd6esCmYeu7Jtaz78ITAUM8U/i2Xy2aLfp34+faZAt6HeN/Aa+H68QA7ZA49U+m3Yvgi3VGiRInyKiTi+49HIsaPGD9i/IjxI8aPGH9XMP5LZ/6NRiN953d+p37sx35Mf//v//1n3v/3//7f65d+6Zf0X//rf9Wbb76pn/3Zn9X/9//9f/rCF76gcrksSfqRH/kRPXnyRP/jf/wPLRYL/eN//I/1Ez/xE/r1X//1Dz+iT6DgqDjenVOoxuOxGekuCYt5Npspn89rNpttsG/bUnv968Vi0VgQ2Cxf/Fi6dkY4O57Ie8cubZ4q5hcqTqHf71tgTdNUzWZTx8fHG/UK0jS1QJzP5w1I0M/9/X3t7+/rtddeU71e1927d1Uul1Wr1ZTJZDYctA+gtVpN5XJZ3/md36m33npLJycnarfbarfbGo/HG4Vnl8ulzs7OdHZ2Zn0i8BaLRWNYYD6Ojo7UaDT06U9/2nTpU4phRxhnyPC9rMMJr/dtUliZmg2czobeYSV9AdpcLme1FwqFwjMAwDvY1Wpl2ws887YNJGAfsEoXFxc2lzAs6/Va/X5f8/nctktgH9SRoK8wS9RB8VsXJG2AAZgl/By1LQ4ODiRJX/7yl41RDvVHH8bjsVar1UbtEBhV+hrOCYw0mQTYo/+igS3AQB4dHUmSarWaisWiFT4moLLVYxujjg7RC18KfFo+dU24r58j6bpuiHTN3PtxeAEoAxz8FgBsj5O6xuOx3Qc7y2SuWWCAB/bg2Ub6zRg9mMJGeR/fga58NgIMbjgO/IoHoh5Y1Go1SdLR0ZG63a663a76/b71J0qUKFE+Ton4/uORiPEjxo8YP2L8iPEjxpd2A+O/dMT5/u//fn3/93//1vfSNNUv/uIv6md+5mf0d/7O35Ek/bf/9t90cnKi3/iN39AP//AP64tf/KJ+8zd/U7/3e7+n7/qu75Ik/cf/+B/1Az/wA/oP/+E/6N69ex9iOJ9sWa+vC+1SE0LarHlx2+Kf6PvaAzjWF0lFZRHBpLDwQtbHLza/oHBMOAr/RN47S1J6p9Op9atUKtnx9NKzJ25J12nl9IEU3fAkLV8TAfH9B9QdHh5aOjzBpd/vq9vtGiPui8DCCgAEyuWyfQ6G6ujoSPV63bYdNJtNuzYEBB+neLbDM1IEFR+UPBvLGDn1iDnbxvYyl3zes6+hhEwL4AvnTZ0NgAHAxTM2njFmXF63nrGC9ctkrrYGFAoF297APe/cuSNJOj09tWBKPRdvuwQVfsMmevDg9e7HDAvHdgxOoZvNZmbbPkhXKhVVq9UNxkvaTGcPWcCbmHu/FcDPmd9m4NlA2uJzYbHd0IcABAAFnuljWwr3oQ/8T/o9Y4F9pJ+eXfSAw4+fPvsgHvaNvnjQ6q/1OsWvexaX/z1Dydrw+okSJUqUj0sivv94JWL8iPEjxo8YP2L8iPFvG+N/pHTT17/+dZ2enur7vu/77LVms6nv/u7v1v/5P/9HP/zDP6z/83/+j1qtlgEDSfq+7/s+ZbNZ/c7v/I7+3t/7ex9llz4xwhNm0sAHg4HG47EF3V0Sn0otaaNwaSjbFgqfBQCRgu2BAQsfRwdgOj8/VyaT2XBqmcx1SjTOk1R6gu/e3p45Q39iFawJTrzT6ejy8tK2ErRaLasvkM1mVavVNBqNlCSJHjx4sMHastBns5mk64LGOPU333xT8/lcb731lhaLhfWNE8jeeOMNnZ2dmQOvVCqq1+sW+D0zVavVrKaIT5HG2b5KMMmconNOa2JcnDaFLjxQQG+cpoSjJWCTkg1jEoJEAmw4XoLYdDrVaDTS6emp1XLhhKn1em11UqhDwUllMMSAF29bHmRms1l95jOfUaFQ0MHBwQYTxLwADKbTqdrttgqFgrrdrp2kRzuw62wDGo/Hury83PiCQL0S1gtp8OhnNpspk7mqa+NZRk6W82nnpVLJarUMBgNbc4B29JEkiWq1mtW/yWQyxpj7+howt0mSbAA4mDhfo8UHRNYjLDLzg1+hP5I2ABCAcblcqt/vK5e7qt9SKpWsPkp4giLs4GKxUDabNTDHvT3o4EtBsVi0jA0//5IMfPltTcwntoD/K5fLNl8eMAFAAKPU8aFW0K75/yhRonzjScT3H04ixo8YP2L8iPEjxo8Yfxcw/kf68O/09FSSdHJysvH6ycmJvXd6eqrj4+PNTuTz2t/ft2tCYcEgpEn+eROcIiwGC2OXtnwRUH1qvn/q7p/++8/wnqRnAoB0HUT9U3T/VB9HQZoxTA5CcPBP5km3n0wm2tvb20ix92ygZ6Nms5k6nY59PpvNqtFoSJIuLy/N+c3nc+3v7xtjiCOUrlkOxoMj9KnvaZqq2+3aCV+j0cgKzeKUqtWq1fLwv3Hq3vnctgCy2ArgtwSEhVQ9aylpYxw+8KM3nK6v7eGvDUGBDzoww2dnZ+r1ejo9PdV0OjVQCcPbaDRM35wK5hlPbIs+eDBycHCgYrGoo6MjZTLXp6QRVA4PDyVJx8fHymazarfbkqThcGjbBhifZ6QJRsVi0XTq2S4PDDyAJnB7HRFsPXMX1iBhHfjxss0EoIDu2Z7BZ9ELbW9jylnHIbvI3BPE8Q0+dZ5gSvuMlzHO53NjCOkr84/OtrGDq9XK5tXbrK+dwzYhtnL4sWGrBHjPJntfJMn+f169G8bmi0HvUlZIlChRvjHl48L3UsT4EeNHjB8xfsT4EeNHjP+qZLcKTdwgv/ALv6Cf+7mfu+1ufOzCgqeeAywWqci7AhJ8AVW/CHBW22QbWICNoz3PFG1LD4d5yWQyxlDg9AaDgbF3aZqq1+vZU3xfsNUDEFKBYV9xHtQRubi40OnpqR4+fGh1QarVqo6Pj3VwcKBer6dWq6U333zT2JEwvZo2w7EwBoLScrnU/fv3jdXxtuCBkK+ncdPceH0z3tARPW+uwvl63nX+Gpyid8Lz+VztdlvdblcXFxcaDAbGbOEEcYD0kXZwigQKD+Ioosw8oo9cLrfBgnFNu93W6empvvSlL6nb7ZpeASh7e3uq1WpKkkSVSkWtVkvNZtN0FgYnn6Z+584dq9PigTHrgnXbbDZNP5PJxGrVsAYIhtRO4XMUFl6v18byATS5JwGKMTOug4ODjTR01gRBrlaraW9vT+12W6PRyIJ9s9nU/v6+1Qup1Wra39+3zAVO7ULv3JPgB7BN01SdTueZgsvoxq8Zv17wDfP5/JkizDDmMM7lclkHBwfGHvr6Lt5nAmZgi9frtSaTiQEwGEN0DvPKlzTAh7fRNE03QIhfX8wBIAbfhC1xKp7PUAAocv9SqWSM+rasiyhRokT5pEvE+BHjSxHjR4wfMX7E+BHjvwr5SB/+kfr69OlT3b17115/+vSp/uJf/It2zdnZ2cbnlsul2u22fT6Un/7pn9ZP/dRP2f/9fl+vvfbaR9n1nREfEPxJQ7e1LzwUzwhiqB4UsMC3GbFnc7Y9/fcB1DMJiE83rlQqxgbgFAnIaXpV3BcmGYdFcKWfIThBcMDtdluZTEaXl5cqlUq6vLxUpVJRt9vV0dGR9vf3NZ1OdefOHUvlpe+Mx+spDLaevQj1tc0RvF+ADhlb6To1PpyzkJm5aZ5eBBQgBHvfj9VqpclkssF+Jkmy4SAJDH7uPcAKbY6g4vXif6TrE+CQ0WikXq+nJ0+e6OLiYmM7SSaTUbfb3Til7cGDB+b8w77wG+bSb8vwfeBvAlOlUrHXFouFkiSx4Dafz431ox8UqAbQpmlqgZ/iuH6dsJ5Yg6wX7Jng5oMlaf8eKFGnB4ACC01/1+u1+adt7B5SLBZtqwgMO0wcINenzWMTnrljPMyB36ogSZPJxLZ00AfAoZ8v9AQowTewFYiC3N7GCoXCxvYndOzBPl/YvI2GtuzBDroLWUqfpYAtxcy/KFGi7Ip8XPheihg/YvwriRg/YvyI8SPGjxj/45eP9OHfm2++qTt37uh//s//aWCg3+/rd37nd/TP/tk/kyT95b/8l9XtdvUHf/AH+kt/6S9Jkv7X//pfWq/X+u7v/u6t7RIc/7wLLIokJUmiRqOho6Mjcw6+BsdtijdiSWq1WiqXyzo7O9sI9KGwWPyCoD2cIkwLT9JpKzyyHFaoWCzaopO0wS7xdB+GgiO+cRw80V+v1xoMBppMJhoOh+r3+3aalQ8KMB/0xTM5Ph04BDVhkPcBmve3BZ4QLHkdojfAImwFrAYp4BRb9qzM8xiGEMSE/bxJPNhCfx6cwdhS8BgmhgDO/PuxMf/e5rlPmG4dAh4CzsXFhdrttobDoQU16bqAtWd3JFlqeL/fN3ZpuVwqSRI1m03rhwcCsHSe6fSsFyDm8PDQAuV8PletVjMdUZeGH+pM+Nfm87kFMOb98PBwA4h6kO31A8s4HA7tOl8rA7sAHHjWmHnwWx3YPrFcXp385ucGoN3v9y2QUleFIO/BHwCBrTrowp/e5k8CY91LV5kCzCdt0Odt68+DNUBHmqZmL9gPIMy3wzyGALtYLNp2Asbn/QaAA5ulDb/FQ7oCjsViUXt7e1oul2o2m6rVahoOh8/9wvU88Wv2ZT8bJUqUKMjHhe+liPEjxo8YP9QheosY/xsH489mc41GM81mK81ma7VamYjxI8Z/rnxQjP/SD/+Gw6G+8pWv2P9f//rX9Yd/+Ifa39/X66+/rn/xL/6F/u2//bf67Gc/qzfffFM/+7M/q3v37unv/t2/K0n6lm/5Fv2tv/W39OM//uP65V/+ZS0WC/3kT/6kfviHfzieBOZSd8vlsqrVqprNpp0O5dOtb1v8E/JqtboRMAE3XkID9U/Q/RNzrvN7531qNW15BiZNU7un31JA4CcVmP75IEYh2sFgYKeGUdTWgw1+h6nqfm+/Z7lCXYXAwL/uGa7wM+Fch3r0NRgkPQMMfNFUrns/liG8ZwhO3k8owOvrgLD9YjqdajgcWvp6yLp4+/bg0489HAPXeQDH38PhUL1ezwIwbfu6IuE9KWTM56gn420Odgpg4IMdLB4Agb4wF6VSyUAnOmLeCKij0WgDLPoHgNgc21DoA9d6u0GnAOjJZLJRZ8izWPTfjyUEB6w9wMFsNrOUdQAW/WP7AfPha/j4ewIafL/8FiHS9qnL4cE/voFrGaefay/+y4kHTh4UhQGddhhfaJMAbw9S/ZrxfkzShs/gda+HJEk0nU6NlfX1WnbB90eJEuXPp0R8//FKxPgR44efiRg/YvxrjL/WbLbQcplquZQ92I4YP2L8j1pe+uHf7//+7+uv//W/bv+Tqv+jP/qj+i//5b/oX/2rf6XRaKSf+ImfULfb1V/5K39Fv/mbv6lyuWyf+bVf+zX95E/+pL73e79X2WxWP/RDP6Rf+qVf+giG88kW/+WePeHs1fe1Mm5TWBgU5pWker1ubNtNqeYsFM9gjEYjS89utVq2MAj0sIPeuQIeqGfggwWOj9OoJpOJ7ty5Y6eGZTIZczIEo9FopMlkoidPnuj09FRPnjxRp9PRdDo1J354eKjDw0N97nOfs9Toer2u/f19Y0QBHPRn29N477RDoOD/xzkCVAgyOGSuYdxestmrwqzD4XCDMfRsGQzmTc4G1sSzcgAoP56QrcS5V6tVrVYrO83OnwTGCVfT6VRnZ2d68uTJxolf21L9mX/P5PhxAzoARIvFQpeXlxoMBhoMBsb0jkYjA2LYg28bZ1woFDSdTo2txBY5fc2DLZgs6mPk83k7PY71GjJ1jAF9ehaQH+rTwH4vFgtjwAAvZAISGKmTkc9fnRCHXrwued/fA3sA0PgAlsvlbMsAa5gAyTqCFcNWqQNCzQ0PKNheQBvc3zPsgCX6DDOLHheLhQaDgfkiz8hhn+GWAB/sAe83gQP/5SJ8DZugH367QpIkNk7W2Xp9VXPEfwEAEMNy8nnuQYHxer2uvb09dTqdjbl/GdmFL5FRokT5ZEjE9x+vRIwfMT5jjBg/YvwQ4+dyJRWLWS2X6Z89PF1GjB8x/nPlg2L8l3749z3f8z3PvVkmk9HP//zP6+d//udvvGZ/f1+//uu//rK3/nMvPjWeVFlOJtql2k8sJpyST39+UfACa9DtdrW/v29OEKZhMplYMMN5e+capomzcGBx+v2+ptOp7t+/b/rLZDIb9UPW67X6/b6Gw6HOz8+tVgSpzGmaWoru3bt39c3f/M3mUGBsa7XaxmlKHhxs01sIDDxQClmE+XxuqenUGvEnPMGK+Pb5TQ0G+uYLIXtdhswbYyAIU0PCb8vZxhJ6VqNcLptzn0wmtj0A+wC0XFxc6Pz8XHt7e6rX6xvzSJseHPh58wygZ2NgG3u9noEB+jAejy0IMl/eHnH4bF8gsC2XS5VKJU0mEwtqq9VVnRMCNwKAIJASQLGnNE1tjJ7BkmQMGwHXs99+ngAXBGMYb8/QUySYMdNHiulytD2voxO/ftEVn8E+0Bv68iwd4IOtD9gQzCXB0H9Gui4w7m2OgMzrXE/RXoI219/0pYR+e5vHFr09eVbfM838oBvYQkAG7VOjxDO19M2vVeyBNv1WJ/QJO9hoNAyY7cJ2sChRovz5lYjvP16JGD9ifK6LGD9i/G0Yf73OSMr82YPOpSaTqcrliPEjxv9o5RNx2u83iuCcSEuHYeFEmpuM/jYEYEDdDmmzKLCXkCljUZP2fHFxoXK5rKOjI1WrVWNMstmsOQicKHUNcEqeDVwsFnry5Ikmk4kxGryPY2HRwva022078evp06eaTCbm3KrVqu7cuaNv+qZv0snJiY6Pj20RJ0miBw8eGEDwgdcLgYGi1+Px2LYf4AyazaaSJFGtVjMAQECCeQjlJvYRp0ltAVKKw0CIgwzZSc+Q4Lw9I8J7ONHQLrPZrOr1ujlc6n7AzA0GA/X7fc3nc7377rvW3mw20927d3V0dGQOk3Xg74We/ZHsng0cj8eaTCbqdrsaDAYGtHHA2BG2QZo64GE2m6nf72+AKJgp2B2cNKd4McfValWj0UiFQkGVSkUHBwcWUD0zmCSJBQ10xjXT6dSCJCDXs7mSjB0m6LD2AEaeiaMt2qlWqxvMnw94fgtMyMQCWjwD7gMo9wZ8S9cgZDqdPrMmmANsBxYcQMlaBZxnMhmz5ZBhJVCHQIr1QPuSNk6HY13wPmvBg2LuB8OKH4GlRHe05TMfmF/YX+YIJjnMeGDuyuWyGo2G6vW66vW6AQNs/oMyfVGiRIkS5fYkYvyI8SPGjxj/Jow/n+c1Hs/+DOMXNJ1K4/FSq1VG2WxeUqr1OmL8iPE/vMSHfzskGNx8PtdoNNJ6vTZgsCuMIMJCBhj4J+fbAIx/DScJYwGTUS6X7VStUqlkzJhvu1KpmKOC7QAYTCYTnZ6eajKZWOo2wqKiJgi1KTqdjm0HODs7s2BQrVZ1fHys+/fv6zOf+YwODg4MGPDE/sGDB7aI/QIPhe2Zjx8/tvv1+31jR+7du6ejoyNrH+fC+MN6Id45eCaRALlarVQqlQxgcZ9sNmuAyjNF3pEyPzC9Hiz4miuelfPjBjThrLFlTgEbDocGjN5++22Nx2N7kFUsFtVoNGzeYOZIIy8UCuZk/dYAbHE2m6nT6RjbPBqNDBgwbx7IYk+lUsmAC20C1LAjWC7pqmgrgIeAMZvNjL0tFK5OBzs8PLSxwEARGNL0OmXes00ERem6rgp9InB4lsgXW2buQmCwWCw0Go2UyWRs+w42FLJg4fwS4GB4Yb8AjrTPPf3cUGibYIpga9iYtxVAvWfOCboAA98mhYOxPQ8M0E/IyAH8AYt8UaAd74e9zwIg+rXmawV5hpi1i70g/gEtINfrmdczmYxqtZpqtdpGEfNw/UeJEiVKlE+GRIwfMX7E+BHjb8P4mUxWuVxJmcxS5XJWzWZZs5k0Gi2UplI+P5OUSooYP2L8Dy/x4d+OCQY3HA4tJdazL7vwxc/fn8UIwxKmSHvxgSgMJqS6w7L44AU74AXGiqfz1JigrTt37thR5h6s+D5Wq1WNx2NjaCjQmsvldHh4qPv37+vg4MBYyWazqUqlokajYXVB/FYAL+v11alL0+lUb7/9tnq9nh49emT1KWazmQXsxWKhs7MzC2Z7e3s6ODhQqVRSs9ncYPTQC07M3xfgQyBET378PkMMB8zr6JT2YRh9bYZwPqn/wDwBRgCNtAnYYIsqgbHT6eidd97RbDazALW3t6e9vT2rvcCc4PAJCNjOYrFQt9u1YM2Jbmz1GA6HG2PARqifQT0abMMDEZw1n4UN9w/ZAH6k2QMcYLt9UAJES9cADPDU7/fV7XbNnihgzPi3bZdgbdAW/gImDqCI+MAGawb4Jvj4oAwAgGEG4Pg2Cbw+2ALYJNlWEubQFz/mdwgWQrtG9+jQbwmQZGsEps7f07N91PnhswBoxon+6Afj8z6JtH3sm9/YpN++4P21B0AhIPTAjLFQDwRmEEbztv1/lChRokT5YBIxfsT4EeNHjO8xfjabUy5X0HqdlVRWLlfUclnUcllQmua1WGQ1m62Vz5PFFzF+xPgfTuLDvx0SDI96BpVKxRyX9Pxj2F+1eONkYZTLZQvO28Q7Zh9M/YMNX6PAf8YvTpyYL6AK05TJXKUOv/7662o2m88ctV0ul+0UI+nKOROolsulBYU7d+7ozTffNGdZKpW0v7+ver2uO3fu3Lj9Ad2sVit1Oh31+3390R/9kU5PT9Vut+04c8acz+f1+PFjzedzY7TeeustHR8fW1q/H7dnJKTr+iDoqlQq2f2l6/Ru5ss7I5iQ9Xptpw4RSHjfgxDpOrUaR0Yw9Q61XC5rsVhYcMWR40Rx2qPRSNPpVMvlUmdnZ+a433jjjQ1G0m+3ALBMJhPrw3w+1+XlpTG9k8lEg8FAvV5Pjx8/1mAwMH3Rx2q1aixeLpfT0dGRlsulkiRRpVKxtgnYPpizNYAU8eFwaH2cTCbK5XIaj8eq1+uqVquq1WrKZDLGeGHT/kHdYDBQp9PR5eXlRltsHfHp66whD9aWy6VyuZwBkclkIkk2hwQpQIDfsoFNhun06AtgAAAM1xR/o8tyuWzAT7pmxWjX1+Tx25kJuIAzXzTXAxLs2wd2+gojSV/ZQgQYGQwGW9P5AcbYLIHeb1HwP5zUCBDCb/MbkO5Ze9YVTCXbDTidDZ/C55rNpiaTiRqNhn2JAXDd9pfDKFGiRInychIxfsT4EeNHjB9i/Ewmp3xeymYzymYT5XIFLRalP3sASBupCoVUSVKUlIkYP2L8DyXx4d8OCQEAlgDDlnRjELpNYZGw792n2HoJg7t07QRwKixGHIUHArSN418ul1YvhSPlSe/GqXgw5X+4tw96LMZyuaxisWh1DFarlSqViur1uprNpprNpm1f2MYE0jZszuPHj3V5eWmnkuHUuC/3hn3r9Xp68uSJ6vW6jo+PVSqVNtKJCVTUimCcOEbvnDwIk/TMwyKfXgxT5dnAMDjwnmdGcHYwetwLO6CYKcWeV6uVAQUApE8L73a7evz4sSRZHZRM5io1utfrWf+5J7ZHrY7lcmnFf8/OztTv93V+fq7JZGK2cXJyIukaMCVJomKxaCd/AdA8ePVsMCygD2b0g7nhJLQnT56oWq3ayWAEBAI/a8UHKg/s0LNPISewU3cEZjG0Qc8wSdeMVL/fV5pebceZzWbGvKJHvwb4XS6XrT4OgY1tBtiBfyAZrntep5/+Ghhs5tWzprByfnzohM/xWQAy7B79Avzym3n3fsq3+byMBj4H+K3Vahv2C0ONP2QuPBMrXYN51sw21t+zlmQ39Pv9rex8lChRokTZfYkYP2L8iPEjxg8x/lUdv5ny+aUymZWy2YxGo4xKpawWi1TZrJTPS+t1Ruu1tFqlymTWymQixo8Y/4NJfPi3Y7JeX6U7t9ttSVKz2TQjwZnvgmx7ys1T9fBhBMbsF6AkC76kirPQPWNFQU4W+2Qy0Xw+V6/X02KxMMaGFHrqHcA8hQ6L+0+nU2PAWIC1Ws0cIQ9a8vm8Dg4OdHh4qKOjI+vLTbJer63g75e//GU9ffpU5+fnFniYX//QBid2cXGh0Whkp48dHByY88lkrlLEGfdoNLJgBeji3gRgn0ofOmnexyFLMgdKHTn/GR+s/HYECvAWCoWNgFcqlbS3t6f1em3bM9I01XA4VDabtXswfrZFjMdjdTodPX782AJTkiTa29t7hmEBIHjWiLoj7777rvr9vh4+fKj5fK4333xTpVJJd+/eVaVSsZPSGo2GyuWybd94+PChTk9P7eSzZrOp/f19JUmiVqulwWCg09PTjXmjL91u11ilUqmk6XSqcrms4+NjFYtFY7jq9bqNDaaOrQ+VSsWAJXbCOiDtHkAOyGI9hfqEqQN8LBYLq5cDIOA+/CbowXolSWLMZqPRMCZ3Npup2+1uMHPYE4ASUBICA77sAJb5QuC3qEgy+/Vj5BquC0EWtupBK2AOUBb6BHyAB81h8OV6vkCUy+UN38w68AWi0QXAgNfIzuQeMP+epUd/lUrFdA9gjVl/UaJEifLJlIjxI8aPGD9ifDD3cgnGX6lYHCuX48HsSsViVouFlM1KxWJWq9XVA0ApVZoulM1GjB8x/geT+PBvxyRkzzB6AtKuMIMYvE/Plq6DSXit/414ZwKzQoFgXy8AxwXzslgsNBwOrQ0KheKUAVCeWfSMkneUMEEUnuUktmw2q/39fSsKDLNz03YHr5Nut6ter7eR0sxYpevj0z17IMmub7fbxo5RpwJnKl2Dx1zu6rQs+oVeYDP9Vgvu7ZmPbayhP2kJhoYfXvOsox+7ZzNyuZxqtZoWi4X9JgD4PvkUZ58KDwChSDBFjSnoy4lxnlmcz+d68uSJRqORLi4uNB6PDWzC6gIEpOsizZPJRKPRyOrwUKSX7SJ+Gwd1P0qlkhqNhmazmW2BgB31zC+vp2m6YZu8J8nqkvA/QY2AIcmYQ3STz1+dsNXv9w08cW+CNfrywI76Ltg7Qd6D9m0BmjWKrRSLRdVqtY11jb3QDlsnmGf6wr1Y0/SbwOi3l2CjbGPw21O8rrBnD5K9T6J/iAcSXhg/8+2ZQA+aqI3i7dSfZAaI8OskZEN9n8P3+KIFMICZ5gtSlChRokT55EnE+BHjR4wfMT73Xq9TSVktl6lWq7VWq5nStKhstqjxOFW7PVW1mpdUVD5/9eCvWMyq0SipUMhFjK+I8T+IxId/OyY+SEraMERf++G2JU2vT+7p9/sbR137BSptLkjpejEQJAjYHN/ugzj7+HHgFxcXtgjL5bLeeOMNlctl1et1e+BB//wPwkMUHCJFhGHyPBMJO/fWW2+pXq+bg7hJ1uurugOPHz9Wu93WaDQyxxduUcDJeUfIWAnO8/lc+/v7dhqQvw/BazAYWMDxdTEoWMyPT/sP58A7QWwNwERg9en8tMXrHszRFmxqoVDQ06dPlaapyuWyJpOJBXnS9AlEgLx+v6/RaKR2u62LiwsLojAxrVZLn/rUp1StVrW3t2dbOkajkf70T/9UvV5Pp6enWq/XVkvh7t27VmSYbSPj8VgPHz5Uu902Vqzb7VohbmypUCjYqVyAlMPDQ33uc5/TdDrVo0ePNBqN9OTJE3PqPvADZvf3980OmEMAEeOAKUQf/E3Q6ff7FiCGw6GePn2qarVqATiXu6rHsbe3t1H3hnmjYDIAaDgc2nYK328/Jx7MSFdAIUkS3blzR9PpVN1u196nH2xxwb5zuZwajcZGZsNwODQmslgsGlvJyVfYHn1gjgjo3ubwl+jL99UHXcYpXYNh/0WC9U9gpw36Q3q+3woA0BoMBsYOwoxzH+83WYP89gWJPcsMUD48PNTdu3d1fn5uazlKlChRonzyJGL8iPEjxo8Y/+qBdVZSVuv1TGm61ny+1HI5VKFQ12qVUzab6vHjoZKkoPU6VT6f0XR6Vffv4KCparWoJKkok4kY36//iPHfX+LDvx0SDNgzHThqgt4usYIh48ZCYhGxCN+vzywmAn6xWLQ6GDx59+m7pFWzJ5+HISxArmUR+sVIWv5gMLBCr8PhUJ1OR9Pp1Binvb09PXjwQEdHR6pWq+awbxLS8YfDobGCvuYIIAfHg15wfqQVIzib2Wy2Edj5G1YCh0gbtVrNCotK2jgG3Z8W68WzFgQQn4Ltf4dsjSRjezwo9OnTFLWu1+vWDgdZ+PtlMhmrp+AZWxw5jpkC2ZlMxor8shWAU7+Yr1ar9cz1bB0ADA6HQ0u/bjQapksABwy1bxdGbbVaKUkSs0lJloXnt114XXuWnECKHXh7gGGD7fYBjf4AZkulkt0Tho00e+weXaGHyWRiANkzgSFD5dnNbQCCuWP9e/bOs8QI/fd99qx1yHr5LxrYNra27UuH/2LlgZr3VejX65l+h0yd98fY/Hq9Nn3wYJY59SykXyd+OwNr0oMGD1J4z4MSz4JHiRIlSpRPlkSMHzE+EjF+xPi5XFZpuv6ztV/RbFbWZHK1zXe9zmg+TzUYzLVapSqX8yoUMlouU63X0nS6/LMHZitlsxHjR4z/chIf/u2YYEikuZPGXKvVNBwOdwYYSNeGTn9hoDiy2qfX+n6HC38ymajdblvQ3Nvb0507d6wtHBkLuFgs6v79+8ZMkKLN+15wErCBvV5P0+lUFxcX6vf7uri4UKfTsWvu3Lmjk5MTffazn9V3f/d36+DgwBib5+l+uVzq4uJC3W5Xjx49smPpcaCAH5g/UsT90fPeeY/HYwMuvm5Ks9n8/9l7sxjbtiwt71+777vo4zT3nLyZNzOBqszCuFDxBIaHSiQQlCzLgCXbIOANVLxAIZAAWyokkF9syY9+s/xmy7IsSyUBxjJpTNKUBJVOKut2p4t2932zlh/2/UaMvU6c22TdzBPnnjmkUETsZq3ZjOZf8x9zTBWLRXNiHsyUSiWdnp5qs9nYiUfU38D5EtS90/NZZjg6P36+5kYaABA8vQPk71qtpmw2q3a7rSRJdHx8bKn84/HYxpy5gUFaLBZ2ChbMZKFQUKPR0IMHD1SpVFSv15UkibG619fXmk6nurq6UpIkajQaKpfLeuedd1Qulw1QDYdDxXGss7Mzq+0xGAz04MEDdToddTodG5coiuxEMdi0arVq7by8vFSpVNLe3p7q9br1mxotBE0PqghcPoAwnh70wYAlSaJ6va5Wq2XAk3liG0O5XLaACVje39+3tHLp5tQ1wOh0OtVgMDCABIj188f8s+3HA0j0GZ0tFAo2Nv1+32oUwjR7cEAbGDP6TzFlD1BoC2BiPp9bAWeYdITPsx2BMfdCgIVxw64BR3zG2wo6z3dYXGULkT+VjnYAJHO5nGVm0jfuw8Me36Ut2BM2wYMhfiIs/gUJEiTImykB4weMLwWMHzD+4pPF4C3Gr9f31O9n1OslWq1iLZeRJpNYm81SpdJKq1WiQkGqViM1GmsdHs61XkuZTE6ZTKLxeKLlMmD8gPE/n4TFvzsmPo3ep2izJeCuAANWtlFqv+LOana6rWlwQNCmLgPMDMVHOXqcE4qomZDP540VxLjSTBUBmDRjgnK/37c0ZlKhcealUkkPHjzQ1772NT148EDtdtsYns/aCkAQHo/HrpDr+iVni5Phde4P64HjIRBR0225XBp75MGPH0fpxqnhxEhvTjMjvhaHZy5hImFeJO20zzs2WA/PWHjWiz575wqAZLzY7kGqtySbK9LICTrMx212QL9g7dgSwRhTP4Yi0H7hLJfL6fT0VMfHxzsp6JlMRt1u104TG41GpltsUWHBLZ/PW8Fiir0ytp7tBSj6QODZ9UwmY4WTKfpMH9AZPwf8zclwmUxG8/ncMgLRWxhA9JJ6IP6Ye68jtB37RGdpI+3zAMD7BenlE6/SDB7B3euSD8h+7DzT7BlE/30CPWPp9TCt996mvY36DAJ0P83GeZaUefBt9Nf1DGkalDP/t/kIgAEPQhRlLpVKO2AoSJAgQYK8ORIwfsD4AeMHjL+L8RNtNitJjPFKSbKUFCmOM1qvI83na8Vx9MnW37WGw4mSZKN8PlImw0E5AeMHjP/5JCz+3SHxwRbmodVqqdVqqdPpaDKZ7DiT1y0oPayOZ4nY3+8FpSdg+nT1JEl0dHSko6MjHRwc6P79+ztFYKklcXp6akaez+dtbz7GBbNCnQNOl6I4bL/f3zm+vFQqqdPp6J133tGjR4/0zW9+Uz/3cz+ng4MDPXz4cKcuxG2Cg5zNZnrx4oV6vZ5Go9FLTAG1HtiKmSRbZw04YcU/n88bq3d5eakPP/xQ6/Va+/v7VsPNBxeczmw2MweCg2QbAk7fB99yuWxzQeCcTqfGslGAlJPRfAo4cz6dTpXNZlWpVHaKVTO2vp4D80UR3UKhYHPU7/cNDHin12q1dHp6qlqtZie9eYaFceWnWCzq4OBAuVxOh4eHxn6R+j+fz3VxcaH5fK52u61SqaT79++r1Wrpu9/9rh49eqRqtWop/plMRs+ePdNHH32k0Wikbrers7Mz/fCHP1QURer1esrn82q1WsrlcpZt59vGPANSZ7OZ1cGAqfVjxEMA7CTbDgaDgc0jPoI2wnYSvFerlZ4+fapisai9vT1jYX2x48FgoOvra9saQ8BiOwZzMZlMNBgMJMlsMZPZFubFH6G7Pghms1nTMdqNLkqyvlJsmTo4fjxoA9uDGGsPCj1IlWT2wVYSD+g9sABA+4LdbD8CZMRxvMN4Y1M8aAwGA+s//eRzbF+AySS1n/fxHR5s+wcHMiHW67Xq9bpOT0/1/PlzHR0dKY5j9Xq9OxEDggQJEiTI55OA8QPGDxg/YPw0xt/Oz7XW64JyuYo2m0RRVFIUlZQkNa3XiUajlfL5REmyXfB99uxc5XJO02lTuVyk9bqv9XoRMH7A+J9LwuLfHRTPtKF4GFGaeXndAnPgV+99qq0XzxJ5pgqWxRfmHY/HVigWY47j2ArSpq/h023jOLZAMJlM7ESiTCajer2uarVqNSJqtZoqlYru3bun+/fv6969e9rf37e6EJ+Vfovh02ZO4kozY3Ec79RzwRH4cfKgEPE1JZIksQLGpLbzmVKp9JJOpBknz0DwPvfmb2rGpbcQcG/6w5yjq35hKn19mKXJZGL1N6inASPoGUuY4WazaaexVavVnX7CgtJWXmPrCMHd12DxJ2/V63U1m00dHR1pb29PrVZL1WrV9AEnzZZbwC6OGrCEXpEyjj4AjGifdFPjxfc5HTAymYzV+IMFIlB7XaLvt+kjbCLMaiaTscLUbLWAEfS6KmmnuC3sNoDSs3h8lvH0c+8ZON9mPuNZNs/Evep1bxP0h4cJ337vW3jf6763sfR3fTaG/x79ZH5oC/Pnx8Pb/G0/vm9pW+T7tIuxQz98dgi1bV6lA0GCBAkS5O5KwPgB4yMB4weMv80yWyqTiZXLrRXHC+XzI2UyG2WzeWWzGW2nMdJmE2m1SjQeL7RcrpTLZZTLSev1UHG80nw+1XIZMH7A+J8uYfHvDglKS5o0dbzK5bLa7bb6/f4r02tfV3thsJIkUbvdVi6XMyYJo8EoWIn3gQRGCuZktVrp6upK3W7X6pdVKhV1Op2dFXXuD7NIMWFOXbq+vtZ8PtdwOLQaIxT4bbVaevfdd3VycmK1VnzRZdru7/UqWa1Wuri4ULfb1ZMnTzQYDDSbzbTZbAxYYLyc5sVWTgKAdxTz+dzGrFQq6eDgwILjcrm0+iX//t//eyVJYtsnms3mjjNlfGBHYHT8ke+SbF7os2dAvBPm3mzbYCEJ/fSOmOvQ//F4rG63qw8++EDX19e2MAVD6+ujlMtlvfvuu3r33XcNFHvQQrq8tw3ut1qt7PQpPkN70K1Wq6V8Pq/vfve7unfvnh4/fqy9vT1zuJVKRZVKxXT14ODAggRsI0ET5hdGslarWao4wMADr+FwqOFwaNl8ngUCrACI9vb2rGAvdWGwN39KG3PFVghYXvTo8vLSmEnPoF1fX6vf71tb6SNFmjlhrtFo2CJiq9XayQLwjBq1bbxu0W9eZwtIrVZ7CfAmSWLbe2DT0GUAnWcg8/m8gRh8pg+81MxhHAA1gBnanU6/596e0Ze2rDu6ht17YEAbeJhDX9Bd/7DEPbFRfnPvQqFg+pPL5VSr1RTHsVqtltrttq6vr3fAVpAgQYIEufsSMH7A+AHjB4z/KoyfzycqFGbK58fKZM6UzbaUzd6XVJbUlJTRYhFptdpovZ4qk1nr6qqvKForjvtKkqUymY3ieK2rq2sNBgHjB4x/u4TFvzsocRzvFI1F0WEP7pKg0BicpJfYrjQ7mH6NFF1SxjOZjDErGDuBIL3yT0BibGARk2SbAt9oNBTHsQXXk5MTNZtNnZyc6PDwULVazRgnv5hym8BG+j7E8bbw6HQ6tbpqjIHvvwcIjBsMw2cxvZ5xIZAUi0VzQv4nzfQxJn5u0vNAnwEpHiDQR18nwrfDB79XtRsHPh6PNRgMNJ1OLbDCOBFAODGsXq9bn+h7ejsMAQk9yGazxnQBgNI6Rt2XTqejZrNpwJP59+naBH22ncA2UuQY9sZ/XrrZlsJ7jB+/sRffbj8XZAFUq1U1Gg1JsmC8Wq1Ml/zYp1kt7gd4YTwIgugqn/cMOyCKYszU/eCaPmj6/3nfz7/XOfrrx4ugyfu0w/u+tE4RhD2Ddxs7TX9op7eNdBvTvsrr/m39+6wHM+byNr1N39ODivQ1aAvMYLVaNRDr6w0FCRIkSJA3QwLGDxg/PcYB4weMf4PxI0mxpI2y2YWSJJKUl5SRtH1vs1los1lrs1kqSVZKkomkbfZgHK8Dxk+1MWD8XQmLf3dMkiSxk6pgODKZbWoyDukugQOyirLZrAXvYrGo1Wr1UpFYv9Iv3QCIRqNhwfrBgwcajUbq9/uWjuyvId0EhGw2q1KppCiK1Gw2lclkjP2iGCwMBMEf58CWAACJbyNp5X5Vn60L3pHBolxeXhpbN5vNVKvVXkqTlm7qt+Fk2YKZz+d3AhP95DP85HI5tdttlctllUolK+pK0WTqjeBIAEk4Rw+gAAywFwRgHygymYzVOvF95xq+boYfE+/cPSB4+vSpnj17ZswtbSUwHx4e6vDwUCcnJ+p0Oi8BHLaOMBfSzSla9LHRaFib/bYFTgP71re+pb29PT169EitVkv1et3qqAC2fB2VfD6vk5MTy7ZrNps6Pj7WdDpVsVhUvV43Fn+z2Sifz+vo6EiSbH4BjrSXbQGMO20rl8sql8sGCE5PT1UoFNTr9XR1dbUDpgAX9JuTgf3WmNVqtXPCng9ql5eXxs7ymiRjkTlBjm0ug8FAV1dXNv8eSPpMBnSH1z3DDOj3BYhhvfL5vG1BoNCyZ9PQT77nA70HroAdACI1iajpAzuIDyXY+9eZd4Am4JUxRryuY0eMBW33QISHJ3wNjDcPFfgo7+ukm2wCahQNh0M9e/bM6tyk/UyQIEGCBLmbEjB+wPgB4weM/3kw/mq10WrVUxRlJF06Yj/ScpnXcrlRtztWHG+UJCMlyUpRtF38u7y80nQ6Dhg/YPxbJSz+3UEhldUXz/TFVqWbWg+vW3BGOGaCkq8n4T/rhRoK9Xpde3t7Ojg40PHxsarVqjlNTlhqtVrG7MCceGfD65zs1Gw2zeH7sSOV1xuvNyzPVvjVewLdbUwfDsIzlZ5RwNm8StLf9WOF4+I+1Jao1Wpar9c7jto7FOaEH8/ApJlN7+CkmyDhx4Wx5z78j6SdGU6cWinUZZnP5xYAOKkLgEdQ5Nj4NFPjA4Rvj6Sd9H8+z/+5XM5ADMW1/X24h9+u4r/PmMMCFgqFHcDKZ3kt3XYfyNAZrw9cJ81IYxt8f7FYGKjyoMtfK83uweyl2S3mIM3i+c/4wsBsTYBx9zblx9vbjB8f5s8zfp/GhqWBpteDNMOeFuace9I2/xs98aDZv562ad+ONMPoF139fdL1QhC+f5tP8NflOt6nsiXC636QIEGCBHlzJGD8gPEDxg8Y//Ng/NFo/Mm140/au9F6nShJNorjjVarqVarpaTZJxmAa20264DxA8b/VAmLf3dQYAU5sh5WA0d211hBGA4UmFOWOHWJrCNv4NnszSln3/72t/XNb35Tjx8/1nvvvaflcqnpdGor7eVyWXt7ezt1K3BKOGH/vyS7Jw7w6dOndqoRJ0HVajUdHByo3W5boPFBiLZKNwwd9/KgpNVqKUkS7e3t7ZwyRhtoIwABB8kx6bBCBD6csU99BhRUq1UlybYOCExMJpOx79PW4XC4U7MC9guG4TbH4p2hzyrj2owPDt8DAw9M4nhbw+Hs7EzX19d6//339eGHH+r6+tpqQgB2MpmM2u22Dg4O9ODBAx0fH1vBX+7BIhY1MwgqnCrG+z6YMWa1Wk2S9PDhQ5VKJT169MhYaIAJbaEfMDOwQzC8bFmpVCqmV75wKwxbOiAQ8AEUBA1eYy5w+HEcazKZqFKpqN1uW6Cez+d2ihgnqH300Uc7C3xkBHKy2ng81mKxsPm8OVlsbOOUDrIeIIzHY6s/EUXRzlaFtF6gQ/SHosroEfPKD2zzeDzeAZ1s0yErgDbBnHr7gv3D9+AfYMWpXeM/F0WRtZ1xQScB2b7WCPbCNQHk6AV6wPwDOGAT6Rd1GanBwrYQfBz25IEDdkCdIn7K5bJlL9w2h0GCBAkS5G5KwPgB4weMHzD+7wbjz2YDSQstl88/wfgrbTZrzeezT2pjBowfMP6rJSz+3UHBCfiaBjiNNPvyugUngvHjGPyR4Sg5f/Ob2g97e3s6Pj7W0dGRDg8PLTASgEi99sAAZ8yPZ2KS5KY4MAbOSV2kaeMobluZx6mnxzm9Ys9nMdJaraYoigwMMTZpJgjH5tlMzzj4+3m26Lb2eNCRZhP4+TRGMs3kvIrV4B5+HNL/exC1ZaxGGgwGGgwGBlT8NgScHKdycfIVjpn2eKfn7832E/+59Jwyvpz+RrHfYrH4UvFaUtQ9IEmDcN9vApdn/JhrP46851ltAAgnjBUKBQtKtAXd57rz+VyFQkHL5dIAHod2TCaTnaw+Ti1Ls6QAJ88236YPnrXzJ90BbAnyacaTMfLifQM6ywOFf1/Sjk34bEXe83bPZ7gvAdj7SoKtt8d0e32f06+jqwADXmdOGHPP3PuxZC79/94mab9nWG9jSfmMZwZD5l+QIEGCvHkSMH7A+NwvYPyA8X8SjF8sTrXZrJTNJspktpmB21qA608WAgPGDxj/1RIW/+6gLBYLXV1d2SlWkqxWAA6NleW7IL5QqCRjaiqVisbjsaWll0olS+XPZDJ68OCB3n33Xf2BP/AH9Iu/+IvGDqWDlQ+APgDdBpBIl+73+5rNZrq6utJsNtPl5aVms5mazabVWmi322o0GlbsNX1tf/1CoaB2u23/e2d///59dTodO4nqyZMnlgLvCyV7pnKxWKhUKhnDNBqNdu7FPPtU+SiKrE7bYDCQdLOtghoktJlTpUqlkuI4ttOtEIIodSx8f7LZrAUY+uprj1SrVfsc98OZbjYb9Xo9DYdD/dZv/ZaeP3+uH/3oR3r+/LlGo5HW67UODg5UqVT06NEj7e3t6fT0VPv7++bwSD9nfKIosrom4/HYGNl8Pq9Op6PpdKrz83OtVisDhIAa2B/sp9FoqNVqqVar2TVx1Jyg62umJEliDCCLZtK2bsbFxYU2m4263a4ajYaOj48NUBAwkiSxa1L3otPpqFQqaW9vT9VqVfv7+7Z1BcBA8CEIVyqVnVoybLc4PT3VbDbT9fX1TtbfRx99pPF4LElmB8vl0sAZwTkNDtLgCjDAd5vNpm192N/ftzmH2UrrA+9HUWR9xN48i4p+RVFkBZt9sI2iyOqPcEIggAgGLg208RvS1n9uNhtNp1M7EY7ADsvngSHt99kYudxNLRcEBhym0fsHz/Ay1mnfhU36uQC84Cexi1qtZtujWq2WndBGO4IECRIkyN2XgPEDxg8YP2D8gPEDxn9dGD8s/t1BIXhwGhhKgqKkmYrXKZ5B4AeHlm6rX7HP5bYFe9vttjqdjjqdjur1urEdP2lbEN8ev/LuT9Px9SAwSs/kpRk5H1gRHLcktVotRVFkhywwBt7gPSNAm3xBVtKSPYvkr4NezOdz0wmu5RkF2opzum0riWctPAjyjAziAyjj4oGaZzVns5mlkl9dXWk0Gmk6nVqg5qj7Tqej/f19C9TS7hYMfhgLgpafL8/iSLLg6I+OZxx90WXPqnhG0QNSHzjSIJxg5BlmQC/39mxOHN8c707Q41QxftN3X98lrQe5XM50CyA4m812svooIJzNZjWZTFQsFjWbzXbYTgKhZ8O8XqRZwUKhoOl0aqwkAJy5YEw8oGKu0uyqty1/37Sd+DH0+p0GsemsA29L/vNptjbdV8+y8R1/OiFj5m2Ba6QfJPw4pO3NCwDQt8W3wTOgMIL+IREdDRIkSJAgb4YEjP+TtwUJGD9gfOYnYPyA8QPG/2ISFv/uoMD69Ho9XV9f77A2aWO6CwJrcH5+rtlsppOTE1NYjNkbYK1WU6PR0KNHj/R7fs/v0YMHD9TpdHZWyP3vtNG9Sgje2WxWe3t72mw2Ojg42HHu3og4dQi2aTweW/pztVpVq9WyE8p8SvBt9yyXy7p3757VLRmPxyoWixqPx+r1elosFuZYqAnBGFUqFVWrVY1GI43HY3M0sH044+l0qqurK2NIisWiOp2OsSWwHt7RozcATH/ikWccGGvYQJ/G7dkpX3MhPSfc/8c//rFevHihH/zgBzo7O1Ov11OSJPrmN7+pVqulg4MDVatV3bt3T81m85P6FTNjQunbZrPRYDAw5hOn7Ot/nJ2dWaDEsS+XS3344Ydar9fG+t6/f197e3u2hYBi2+k+ENRhZv02BgI2bfAghECZydyckEZ78/m8FT8GBC6XS52cnKher9spZIABwAvjIW1rBMFyMW8EnnK5rFarpc1mo8lkYuzdYrFQr9fTdDrV//f//X/q9/vKZDIajUYajUamU/5UNgIqWQeAKPQhk9nW65hMJhoOh8rn8yqXy5JkxYIByB5oSTfbM/r9vvkMSXaa32QysXqEzA32BVNKjQ7PWEfRdnuRbzfMJu32jKJ0s0XAv++3bOAn0iw4wJZ5z2Qydk/+z+fziuNYw+HQrg0oYy79w4Hf9uHBhGc11+u1SqWSDg4OdHp6qq997WuK41gvXrywmo53JUskSJAgQYK8WgLGDxg/YPyA8QPGDxj/dWH8sPh3B4XgQTFXvzIs3Z4K/zqFgEtRYFJrcTYeHEg3aeyVSkWNRkPlctmMx1/T/0Y+q+8YFoEEJgZD5Bh12BzS86lbwalVbGuIokj7+/sWGG4TDJi0+1arpVxuexqZZ22iaJtaDzODeMbXA5dsNmtME30gbZ16KwQUz+IkSbKzhSI9pv719PzcxozxGdrptwIg6Ox8Pjc28Pr6Wr1ez8ax2Wxqf3/fUuEbjYZqtZoBMn9Pz8AQZDwj49PiCWYeNFA017cZByzdnLB2G6u5Xq8tkDBu9N8zr2nAS9uYS8AfYIQAWK1W7ZSver1u+u8ZTP+ba3vWyrOFBE8f5JiPQqGgyWSiy8tLRVGker1uQS2Kop0tAtlsdgdA+zod1OghU4Gx92PHmKIznnX0AqtIP/wP1yHdnf75tgFyCba3sYGAbz7n7dQzj54V9Uy310Wvk97m/bXTAlDAb/j+eZ2hzelre9vkOx6YwCanfUmQIEGCBLnbEjB+wPi8HjB+wPgB4weM/7PG+GHx7w4KSjObzfT8+fOXUtg/L0v2sxSAAavotVpN+/v7SpLEGBicLgwTbBin4KSDGM4Jo/Tvv6r/HqQsl0tdXl5avQjS1KfTqdV4mE6nms/nms1mBsIyme3pVKenp3r8+LH29vYs6HsD9wKLl81mdXx8bCzgeDxWo9HQeDzWaDQyZ5rJZOx4dQK8tGUMarWa7f2/d++epQD7WhXFYtEYmziONRqNdhw5bUwzrWmWEPGMiHeY6Tn2bK93srPZTB9//LGeP3+u3/iN3zA2ENYzm82q0+lob2/P6l8QIMvlsgVAAALsIMGe+ZzNZqY/y+VS/X5f6/Va3W5X4/FYH3zwgabTqa6vrxXH29PCGCuYJbYa+NRzAiO1LbAxDzIJ/Ogj7B3AhXon9IcAvVwujb2DVU2S7clx1HrhWozvbYd1+DGnHYVCYSeQ1Wo1++5ms1G1WjXWaDAYKI5j9Xo9nZ2daTKZKJvNajqdvqTPFE322yfm87lGo5Gurq4M4LbbbdXrdZsT2FTaClNJrZxMJmNBO336ld9SQVCln+g94Bqw7QMmtVAk2VwDSgF63l48+EEXAOPox2KxUL/ft/lhnHm4oC/YP/oFkPKAOg04/DYdWGVvw96vwJRHUaROp6N79+6p3++r3W5rMBhYMeiQ/RckSJAgd1sCxg8YP2D8gPEDxg8Y/3Vh/LD4d4dlvV6b8bICfBcFZSRFGifM0dWeTSGoeFbjtvTy9Mo5DvG2z/nPe4PGqEejkZ4+fap+v6+LiwtLh2Z85/O55vO5VquVtXu9XqtQKKjT6Wi5XJrRf5rh0Y9KpWKp0fl8XvP53IKcpB1niEOg7TgyAibp4h6U8D7jCIsCu0Bw90wyTsOzJ94JMUd+nD1byDzwmp8H+nF9fa2Liwt9/PHHuri4sPcJLr7AMdsLfKo0AYzXPJMKgwuQoo7KdDrVcrnUcDjUcDjU9fW1ZrOZ5vP5S+nVPsh6JjGOYwskzCPBme/SzzST6K+L/tzGqnpWiX4D+BgLAjBBkbYyx+m2eLvwYy3JtlRgY6Tpt1otJUmiyWQiSQZmfGBkPAj06C79hxGcTqeqVCo7eoceeYDpdQQQ5cfO6yYsV9rW+Gya1cXfAHY5QZCxBsx6nUansDXP1qXn1bPQnr3320CYI/SGH++T6Ge6P2k7SjOpjIkfH2oa4RvIVvCMdZAgQYIEudsSMH7A+AHjB4wfMH7A+D9rjH83I81bLp41ury8VCaT0f3793eO3r5rD3kwQzBhsCU+1R/nxpHi1L9YLBY7DtcHutuMlft59q/b7Wo+n6vf71sQWa1WevHihSaTiS4uLjQej3V5eanRaGQp2AACgrJnzLwz8kHy0wTjzWazOjo6spoU0+lUP/jBD9Tr9XR5eamLiwu779XVlTKZjAW0x48f6/Hjxzo5OVGj0TCHhONOBznYjyRJDIilHbUvOJwkyU4NAfrkWY+00/KveSC3Wq3U6/V0fn6u//P//D/1/Plzffzxx5pOpzo4ODCnxbV9HQ3GmzYPh0NtNhsLRvP5XIvFQt1uV8+ePdspgkydjEwmo+l0qhcvXmg+n6vX6ymKttsPyuWy3nnnHWsHDppgmSSJBoOBZrOZBUH0lrGhv9S/gIUENLD1o1KpGMuFTtFG2gkY5XMwlh4koT/lctnu44uCw2guFgubX+8TqJMBeGKeCODtdtvaUiqVjEXz6elxHFuR5mazqVartVP7BMZb2qb3X19f2xYfz4oSKOk/esnWCK8PaXDjGerZbGbMKnYJMCRrQJKxg3Ecazqdmv/BdrFxrpHP54355OGA+2M3bF1A9yjIy/YXAIEHz1yj0WjsBHb8HGAFm2DemUtOEEzbOVKpVHR4eKizszO1220DQ2lGMUiQIEGC3D0JGD9g/IDxA8YPGD9g/NeF8cPi3x0VAiTp62lDv2uSJImlwcLISdoJZBgOdQUwttVqZcbCtW5bHU+zOqQGz+dzdbtdTadTXVxcWNBbr9e2JaDf72s2m2k0GmkymahcLhvTlw6C3Pe2n88j9KNSqRhjQDCAiSQI0g/PQOXzeUu1Jg04fe00G8oPzhdd8U4ThoPx82nxr+ob9/a/+cHZTiYT9Xo9ffzxx3r69KlGo5ExQLCXtMczcr7NADXaTOBhO0Cv17OgJN2kfLOtwwOHfD6vRqNh49hut43t8kwd7SEVOz0+zB1MGIV2PUMKSAFUpLdbpNkvwIlnxWHR/Rx78OXrPTDmzB3CtQFO6QwCxrhUKmmxWKhcLmuz2ahUKmk+n1u/0Zd6va5Wq2X1W0hzHw6HBmSlmwLQbKXwKf+k39MPD3wYJz/efI7AjJ7AwNF/xox+pwMybB36xxziUz3oh1Wbz+cGwuI4tntgF9QJYssDfs5v8eC66DG2S9D2oMQ/3HmwzXt+SwjzzfvZbNa2bABo0z4sSJAgQYLcXQkYP2D8gPEDxmcMvG4GjB8w/k8b44fFvzssq9VK/X5fnU7Hiqe2220tFgvbz35XxAMDWEEfEHGErKDDeH7wwQdWJLZWq1ltAepjeGeFk5hMJvroo480Ho/19OnTnWPXKZQJ47ZarawOw2Kx0OHhoV3TGxKG3u/31e12NZvN9OzZM+XzeR0cHOjg4EDvvfeeFeP8PIboAyd1FGAnfV0Q0qv39vZsrz91SNL38AHaOyNOOPInRFGjIo7jnXnwDhPxxW/9PX0w83UyYG6vr6/1r//1v9bTp0/14YcfqtfrGeNF3Q+2SBwdHVltG5yld/qTyUTT6dQc9NXVlTGol5eXO44byWazVtiZgJDP59XpdHR8fKyvf/3rOjg42GF/lsulms2mbU8gWBDgFouFMXYEL+rYwCQ1m03t7e2p2WxaICC4Ax4AR+VyWVEUGYtFSnetVlOlUrHtAAATdAd7YewJEAQG2kVdFGyPz7FNg6C92WzU7/c1mUzs5Lt8Pq9arWb3PTk5sVo42CQ1RlarlUajka6vr7VarQyUDwYDq6FBwWWKHWcyGbNlD+w9IK9UKi8xzWwz4LrMAyANNhNdHI1Gdl/GS5KBPuYC0AULyximsxji+Oa0sSRJlM/n1Ww2dwCUZ/uwlXw+r3q9br+TJNF0OrX3sCf6ie7hBzabjTGPfrsB7cBWq9Wq6vW62u22RqPRDjvsPxskSJAgQe6mBIwfMH7A+AHjB4wfMD7twFZ/2hg/LP7dYSHlndoUpVLJnMldZAcxYFhBjNMzg56JGY1Guri4UK/X02g0Ui6XU71e3zFsL56defbsmfr9vn77t39bm81GzWbTHC7GvdlsrBCttA3+1NZgVR7n65lMnGy/39fV1ZWePXumKIr04MEDW+3nmp82D96RzedzYwNhLWkHzp004larpb29PdVqtc8ccxysL3YaRZExEOiPZyh8OrJ0k659W1+8E/dAgn6NRiM9efJET58+Va/Xs2BTLBYN6DUaDRWLRTUaDTvBzLOKOEgYYsYNtnEwGGg8Hu9sJSAVHIbG17SIosiA9P7+vg4ODuw9tkagl/l83lghAArXJih5JgnQUyqVVK/XLaj58aN91NxgzHH0fjsABXAJRunx9owa/YT1w95gmjnRDvA8m810dnamzWajTqdj207QdVLJi8WiBZLDw0Pdu3dP9+7d0+HhofUVAFer1VQoFKwALfNFuzabzQ7jSJCj/2mdAqQCqjxj7dlNz/5tNhurC+MLLjOXzG06u4C+Mo98hnthF/gD317a6Iv8MmfMK3rDdcrlsuJ4u1WKOfR25dle2FTGD3v2tWH4HsAGfwcY85/DvoIECRIkyN2UgPF3JWD82+8RMH7A+AHjB4z/ZWL8sPh3BwWlmc/nGo/HZoDZbFYHBwdaLpf64IMPXnczdwQlZDV9sVioVqvtnMTE51jVf/Lkicbjsb3/zjvvmLHDpGAc0+lUw+FQH374ofr9vn784x9bIVgMnRoBGCuOJJfLmQER1GFHvFPyR2wPh0PbTjAcDnXv3j2NRiM1Gg2dnJyoWCyqXq8b+wGDkWbUvHESTAiMnIRGvQXYR9iUzwJ/pAdnMhlVKhVJMsCCc6rX64rjeCcgAyR8MPNOy4tnZJm3q6srzWYzdbtdKwBM/Y+DgwM9evRI9Xpd77zzjorForFt6DUsIfU+YPMIPtPp1E6OWq/Xqlarevz4sQVB2gCD54uyFotFVatVa0ulUjH9SpJE/X7fbIm5KxaLVnPCb5Pw7SoUCjo8PLTtDvV6XUdHR5aWnc3eFPHl5DDGjZR75gf9pKYHjt0HKZ8u7ufZM0SwwXwniiKzP4pe//jHP9ZqtVKj0VChUFCz2bSaGZystlwu7bS7o6Mj3bt3TycnJ9rf37dixf50rqurKwPnsF/0YbPZqFar7Wzz8Kd2STIwhC2iG2nQyvfTbBeBUdJO6n8URVarpFqtKkkSG3vGh1olHqzA0jGm/kEmnarPfPl6McwTgJjtIfgiWE500J8exne97bLFBKaf9z2gm8/niuN4h1nmXrcBgrAYGCRIkCB3QwLGDxg/YPyA8ZnjgPEDxpd+thg/LP7dQcEQAAe+6GWr1dJwOHylI3+dgvF7lsufcITD9Snfo9FI+/v7arfbKpVKOjk5MWeOYa7Xa43HY3W7XX3wwQfq9/t6+vSpGRuGmM1mzWAxRknmVAkQGDkOS7opQIpxx3Gs4XCo6XSqwWCgfr+vYrFoWzKq1ar29/ct4Hp2B0kDA3/kvSRjeWl7s9m0wrLpa71K+AzXZB4YOwqvwnYg1A35LPHsx2q10ng8tgLL5+fnGgwGFiwbjYYqlYq+853vqN1u6/j4WJlMRi9evLCaLKvVSrnc9jQjghIB2Ad+TmgjzbzZbBqDOBgMNBgMJMkKp7JtARaq0WgYG8mcStJgMLDgks1mrS5MNpvdCZTMHwG8XC6r0WgojmObR4IsLDQ1HPzWi/V6vVPk2AMDDzqYN4JPei7TrCyvozvcD/tCZ58/f67FYqF6vW765tPsGX/GrNVqqdPpqNVqqdVq2WllsGGDwcAY3G63a8E9jmMDB4BydAxg6HUKEIduYcvoNKAAsMDneB9A4dlDwA5B1Qdh5ojfvk7Ip7GxAAX0wW8FSIM0/IfPSvB1ZrhOupZLen79ddJ1UbABAA/6S62hIEGCBAlytyVg/IDxA8YPGN/PZcD4AeP/LDF+WPy7g+LTYjFInM7h4aGduHXXBFZjMpns1EjgB4Dj9/evVit9/PHHkqRut6vz83O1Wi0dHh6aA55MJnaC1/n5+UvbDUiPxqFjYLAFHjBgpKT2097ZbGZBARBRq9XsupPJRM+fP1e329XFxYUqlYru3bunarWqy8tLlUoltdttc7C+mChOEQdHKi/p8u12W7VazRzy4eGhJFk6v2eFPGDyfU1L+vXPYhhfJQTLwWCgs7MznZ+f67d+67c0Go30/PlzzedzDYdDc5pRFBlrcXV1pSiKNBwObW58ijdC8O12uxoMBsZ+EORhe2Al+/2+gRHAA3UUarWa9vb2dHx8rKOjI0utRh+pRQIAIbAS4AiWzBnfieNYo9HITn+CWZK2W0i4Nwy0JGP9cPAw05xS5mu3+KCXnqt0SrufU/SJa1Kv5MWLF7bFZbXantZWKBTU6/V2CipXKhUDX2nwyDwBvJIkMUb26upKvV7PitFms1k1Gg1jEXO5nPWfsSyXy/Y/wIigKMmYLh8oARcULSYLgODLmHmAT3p9OnhvNht7qAJQ+O0oPIhF0U3RYPQlHZwBE8xvsVhUuVw2Vnqz2Wg8Hr9UwBpQ4m3As8LMK2yy75PPfsA/7e/vq9vtqtVqaTweazabvfRA4v2FB2hBggQJEuRnLwHjB4wvBYwfMP5WAsYPGP9njfHD4t8dFZyFZ0wymYz29vY0HA7vJDAAzLBXX5I5d/bS+8+xiu2PcL+4uNDBwYEePHhgTAxMFOni0k2NEQImCu/rNuBUYAw8GwNomE6nFsSur69VLpctxbZcLluQApxIW+OqVqsaj8eq1WqaTCY7jCbBhCB+Wz2JcrmsarVq6etHR0c7jAwBFpDl2QaYCdiV24L+lwkMJpOJrq6u9P777+vZs2f6zd/8TQ2HQz179mynX6SdA2b7/b6SJNFkMtmplUC7aTvgq9/v68WLFzZHrVbLAhcggCK2vj4IcxtFkWq1mtUB2dvbs3FKAyuCAEWSYa+p3QC7BuObJIk5esY/n88bY42jJojh3LGBOI4taJLG7ecFZ37bPOEL0Nk0kACU+ACPfhIQp9OpMpmMhsOhjT1tpY3YlA8qfnsNwarb7Ro4W6/XqtVqVvSZ7R6kxNN+gHg2m9V4PDYf4HWC7R20A2BQrVZNrxgzPsM1aDPX8sV/aQPjQHvy+bzZJvf2einJ5h9fvFgsNJ1Od2wZFrLVatlrPn2fdtMWz57yvw/+s9nM/D51VfgO/gz/1G63LZsAcO63XyBh8S9IkCBB7o4EjB8wfsD4AePTloDxA8b/WWL8sPh3R8VvC+CHeiCDwWAnMNwV8VsCCOIwLbwPgyPdFPgESJA+fXZ2prOzMzWbTZ2enlqqby6X09HRkfUbQ/f/44y8U8CpAEb8VgFYJ4xvtdqenjSdTncMG+BCUCGAlEol9Xo9lctlYwuvrq4sOCTJtgbFbDbThx9+qOvra1vtp6YIfcfhwqrBllH4E8dQLBbVarWs5oZPG/Z1CnBePp3ab5/wTgZZLBZ2b9r04sUL9Xo9PXnyRIPBwJwhNT16vZ4kaTweq9frKZvNWoDwDG2r1VKxWDRm5uLiQsPh0Arxnp2d6erqyvSn1+vZ/8vl0saFNvo5xDk3Gg07vYq0cIJHLpezLRnz+Vyz2cwCE/romRefoo6Tpm2MjyRjhWDDSNeGXfRsjweKzIO/NwGJLQ58HjALA877XLdSqdh2hTiO1W63NZ/PrQ98ttvt2mlrvg3oAQzZbDYzMBFFkQaDgbrdrn70ox/po48+0mQyMR08OjpSp9OxuijYDsAKQIB/YF7op28Degpw4aHC11jhu9Tb8KypD7AeZPF/uVy2z/p58aDbf89vNYCB5vNkLaBr1DCiTTDS6TbwkOe3PPA5+oI9cz/mx7PpbNcADJMt4YEj94VNBqQECRIkSJDXJwHjB4wfMH7A+AHjB4z/OjB+WPy7w8JKNEEtn89rf3/fUpA9G3YXxIMZgAFtJEj64IWDm81m5nw2m40xZsfHx5rP58a4FItFHR4emqMmaGNE0s0R7ATHTCazU+SVH5yIJGNHisWiOUACEdsxOO4cw4WZyuVyOj8/V7FYtIKq1A4hmJASf3Z2pvF4bGnNpA9T2wCm5enTp/rwww/NGVGkGNBVr9f18OFDA0mFQsH6SFDy2w+8nlDAGCaiVqvtOBFqbSwWCztJ6v3339d4PNbV1ZWSJLEg7IEBKda5XE7X19eWbg5DVSgU9PDhQwtg6/VaT548UbfbNX24vr5Wv9+3oMt9YBlxlNJNsWNASqvVsmLLnNBFAAJUA7Cy2azVevFFkhHqlVBo1ztpn87OddEdGEcCCN9JAwNJZs+esWbOPItMIKGOCuJtKpPJ2KlTbF9ot9sGzD0T2+v1LMgADj0Y8sBgNptZW549e6YPP/xQv/3bv62PPvrIwClbWKhjE8exxuOxJNkc+roWAFtYQG+LtJXx8KDPn/Dlx8sX/yZgfxpLns6m4LOwrbTDp9UD8jxQoh8EZv7GnwEMfJ/QBcaU+ffMpRefOYGeeF1ar9c7BcXZKpbWO78NIUiQIEGC3A0JGD9g/IDxA8b/STB+q9XWZBIwPhIw/hfD+GHx7w4L6caceJXP51WtVo31GI1GmkwmO479dQsr7xyPjpJ6Ng4hyPr3/Qo/ARkj80wO6ckEEhw+jg6Dx7C4NsErvfpfLpfVarWMASD9d7FYGMjwQCJJbgoOU5CWoCnJao0whxzRzklFmUxGg8HA0tTp33w+NwfkAx9pxsvlUsPhUB9//LEmk4nVICFooQ/0j8LC1Algu0O1WrUaJpwWFsex+v2+BoOBFeSdTCaWfk8aO/3L5XIaj8c7NVsILP70o/l8buCnVCoZ2Op2u9beOI7txDscJ/PvHV06bd47v1wuZ46SHwK/d+iwZ4AMWBrv8AELOG1YHFgfgCmAg3omfiuGB+18F/Ep2mnggH6kU/P539ci8ffyn/fFZD0IhhVOM5KAUMDS5eWlzf1kMtHFxYWePXtm9XhISYcFhMEG3Pgi4LQLPWcc0Ak/RoDNzWZjtocdcA/Gin5ir4yB3+rggztjK90wioivzeJ1zD9MeBDDVgH6h957cH4b6PNt8sV90zrBePC54XBoDxr4IrIKms2mWq2WbU0CNPAgRr9vA0xBggQJEuT1SMD4AeMHjB8wvtdfrvVZGD+bLSibLSiKtj/Z7FJRFDB+wPifT8Li3x0WFGI0GtlpRK1Wy045Go1G5vDvikRRpGq1qkajYQHc121Ir3xjVLelqsZxrOl0agGGWgIYDIVJCVqFwvaYc5/ijvFhFP7kJm8oFHLFSeL4YUakm9PCSOHv9/vWzmw2q9FoZI7SpzcPh0NLkU6SxE5jIj2btngQ5dkaUs4JlNTnuLy8NFZQ2joUmEvmol6vGwiBpcnlcmq326pWqzo9PVW73bY56vf7xk4Oh0Nj0gATPoX58PBQy+VSR0dH6vV6+sEPfmCBBDYOgAfrl8lktFgszPH7gO+BIXPHd72zJoDCdPl08Fqtpnq9buDZL4AR6GH9mDu2m/jUeK7v2ST0jjkiBZu5gZWB9cIpUwQ3Hfg9e414YEFQwUa4P2DEg2oAMNcGUPqtH+i/P7WOcQewTiYT5fN5jUYjxXGsy8tLXV5e2vYMwCvjG0WRFYN+8uSJCoWCOp2OsWWkqNMmADPA2gdu5srbynK5tKwA9J85JPiSOSFtswLYnoF+eN+EbwDMMCecPsi9vX4RkNPbFwCQfIYTz2ij35LC3KDXPuMDP4FteZAK8zmZTGycYCABZu12WwcHB5pOpwbe09kRnn0MEiRIkCCvXwLGDxg/YPyA8b8oxo+ijHK5orLZoqKoqEymoFwuryhKAsYPGP9zSVj8u8Oy2WzrXXBCFYpJKjnM210RHGnaAUovp7ummR1WzjE6DJWgh6OifkYulzNWhu+vViuNRiO7DuyEb5N0wwAQtLzhVqtV7e3tGaChoCpptRReXa1WqtVqkrRTq4OUbpxFHMdqNBqSpMlkYvVK2DKxWq0svZ4fv91hPp+rUqmo0+lYmjtsaD6fV7/fN4dDYN9sNpaOT3DiBCiCPA5U2jIkzA9MM/pGkPTzCBCq1WoGntbrbfFenLtPm08zFD7Y+2t6vUizOT5Q+/8lWRo6YMrbBPrkmSiCNayUD8AeRKTbRjYdwcG3gWsTtOgn85IkiQGter1uDJhnzQCG/t4+qHJdf1/0jsBIe+kXY0rdG04LI1AAFDnFC9DLqVvdblfX19e2hWKz2Riomc1mBhwZHz8HjCvi+0ebsD0ADg8JnqldrVaWHTGZTF4a9ziOVa1WbbwYJ9ooycAafskXmZZkc+r9CfrqgTnghvEEEKA/HmjSxvQJhf6zXr+9v2Te/BYIwAlt9lsGKpXKztx6/fA6GSRIkCBB7oYEjB8wfsD4AeN/UYy/2cRaLhNtX8pKyqlQKCqTSQLGDxj/c0lY/LvDslqtrD7DdDq1Wg6cAMNR7HdFvILz26cd+8/47/A+n+dYc4psEgjn87kF0XK5rPV6bRlNBCBqEVCA1IMADBkHxoq+v3+j0VC9Xpe0dbL9ft/6wklO+/v7O6wg2xEqlYpWq5WePn1qTjSbzWp/f1/FYlEXFxeWZu+PNG+1Wvb9Tqej5XJpp48lSaJ6va7j42NF0bYw7HA41Pvvv6/FYqGLi4ud1ParqytJ0uHhoQqFgobDoSTp8vJS8/lc1Wp1x4EvFguNRiMLegBRnDRsDeOHQysUCmo0GjbumUxGh4eHmkwmltZ9dnZmDOttwNAzLzhhrx+e3fRB1wdM5pS54LN8hn55YACoAVB4dtIDC9pGMCM44HwJrgAKfrgfDp16JhRBbrfbO2zlbawnQh8AyLcBA8aO6wBKCRo+jb1arZpt0BZO3CuVSvYQMhwONRgMrDA3bCD922y2x9xXKhVj/3iPvhHI/IIk20IANJvNZqfmDltxGOdMJqPZbGb1aWDHmCcY3mazaUwj4xPHsUajkc07Dwr8MP/cC6YVu8C/8Lpnjf1pZ6PRSKvVykCIdPPwEUWRAW8/Z16/fQaAB1S+jgp6CIML68f4woSXy+WdMcAefGHuIEGCBAny+iVg/IDxA8YPGP+LYvzNJtFsFms+l+I4oyjKKZ8vKpeLAsYPGP9zSVj8u8OCQWE07LcnPZsj5++KYDgU85VerlNwm3j2gCAOS0j9CukmnR8D4l6MURzHxnRhCJ5pkGTGCyOD8/EBBDAjyY5tp/5BqVRSpVLZYbsIRLB81BqAZanX6yoWi+ZYvROgX/5/2EGcAses4xySJNHx8bE52s1mY86JMTw9PVWxWDTnAVORdhC8Txvy+bw5Fmmrg4wZwQdHOhqNtFwurXYE4MOz2ACutC7cBhQ8G+f1wjs5DyRpO+LZHMaFz1NHgvnmc9nsNoWf4ORTv306O2O/WCyMIWPrBrqH0CYfEHzQIu0ex5/WF+bQL+Z59ihtO9JNkdz1er2zlchvZ0GHAQIUUfa1a3wNGAI1c+5ZeHSL+9EWfw9YbN7zgNODdfSR8cbe/bhzL77rmUXS5rkWvkHSSyd/TSaTnQcW/k6n6DOunjVGb1hUlfRSVoHXZ8bFn1qH7Xt99w8n/p5ez7k/fsK3pVKpGDDgQYq2eEBzl2JFkCBBgrztEjB+wPgB4weM/3kx/jbjb63ZbK3r66m63bnW66ySJK9MRsrlMiqVKiqXS2o2A8Zn3ALGf1nC4t8dFoyCh/lms2ms2d7enkajkRnA6xYUnpocrVbLmC9f8yH9HQ9+CIas6JOqLEnNZtNSmDGMbDarTqdjQZl0YO8Yrq+vrR3r9VrX19e2b57Tnkqlkp1q5I0I4zs8PFQ+n7eaI9Vq1RgDAAIBknodkiyN/+DgQMViUZlMxoLCbDaztvo0c0lm6DBsjUbDChUvFgtVKhW1221jEheLhT7++GPNZjO1Wi1lMhm9++67KpVKVkialHSCGGnXBNFMJmNOlNcIeoPBwLYnkPLMdpX5fK6Liwt73zs5nCx9JwDCcqRZP5w980vQSb/unaUPmB4U0D/em0wmWq+3p6jBasVxbAwVWz8ouExNCXSJoDEej3V2draTwu6ZSK6ZJIkVh4XRY3w4OY1CxcyR3yYAYwYTTGBIs6YEpUKhYHMwnU51fn5u80KbSqWSGo2GqtWqHj9+bAx4LpfTRx99ZOn/19fXNn4U5AU0eFaMsfY1bfw9Op2O2SE+jGCezWaNoUb/PdPrswn8nNJf/4BEWj6ZjYC9fD6vdrtt47fZbNTtdpUk260RhULBQL9n2rxuMg4ARcDhbSCCeea71GpiS4Bn172f8TWLGGv0C71mbNjSw/jDyC+XS/X7fbVaLQPuXM/XuAkSJEiQIHdDAsYPGD9g/IDxPy/GXyxWmk7n6vVmevJkpIuLiRaLnNbrvAqFssrlnGq1lmq1ir72tXfUbAaMHzD+7fKFo8o//af/VP/gH/wD/ct/+S/14sUL/c//8/+sP/Wn/pQN4t/6W39L//v//r/r/fffV7PZ1B/7Y39Mf//v/32dnp7aNR49eqSPPvpo57q//uu/rr/xN/7GF23OV15QlOl0qsViYQGYk47u0lautFHh2G8LBtIuM4QB+DRiAq53iN4p8j1pl1HAaUiyk7BI5yYdfzKZaDgcWt0RVs89o4lRUTsCFicNcPyqPfUeuDdFSaUbZwbzxvVIV8aQAT04AILkbcAKx0smFw6Ga+OsKNzqWQ5SiQnc9KFYLNo4zWYzY//Y5oBDggWdTCY7zKtPT2cc/fynQYFnhm57n/89+wtbCKhhXhaLhTHopPoDOhhHL3yXcUIHkyQxJhXdSjOSsIKemQMQSTJd5lh42CFqWhBoJZnjpj9+LPwY+sAIMODzACf+92NLWwhCjBPtns/nBnL5oR8EbsaILIXBYGDAxr8/Ho9tftCnXC5n9WJoo+8T+oEt+7H2p8phz9iHtwXGXLphZJk37Mvbup/LNPjimtgT7UizvP7+/nve5n1f/bz6ufMPSWnbQH9vsxv6xniUSiXLjOD9fD5vtYuCBAkS5FUS8P3PXgLGDxg/YPy3B+Ov1xtFUUZJwrjdjOFmw0It230TrVYbZbMZ5fPSZpPReJzVdJrXcpnTZlNQHBckFbVeb7ReS8tlrNUq0Xy+ULEYMH7A+LfLF178m0wm+s53vqM//+f/vH7lV35l573pdKp/9a/+lf723/7b+s53vqNer6e/+lf/qv7kn/yT+sEPfrDz2b/39/6e/uJf/Iv2P840yK7g7LrdrjqdjrE3BwcHGo/HOynOr7udnimBLUinh7+KHcT4KH7LavpwODQmzoOCNKjAsfqACIvoWSTSnN9//32dnZ1Zmv/9+/e1WCx0cHBgJzfFcWxsoDd2+sk1WVAh6FerVeVyuZ26C6SZFwoFS6f2dR5wODgiHNhqtVI2uz1dzLNP9J97Hh8fa7lcqlwuG+OEk8vn8zo9Pd05YcmzT3wONqFUKmk8Hqvb7arX6+n8/Fyz2cxqizAGviaBn0eCHW3k/TRAxNl5Fuw2xtCPeRowSDdbUeJ4W/9hMBhoOByqVCrZ+OFcCXi+poevX8FYAIpgjWnnbQGL68MasYUCJprtAzA42ez2RLtSqaT1eltEGTaL6/qAgW0z1sw5r0k3NSZ4z7NP6N9yubR0cerrIIA8GC/Y0Uwmo2q1ajY9n8+thoYvzFssFtVutzUej+00vidPniibzarZbNqDDGwdgZlx8foDkEAfOI2P7zOGntGm/zBwbBFI+4dyuWzvE4hh/jabjW1B8g80fGa5XL5UsBuw74O0vy+AxgNO76uxF+boNsCMrjInXjwo4KTI2Wy2Y4ulUkkHBwc7WxaCBAkSJC0B3//sJWD8gPEDxn87MH4UZbVex9psVoqijKKIfsaKou3C3Wy2USaTVzabV5Kw1VbKZjOaz6Xz86IuL0uaz8taLEpKkoaSRFqtxoqiRJPJRlG0Ur8/1HIZMH7A+LfLF178+973vqfvfe97t77XbDb1G7/xGzuv/Xf/3X+nX/zFX9THH3+shw8f2usUOA3y2UJAwxFHUWQOC6W6LeC+DvEr/RgshpL+jGeNCBQEOs/AERB92jySZgtx0gS8NDtVrVY1mUxs/GCKcHicbkW7CeTSTeFVnAbp4qVSaWeF3wdb6aYwMQGSgJROb08HSJwkbZdugizinQxOwgMon6rNFgaclWeU04wGi0UUJuZv2nEbm+O/z9/MtX+N37SBYOFrK9BXfw0/Dv76fixms5n9AAJZKPN6COv8KrAK0E0HGACC31KB3qb1xGfiZTIZYyml7faARqPx0lxwfa7r9Zq2+gVBvkdbfGq7tK1nE8expZI3Gg1VKhVVq1V7D6DInFarVfM3XNcz0wAf5of3ZrOZstmsLi4ubDsJ2y1qtZr29vaMSU2PFX+nAyzz5LcLMdeMBf7Bi8+QBBB6fef7vM7/Xh/8NbAtb2MenKQZRXwDeoMvYu5oE330ukmffBtgoQFo3k54ACqVSlYnCvCCXgKoggQJEuRVEvD965GA8QPGDxj/q4vxs9mcpIwyGbJNs4qiWLlcpFwuUjYr5XLbmn6zGZgxVja7XfRbraTxeK3xOFG/v9JgsNFqFSmOM8rny0qStcrlSIVColqtoWq1pHK5qkqloCQJGD9g/Jflp15MYjAYKIq2px15+ft//+/rv/qv/is9fPhQf/bP/ln96q/+6itrW/BAi3h24m2Q1Wqlq6sr7e/vWwDqdDoaDAbmVNMO+nWINyiCj2fGpBsFTzNESZIYA1etVq2wJQGkUqnsGBv38/0myPjfpHOTZry3tydJdkLQZDLRdDrVYDAw5q7RaJhx1mo1u7e0dTiTyUSZTGbnRCPaGcex+v2+9VHaguZKpWLp0+gygYsgI8mCDmxWs9nUarWyo8Z9IGI8aRfgAucDo8B4SLKaHHweRhOn5ueJ059gyKhn8So9807aB3ScmAdMURTt1FcBXMG2wCTDGlGXwgeDNChYrVbqdrvKZrO6vr5WPr892czrHwHE998DKfoBWPTZcoAXACuZc/P5XMViUZVKxe7BPEqymi1PnjzReDw2gDudTm1+Dw8PbWEuPU7UJmEsAW68B/NITYh+v2/sUbvd3ikU++DBA9VqNTUajZ26KNTmWC6Xpm+cvDWdTvXRRx8pl8vp6urKWDqCKuM1GAw0Ho81GAwMpEXR9vSxZrMpSTo6OlIcx9Ymn9YPK8ZCpddJgrC3K/+wgA8kaGJjsO6MR7FYVBRFBu6xO+7F1hbYUeyaz/gHl2KxqPF4rKurq51Ajb+p1+s7jKVf4CXI+0Ve2FDmn7nwPs7rPddmG1Kn09Hp6ak2m43q9boBqnq9bm0JEiRIkC9Lvgx8LwWMHzB+wPgB4381MX6j0dR8vtb+/kpJ0lIcV1QobJTPZ1QuS+WyVK0WVa2WtFrFurxkO22sUklqt4taLNYajea6vl7r/feXGgwWms2kzSavSqWtcrmiTmelSiWrBw8OVK+Xtb9fVqmUlbRWkgSMHzD+rvxUF//m87n++l//6/ozf+bPWFFXSforf+Wv6Pf//t+vTqejf/bP/pl+7dd+TS9evNB/89/8N7de59d//df1d//u3/1pNvVOC6m4BBLPVt3GlL1u8U7DGzjyKhbGKz/OgOO2vYHxvg+UnoG8bZWfz8FINBoNq/dAyq201dl+v7+TRk7dFQK/dOMk0obKb173LJp3OKSmEwD9Sj+f5R4Eec8e0pe0sfv/uX8agPkx9MwDTE6SJAbGcU447dtAAf2lPT5FGmYyk8moXq/v6G2j0bD6K6THo+uwkbPZTIPBwArUAhDoA789i7dYLCywzefzHR3yY4OuspCWZizz+fzO+JHuT7D022YJKp699GwRgYSxjOPYQAunbwFeC4WCBUxYSObF67O0ZZiXy6XVb+n3+xoOh1bfgyC2t7enarWqw8NDO1kOlniz2eycjIfuEYwJ5M1mU8vlUoPBwACm1/90/wnOXGs4HFqtGdh0r8PoJPOIDabZv/Q8+ocMfmMjabbbv0Yb4/jmFDbaig6j2x6sp32RB8L4PsbD26Rn8L3e3GZTt+n4q77jP1sqlcymmEcWj/01ggQJEuR3I18WvpcCxg8YP2D8gPG/ehh/NJorjgs6P19qNltKWilJViqV8srnI5VKUqEQq1aLVaut1e9Lw2EiKVYms80CjOOsZrO1rq4W6vVWur5eajJZajaLtVxGiqLSJwtROdXrebXb28W/VqugUimrJFkpjtcqlQLGDxj/Rn5qi3+r1Ur/yX/ynyhJEv33//1/v/PeX/trf83+/vmf/3kVCgX95b/8l/Xrv/7rxl54+bVf+7Wd7wyHQz148OCn1fQ7J7AdvV7P6hxwOhQr6HflwQ42act4NES6ajpVPW0knkHCmdJPmE9JxmARMDFC7sECii8GKskYGlbrHz58qKOjI41GIyt4y88Pf/hDFYtFW01frVZ2WphfnKnVakqS7QlbBEC/yu+DVRRF6na7tjjDcfL+0AXqkKxWK41GI2WzWTNo2LLFYmH9h1FjzGELkyTZYT2SJLGaFGxHwAlyulWpVFKhUDAAyqlQ4/HYigDfJgAtHKrvB46Vehff/va3tbe3p+PjY9XrdZ2enhpjWiwWd05YWi6Xurq60osXL/TDH/5Q/+yf/TMDCDA3OGX6mySJBoOBMpmMLi8vjR1cr9eWUUe/AayANOzIF7UtFAqaTqcaj8dWDPns7EwffvihFZSmDcvl0ur1oMecBEWh5uPjY83nczudbjgcajKZqFqtarlcajwe2wlaBGEAGunjnrHERsbjsTGOz58/12g00vX1tZbLpSqVisrlsn7hF35BnU5HDx48sOLW9H+z2Wg0GtmWhc1mY8EEmz44OFCpVDK2yZ8qh+2i574YsiSrH/LRRx9pNBqpXq9rPp/bNhX0hG1AgMFyuWx1cQj2sHrSlumbzWZarVaazWbmayiWzliRceCzCgA2l5eXWiwWevDggW0T8jEIvwUz7gMyTGOlUrE2+nop1A6p1+s7PslfGx/hg7v3Idiq9++eXWR+sO12u635fK6TkxMDPWR63pUYESRIkDdbvkx8LwWMHzB+wPgB43+1MP5sNtf19VKXl2OdnW0+WeBaKUmWqlRyKpVySpL1JwtTK1WrGeVyUrEoRdFGmcxSSZJRHBc0HC700UdTzecr9XpjrVZzjccbxXGkYrGlQiGjBw/uaX+/pkeP9lWrFdVuRyqVIkkrSRvNZkOt1wHjB4y/lZ/K4h/A4KOPPtI/+kf/aIcVvE3+4B/8g1qv1/rwww/1zW9+86X32c/8tkocxzssDYyFZwXvCjCQZM7dK7ZnZdKr9WnBgP2WAmkXUGCInklLXwvDSRsjhTN9phXXICj5eh3UP1gsFjvgAyPGsH2qsjd4HGW63gX3Y9tCmrmj7YwjgMnfF8cHw8fnWCxijD17wnuwgAALTvUC2JGOj/P3wZ7vU/zYj2mj0dhhWzudjkqlkr7+9a+r3W7r4OBAtVpNh4eHqtfrBkoonkuwxslPJhM9e/bMgvxisdB4PH5pnPz89ft9FQoF9ft9STdHsHud8+xKOu0a5idJkh1QNpvNjBGcTqc71x6NRtpsNgbmPGOEnnnGCjsh6KCHfg5vSx1n8S+bzWqxWGg0Gqnb7drpdpzMxrV84eNSqWQgCb3abDYGfhh7FhxhlcrlsgGsarVqWYWeBbvNRhnb9Xpt2yGGw6Hy+bwWi4UV50WXfAYBOp5+oGBu+PHf9axhmgVPC/3Hbnz2Qdo/MZfpvjGm3CuKIgPGXM/rgmfoEa+X6Ec6+Hu9TP9Nm/GX1AUBsDI2t7GPQYIECfJF5MvG91LA+AHjB4wfMP5XDeNnNJ1mtVjktVhEkhJlMrGktdbrpbYqF0vaaD6XZjOpUJBKpURRtJG0VJJs6wCORgsNBgstFivNZuD0jKSskqQoKaMkySuOc4qikjKZknK5SPl8pCjKabv4NwoYP2B8ky998Q9g8Nu//dv6x//4H1v9hU+Tf/Nv/o0ymYwODw+/7OZ8JYSH8+FwaI6OlV6c6l0ABgRD6rXAJOBMcPzpAJNO7Yftoo84Z5wQnyMQIARtH7gxVn6KxaIVzozjWO1225g9WDqKmsIanZ+fq1Qq2Ulbe3t7dm+KoEo3RX+r1eoOEzcajczJpU//8kCPhR0cliRjAWu12s7JWwRw2ABAogcAOFHGhnT7JElULpct/XuxWGgwGGgymWg0Gmk6nVommK9TQttrtZr9rlQqOj4+Vq1W071791StVvXgwQNVKhUDBK1WS8Vi0QAEjgoWyOsB7V+v1zo6OtLXv/51PX78WN/4xjf0O7/zO/q//+//WxcXF/rxj39sANQHILZ0/OZv/qZarZay2awODg703e9+V+12e8devM3ANEq7WzpYXJtMJhqPx+r1erq+vrYaMgROdKder2uz2ahcLu/UYEiSxFiwQqGgxWKhfr+v1WqldrutbDar+XyufD6vjz/+WHEcG0vlC1L78ZG2AWI0GumDDz4wloxxpI5OpVKxrQy5XM7YNs+Kfvzxx7q6ulK327UAzvcPDg526mqsVitdXFxoMplosVgYO+rnzwv1OZ49e6Zer2cnGe7t7e0ASH96H+Aaf5HJZGz7TKFQsPo6sH8exHk9x/7TOkYgpSi9zz7wWw7wWZJ27Itr0m4/L+122x7mvG/kc9RTYZzwG7QXH4V9831sJw0W/MMh3zk+PtZ0OlW/3zfgctuWhCBBggT5vBLw/U9HAsYPGD9g/K8Wxp/NVnr+vKXBYE+tVl7FYqxcbqZMZql+f7izIJXLZZTN5pTJJMpm2YIcK0kiJUmk+Xypbre/sxicJHllMnklSUZJklG/n0ja6Pg4r0KhJInFspWktUajj3V1da1+/1qTScD4yNuK8b/w4t94PNaPf/xj+/+DDz7Qv/k3/0adTkcnJyf6j//j/1j/6l/9K/1v/9v/ps1mo7OzM0lSp9NRoVDQ97//ff3zf/7P9Uf+yB9RvV7X97//ff3qr/6q/rP/7D9Tu93+os15KwSFg5lYr9eqVquWcnpXtgSg2L5uAwZ0W+0K6eXVem9wfp+9Z22kGxYHg7pNPJvgV9A9U8APR8YTZGnHbDYzNtC3j+ukjfQ2xhM219dzIdASHP11vaODFUmzFdw7PS5IukYM7QJQpXWKbRHT6VSTycTSu1kkKhQKKpfLFujZElGpVHRycmKAoFqt6vT0VOVyWe1227ZWACp8u9I6wd9xHBvIKxQKarfbOj091WQy0eHhoVarlTlZz0gxLoAxSbq4uJC0LUxOG/w48jfjjPNkKwfjQ6o3B2vww3fQHWlbYFqSsaTp+SLtHvbNFzuHFYXdpK+kn3sgzbVoly8qnbY5rnsbu5skN6nsAGR0M4qinZo0LETC2Hpg7ucgLT5QjkYjFQoFDYdDe2jwOoCOME5sNeHa6f/5jq+pkw6E/m//Hn7G6wF+izZ4hj3N/vuHD/wWha39vHub5sHFM/q0P91ur6f0m7n31/fMIGALwHWb3w0SJEiQtAR8/3okYPyA8QPG/+pg/PV6o/U61mqV0WKR1WIhZTIbJcn2IA+/ULzFmFnlcrGiKFE2myiO9clPojhOdg6GuMGHGUmRtluDIy2X0mIRa7WS4jijzebmPUmazRYajcYaDIYajwPGf9sx/hde/PvBD36gP/JH/oj9T52O//w//8/1d/7O39H/+r/+r5Kk7373uzvf+8f/+B/rD//hP6xisaj/6X/6n/R3/s7f0WKx0OPHj/Wrv/qrO/U+guwKLNBoNLJV3tPTU7VaLe3t7Wk4HOry8tIWCF6X4JR7vZ5ms5keP35sDBKFP73zlXaDNwJjFEWR1SHDCacdQrPZ3GHT0qmvvMbKe3qlHadA7YNyubxTO6Lf7+vp06dWi4ATnwAkUbRNAWZ1PooiW2RhweXi4sKC7nq91uHhoZrNpuJ4W4QUh0DwxemyKEMGmCQLAIwRtQZgGbgWDoLxy2azBiJx0vP5XJeXl7q+vt45KGKxWBiLt7+/r9PTUx0cHOjrX/+66vW6Dg8P7XqFQsFYv3a7vcPueJDjJV001s+nT3lmDA4ODtRoNFStVrXZbPTDH/5QH3zwgbFSXi8Yi8vLSzvdjZMIj4+P9e1vf9tYG0kGsAnCAKjBYKCLiwuri9LtdvXixQvbVksmHYEjl8tpNBrZQRq1Ws3qyAA0AZm9Xk+j0Ui9Xs9qrwBOYYMWi4WNL2nefmypm9Htdq34saQdZg0QSD1BmDWK2krSbDbTbDbTkydP9O///b+3cSMIdTode7BDLwGIpPWjk8xjugguwil4H374oa6urlSv13V1daWvfe1r6nQ6O+3H5j0LiADeuQcgl3vz47MNvK+RbrYQpYHIeDzWarUywO4XWv3CLXqbz+fNHzDPgP5ms2nMvwex1PDpdruWss/2a9hp/9Dh2cpMJmMPGp6hxK96QE0xYADDq2r6BAkSJIgU8P3rkoDxA8YPGP+rg/G73aH6/ZnG46lms6mKxamS5GbBm+w1cDa6uMVqWUmRZaWSRcYiHDbG7/U60XyeaDzeLjpPJmuVyxtNpxlth3qhzWamjz9+rg8++B11u+caDnvK5QLGf5sx/hde/PvDf/gPv5KFkW5fEfby+3//79f/8//8P1/0tm+1oFRkCvlToiqVih1HfxcEVtCv0vugyWdu+83fGCCBNb1lgJV4aXcvvfTyaTtpkMBr6R+uTV0LDIzAzHuexcMRvYoF8UyQ/2HVnm0JZHr5egS0kyCRbi/CeOAYfebXbWPA+LBFlACHo8H5NxoNNZtNHRwc6J133tHR0ZHeffddVatVHRwcWMCCHQSk+No03DcNAvxcpF9Pvwcrlc1mVa/Xtb+/r3a7bTUpYN3SLAlj5tnBKIq0t7dn9sO4sejmGSLq5/ki0ePxWPP53ObWM0dJktix98PhUHEcWyFpmGAYRU4pY85gZbkWh3AQILAjFgARWF1AhA90fM6DJsbJs0rYWLreCfrD4iNgU5LbqvDy9pu0fnqhL4zT9fW1stmsjo6OVKvVdvQ8rd/0JQ00b2PJ/Y/Xwc/KnMB+sAX/EJIGBv76Hrj5+i+0j4cV2g3goG/p/vn7vWo8ec9nDfgHndt8XZAgQYJ8mgR8/3okYPyA8QPG/+pg/MlkptlsqfV6u3V3mwl4syCdXhzlfjc15LSDOcGLjJfXIYk2RtpsMloupeUy0WoVa7mU4nitzWat+Xyl+Xyp6XSh6XSuTEaKooDx/Ry8TRj/p3ba789CfID4KotnBbvdriqViq0AHxwcaDwe60c/+tHrbqYJq/Skl282m51g5xXV/40xTKdTnZ+fWyFpHJAkOx4clswvmkgyJ8wKffq4chY6uC8OmQUXnJN3zrB+BA/aCkgjq4qVe75LUK/X68ZiRFGkWq1mLGWtVtN4PNZkMrHVf5gtCvHGcaxisWjBHzCR3j5AwdUkSVSpVHYYWOoa0OanT5+q1+vp4uJC/X5fzWZT+/v7evz4sR49eqSTkxM9ePBAjUbD6ro0m01jA9PB2ztF/7oPbLzHqW5pAMH/aZDLd9vttt577z0tl0t9/etf19XVlfWJQrzMH/MwHA41m830/e9/X6VSSb/5m7+pWq2mvb09lctlO02vXq8bI1wul/X06VM9efJE/X7f7sMYZrNZY8am06murq4Ux7FtGZhOpyoUCrq8vDTG0c/BaLQtvFuv11WtVjUcDjUej1Wr1awtMKDUm7m6utLJyYlOTk6MDQRklkolHR8fa7PZWO0Z2glju7+/b34DcJPJZKzNSZJYrQmvJ9J2gRBmFd2qVquq1+uStHNYyKvAnySrKQI7+m//7b9VtVo1XeW0KoANGYywdQROWC+EhVLGhfbThvQPPsU/TKQXQ33BbL94ymvYIPeGgQcsexCDL+IHHcUHcH+2rPgt4TwQkpFQKBSsrdzb2x5ZBX67D3P6NsTKIEGCfHUkYPyA8QPGDxj/TcL4q9Va/X6s+TyjJCkpl6tqPl9psRiYfqEHjB22VK/XVavVbP7pp687B6YDw2+TArLK5QpKkrwGg0hJslY2G6tajRTHc202cy0WOUVRWet1TotFpNVqos1mexJ1wPhvH8YPi39vgBCoOBnUBzuc2V1hBaVdZoaA7Ve8/ec8i4eBwFhRrFbSTl0FvoPT5G9JlgXlT78hMN220p7+Pw1cAGDesL3D5ofUZA+AEJ/OC8AghZiaCgAe77zS7CiO6DbGI90H2sJncTSz2cy2gQ6HQ9tGQv2Ok5MTPX78WKenp3r48KFqtZqazaadPOdZGc/EfJY+pFkQDwrSrEhafECgSHS9Xtd0OlUulzMnngYlkgxc9ft92w5RLpc1n89VrVY1mUyscG+lUrGFN7bmjsdjS7v3uoQzZvy8LiZJsnMaGcCAgEOhWnSDuSWglMvlHQbKz5vXZemmADbBwOsOQQnWk20PAGOYyul0+hLrji2hmwR+P39+y4L/HuPv59bPCf0aj8dar9eaTCZ2uhoZBX5bkNd1zz4inh1Nfy6tQ/5/r8fep/jrfxoTyed5DR3xuu3Hx7OMHtQRtD3ITz8s4Qd8MeC0rfg58b7K622QIEGCvCkSMH7A+AHjB4z/JmH81Wqt6TSvzaakbY2/nOJ4ozhOtNm8fPAJCze3ZYBKNye9sojkcR0Yc2s7eSVJTotFotlso+mUay8UxwutVlKSZLU9/TcrKRMwvt5ejP9GL/6lB/GrKjid2Wymi4sLVSoVzedzRVGk4+NjOyX0rgkKTQq8T6WXdgtlRtGWwRsOh/b+crm000p9zTMkSW7SsOk/tc+kG/YJgyQ4+VV+nJQvEjudTs2h0j6/sp7JZIyB8+whWzD9KUoAFQ+QcDKVSsW2GVA4lrR0b9zz+VzPnz831iObzdq1YUtoJyebAR5JQ3/+/LnG47H6/b7m87nVmzs8PFSr1dJ3vvMdvffee3rnnXf08OFDA5zMXdo5ImmwdBtwwGGm+8X3P48ADAjiBwcHVtsFwJQkyUuMJY4VJoqT1Z4/f65sNmunk6Ff7XZbjUbDnHmhUNDp6alms5mxfrPZzOY3SRJNJhMDIHwnSRL1+31rMzqQJInNca1WU7Va3ampMZ/PdXV1pV6vZ/3wwFGSjUEul1Or1dJ6vVa/3zf20DOjrVZL1WrV9Kvb7WowGJiunp+fazweW91BTrGjTbR7sVhoPB7bvLI9AlCGbXrwkn4oIH3dA4T1eq1ut6tqtarj42M1Go2d+hjYK+2AjYOB4yGAekOtVsseLmDuJe3U00mDCnwPIMTrblrP0XXvbz0A4zdjhvAg4NvAViNq9jAuFOD2D0a0lWvCDnqGnX7n83k7QbHf71uNmc8C8EGCBAlylyRg/IDxA8YPGP9NwvhxLOVyZPYVtV4XP/nu5hMdW2k6vdka63WU/8kOJLOPZwPwr1+QujndOKfNJqPLy4X6/aUGg5kKhZVms2utVlPF8UzrdUmFQkvNZqTNpqY4biibVcD4evsw/hu9+Pd5ncpXQQiy8/ncnEAURapUKqrVajvB7q6IZ1B83YBXsbkYPadmwWDhaD0AwEngfAjiPh3f388zJl7SDEAaAKRX4AmAOGvvCGGFCH4EF5+R5VkDgq7P2kqzEbyWLvqKwNRI2glK3oFyihV1LXDoSZKo0Wjo+PhY9+/f16NHj3R6eqrDw0Nr26dJur30Ly2fhzn8LAFwEAgAVdKNnjEGaTZEellfENhnQBm6B/NI8WdJBip8m7h2mhGSbhhJMu4Q2uhBIG2FAfSf8xkBAMFGo2GMoF/0I+jQjnQNG4AUafyXl5caj8eWfu5tzKerE8QRH0D9eHyafd82lwQtsh3YcuGZrDTYpJ++Hgzg1afw01de57XbxOsn/iLNpHkwG8fxjs/x2xhov7828yhpx4Z9HRdvS/466QwAn2GQBut8j+0D+KB0H4MECRLkrkvA+AHjB4wfMP6bhPG32X5SFLE1OVImE0m6yVL1i3fbE3tjbTY3pzNL2tlKKt0sKKX7t8W8GUVRRkkSablMtF7HkhbKZhefZN9NlM+vlMlss/+y2aK2pw8nktaK41XA+Hq7MP4bvfh3l9Lgf9oC03N5ealarabZbKZSqaT9/X1jBT/LIH+W4h0zpyFxepBnLvisdOPgqfGRyWRUr9e1Xq8t04naHDgqnAl1y/ierx8QRZGxbul74QBoE+wGK/is1vugS3o2bWelHqPlXo1GQ7lcTnG83VZArQK2CHjD5pqr1coCUZrBlKRarWaOLooi2+8/n29rN+TzeWNayCKbzWZ6+vSp6Uw+n9e9e/dUq9X0S7/0S/rmN7+pd955R6enp1Z34Iuwda/6Pw2iJO2kjzMXLIJ5XbjtegDMcrmsZrNp4+vZ5nRqN/f1C26eicFJe32FTavX66rX62q1WhqNRsbGUo9nG9g3lr0HcABkwFRxffpOm5fL5U67SIlHFzxIyGQyVnS5Uqmo1WrZycH9fl8//vGPlclkjFUrl8vKZLZFjQG5/kStDz/8UJeXl/rxj3+sbre7M8aSLLAQXGGcarWaOp2OkiTR8+fPJclYUZg4xtTXxeDaMLGFQsHqEB4dHanZbNq8wGR6PVmv13ZSHls3WBCl7guBUNJLQM3/HUXRzqnJkgwsA4hZHPV6xbzCfvptCMwrxbHZesLDHOOTJImBODIr0UnYbTI++EkXGgYYoB/8j68ql8tqNBqK41i1Wu0lljZIkCBB3gQJGD9g/IDxA8Z/kzB+FGVs8W+5XGizWUq6Ieo3GxadXt5+GscFywgrlUrabLYZgvP53HbnUEeOxXZwZanEKbQFRZHU7081n/fV7b7QbNZXoTBULjf/ZBFwrWo1UqlU1maz0GaTaLNJAsZ/izD+G73497YJjmA2m2m1WqlYLO6kbqMcd0VQSFbu/Qr1qz4vyWpXwAyWy2ULnDg8jBFjh4Hxq/+eUSCLie9gVD6A4Nikm+PFPdjwacl+nPkcjsQHc5/Z5R0TRu77TaBiAcjXNGHs/Ao/zmWz2VjdNvrZ6/XsoIjZbKbhcKj5fG41SFqtlvb39/XgwQM9evRIR0dHarVatzINnyWfBUjRA8aZscDhvgoU8Fp63Ai6nvXwTKC/Z7qd/rN+ftPBC7a2XC7bse3z+Xxn/HmNk7JgoJintE165sjroAeKadYLlgx95LoUh6Z2znA4tG0KPtikixhzn/l8rtFopF6vp263a69TiJh7MJboPMAXACLJ2slnfLDiugQ4wFWpVFKn07GiwixWepv148QcAe4BHfQNtpQ5uI2J9rrhdUG6YY29j/KMHw8jjCv6RfvS/WS+YeYZJ4CT9yv+Ycdv//BbaPxWGm8P/m9014MU/zAUJEiQIEHurgSMHzB+wPhvNsaPooyyWRY0Y0lrRVFBUZSVtJGUiEy/m8Wdm2w6rs+iMovgLDym60t63B1FNzh0sdhoOl1pPJ5rMpmpWJwpl5urXE5UKEjrdaIoyipJIsWxPlkADBj/bcH4YfHvDZLVaqXLy0s1Gg1jeJrNpubzuVqtlprNpobD4SvTXn9W4pUexbwtxTb9HRQ9jmM73en8/FxRFOnk5ESFQsECIBlNOHHPDngDp94DTonA6AM8Bu+L3cKO+VR9AjasJYGJAxzYXsm9+U3/y+WyyuWyfQ42k2LC1BCgTzgbghTXodDsYrHQ9fW1FouFrq6uDIRtNht1u12r27bZbOuddDod/dIv/ZLu37+vd999VwcHB3r48KH29/d3HLNnQj+PeAfl55Mxxpnyuj9t1gcM/10PCPx9WODa399Xt9tVs9ncAYez2UxJkhjrQ20Frj8ej+30pFKpZIwUQOP4+Fj7+/va399Xp9OxOYMhnM1mGgwGyufzqlarljU3Go10dnZmtgfIy+VytmWHQAVbWK/XVSqVjCUDvFG/b7FYWMHjXC6n8XiswWCgarVqOgkY7XQ6O8Gh1WqpUChYqv1wOLStCdhAo9FQs9m0Bw7GJZ/PazKZqNfr2b0ZS8+gex3lh356W2s0GnbiMICgXC7r+PjYartUKhU1Gg1bvIzjeAfsZ7NZe1jwYLtUKmk+n2s6ne7Uy2HeeZDAzsfjsV0bG+R/HiaSJDHmmWsjpVLJ2D7sBBvFhqkXg617JtCzicydZ0AZfw94AX/eJv3DjX/wYTEYJrJUKilJki/E9AcJEiRIkJ+9BIwfMH7A+G8+xi8W88pkcioW11ouF4qisqSSZrOsVqvNJ+Oz0GaztrZmMhk7vTV90q10cyI1PzxHsGiOXiVJrGw2p82mIKmpXK6jQiErKdJqlVE+HymfjzQc9jQY9D75n2y5rNbrJGD8twDjh8W/N0hgfzCCOI53mMFSqWQFO1+3eNbus0CBF5/9tFwurfgqQdmzYAR+FB5AsdlsdozL//aLGaR/+0UTxP/v2RcYCK5FmyXtgALPODAetMmnAPtT3VhY4T44fe9wacd0OtVkMtHl5aUmk4kdVQ8QYwGJfnCC1sOHD/Xee+/p3Xff1f7+vhqNhhWrTTubzytpdhPnyrVov3fCm81mBzh53UizN/49nH2lUrEjz0ulkp1WBUhjLjglj/kejUZar9cWtEhxL5VKtsXm8PBQ7XZb7XZbhUJBhULBwAsAjQCXz+e1v7+/k0YOcKSP1N0DNPA/96xWq8Yssv2XLR6MGU5/sVhYajljHEXbNHCEwMhiny+e2+l0jOli7AiuXAsQMh6PDXAwB+gg9u3ZqjSDDdjmlLXj42NVKhXt7e2pXC7r5ORE1WrVgIIH7fgAX2wY+/A2xP35LO+jw+g2OscDBOOEv6B/sIyc4OZPWcaHebbV27oH7ugqoIH7ecALUOS6tMH7FgRb9kwn9/OAPr1tnHum/VuQIEGCBLlbEjB+wPgB47/5GL9Q4GCXRPn8Rtu6fjdYbLNZab3ezfD0mNdvOWeMfH1Gn3XIPKAL2y3piTabnJKkoCiqKJtdab0eKY7zn7Qj0nK5rXFYLucURTnFcaQkyVgGYMD4X22M/0Yv/vkJeRtkvd6e6nl9fa1+v69yuWyMTqfTUafTsZM8X6eg5NPp1BiMJEksMPj5Sqe18l1W0kejkSqVinq9niRpf39f0nYBJY63x7tzryRJLK0dRwUrKMnABo6AzKnVaqVSqaRKpfJSjRGf5uydg3fOtJ0AQro0fcYwAQZcH9aOH1iPxWJhjBfBJIoijcdjnZ2dWao/J3qtVitjSRlL7kfw/8Vf/EWdnp7qP/wP/0Odnp6q3W5bYMW5emb2izAIPj2eBawkuSlgzA8CqOX+OH/mLN0G7zRpI6wtDjQdNAEM9+/fV6FQsPGiiHC9XlehUNA777yjk5MTHRwcqNFoqNPpqNlsGgjwgJIFOwI9NRc4wQrW8Ozs7KXTqmDH8vm82u22isWims2mAftcLqf79+8riiL1ej0Nh0NdXFzo4uJC4/FYw+FQ0pZ9HAwGNu8s+jHWgMrFYmHsIGOZJImur68tIMbxtlZPrVbTeDzesb1CoaBarWYBEmZdktU+AaT7OhnYrde9b3/722o0Grp3757K5bKdusZWJvqP/XD4iLdRwNze3p4Wi4XV1gEMDodDLRYLGyfPsmE/m81G19fXdj2v7/gJimW3Wq0dUEnb6vX6Tp/xBx7Mw8JOJhP7LnMBmwp76L/PnMCk+1o3bMH2ACTdP/72h7x435UuJB4kSJAgd1kCxg8YP2D8gPGZ2zcJ4xcKReXzJUXRRrncWNJC83lVi0VRvV6i4TCn6+ui+v2NFgu2jm7rBLIdHrwo3SwsMRcsBJP5hrBovtVLKYpKymQSJclEq9VaqxXbkpsqFqV8PlE2q08WMbOKooDx3waM/0Yv/r1tAhtGTRAe8CnwX61WvxCb89MUlJ20V0k7AVl6GRSkgxEGNpvNNJlMrACqT4ElY4n7tFotM1jGplAoWLZUug0wCaSE+wwnvsNKPH97tsozM551xCh9X3kfpgFHwm8yu/hb2qZ6c49er6cnT55oNpvp+vraTm2FDeBemcz2cAjqfuzt7enb3/62Hj9+rK997WvqdDoGXm4DAF8UGDCuFCZmjHDwnvmMosicMs7Op2jDKr0KLPKad5pcwztMAjvbX2EDAUIU9e10Ojo4ONC9e/fU6XTUaDRUq9V2Ur4ZU8+sUJOEVHb+nk6nprMI34XJhIVsNps7rCPbfxuNhsbjsc3R5eWlZrOZoigy8DiZTCTdFH/2DKBfBKRuBkGc7/F5AnLabzB+fjsNfUdfCTSegcXuC4WC2u22Op2OHj9+rHa7rZOTkx2988GbOfNz6m1xs9kWXaY2CwzsdDq1TMnZbKZ+v38rgKfdAMTJZGJbZXK5nC3IUkenVquZT+U32xXwEx6UwjyyLcCDs2azaX6BsffbEPAvjCusIwIDyhzx3m1Mn8968CACwBYkSJAgQe6mBIwfMH7A+F8djN9olJTPZ1UoxMrlNlosCprPK7q6yqnX2yiXmyuO1xqPZ5/UspPW65sMN66dxsV+oZr2gun53g1pkpNUVBwXFMcFbTbbE4iz2ZIymZUymfiTH32yKJgEjP8WYPw3evHvVY7tqypM7nw+12AwUL1et1Xnvb099fv9ndTguyAEZxSVoJD+TDoAeIWezWa6vLy0jCX6mMlkbKUdh1+tVg00SDdsiU+nZRzX67WxcKQOY4CwewRpH5SkrTMYjUY76da026cc49QACd4B0ofZbKbRaKThcKher6fpdKrxeKyrqytdXl7aPUejkV68eLGT+kvQ5Z60v9FoqNVq6Q/9oT+kBw8e6Bd+4Rd0dHRkDtCnct82Z7eJHwO/0DSZTKwmiU9RxunBrsLEEdRhL2Aw0sEifW/PbsAGwaT4wymYm/l8rh/96EfK5XLGmlJn7+joSPV6Xaenp7YFoNFoqFqtqlQq7WzNoMCs3xZA++M41uHhoTn0+XyuUqlk4I3v53I5HR0dqVaraW9vT8Vi0WpNDAYDbTYbY0kJLIVCQYeHh3aKntfFwWBgC3fo2nw+19nZmYrFomq1mmq1mm3/xQapH0Pf+v2+1QXEPmF3uS4MLAB7OByq2+1qMplouVzaAmaz2VS5XNbh4aGq1aoePHigRqOhd99911L+CZySjA2EqWeOKMLM9mPsEmCA/U0mE9sevVwubYuMZ+joCwC82+3aomgmk7FCvcvl0hZKuS9jQe0X6oCUSqUd9hrdBZz7oB7Hsc0V34MlxCfRf+6PXWEr3sd4n4K+c23sFt+1Wq1Uq9VeAiBBggQJ8iZIwPgB4weMHzD+m4zxZ7OpRqOB1uuNMpmhtttwI9XrkQ4OsspmcxoOpXK5qNUqq+Xy5nRav/gDLh2PR8pmczuJAx4bkjHnszW3/ZSSpKD1OtZikSiflwqFSLlcpHI5UqmUUbGY1Wq11NnZIGD8rzjGf6MX/5ict0VQcFLAyQairkG9Xv9Ce75/VuKLvaa3BHhJG5VPCR6PxzuFXH0Al25YN4qgekaOgEyw8Ywl6c0+xZZrAUBuGBTZ/2mn44Ml1+K+vMZ3PZODo4SpGI1GGo1G6vf7KhaLGg6H5oCm06mur69tznF2nqmUZAxUs9nUt771Lb377rvGzHCtV9nNp4ECfw/6ikNeLBbq9/s74858U4AVx4ejByB5NujT2sdYYwOANoChZ4JgzZfLpekJwbnZbOrg4EDNZtO2ANRqNaupk97GAmNJ+3HC1JtoNpuStMM+z2YzK1Ld6/UURZGazaZarZZarZa9x6m7PsASEGCUYJPH4/HOFhi/JQKdHAwGKhaLVhTXs8sAFwLqer22exNoPIvm61lgw6vVSv1+X+Px2K7BImS1WlWz2dS7776rRqOhd955R9VqVcfHx8rlcga2sAUyC/1W5eVyqU6nY4ugBExfI5GFUg/I+f5wOLRtPuv1WpPJZCcwdrtdJUlic4BeM8f1et2CKmwfQX+1WqlSqWi5XO6k6PPwATDARxHUYWd5jS0R3N/bL2PsmT8PLr0/ATB4u/VZCfl83nRkPp+/VGMkSJAgQe6yBIwfMH7A+AHjv8kYf7G4wfj5/Fj5fFGZTEnFYkGtVk25XE2FQlaZTFajkbTZ3GTwsbDnx2c+XyiXW+9koUk32WN+W/t2/hafJBRESpKcNpuVpG2mXxxLUZSoUIhUKGSUy2U1nS4Dxn8LMP4b/TRwV9Lff5aC4vV6PXNInLLDVsF0IPtZiw/CKCxsEavatwGEdPDlf7ZCcNopadgeGLJAwkIFCxqkwfqUcv6PomiHIfM1DnA0nmHgpKHLy0sDK1EUWcYWq/HUnPBp6z4Q8j9tWK1Wmk6n6vV6Ojs7s1NeZ7OZ3UO62b7A3z5Y85tabV/72td0enqqBw8e6Pj4eOckoDTDmZ4DrpV+34/farXSYDDQfD638fCHRvhreZaVGnNkk/mizbTJ39czrYCO9Xp74hc6AUPmnSfz0Wg0bEGtWCzq0aNHarVaevfdd9Vut3VwcKB6vW4p4J7toU0ECHQXx4/zPT4+3hmXTCZjBbs56U3STgHjTCaj8Xhs7BrbUtjCglNn6wK6je30+3075Una+gCCMen4/nh52MDBYGAMNCn1LBAmSWJtmM/n9gAyHA5VqVRUr9fV6/V0fn5udlKpVHTv3j01Gg09fPhQ7XZb7733ns21D3TMw2Qy2bF/wBjBkO0lAA7GjesRHCVZjQ7S+uv1uqbTqc7Pz3dASJJst6g8f/58pyAwTCU2y+ldsI3Mx2azUb/fN5tut9vKZDI7wdfrHsJnaDPbeMioZH7I9qRdLNT6LUP0P5/P27YVdAtAul5v6xgNh0PbSvUqew4SJEiQuywB4weMHzB+wPhfFYxfLFJPsKRcrqBCYa2Dg1iNhrS/n6jfX+viYqXVKq/lsiKpqtWqJSmyhZ1Wq2WL4Cxes0hEpt920Xu+s4gaRStF0UbSNusvii612XwkKaP1OqvptKTFoqJ+P2D8twHjv9GLf2/jwwyTzwM8mTntdlvD4dCU83UDg9vmBmeaDtD8TreZfsCazedzC5SNRsPuQ/DBCHO53A5bxu/bgIE3aF8oeL1em9F61oJTtzC+XC5n9R1gE7wj8EGGH1hLnBaAYzAY6Pr6esfgPRN32zinwTHsyb179/Tw4UMdHR1pf39/J2U+fQ0vjNerGHe+v1qtNBwObTx8rQEYYM9IkUoPcEqDglcBEdrjU6BhA9EJGA/aTdo19UA4UbdQKOjk5MRqVOzt7alSqVjhYBbXPIvs9YcUbtgoSXYPSaYn+Xxek8lE3W5XURRpNpvZwhpBBJYXcAWLVSgUDODA5FFrRJKBRk5643MEjZOTE+XzeauLQ/vZRoHfuL6+ti0VXMdvxwB0UYenXq9rvV7r+vratqlw33v37mlvb0/f/OY31Wq19I1vfEOZTMZqbmCL1CvinswnQAmWEbaZNHwKLXt99cwiYHiz2Wh/f98KApNWz3ewbw5NYRsAKf9eJwnW6Aa6jr4mSWLbR9B3topwcvNmszHmeMvYzneApfcFfpuGJAO6/hQywB8MLHbBIi5Aj9ooPFxIN5mfQYIECfKmyNvoswLGDxjfj0/A+F89jF8obDF+qxWp2byp93Z+PlGhMFO/n9H5+VhJ0tRmU1EU5ZTN5mxRiMW/dKYr47ZYzDWdzj55bf1JZtpGUSRt6/tFSpKu4vh3tFoVtFiUtFrVFceNgPHfEoz/Ri/+va2y2WyMFUS5q9WqFSUlNfmL7P/+MsU7UxwArAqp7GnB6fogz7UkGQt3dnam+Xy+U1tCumE+KKbLNTE6glOajfQnmWI4BHUPCqjBwuk9BBtks9nYlgUPWqIosmv4k7F84F0sFlbc1AMGL2lGz48bgbBSqei9997T3t6efu7nfs5O/MI5enD0KvDGZ24Dlmm2D/FjylZVHD0BMZfL7bCn6YKl6Xb5ufDp1eiHfy9Jbk4dI2hzii41OMiEg8HyBV1fdeAFoNvrh0/DR0em0+kOSOPajD1z6k/tymQyqtfrVkAZ1sqn2GMTMKoER1Ly/fYfdN6z0wSQJNnWCKS9nFJGCj7AW5IFGYrs0rd+v2/Xojhup9PR4eGhvvnNb6rRaGh/f98KAjPv9MvrF2PI3JFKn81mjZn171P0HP8hbZlESZaqzzZnTiiWboBaJrOtJbLZbFQsFjUajfThhx9qNBppMploOp1KktVyyeVyliEQx7EBO+xovV5rPB7r/PzcDm1BH7gOPpDP0x7mP0kSe8jBfrFnHk7SWz5gMPnxgJlFY0AH/6ftKEiQIEGC3G0JGD9gfD9uAeO/HRi/1UqUJJEKhakWi3NlMjNFUaIkKWq9rimOM9psMpLyKhRqymRyKhbzkhKtVlOtVmvlcmOtVhNlMl1F0UKZzFzSUlJX0kxJEimOIy2XH2m9ngaM/5Zi/LD49wbKer0t1N/v97VcLlWpVHaAQT6f/0KnvnzZgmNAwVFKnxLvxQcDPp+uH+KLfW42G0vDrtVqO8zLfD634AOr52snpAMeLFo6IHFvvxWg3+/buLINY7PZGJMHMPAr+5lMZgcY+CwrBGBACnA6UPKbsUkHUdKiW62Wfu/v/b06OTnR7/t9v08HBwdqtVo7p4l9FlvsHdptc5TeznHbPHPcPcWSa7Wa8vm8pV2jB4xPuoZIulAxuuOZVtrEOAIMCKSAZcbg5OTE/gegEIxgcdNt4L301g7YQ0AozhjmhVTvVqu1U1vCB0Rq+FDvIpvN6uLiQoPBwBhU2gTTxOtxHBszx2dgRAERAKP9/X3TMUAINUE8C0cgnM/nlsbPDw8fFPzd399Xp9PRo0ePdHJyovfee8+2egDgoigyvcOWvM15tpuHGAK/Z9KxfRg62G2AAanwzAH+oNVqabVaaTQaKZPJ6PDwUJJUrVY1GAy0Wq3U7Xb1O7/zO8aokU3ga5HA2HISGPbMd+I4NiCMXdxWFNjbUbFYtO0ZksxepJvTEtmGAkDEBvjbZ0z4McVeeDj0NhQW/4IECRLk7kvA+AHj+3ELGP/twPjtdlaVSk6FwlzT6bWksQqFpdbriqbTfcVxXut1+ZPvZZTJ5FSvl5XJJJpMZspmY+VyE2WzA0XRuaSRpJGiaK44/kDr9YWSJKf1OmD8tx3jv/GLfz6gvC0Sx9sCq6xqUySTFNVCobCz5/11CIbhU/ORdNDxLCLv4VxwFtQ+I4Ubh8xKO33lnj54phlJjA6GYVsP4SZtH6fsA0+SbAuIYuxsraTOAdfFgfp+cR8MmTRmAoZPCb4tIPNd/xsh/fvk5ERHR0d67733dHx8rP39fTUajR2287brpgWn86r3GWPYuSiKLHhwahNjTjoyDBGsrK9VR1s8aLltHJgHWDoWuEql0g6z5pm6JEn04YcfWr2I1WplQInv0n6uz3yQvk/9PezLb9cAvNJnn+YOACyVSmq326af6Fo2m1WlUlEcx3YiFsEJMOJrpgAmoiiy08QkWeo/TBOFcAGpgA4C6cnJicrlsrHbFGomyPl2+i0dMIH7+/t69OiRDg4O9N5776nRaFj7mTu/fcMHSvTKM1m3Mc2+PgzjnSTbQ04YB77LSYBstWArjx9jz8BzeuLBwYGy2ax6vZ75Au6JPsEIAg5ms5llX/o2LpdLlUollctlSbL++occ5saLf3jBDgCh/h6MqQfS/iHC24oHDCwIYz9h8S9IkCBvmgSMHzC+FDB+wPhvH8aP40i5XF5xHKlWW2i9Xn2SxVbSZpNTJlNQrVZVNptRpbLSep0om000ncZ68aKv8bir6bSvzWahOB4rjteK40ibTcD4bzvGf6MX/z7NeX2VZbPZnupJ8X5OMKKgKamjr1soXouSppUYSbNgGCWGUSqVrOYGx7iz4g0DQ/orztmvyGP4uVzODIoAzv58HJuvD4LRelbIF1plT36j0dBmszHDpy6A7weMFicOFQqFnT38nk28LTDfBny983v8+LHu3bunn//5n9fBwYGOjo52HLZn0vzvtHyW3nh20TtGaltI0ng8NgcGs1atVo19S7OAft69k0z/wBJRo6FcLqtWqxm74hnL0Whkp4FxKlocxzo9PTWgUqvV7J7cF7BJQPY1TFqtlhaLhUaj0UtsNyyhZ0lhpwuFgtbrtXq9nrHK2WzWAAtp7D7Q8X2uwX2KxaI2m40ODg5e0gMy95bLpYbDoV1zyyi2Va1W9ejRIw2HQ11cXNi2XvoPaAHYEIxgdNvttk5PT/X1r39dJycn+ta3vrUTyPzDgJ/LtG57cJ3WKz5DkMeuOL1stVqpXq9rb2/PfAPzyb1oswcQ6Huz2VS5XNbJyYmKxaIBA2Q0Gpk+SbLah4w/rCGZmAT8JElsO4QHO35O034QwMd72Cs/6DNbRfj8ZrMx0P0qO0YHAUUeHAUJEiTImyBvq88KGD9gfD4XMH7A+FKkKFppudzo+nqs9Xq70JnNFlWp1D4Z/5YymZyOjsqfbEsd6vLyXJtN9xOyf6443mi9Dhg/YPw3fPFPentZQR702c8OywGT8bqBAY7BF0hNp5N/2ncRjJzCoAAfAsx4PJZ0wwoSjHwKN8BBkgVlnK1vE04LkOH1CoYHYMD4ktrLfGB8MFeAEpwtDhCH508b+zTgdJvgQCmGWqvVLHXZjwWf/TKAtNe9breri4sL/dZv/ZYdIhHHsTExAKXj42NVKhWdnJyoVqvp4cOHajab6nQ6BhgIrgSjdKDwgDGKIjt9tt1ua71e6+LiYuc7ftx8v5lv7kWmXK1WeymLztfEgxXy8wTo4l5cl36Tvs7/ACO2hwDquA7sI9fywa1YLFq9G2mb8cf/vn4I9/SMN/Plx6RSqahWq6nf7ytJkp3g7sE89240Gtrb29Ph4eFOnRnswANOvy0jSRKz/bRNevZK0ksgC8AMAGbuKUQNQwiL6x8GqAOSDoiAjVqtZroJm5ckic7Pzw0cLBYLAx+AUbZdVatVNZtNeyjLZDJWO8UzgsyBH2NYQxZb+WFrBPOfHluvYwgPMdlsdicLhGuiB/4kwCBBggR5UyRg/IDxpYDxA8Z/uzF+sbhdGKpUctpsMtpsFoqijcplrhspiqTNZqHNZq1qtajZLGD8gPFvlzd68e/zpC9/FSVJEgMFvV7PjuL2x2W/bmAg6aWTbGBfPg0Y3MYWFQoFNRoNCwYo+3q91mQy2fn8YDAwg8hmb4qDsppOmjW6A9sAUIB5wEnhyHB06fRhtmf4wxEkmfPwqbiegeLQBZgrAhB99t8BVPCeD3g4rFarpU6no1arZWnLMJDSy2zfq0DIpwmOCWbs+fPn+vDDD/V//V//l3q9np49e2Yp7lF0U6MFJpfTt7773e/q5ORE3/jGN3R4eGhz609DAhzwN4EBhw8oOD09lSR9/PHH9nnPXKb9A58BtI7HY81mMwNVnn2aTCYWoNJjxdh7FgzQRNBvNBrWD9gh5n25XFqdFIIjztu3PZPZ1hmpVCq2DUjaLt5xChrXRq+8fjCm2AlgsdFoKI5jA1SAaTIHaQO2t7+/r/v37+udd97RN77xDdM7z/55Jly6CVowmeggOkmQZs6wsdlsZjUJl8ul9Z9Aiq3BVmazWWPoATUAqHRtGWq4tFotq8cymUx22MooimyOAGaNRsMYxWq1qlarZSfsVatVZbNZDQYDe4Dw+uIfSqQta+5T/GH7GAMyEdiOQpu8//BZEzDv6S1gMI88zHj2M0iQIEHuugSMHzB+wPgB40sB41cqpU+us/xEP+afYLzlJ4uCs0/0daoo2qjZrCtJNgHjB4x/q7zRi39+RfVtYgY9MzMYDFSr1fTgwQOVSiVbpb5LD3peyTHUzyM4meVyqdFoZKv/0s2pOD7lHUbDM5IYEgaEUfniwJ5tSrMWvMaYe5YtSRILJDgtaZtGvFqtLEUYh++dVLqN6S0TfuU/SZKdwI4jgLGBrfAnweF0cB63BchPYxv9by8+tZlMMw6VoDg1fQEEUqiX49lfvHhhzhmd8AVifXDxjIh0U+iU4scHBweaz+cGBNNbO8hwa7fbarVaBv78KVGk7KdBJu33uoUuMw5p8Y4+Peb0lRR5gJD/LACW/jN+FKAlyHjA7LeceGAlyXSWoNPpdLTZbHR5eanlcml2iR56FpxtC/v7+zo+PtaDBw+0v79v+rVcLs0GPXOXPoXQ21Barxh/gphPh/e6C0hhqwBAmQNKsD/66n+YS0kG4rg2bCvgr1AoWPYB2Qy5XE6tVsvARL1eV71e36nV4seB7Uo+HR/b8aCXz/N95sLrPPVNPHjwWQ9evC/zNXqYSz8nQYIECXLXJWD8gPEDxg8YP2D8gPEDxv9yMf4bv/iXTvl8GwRWcDwe6+zszBwOjqLdbu+kK7/OdkqylXMUn1Tfz/ouznc6ners7Ey1Wk3FYlG1Ws2CimdAcaKr1Ur9ft8CL4ZUKBTsfdL10yylN2T+x6lNp9Od1Nsk2aaNc2oqxtftdo0NgTFgqwbXxOjZFuALpnqmJd2mJEmsEHE+n1e5XFa9XtfR0ZEODw9t6wQ24RlMLwSCtNyWRu2DNYwmGWTValWPHz9WrVbTaDTSeDzWcDi0cU2SRJPJRLPZTOfn55pMJspmszo/P1e5XH6JASF9PG3bOFQcJAH28ePHlrpOoCJAFAoFtdttNZtNnZ6e6vDwUNls1hgfnH4+nzeGjYLaPvAzr/P53Fh3ArUHlNwX3QJEApTYqjGZTIwdTJJE5XL5pW0RPpDxWa7ltwns7e1pvV7bqWu+ELZ0k+nHKV0PHz5ULpfT1dWV1uu1arWaptOpAW/aSoA8OjrSw4cP9c1vflO/7/f9PtMvHkwKhYJtAcnlcvZ6GujSljTjSco9eoqtAZA84KYGDCcXczofel4sFtVsNnd0lb8ZF9qJ36hWq5K2TN1isVCpVFKz2TRAxYPW3t6eOp2Oms2m2u22tR1d9MzctiDzje154EYbvC5jYxQ6B/jQf7+9AmDA/7fZ8GazrRcynU41mUysUPLbFieDBAnyZkvA+AHjB4wfMH7A+AHjB4yvnXH+3WL81x89fheCAbyNwICgNxgM7MhrFLlarb52YOANkrZKn11s9rZrYFDp72MgfhXd1+xgpd8zep5xwRHfFgyll9kx79R829KfwxEQRPlcWny/PIPh9doHHJ/uvtlsLCWaWiDUlvDOhuu9ihFMs1t+PH0/0ywLksvl1G63lSSJ2u22stmsnSTLddDHZrNpfwMYer2e2u221ZzwjNptY09bCMDNZtMYGkCaZ5Cq1arq9frOVhnGB6ebyWRsfjzr6cFbmuVhbDwT7Rkp6SYV3I+Zt13S070ueLaHewFkCGqAFPrpgRR9ISgSXAaDgWazmQWJ6XS6UzPDs2TFYlH1el21Wk37+/s6PDxUs9ncAdPpcYJRo72wr7TrVQz0bcHN+wrAFXVPpJvi3jDj6fH1Y8fY0E5sEX8ASABA+e009Ad/gp3VarWXMlIAmdiE11fmlAcD9AVdp7/oGX30tu+BgWeAyXjwPg3gyPjTH+4TJEiQIG+CBIwfMH7A+AHjB4wfML6/nh+7gPF/Moz/xi/+MXhvkyRJYqcvnZ2dqVAo2Ao9adIo4esU6mrQNmn3+OzPEhwzwcqnwpPm6msoSLKj2uM4NiYlSRJj7rzjwIBpl7+vX81Pi2eqPNPgnZEkCyqenUgHae7nQYK/D+OFQ6ZvHD3e6XS0v7+vg4MD7e3t7bArXJs2+mDmxzftMNJsnB83n9YNEHv8+LHa7bYGg4Gur681GAzM+UZRpIODA1WrVZ2entrpW1EU6fr62tLsl8ulHjx4oGq1uhN8/dzSd8aFAsPD4VD1et3qlEiy4r77+/va29tTo9EwZpq++XRp+ubBbJIkdk1OA+PejMl6vdZ8Plcms63b4QPCdDp9CYRhu2znIW0bttuf4gdzNB6PNR6PLVV9sVhoPB7vbP1hzGDdYSzRmW63qzje1vjLZDLq9XqazWbGypFaD4A6OjpSp9PR17/+dX3ta1+zws1RFBlTuVwuTS8pSO3Bwmw2s4DImHkQgy4tFgsD0nEcG0MKswsLSG0MAjUBEpDlAYC3XeYDQObHqlQq2Q/MPttNFouFptOpZrOZ2u221a5ptVov+QTaBTjcbDZWqwVfw/gBnOnDZDKxLSnz+dz0gOuxTYJrzedzq7Xj/VeSbLcflctlq0UzHo/tnmHxL0iQIG+SBIwfMH7A+AHjB4wfMH7A+F8uxn+jF/+k3W0Br1p5/qqJV/TZbGYKhVHXarWdQPc62yntsl+vCraf93re8XjxSp8O1lEUmTPG4Dyjlw6mOFOAjWc4cOwI1/ffx+BhCtLX8sEjzQz6wOvZSu8EaDOsGGwbgcKP76uATZrlSgMG2kXRafRtsVio3++r3+/ryZMnlrI9Go2ssLGvc5HNZtVqtdRut/XgwQPV63WrFwEg4DQu+s79aZvvB5/xbA1670Ei808wJYgDDvxYAFQ8YMUZAx4IOn5LBOLb6h9WPDvE5whamcy2ngZjC+vjmR7aQPo/1wOcSHqJLaQPvubJer22bRqAGAodU8+GMfX1U/b3960GBuwb96aN/sHMb2Wg39ist13GExbN18RhLP3nPZPnT9vzAD59+iFj7IHkq2IE14uiyGyX7Q08iFCHiHHyIN8/uNAX7w+8/vg2wMrifwCpaRaVcaCvnqX37CDAJz1uaf8RJEiQIG+KBIwfML4UMH7A+AHjB4wfMP6XhfHf6MU/r1w/abB5UwVm6OrqSoVCQd1u1+pEEABft/hAh0NIG/CrxDuctBH4vfK8N51OLU0eI/Ws4dOnTzUajbS3t6dqtWqMXbqgp3eWsFq8VygUtNlsi9rCoOAYfMAql8vGtmQyGat/Qsq7LwabZg0xZM9cEIxwRLnctshtq9XSo0ePdP/+fR0cHKjVapkT8iDiNtugT8yNrw/i2cJut6vnz58b8zIcDvX8+XNdXV3pt37rt5TNZnVwcKDlcqmzszONRiMrWks7v/GNb+j+/fv67ne/q06no36/r9lspg8++EDdblez2cwKBuN0ARyeGWEccPL5fN6K/Lbb7Z2gAeNDHQeC8OnpqZrNpoGXNIjBMcMURVFkY09gGo1GLzGr3hfBsKF7aZaa18fjsc7Pz+1ax8fHarfbtr2D9Px0XYsoikyHB4OB9TObzdrY+9O0FouFPvroI2uXB0Hj8diAbj6fty0Ajx490unpqY6OjnRwcGCA2Ne18cWxeUjxAYl2w6DSf+p/wNBeX1/vsFyk5zNu6CLbGEjjl25S4Mvlst1TktWa4d6cWgZ75h8avL+q1+tqNBr2GqwgepkOwgBTz8hyXcAe44IeedAtSfV63eqv5HI5q1mETgK4Ab+r1cr65QM+8z6dTm3e8UtBggQJ8qZJwPgB4weMHzB+wPgB4weM/+Vi/Dd+8Y/Be9sEBaOIKQpMau7nTbv/aYtXXIz4s9qWDmQ+UJEajGHi1DAUAiuCYRDoMSq/ss49PQjwq/p+vz7Miq/94B2Sb4NfkU8zGdzT398Ha3+tdBvZGgEDXK1WrZBueuxu+5/2eAbL3zeOY81mMwtcH330kaVHU4C63+/r7OxMudzNyUyDwcACE7UwVquVxuOxer2erq6uFMex1abodrvqdrs6OTnZOVGNvksygJAWD5LYIpIGRZlMxlKkK5WKATnvUD2z9SoQhcDWEBABhH6bS5rNSTPGXl8IfGxXKZfL9j1AEDrPGFMzgsC5XC6VJIkVvybV//r6+iWdp+30hbn2/9OvfD5voBkmyuuP1x3aTBFcz5jx40EY4MaDeICfZ1h9ULttfP39+dsDNr7H/f288zDg688Q1L3wgMW8eQbdgzXPAPt59yzwbawnbff3SDOh3mcgPrOB8aOP+EYPeN+2B+cgQYK8+RIwfsD4AeMHjB8wfsD4AeN/uRj/jV788xObyWR20nTfBtlsNhqNRup2u3rx4oUymYwajcZLKayvQ1BQmAFpa2R+Rd4beVq8sbBXPkkSXV1dablcql6vm8OTdp0wTpPXJdkqua+B4NvJqVrcDwCzXC6Ntep2uwYMYGBxpNKNk4UBxWip8UBAIIhhsFwjzYJ4Rynd6Hu5XLYTiU5OTnR0dKRqtWr3+awAdxsgAVwTSF68eKH3339fP/rRj/T//r//r8bjsY09TBK1BkgXZ75heLLZrObzuf71v/7XqlarevLkiZ08tV6vLYg1Gg3VajU7jclvg4jj2NLhGQMcPTpVKpXsxCbvjHO5nNXHuX//vm2Z8LUROIXLBzP0hq0K1Imgn7PZTJVKRc1m01hkSTuAExYwk8mo2WxaGj71Q+bzuV37+vraTlArl8tqt9tqNBpW2NuzSNPp1GqHALpWq5Xef/99zedzXV1daT6f6/z83FLO2TrBiWc+4PqgBXvGePoTyjyYZUuHT1+HMYYVh6lj3Farlc7OzgzYsDUHNqxYLGo+nxvzyHxjL2nQjh5wf8/YeVvEzukfjCb3aLVaKhQKGo1GVmPJ1xFi7GDyYfrQRbZbUO/D12IBuDYajZ2HVwAEQR/dmUwm1mf6g8377T4AN8Aj+jCZTDQYDEzH1uu1jXP6oSNIkCBB7roEjB8wfsD4AeMHjB8wfsD4Xy7Gf6MX/6SXj21/mwTlwklPJhO1Wi2rj4BCvy7A5BkQv9qfZkk+7fvSzelMsBw4Ju/Muaav7eGZJViONIPs9SfdXl4j4G02GyvEijNNs7Bp1iTtyHwg9sHbM5Tp/nNdz6DgHAqFws5x4l9UPKvixwDnMp1ONRwONR6PNRqNjB1MM7K+D2m2lOB1fn5udSnieFssF+DF3+v1eoeJ+iyQg6THl3R6Xzga5sYHxvS4e1ZH0g6z4pkd7ukBQ5pZ9an8frxvY51hmnHmbJ3xP7BE3Nun/o/HY9uuwLzRdvTF15vwtoMuAvJ8Md7bALxn+X0/vA6lQe1tn/ev85s28lqagWTMeT/NCnrW7jZG3F/D3wtQzdzDovq5B2j5+fegJO1ruVaa3fe/vf55sHObz/APCLex+mkW1rflNv8SJEiQIHddAsYPGD9g/IDxA8YPGD9g/C8P47/Ri3+s0n5e5/FVE5zrYDDQ06dPJUlf//rXValUdP/+fV1dXen8/NwKjv6sBeOaTCbmbGAnvHNKS1qJ4zg2NmE4HCqKInO63tmxMu9rCWAg1MtAcCzUFiA1m+LKtANmCCNfLBZ69uzZDqv06NEjY6fy+bwqlYoxj5yCxOo+RXxpNyykrwvi+49zwkFxH44jh73xzM0XFe9cPStJwBoOh1ZjgOK9HjgtFoudAOiBFqyXJF1dXSmbzarRaFi6eS6X02Aw0IsXL/To0SNNp1M1Gg2r3wBQSAcUHCNgwm83yeVyOjw81MHBger1up3g5QGMD8oEUIJtOm2e+WT7AwV4M5ltjZhms2lz5gv8Apxms5kFWXQUUAdzOhwONZ/Pdxhj7lWtVu0ENYDZxcWF1fsAsE4mE52dnVndEuYDu4Oxy2azViuCMaNIcrvdNp2CifJ6CYOdBjj5fF6NRmPns9PpdAdcMBd++wZjAmjzdgJYZK58YWQyDAh+BGn8ClslmEvmHF1i7LlGtVq18VmtVlosFsYEYhPoBgWii8Wi+ZfNZqPJZGLgijmBJZdkduKBGLrM9zKZbUFmruF9wW3j5Vlo3z+yCvzDEfofJEiQIG+CBIwfMH7A+AHjB4wfMH7A+F8uxn+jF//SjNDbKKSFclS4tC3qWavV1Gg01O12TaF+1pkfPsiRZo9R+NX1z3sdz7R4ZgLn5pkE6eX6GX7V3AdSH+T4nv8+7cVheSYlzbRwrdtW99N98vdKAwLkVewp/fVt+klswLMLXJe+VioVVSoV1et1STInjYNLt9H3O814StqZbxwhKeGkn3sQRODy85FmP3gdZ8l81Go11et1A2eeWaPP6KVniv0cAhgoWptmdghKbCnwJ8QxlnzP99vrIPeGVeI61KbwbdhsNioUCpayzvd8/Yd0IKHfMFr0hcDidZvCtuVy2QInfU2zc97uCMr0mVR3bJUizX4LDHPnmcN022/rix8v7pdmaqXdehn+875mjtdRb0+Mu28bwPBVGRb4J8aD1/y9faD2+uu/w+fTzKF/3QMLP04epHiAm753kCBBgrwJEjB+wPgB4weMHzB+wPgB43+5GP+NX/xL1wl4mx5wcGyz2Uwff/yxFQ7N5XJ68OCB5vO5+v2+FWj9WW8N8E5YkqVP+5TvLwIOvBNE0QkoGIevReENyLMfnMSEA/AnSMFa8T4njBHA2GaRyWTU6XRUKBRUr9eVJNuCrLc5Mq7N+M9mM7u3Z00YD9gNaTftGLbC11mo1+vGhH4RcJD+LO3GMZ6cnFhdhyRJ1O129ezZM11fX+v999/fOWWIz+CIGGsCPeNNG1utliqVivb29lSr1fQLv/AL+sY3vqEHDx6o2WwaG0Xf/VhSnDWbzdppY8ViUa1WS5PJRLVaTcViUY8fP9bx8bGOj4/VaDR2wEqSJLa9gW0iafCMrnEiF2wcn6N+Q6FQsDoQo9HIdIMtG9go4wLbRx0HToHKZLb1QlarlQGybrer1WqlZrOpTqejWq2mw8NDrVYrTSYTTadTC7ww2dgDgIoCw7C6zAfsHLVRyuWyGo2Gjo+PdXR0pHa7rWq1Kkk7J+LlcjnVajXTP+YVBpnguF6vNR6PjRXOZDI6ODiw09Uk7TDMjJOv60OQ81tfCM7D4dDAK9kR6AeghdfX67XNnbe3NOABODFvUXRT+wRd5NpRFO0EXgCdf9hg3n0Qj6Jo5+EGgMz18WH0xwNhMh1qtZoBN4ASOtDv99Xr9dTr9ax9ZBG8jsyQIEGCBPlJJWD8gPEDxg8YP2D8gPEDxv9yMf4bv/jHwKQN+20RggYngRF8qtWqFQbGcF9n+7xS4uS/SJvSK9+v2k7gV875nvTySV/+mrTJM3geKPjAAeNKIVECANsf/E96tZ97MkeejUuzbP49/75nP2AxbkuZ/6LCPX0ArlQqarVa2t/fVxRFmkwmWi6XL52AVa1WDehEUWS1FajF4QuZZjIZ2xKwt7enarWq/f19C3yARt8Xz+Kk2RTmiHovsIAwXLQBvfCAkMCTnqP0fPh5IzimGUXe97pJynl6rgkaBCqK70oyYM93SO8fj8cqFAo2xoVCwbZLcC3aJt3UaCF1fjweW5s96LxNl3ztEPpEX3xA88w48+CDLjrJPf34f5qvxs5pG/PF99Pv36b73tZvA31pP+Lb7O0gzSZ7fUyzgLf5D69LfC7dVnSH66VZwdseHnjP+zL0ym9p8IWugwQJEuRNkoDxA8ZPS8D4P5kEjL8rAeMHjP82Y/w3evHPpwxjIP50lbdF4jjWeDzWYDCw+gCnp6fKZrP6d//u3+nq6srqO/wsBWODsYCJgGEjdfXzymazPYWrXC5ruVxaYV7Pgkg36bus3KdrFHhGC+BELQ8PQHD8tVpNi8VCo9FIhUJBJycnyufzOjw8VJIkxgZR6JbiwN5pplmBNIDxdQ08iEKXvZOCkSmVSmo2m2o0GhZQfzeCMyXwVKtVHR0d6Vvf+pYuLy8taDx79syYzXq9rm9961vGWMFUUlvCF2dG+J8ToO7fv6/9/f2d07xojx8H5sUHJYBbuVxWrVbTwcGBCoWC1VTAoTLnvJYOCp6F9P/H8fZEL0788mwfWyM8awhjJ8n0AB2gxok/sSmfz+vdd9/VgwcPXqrhwKlf0+lUH3zwgXq9ngaDger1uo6Pj00fYK45Ycz3oVwuK5PJWC2XwWAgSXZ6HeMHqEqSZOe0rvF4rOl0av1mPEul0k5RauaDOhi85mtqYFOe9fVzyelV0paJhIUfDocaDoc2hvj7YrGoarVqdkrGgAcvsIbYmK9140EHcwQgwh94GyRw85043tajIivAAwC2QN1my+kaVpwQRzuYE/TT1w5iDJlzQBu6Sz2jfr+vKIp0cHCwcxJhkCBBgrwpEjD+VgLGDxg/YPyA8QPGDxj/y8L4b/TiH5PvBxPFeJuEVWUcSxzHluILK/K7YYy+jLYB2JgvAsYXFb+aDxBE0oHRMxToBE7BMwv+JCcfLDB+nAHt56QmWBruixNM772/LWD799OMYJrFSLNhBHDSk29jIn5S4Tpcu1QqqdFoaLlcqtlsqtlsGgtIEdVOp6NGo6HT01OVy2W1Wi1j/XwNBT/fgA/YVQL5bYxgeg5vay96RZFh7uXZP7/d4tPYpDQjmwYR0s12HIKAZ2pIa/dbcNLzil7Rf88MAUKYY9LSKfgL08MYbjYbC+oULPbz6PubrqfzKjbc/+0/jy3ja/2c8jcBEfaU/9O24fU4zWhuNpsdv+7HkfbiR7gnDKTXkzRA533ajm7A+PL5NNPHOHhJ9yPNGvqxua1Nnmn1bbhte0+a3eTzXjabjRWIXiwWn6rnQYIECXLXJWD8rQSMv5WA8QPGDxg/YPyA8X/3GP+NXvzzQaZUKknSjpG+LZIkiR39PZlMNJ/Ptb+/byzJ8+fPrR7A6xBYBlb8YbM4Av5VTj8t6VXxKNqeDEbw8vdKF4dFL6gDwclbjUZD1WrV6hxQ14C0WpxZmr2kJgEGTlCL49iMc7lcGgOKwwZI0BdYXIw+nRIs3aS8+8/gPHCin+YAPAjyLOOnOQvuVa1WdXx8bHVU6vW6HTd/fn6uSqWi/f191et1dTodYxLL5bKdoDUej7XZbKxWBTU7aIMv2Htbm24DPengBjPst8BwwhanQtEfTu+CMWb8fQp/OpDxGQI07SLtOpPZbnXgmugon2MOs9mssbjFYtFO+iLFX7oJjACFjz/+WO+//74B4dlspvPzc7MjANF4PDY/wLXSQa9cLiuKIjUaDdXrdesfACefz++cphdFkbFjAF+uO5vNjN2nDQRDCpSv12s7MYsTsQAN1LVBD6jFwalojUbDTnGjLgvtZ86xOQT7YeywW8YfsALYms1mVjg3m80aQMVv0FdsmrFK+4FM5uZ0MYAbIMQDCw/WuD5MNcweuuFB6GKxMLbSgxb0FF1/8uSJnj9/rl6vp1KpZODB63aQIEGCvAkSMP5WAsYPGD9g/IDxA8YPGP/Lwvhv/OIfQhB4GzMcWOXmSHRYAowPJ/y62uYdbJIkFkiZry+isFyP9Ox0GrBf9ZdeXpknyHPaUqlUMsclvZw2zP3STJFnFjx7gUPixzsD/z9/fxaLfRtLQ7/SY/dZus8YfR4b8c6XtGoK7u7t7Smfz2s6nVrqtNcv/k8HelLIq9XqjoPzTph23tYn7zy906RPns30+sCccA8fVGaz2UugyTtcfiTtBAo+D7NEv/mdJIkFUs/kAFo5zj6TuSlQnWaI6PtkMtH19bVms5lGo5EFCgAJQYbA7gOgHxteI9jDKNNGxtjrGvrt9dkzUqT9SzcBjh++w//pYA176dl3P69+rgiYnkH07Jln6KQbNtgXMuYnzex6sJzewuOvmWbh/Lz69/3Ye3vzY+Ovj2/w/3vG0D8opPvsx3W5XNoDIKwyuuuZziBBggR5EyRg/K0EjB8wvv/sp41dwPgB4weMHzD+Z8kbvfiHYmcyGVUqFeXzeQEpWygAAOjHSURBVI3H45eO4/6qC44CtmY8Hmtvb0+FQkGnp6e6uLjQ1dWVer3ea2kf2wGoq8DqNvPnHf2niWfSzs/PVa/Xtb+/v5M23O/3tVwuNZlMjC1OM22wdJvNxpzzfD63eiqs/ktbQ8RpU4dkMBgon88bu8P2gFarZYDFs3QwBBiwd5AwhRg6wYSgw+uk+AI+JBkTAWP4KkkDis8j9BvHWa1Wba663a76/b4xp8+ePVMURXry5InV9yiXy1abw9dYgDkhiKTbJ91s2/Ap37f1ZbPZaDqdajqdGvNHzRkAHzVGqN3Bbz4HYAVYM57r9dpYLGlb26Pdbms2m2k4HBpDB8MFY4pewArCTibJzUlxzC/1LthiQtAjpZuCxnG8rTvR6/V0fn5uwbJYLFofCAi+roQfLxgi7AHb8wGW64xGI6vpksvl7KQzmDRYQPSeORuNRtY2r+ucEIb++W0BnAaGvhGcYRtHo5EFQvSCMaPNaTAOY+mDMiCeU+FgAwEnsNKz2czAGvdpt9s2Njw44HM8C0hbPHiCBY6iyPQF5phgDfDmfWr9+NMb6dtyuTTGnXsACPB7ZIYAODwoDhIkSJA3RQLG30rA+AHjB4wfMH7A+AHjf1kY/41e/PNODgV9W7MbcFQ4FZxjpVKxE5Zel3ij8cwIjtCn9H6WYHQUKE0zOTh46YbFwVF5ZgGn4YMvTCFHuXs2Rbqpc4DBe8eA06Ut6f4TDPxKvwcrtMG/5l/3/fRt/7StAF7SQfjzfB7HQgAhUNVqNS2XSwMOo9FoJ32cYAIYYAuA70O6zd6JM8efZcue9aPNADUYSNrj0/9hpW4Db77gLcGE/hOkEYIE+uIZt0wmY9tT2H7CFhMCcTo1nKDI9Qj+tVpNnU5HSZLYVhhAITqJ7tAvatUgfguI13kPqglOi8ViZz79+4y3b79nM3nNM2ielfX67LdvAWZoG/1aLpfmK7AZD4S9zfjf/M09uY+/B/cFhPu+8D1AG3NKXzwbCziDgfQAgb54BhEQ6+/ltzZ4v5TWd2zIA2b6x7UBPLTVM8NBggQJ8qZIwPg3EjB+wPifJgHjB4wfMH7A+J9X3ujFP1Zj4zhWpVJRuVzW+fm5TcLbIijcYrEwZubhw4cql8tqNpva399XsVh8be1D4Qm6sEOwItTEuE3Sc4nhwybgXHDee3t7ZhiSdgzaGyMMA3rjWRKYEwwW0BnHsTn39Xptf3N9Timi7gr34khuAh06y2lbsA/pNnoHiTPGaRAAaf8XBQafJoy3D3Q4/Exme/LUcDjU2dmZhsOhnj17ZvNQrVatNguOtdlsqlwuq16vq1KpWKDhPjgwPweMlWdP0joF4wRTRPApFos6OjpSvV435tazMZvNRr1ez9rhnTf3YQ44bQpww718bQwCKdcCpNIvCvamgQHOfzababPZaG9vz7anoPeTyURRtK3fUSwW1Wq1VCqVrJbHfD7XbDbTxcWFsUuLxUKDwcBqhwBeYMuwCxgmGDG2SHCqYKFQsLohjOFyudRoNDIAA6vO93k4iaLIrs1YUf8DHYSZA7x5HSXAwqp6obaO1xHYXuyxXq/v2CsC29xqtex7vgYQIMCDkcVioWKxqMPDQ41GIztlizn2OuTnnT4MBoMd/aV/0+nUGHd/mtp0OrV58iDFP0gBECXZnPT7fV1dXRlj77c1va3b5YIECfLmSsD4WwkYP2D8gPEDxg8YP2D8Lwvjf2EK7Z/+03+qP/En/oROT08VRZH+l//lf9l5/7/4L/4L6zg/v/zLv7zzmW63qz/35/6cGo2GWq2W/sJf+Asaj8dftCk7HWV/vVe8t0kIVoPBQNfX12YQsAqvkxX0rAFsj2dsPov9uW11HKXnmtKW7SBdFsYEp3Vbm2iLr0cBGCAd3bOX/lppphPjoxaAZwFxcD7gYvA+Zf42QJtezSeg+DZ+VrqvZx4/ix1It/E29gr2YTweazQaaTAYaDAYaDgcajAYGAtGG2ETSSH38+FZUs8aphkk3we+h857QEAQr1arpgce2HhQR0D290zrCtf1NV/4m99pRp4gnO5Pei4ABgQo7gejKd0UtwYMHBwc6OjoSA8ePNDx8bFarZYajYZqtZpqtZqazab9DzPrwQ6sHz++jpAHEBS/JWXes2bL5fKla9BfAilsHmPPOMKyEUQB8Gmd9Cwa4+MLLXv2L22Hkmze08J32C5Ce9BrbydeX3K53M5pdYzFbXPq9ZUHA8YJ4CLJtlmk2XJ0CYbPPzQBSAj8/qFwPp9rMpmYXjO2gJS3NWMmSJAgn0/uEr6XAsb3EjB+wPifNv7+WgHjB4wfMH7A+J8mXzjzbzKZ6Dvf+Y7+/J//8/qVX/mVWz/zy7/8y/of/of/wf5PM1J/7s/9Ob148UK/8Ru/odVqpf/yv/wv9Zf+0l/S//g//o9fqC2sDks3Dp2A41ft3wbB6J88eaLNZqPnz58bWIJtuAvtm81mdsIPRolTfNX3vOAwMJ7r62ut12urXyDdpERL2zoIpKYnSWJOCScCQ+mNm60GGCRbCHythSiKLLWcrQB8HyeHs/K66QNEGmj49F0CIwyDT0POZDIvHXf/afJ5WfK0Q/Pf9/1h7EejkWazmaWuw8J97Wtf0/7+vh49emQnhHGKE2NHfzzwSPfFB0/vcKnV4Ws+sOXA11OBxfJBgx+/bYCxZk6ZV/SA2go4eLac+NoazJWfzzSgY84AGjzI0MZms2mnp+VyOauT4dsGgw5rVKvV7BrlcllJkth7i8VCUbSto9HpdLTZbHR1dWVsnqSd4BJFkdW1yWazxpQBDqirAjs6Ho8Vx7FqtdqO/VCrg6DnA7RnuXzRZNrgU/YZPxhwD16m06kFbV+bBZCInbGNA1v2zDDXZtwATZPJxHynBy48eOzv79tcoB++aLbPckiD2kwmY9kD2WzW9BIASJu8DTIeHijxffQEvWU8sAG/NeBtiodBggT54nKX8L0UML6XgPEDxn+VBIwfMH7A+AHjf5F4+IUX/773ve/pe9/73qd+plgs6vj4+Nb3fvjDH+r/+D/+D/2Lf/Ev9Af+wB+QJP23/+1/qz/+x/+4/uE//Ic6PT393G3xq91+lZ6BfNskjmN1u13l83kNBgONx2Nls1lLOf28AeKnJTAQHsDdxsR8HmFlfDKZKJPJ7KQ6R9FNDQ8CAGwdRYilG/3xARiH5NPwPWPlv5dOCU6zbv573pCpG+BX6j2L+CrA4EEDffpJ5TaWLQ0KuJ/vj2diYDpoS6vVUqfT0eHhofb397W3t6darWZp+fQrHTBfZau3MaLpgM98YPs++OMY069J2tFBz0Km2Tyu4R1vmtlmOwIBjnFLs53oIMAAoAQwLZfLlnp/m9Bf+g+4kGSAYjabKZvNajqdGmDAP9JGn2LPvTxDXi6XlclkDAR6hpcfmFXa64ERbWIsCXTMpdd9gqNnyzxLzlwxdp615DcAIT3f+AGvz+gu4A7/gF+A2fUB2G8/yOVyajQaVugZfQBkMlbeZtI+AvBDoOc6nn1n/L1PSuuxnzuu4UGBf5gJi39BggT5LLlL+F4KGD8tAeMHjP95JWD8gPG5FtcOGD9gfOSnUvPvn/yTf6LDw0O12239R//Rf6T/+r/+r7W3tydJ+v73v69Wq2XAQJL+2B/7Y8pkMvrn//yf60//6T/9ue9DDQVJO4rLCrJPpXwbJI5j9ft9SdIHH3xgq9itVkv1el21Ws1W+n/W4o0A9qFararT6RjD4B33p11HkjmtwWBgLAkG5JkUb1QYGawBKb9xHFuqOm3Aofp0bUACTAHGzHcPDg6sxgjOmP89+4RjIrXaG/Rt/aXt/t7UUvm8wOpVwRcHymf8+PvveNam0+losVjonXfesRoK5XJZDx48UKvV0re+9S3V63W12+2d079gz7yT+zRQ8Gl9wYGyzYCaKLSRe3idoB+krVObhuDmnbEHk2lWh3R29IJT0qhJwT1hognEABe2wtB2gALX5x7oId8tl8sql8sGiOm/tGUHKQDMaXTL5VK1Ws3AwHq9ttPqCKj+ZLZ8Pm/MpHRTYHsymeyw+Jyihh2NRiNrH6yndAMM6BugnXtXq1VFUWRtQ/yWF04wY6w9sPfX5H6eEQWkeICZ9jGz2WwHDOAb5/O5fR8AxnjAQPr7LhYL873YMTrH/9gQc+oZa0mmc7DFbAtAL+iHBwxJsi0QfX5+rqurK41GI2OxC4WC1bEByAQJEiTI70Z+VvheChg/LQHjB4z/KgkYP2D8gPEDxv+88qUv/v3yL/+yfuVXfkWPHz/W7/zO7+hv/s2/qe9973v6/ve/r2w2q7OzMx0eHu424hNnc3Z2dus1ScVFhsOhpN0TnrwyoYhvm2DEURTp8vJStVrN0rI5Dt2nPP+sBWAgydL02WOP0X0e1tKDA9gPGAqcUpoxSwMDHBtGjiFhqJ6V8yv2fpXfOz7SlmEFPKPo08Y94wjb5OspfFqf/b396UTe6X0Rvf8in+f+2WxW9Xpds9lMBwcHkmQ1ON599101Gg3du3dP5XLZ6lEAiDzb8btlp32QZt5hjTwr450qQdezRzA0vo+AOoCdtxf8DEEbXUqzUWxL8SCTe/MdWMV6va5SqbTzMEPA5J6wScViccf50wcCJu2FESQQUxy4Wq2qUChYzQjPUPoaGR6QLhYLFQoFm0P+5n22hXhAJt2wmPQBm6SftIX/03NGYMVWAFOMo2eZYduxZ5g82nqbf0mSxOIKafx+6wAPG9zPAwEPDNA72H50iral74s+AZAADtwLvUBv0jrMPaWbAuX9fl/D4VCz2WxHL9ELgHCQIEGC/KTy08D3UsD4n1cCxg8YP2D8gPEDxg8Y/3eL8b/0xb//9D/9T+3vn/u5n9PP//zP691339U/+Sf/RH/0j/7Rn+iav/7rv66/+3f/7kuvY+DS7mlC6YKjb4ug6FEU6YMPPtBisdDx8bH29vbUbrd1dHRkivS7dcw/ieCohsOh+v2+4ji2IrE4uS8icRybgwQsNhoNq9OADvhARHD1DmC1Wu2k4sI0+FoCPoBSPHUymRi4oVgrzhsHzb1g/QAH1ELgWj6owB5IuyyGdxqvOj3p84r/nv+N+JRoHBJs0aNHj9TpdGx8YMA8IPDbPeif34KRZmrS7fq0dnsQh2OFXfWnOEVRZGn65XJZkgw4cx+cvq8f5EFloVCwuW21WlYDwjtaalOkAyH3nM/nO2nafj49SKB/6EG5XLbUe4Iv7zWbTbunT4knwKODhULBAgV1K/isdHNSXqvVUqVSUavVsmyLOI5VKpVUrVaVy+UskNHmSqWi9Xqt6XRq8wjr5ccXZm42mxlQZovCcrk0vSagchoZ+kPRXOba22qabUbfCOroMIHVj710w9h5kA1Qmc/nO1s2JNl8+IeCarVqcwFYwv49Iw3QA6ygE4yPtzv014M9X+DYb3/x7ChF4MkaoJ8wwUGCBAnyk8pPA99LAeN/XgkYP2D8zysB4weMLwWMHzD+7fJT2fbrhcKgP/7xj/VH/+gf1fHxsS4uLnY+s16v1e12X1lH5Nd+7df01/7aX7P/h8OhHjx4sJMinU7lfRtZQelmpfnZs2daLBb6Q3/oD6lQKKjZbKrT6ajX630hBu6n0bbJZKLhcLizak0g/yLbOHAsuVxO0+nUjDtddNc7Y5yXDyh+tZzCvjgEUoC5nyT7znw+13w+t5OX6vW6MRGecUyDEa7v2Skvvr1+mwCOgsDnA+1PIrd9zwdrmBV+YJAKhYI6nY4ajYY57Xw+r4ODgx0HT4DFWQHY/X19Xz+rbQhzjKMjlRtgkHby0m7RXPyEZ1gAcThf5gxgwPwyr1EUaTKZSLoJ/OktHRR9TbOO2J5nv9hmwOcIiIwv95C2QaFWq2m5XGoymezMFX0HtAEMYPbIpPAnWmUyGe3v79sYEWRhDSlyC4jNZrNWRJe5xU4AY143CWbD4VCbzUaVSsUCG8DS6/R4PNZ0OjWQQ2D0wIAfAqIP/uicpJ328j7Bmr9haj1wABwwjugpusbnstmsASlS/GEYF4uFstltPSbfJs9SMj7MC77J6wc6wDhhA/6hhZgH0CqVSjvAgGsECRIkyJclXwa+lwLG/yISMH7A+J9XAsYPGD9g/IDxb5Of+uLf06dPdX19rZOTE0nSL/3SL6nf7+tf/st/qf/gP/gPJEn/6B/9I8VxrD/4B//grddglTst/z97/xlr+Xqe9ePX6r3tMrOnnmIfO7ZjHGIsYiL4OQElRIg3WEL0IBCgKAGRIIGCeEGIwBQBEi+AN5S8IApCokggOoTqEGJix+0cz5k5Z+quq/f+f7H/n3vf6ztrz5mZM23PPJe0tdta3+9T7/ta3+t5roeO8sqG37v9qmK5PN4jzkk9yWRS29vbev3111Wv11Wv1y0QPkswkEmoxWLRVIdisajBYPCBy1aj6hcTst1u21Nx1BP+79/nkxRBk6CKUuETth9jLD0vlUo2yTOZzMppYn55rw8+0TqgXvgjwgkGJAruDwH2W16YE14BexzQTtH3rwu6KGi0LwkDpSiqxvrrr7uXN3BdLBYrSueD6kMb+a0d/hpeGaT/o34TKLU+OUT7h3iCAtntdm28EMB9XQn0gLGMWkSZvUrEUne/7YTj3L2xq79uKpUyTw5PLH0/kYxZKu89QDwgSGzNgVTjUROLxTQYDO5Tu0jasdixt483GfaKI4mMMcI9PXH3/QKh9ObljC2vvPFeSB3zkf+xrYG/QVq8V0m0HTwhYuz4OjBmGEu0CWMBwkA/+A880vGKBdpFOiHMfNBgHnN92tarfqiD6XRag8FA/X5frVZL+/v7ajabK8o494+q8AEBAQFPAk+C30uB4z8qAscPHP9hETh+4PiB4weOH8UjP/zr9Xp699137ff33ntPX/3qV7WxsaGNjQ39zM/8jL74xS9qZ2dH169f15/9s39WH/3oR/XDP/zDkqRPfOIT+u2//bfrj/2xP6a///f/vqbTqX7iJ35Cv+f3/J5HPgnMKy1MSp4iM/BeRSwWC1PJGOTnzp3TZDLR9evXlUwm71OpnlW5mKTD4dCIAcvIWWb/IPhBTlKRjsdlPB5fORLbJ3ivgnhiIMkmExOH4OmX5XvfCZa8c50oMfABOqqC+TqgHET9QEj83JsE4RUkjFl9kI0imlD422m/e4K9LqCQkPm5UCiskBm/1Dl6Dx+keT+BlmTLCVQQkNMCWVRNI9HTT75dvD8EiMfjtqz7NFJFven3xWKhXq+3khyiiqZXeaT1xMC3szcJns1mKhQKymQyGg6HarfbK23h681yfEiEV4d4DR+OUKz4oo9oF9QywFhmHo3HYyMGjEUUqmKxKOnElym6tSW6NYv558lctG5+iwRznNczTnh9lDizykCSKfrMHbZF0C5+vvF671fCh4To32lrxrJXcn08ZU7Qh35+MEeoP74f3tNFkrUDCirkjtjV7/eNGBwcHKjVamk+n1t7cf/w0C8gIOBh8CLxeylw/NMQOH7g+Lw3cPzA8QPHDxz/UfHID/9+5Vd+RT/wAz9gv7NU/0d/9Ef19/7e39Ov/dqv6ed+7ufUarV08eJF/dAP/ZB+9md/dkXV+yf/5J/oJ37iJ/Rbf+tvVTwe1xe/+EX9nb/zdx658H4ZLstemcyv+gcent6j/m1ubiqZTJqPA0tbnyWYiOz3L5fLNpDz+byGw6EFwmgCi14jqjaxbLrZbGo6na7ssfcTdJ36RcDgNCn/GsoCoZGkUqlkCgtkgeQhnSgSTH5UR39tVASCHapJKpVSoVBQqVRaUVooCwF4MBiYoWtUnQLr5oAP3KeRhnVt4H/3gW7d/aLEgERJ+f1yfcZotM9Og1dq/bYMr/pwuhckUDpRIL0q55df8zoSpt8a4E9ro8zeowM1lHqSPPCkYHwwfiCplJt+RIXqdrvq9Xq2rDuTyahSqay0AeOAa5LIvBcH84q+YtuEJ8wQI7+NhiTqTX/pM9o5Foup1+utJEBUasYiRMkruMTsWCxm7cb4jy5x9+ONZOrnI6+DPPgkzL1QXqNbPry/iI8pKGos6/flpR0gH4whtgL4senbxY9Bxgkkhvczh/3cY0xwHeLDfD5Xr9ezr263q0ajYcboxCRIhr9nQEBAwGl4kfi9FDj+gxA4fuD4geMHjh84fuD4j8PxH/nTwBe+8IVTg7Yk/ft//+8/8BobGxv6+Z//+Ue99X3wS2YhBX4p5qsMghdP98+dO6dz585pa2tLhULBAtuzxnK5tPtubGysEIN+v28T6UHEIJqoIAaDwUD1el3j8Vibm5srgWrdU3ImOkuOi8WiBdx1yhZBuFKp2M/J5PEpSihQBBfpxDgUlYEgHFVYCEAojOVyWVtbW+r1emuVh8lkok6nY0d7P0jdioK2jQYhTwr4Tln9NgevPKFW+C/fbgQ7EgyJ1S99ZozSBr4Mvp998CaBTKdTI0h4kmCC6hVKSNh8fuJF4VVZyIBXmePxE08Nrk8Ch8wNh0MrF+3hyWC/31cikVg57h6FOplMajgcajabqdfrKZlM2naWdrutTqdjpCKTyahYLK4odNzDm+mSCBl76XRa5XLZkrYkdbvdFT8L5gdKE0fPl0ol87FYLBamUI3HY8Xjxx4V7XZb6fTxUfPxeNxUQgiGV7IhH76f2VaAQks7E8P9WOXDHvMM8sJc8+M2mTw26CVZx+NxDQYDIyN+NYDPIYvFwlRD4qcf27SX3z7g/YT8hwH6hHFGnfkQkkgkbHxBjqKEnHkBsWQ8jEYjdbtdGyfNZlONRsMMlCGrXq3lngEBAQGn4UXi91Lg+A9C4PiB469D4PiB4weOHzj+B+FMLwXwgYQJ4TvuVYVXTdrttnmylMtlVSoVFYtF9Xq951Y+vwxckilhrVZrJag8DKJJttPpaLFYqFKprCwNJ8mR1EgWku5LItyb1/mn6ZBQEo2fzFyPIITyEr2uv06/37dA7ZNds9nUcDhc+b+0unTakwx/Xf89SpB9AF3Xlnz39VqnEkavQfv5v1FGyuDL4omE9/CIXnMdfH/7wOwVoagivI4A0UckGU+G5vOTk6BQnrwqGFUUCciehKCAorjx+tFotKLcUV7qQ4KSZISHsUjigWRAOnw7U7/l8tgXiL9DYlOplKleXi1jqXxUoaP8KGLpdNoSEv3n+5+ysESe0/poe+Y9Cib3JPHzflRMTyh9UqdPKBeqKMmW/9M/qJq8n7JDnPyHB79igvLTx/jDcA3KDVC3fZ/5e9LmjB3mG+2Fakyf+W0hfAjI5/N2Att8Ple/3zcF1KusvC8afwICAgJedASOvx6B4weOHzh+4PiB4weO/7gc/0w//PMnm3DEdLlcfuWJgXSiCu7v7+vu3bu6evWqtre3tbm5qc3NTbVaredaNq/AMCnx2ZBWzVvXIZoMCQjNZlOj0Ujnz583w1Seji+XS0sc/km9D4peZfPLx73agxrnFS7pxNzTT2KvYkXVxn6/r16vZ+oDAWMymajb7VrS8soEgYuAEQ0AUXUumtRJEl5dJYlQT+7jVcB1bU/C5VpREhIlBl7lo00Wi4UlK/qecnv4+xBcWU7PigCSmJ//JPWowsjruUYul1vZ4oCqh0kuYwwlM9rOqIiofBA8FDdIw3w+12Aw0GKxULFYVC6Xs2v1+307sYu/ozz6pfOoRel0WrVazRS1qB/Fcrk0k2zqgdoGcfFK5bpkHIud+HqgSmWzWU2nU/V6vZWj6elzvwwecsQXhBi11Y9b/15fRuYO7QWJYhxQpslkYh94iB+MZ8YEc2w6PT6trFAoWHt7E/Hl8ljdZ47yAaNYLKpQKKyQEJRICBTjhXryOvIV9YzOJz9OISHUlb5gTOfzeavrdDpVt9s1VRUPGE9caceAgICAs4LA8U9H4PiB40uB4weOHzh+4PiPzvHP9MM/nzx8w/nlzj6BvEpA2Wi1Wtrb27NTjBhUz9P/yasu7XbbgjmT6nFWqDD4R6OR4vG4GWfS/6gSBCgmDZPFK2DRibsu8a778k/kpePEz5YHfBQk2UTnKX702t5bwCcz/sdydO9ZwDW8QubVMN/2fk7463Md7rtuW020XPztNPh2JTEwLwnEkAJPRtbBtwEJzPcZS6FZ2u7HUVRZ8/32oHtBFPmKxWIrPg5c0/e996igL6LtRXtTRhJj1EhYOjmSnvHLWPflh/Dyfm9g6xU7/o7xMiSXdqVtUD9pW+ro55EnBX5OQdRQ5yCxtIsfF378cH9fDuIC/cf2DcYKryPhQ+QZR9SX77Q7S/+pA98pC+1Gv9C/vB/ChLLo5w8rVKJjmbJFxx5z1SuLPpFDeH37cILgeDzWaDQydZx5Fl0dQx8GBAQEnBUEjn86AscPHD9w/MDxA8cPHJ97v1Ir/6i8P0o9GhRfRXLARL59+7aWy6U+85nP6OLFi0qn09rY2FgxtHzWYIC3220zKK7Vakqn03a0PMtdHwY+qJGMh8OhXUs6OeabpB9VHObzuZloZrPZleAdfZrun7b7//utAvP5XJ1Ox67PCWKJRELNZtPUBk8kPFGRVj0mfOIfjUbqdDqmPjHuCcrL5fFS8Whi98ELELwYLz5wrwviXMf/HL3eum0ItD3tJ52cOuW3bXyQmg8pQA2knei3YrGoZDJpqiptCPHo9/v2d8aB70viBuMJZRYVMp1O26l10skpXvQ/yhnKM6/xS+T9uPJtRTvgybGu7byXCWOL9/ql7Iwb5hHL1PFDkWRjJ5qQUdsgQel02ranxONxuwbfSbqUi8RI3/qkFyWKXu1l7lAmtlPQLvQ7bUz/M9+lE+NpxgWGw4zxbrcr6djQG/8djHn9hxISPySw3W6r3W5b+/itJ/QtnjFsbSqVSivj2ZtF+3lIGSA/fKjhNfl8Xrlczvxj6Ldut2ungfV6PRu/futGVGEMCAgIOCsIHP90BI4fOH7g+IHjB44fOP7jcPwz/fBPOglS/sk2Ez+ZTK4Eu1cNy+VSvV5PzWZT9Xpd9XpdklQsFi1QPM+2wcC3UqkomUzaRMQn4FHKxmsJcAQyAqM3xyRIAAIXE/001Ygg4JURX05UDyagT14EhXQ6vWLS7BWQKJElgXBv6oei6IOHL+ODAsBp/+N9fK1TBE+7R5RAnKYY+iTgFRFe9zgPJ3zbk6R9ouee/OzhAym/U3f+xhJ+FECSfCqVUqlUUiKRsLnE2GIcRX1kCNKQcl63rr/9+3xbecLhlTdUOa5HPdjmQGz03ifUxSub3N+rnp7U+C0R+Xx+bZ9ElWa/DcePB0yA2RJEYmZ8QQLZmuMVV9Q66ufJNff1/RVVhMkR9Fl0C4E/oc/P0el0qn6/b2Xkw4QnTH6rky+PV3olrSRrP8+j7edzGvFjsVjY1iFijJ+71B210yueAQEBAWcFgeOfjsDxA8ePInD8EwSOHzh+4PjrcaYf/tH5dGQsFjPjRp704hPyKmKxWOjw8FDD4VDXr183lezcuXNmIio9H9V0uVyaL8LW1papLRsbG7b0mIn8KNdkKW+9Xtd0OrUjv7e2tsyTwfvIMIFQldZNYAItyd2f8JNIJCxoejVoPB6r1WqZGTMGoqVSSb1eb2UZb3QLgCc5PshLJwG70+mo2+2uBFufjNYldpLBuiTM/7xasy5Re4XKtw/39PcgyK97vU/U9BvJ/UHw5IU2Qr1KpVIaDoeKx0+8M/wSev967kuypd/9ioJ4PK7RaKTBYGBLrP3WFRIBSk6r1VIsFlMul5Ok+xILr63Vakomk2b07BVIfvaJDHBP1DFJljhJTrQRdSiVSpbQvFGuV6K8BwhlJPlHy4byuVwutbGxoclkon6/vzIG/NJ36WT7AUot86fdbkuSdnZ2lM/nzQAZ4ozHBYmNvkJ9Y3uTLwNl5sSyKPnD/ySVSq1scaDdomTdX1M6Nvru9Xo2BvP5vKrVqn1fLpeq1WrmG7RYHG8/wLOD+co4SSQSGg6Hpjj7/qNP2NrEygJWP/R6Pe3t7andblse9EQIk3X8Tj5obgUEBAS8SAgc/8EIHD9wfI/A8QPHDxw/cPyHwZl++OefmDPheWotnSyffVVBQBiPx2q322o0GkokEtrc3DRl0PsqPGsQjAk6yWRSpVJJg8HAyuaT+MOApANBHAwGK0/qvQIUTRIEQB8gKSOTiiW5qAk+kUSf6PMzCl673TaViX7xSgzvA54Q+ESIMjEYDNTv91e2G3hC8CAF8DQ87nzx7/Nt4AnPOsWLOpGko0ll3fUXi4UlD5JdJpMxE1aCqFe6vKLrVTWfNPib70evspGgOL7eL/lmu4FPItG6esULpcsrgZSXoE5d8KvgPSyX9wmNcnjTYUn2OtrXnzIFsUWN833g1VSW+Pv29+X2ydX7ZnAtP8888QXMKU/I0um0mdpCvPz4YatBdCxRN64V7QNUReaR99SJx0/8USiHVxGjhJS26ff7kmQftvyqAa8Gp9NpS/TRMtMu1JcPHvSdj0neCLvb7VqZIU4ogbyeD8qv6gfkgICAs4nA8R+MwPEDx1+HwPEDx5cCxw8c/3Sc6Yd/BGd+lmT7/ZlQ69SRVwmYot65c0epVErf+73fqzfeeENf+9rXVK1W1e127USZZw2C9mAw0HA4VDabVa1W02JxfKIXCfRRVEsmUaPRUK/XM6Voa2vLAi6EgYRP4JGOtymMRiNls1lTYLrdrikp7MOPx+OmAqJy+KDhA2Or1bJE5n1Y/NHdHj55+CXQBLThcKi9vT2Vy2Xt7u5qsVioUqlYeaTVpfb+ur6dovBBex1BeJCa6N/jE54vN7/zWn6HHHpV05P+aKKeTCbWv91uV6lUypQ2YsLGxoYWi4UODg5McSQB+oDvt4Jwf/otkUisnN6UzWZVKpW0vb2tbDarcrls/Y05M4qVb18CMku7aTO8Jqgrp4dVKhUVi0VLTpARn2ghANQH4oLxdLPZNCXS91OtVlMqldLR0ZFGo5GRHW+m6wnpYDBQt9tdUc2ZY3wAg5BR18FgoOVyaX4UUVLOeICU0cb8XiwWlc1mjXz1+311Oh2bq8lk0k5K8yoecxJy4tVRxkU+n1csFrO+wvcE1azdbms4HBrR9Nf2HwLG47EGg4FGo5F6vZ7K5bKRmWKxaGOGNonFYiqXy5rNZqrX6+bnEovFTA1kfORyuft8rvxpYt1uV91uV/V6XXfv3tXBwYEGg4FyuZwKhYLy+byy2awp5WxbeJQ4GhAQEPC8ETj+ByNw/MDx/XV9O0UROH7g+IHjB44vnfGHf9GK+qen4YPOMVAImODL5dJMUyuVysrR2c8aXokbj8fKZDKmgESf+j8q8BIYjUZmDsukxb+B5d1MeII0T/O9KSmv80oSZYwqigSCYrGo5fL4eHf+z5Lk5XJpx7kzVr1CFU2GJDMCCkvVW62WHT/vT9Pimqcleq/WeTyuYrjuf14dXPf3aP3WlcW/l3amb0lkXsni/56ESCcnK0XJhg/4lIH+gxyQcLmP/51ykeglGZn1dfJqIeX3S7cXi4UlIp/MKQ9L4CEGD2q3aBvG43FLzqjvXDtKwHyCj4I6Mfb933kP6pNXDv2JfH5O04Z+Dvkx7seoH9fR8eSJHK9jewH3o5088UEZpP8g+Hz3Y4n28ff02xRYeUD/+DjiFVyvBvsvr8L6seuNlqkL858YwOlolNe3D+1L/QICAgLOCgLH/2AEjh84PteItn3g+IHjB44fOP46nOmHf36pKY3KEk8fWF9lEIwODw8Vix3vdy8UCrp48aLeeustLRYLMwl+1qD/OD2H02sgCD74PAq8WtBsNi2oHhwc6PXXX9fm5qYymYw9+U+lUrbEnsBAQkcNRFVCKUokTk5CwjiUU8gIFFevXrXXtttttVot9Xq9+7YEMJH903uCA9djOTEEo9VqaW9vT++8846Gw6HefPPNFYWSYOaXbfv5QBCJkh0frKSH2yKwjnRIq8vR/Wt94vNB0ZvjRskDbUK7sQyaPqB+BHJ/khwqEAoQbe0TJuONbQa0YSqVMrNq+iefz6+otahvm5ubZtS6WCxWTqFaLpdmfjsYDDQYDLS9vW1qVDqdVjqdXgnyANWc+yeTSTPQpX4+sfgEjmFvq9XSYrFQr9ez+nHClx+D3keF/vMm2bQVZcF7Yx0JQ+XqdDpKpVIqFotKpVLKZrOWqOLxE+8Rv0oAkg1RKhaLmkwm1oY+6SaTSVNRGf/4ZuAHRX0gDOSIZrNpqmQ2m1WhULCVBNzLGxIzV+iDTCZjii1K5Gg0WlFpGXPck76jzlyTNuMDA/PeE2L+32w21Ww2LabwP7YL+DmIisp4CQgICDgLCBz/gxE4fuD4UuD4geMHjh84/ivk+SetKig0YDQQvspAgSI4LhYL5fN5bW1t6fbt2/epL8+6bBhn+vKRXE9Tlh7muigSkkz57Pf7ymazK8qA//IJZjKZGFHx6iHv5W/AKxBehSgWi0ZaF4uFmQCvQ1TR88nHqy/+yPFKpWLXjKpoD8IHqXAPatt17+d/0eS+7n+0j+9fTwai9YAkkSyiSirXIjF4VYVr+/6N1ttfRzqJI1zDj0cfY3zfRK/jxwzl5/0+qaHW8B6vinm1xytDKIm+TSm3pJUk4K8DOYrFYlYvSTbvfJtG1VKu7xVNFDXuQX28Ukuigyj5D27xeNy2atAGUTJImbwK6okT7/Hjx/upeKJFezFOksmkkcOo+ufrHN324vua/uN+zO3odp51X/Slbw//P1RGYhLxMmomHu1n7zNEPdcpvQEBAQEvKgLHfzgEjh84/mn3Ou3eH9S2697P/wLHDxw/cPyzzfHP/MM/HxRisZOTXKJPzZ9X4nveYLD0ej3F43G1Wi11Oh2dO3dOn/vc53RwcKCvfe1rz7WMvV7PntynUikNBgMVi0Vb5k5CeBQwuTzh4LSkbrernZ0dVatVW0bv9/1LstO2isWiyuWyqQJMQp7ux2IxWwqMEuGVgMViocuXL5vHSLfb1eHhoXq9njqdzn3L130C9IHGT3Lq1Ww2de3aNU2nUx0cHEiS8vm81cEHsWgyJGhxT///6FyJ/s8H62ib+/t51V46WSpPIPXBPloG/zMkbTweq9fr2WlflIXX4gsinahgpVJJ8fiJmaxX6ehL6TgAowqi8EwmE+VyOVMeSaLdbtcUYpZnU/75fG5JyScOSAAEcblcmucFr8efAqAkcy3eS9BHkUskEivqonR8+hYE0htYe/8U7r9YHPumDIdDFQqFFSLMiVr06Xg8VrfbValUsoTm+y+TyWhra8vmKwo2fZpOpzWZTGw7QC6Xs2sNh0NT0emDKAnEQwWCE1W6eC19RvxoNBorvjOMC5RDEi7jxOcW7k2Z+dtsNrNVBX5udDodS8aMXwCx8luHIEwQJMa73+LDnENVbjab6nQ6GgwGK4bpxIter2fjMxaLWb8GBAQEnBUEjv/BCBw/cPzA8QPHDxw/cPxH4fhn+uGftPp0lg7l+6tKBtYBzw2OsU6lUtrc3FQul3ts5e1Jl4397QRNgu+HKRdjgaTU7/eVTqdVLpfNv8ErVVG1b51KER1bvAby4Je2L5dLC9aFQkHL5VLdbtcCOu/1yldUxfDffVk4EQySkc/nzfh2nWIXhVfvHub1jwp//ajq579Hf46CdichLJfL+4iND+bSCWnx3hc+wEb7mO9RtdKXzycSTl7yS+K9yuzf571DII6QFK+u+T6Pkjbew/hYRyij74sqYtw/qsBFVTVfdp/4vULpl8p75RDjYpLhdDo1ksZ7o+Vkznjy5cH9UBz93IuS0ei8pO1pP7xJaFfuCfmOKoS819/LK3WUz38Q8HX3YzHat5TZb81ZZ/5Nm00mEzNGbjabtgWJNvTbFvw9qEPIhwEBAWcNgeM/HALHDxw/isDxA8cPHD9w/HU40w//fIMQAGio6NNkP4leNSyXSw2HQ83nc73//vuqVqv61Kc+pbfeekvb29tKJpM2+Z4HUEPwBNnY2NDly5eVSCS0v7+/drn7w4IJxjX29/ftJK/5fK6NjY2VJd+Mpfl8rnK5bP4cKHXj8dg8H6bTqb2XL4Ijk9O/bmdnx1SaWOzYB4UjxCWZWhANHNQjGqQnk4kODg4Uj8f1jW98Q81mU+fOnTOFwROOqIIHosngtMToX48S48vpCcA6MuMTYDRQRpO6v7cPjqPRSJ1OR4vFQsVi0U5XWywWdioVqhJkjO8oY51OR5PJRFtbW+ZnQb0lmZLkEzXXzmQy6vf7ajQa1g4QNNqce/sxgf8F/hLUy6s+lAHVh/EK0cvn8xoMBur3+xbnEomEyuWytS9jiLHB2PPkQtJKkiZRco/5fK5er2fEnHpC2qkPBDedTiufzyudTqtUKplCLh0rk7xvPB7fN1cgF7S799vxf+92uxYbKBfGyVwXkk/7Ui+Ue8ZLq9UyQkN7pFIpuydzk/vQR14l5pr0Y6fTsQ8U/G08Huvg4ECJREIbGxuWg6STLSaAD0Obm5t2X/qw2+3aNe/cuaNbt27p61//un75l3/ZThiMxY5PMsvlcioWi+Zpgp8I9XhV819AQMDZROD4D4fA8QPHDxw/cPzA8QPHf1ic6Yd/HtEgGlVuXnWQ2Pr9vtrtthaLY0+QfD6vTCZje/afB+grEu9isTDDUfbrR5/4P849mGzxeNyCbKFQsGBG8pJOVCN/X082fbm9quS/oomRpeGYEHOPdWoQeFCCXi6XGo1G6vf7qtfryuVyGg6Hdox4VCF4WJx2z6gyGf37uraJXvdx1Ufff9Kqqhe9p++nqEoGASY5riM60bL615OMpJMPHCiEi8Vi5Vq8z4+JdWrzuvHiP8ig6qw76c0vUY8qd15ROq1NJZlC6bfGcH8IBWXyY5W29PegPXkfJ/vxvgd9QIM4erLo6xlVyXx9ff2lk+0nzHfKRnt5ghads74NfT/5snuVGTLvx/aDlH3qEyVzXJfvxETey8l/fA0GAxtztDtxky8f16LbJwICAgLOCgLHfzACxw8c/2EROH7g+IHjv9oc/0w//PMEwE86P0ACOTgGk2lvb0+5XE7f/d3frUwmo3PnzuljH/uY9vf3dffu3efaXuPx2Dw4IAO5XE7L5VK9Xu9DkQOf3KfTqRqNhiknqIN4I6CW4DnAJCcp4SXA2GPcYfbr1STa3S9nLpfLGo/HlsD9MuJo8iRoUwfvg7BYLNRutzWfz/XVr35VR0dH+vjHP67BYKArV67YCWZeefLtcVoiXNd2JACfSP1Scw+vDn4QEfDq2roy0p60P6oYS5yLxaK9FvVmuVyq3W5ruVxaX6GK0x+cEOXJGV+oc7Q3ahFjh0TnfTl433Q61Wg0WiG1qDSeAJ+WUP02AQK9985Ip9Maj8emJnOqVzT2UT6/XYFx4AkV5cD0utvtWrkWi4UpcdwLMorStFiceJT4NmPezOdzVSoVZbNZ2xrg1Ti8MPxYpJ1RfUulkjY3N23ri3SioHJy23A4vC+Je58Utj5Vq1XN53P1+/0VHw3UM04A45Q+T5golz+VDaDAUrZ4PG4+Qtyb9qOMzE9Oa6MtiQXe7HexWGhvb0/vvvuubt26pf39/ZU5RrtWq1VVKhXt7OyoUCisqJsBAQEBZwmB4z88AscPHD/aHoHjB44fOP4xAsdfxUvx8E9ar1QEUnAC2oPgSlLM5XLa2Ngws+AHPbV/2mByEWBisRPz0Khychq8QhKFD5qYnA6HQzMh9QHRK6T+mgRw/4Sdcvn3S1o5xhw1Ivr0f13Z/TWjv/u/kWQmk4na7bby+bxarZby+byZiZ7mDfKwfezJ93w+X1Ez1l0jWu6Hvc9pZaQvOBae5feMB/oB0sJ7UIVQ5Xy/SFpR87wKFy27r7s3FJZWT37z5ffl5rv3tfF1ok19O3Atlq1H7+OVIj+eouPntJgYJVzz+XzFN4X7ebLKmI+qhlES4vsCsC3DE0Du4/vSq3a+vIlEQtlsVqPRyP5OOfidDxLcg3J5nwy+/BgGnjRxjWg9/L39/I+OcX6PmgdHQZ1pe7YLRfuKsT8YDNTpdNTr9VYIoScIXoll/vPh4DQiHxAQEPAiInD8h0fg+IHjR9viYRA4fuD4geOvtuGrwPHP/MM/Oo8O4MmsnxgfpEy8Klguj/fwHxwcaH9/X3t7e6rVavr+7/9+JZNJ3bx50wbh8wBP3bl/KpVSuVy2YPygJEMfM+FPIzieeIxGI/Ml8EmHJdj4DOTzeUs0TEAf1FAofKD3CZLX9vt9jcdj1et18yVhC4R0QjyidUomk+ZdMRqN7gui0+lU9+7d03g81le+8hXt7u6qVCppa2tLGxsb9y0FplxR4rEOzLHxeKzhcGhtsi6YRwP6h513HHfebrd1dHSkfr+v0Wi0sm0DJdcnA1QfSdrZ2TFPFxQ7+oqk41VB33fz+fGpXvl8XsPhUI1GQ+l0WoVCwcaIJ4QkUvqboI46jDKI2tVoNNTr9Uw1822HqS5eHKPRaIUokGw9UaEf8YFYLBbmm4EihdqdTCatTznRijGfSqVsnjBml8ul8vm8KVXT6dT8QIrFoubzYx8TEI/HVSwWzbNEkqrV6srY8NtiYrGYqWzL5dKSGW1JMsazBE+PXC63Mqd5L23n1fN4PK5qtapkMmlxBbWYsVooFMx7xSdftvGgTjNmUAkZi35e0D+DwWAlF9FfeH2wOoA2QW2m7MPhUK1WS3t7e7p7965t6eL6UYLMOOdDX7FYND+UgICAgLOCwPEfDYHjB47Pffx3f68oAscPHD9w/FeP45/5h3/RIPSkg9PLBB8cOREsk8loZ2dH5XJ57dPyZ10+/+SaAOiNMx8EPwZOUwe5PokePw2ORGeCS8dqhl+efRrZ9AlpHSHhGih4tD8+AB9EeAgmPnFF7z8ajdTr9XR0dKR0Oq1er6disXifEvA4iq9Xs3x5o4pOVD39sPPPLw3v9XqWoLjHacqv374QVbR80vbK2DrFZLk8XkqfSqU0Go0sGXk1R7r/ZCivxKKYeQLlg/d8PrfEwD0pTzTg0+b+nlEV0yuKlJ2x5+vpT7zy45ex7scm4y6ZTBp5JkF6ldJ/KIM0+bLkcjlJJ1sLPCnwRBtig7FzLBaz9qCd/IeH6L1jsZh5YbBNhDEBwYheh7JyPW/a7a+7joR6YrFuvFN2r+Bx7+Xy5KRATMSjHw4Y/3zRfh7R2O3JVyaTUSqVWlnpEBAQEPCiI3D8R0Pg+IHjB44fOL4UOH7g+A/GmX74J50sr2UCSPf7gdDYjxMUXzbwhPr27dv69re/rQsXLujTn/603nnnHVt26/fJP0ugopAMYrGYCoXCylP1B72XQE7QIWitIwdMkna7rdFopGazqdu3b2tra0vnzp1TrVYzRY0ycQ+/1JjTpVAIpOOn/PF43JQelhijcHU6HfX7ffNNkFaX/EcTKvdOJpMqlUpaLBYrp5ERqHu9nq5du6Z2u62rV6/aNgHKGg040d9PA0khn89bcF5HIr1iuq5/HoUkoGB1u10dHR3p7t27ymazqlQqK68jeUCCer2etStKrD9hDX8E/B5Y5k/whABQbzw5WGbNeKDNo3VKJpPmUYLi1Gw2FY/HVSqVlEgkNBwOTemTjhOEV7G63e7KCXGMiel0aooUiZexPBqNVmIdZUQ1RTmDtKAAVqtVpVIp2xaDEsv88KeR0Q7nz59Xt9vV/v6+jU1PoP0JWtJxzInH49rY2FA6nValUrH2k2Svo88oI31GP9HPEDQUSe6L2bkvD/2ayWTs/+Px2MrCffr9vmazmbLZrJU9l8uZaTj34O/L5bFHUZQse6JFu1WrVcViMfML8qSG+9PezNNkMmnj5P3339e3vvUtXbt2TQcHBxoOh9ZetAPG7oVCQcViUdVqVeVy2foiPPwLCAg4iwgc/9EQOH7g+NwvcPzA8QPHDxx/Hc70wz//xDoa6Ph/wCpYotzpdFSv17Wzs6NaraZSqWRLgZ8XfKCj7whg6/r3tGtElarT1COUDQIrSaBcLls7EJCj1yBYz+dzM5aVTkgAP3tFjwDHtotosowqPID3EjSZ4F7JSSaTmkwmarVaSiQSdjJY1MNCup8EPEy7cg+v3pxW9g87D2lbxqo/gh7Vxi/D9+3ikydqmB8DKFGQX9oyk8lYG0W3GXl1kWuRDDyx4/8+0VEm7oFBMCqdJDvRCeIxHA7N9NgnS69qoVxzfz9nPGnj5yhh5m8ca8+1vakvfUEbQ4iz2ezKUnoSNX3jl/PTj7Ql7/fKY3S+Mofob9R21LzlcmleFyS9XC5n2xU88Y+2g293yuoVOwgAfx8MBprNZtan/I9tEdHx7T88eKUxHo+vxFZPor3HCvdg7DCn9/b21Gw2NRwO71NAGQ+QIJRAVlR49TUgICDgrCBw/EdH4Pir9wocP3B8KXD8wPEDx/c40w//pJMlnev2YksnT5rXLfl9FUGiuHHjhqbTqWq1mj71qU+pVCrp8uXLOjg4sH3qzxoEIdQgH9AICA/rVUJ/r1s27V/jl+smEgkdHR1pOp2q1WppNBqpWCxqa2trpSwEOkkrXgtc0y89l1YDtZ/8yWTSfifAriNmBBo8GDx54gslp16vazqd6t1339VoNNJnPvMZVSqVlYRFHRaLhREvrkNZvDoZTZDriMGDgs7DBiT6itOdut2unUyVz+dt24bvW4Iq9YnH4xYYCa4kFV8eykTbosTwPggGfSxJ5XJ5pV08SQCz2UztdnulrWhX/DII7rTjYDDQaDQyRWo+Pz6ZazQaaTweG2nx5LLf71t5/TgmEbC9hb7FZ4LxBQnxxBE1G6+Q6XSqTCZjJ1mRsKhHtVqVJLsHBNorrbRJLBYzP4p8Pm+KnR8fvs0gGlyX69A2+XzeiD39C9lmrngSQNlR0zudjrWfV1lHo5GRHt4LccJHJTpu6GNPSEnQ8Xhcg8HACJEk60vvfSTJVGLa4+bNm9rd3dXbb7+ta9euqV6vr/gH0c+lUsm2dW1tbalSqahWq6lSqahYLBoRW6fWBwQEBLzICBz/0RA4fuD4geMHjh84fuD4D8KZf/gXVZGi5CCsdlgFA5Jlyp1OR8vlUplMRuVyWb1e71Ql7WnDq4Lj8die/EvHk+BRlrSuW64dvZdPhkzu4XBogT+bzdpybZIN5IVgxNjzKhHKjVesPQge0aX6D6qfvy+/+/8Bll/X63Xb4jGdTleWaHMtCMw6lWud4u7Vrqcxr3xQ5yh2Aj/qj0/w0fd6IoOqQ5uuiwtRpZT3SSdJiPf4JBw9mS6q7rKdxX9YIXF4Usb9vcpD/5I8WApP/3hywNH1vgyMKb64LkqbP4oeRQq1MJVK2f0hEV6BlE48WpbL4+0VnhCjdkaVWL+9gLp4ohGNNVGFLkqqY7GYqYC0ddQQ2M8TTzhoV7aE+K1kqMVRnx4IvI8XXDs6/ogLkAPacrFY3EewWJHAHIsqls1mUwcHBzo4OFC9XjeF0teHcVksFlUqlczMGCLNvAkr/wICAs4iAsd/NASOf3KvwPEDxweB4weOHzj+CV6Kh3/RjqejPVkIOAbt1W63NZ1OdXh4qEajoWw2q+/6ru+SJN2+fftUheppgv6aTCbq9Xo2yDOZjD1Rx/fgYa4TncjrXuMnGAGAJf6DwUCVSkW9Xk+lUkmXLl2yQBYNqn6MMeFJZD7hc7KU34JBEvogxfO0oOQT3nQ61WAw0M2bNzUYDHT9+nVJ0ptvvmn+Bz6Y+2tE5wv1is6fp0UKhsOhxuOxms2mms2mbQVAYSJwz2azFU8EXy6UpGg9SSAESZKq7//lcmnjgO0IBHkMakmKJE6u5a8RXfrNeKI9SRB+qTgkhDHA8vXJZGJbCegTxh/lgMT69vAk25NKTwQpv3Ss1KXTaTPsxZPEE2iuB3FH7YIw89Xr9VYMvFERk8njU+Tw8KBPfR968kMbQ7Iw0k4kEisnkuFh4tVhFELmnv/wCCA5EDIIfTweN+JAX/hy+nlPmT1xRj0sFotGAGgXrgfZ9CSWccIJce+8846uX7+u3d3dla0JEKZyuayNjQ2dP39eV65cUbFY1Pb2tkqlkiqVivL5vMUgxnVAQEDAWULg+I+GwPFXXxM4/sk1AscPHD9w/MDxpZfo4R9goke3AARycILlcmlqUbfb1WAwUDqd1s7Ojvb29kxpeB7eIEzmyWRiS1nZ9/8o5XlYVTNKKknQs9nMjgLn71tbWyskgEDIROeeBCcCjlcYEolj805vFMxS6YdZsntavXzQmkwmajabkqTDw0NVq1VduXLlviQfvVZUNXtWyjrtSMLHqwbCxBggWaIaeg8KyumX4Ps6Rkkcqhl9R1D3ai3/8youfUtSITF6xcnfl3qRoCgzRIN7QA6i44Zy+3L4/vDtI2nl/lzLJ236FSLilS+2CTDeqSNkiPIxR1DuOcmK+3sDYUk2viF5XsGLwpfXk+VUKmWEO+pdEl0ZQt25F30A8aP+UdLjlVqu4+MDY8Srk76v6X8SOPfib3yoyWazK33p/Y4Wi4W63a7q9br29/d17949dTqdFTWXMZTL5VStVu2rUCiYMojPi7/Po2wJCAgICHgREDj+oyNw/BMEjn9/W6z7+WkicPzA8X0fBo7//Dn+mX/4558i+070S5wDKbgfTIxOp2Nk4FOf+pT6/b6+/e1v2wlZD5tgnyTwgkDhSaVSdnpQq9V6YJketbw+KRE4WPpNYKzX60akMpmMqtWqnWgUHW/z+VyNRkOStLW1ZYqJpBWVC1WIYCCdmKgyph8WBAuCKspmMpnUu+++q/l8rkuXLpm3gz/Vap3R8rOaL7QZfhi3bt3S7u6uOp2O2u22SqWSyuWyUqmUESkSrFf0fDIhgJJ08/m8KXNe9eH/0S0ZkNDlcqnxeGxqGeVknPjES5k8+aN+vIZ7JpPHJ6px0pP3rWAZud/64etHEkEtpOxeYSOpszUkm83aWMMwWpKRbq84QnIhr/iDQFzwwUmn07ZNg/tRVq+YsnWCcc18Ojo6Uq/X04ULF+x0OeDVR+rJ9fDqoI29+utNvZPJpMrlsuLxuAqFwsq4oM38sn9PLoh5vJa/c0/uRzswd5hL9OV4PFa9Xre2ZE5yHU88ueZgMFCv19ONGzd0+/Zt3bhxQ7u7u+aJQ/9ms1mVSiVVq1XVajXzV/Hqn7+HJCPTAQEBAWcJgeM/HgLHP3l94PiB43PtwPEDxw8c/yV5+OcHk3S/mWnA/WBCDAYDNZtNXbx4UZcvX9atW7e0ubn50Ka7TwOoQwzkROL46G2W7z5pMH4gIRwZLh0ni16vZ94UhUJBsVjMnrpHT6eazWY2kTn2nTITLLk2E5dgwu+PQgqATyAEpmQyqb29PaVSKbXbbW1ubtqx4E9zGyAJ8kF95ZWY4XCoXq+n/f19vf/++xoMBhoOh4rFYqpUKhZcvUpE2f09+IDA33mfJEsMXvWjvekDr7pEySKJKao4eoLgkznl8W3B8m/GTbfbXbmmT6DRa/nXSLLERh15L8mJMYgnCdsVKBP9z1jwaiqqE/4gPrZ6dTSqRPpECgkgOTM25/O52u22xuOxtra27hsTvoz0N8ok2wAgUF7NRQ0fDAZmhMxcJsnznTL7+cIX96Nd/AdMP5f5nfFDu0SVU9+2KJS+T7yyyDaL/f193bx5U/v7+2o0GivEEUKSz+dVKBRUKBRMZVxXJq7vlemAgICAs4LA8R8PgeOfIHD8J4vA8QPHDxz/bHP8M//wDzCoCQR0EAGAwfo8VK4XGYeHh/r2t7+tfD6vT3/60zp//rzeeOMNSdL777//XNoMv4HRaKROpyNJZmzrA9yTQJRAstQZpcUvxfZKIYmDiSqdeDh0Oh0tFgvt7++vKIy9Xs+WvA8GAzvZqlqtKplMqtVqKZPJqN/vq9frWdmk+5Ns9O/egBXVYzgc6vr162q1WvrYxz6myWSij3/849rc3LQ6gUchXNz7NNX9tGt5BXY+n9upc++//74ODg509+5dHRwcmJ8BiSaasFnq7fuGgEh7exWLhEwi9AqdTzos5U6lUioUCtrZ2THfEIIsfZlIJCxJUadOp7MybqJqF8nOq1kkae6bSCTMkNafaDYcDi3RpdNpFQoFa+vFYmHmwPl8XpIs3g2HwxX1lyQDmYWAkUzZasEpZJPJROPx2MpNgkomkyqVSuY/Q+Ij5lI22oMtB6iitKknVqikw+Fw5b6SrO6oY8xR+iWfzxthicdPTt/idC3Gi1fy4vETLxZPGqgLbcX/PDHw/eqJEFstfJ/TZsVi0X5HMUVVnc1mqtfrOjw81O7urnZ3d9Xr9Va2F6Hql0ollUqlFYKRzWZVKBRULpftu1d2n1S8DAgICHgeCBz/8RA4fuD4667/QW3G98DxA8cPHP/l4/gvxcM/OoBJFo/HV5Zf8je/dDvgGM1mU++9954+/vGPq1gsamNjQ5cuXVK73V4JzM8STJzRaKR+v28BkmDyqAOdILwOPslJJycgcT+vtES/ut3ufcvLF4uF+v2+BbRkMqnRaLSisvZ6PTNMxRwVBZGysHXgtOTr60ab8V4SgCTduXNHrVZL169fVzKZ1MWLF1WtVlfa5FGVVj/fvDLzQaA+KKMHBwfa39/XN77xDd26dUutVkvdbldvvPGGtre37yMGklbIgV9Szd857p75DxkgERIL+BtJeDKZmAfNfD5XLpez7QS0LUl4sVgYSQUo7H5Ztm8vXhNt68ViYWWE3EA0ONFpOBzaEn+Sci6Xs2SECsy9vSrlDY1jsdiKauXHiU/4sVjsvnaJkhwS/WAwMCLM/zyJ4pqQArZ3MGd8O4zHYw2HQyMGXomMxWK2lcUrjiR7tj6Mx2Mtl8d+RyReyuXHEP0ZVej9OPUxI0qkeb9XMaNj1c8TSTaeut3uCtmgnVutlg4PD3V4eKijo6P7Tv7CSLxQKKhYLFqdUYaJJaiFfitNtA8DAgICzgoCx398BI4fOH7g+IHjB44fOL7HS/HwT5I9LfZEQFo1e+XnQAxO0G63devWLe3v76vVammxWGhjY0PFYtF8EPAQeFYgcI3HY3W7XeVyOeVyOVMUCCAPS1qik/VBYGkxEy6bzSqbzZqZJ8oDk9EHDNQu3kvyYWk5qgHEQjpOVLVaTRcvXtTW1pb6/b7u3bunVCqlfr+vdrt9n3IprRqRrhvTqBUQjPfff1+S9JGPfMSIiFev/PLhR0W0bP7vkqzezWZTw+FQd+7cUbvd1jvvvKP9/X3t7e2p1Wopn8+rVqtpc3PTiAFtSsLxSc4nONSRXC5nPhLEBF4ryQgD5ep2u5Y8IYMoR74dvXrFvUgwfPfJ16tMUUAUUXpQlYhbUbNcXxavVPF/lrKjos/nJ6fQoWR5TwtIlPeYAIxLVHnfxhDy2WxmZD2Xy6lcLpsS69uLNoFscG/eG11iD6JbEKKkF/LkCSEECWIU3VLhy8L7o33E75lMxv4GQfL3ZRxwLZI7Civ1oo4kcEgZHzRQPQ8PD9Xr9XTt2jXdu3dP9XrdCI7f+uJjCO3MOCfvEXOy2az9zLiJEpuAgICAs4LA8R8PgeOvInD8R0fg+IHjB47/cnH8l+bhH4OBJ/5+wHlSELCKTqej4XB4HzGoVCr2BP5ZEwMGPcSAfovH42YeysR5VJL3QcSQycvE98SAYM53jnNnohKcuA/eGyw390vVCcrpdFqbm5u6cuWK3TuXy2k0Guno6Ejdbncl0D0oAfv/kzxY8n779m3N53Pt7++v+IIwL57G/KB/CK4QgK9+9ava3d3V22+/rb29PWvbj370o7pw4YI2Nze1tbVl5q9+GT3GqgTj8Xi8kqyr1aoZznrSQJtMJpMVtarf72s4HKpSqRgx8KeLRdUu2pokJ514dPA7/biufyStKFaZTEaDwcA8KKiXrzP9SoDnf3x5dZDXR1VJEi2mwYxDfvdthOrpSZQnGH7rhFcxSXTEC64L+SCJemLg6+bvT7KLjmc/Vj2pgZRAHClD9PVc07eVvz4kxpM8iAFby6gb6m8mkzEixThMpVIql8vWTqwWYOwul0v1+32NRiPdvXtX9Xpd165d0+7urlqtlpWfLVD0o+9/YiTjmXuhEFI+/h8e/gUEBJxVBI7/eAgcfxWB4z85BI5/f/9IgeMHjv/ic/yX4uEfjeQ72g8C6YQgPMpS8lcBtFu329X+/r4kqVar2VcikdBwOHzmSip9OhqNlE6nTbnZ3Nw0o2ASw6Mogw9bDyZdIpG4z+cBZYBgXq1WFY/HTe1ByUNhQqVhGXcsduxfUC6XlclkbAlvqVRSsVhUtVrV+fPndf36dUnHx6c3Go0HJhtfP68mEUwODw81m830zW9+U5PJRJ/+9Kd18eJFC9L+2gROH1DWKZLr7k/bLZfHy7Ink4n29vbU6/X09ttvq16v6+tf/7r29/dNDalWqyqXy7p8+bKuXLmijY0NM3ElEEMAOCmLYI0RKskETwkCvf9QsO6L63mDZBKAV7akE2KB/wXxBYJHAkBNGwwGkrTiJ0J/SCdEgnv4pM52FA+vlqEmQlBQsrxaFu2n5XJparrffuDHk1ccaX+2SJAAUaIw6/Zt5+vH/VGkcrmceVRECQl9wcldEHCu5fsAckK/k4gZF/7/vM8nWr68UkfC5XevJvs5Rb9Er71cLpXP540YMf4TiYTFKL8dYzqdqt1uq9fr6Tvf+Y729vZ0+/ZttVotJZNJmwOsKvDbM4bDoRqNhgqFgqrV6kobQC75IMKKBN+WAQEBAWcJgeM/PgLHX4/A8QPHDxw/cPxXleO/FA//pJOlrNGn9k9T9XgZwGBttVq6c+eOKVTb29t2Us/R0dEzJwbScZ8OBgOlUimNRiNls1lduHBB3W5XrVbLfAMetmwP8zofzLy6k8/ntbm5acGEAJBKpbS1taVkMqnBYKDxeKx+v2/Lpklcs9nJyUn4KOTz+ZUjva9cuaJLly7pIx/5iLrdrv7v//2/ajQaOjg4ULvdliRLDNG6EMSidaU+u7u7ajab+spXvqKjoyNVKhUz3fVJmHni1R+2hvgg7u8XLQvv7Xa7GgwGevfdd1Wv1/Wrv/qr2t/f17e+9S0dHR3Zta5cuaIrV67o9ddf15tvvmleBz7JDAYDU2D8qV4osyigeCjQTv4DwTpFCSNn/CoIsKiZvFaSJf16va5MJmNHzUvHCadYLGo6nWp/f9/KIsnMcGmr6BYDaVVBQ22LqjgEetRqyClbIZbL5QoZ8WXn/c1mU5PJRMVi0YgMZaF8PhmyvSKXy5k6zn0xKMZwNvrBKx4/Nrrt9XpGhtlGQJv4mMzfaZdut2tzzCuuPvH7bQb4zJBI/ZJ4PEuYj9lsVolEwkgc6jn1I/mTWAFEnuROGyUSCRUKBY1GI/V6vZWtEMwrT5ym06mazaYR5Zs3b6rZbGo8HuvSpUuqVqva3NxUqVQy5frg4ECHh4fq9/u20qBYLNr4wzCZLQc+XkR/DggICDhLCBz/8RA4/ioCxw8cP3D8wPFfdY7/0jz8k1ZPZWHS8+TbD/6AVSyXS/V6Pe3t7ZkBabVa1YULF7RYLHTz5s2VJ+PPslxMQE40Qg3haHEUyydVtnWKGvcgWHjlCNWUYJ5KpVQqlTSfzy3ZMCFRFBKJhC39T6fTqlQqymazZkBL4P/oRz+q7//+79f169ct4BwdHd2n4PmfvcoTVTAl6d69e5pOp/rGN76h8Xis119/XefPn1exWLTtFtHkGb3Puj4iaU2nU9XrdQ2HQ927d0/dbldf//rX1Wg0dP36dXU6HY1GI8XjcfOduXz5si5duqRKpbLi14BSRJJNp9OaTqcajUZmVp3P51cSP20bTVLR+vA3kor3GZFOlC7UUUgDZfMKEu8hsQCf7B/0wSTqJ0K7Euxns5klON8u1M8rfJ7UMF98gmMbCGOYunCNaDlQsVCjJFky8srrcrk05RYSRHvTR7Qp9fNkk/5gzM7nc3W7XR0dHa14PHkPFk98qB/JmC/vaYJSx9ykHRkzyWTSVMXoNhzfL8xntvv0+/0VE2Z/GiVlo71ms+MTv7rdrm7cuKGjoyO1Wi0zl0YR3NraUq1WszkpnWzzoN70oT8hDnXatxNqNjEgICAg4CwicPzHQ+D4q/eUAscPHD9wfClwfF8uP94ZIy8rx39pHv4xQXkqzEDyE5iBHHA/Wq2Wbty4oa2tLZVKJZ0/f15vvfWWlsulvvGNb6woNM8K9BeJgCXDiUTCluG32+2VpdJPCowTgj3+CBzBjkIlHZ/sxTHcmUxG1WpVkkx58NsAksmkzp8/r0wmY5P5/PnzdrqPV5pYJv+rv/qrarVapuz5oBpNNn58e5LAUu5r167pzp07kqT33ntP3/d936ePf/zjunr1qkqlkr3XJ+d1Cc2TbdSYbrerfr+vt99+W61WS9/+9rfVbDb1ta99TY1GY8X3IplM6sqVK9rZ2dF3fdd36eLFi6ZUkdRJ2vjCoA5DkAiCPqGhvBA8KWM06fG7X87utz+wHJvj6BeLhX3Q4IMHvjAkpOjpVT55+S0B0faMkhD+T2KnDnhu8KEHsurr6k9Cm8/nlpTZJoHaSvmYY34FhbSqpkIKIGK1Wk3j8Vi9Xs+uxT0hAr5NMcPFAySqdgJPDGazmY6OjvT+++/b30mYlH3dkn9URRI8HhzELk7go11yuZwRD7YYsRrB+4D4LQKM4XQ6rdFopG63u+K7kcvltFgsbNyQkFFYb9++rWazqa9+9at2Gl6/31epVLKVDxcuXFClUrHy0be0E2X2/h/+gwUECYUQtTwgICDgLCJw/A+HwPFXETh+4PiB4weO/6py/Jfm4Z908sSWJZrJZNI650FP5QOkfr+vvb097e7uand3V/1+33waosuznyW8MtfpdHR4eGiThGQ6Ho81GAxWPByedBl8/RlbkkydQTmJjjGIqd9ewOu5Xr/ft20CqDlM+FqtpkuXLunTn/60CoWCdnd37Vj4h1W6vTKFx8r+/r4Wi4U2NzetbrPZzLxJeF/0HpSd+k4mE7XbbY1GIx0cHKjb7ertt99Wu93WjRs31G63jRSgvJTLZeXzeZ0/f95OQNvY2FhRXvx32gOSJcmSDJ4LGPhSXr6iJrnek8H/DhHwwd+rSVw3kUgol8tJksUZn/C8Qh31vIjWi+XbqJJ43PgxB5HwiZA+8v3mPSeoE4QQMuNJiW8j/k7i8ePGK3JeMecaEAOIMqSFdoR0cJ11PiWArRzdbleNRkP9ft/IFqQGhRRC4Jfv+34lMfJ3r9p7chIdL8xLFEP+H1VJaRuUVtoYcuDV0uiHi729PTUaDdXrdbVaLVNlS6WSyuWyqtWqKpWKpGPj6H6/r36/b1sQIEYQAr4Yh76N2TbVarVsW1FAQEDAWUTg+I+PwPEfXIbA8bVS9sDxA8cPHP/l5fgvzcM/JhEGlf4kKzoyukw44ATNZlPf+c53VCqV9NprrymVSmlnZ0eNRsOWAI9Go+eiqk6nU7VaLVtynMvlTFkbj8caDoe2HD26f/9JgWThvQZ46k4w6fV6lqQIFJJMNcvlcvft1U8kEuYDUKvVdO7cOVMTURpJPl/96lf13nvvqdls2glaH6R0e4UJdWgymejdd9/VrVu3NBqNdOvWLdXrdTWbTV25ckWXL182YuJBIsLkt9vtqtfr6ebNm+p0Orp27Zra7bbefvttdbtd3blzR8Ph0MYN5sc7Ozuq1Wp66623dPXqVV28eFGbm5vqdDrq9/srZIQAjWJI0C6Xy9bmkA3mt1eFvDonacXvgSXd8/lcpVLJVF76OJp0+L1UKtk2FfwtosQgFoupUCisvNcTBP6PihOPx9VqtWz8+kRFG6ACsWUHtWswGKjb7a6sfqD98OLwp5vFYrEVQ1/vMeM/QJFI/aldfixwD5I+9YAsD4dDxWIxG88Qoej2Cx+7p9OpDg8PdffuXTUaDQ2HQ/vKZDLa3Nw05dG3D22PT0g2m9V8PrftOpAWnzyZ1/Q5248g516p5fXeywXgzcK9o+8fDofq9/va3d1Vp9PRt771LbVaLd26dUudTsfm2s7Ojra3t3Xx4kVtb2+bD1Cr1TKiRHujApbLZfvK5/M2ThKJhJH2wWCg3d3d8PAvICDgzCJw/A+HwPEfjMDxA8cPHH91LASOf4yXkeO/NA//pFX/CJaIsqT3YYLoqwyUt2azqbt372pzc1PValWFQkHlclmLxULtdvuJL71/GHhVrtfr2d9TqeNTuLLZrLrdrqSTifs0ygC8esAyX08SSAbeBwBFDiVNkgVSH/S2t7fNJ4P7ptNpbWxs6Pz587p69aqy2ax5CHzQHv+oGk5bojAcHR1ZwOz3+6rX63bKkD/GnHnFUvDRaKRms6ler6dbt26p2+3q1q1b6vV6Ojg4sGA+nU4tIVSrVRWLRV24cEGbm5sql8tGlqKKGT/TdizHp9x+6T9t781lCfQkDn+Km1dJ/UqC6XRqy+S9r1AikTCiIMnUScrntwH4DyA+wfv/814UQb90Pnpv+jBaXogPijieNajVtJ8fj9SFOqxrc/+7b2NICQSDdp/P5xoMBitkgp+9yhqdl5SNa0XfSxn5cMdc63a7isViNj94D/XxRJh+py+iSqsnbVHFMLo1QpK1Je9njFEOXkdZRqORxuOxOp2Out2u7t69q3a7rcPDQzM6lmRGy5VKRZVKxcZbv99Xt9tVt9tVu91e2aLAmPHjRVr1HGI8QFaC519AQMBZRuD4j4/A8T+4DCBw/MDxA8cPHP9l5vgv3cM/JjAKDaemnDYJAo6BX8Tt27f1//7f/9OnPvUpffrTn9bW1pYuXbqkZDJpy/Gfh7K6WCxMjSLh5nI5bW9vazgcqtVq2QR4WuUjqHB9Tinqdru2nN4vnWbc+SXfqGkY4vqgT3KIxWLa2dkxFTKbzeq1117TYrEwc+C7d+8qFouZ4hZddg4IWH55/3K5tEBx48YN3bp1S2+//bby+byuXr2q119/XTs7O7p69aotO8b3oN/v6+joSL1eT7u7u+r1erpz544RBZ8Alsvj5eDb29sqFAq6cuWKyuWyPvOZz+j8+fPa2NgwVcwvY5dOTjZj2T1L4KfTqbUTpAqVhKRH/XivdLxKIJVKqdfraT6frxg6TyYTjUajlcQwHo9tu0HUYBZlF7LKOCARkpQgJXyH3PDebDarYrFor0d94j4+CZPwIQVsH+l0OhoMBmo0Gkomk7aUnHYgcZC0UMV8Uo4SR0l2bwiVX9Lvtyeg4rEtgPfh3cM88WWhT5irfom/vzZEySva9+7d02KxULVatb/7LTqeJEpSqVSyDxQQP17niSbKLoSLue63DniiCVlh3OIxwhidTCZqNpvq9/umcP7Kr/yKWq2WDg8P7QNrLBazD2GXL1/W9va2lstjc/ZGo6H9/X3t7e1pf3/f2p62xYOG8btYLMznhNfmcjmNRiPbWhAQEBBwVhE4/uMjcPwPRuD4geMHjh84/qvA8V+qh3+SVoJ2IpEwNRAEYnA6GNT9ft8STiaT0dbWlsbjsQWU57mtguXeKJTZbFaSbAlwr9dbUWKeFkgKGNXyxN0HJQKMV5QINP5kJ/6P4e/m5qYpBn45ey6XU61WM7UWlcADAuDL6ckMv/s6LBYLMwslyA8GA1tuDzFgXLTbbQ2HQ9XrdSMMBCivRGB2XKvVVCqVtLW1ZcpHsVhUNptdUcV8QEOR8oqqV3R8/ag3CcwvcffX4DrT6dS2O3AvCAL9hwrlVaOoEkk56IcoOeMe0dUI+GV4wuHHBB4e69RcT478agdPLmgHvy2FdiDxMRZRj6L34z3Rpft+2wEKavT/XomkTJ6U8nev3Po6JpNJ5XK5lf/7/ocYoarSB55EMCaoI9sUIJvrxgjwqi/97YmCVwlpx8ViYR8EZrOZ+v2+9vf31e12tbu7q1arZcSa7Rh40OADgnqOmkjCZ2wwNiGwjGfm5mAw0GAwMKJFbMIr6XnG7YCAgIAngcDxHx+B4z88AscPHD9w/MDxaceXjeO/dA//8AvwppoBD4/hcKijoyO1223NZjMVi0V96lOfUjqd1q/92q+tLHV/XhgMBrp+/bpKpZIpbhsbG8pms/bk+2mqg9JxUBgOhxqPxxqPx0qn09re3lYmk1GpVFpRd2gvlKt8Pr+iEk4mEw0GA924cUOtVkuZTEYf/ehHVSgUVk7nKpfLunr1qkajkXZ2dhSLxXR0dHRfPT05IBj64OZB4KOM7XZb169fN48CAivqF0HUL/P2wRWFLpPJ6Pz588rn8/rYxz6mSqWiy5cvq1Qq6dKlS2Yy7QOeP62KIInSOxgMVhQa79Xgl+pzbDr1JR5Qb+8tgZJHguv1ekZm6Fef5HO5nLUXyWa5XJrRcblcXlEBS6WS9ZFXj4rFop0ER1KNx09MfqkvdY1uL+D/zEVULcYlfSCdJEySdqfTkSRTjyDUfrwyHmaz2Yp6Sh3wvfAeI6hklI+6+vZg/FBnjGp5PXM5m81qa2trJRFyKhtJ8N69e3YqGWqeVy65h/cpmc/ndnIg14T4sK0H9RaflHVzC+JIuzF2OaVPkg4PD/XLv/zLarVaunnzpobDoQ4ODqy+sVhM29vbKhaLeu2111Sr1WwLDttu8NtJJBJWT9RHvGv6/b59oJCk7e1tq9tgMNDNmzc1GAxWfF8CAgICzioCx/9wCBz/4RA4fuD4geMHjv+ycvz15zE/AP/9v/93/c7f+Tt18eJFxWIx/ct/+S/va7h1X3/jb/wNe83rr79+3///6l/9q49alFPhg1XAo4GnzIPBwExqOZmGiRtVD541eALP6WD4ERBEUF2eNrzSQrDm1B5/MplPpD7AMj4TiWPfA9S5ZrOp/f19a3+CfywWs/qxVN+rFB9U1g+qB0GfY997vd5KgMJ3AkITNV+mLBjk1mo1bW9va3NzU5ubmyoWi8rn8yueBX4JOHUioaDEUT/K6FXN6Nc6fwb/Wq+qeKKBH4jvo2gb0W+UzRuvevWLZBSNQd67Ilo23utJB2oT/0fRJCl55ZL6+r6UjskoJECSvYdx59/nl7ivI9WUxbcb9ZK08l7fV3z3Kp9vT9T1qLKcTqeNwPF7LpdTOp1eaRPajfHCsn9fR68aQyTYNhJVHoHPTyTl6Hik7IPBQO12W/V6Xbu7u9rb29PR0ZHq9br5gfgPCMViURsbG9rc3FSpVDLTb39dysMWgHw+v+KfQxtPp1M7PW13d1f7+/tqNBpqNptqt9v2hWdSQEBAwDqcBX4vBY7/YRA4/sMjcPzA8QPHDxz/ZeT4j7zyr9/v6zOf+Yz+yB/5I/pdv+t33fd/nk6Cf/tv/63+6B/9o/riF7+48ve/9Jf+kv7YH/tj9rtXPwKeH8bjsZrNpm7evKmvfOUrunjxoj7zmc9oNBqpXC6bGvY8SddisbDTv9577z3lcjnt7OwonU6rVCqZguCTyNMAgZ8kiTLRbreVTqd18eJFU2ckmRpAIGdi5/N5VSoVW25/7do1JZNJfeQjH7El+cyPdDptJ0GNRiMzS40moejy9Ggw93WIvp6gs079JUjyWgKnT+61Wk2VSkXf/d3frc3NTb322msqFApGCAjubAcg8KN04JVAkEdhWkcMfHD05cabwxOGxeLYR0I6OSbe9x/qFW3hf2bMpVIpI2RsJWAJP/4OGNV6RY72iSZv7un7I5PJqFwu2xJvrwbiUZJOp42M0qYQZsZYNpvVpUuXFIvFdOfOHdv2AblB3VosFuYnQZ9Qbu/FwZYJxhz1ZjzwO1tiUA+jfcR4JBl7dT3qeUE/zudzGyvT6VSj0cjUPJREP4a8YkcfS7J2YusQvhqQO8YLY5qyMl49gfakgKX/3W5Xt2/fVqvV0rVr18yriDGcTqd14cIFFYtFfeITn1C1WlWtVlMmk7GYFf3wUK1WVS6XbYzwwQ1Vvd/v6+bNm9rf39edO3dUKBS0s7NjW3wGg4Hu3r2r4XB4fxALCAgI+P8j8PuXH4HjPzwCxw8cP3D8wPFfRo7/yA//fuRHfkQ/8iM/cur/d3Z2Vn7/V//qX+kHfuAH9Oabb678vVQq3ffagOcPBj3mrtVq1SZcPp+3Cfm8QbCnPCxfRjHg9CqvWj2L8hCE+O6VL+CXqS8Wq0fNS8dbHg4PD5XP57W1tWVBYTgcriwtJ5itUwWjyYa/+eXx0ddFX3/aNT0JYQl1InF8zHs2mzUVGe+SUqlkS9alEx8Kn8T9kvRoAiHAE4z9/7wK5AmAT04kFpKFr8M6Fcsv04+qjp6Y+KS3XC6NGHKP0zwYUBzx9UC18gTPEwnf/tG29z/TTrQr7Ug70c7RPvWeHz7Rr1O1vcJG+Xyb+Ot5VZD6SVoZ7/QZX7FYzJI7Ywri6BV/T65RSyWtJG/6MtpGvu08+cUbxY/TqLrJaXisSMBzo9Pp6ODgQN1u1076YssD187n8zY/vB+On4NenfSEJJvNWt/jP8P/Pcn1p/WhFvb7fTMmDggICDgNgd+//Agc/8OVJ3D8wPEDxw8c/6xz/Kfq+be/v69/82/+jX7u537uvv/91b/6V/WzP/uzunr1qn7f7/t9+smf/EmbzFHwxBiwpz3gyYOn/Y1GQ9/5zneUyWS0XC6Vz+f12muvKZPJaG9v74Xwj5rP52ZEy0Qrl8taLo8NVTn5ySeaJw2fmH2ASyaTOjo6Ujabtaf+BO5+v79yJPdwOLTAl8lk1Gq11Ol09P777+vXfu3X9Prrr+tzn/ucJNmyaZYnr1MzfAD0S+QpbzT4+QC47jWAvxHoUadqtZqy2ax2dnZULBb1+uuvq1wu66233lK5XNbW1tbKiWkEO4xR8cbgHpAqnwxKpZIdi+63ClSrVUtEBHoUMcayVzj9aVwobSi6PnGRJLxfBe3DvSE3eHeQwDgBy5tAU775fG6vp5wkP8YSCTKVSpmK5RMU2xGWy5PtB7w/k8loPB7r4OBAo9FIvV7PlqBnMhlLbpBp6gsJInkNBgONRiNbmo4qSD0SiYSKxaIZ8zLmIeexWMxWD1Bm2i5KjLl2r9fTZDKxxMkWkul0aoosX5lMZmUrzmg0UjabtZO0SMjeeNlvQ6H9UMqKxeKKChxVb/GR6XQ6Nj8PDg40HA7VbrfVaDR048YN9ft91et121qTSCTM6PfSpUt2Il4ulzODYsYJ7c22j2KxaP4xxWJxZQwul0sVi0XVajWl02nbUoBHy9HRkYbDoXZ3d9Vut/XNb34zrPwLCAh4YnhS/F4KHP9ZInD8R0Pg+IHjB44fOP7LxvGf6sO/n/u5n1OpVLpv+8Cf+lN/St/7vd+rjY0N/e///b/10z/909rd3dXf+lt/a+11vvSlL+lnfuZnnmZRAxx4utzv9225biwW08bGxoop64sAgr5fjhyPHxurxmKxFVPPB5GDdSrao8Inzvl8boGU9vNLrb365D0a/DJtElsqldL29rbVrd1urySy01Ta6N/9UvdHRXSZPG3NFgWMWQlWKIFe1SGR+qTgPRi8usYHAT4weOXKtx+B0F8Txci/L/reqMLHa6LJwSuDvu98m/C7f8268RS9DgkXlYt7exXO18kTP+rlVUX/5ZeuQ0Lps6jSGR3v3GedKuqVbF8W4FVXAFnm1C5fTkgGYxv1EDIGAY0qx75//BJ9v+2GMeXbxxM1Tyip17rx4gk/nj+QgcFgoFarZSd9jUYj+yCSTqeVSqVUqVSMnOGHw7iln6WTOMDvkBq2O3iSD0FCMczn83a92Wxm20nw8uF0sYCAgIAngSfF76XA8Z81AscPHP+0awWOHzh+4PgvP8d/qg///uE//If6/b//9694IkjST/3UT9nPv+7X/Tql02n9iT/xJ/SlL33J1AGPn/7pn155T6fT0ZUrV55ewV9x8FS90+mo0Wjo8PBQsVhMn/vc51StVvVLv/RLdjz1i4D5fK5Wq6XpdGreE5yodO3aNbVaLfNCAD5w+wDng/DDgIAS/RuK5XA41GKxsAmcSqVMwSSINptNtVotS7AESgLN+++/ry9/+csqFova3t7WbDZTt9tVt9tdSRY+yHv1gDoSwP3rKOu6BBEF6hGJPp/Pq1Ao6LXXXlO5XNYbb7yhYrGoq1evKpfLqVgsrhj/kuRRQrypLWRgMpmo1WqpXq+rUChYsPYJEJWGtpRk10Jx86eYUXaCsfdbQNnkf7yPL69g8TMKHCpYlGixdB7VB2XSq4TSsa8D6tW6BBxNfJSXLTqxWMy2Ifh7zWYzq3er1bK+8mX3y9v9Un/aktf6bQ20wWg0MrPiRCKhUqlk4wilNR6Pmwo5Go20XC7Ny4StEIyjSqWiWOxY0eSDSKfTsfGWSByfhIVCi1k19cInZTKZqNlsmprq1VtIiVcwvbrKGEStoz36/b46nY56vd6KAri3t6f3339f3W7XTnqjfpVKRalUSpubm8rn83r99dfNxwQw/pkPyWRSw+HQSAXqMuUjJs/nc4sj5XLZyPjGxob6/b55kty9e1fdbld7e3vWx4/zgSAgICBgHZ4Uv5cCx3/WCBw/cPx1CBw/cPzA8V8Njv/UHv79j//xP/TOO+/on/7Tf/qBr/2Nv/E3ajab6f3339fHP/7x+/7vlwwHPBsQOEajkTqdjhnQ4g9CsHwR4Cc2apk/Upxl0l6BAlGlzH9/FHKw7m/cj8SA4oEPgLS69BiVyKuKBFWe9EMEvN+Dr4tP+NFA8CA162EBCSHYZrNZI2J+GTdKRlSx8gpSNBGi6nhVdN2WBq/uRLc6RFVX/o+i5Imff42/nk+S0fZaR6CiPhIgSsQYA/zdK1c+sfI7idN7RHg1y6uCgPdCwkhGGPPSd74NfNKAhHgPm3XjJvo3ruvr5ctEPGFuUj/pZIsF249Q+SGN0f/5cY7SSf/yf1/udYiORcpG8uUa/X5/5US8drttCiCKmzdHZwl/JpOxE75KpZISiYT6/b69zhMuxjvfKR9bPXitJ6z8z4+l2Wym4XBoqiUKJnV7UeJ1QEDA2caT5PdS4PjPA4HjB46/DoHjB44fOP7Lz/Gf2sO/f/AP/oE++9nP6jOf+cwHvvarX/2q4vG4zp0797SKE/CImEwmarfbunfvnr72ta/ptdde0w/+4A9qOByqXC7bk/loEHge8Mn3vffeM6Uqm81qY2PDTi4i2axT/Zh4BN8nQXoI6HhYsLwftQlVablcKpfLmcqDmsix55IsQezu7iqZTCqXy1mdSQQEznXJi4DplztHlURwWv19MkilUiqVStrY2NCFCxdULpdNBcnn85bUCPpe4fL19gRoMBiYZwH+BiQ2nzyiiZvrkEhQz3i9NwyGeESTK6SyVCopm83et5TetxVBmGXrXrnxbUcdIQ7czxsak1Dj8bidbofyRRswbj0p8t4l1ItySTJfHJ/o/NJ6/gbJ98oyidyP4Xg8bsoiShvjGIUO7xJvVrtcLq1tO52OYrGYNjc3zdzWj7lKpaJKpWJ+MZzoVygUlM/n7dQz357L5dL8MKbTqXq9nmazmfr9viVp2seTKvrLl3E0Gml/f1+j0ciMfIfDoUajker1uhqNhvr9vn21220jUZxcVi6X7QQ/T5a8f5IfC4vFQs1mU7PZzFYKQOoop58/mP/6LTas3mi1Wrpx44ba7bZ2d3fNK+VRVzoEBAQEPAiB3599BI4fOP66dub/geMHjh84/svL8R/54V+v19O7775rv7/33nv66le/qo2NDV29elXS8ZL9f/bP/pn+5t/8m/e9/8tf/rL+z//5P/qBH/gBlUolffnLX9ZP/uRP6g/8gT+gWq32qMUJeEogyQyHQzUaDW1tbZkKVCwWNRgM7MSrF+FDJUGR472ZiJlMRrPZyWlT65bvn6YifFiCwHtJykz4yWRiiggT3icXfEBisdjKlhqSKD4ABHcC9YNI2mlqqP95nZJ42nVIupz+xZcPXNHk7X/2iiQJ3fuieL8Egtq6wO7VLX8PFDjUYX/faELif16R8a/3idMTK/9/X8d1ipl/n28HCKl/na9XFFE1yyua/p5R7xnvN8M1/Pjx7/VbADwxoO09qfLXjvavX/LOVgHpxPfCt58nGxg5AxTo6XRqY8ubxzO36HNJVje+R8efLyfjj21QKIFsT5hMJmo0GqrX60YWqAsJOpPJqFwu28oJT768Mu3rCzA1ZrsGCidl9MSAezL/UVA57avVaqnX66nf71udXoT4HBAQ8OIj8PtXB4HjB47/oOsEjh84fuD4Ly/Hf+SHf7/yK7+iH/iBH7Df8en40R/9Uf3jf/yPJUm/8Au/oOVyqd/7e3/vfe/PZDL6hV/4Bf3Fv/gXNR6P9cYbb+gnf/InV/w+Ap4/eLrf7XZ18+ZNFYtF9ft95XI5/ebf/Jt17949ffnLXzbD4BeBHMznc7XbbY1GIx0cHKhcLiuXyymXy6nVamk+n6vX660EHUlrk4UPfB+W/PBelJvxeGzBBDNdTIBRoobDodWHskAY8NpIJpOqVqtm3Lxum8C6evr6RU8SiybtKPz7MCGtVCoql8sql8u2RcArbaPRyH5HsUGNSafTtvwbT4dcLqd8Pm+/MxZ9EuVvvV5vJZniQUEyq1arSqfT6nQ6FnwhCpTJ15NtGZTVq4x4TLCdw5u3+qX0eHOQmGljEh9JbTgcajAYmHLJtVnu7b1JeL8nXd7ngv7yp0stl0tLmCQ4VDXqFU2YfgsGCibJxS9F98mL9/itL8vlsf8HfQFRWC6Xtlzde3Jks1m758bGhiqVivUB23rwIsnlctZ34/FYy+XSypjL5WyeLBbHp7TRlrFYbOV0M9plOp1qb29P3W7XTs7a399Xq9WyMUh70f7lclkXLlywrVL5fF5bW1tGcKLzx88pysr4abValuBRmek3SUa+uTdjq9Pp6OjoSI1GQzdv3lSv11s5hcz374f9kBMQEPDyI/D7VweB4weOHzh+4PiB47+aHP+RH/594Qtf+MAb/PE//sf1x//4H1/7v+/93u/VL/3SLz3qbQOeA5bLpQXffr+v0WikWCymCxcuaLFY2LL0F+mDJUqENwtFzcRs9IPK65On//3DkgOCpE84kixwEbRZEs1rJRkx8IqKXyJPgPwgVc/Xh+uSpH1Q/6AlxD5RcSoRPxPwITkkjugyc66BYkQCIbjyP59cIAZe0VlHdGg3rgOiChjX4m8keO/XwP/8Fgdfn9PayquMvl1JUl51i8ViK9soIDbrSKkfm1GFzrcv7eUTvt/6sm6c+691f/dt5tVa7ss9T1uGTkyRTgyc6SevOkKoIHOob5Aqrs1Sf+7j6wbJ86/3hG8+n5vCh+dHp9Mxw18MxlEjIWkQ82q1qlKppK2tLRUKBW1ubhrBXUcK+Jm57H/34yM6PpkPzC/qQLkpL14g68aMn+MBAQEB6xD4/auFwPEDxz8NgeMHjh84/svL8Z/qab8BZx/T6VTtdlt7e3t6++23ValU9D3f8z3a2dnRN77xDaVSqZUTjV4ELBYL7e/vq91u2xN8TqXyS8+9OkjgIfn6wOcTh8ejEgWuh+KXy+XMe4K9/hjpbm5uqtvtqtFomBpCwGdrQCaTUa1Wsy0H4/HYPFo+qGwEJK9i+bp6bw3+7q/rr08w9x4FBFDfbih2qID5fF6ZTEaDwUDj8dgInFfdRqPRiqdHPp831QtllXv7ZIDas7+/b0ut6QMfHFHLUqmUMpmMJpOJjo6OzI/CJ3M8LDwpG4/H6na7Vr9kMmnG5SQI2opTythKgW+KX+49n8+triw/pwwoR5Bc7+/BdSAV3W5Xs9mxgfR0Ol3xhYCExGInWyZQXTGOBYxRlDYSklc5OQmMcVgoFKwvFouFKXEkNO5DmUqlktLptPUlgNjTPhx1z4lZ1Jt6sIWJcUqZ/fYHzHF7vZ55lIzHY927d0+9Xk+7u7umBk6nU9VqNfMpqVQq2tjY0Pb2tjKZjJ0ahmKXzWZtJQVzNBaLmZEx6iI/0zeFQkGZTMaIFW3u5xO+JLFYTO12W81mU0dHR7p9+7b6/b4pi9HET19Xq1XFYjHt7+8/MC4EBAQEBLw6CBw/cPzA8QPHDxz/1eL44eFfwAOBYjMcDnV0dKRUKqWNjQ3N53OVSiV1Op2VyfwigIlEEJtOpxYAWXLtgx9P5aPeCk9a6eR6KFZMZAIoXggEG+k4mXC8uCcsBD/qQ9LyfhkPUx6flEgavD+qNvEeTxQoh38vQMHxydQrTX55O/UnwXkVlT6hrBApvrzyF1XHSCIsOY8CAkQ7QhQoi0/sUWNeEiP3JZDj+0DZKZM/Bt5vDYgqlIxF2iXa3nilUCbGNd8hR4x930e+LyCj9IFPLP51iUTClvdTL/ohk8kYsYz63jDPmGvesJrXewXWK3vUzavAbJmYTqcraqhXFOkfvli1gFoMMWi322Z4zmmHKIMQumQyaYbXW1tb2tzc1Pb2ti5cuGBEMjoOvSkzZcrlctaWbMvwZUVx5L1eaU8kEkZyaSM+MGBQPB6PbTuBB+OI7TsvWpwOCAgICHi+CBz/ySFw/MDxQeD4geO/yBw/PPwLeCAIrkdHR/rGN76h4XCoz372syoUCrp48aKWy6Vu375tg/pFAX4Ih4eHGgwGdvpQpVJRPB5Xo9EwNccnIQKzdP8e+nVKGH9/WBJBgsDrYzqdqlKpmL+HVxrwzsBjo9frWQCo1+umPqVSKW1ubhqBGw6HdiLSB4EkR3Bm6THBVDohDPw8nU5tTEiy736rQiwWs0TovSOkE0Narke9CZC0LUHNJ0iv6kFaUYWiy6h5DYkS4ufJzWg0Ur/fvy/IewKDsgVhgABwfX9aGyQNcurHh1/O7kkhZChKrFBIJ5OJbfmg/n5JOcnWt210KwTjCYPbcrmsVCp13/YHT8rWjXf63ydGCIDvq2Ty+BQuxg5jHu8aTyRRDFHC/P38XPQmuPl8Xv1+f8WQHEUOU1/IpiQ7bavZbGo0Guno6GjF5wPF+WMf+5gSiYQ2NjZUKpVsbmJ2XalUVKvV7iOl1GU6nSqXy1k9ISfL5XKF0FFerxQyDvz2ID+OG42GEYKDgwP1+311u90Vgu7bLp1Oq1qtrozJgICAgIAAEDh+4PiB4weOHzj+q8Xxw8O/gAeCQDAYDHRwcGAntqVSKVUqFXW7XQvoj5IgnzYIviw7jk6Qbre7kvh9svDB+UHwyeNhlTjKRlJaLpdmCkywR5Ei+HqPCLYtsPR5MBgon88boWDZ/WAw+MAy+URDsvEql/+Klh9ywBeqkScRvj7RtvKkigDr7833BymW3IPkQrDmmtTdk75o/b0ydVp9vcLn/UC4pk9mXoGKtr+vs0/Gvp5RcoMyOZ1O7yMrPon7oL+uHpTR+2P4PvJYN/49MWD8evLo1WXqzNaOwWCwkhgpt28jyuHLHa0D94Ag+G0ykIvRaGQnY3HP5XJpy++Pjo6MGKAYxuPHptHZbFbValXFYlGXLl3SxsaGLc9nfBaLRZVKpZU28f1P+/IdUreujbwaulwujZR7Uuc/tGD222g01Gw2TcGOjmtIVCqVUqFQsPH4osTmgICAgIAXA4Hjn47A8QPHDxw/cPyXkeOHh38BHwiS2N7enqrVqjqdjlKplD75yU+qVqvp7bffViKRMO+KFwXL5Yn3BicP5fN55fN586Bg2bRXVqLXOA1+ia0nGA9TLknmr0DAJPigQKB45fN5FQoFNZtNtdttjcdj8zPAsHRzc1OJREKbm5tmcMpS4XXBnzJEPT+8ShElej4xce/lcqmbN29qMBjo3LlzRsBSqZQlW5aCUxbu4VU41C9OesLzolwumy8IgZNgTJ9Rbp9gaUv+T1lQHyFBKHooXD4ZkVhSqZR5rdAOeFGgdEHWUHSpN8liuVyaculPGkNVzOVylnT5HwE9lUqpWCxaIpS0YggLsUomk5aQ/GshxCRRVE6vSPqT1nxilo7JA/4l3JM2hVgxHxaLhalgfqz4Je1eUfX+PFFFPvodErZcLlUoFDSdTs1PBg8O6kfZut2ubQEYj8fmm8G8KpVKymQyevPNN1WtVu1Ur0KhoGw2q1wuZz4xKMsQdL7YEuG3iiQSCTNLp70pA8qsJ/20M+2HV8lgMFC9Xler1VK73bYtDHzg8fMTL5pcLqdz584ZgZrNZjo8PFzZkhIQEBAQECAFjn8aAscPHD9w/MDxX0aOHx7+BTwUZrOZOp2Out2uBoOBHYMdj8dVqVTsRJoXjRgQlJlspVLJgrc/betx1EyvWHi16mHJAWrUaDSy4I0PiFcYUqmUyuWyBUIUMtQ/AjLBiP3/JJloAPGIKkrSqlIUDdCUnUQIIUwkEqYQexNcrxZ7nwqCOK+h3fBukWQkYDAYWB+RVFBHo2quV6n4uw/aHCFPPUjuXsnzdSXIR1UrkjF/I6Aznryyw5zgHvSJ34IS9aihvLRPMpm0hOavCfw2hWi/Qi58O9MH3BuiwXL0daoi5ALfFO/r4RVZ37fUxfeVb3/aYd0YjaqDXoWDaEG+vB+GH29sGyCh9no9LZdLMyAuFosqFou6ePGitre3Va1WbYxA0tPptCmbsVjMSKX/8vPGvzeVSqndbtu4wGTYjxG8Oigb7dpqtdRqtbS3t6fDw0ONRiNbDbCO7EOwC4WCtra2LC7gKfQiGbYHBAQEBLw4CBz/fgSOHzg+fwscP3D8l4njh4d/AQ8FEsHR0ZF+5Vd+RTs7O/qu7/ou1Wo1Xb58WbFYTPV6fe0S1ecJAhLHZEtSpVJRuVxWPB63J+4k6YfFOhXRq0kPew1pVcFZLBYqFov2GshCJpNRqVTSzs6OKWeTyUStVkvz+Vz1et1Or5KkjY0NFQoFCygko0eFV3c8+eFrMpmoXq9rPp/rxo0bqtVqisWOT4NimTVJlATLse6Ynfokye8so/ZEi8S2LijzOt7nlZZooqKfFovjE74IqJCE5XJp6vF0enyqWDKZVLVatXbxSSudTq8oWpPJZMXQ1ZeBskEmKMdoNLJ2IoGgNnl1jiXukDJIFP0LOeBelIuyVKtVzedzU8toJwil98dY17aegEEgZrOZEYd4PG7EkG03vi9820XJhFehIQ28LpFIrPw/Fjs+YWtzc9NO0aKvFouFqYbFYlHz+VyXLl1aUYer1erKaV47Ozt2WiBKnVcvIS8o7tS/UChoY2NjhShCllDmUfc4dYw2jCqzxJS9vT11u10dHh6q3W6r1+up3+9bjIrGF7YCsaUhmUyq0+loNpuZEsn7AwICAgICoggcfxWB4weOz/fA8QPHf9k4fnj4F/BQQGHqdrt67733NJ1O9d3f/d32BJpA9qIBdaTb7Wo0GqlWq6lYLCqXy9nT/l6vd+qT9g+6trQa6B6FFBHoWCKPCoa6x9HoJC0m/ng8ViKRWDED7fV6SqfTKpfLSiQSZmBKgHgSH/zX1Y1l15K0v79vRrOTyeQ+34SoqkPyQTGhDReLxUrwlU4UNa8O8XoSFQmVe/rrUX6vdEknahpqWDKZNMLAMn2CN4a6qCu0h1fsUDYl2dYAkhrKJsnHE4PJZGLbEphrwBOZRCJhCTCdTpv6S8KgHb1CRRkgbJ4YoE4x1liu7n0uuJ7ffuD7gGvweuo7HA7tdWyr8ITCjyef8PjO3E2lUkakvAKcTqdVKpUUj8ftxLder2d9gofKcrk00kJ/b21t2RaNWCymYrFo8QsyA5H1JAujYV43n89tpQGKPf3BFpfBYKDBYGCkgvd6M2KuP5/P1Ww2dXBwoHq9bv102nJ++jabzSqfz5sBM/fb399fuUdAQEBAQEAUgeOvv7YUOH7g+IHjB47/cnH88PAv4KGxWCzU7/d17do1e9rNXvp8Pq9vfvObZhz8qEn2aYOgzLL1crmsYrFoZe10Oup0Oo+laHrF7HFAwMOclK9CoWBeDUxugls+n7eAhmIxHo91dHRkClYymdTFixc1m810cHBgS4M/LEnwAXw2OzFcvnXrlprNphKJhGq1mkqlkpbLpRmSAp/Eokv7/T1QcEgCXl2EXJCsIGVsAYkuvyeARpfs817IIspLOp1WOp22dkX98t4VlIH+ZzsHdSMxenVLOvHygIzwHghAKpWyZeneaNYrZahfqKCeZJKIeR2AdHh1ES8TiArbGugT2gFChKKJKgdms5mdCOf/xmupnycb9BUrCfD0oC70Fb4WqG2oytKJj4vvW+lky8jOzs5K+3PaGGOSEwz5YkzwO0RpNBqZ0fByuTSimEqlVrbdjEYjNZtNi4OTyUS9Xs+u45M0Y6/T6diqin6/r8PDQzUaDdvOsC6pMydYNQAJh0j0+33r2xdplUZAQEBAwIuJwPHXI3D8wPEDxw8c/2Xi+OHhX8BDgyf9t2/fVjKZVK/XUzKZ1KVLl+zIadS3F5EYzOcnpsAkLibfZDIxdetxycHjwgd1kj8JAxWHgEJwJQmxbB1/B9S0crmsTCZjy9hRy05bVvy49WWryGw20+7urtrttjKZjPr9vl577bWVE86op1dOKI9XWH3ZqDMKjiQjBtTDqypR412uTcAn4bDsm+RcKpVUKBTuq994PLal+ZSV+kSX3bM1IEr0uBZqmS+j9y2h/pQLRQ9lzbcf1/ImyBChZDKpXC5nBIUxFY/HLXGSWPHJYXzQXpAXthMwtnivV3dRNVutli2TR+2lTtTf/05CpT36/b6NDa+WQ04oG8bEmN/igQFoD4iOJ1ClUmllKwXzH3Nt1EDv1QOh5rQ7iCcnhJGApeN51u12NR6P1e12jThjJuw9XSCKJPHDw0P1+30z/eb1UXilFfUfs+hWq2Uf2ihrQEBAQEDAByFw/NMROH7g+IHjB47/snD88PAv4JHAk/J2u6333ntP58+f15tvvqlsNmteFUyyFw0En/l8rmw2axMadZByE6ge5/ofBj64MPEnk4ktp0at8oF+Z2fHTg2aTqdqNBpaLBbmA4Anx9bWlpEJgqFPyI8LEoNXIu7cuaN2u61arWYnlHkvjeh7IQgkN1QfkrhXEPm7T3gob74uBM98Pm/JmOS+XC6VyWTsXj5Be4XIK5M+eaM40l+8HmWNJEsCIQmRWLxKmUqlrC7+VLp0Om0nubFcX5KNC04wo8y0H8vnqa9XvfA98cST+3nCQdtQN5KrJyOckkXyRGmnjHyH2DC+vaLMeGEZ/9HR0cpWA07qQ8HF0wQPjnw+b4SP+qBa0p+og9QJwhglWmyzoM8ZS6lUSvl8fmUrhB833hNlOBzaqWSog2xT8aQectnr9TQYDHR0dKThcKhGo2GEYp1/D+1A29NOw+HQ/D5Q/cODv4CAgICAR0Xg+A++/odB4PiB4weOHzj+i8Dxw8O/gEcCgQ9iMJ/P9Rt+w29QtVrV+fPn1ev1dOfOneddzFPR7/c1HA7tNKNaraZyuaxer6d8Pm++Ah9mif/jwqtJy+WxhwHLsEej0YrnAkG+VCqZWe1gMFC73baTj/h7sVjU9va2KQcERP/1YctNgufEoVwup2w2q83NTW1vbxsB8z4Y3Hs2m60oMtTNK4YkaN7n/UP8taRVLxASaqfTWVnqjpKHjwNJj9fw5VUZyk0S8iSCa3nlkCRCsiIR+q0NKI5eBcP8GR8JSWYYixrnVb/5fG6ql/foYBk/iY8y+uRLvak796bNIQaUGZKFkS6Gt/6kMF8Wfy+v0BJHvMktptWMA5bR06/FYlGlUkm1Ws2uVywWrb8xYPb3fNCYZSzM5/P7iAFtAxmhLp6keWC8CzEg0dMPfix6YtDpdHT79m11Op0PXMaPWlwqlcwXiNPBms1meNgXEBAQEPChEDj+00Pg+IHjB44fOP6LwPHDw7+ARwJP0QeDga5du6bRaKSjoyNbfr69vb1iavqiwZcfdYg99Zubm7YU1ycFn5CeRfkIVMPhUK1Wy5ZiZ7NZVSqV+3wVSKb4DbB8Gb8D6ppIJLSxsaFsNmtBbDAYWED8sPXzCosk3bt3T91uVxsbG9rd3dWFCxdUKBRUq9UssUWTOb+TiCAI1NP7Vkgy3wuSDiogwRUVyCcCfmaZeywWs+9cZzgcajQarSha0a0FKIzz+XzF5JbXkFBYBk5S94QCAuG3K0BaTmsXfo++jnGNXwzKlb+HP+GKrRFcx6uikAraqVAoqFQqaTgc2ilkHEkfVf184vcqIIoVc2t3d1f9fl+9Xk/j8dhIOe2HQs+JcefOnTMfj3w+b2orfYMaRkL3imQUtAdjjNd6ksF12D7iSTlzdDabmXoLGafdaAfiSa/X03w+V7/f13g81sHBgZ3y5dU8X8ZYLGbbHnK5nCmUbANC4Q8P/gICAgICPiwCx3/65QscP3D8wPEDx3+eHD88/At4ZDC4v/GNb6jVamlvb0+1Wk0bGxuaTqd2pPiTSDZPGpSJ5bgc946hZjweX3k6Lz1bYiCdBLp+v694PG5LisvlsiqViqkDkmypd61WM+VnOBzq8PDQlBYQj8e1ubmpzc1NpdNpMz/2ZqYfFqhbk8lEt27dssRUrVb1iU98Qpubm5aw/DJ+n5j43Zv1+iX0JBGSMfeMx49NfZfLpVqtlrUjJNUreGwxYLm7VyCXy6WZQ3O6EvD+GBADEj9Jn2RLwuF11MMv0/d/92SD/vLtQnv4LQrUjWTBiXyM5UwmszKOSXA+aXE/30aoZKh+nDTFkfLxeFyDweA+UiOtngTG2IK0eH+Mu3fv2nH3/X5fg8HAxjDllaRcLqdMJqNUKqXz58+b5whbXCB41Mmryw8iBrQHZIa/QaAgWNw/k8kYWaGtR6OROp2O+YBAFDwxQL3rdruaTCZqNBqaTCY6ODiw9zMm/Bxk7BcKBRWLRRWLRVUqFfV6PbXbbQ2HQzvFMCAgICAg4EkgcPyni8DxA8envwLHDxz/eXD88PAv4LFA8BgOh9rd3dVsNlOtVlMicXIE/Yt4Ihjw6iAJACWnUqnY03b/+mddPk4TIvBLsratVCoWOBKJhAWvjY2NFWNXTgRDXURhYSsEy6jZKvGkCIJ0suy61+tpuVzqzp076vV6ymQyphYWCgVTeDxR8GqhTzokIa9ESSdeCRjyZrPZlaTr/UU8UGK8/wJJl6X8tInfEsDPkApJK0mW93lSAvxyda+q+TJBWPDvYFm539LAtbxPCgmG1/s2hFz58pMMo2opS88ZfyR7TtHy21QgSqjPkJ/Dw0NNJhPzqoEYoF43m03bFjAajexkK8yGc7ncymlX29vbymazisVipthms1nrH7Yj0G4+2a8DJE86Ngle9x5/Xfw+er3eiu8RBCi6nD+ZTNqWgNFopHq9vqL093o92wbixw3lyOVytiVBkimHEALqGh7+BQQEBAQ8SQSO//TLFzh+4PiB4weO/zw4fnj4F/BYWC6XZlz57rvvajAY6Hu+53t07tw5VatVCwovKjFgMvEkf2try7YHbG9vK5FIWEJ7Xh+uMYdFnSGxc2oVSZ2/kQAnk4ny+bzm87ktkT88PFS73VaxWFQmk9G5c+fs53w+r/39fQti604fehygcjWbTVsGnc/nNRqNtLW1pddff10bGxu6fPmyyuWy1Zf3+qRFwCU5eo8JCJ0/IS1KMkiwKDYgqgpCtqQTDw4S5mw2M2JFckb1QYGNJqLoUnX6aJ3STHk5nSsej1vi4zr++t6jI5VKWZlIZPzPq2yMF69UsnUEXxYSLsoiCqok2/oDEaCNML+F6AyHQyOCt27dshO1vPJKu1CWcrmsYrFonhu1Wk21Ws08SpifkuzUvnw+b+2IOsjpYX77wzpyQBJm7FAOti+w1B4FsNvtqtlsmnlvt9t9oLKNMsm2nLt376rf76vVatl2Ak/yUCRZpVCpVFQsFm17CsopKmNAQEBAQMDTQOD4Tx+B4weOHzh+4PjPg+OHh38BjwUG9GQy0e7uriTpk5/8pNLptLa2ttTpdCxgnmZu+SIAlWIwGNiy43w+r8lkolqtZv97nitsvD9It9s11YXAhgIlnSQaDF3x3SiVSisqmSTzGuAkNJIbWxC8f8bjwPstoHRI0mAwULPZNMNbb8bLkm6UIZ+YaQsfSKkLQdYnZ5bj+8RPYvLbAyinv54nJf69EBPK4r0ohsPhyrLyaMDnHvyda5NAokbJUXUqqtjyN18PvHj4P1tHIBWeYCQSCVNPfbl9mSGfklYULFS+WCxmqt7h4aG1A34XGNXi65FOp1UoFIxgeaUTlRg1DMXYb2NgDLElhBOxUEUZK1FV9TRlkLrSN560oJLP53PbItLpdNTtds0DJNpHKICccDYYDLS7u2u+H8Ph0MaTVw9RQak3bY5nD236In/YCggICAh4ORA4/rND4PiB4weOHzj+s+T44eFfwGNjPp9rOBzq29/+tprNpn7Tb/pNymazeu2115RMJs0cc91S7BcFKFEkIFRNglin07EtD8+D4Hj1xCeknZ0dSVKhUDDlhv9JsoBZKBQUi8V0/vx5FQoFO2Kca/N+1Iho4IOUROvtA2KUOPA/76kA6YrFYqrX62q322q328rlcpYsUWi4Bkvdo0utfVlIwBAlEi2eNARiv1Se8Tifzy3hRBMLbUL9uT9kjG0EXt1BiWNZO8mV9vDmwJLsuiRvEgTKrFf9vFIbJYE+wZRKpZXXZLNZU+38PPReE5SR+/E/1NZcLidJtuQfAkbCR/E7ODiw7xjVzmYz9Xo9JRIJXbp0SYVCQR/96EftNCvaUjpels8R9xBbvnyfTadTU9YgQ+Vy2foPzxEMdD+IFEj3m0qzlaHb7arX69n3wWCgfr9v4ySRSNgJX4yBZrOpTqejW7duqdfraXd311TF6HxiPKXTaZ07d862x8TjcTUaDbXbbbvvk9yuExAQEBAQ8CAEjv/0ETh+4PiB4weO/6w5fnj4F/ChsFgsbH96q9VSKpXS5cuXVSwW9f7772s0Gpkx64sIJhoqR7/fV7fb1XK5VD6f12w2U6FQMA+DJ7FFwCtODzvRue9kMtFoNFK73dZicWwQTPKQVk+sisViRgIgNn45OgqGN23FByKbzdo2hOFwaIHZq0eQKRQYXz9fZgK6JFMJvfLX7Xa1t7enXC6nbDZrgZOTj1BuWSrugyr34QuFjO+oSFzT+4JETxPzdfPqoCSrKyTEK3CQDl7nVb54PG59QJkgSL7Mp32PtimgL3gtHh9cEyJDWakb48OPQa4PEfJeIp7EoEz1+331+301m00bV5DIeDxuCvTm5qZdN5VKaXt7W/l8XhcuXFA+n1elUlkhBhAq2o1xwzj02ytoT0yA/VyKtoEfF6fNN094JpOJWq2WGo2GOp2OeQMxR/yYoBy0AYp3t9s1w17Mj2l72htltFQqrZyeyIlh+I48SbPugICAgICAh0Xg+I+OwPEDxw8cP3D8F5njh4d/AR8Ks9lMrVZLsVhMt27dkiR99rOfVSqV0u3bty1xEIRfRCyXS9tzLx0H3Y2NDZ07d858AjDf9JP7cUGgfpTJjjLEsvPd3V0Nh0NVq1UL+NKJv0WxWFQsFrPl/QT1bDZrS6tns5l5HKBE5fN5bW1tWVDm1CGUNRIfJrCTyUT1ev0+xZQyEWyXy6V5PRQKBVNsksmk9vb2tLe3p2q1qlKppFqtpmq1qq2tLaXTaTNeLRaL2tzctDHl24Y+oR1QB/HTwNsBYoRaWKlULJFT7igx4H/JZFLz+fEpePl83k5f4/4+6KNMolT6rTHlctlONPMeFsCTu3VAkeS+iUTCfF9I7CiOtEO5XFY8HrfxAXFEgaJfR6ORkeBMJmOJmHFwdHSk27dvW5+Q9JPJpHl2bG5uKpfL6eLFiyoUCrp8+bIymYwptaijxWJRyeRJCuJe+KGQjFEA8cahfReL49PyGGs+8aPY0a60pe+jaJvOZjPV63V1u129//77tpR/OBwaKV0sFjY+IBN8qGi1Wup2u7p165b6/b6d9MUHI8pGW0MIzp07p2w2a0Tg8PDQyMGjfHgICAgICAh4kggc/9EROH7g+IHjB47/InP88PAv4EODZa71el25XE7z+bEJbalUUqVSMdXlRYZXB3mST1KlTihWqIMf9l6Peg2/5Hk4HNq2i+l0aick+QRD8CIx4clAQkgmk8rlciuqC4nT+0Cg0niPDoLzZDJRtVpdIUskSfwUMpmMqXEkLa6DysdyagjKcDiUdLy1gURBolsulysqHXX17eSVMMouyfxTSCSeFPBef01PFEis1IGxEL2HdLJVgbLQLtKJN4cnHevGgyccfvsF5AeC4Mvq1VD/u38PBALFkt+5NknZE2bmBObZJDaIHsvyU6mUEcByuWztHW3XaP9I93u9+Dbj715x9eON/oy2nf8uyRQ23w6LxcLUt3q9rn6/b4oe/e23Z1Afv0VhMBiYithqtcxXh3akTyBxzD2MmWljPD8+bIwJCAgICAh4Eggc//HuFTh+4PiB4weO/yJy/PDwL+BDgWDf7/f1zjvvqNPp6LOf/ayy2ax2dnY0Go303nvvqV6vf2g17WljuVyasSkBN5/Pa2NjwxQSTxged+Kua4cHLVf25SOINBoNjUYjW4LNUmpUC75QUrzqmU6nValUzCukXC5bosN4lOPXOYlpc3NTV65csfITjH1QJvkTFG/dumVmptPpVJ1Ox05Xm0wm2tjYULlcNsJx584d7e/vWwB98803NZlMVsxge72eKVBsefD3pm39KVDL5dLUwWKxaNcfj8cWnKkLAZ9r4hXiE0Oj0dByuTQ1nOXd3tuEvoJsoXZBeiBzKKu8hy+fzH3y9F4S8/nxaVyQQk9QILP4SPhl5bQTdWb5PWUcDofa29vT0dGR6vW66vW6XTuXy6lYLKpUKml7e1vlclk7OzsqlUq6ePGitcN8Plej0dB4PLb2gjhgdku70Jds/aAPISi0I/dPJpNKp9OWlFF9fTtByCAb1LfX62k6narf79t4n0wmOjw8VL/fN/Uf0ue3s8zncztJzRP0druter2ua9euqdfrmSmyJ22oxJlMRlevXlUmkzGiy8livV7Ptg6EB38BAQEBAc8bgeM/OgLHDxw/cPzA8V9kjh8e/gV8aBBM+/2+nZZTKpVUKpW0s7OjSqVi6o5XrV5EUBf29ksyM9RCoSDpOLGiXj2pCfwo1yHpjMdj9Xo9SVKv17MTtby/BfBkwW9HwJ+D7355ONfKZrPKZrN25DpBmoTJEm8CJuQpmUyuKCv1et3ISTweN/8HFEq+0/7NZlO7u7u2HHs2m1lZfNKPto1X0qJLv1EXpWOFyScOrxLRfp5scC2/JDyqcPE71+J9fnm/v59Xyx40LqJl4X8kLr9Unf6LjgHaxati3iwZVQx/lnq9bidY0f/0O2pgqVSyE7yKxaKptZPJRN1uV6PRSJ1Ox+7HGEmn01ouT04qgyBFvS8ggX55fCqVUiaT0Xg81mg0sgTt6w2ZmM1mpnR7pRHDa04sRMmDtPl+jCqMtBekt9FoqNVq2UlfKOyMD+YlW2EgaswLtmEwNl/0D1ABAQEBAa8OAsd/Mvd9lNcGjh84fuD4geM/LYSHfwEfGiSqg4MDTadTXbt2TePxWG+++abeeustvfPOO+r3+9rf31e3233exX0gCAQYgBaLRc1mMxWLRV28eFHdbtcUtk6n81ye4JM4OYUJZSuXy2l7e9uOdpdWj3NHhUokEqaIsEQZlQbCgykypxRlMhnznJjNZiqVSrp69aqKxaJ2dnYsWSwWC7VaLVOD5vO5qWW3bt2yE5I6nY4tWy8Wi8pms3bS1MHBgZrNpt5991299957yufzKpfL2tzcVKvV0tbWlt566y0L3L7vCKocE4/iRBLFuwRvClQgSI5PSJ6kQJIWi4URE58kUbVQf5bLpalCLF/3prVRpY7EFSUNi8XCSBrKLeSNOpFcIHHcazabKZVKWZ2Wy+XK6W6z2Ux7e3vqdrva399Xp9PRvXv3VK/XzduiXC6b4re5uWlJuVQqaWtrS9vb2/rIRz5iJ+cNh0Pr3+985zumEEvHBDudTmtjY0PZbNa2DJw7d065XM7mHEmdfi8UCprPj08d9CSl0+mo2WzaqWPRrQK8HzIJeZ1Op0Z89vf3NRgMVrZUSLIxSXmoB6Sg3++r1Wqp1Wrp4ODA1EEIO32QSqVsVcHm5qYkqV6vG/GlHz7MKoOAgICAgICnhcDxA8cPHD9w/MDxXx6OHx7+BTwRsMybY8DT6bQuXry44gvSbDYfaun7iwD/9H80GtmT/XQ6beoIxrwkgGcJkgLKHuahxWJRkjSZTCSdmONGj5oncaGeoajgA+KTDX4eXEs6UfVyuZwKhcLKqVd+GwLJCVUkHj8+kp7tCKgmqVTKlkT705OoB2pyPp/XfD43nxmvZEaVH+rvlTGSIonCqz8+IXtFSDpR17zC56/N+9eNb5+YaTsSGAodoDynKUO+fFGVlyXs0TKw1N+TNtp3d3fXjGu73a4ODw/t9CsSHCa/ECLGCKSR/oVEcQpWu902TwzKPp1OlUwmjWyxbYH/MaY9ocX4158GhoJIUvUqMHODscS4Xy6X6vV6K6on2xYgx9F25ppcj20DrIDodrs2bqPzKZvNKpPJmBrovUdoF7/FIyAgICAg4EVE4PjPFoHjB44fOH7g+E8L4eFfwBPBYrEwheV//I//oa2tLb3xxhva2trSa6+9pul0qna7bUrai7Ds9UEg2OCnIEkXL15UNpvVG2+8YaaofsnzswTBZD6fazQa6e7du7ZsvlgsKp/PmxonSZVKZWUrAMupCVDlclnFYlHVatU8OlAM8XHo9XqWGFiazVcsFrO2+NrXvqZ6va4bN25oMpno4sWLKhaLunLliiqVii5evGhKYyKRsC0ElUpFtVpNtVpNW1tbOjg40O7urrrdrm7fvq3bt2/rO9/5jra2tvTee++pXC7bKVMY0EIYCNAkN+oDaWF7B6QE9cf7P0haIUyZTEaS7LX9ft/qQV94NdD7SHjFEnUMlUnSCqnhvj45+eXoJOlYLKZcLrfi54FxLadW4anR6XQ0HA719ttvq9Vq2SlXfik8iXexWJjKvLW1patXr2pra0vValWSjOSVSiW7P34vjUZDN27cUKvV0q1bt6yOiURCtVpNqVRKjUZDyWRSly9fVqFQsBPqstmskQ1U7EwmYwSo1+up0+nY2Ie0szWG5D2ZTNRqtexkuUqlYmr3N7/5TR0cHOgXf/EXtb+/b+rv66+/rmq1amovcxtfGFTuu3fv6v3337d7ew8T+go/lp2dHeVyOZ07d07z+VzXr1/XcDhUq9V6IZXAgICAgICAdQgcP3D8wPEDxw8c/+Xg+OHhX8ATA4Gp3W6bajadTlUsFrW1taVisWj7+F90YgAIrpwQRiDBLBdVzitIz6OMKC94mHS7Xc3nc1PrCLCUlfdBDvD0YLn1crlcMdSlHUhyKCQcHY9yA1BSptOper2eFouFvR5VNZfLrShN+XzekgGJIpfL2Qlmy+XSjltnKTcJm6Xfksxrwh85L50oqd4TA5XPJ+Woh4hXBGlDSIS/DvCeN9zTX4trRO9DYuG6nixEVc8ofL+gvM7nczWbTY3HY9XrdVPs2+22md9i1IwJrff6yOVyKpVKtjweAui9YCCbzH3/5T00qAOJly/GGIq7JwbUC6I1GAzU7/e1WCxWiJBXB30b0xesVphMJmo2m2o0GvYhhXtBMPxWEH8dTLIpAwSTMvj6MXZR04kfk8nEPED8mAgICAgICHjRETh+4PggcHyt3NNfK3D8wPFfdI4fHv4FPDEQBBuNhiaTie7cuaNKpaLXXntNV65c0d7enkajkfb29tRqtZ53cR8KBCD8KQqFgnZ2dhSLxbSzs2PeIOPxWOPx+LmQA7+cGvPc0WikbDZrZGx7e9sSr0/23W5XzWZTnU5HmUzGPA5Y6s/pZ4CA3u121e12ValUNBwOVSwWdf78eeVyOX3sYx9Tp9ORJFOKjo6O1O/3lUqldPnyZVUqFX3yk59UuVxWPB5XoVDQwcGBeTak02mdP39e1WpV3W5X586dM3PgZrOpw8NDU18ymYyq1aoKhYJee+0166N8Pq8LFy4ok8kYceMUNxQfEgPKmz/1yydjEgTkSTr2HCFJkdwk2WlnvF86SVbR7Qte8WOsYaDsjY8hO6h+fkk89WJuoQKORiPV63UNh0PdvXtXg8FAvV7P+hRzZa/sbm5uqlQq6fz589rc3DSCwBfJnDZlG4AnM3jHFItFpVIpU08vXLhgy+OTyaTOnTunQqGgc+fO2dhEcV4uj09aOzw8tO0Fh4eH2tvbW2lzjLolKZvNqlqtmurNdpHRaKR2u61er6dvf/vbtu0BwiAd+38wZ5LJpAaDgcbjsREm2rfVaq0keuYfKmY+nzd/HNTF73znO2Y8HFWdAwICAgICzgICxw8cP3D8wPEDxz/7HD88/At4oiB4TSYTtdttNZtNXb58WblcTpVKReVy+Uz5gkgndcI0lFOuOBGMY+R52v+8yAFLotmeQeCaTqem9HlSQL0gNHg1oPCh1s1mM1PPSJqSTOXD4LlSqZjaJ0kbGxumipCIKav32Yj+nUSJwuLVvGazqdFoZCrPeDw2/xKMYvEaKRQKK8vnUc1Y8u59Ogj0eF34fqSMtAuqF8oRPhAsw59MJloul2YSHPUU8SSAn/nyy/ijpAKPFel4WT7eGyhnqH5szWAbzmg0su06XjmDcGCYnEgkVCqVVC6XVS6XbXsFyirvRYkbjUZKp9NWX66BZ0u5XLa5kkqljLyhlhWLRSN2bA+B9MxmM/V6PTWbTVPwMAtmrnFCGGQllUopn8/bVgnKLp1sHxgOh7b9gXqgNqMGJpNJO8WMZf+QAYil3wIQbUu8d7xxsDc5DggICAgIOIsIHD9w/MDxA8cPHP9sc/zw8C/giYMA/Ku/+qs6PDzU7/29v1eXL1/WW2+9ZUak7Ik/C0/IJVmQRQUsFAq6dOmSksmkNjc3NRqN1Gg0bKnw8yI9PoHG43E1m00lEgnV63Vls1ldvXpV5XLZghTLnFGyms2m+Wrg35BOp5XL5VStVs0MWTpOLpPJRLdu3VI2m1W32zUfhFqtps997nOaz+fqdrsWVEkY2WxWlUpFy+XSDFVRJ9vtthqNhgqFgqlF58+fV6vVUrlcVqfT0d27dzUajeza+/v7isfjOjo6MoUmm83qtddes+SDx4Yk7ezsqFAoaHt7W4VCwVSgfD5vr/WKXbFYVLlctrFLfeLxuKlelUpF8/lcrVZLsVhMGxsbluhIJKiCmUzGluNjvEtixB+Fk9RIPuPx2JajQ4y63a4Gg4Ep7r1eT9KJz0m1WlUymdSlS5eMaMViMTPBrdVqpoSRSNmewbYFVEcSKmbK+/v72t7eViwWUz6ft/EBWXjzzTeNeOL/wTYQiAbtS33m87mtGrhz544pxbRNNpu1ZM6WDwgB/ZnJZMz/RpIlZ0B96PPlcql79+6ZT0kymVSv11tR+ykrpMQToVQqZeomHxzoPwgJZCIgICAgIOAsI3D8wPEDxw8cP3D8s8vxw8O/gKcCkhNGq4lEwo5yZ1lw1CvhRYZX3VAHp9OpYrGYKQ/eLPZ5Kp6oXJLs2PhEIqHJZGKGvqhvqB3eXwEDXdSWbDarxWJhS+ExHeb1vV7PFEVOfmNLAUv8Z7OZhsOh5vP5yqlLKFscO4/vgl/uTuCfz+eqVquKxWLq9XpKp9NWfl7f7/cVi8U0HA6VSqVWfEW8shWLxVQqlawMKDej0chUTV6P0oenSbPZtHaKx+OmBjFGIAYorFGzWOnYs4R6othxohYJK2rQ630tPEHgJC9UUlRbypDJZJTL5ax/SPbj8ViVSsWULLZGSDI/DsYJCZE2QjXNZDJGRkqlkily6XTaTvoaDoe2fB9FUJIRAb7jldFqtdRoNGx7CuVje8RisbC2ZWz7U8kgsox/77GCWXDUR4RT67guZI0v2gJACjyhYtsI92DbhfeHCQgICAgIOOsIHD9w/MDxA8cPHP9scvzw8C/gqWCxWOj27dtqtVp65513VCqVdO7cOVUqFe3v75unA8vWzwrwBqB+mUxG586dswSISjYajZ5rOQliLDXvdDoWVFGBEomEGo2GnaLkl673+301Gg2lUikz2+33+yoUCtrc3DSS4JWj9957T5Jsqfebb76pYrGojY0NC5ze5PXevXtqt9v6+te/rps3b6rdbtv2AupAMkUhvHjxojY3N02J7fV6Gg6HOjw8tGTKKU7L5VJHR0crxruQk2vXrimZTKpSqSiXy9nSb1QhkhFLyDHGJRmTKEm+qVRKlUrFPFbi8bhKpZIlL+nEJBifChIiBCCfz9s2E7agoGb5bRFsAeC0rkQioe3tbSuDPxGNbRm0AWRnY2PDEr1PtCRKkiY+J97kFyLJa2OxmIrFotrtttLptIrFohHK2Wxm6tje3p5ms5kZFOMjAiGCNNAeiURCW1tbVn88NvC4YUsLJ8GxRWA0Gung4EDz+dzUvXv37unw8FDf/va3tbe3Z1snPEH2Rst+y4YnBBCRTCajQqFgfYAPEiovfXRWtj0FBAQEBAQ8LALHDxw/cPzA8QPHP5scPzz8C3gqWC6XGg6HWi6XZgZbrVZVq9XsdKGzYggchfdfkE7Ul0KhYIH0RfE7oQxsv8AnBNVmPB6bn4UvL2pNKpWyoJnL5bRcLk0lzOVyFkxJcGwrwIfDK0UkSRJqo9FQo9HQvXv3dPfuXTPBJSn7wBw9PYrtCJlMxpI93hOU1y/jpi1Qnjgxazab2RJ2EmEsFrOTnIbDoXq9nnK5nHlvkFCiXhSof6hkvV7PxoYkqw/3QPWkTNyTZfLD4VD9fn/FP4Xr8HrUPk7r2tjYsO0W6XT6PnJCm+Dzwngg6UIQfZt5UhL1MmHbyWQyWVFf2VrACXp4lIzHYyNxEAOIarFYVDqdNjKLWbM3GmYsQKAYu5TL+6jMZjPzQ2m1Wup0OqY+M+59m3L9aHsDtmZQP7ZdYL6NeTDzICAgICAg4GVE4PiB4weOHzh+4PhnE+HhX8BTAxP1//7f/6u9vT19/vOf19WrV+10sE6no8PDwzM5iebzuQaDgRaLhXltVKtVJRIJFQoFSTL18HnUj2XhBHq+CGAoMd6rIpp8+MLjpN/vK5fLqdFomPLEcmvuiVITj8d1/fp1pVIpO+2LRFir1UzBWS6XarfbRiQkGTHgNKlSqaRarbbi64CvRKFQ0GKx0M7OjpXVq1rtdttIDKdCUV5P3rwaRrLKZrO2zL5QKNgWAkCCgPRAtPb29lbIFj/77S+xWEzlctkIENeTZJ4k0WX4bHHwqiCJH+Nhro3vx3A4NFWVJfrL5dJIHSTBEzyW54/HY1v6zilXbEnADyWRSOjg4ED5fF6Hh4crqiBJ/ejoyPpDkn0wwHQZRRJTYLY7SCfENhaLmUEvJ40xHvBuwQeE9phMJtrf31e329WNGzfU7XbtZDRPfPz3dWDbDyTAb59g6T9bW57XfA8ICAgICHiWCBw/cPzA8QPHDxz/7CE8/At4akBNODg40HK51Cc+8QlduHDBkijBi9eeJZAACdrSSWD3PhWnKQxPGygYJB2fAPnd+2NEEd1SQJJCcaOO3MP7otAeh4eHKwa0qGkbGxsqFAp2BD3lJeDir8HR87yO+/itBZy65IkQ9ZzP55acSqWSksnkCjGQZEQg6heBQke9C4WCeZGgoGEEWywW7XqYy3IdVESvpEnHY6VWqxlhkU5OCCuVSsrn85ZkMGxmGTrEAH8PyoLCSHugHvql7l5lZfsDpMgTSPqaMcJJXZAJyAN15rUs6adMi8VC7XbbCAmnjXHqlld7+aLcqKP+hDB/qha/00epVMqU4UwmY9sQut2u7t69a9tHuPbDzCG+09cowPQZ/QtZOmtxLCAgICAg4HEQOH7g+IHjB44fOP7ZQ3j4F/BUsVgsdHR0pNFopN3dXdVqNV29elVvvfWWWq2Wbt68aUtpzxpQfBqNhnkZJJNJVatVVSoVO20JleO0JPyk8TBki0T1sMSFZIGiEo/HVa/XV5ZJk5wJvCgn+F9Q/36/b34RyWRSpVLJEi+eGChFkswwlyXo1BEyQn0Xi4VGo5GpYnifzOdzU+C8IsR7ogqoN4Xlq1qt6vz58yoWi9ra2rIl4dSb8uC9QuLybQuZQS3O5/NGMtgi0e12LSGOx2NT3vC9IEHTNiR5CBYqI0vjaR/Gaq/XM9Lkj7tvtVqmINIueHVAviStnL5VLpdX6oY6SlkYB6VSaYW0sBXAtzlbSlKplOr1ujqdjv0fhbbf76+0jyffjI3d3V3r/+l0qsPDQ/X7fe3v71t7+rEfBf3IXAao6H4bAtehni8LKQgICAgICHgYBI4fOH7g+McIHD9w/LOC8PAv4KkCVWOxWNhe/AsXLujChQva3Nw05eUsEgPpJBnhtYHiyfJzvqPOPO3g4UnBgwjCowYyrxhFlUYSY1SZI+lxYhZBl6Xm+CmgtKAaoQ75Zeq8hy/qyj0pD2UjeaLgkFQJ5FEQ5JPJ5AoBYXtCtVrV5uamqtWqrly5YlsWfH1RwfD38EoY9Y3FYnZCFISJ/+/t7anVamkwGJjRsSRT2bwSSV3wNfGnf/F3SdaOXsljOwHqIieodTodS4C0sVdtuRav4TQ/7uMNn33ihVhEFVvuQXvR7p1Ox5TE+XxuSmi/3zeSjeIaVfi84okR8Xg8ttPq6JPTwPjilC9A3Wlb2u5lIgMBAQEBAQGPgsDxA8cPHD9wfN9OgeO/+AgP/wKeOphA169f12g00sbGhi5fvqydnR198pOf1K1bt3T37l0LzmcNKBT4ZEjHCaVUKqlUKpl3CAnhaSG69Ft6elst/HUJ8tyTclBXtg6gUPk+9j4OqIMkZW+aizExhsTct9vt2rYDEh8KZDweVy6XMzWTLQm+jJAXTyqAV/uos0/QiURCg8FAd+7cseTDdzw4WMouyTw5UAUvXLigUqmkSqWibDarnZ0dbWxs6OjoyAx2O52OhsOh2u22jaFsNqtisbiiPPqkNZlM1G63JcnMgrPZrJbLpQ4ODswDBhUvl8tpc3NThUJhJUFjuoupMAbDkL12u23bElDSIAzS8RygrVH4ZrOZOp2OLetfLI5PTvOGxN1u105b82Vh+w3Xob/874xF7okC6X1v1oHEHyUA0bFOPV42FTAgICAgIOBxEDh+4PiB4weOHzj+2UF4+Bfw1MGT+IODAy0WCwuclUpFFy5cULvd1t7e3trgfFawWCzMKBV/CHwPOA6dIPUkA4onAx7c42kHL66/WCxWki1/8wGUwIuSgyLMcnKUO97jVUGCdC6Xs3vzdzxE/DJtrsG2BE7pgpz4L6+cPajNGJ/+fZPJRM1mU/1+346Wb7VaisfjOnfunOLxuJ3mVS6XlUwmrS6lUsmSaDKZVLlctrKiBFLH4XBonhOYLc9mM/NeITkOBgNNp1M1m00tFguVy2UzDZZkSbhSqSgejyubzSoej6tQKNjJZ5PJZEVVRYWEXLAUH2NevyWEL5I5aiR1XCwW5m+CGsi2BL9lAuWN/kQB9N4l0XHgl+fTX/7rQYiOCfraj++zGpsCAgICAgKeFgLHDxyfsgaOHzh+4PgvPsLDv4CnDibZcDhUq9XSwcGB7ty5o3PnzukLX/iCYrGYDg8P1ev11Ol0nndxPxQWi2Pz0+FwaKak5XLZjjgfjUZGIJ5EoPEJlN+lE8LgjWYfhHUEg2v7ZdKoP76+3pPB3yuaaNkW4Zftsx0A9SmVSlkCJJmTbPwSdr8kfF29B4OBJc/ZbKbDw0NNJhNVq9UVHw9IAddCPcQPgqTHcvLZbKZKpWInaSUSCV24cEGj0UiFQkHD4VD7+/vmpSHJls77tuL+3IdT2abTqe7du6d3331XBwcH2t/fNzV5OBxqPB5bwl4ul9amJHj6hrrRJviI7OzsaLlcqlAo2NJ+Xkt/Q0i8wjYej02pQwnc3NxcUQHZtsHYxnsFQtzr9ex0LtQ9v0WDpO6NmaPeG5AM39/rtqlEyYPfksIY9mrvadfn55dZAQwICAgICHhcBI4fOL4UOH7g+IHjnxU80sO/L33pS/rn//yf6+2331Yul9Nv+k2/SX/tr/01ffzjH7fXjEYj/Zk/82f0C7/wCxqPx/rhH/5h/d2/+3d1/vx5e82tW7f0Yz/2Y/qv//W/qlgs6kd/9Ef1pS99aSXgBLxcWC6PzUCTyaRarZbq9brOnTunN998U9evX1epVLKjv88yvDrIaU7ValXpdNpMZkluzyLgEPy86hX9X/R3H3Q9KWDJNkGVhBrdynEaCfEeEFzfK0ne5BalZzweK51OK5fLWWJGleLeJECuSVKhztPpVO12e0XFImnTBySS6XRqpI7k69XATCajXq+n5XJpS+FrtZp5bND3LHmXtHId37ZRBQ2Vr16v6+7duzo6OlKj0TAlDMUxWm6W7Hv1L2qaDEnNZrP3tb8nFNzLn+4FuSLxJxIJU2+5l1duISytVsvak60A4/FYR0dHZgwsaUW5RfGMxY5PjoMc0j/R7SS+jn6cr1Oj/Xe2NvC66H0CAgICXjUEjh/wuAgcP3D8wPEDxw8c/2zgkTLxf/tv/00//uM/rs997nOazWb683/+z+uHfuiH9K1vfUuFQkGS9JM/+ZP6N//m3+if/bN/pkqlop/4iZ/Q7/pdv0v/63/9L0nHE/53/I7foZ2dHf3v//2/tbu7qz/0h/6QUqmU/spf+StPvoYBLwxQAq5fv654PK7f8Bt+g86fP6/z58/rE5/4hG7cuLFiAnpW4X0PSGyLxULFYtGSSa/XU7/ft2PjPwwe9P6oMrdu+TtqUPQ6XhX0QTnquQAIztEtAbwmSkRQme7evavRaKTt7W3VarWV+/NePD54D0vhKQNeHxjNQgwoy8bGhubzuZ00Rln8yVWpVMrux+lTKJDJZNKSNkS21+spnU6rWCxaskkkEnr99ddXklP0ZDTuwRaB/f193blzR7dv39bR0ZHefvtt3bhxQ4PBQMPhUIVCQeVyeSXRefUvmUyaysfrMKCmHSAKGPZGyR//53S2dDptJMKruihnKLRsDRiPx2q1WjZv5/O5Go3GyutHo5Gm06k6nc6Kka73ffFjxRsqryO1ngxEDakZM2wBoX5cj/eiOvp7BQQEBLyKCBw/4MMgcPzA8T0Cxw8cnzoEjv9i4ZEe/v27f/fvVn7/x//4H+vcuXP6yle+ot/yW36L2u22/sE/+Af6+Z//ef3gD/6gJOkf/aN/pE984hP6pV/6JX3f932f/sN/+A/61re+pf/0n/6Tzp8/r+/5nu/Rz/7sz+rP/bk/p7/4F//iypHTAS8XUEru3Lmj2Wymj3zkI0okEtrc3NQbb7yhbrer69evS9KZJgYsMSbxl0olJRIJVSoVW/IuyU40eprB6EEBNbrs+TT410f9MPz7osutvfIZXbIvnfg+HBwcaDgc2jaAbDZrp2z54E8A9wpVOp22JOWTEP/PZrNKJBIqlUorp24xvvzWAK7FkvlisWhbBDwZWS6XKhaLmk6n9oEonU6rUCgom81qc3NzpZ1RB9mKgIqKCob577e+9S3dvHlTt2/f1t7entUnHo9rY2PDyovCx8+YJKMKxmIxS9pHR0crRC5KDKIEwW/N4BpsO6DtvfcGSmW/37cyS8djG6LA/Uj8kDtPSr2a90GIkgJU1SgRSCQSRsQB2xPog9M8RgICAgJeNQSOH/BhEDh+4PiB4weOHzj+i48PtQaf02YYtF/5ylc0nU71237bb7PXfNd3fZeuXr2qL3/5y/q+7/s+ffnLX9anP/3plS0CP/zDP6wf+7Ef0ze/+U39+l//6z9MkQJeYJBYGDd3797VrVu3lMlk9OlPf1rdblfXrl0zw9KzDgJPs9k089NsNqt0Oq3NzU1TIgjATzIwnXatqBoI1hGG6DUWi8VaMhD1k/BeCwTc5XJpahzL+fl/v9+3tuh0OqpUKiqXy7aEPZvNKpfLaTqdajAYSDpOshgtkxQkmQKLSuiPpmeZud96QvJluwNbN5bLpZnW4sMxGo2UTqc1GAzsaPpsNmvm1pAmlvpzEhj3I2lBCNjicOfOHTWbTb377ru6d++e+v2+hsOh1Xtzc1NXr161k7Akrfij+H5jSX0ikdBisTDPD/7HSWn0CYTMX8N/jcfjlWQ6Go2MKLH1AQLc7Xatv+fzuYbD4X2EMHr9B403D08E+I56CTFiPEgnHywoC2QEUkM5AykICAgIWI/A8QMeBYHjB44fOH7g+IHjv/h47Id/i8VCf/pP/2l9//d/v777u79bkrS3t6d0Oq1qtbry2vPnz2tvb89e40kB/+d/68DgBGfdMPZVBcEAb4a7d+/q9u3bunr1qt566y3dvXtXGxsbWi6Xajabz7u4HxoEoGazaQkin8/rwoULKpfLRhYIXs8iQK0LyNIqMYj+z/8NcuBfn0wmVxQelqsvl8sVIsGSeZIM7yH5DodDNRoNbWxsaDQa2clYy+XSTqGaz+dmQMtyfEmmPvG64XC4omCy7J+l8tSZduc1EANO1RoOh+r1evadZAQxSKVSajabdqIV9UqlUtra2jL/l+VyaYpkr9ezNpjNZrp7964ajYZtCcAgOJvNqlAoGDEYjUbq9/v2vvF4rHa7fZ8CSTvEYsf+Jd5kF7WUtm82mxqNRivvXy6XZlA8GAzsC4W01+uZIsg1vdGxJ4OMAxRH6X6j3tPGmx+b3t8EYEqczWZVqVSsXyA00+nU2poT0p62Ch8QEBDwMiBw/IBHReD4geMHjh84fuD4Lz4e++Hfj//4j+sb3/iG/uf//J9Psjxr8aUvfUk/8zM/89TvE/BsQGC+d++evvnNbyqTyejixYsqFAq6dOmSZrOZdnd3LbGedRAsORkplUqZElYsFm35Nckxqtg96bI86O8fdF+v7njlxV/Hm8JKJ/4gEApUKk8mpJOkhNkuqhzX4zQszG+5x3K5NONanzhYxi6dqEQof/7eJEruHyVI9B/kA88JkkwqlVpJ9Hz1ej3F43HzwclkMpJkJ2JJMuLYaDTMULhYLKpYLKpWq6larSqbzZqaGe0fr776vuGemCd3Oh1L5ovFwlTSdrttqiWKLabVeKD4L5RJvw0DZc0TgnWJf914idYlujXAL+8vFAoqlUorXiUeo9HI5pjfxkFZg99HQEBAwMMhcPyAx0Xg+IHjB44fOP66sRU4/ouBx3r49xM/8RP61//6X+u///f/rsuXL9vfd3Z2NJlM1Gq1VpTB/f197ezs2Gt++Zd/eeV6+/v79r91+Omf/mn91E/9lP3e6XR05cqVxyl6wAsAgs/Nmzc1HA61s7OjT3/60yoWi7p69aoGg4GuX7++Yg561rFcLtXv9y3RpdNp1Wo1lctlSyqNRsOWLD9rP5SHISPRhIlPhF+mDTHwKhhH0KPseFNcn0x8Uu12u8rlcsrlcur1eivKFca3GARLJ2ST370C5RXXVCplniwojCiXvC7aJpRzNpsplUoZ0UENSyaTRgpQoLz3CEQHpa7Vamk8HhvBODw81NHRkbVNtVrV1taWEYN8Pm9bIXy5PJlDraXOJEL8Ow4ODtTv922MYfrLKV2A7QqogmxX8aebefWP+z8MPmhMs7XDG/Z6YlCpVHT58mVVKhVtbW1pOByq3W6bmjwajdRsNo1k+w8WgRAEBAQEPBwCxw/4MAgcP3D8wPEDx48icPwXB4/08G+5XOpP/sk/qX/xL/6FfvEXf1FvvPHGyv8/+9nPKpVK6T//5/+sL37xi5Kkd955R7du3dLnP/95SdLnP/95/eW//Jd1cHCgc+fOSZL+43/8jyqXy/rkJz+59r6ZTMaeqAe8HED1abfbunv3rt59912Nx2NdvnxZR0dHyuVy93k3vAxAwVouj5fCk1hYAl6tVi0Qo2Y8TZXwYcrrkyXJ3/8eVeOiryNhkgj9dgBe679ISpJWlr1THpbjFwoFKxs+GRzvDjFgywXkBJA02SKAHwgJFfIqnfh4TKdTJRIJDYdDZTIZ+zsKH2qndOIF41UuiC5EBy8T+r5YLCqXy2lra8vUQO/l4T1EOH2r0+mseLLwepI4RJSl/6iD0jEJgQhAoHgf1+OeXgWMLvl/lLHkvwPGT7FYVCaTsXtAFLy/inR8gtzR0ZERnfF4bEorKmB0jAUEBAQEPBiB4wc8KQSOHzh+4PiB40uB47+IeKSHfz/+4z+un//5n9e/+lf/SqVSyfw7KpWKcrmcKpWK/ugf/aP6qZ/6KW1sbKhcLutP/sk/qc9//vP6vu/7PknSD/3QD+mTn/yk/uAf/IP663/9r2tvb09/4S/8Bf34j/94SP6vGFgWf/36dRUKBV25ckUf+9jHdHR0ZD4PXg15WYDCwtLtUqmkZDKpYrGocrlsS+HxfyDJPA9ADKJkwP+MyrfOs2G5XJqXDypZ9Po+qXGsfTKZ1GQyMQ+KVqtlZcnn8+p0OioWizY+RqOREonEikmwdNzW8XhcW1tb9je2CpAUOUEKXxPamzb3JIOl9/P53IyHpePkBvnwSqUnBiTddrutbrdrHhb0/ZUrV7S5ualyuaxCobCiwOFvgTcS5KLVatn9Se54dEynU7XbbasLRtzes4TEjymwP/mL/ln3/XHH0jpAjmq1miqViqmHkDWvsKKuNxoNtdtt7e/vW/0CCQgICAh4fASOH/AkETh+4PiB4weOHzj+i4dHevj39/7e35MkfeELX1j5+z/6R/9If/gP/2FJ0t/+239b8XhcX/ziFzUej/XDP/zD+rt/9+/aaxOJhP71v/7X+rEf+zF9/vOfV6FQ0I/+6I/qL/2lv/ThahJw5oAKcXR0pOvXr6tYLFpwZ6l8VIV6mUAAZxk0y9UlWZLBTJbTmFBJn2WbRO/Fcm1+JllGX+f/5l8XxWnmsN6o1yuTeG0sFouVk7+kk2TCqWN4eIzHYztZLJFIqN/v2wlYkBsSUDKZtKQMhsOh/Uyy8v4VGPByOph0QihIypCPYrGoZDJpxAAjYrYaoDIOBgP1+307zWs0GmkwGBip4fQt6o3i7A168cegLSECqKH+RCy/dWJdfzwp0G4Qwlwup1QqpWw2e9+WC29kDNjywHaGZ2GiHRAQEPCyI3D8gCeJwPEDx5cCxw8cP3D8Fw2x5RlsUY4KD3g5gO/Dj/zIj+h3/+7frV/7tV/Tf/kv/0W7u7t65513XvpJT6AsFovK5/P2JcnMZDudzspR6y+iT4pPsp4AnGbCGiUJqIIojFE/h6g6hHEuxIDl8v76bC+o1WpmIhuPx1eOgwfxeNyW5aM0USYUN0grp0+R4LLZrM6fP2/mvovFwrYgdDodzedzlUolJRIJU+rK5bLS6bSOjo7U6/WUzWaN6CwWC9XrdR0dHRlh7PV6ajQaVlaWwHN/CIEnAqjPJE9+j/YVhOJpJtkoIYAIsP0hn88bmYrH4zo4OFCz2TRlOOqT87LHhaeFdrutcrn8vIsREBAQsBaB479cCBw/cHwpcPzA8QPHfxZ4GI7/2Kf9BgQ8KaBy1Ot1vffee2q323a8N0arL2IifFIgwE2nU1O3pGOlB5WkWq1qNBqZgkOgfJE8D0j0KHl+OXxUSTwN/C+aANg6kMvlTCUi8XoF0b+epf+LxUL9ft+W5KOgSTLi4H1F/Cla3pvEq265XG5FGRyPx8pms1oul+p2u0aG8P9YLBamALMVZjKZKJlMqt1uazQaqdfrrbQFWwdQzNgmIsmUZFQz79vhVUG/VJ528f3DlognSQg8AfBEAOUVoHZ6Xxbv2cK2B3+K14sy1gMCAgICAgI+GIHjB44PAsc/QeD4geM/L4SHfwHPHQS1Gzdu6Bd/8ReVTCZVLpfVbreVTqfNHPdlBt4gLPvudrsqFAoql8sql8s6f/68BoOBstmshsOhjo6OVnweHjdgrvPn+LCgPFEi4H/3/4+SiKj5MEBBIvF59RA1kMTiEyZ+GvF43I6R9z4cqICStLe3p2azafdFFUSRpPzFYtGS9HJ5bDYMcet0Okby+I6KyfaE+XxuS9/px8FgoPF4bGSQZf+5XM7uNxwO79tmgXEuv3OtdWosv9PGj9r/0b5a93/aKp/PK5lMmkcLW378aXdsC0L5w3AYsneaohwQEBAQEBDw4iNw/MDxA8cPHD9w/BcH4eFfwHMHEx9z03K5rEqlsmKOiynqywyviKE0DYdDWz5NQI3FYrYEnMAZTYTPU0X1iSv696hRsHQ/YVinIpIoaAMMa/k5SkbWlYlkNJvNlEql7JqoTiRors316Q9O2aIP8OLA64N7k/g56W0wGGi5XK5slWB5vqQVJc8v4fenknHyV1Tlgxj4NnoUX49oHzwsaB9IAKqf/x+nsvl28dsx/LYF+taXPfh8BAQEBAQEnG0Ejn+MwPEDxw8cP3D8FwHh4V/ACwHUlDt37ujNN9/U5uamFouFOp2O6vW6er3eK6MQENyn06mZwR4eHprCgr8FQZeTnDDJxcj2YcgByfRJtOu6a6xLRNG/kWA8sVmXsKIngvnrYdxL0qZtouoj6h+JnGXnEALMc315fTuSiP3yfO55584dOxFMkiU6vEr8cffJZNL6jLJxChdL40mS/hqeGERJgW+P01S70+CJ0IPex3UxTU6n0yoUCkqn0yqVStaHXqll+wNbJTyJXVeHgICAgICAgJcHgeOfIHD8wPEDxw94nggP/wJeGBCYR6ORJpOJMpmMXnvtNSWTSd2+fduOKX9V4JUulCZJK4a5+CvkcjkLsj7BPYyPwpMKyB90ndNUu2gi86qgvyZKGT/710a3EUA0/DVQzSTZdaJ+GLTXOj8T/+UTGtf0yd97kXiS5lUxiADw/RUlwZ4kRFXBdUTgcfr0Qe/xHh/41EBSUf8oW1T1ox38330dX2avn4CAgICAgIDA8aMIHD9wfP+/wPEDnhXCw7+AFwaoJKVSSXt7e3rttdf0hS98QV//+td148YNdbtddTqdV0o9QPEigfT7fVOeMMfNZrO6fPmy4vG4eVHU63XbUuCNcp/3Mut19z6tTNG/RRPpOuCNwVd0W8F4PJYkU95IWnhwsPWEJe541XgCQJL09yTRQ0i8PwfqIO+ljN77wpeR97HU3if/p5VEP+i6iURCqVRKhUJBlUpFuVxOlUrFlOvxeKxWq6XpdGrmx9F+9fUMCAgICAgIeHUQOP79CBz/BIHjB44f8GwQHv4FvDBgmTBLv7e3t80LY2trS4lEQt1u95UMLNSZJEVSwax2NBopHo9bIovFjo9492ohyc0rNi/aUuyHURYf5hokOhJ4VD2DENAOvM7/Hm2jqELpVS3/e9RPhC/KgxLpCdtp5CBan2cNFNZ0Om0kNJVKSZKZdONjMplMjLw9bwIaEBAQEBAQ8OIgcPzTETj+w/2f1wSO/2QQOP6rifDwL+CFAcHk8PDQlJQ333xTiURC/9//9//p/fff197enik7rypQmqRjg9Vut6t2u71i0JrJZJTJZHT+/Hk79h5fiel0qk6nYz4Y6xScZ40nuS3BL+uPngzGa3yi5T1+C4DfEhBN3nh3cCpXVDWEWGAe7AmGpPv8Rk6DJxTPEn4bRTqdViaTUa1W09bW/6+9O4+No7rjAP7da/a0vTjO5YTcHKWECGhJo6oUlSgkQoUW1FIaCWgpFBpaWiiKqAS0/FEQSCC1QrR/cElUtEXiUOmlcISjhACBcDYmSU1uJ8a395qdndc/ot/Lm/XGdhLsndl8P5LleM/3dux538xv5r02PZ9HPp/Hnj179CTGEoj8FjSJiIio/pjxx4cZf/TXYcY/Nsz4xIN/5CtS8crlchgaGkJ/fz8ikQimTJmCgYEBJBIJPcfA8bwDMgcZc94QWZkpGo3q08kB6CqhrNZkWRaUUnrS2eoKVa1KWJBIu2WQrlXVM1U/rno+kOrXNoNA9Wcl84JUt+VwP/uBtNeczyQUCulLJaRKKhP7lkqlERMU+7FfRERE5A/M+OPDjD86Zvwjw4xPJh78I9+R04r37duH9957D3PmzMFXvvIVRCIRzJ07F319fejq6vIMZsczqcgAh+aqsG0b4XAYuVwO0WgU6XQasVhMV3nMSqFUGeUyA5nbolQqeU51D9KO36wAjvfx5mPH6u9op+lXVxL9+NlVz2mSSCT0JL+y4pxlWXoC7kKhgKGhIR0MZKU6wJ9Bh4iIiPyHGf/IMOOPxIw/OmZ8Gg0P/pHvyI60WCyit7dXL3mfSCQwZcoUAEBPT8+oO+fjlTkQua6LUqkEx3EQjUY9lS8h1SCp/Mjz5HZz8l3zdeXnIJiodpqXCNS6zw+hQLaj2Va5XMFst2VZsCxLT0BsrjInlXqpAsqEyUHZ/kREROQPzPhHjxl/JGZ8Znw6Mjz4R77V19eHDz74ALZtY8GCBbAsCytWrMCePXswMDCAwcFBDAwMMBzUIDtu27Y9VUJzYJDVriKRCFKpFJLJpL5sQD7TYrGIXC6nX7NcLiOfz+tqofl+9QgM1UHHZJ62/3kz+1sdDMxLA+pJ5oWR0/kB6MG/qakJsVhMV3wzmQwSiQSGh4dRKBSQy+XQ19enq4LSXwYCIiIiOlbM+EePGZ8ZnxmfjhYP/pFvyZLi/f396O3tRTabxYwZM1AsFpHJZGDbNoaGhhgMRlFdyRMSDOQUcMuyRswdAkAHBXOOCFltTKpGMjiblw4c6Sn2x2K0cDCRZN4Q+bcfmNtJVvAyg4EEQbk8pFwu620p88eYl4Q4juOpDBMREREdK2b8Y8eMP3GY8alR8eAf+ZbMc3HgwAG8+uqrOPHEE3HeeechkUjgtNNOQ3d3N4aGhnSVisZP5gGRFbCKxSIikYgODDKwAAcHm3g8jubmZsTjcaTTaQDQp5XL3CKyIpTMF1EoFDyVQhloqgfRo9l2MiCHw+G6VqrMcFAP1VXeWCymq4GxWAxNTU16NTTXdTE8PKxX8srn8yiVSqhUKujt7dUrnJmTQ/sl8BAREVHjYMafOMz4nw9mfGpEPPhHvibzgnR3dyOdTuvBJ5vNwrbtESte0fiZA6pUjczLBsxVxWTwNyuGlmXpywrkPplzRKpLEjzM96geyM2qXnWVrXpgMgdic0LbiawMjvbaE/3+5uvXul3+bQaDSCQCy7IQi8V01RfwrnbmOI6eL6Y6CDAMEBER0URjxp84zPjjw4xPxxse/CPfK5VK6O7uRiQSwXvvvYdMJoO2tjZEIhFks1kAwNDQUN3nX2gEMngAGLHsey6X04HBHIzi8TiAQ4O2DE7ZbFYPVqFQCIVCQV9OII+XKqLjOHogk/etnnjWdV19enp1cDArmOZrm4Gx1uAt4aL68gUhfa31WvJZSDCSiqe0RS6RqB7czdc030+qstJ2CWYSzsz5W6LRKBzHQaFQQCgU0iFNKoCO46BcLqO3t1d/bpVKRU/oK+9phgEGAiIiIppMzPiThxmfGZ+IB//I9+T08uHhYXR3d8N1XbS3tyOZTCKRSCCRSCCXy/EU5s9JrUGyUqnoiYXNSwYikQgcx/EMejIwyuTCMmgB0NUo81KBcDgM27aRSCRgWZaeg8JxHH3Kv1lhNAcyeR0JNPI+5u+CDM61goE5SNfqtzlPRnX1Uvofi8U8zzcvU6hVxZRLKaoHZHMiZqWUpyJrfsk8HxKo5GfgYLiQgV+2mXyXeT74N0JERER+wIw/uZjxmfHp+MaDfxQISikMDQ1hy5YtmDlzpl4ZbNGiRejr60OpVEI+n4dt29zxTaDqwVgqeCIUCiGfzyMcDus5JmQwqx7MpcIlp6NHo1E9SW0qlfKEA7PyVv2ewKEBXgZpmdeiUCigUql4qmpmW6SKJqfFy4AvbTIrbTJgS1sTiQSi0SgymQxc19WDr3zP5/NQSo1YjUueJ4O2DORy+r4EJ2mrvLe8dqVSQV9fHxzHQalU0v2Xz1/aWOs7/zaIiIjIT5jx/YEZnxmfGh8P/lFg2LaNnp4eJJNJlMtlRCIRtLa26tPSbdtm1WMSVJ/KPtalGFIFk8FbgkE8HtcDvrxOpVLRlwZIRU4GYQkiUuUCvKfmy2MB6IqZOZBHIhHE43HP/DHyPHm8tFVCiVTipL8SGGKxGNLpNCzLQlNTE5Q6OG+N67ooFos6uLiui1Qqpd8DAFKpFKLRqH68hB1z7g6pJkpwkkszpO+5XE5fMkFEREQUZMz4/sCMz4xPjY0H/ygwZPLS/v5+bNmyBdlsFgsWLECpVEJvby8+++wzfPrppygWi/VuKhnMKqKpWCzqCh0AlMtlDA4O6nlGgEOXDEhl7nBzV5in28t7mXN0SIWtXC4jHA7rSxPkveRncy4UqSaaK6SZ4SAUOriCWj6fR6VS0Sudyf1SsZPfRwmt8XgckUhkxKpb1fOECOmvPNZ8DhEREVHQMeMHEzM+Mz4FCw/+UWDIjr5QKKCrqwuhUAhTpkyB67qYOnUqlFLYs2cPg4HPVFcRRfXAVl3hql7pq9bttebbAA6dIi+3y+n+UkGUQVkG/OpT5mXglcqgrK5lzmUiVT6pVkqVz5yPQ95fLlNQSqFUKukwYgaNWp8XK9xERETU6Jjxg4kZnxmfgoUH/yhwbNvGgQMHAAB79uxBMpnEvHnzkM1msWPHDj1PAqsmwWZOplurCiiPqQ4N1SQQhEIhlMtlfVlC9STB1ZMBy/3m5Mfme5qrdskAb75OrSAklyiYl0YcLgAwFBAREdHxhBn/+MCMz4xP9cGDfxQ4juNgYGAA0WgUPT09yGazmDZtGlKpFDKZDIaGhnTFhoJvrEEzaAMoAysRERHRSMz4xxdmfKLJFR77IUT+4rouCoUC+vr68MEHH2DLli2wLAttbW2YN28e5s+fj3Q67TktnIiIiIiI/IsZn4ho4nDPSYEjqy0NDAxg69at6OzshGVZaGlpwaxZszBr1iwkEgl9KjcREREREfkbMz4R0cThZb8UWFId7O3txRtvvIGmpiaUSiVYloVUKoVSqYRcLqeXZCeiYDncXC/Vc7JUX2YhK8IJud9cMc6c60Ves1wueyZ8NueFqTVvDBEREX3+mPGJGhszfn3w4B8Fluu6egn2jRs3orm5GYsWLUIikUA6nYZt2ygWiwwGREeh1iTMk/3+1au8SZtc10UkEkEsFtMrBAKHAoNlWfp1zFXZJAhYloVwOIxYLOZZCa5QKOhV4szAISFCHkdEREQThxmfaOIw4x+/GZ8H/yjwKpUK+vv79TLskUgEfX19OjQQHc+qVzMzVyELh8N6gJRKGXCoGuY4DiqVSs0BWh4nVTTbtnXFTR5rkvl55PnSFvP1zDZFo1HPamvRaBSWZXkGbBmshWVZnteTtshz5LXMuYKUUiiVSnAcB7Ztw3Ec/b7pdBqWZennVioVz380zBXgzJXe5D4iIiI6esz4RIfHjM+Mf6R48I8Cz3Ec9PT0AAD279/vqWYwGNDxTAZJqX5Fo1GEQiFUKhW4rot4PI5IJIJ0Oo14PK4HVBkAy+UySqWSHsjlS17XdV39ONd1dcVNHm+2o/o0fBn4zVP7pa3RaBTxeByxWAyO48B1XaRSKaTTaQCHBuRyuazfIxaL6fvL5TLC4bCuDkqAKBaLnkFcqoDDw8MolUooFosol8t6/9Hc3IyWlhaUy2WUy2XdVyFtkM9Lvh8vlw4QERFNJGZ8otqY8ZnxjwYP/lFDkJ1K9bwAQf7jJKrFrKRVV+vM6p8MjOZAHo0e3OWXSiW4rgvLshCNRnVwcBxHf8mgVy6X9ftIZS4ajSKRSOhB1nEcJJNJhMNhxONxPbeGPMdsq1TVJBS4rusJ8PJcszonlUf5+5b3tG1b3xaNRpHL5fR7mMHAfG35vADoMwnk/aore4VCAaFQSH8m8lz5fCORCOLxuG6P+R+SQqGgA0L1l/TBbFP1v4mIiIgZn44fzPjM+BONB/+oYZjX/RM1InMyWxmYzFAQj8d19S8ajaKpqQmRSERX7SQYDA8Po1Kp6EFeBu9CoaAn0JbKofxNKaV0pS4Wi6GlpQXAwQHOPI0/kUigUqmgr68PAJBOpz2XEJgTdEtlzvy7LZVK+jIEM1AUCgUUCgX9PNu2kc/n9UAulzbIz1JhNMOTWXGUAV8uZ7Bt23N6v+u6GBwcxPDwsP45kUggkUjoz9uyLKTTaR0MZI6ScrmMvr4+/fryOco+yvy5OjD4JRwQERH5BTM+NTpmfGb8ycCDf0REPlRd/TMHfPP0fbOKBUBXuWSwlQFQKaXnx5BJsm3b9pzqn8/n9QApA5o5aJXLZRQKBc/7SUXeDAcSAIBDlTVpm1nJM+fiMNtvTsIr38vlMmzb9vSpVCp52iCvI8HAcZwRFVMASKVSsCwLmUxGh4VQKITBwUEUCgX09/djeHgY+XzeU92TCqm0xbZtzyUC4XAYqVRKV1zNqqQ5ITEA/TlLQJAQISGu1ufhh9BAREREREePGZ8Zv/rzmKyMz4N/REQ+Ul35M0/vj8fjSCQSaGlp0ZUx13V1JU0Gm1KpBKUU+vv7PRPWyqAkP9cy2uDjOA4KhQLC4bCu+pmPl4EXwIjBXQZXs9Inbam+lKf68zA/F3OuEfMU/+rqGnBo5a9IJKIHf+DQ3CGnnHIKWltbMXv2bGQyGXR3d2NoaAiffPIJdu/ejR07dujKowziEk7kfWtdHhCNRpFOpz2XW0gfM5mMrsA6jqNDWrFYRKVS0eFMVF+uQERERETBw4w/8vMwPxdm/InHg39ERHUgg1T1HB4ySa4EA/OUdzmVXObzMAOBWVGSKmD1/Bbm6f3HMsjUuvzGHJzlMdXPMfstRgsF5vPMUFEdRmqFAjNEmOEqkUigtbUVLS0tmDZtGlpbW9He3o6WlhZks1kUCgUkk0nMnDlT39bf34+BgQE9L4h52YAZbGzbRqFQQCQS0Zc1yOTIZltDoZCemFhCmrndzWqsBAPpj1kdlc/FnC/F/Lx4sJCIiIhocjHjH8SM77+Mz4N/RER1IINVLBbTFaVYLIZkMqnn6QiHwygWi8jn8/oUeBmMyuUycrmc57TyyTp1vDoYSOVtPHPyHGsgqVWFrPWaUgmUil00GkUmk0FTUxMWLlyIqVOn4tRTT0VbWxtOPvlktLa26pDW29uL4eFhvP/+++jo6MAnn3yCjo4O5PN5DA4O6s+/WCxiaGhIbxO5zMJsm7nymTlni7Q5mUwiEokgkUggHA4jk8nAsiy9XSWMxONxxONxDA4O6mqvfN5yaYJUg83QcqyfORERERGNHzP+0b0vM/7EZ3we/CMimkDVp7TL6lxyqrjcHo/H9eABQM8zUSqV9IpcMs+HVP7MyWbrfaZXPd7/cO8n1UAZbGVglsE1FDq4Alkul0MsFtNVVQlp6XQakUgE06dPh23b+nMeHBxEX18fSqUScrmcZzJic4JjMyDJz1LZA6CDgfwsVUSZrDkajXrmAZHnAIdWOZPAI8+rVCp6ImZprzkBscy9QkRERETHjhl/Yt+zFmb8Y8v4PPhHRDSBZGCSSWdPOOEEfWp6NBrVA49cDlAsFj1f5nL31RU3v5zRZVYk68G8zEBCgWVZyGaziEajcBwH0WgUzc3NyGQycBwH+XwenZ2dSCQSaG9vRyaT0fN3NDU1IZPJIB6PY+HChVi0aBH27NmDAwcOYO/evRgcHMRnn32G3t5e7Nq1C7ZtI5fL6csyHMdBLpfTg78EAznFvxZZ1U2+i1QqhWQy6emnVBebmpr0wC+/P9I3MzhKoNy7d+8EbgUiIiKi4wcz/sRjxv98Mz4P/hERfY5kx159CjgAfbusliWn+UvFKBKJeE7vNieCDcKCD/Vonzk5sFRYY7GYXolLKm1SiZNBu1KpYHBwELFYDPv379eVQFktDYA+9V+2WyKRQCqV0qfhO46DE044AaVSCfF4XG9Ps3orn4uEu+q5QWS7mnOdmHOeyGpt8jpSEayeVFlulz7KbcDByY+r52EhIiIiovFjxp9czPjQ/fu8Mj4P/hERfU7C4TCSySRisZiu/mWzWUQiET2ZrOysBwYGUCwWUSgUYNu23tHL6du1Jrj1s3qGgup5PxKJhF4xLRQKYXh4GABQLBZRLpf1z/I9Foth586dWLZsGebNm6dff//+/ejp6UE+n0e5XNbzdci8Lc3NzWhpadFBzrZtDA0NoVAoYPfu3boS6DiOnkekelCXOV6qV0yTYGFO+iyPMyc6Nn+WcJlIJEZ8H2ueFiIiIiKqjRl/cjHjT0zG58E/IqKjYFagZCcdiUR0MEgkEojFYgCg52iQ08FlbgapAJpzRQQpDEyU6lP85bu56pd83lKxM7eBrKolz5UB1nEczzwdxWIRANDX14cDBw5g9+7d+jXC4TB6e3sxMDCgV9+SldZk8mbXdfXt5hwvlmWhUCh4qru2baNSqejfF+mHhEGzreaqaTL4y31mqJDnmZ9R9WdirixGRERERKNjxp84zPj1zfg8+EdEdITMU8RbW1sRi8WQyWQ8k7TGYjG4rove3l4Ui0X09/fr08LNCVr9MJGvyTwdfSKZA545MW719+oVvWSAj8ViSKVS+vXkM5UqWDQa1afmy2pd8npSrXNdF+FwGP/73//Q3d2NXbt2IZPJIJPJIJFI6EsK5FIBeQ/LstDU1KQncC4UCnoQnz59OiqVCtrb21EsFtHd3Y1isYhkMolKpYJ0Oo1QKIRiseip+Am51EAqmHIJSbFY9Fw6ICuF1VIsFj0hgZf8EhEREY2NGf/YMeP7N+MH8uCfX/6AiOj4JfshGbBkJ1xdxTFX8ZKBSp7vx33ZZLWp+n3Mn815MczbqitgZrCQ7zLgy8BproxVLpdHTMirlNIreoVCIeTzeRQKBcTjcaRSKcTjccRiMcRiMc/p+qFQyLNKm23biEajsCxLv5Zc/lHdfvmdMQd6sx/V4ajWZzTa74/cLmHIDHt+/J0jIhLcRxFRvTHjf77vw4zvn4wfUn78zRzD7t27ceKJJ9a7GURERIGya9cuzJ49u97NICKqiRmfiIjoyI0n4wfy4J/ruujo6MBpp52GXbt2obm5ud5NOmaDg4M48cQTG6I/jdQXoLH600h9AdgfP2ukvgDB749SCkNDQ2hvb/dUK4mI/IQZ398aqS9AY/WnkfoCNFZ/GqkvAPvjN0eS8QN52W84HMasWbMAAM3NzYHcSIfTSP1ppL4AjdWfRuoLwP74WSP1BQh2f1paWurdBCKiUTHjB0Mj9QVorP40Ul+AxupPI/UFYH/8ZLwZn+V/IiIiIiIiIiKiBsWDf0RERERERERERA0qsAf/4vE47rjjDsTj8Xo35XPRSP1ppL4AjdWfRuoLwP74WSP1BWi8/hAR+VWj7W8bqT+N1BegsfrTSH0BGqs/jdQXgP0JskAu+EFERERERERERERjC+yZf0RERERERERERDQ6HvwjIiIiIiIiIiJqUDz4R0RERERERERE1KB48I+IiIiIiIiIiKhBBfbg3wMPPIB58+YhkUhg6dKlePPNN+vdpDHddddd+PKXv4ympiZMmzYN3/rWt9DR0eF5zHnnnYdQKOT5uu666+rU4tH9+te/HtHWU089Vd9fLBaxZs0aTJkyBZlMBpdeein2799fxxYf3rx580b0JRQKYc2aNQD8v11eeeUVfPOb30R7eztCoRCeeeYZz/1KKdx+++2YOXMmkskkli9fjq1bt3oe09vbi9WrV6O5uRnZbBZXX301hoeHJ7EXB43Wl3K5jLVr12Lx4sVIp9Nob2/HFVdcgb1793peo9b2vPvuuye5JweNtW2uuuqqEW1duXKl5zFB2DYAav4NhUIh3Hvvvfoxfto249knj2c/tnPnTlx44YVIpVKYNm0abrnlFjiOM5ldISJqGMz49dVI+R5gxgeCkSOZ8f27bYBgZXzm+8ML5MG/v/zlL7jppptwxx134J133sGSJUtwwQUX4MCBA/Vu2qhefvllrFmzBm+88QbWrVuHcrmMFStWIJfLeR53zTXXYN++ffrrnnvuqVOLx/bFL37R09bXXntN3/eLX/wCf/vb3/Dkk0/i5Zdfxt69e3HJJZfUsbWH99Zbb3n6sW7dOgDAd77zHf0YP2+XXC6HJUuW4IEHHqh5/z333IPf/e53+MMf/oCNGzcinU7jggsuQLFY1I9ZvXo1PvroI6xbtw7PPfccXnnlFVx77bWT1QVttL7k83m88847uO222/DOO+/gqaeeQkdHBy666KIRj73zzjs92+unP/3pZDR/hLG2DQCsXLnS09YnnnjCc38Qtg0ATx/27duHhx9+GKFQCJdeeqnncX7ZNuPZJ4+1H6tUKrjwwgth2zZef/11PPbYY3j00Udx++2316NLRESBxozvD42S7wFmfCAYOZIZ37/bBghWxme+H4UKoHPOOUetWbNG/1ypVFR7e7u666676tiqI3fgwAEFQL388sv6tq9//evqxhtvrF+jjsAdd9yhlixZUvO+/v5+FYvF1JNPPqlv++9//6sAqA0bNkxSC4/ejTfeqBYuXKhc11VKBWu7AFBPP/20/tl1XTVjxgx177336tv6+/tVPB5XTzzxhFJKqY8//lgBUG+99ZZ+zD//+U8VCoXUnj17Jq3t1ar7Usubb76pAKgdO3bo2+bOnavuv//+iW3cUajVnyuvvFJdfPHFh31OkLfNxRdfrL7xjW94bvPrtlFq5D55PPuxf/zjHyocDquuri79mAcffFA1NzerUqk0uR0gIgo4Zvz6a+R8rxQzvlLByZHM+PXRaBmf+f6QwJ35Z9s2Nm3ahOXLl+vbwuEwli9fjg0bNtSxZUduYGAAANDa2uq5/U9/+hPa2tpw+umn49Zbb0U+n69H88Zl69ataG9vx4IFC7B69Wrs3LkTALBp0yaUy2XPdjr11FMxZ84c328n27bx+OOP44c//CFCoZC+PUjbxdTZ2Ymuri7PtmhpacHSpUv1ttiwYQOy2Sy+9KUv6ccsX74c4XAYGzdunPQ2H4mBgQGEQiFks1nP7XfffTemTJmCM888E/fee6+vT9Nev349pk2bhlNOOQXXX389enp69H1B3Tb79+/H3//+d1x99dUj7vPrtqneJ49nP7ZhwwYsXrwY06dP14+54IILMDg4iI8++mgSW09EFGzM+P7RiPkeYMYXQciRADO+XwUt4zPfHxKtdwOO1GeffYZKpeLZEAAwffp0bNmypU6tOnKu6+LnP/85vvrVr+L000/Xt3//+9/H3Llz0d7ejvfffx9r165FR0cHnnrqqTq2tralS5fi0UcfxSmnnIJ9+/bhN7/5Db72ta/hww8/RFdXFyzLGrGznj59Orq6uurT4HF65pln0N/fj6uuukrfFqTtUk0+71p/M3JfV1cXpk2b5rk/Go2itbXV19urWCxi7dq1uPzyy9Hc3Kxv/9nPfoazzjoLra2teP3113Hrrbdi3759uO++++rY2tpWrlyJSy65BPPnz8f27dvxq1/9CqtWrcKGDRsQiUQCu20ee+wxNDU1jbgUyK/bptY+eTz7sa6urpp/W3IfERGNDzO+PzRqvgeY8UUQciQzvn+3TZAyPvO9V+AO/jWKNWvW4MMPP/TMoQHAc43/4sWLMXPmTJx//vnYvn07Fi5cONnNHNWqVav0v8844wwsXboUc+fOxV//+lckk8k6tuzYPPTQQ1i1ahXa29v1bUHaLseLcrmM7373u1BK4cEHH/Tcd9NNN+l/n3HGGbAsCz/+8Y9x1113IR6PT3ZTR/W9731P/3vx4sU444wzsHDhQqxfvx7nn39+HVt2bB5++GGsXr0aiUTCc7tft83h9slERERHIugZv1HzPcCMHxTM+P4WpIzPfO8VuMt+29raEIlERqzGsn//fsyYMaNOrToyN9xwA5577jm89NJLmD179qiPXbp0KQBg27Ztk9G0Y5LNZnHyySdj27ZtmDFjBmzbRn9/v+cxft9OO3bswPPPP48f/ehHoz4uSNtFPu/R/mZmzJgxYjJtx3HQ29vry+0loWDHjh1Yt26dpyJYy9KlS+E4Dj799NPJaeAxWLBgAdra2vTvVtC2DQC8+uqr6OjoGPPvCPDHtjncPnk8+7EZM2bU/NuS+4iIaHyY8f2pEfI9wIxv8nOOZMb377YBgpXxme9HCtzBP8uycPbZZ+OFF17Qt7muixdeeAHLli2rY8vGppTCDTfcgKeffhovvvgi5s+fP+ZzNm/eDACYOXPmBLfu2A0PD2P79u2YOXMmzj77bMRiMc926ujowM6dO329nR555BFMmzYNF1544aiPC9J2mT9/PmbMmOHZFoODg9i4caPeFsuWLUN/fz82bdqkH/Piiy/CdV0dgvxCQsHWrVvx/PPPY8qUKWM+Z/PmzQiHwyNOrfej3bt3o6enR/9uBWnbiIceeghnn302lixZMuZj67ltxtonj2c/tmzZMnzwwQee8CZh9bTTTpucjhARNQBmfH9qhHwPMOMHIUcy4/t324ggZHzm+1HUc7WRo/XnP/9ZxeNx9eijj6qPP/5YXXvttSqbzXpWY/Gj66+/XrW0tKj169erffv26a98Pq+UUmrbtm3qzjvvVG+//bbq7OxUzz77rFqwYIE699xz69zy2m6++Wa1fv161dnZqf7zn/+o5cuXq7a2NnXgwAGllFLXXXedmjNnjnrxxRfV22+/rZYtW6aWLVtW51YfXqVSUXPmzFFr16713B6E7TI0NKTeffdd9e677yoA6r777lPvvvuuXh3r7rvvVtlsVj377LPq/fffVxdffLGaP3++KhQK+jVWrlypzjzzTLVx40b12muvqZNOOkldfvnlvuqLbdvqoosuUrNnz1abN2/2/B3Jykuvv/66uv/++9XmzZvV9u3b1eOPP66mTp2qrrjiiknvy1j9GRoaUr/85S/Vhg0bVGdnp3r++efVWWedpU466SRVLBb1awRh24iBgQGVSqXUgw8+OOL5fts2Y+2TlRp7P+Y4jjr99NPVihUr1ObNm9W//vUvNXXqVHXrrbfWo0tERIHGjF9/jZbvlWLGD0KOZMb377YRQcn4zPeHF8iDf0op9fvf/17NmTNHWZalzjnnHPXGG2/Uu0ljAlDz65FHHlFKKbVz50517rnnqtbWVhWPx9WiRYvULbfcogYGBurb8MO47LLL1MyZM5VlWWrWrFnqsssuU9u2bdP3FwoF9ZOf/ESdcMIJKpVKqW9/+9tq3759dWzx6P79738rAKqjo8NzexC2y0svvVTzd+vKK69USinluq667bbb1PTp01U8Hlfnn3/+iH729PSoyy+/XGUyGdXc3Kx+8IMfqKGhIV/1pbOz87B/Ry+99JJSSqlNmzappUuXqpaWFpVIJNQXvvAF9dvf/tYz0PqlP/l8Xq1YsUJNnTpVxWIxNXfuXHXNNdeM+E9OELaN+OMf/6iSyaTq7+8f8Xy/bZux9slKjW8/9umnn6pVq1apZDKp2tra1M0336zK5fIk94aIqDEw49dXo+V7pZjxg5AjmfH9u21EUDI+8/3hhZRS6kjOFCQiIiIiIiIiIqJgCNycf0RERERERERERDQ+PPhHRERERERERETUoHjwj4iIiIiIiIiIqEHx4B8REREREREREVGD4sE/IiIiIiIiIiKiBsWDf0RERERERERERA2KB/+IiIiIiIiIiIgaFA/+ERERERERERERNSge/CMiIiIiIiIiImpQPPhHRERERERERETUoHjwj4iIiIiIiIiIqEHx4B8REREREREREVGD+j+XAQoJa1J+jQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [(0, 0, 1, i) for i in np.linspace(0, 1, 100)]\n",
    "blue_cmap = mcolors.LinearSegmentedColormap.from_list('blue_alpha', colors)\n",
    "\n",
    "colors = [(1, 0, 0, i) for i in np.linspace(0, 1, 100)]\n",
    "red_cmap = mcolors.LinearSegmentedColormap.from_list('red_alpha',colors)\n",
    "for i in range(1,3):                                               \n",
    "    val_data_example=train_dataset[i]\n",
    "    # Select a slice to visualize (e.g., the middle slice)\n",
    "    slice_idx = val_data_example['image'].shape[3] // 2  # adjust to the depth dimension\n",
    "    print(slice_idx)\n",
    "    # Get image and labels\n",
    "    image = val_data_example['image'][0, :, :, slice_idx].detach().cpu()\n",
    "    label3 = val_data_example['label'][2, :, :, slice_idx].detach().cpu()\n",
    "    label2 = val_data_example['label'][1, :, :, slice_idx].detach().cpu()\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"image\")\n",
    "    plt.imshow(image, cmap='gray')\n",
    "\n",
    "    # Overlay the labels\n",
    "    # We're using different colors and transparency (alpha) for each label\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"image + label\")\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.imshow(label2, cmap=blue_cmap, alpha=0.5)  # Use alpha for transparency\n",
    "    plt.imshow(label3, cmap=red_cmap, alpha=0.5)  # Change 'jet' to any colormap you prefer\n",
    "\n",
    "    # plt.axis('off')  # To not show axis\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your UNet model as a function\n",
    "def unet(in_channels, out_channels):\n",
    "    model = SegResNet(\n",
    "        blocks_down=[1, 2, 2, 4],\n",
    "        blocks_up=[1, 1, 1],\n",
    "        init_filters=16,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        dropout_prob=0.2,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "device_ids = [0,1]  # Specify the GPU device IDs to be used\n",
    "print(\"Using\", num_gpus, \"GPUs!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  3 GPUs!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your UNet model\n",
    "in_channels = 1\n",
    "out_channels = 3\n",
    "model = unet(in_channels, out_channels)\n",
    "model = model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, device_ids=device_ids)\n",
    "\n",
    "\n",
    "# Rest of the code\n",
    "max_epochs = 300\n",
    "val_interval = 1\n",
    "VAL_AMP = True\n",
    "\n",
    "\n",
    "loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "\n",
    "def inference(input):\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=(240, 240, 160),\n",
    "            sw_batch_size=1,\n",
    "            predictor=model,\n",
    "            overlap=0.5,\n",
    "        )\n",
    "\n",
    "    if VAL_AMP:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return _compute(input)\n",
    "    else:\n",
    "        return _compute(input)\n",
    "\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "----------\n",
      "epoch 1/100\n",
      "1/224, train_loss: 0.7052, step time: 2.3770\n",
      "2/224, train_loss: 0.7001, step time: 0.3698\n",
      "3/224, train_loss: 0.6850, step time: 0.3172\n",
      "4/224, train_loss: 0.6822, step time: 0.3178\n",
      "5/224, train_loss: 0.6799, step time: 0.4006\n",
      "6/224, train_loss: 0.6811, step time: 0.3988\n",
      "7/224, train_loss: 0.6786, step time: 0.3951\n",
      "8/224, train_loss: 0.6782, step time: 0.4051\n",
      "9/224, train_loss: 0.6809, step time: 0.3196\n",
      "10/224, train_loss: 0.6762, step time: 0.3192\n",
      "11/224, train_loss: 0.6806, step time: 0.3194\n",
      "12/224, train_loss: 0.6753, step time: 0.3169\n",
      "13/224, train_loss: 0.6772, step time: 0.3167\n",
      "14/224, train_loss: 0.6722, step time: 0.4062\n",
      "15/224, train_loss: 0.6777, step time: 0.3192\n",
      "16/224, train_loss: 0.6773, step time: 0.3177\n",
      "17/224, train_loss: 0.6781, step time: 0.3931\n",
      "18/224, train_loss: 0.6788, step time: 0.3175\n",
      "19/224, train_loss: 0.6779, step time: 0.3175\n",
      "20/224, train_loss: 0.6756, step time: 0.3157\n",
      "21/224, train_loss: 0.6774, step time: 0.4025\n",
      "22/224, train_loss: 0.6772, step time: 0.3177\n",
      "23/224, train_loss: 0.6754, step time: 0.3967\n",
      "24/224, train_loss: 0.6753, step time: 0.3173\n",
      "25/224, train_loss: 0.6757, step time: 0.3167\n",
      "26/224, train_loss: 0.6772, step time: 0.3188\n",
      "27/224, train_loss: 0.6746, step time: 0.4117\n",
      "28/224, train_loss: 0.6782, step time: 0.3173\n",
      "29/224, train_loss: 0.6769, step time: 0.3145\n",
      "30/224, train_loss: 0.6775, step time: 0.3703\n",
      "31/224, train_loss: 0.6779, step time: 0.4113\n",
      "32/224, train_loss: 0.6773, step time: 0.3189\n",
      "33/224, train_loss: 0.6736, step time: 0.3850\n",
      "34/224, train_loss: 0.6766, step time: 0.3152\n",
      "35/224, train_loss: 0.6763, step time: 0.3675\n",
      "36/224, train_loss: 0.6779, step time: 0.3902\n",
      "37/224, train_loss: 0.6769, step time: 0.3180\n",
      "38/224, train_loss: 0.6776, step time: 0.3157\n",
      "39/224, train_loss: 0.6772, step time: 0.3824\n",
      "40/224, train_loss: 0.6758, step time: 0.4035\n",
      "41/224, train_loss: 0.6770, step time: 0.4119\n",
      "42/224, train_loss: 0.6762, step time: 0.3201\n",
      "43/224, train_loss: 0.6762, step time: 0.3186\n",
      "44/224, train_loss: 0.6763, step time: 0.3199\n",
      "45/224, train_loss: 0.6759, step time: 0.4050\n",
      "46/224, train_loss: 0.6753, step time: 0.3170\n",
      "47/224, train_loss: 0.6744, step time: 0.4043\n",
      "48/224, train_loss: 0.6750, step time: 0.3140\n",
      "49/224, train_loss: 0.6759, step time: 0.4063\n",
      "50/224, train_loss: 0.6739, step time: 0.3905\n",
      "51/224, train_loss: 0.6772, step time: 0.3903\n",
      "52/224, train_loss: 0.6746, step time: 0.3867\n",
      "53/224, train_loss: 0.6774, step time: 0.3959\n",
      "54/224, train_loss: 0.6752, step time: 0.4026\n",
      "55/224, train_loss: 0.6744, step time: 0.3147\n",
      "56/224, train_loss: 0.6743, step time: 0.3168\n",
      "57/224, train_loss: 0.6744, step time: 0.4084\n",
      "58/224, train_loss: 0.6740, step time: 0.3723\n",
      "59/224, train_loss: 0.6727, step time: 0.3191\n",
      "60/224, train_loss: 0.6739, step time: 0.3212\n",
      "61/224, train_loss: 0.6739, step time: 0.3158\n",
      "62/224, train_loss: 0.6732, step time: 0.3164\n",
      "63/224, train_loss: 0.6740, step time: 0.3182\n",
      "64/224, train_loss: 0.6763, step time: 0.4172\n",
      "65/224, train_loss: 0.6742, step time: 0.3965\n",
      "66/224, train_loss: 0.6752, step time: 0.3157\n",
      "67/224, train_loss: 0.6760, step time: 0.3151\n",
      "68/224, train_loss: 0.6738, step time: 0.3917\n",
      "69/224, train_loss: 0.6772, step time: 0.3751\n",
      "70/224, train_loss: 0.6755, step time: 0.3166\n",
      "71/224, train_loss: 0.6753, step time: 0.3163\n",
      "72/224, train_loss: 0.6731, step time: 0.3987\n",
      "73/224, train_loss: 0.6741, step time: 0.3763\n",
      "74/224, train_loss: 0.6754, step time: 0.3158\n",
      "75/224, train_loss: 0.6708, step time: 0.3807\n",
      "76/224, train_loss: 0.6712, step time: 0.3741\n",
      "77/224, train_loss: 0.6735, step time: 0.3152\n",
      "78/224, train_loss: 0.6752, step time: 0.3183\n",
      "79/224, train_loss: 0.6706, step time: 0.3839\n",
      "80/224, train_loss: 0.6755, step time: 0.4014\n",
      "81/224, train_loss: 0.6732, step time: 0.3139\n",
      "82/224, train_loss: 0.6733, step time: 0.4011\n",
      "83/224, train_loss: 0.6717, step time: 0.4128\n",
      "84/224, train_loss: 0.6765, step time: 0.3724\n",
      "85/224, train_loss: 0.6767, step time: 0.3161\n",
      "86/224, train_loss: 0.6721, step time: 0.3146\n",
      "87/224, train_loss: 0.6708, step time: 0.3157\n",
      "88/224, train_loss: 0.6707, step time: 0.3158\n",
      "89/224, train_loss: 0.6744, step time: 0.3931\n",
      "90/224, train_loss: 0.6693, step time: 0.3185\n",
      "91/224, train_loss: 0.6710, step time: 0.3739\n",
      "92/224, train_loss: 0.6710, step time: 0.3702\n",
      "93/224, train_loss: 0.6762, step time: 0.4033\n",
      "94/224, train_loss: 0.6764, step time: 0.3159\n",
      "95/224, train_loss: 0.6751, step time: 0.3852\n",
      "96/224, train_loss: 0.6685, step time: 0.4047\n",
      "97/224, train_loss: 0.6767, step time: 0.3179\n",
      "98/224, train_loss: 0.6748, step time: 0.3982\n",
      "99/224, train_loss: 0.6687, step time: 0.3798\n",
      "100/224, train_loss: 0.6759, step time: 0.3873\n",
      "101/224, train_loss: 0.6749, step time: 0.3177\n",
      "102/224, train_loss: 0.6714, step time: 0.3184\n",
      "103/224, train_loss: 0.6678, step time: 0.3745\n",
      "104/224, train_loss: 0.6764, step time: 0.3153\n",
      "105/224, train_loss: 0.6746, step time: 0.3152\n",
      "106/224, train_loss: 0.6763, step time: 0.3846\n",
      "107/224, train_loss: 0.6748, step time: 0.3954\n",
      "108/224, train_loss: 0.6743, step time: 0.3164\n",
      "109/224, train_loss: 0.6711, step time: 0.3696\n",
      "110/224, train_loss: 0.6722, step time: 0.3181\n",
      "111/224, train_loss: 0.6689, step time: 0.3153\n",
      "112/224, train_loss: 0.6738, step time: 0.3770\n",
      "113/224, train_loss: 0.6724, step time: 0.3689\n",
      "114/224, train_loss: 0.6750, step time: 0.3978\n",
      "115/224, train_loss: 0.6735, step time: 0.3156\n",
      "116/224, train_loss: 0.6737, step time: 0.3133\n",
      "117/224, train_loss: 0.6661, step time: 0.3751\n",
      "118/224, train_loss: 0.6745, step time: 0.4054\n",
      "119/224, train_loss: 0.6768, step time: 0.3177\n",
      "120/224, train_loss: 0.6698, step time: 0.3150\n",
      "121/224, train_loss: 0.6753, step time: 0.3896\n",
      "122/224, train_loss: 0.6697, step time: 0.3727\n",
      "123/224, train_loss: 0.6763, step time: 0.3977\n",
      "124/224, train_loss: 0.6731, step time: 0.4155\n",
      "125/224, train_loss: 0.6762, step time: 0.3919\n",
      "126/224, train_loss: 0.6701, step time: 0.3807\n",
      "127/224, train_loss: 0.6714, step time: 0.3178\n",
      "128/224, train_loss: 0.6615, step time: 0.3864\n",
      "129/224, train_loss: 0.6642, step time: 0.3790\n",
      "130/224, train_loss: 0.6676, step time: 0.3160\n",
      "131/224, train_loss: 0.6744, step time: 0.3926\n",
      "132/224, train_loss: 0.6724, step time: 0.3152\n",
      "133/224, train_loss: 0.6652, step time: 0.3929\n",
      "134/224, train_loss: 0.6753, step time: 0.3863\n",
      "135/224, train_loss: 0.6729, step time: 0.3135\n",
      "136/224, train_loss: 0.6708, step time: 0.3735\n",
      "137/224, train_loss: 0.6767, step time: 0.3154\n",
      "138/224, train_loss: 0.6730, step time: 0.3172\n",
      "139/224, train_loss: 0.6699, step time: 0.3879\n",
      "140/224, train_loss: 0.6716, step time: 0.3777\n",
      "141/224, train_loss: 0.6726, step time: 0.3151\n",
      "142/224, train_loss: 0.6604, step time: 0.3964\n",
      "143/224, train_loss: 0.6704, step time: 0.4090\n",
      "144/224, train_loss: 0.6758, step time: 0.3153\n",
      "145/224, train_loss: 0.6746, step time: 0.3848\n",
      "146/224, train_loss: 0.6745, step time: 0.3178\n",
      "147/224, train_loss: 0.6748, step time: 0.4107\n",
      "148/224, train_loss: 0.6743, step time: 0.4071\n",
      "149/224, train_loss: 0.6734, step time: 0.4091\n",
      "150/224, train_loss: 0.6716, step time: 0.3152\n",
      "151/224, train_loss: 0.6717, step time: 0.4102\n",
      "152/224, train_loss: 0.6724, step time: 0.3963\n",
      "153/224, train_loss: 0.6707, step time: 0.3157\n",
      "154/224, train_loss: 0.6757, step time: 0.3828\n",
      "155/224, train_loss: 0.6690, step time: 0.3159\n",
      "156/224, train_loss: 0.6727, step time: 0.3157\n",
      "157/224, train_loss: 0.6721, step time: 0.3178\n",
      "158/224, train_loss: 0.6753, step time: 0.3175\n",
      "159/224, train_loss: 0.6630, step time: 0.3156\n",
      "160/224, train_loss: 0.6728, step time: 0.3172\n",
      "161/224, train_loss: 0.6757, step time: 0.3812\n",
      "162/224, train_loss: 0.6718, step time: 0.3159\n",
      "163/224, train_loss: 0.6696, step time: 0.3150\n",
      "164/224, train_loss: 0.6652, step time: 0.3755\n",
      "165/224, train_loss: 0.6704, step time: 0.3152\n",
      "166/224, train_loss: 0.6693, step time: 0.3158\n",
      "167/224, train_loss: 0.6690, step time: 0.3158\n",
      "168/224, train_loss: 0.6744, step time: 0.3154\n",
      "169/224, train_loss: 0.6754, step time: 0.3173\n",
      "170/224, train_loss: 0.6685, step time: 0.3170\n",
      "171/224, train_loss: 0.6729, step time: 0.3150\n",
      "172/224, train_loss: 0.6693, step time: 0.3853\n",
      "173/224, train_loss: 0.6714, step time: 0.3729\n",
      "174/224, train_loss: 0.6678, step time: 0.3181\n",
      "175/224, train_loss: 0.6746, step time: 0.3815\n",
      "176/224, train_loss: 0.6700, step time: 0.4063\n",
      "177/224, train_loss: 0.6712, step time: 0.3812\n",
      "178/224, train_loss: 0.6647, step time: 0.3971\n",
      "179/224, train_loss: 0.6701, step time: 0.3149\n",
      "180/224, train_loss: 0.6674, step time: 0.3175\n",
      "181/224, train_loss: 0.6735, step time: 0.3155\n",
      "182/224, train_loss: 0.6699, step time: 0.3168\n",
      "183/224, train_loss: 0.6681, step time: 0.3160\n",
      "184/224, train_loss: 0.6729, step time: 0.3155\n",
      "185/224, train_loss: 0.6740, step time: 0.3153\n",
      "186/224, train_loss: 0.6668, step time: 0.3781\n",
      "187/224, train_loss: 0.6740, step time: 0.4033\n",
      "188/224, train_loss: 0.6748, step time: 0.3166\n",
      "189/224, train_loss: 0.6710, step time: 0.4062\n",
      "190/224, train_loss: 0.6739, step time: 0.3128\n",
      "191/224, train_loss: 0.6711, step time: 0.3969\n",
      "192/224, train_loss: 0.6697, step time: 0.3181\n",
      "193/224, train_loss: 0.6703, step time: 0.3744\n",
      "194/224, train_loss: 0.6711, step time: 0.3132\n",
      "195/224, train_loss: 0.6711, step time: 0.3176\n",
      "196/224, train_loss: 0.6708, step time: 0.3157\n",
      "197/224, train_loss: 0.6738, step time: 0.3133\n",
      "198/224, train_loss: 0.6707, step time: 0.3939\n",
      "199/224, train_loss: 0.6699, step time: 0.3902\n",
      "200/224, train_loss: 0.6698, step time: 0.3989\n",
      "201/224, train_loss: 0.6734, step time: 0.3152\n",
      "202/224, train_loss: 0.6660, step time: 0.4045\n",
      "203/224, train_loss: 0.6522, step time: 0.4054\n",
      "204/224, train_loss: 0.6706, step time: 0.3178\n",
      "205/224, train_loss: 0.6692, step time: 0.3170\n",
      "206/224, train_loss: 0.6679, step time: 0.3153\n",
      "207/224, train_loss: 0.6673, step time: 0.3156\n",
      "208/224, train_loss: 0.6736, step time: 0.3159\n",
      "209/224, train_loss: 0.6708, step time: 0.3720\n",
      "210/224, train_loss: 0.6742, step time: 0.3734\n",
      "211/224, train_loss: 0.6658, step time: 0.4010\n",
      "212/224, train_loss: 0.6711, step time: 0.3663\n",
      "213/224, train_loss: 0.6695, step time: 0.4121\n",
      "214/224, train_loss: 0.6699, step time: 0.4015\n",
      "215/224, train_loss: 0.6710, step time: 0.3180\n",
      "216/224, train_loss: 0.6720, step time: 0.3157\n",
      "217/224, train_loss: 0.6666, step time: 0.4016\n",
      "218/224, train_loss: 0.6710, step time: 0.3132\n",
      "219/224, train_loss: 0.6666, step time: 0.3706\n",
      "220/224, train_loss: 0.6722, step time: 0.3681\n",
      "221/224, train_loss: 0.6715, step time: 0.3131\n",
      "222/224, train_loss: 0.6632, step time: 0.3178\n",
      "223/224, train_loss: 0.6689, step time: 0.4099\n",
      "224/224, train_loss: 0.6720, step time: 0.3806\n",
      "epoch 1 average loss: 0.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/monai/metrics/utils.py:219: UserWarning: y should be a binarized tensor.\n",
      "  warnings.warn(f\"{name} should be a binarized tensor.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 1 current mean dice: 0.3478 class1: 0.9984 class2: 0.0444 class3: 0.0005\n",
      "best mean dice: 0.3478 at epoch: 1\n",
      "time consuming of epoch 1 is: 703.4937\n",
      "hello\n",
      "----------\n",
      "epoch 2/100\n",
      "1/224, train_loss: 0.6697, step time: 0.3970\n",
      "2/224, train_loss: 0.6718, step time: 0.4080\n",
      "3/224, train_loss: 0.6685, step time: 0.3181\n",
      "4/224, train_loss: 0.6665, step time: 0.3833\n",
      "5/224, train_loss: 0.6716, step time: 0.4040\n",
      "6/224, train_loss: 0.6677, step time: 0.3764\n",
      "7/224, train_loss: 0.6748, step time: 0.3784\n",
      "8/224, train_loss: 0.6716, step time: 0.3174\n",
      "9/224, train_loss: 0.6679, step time: 0.3156\n",
      "10/224, train_loss: 0.6726, step time: 0.4100\n",
      "11/224, train_loss: 0.6681, step time: 0.3160\n",
      "12/224, train_loss: 0.6712, step time: 0.3961\n",
      "13/224, train_loss: 0.6688, step time: 0.3153\n",
      "14/224, train_loss: 0.6711, step time: 0.3873\n",
      "15/224, train_loss: 0.6691, step time: 0.3915\n",
      "16/224, train_loss: 0.6663, step time: 0.3156\n",
      "17/224, train_loss: 0.6742, step time: 0.3177\n",
      "18/224, train_loss: 0.6652, step time: 0.3150\n",
      "19/224, train_loss: 0.6743, step time: 0.3134\n",
      "20/224, train_loss: 0.6650, step time: 0.3983\n",
      "21/224, train_loss: 0.6700, step time: 0.4091\n",
      "22/224, train_loss: 0.6729, step time: 0.3179\n",
      "23/224, train_loss: 0.6683, step time: 0.3155\n",
      "24/224, train_loss: 0.6730, step time: 0.3150\n",
      "25/224, train_loss: 0.6729, step time: 0.3758\n",
      "26/224, train_loss: 0.6696, step time: 0.3177\n",
      "27/224, train_loss: 0.6624, step time: 0.3132\n",
      "28/224, train_loss: 0.6686, step time: 0.3949\n",
      "29/224, train_loss: 0.6723, step time: 0.3153\n",
      "30/224, train_loss: 0.6701, step time: 0.4083\n",
      "31/224, train_loss: 0.6681, step time: 0.3951\n",
      "32/224, train_loss: 0.6679, step time: 0.3783\n",
      "33/224, train_loss: 0.6716, step time: 0.3989\n",
      "34/224, train_loss: 0.6699, step time: 0.3756\n",
      "35/224, train_loss: 0.6716, step time: 0.3153\n",
      "36/224, train_loss: 0.6702, step time: 0.3963\n",
      "37/224, train_loss: 0.6692, step time: 0.3634\n",
      "38/224, train_loss: 0.6686, step time: 0.3728\n",
      "39/224, train_loss: 0.6622, step time: 0.3130\n",
      "40/224, train_loss: 0.6632, step time: 0.4051\n",
      "41/224, train_loss: 0.6714, step time: 0.3890\n",
      "42/224, train_loss: 0.6723, step time: 0.3155\n",
      "43/224, train_loss: 0.6721, step time: 0.3882\n",
      "44/224, train_loss: 0.6699, step time: 0.3753\n",
      "45/224, train_loss: 0.6679, step time: 0.3974\n",
      "46/224, train_loss: 0.6680, step time: 0.3160\n",
      "47/224, train_loss: 0.6634, step time: 0.4079\n",
      "48/224, train_loss: 0.6666, step time: 0.4015\n",
      "49/224, train_loss: 0.6680, step time: 0.3160\n",
      "50/224, train_loss: 0.6654, step time: 0.3688\n",
      "51/224, train_loss: 0.6629, step time: 0.4109\n",
      "52/224, train_loss: 0.6621, step time: 0.3161\n",
      "53/224, train_loss: 0.6667, step time: 0.3856\n",
      "54/224, train_loss: 0.6629, step time: 0.3157\n",
      "55/224, train_loss: 0.6712, step time: 0.3894\n",
      "56/224, train_loss: 0.6683, step time: 0.3174\n",
      "57/224, train_loss: 0.6632, step time: 0.3169\n",
      "58/224, train_loss: 0.6662, step time: 0.3813\n",
      "59/224, train_loss: 0.6670, step time: 0.3153\n",
      "60/224, train_loss: 0.6683, step time: 0.3156\n",
      "61/224, train_loss: 0.6582, step time: 0.3178\n",
      "62/224, train_loss: 0.6662, step time: 0.3990\n",
      "63/224, train_loss: 0.6654, step time: 0.4099\n",
      "64/224, train_loss: 0.6705, step time: 0.4026\n",
      "65/224, train_loss: 0.6652, step time: 0.4024\n",
      "66/224, train_loss: 0.6696, step time: 0.3744\n",
      "67/224, train_loss: 0.6716, step time: 0.3894\n",
      "68/224, train_loss: 0.6699, step time: 0.3160\n",
      "69/224, train_loss: 0.6605, step time: 0.3947\n",
      "70/224, train_loss: 0.6695, step time: 0.3939\n",
      "71/224, train_loss: 0.6655, step time: 0.3178\n",
      "72/224, train_loss: 0.6649, step time: 0.3997\n",
      "73/224, train_loss: 0.6462, step time: 0.3138\n",
      "74/224, train_loss: 0.6672, step time: 0.3697\n",
      "75/224, train_loss: 0.6719, step time: 0.3801\n",
      "76/224, train_loss: 0.6692, step time: 0.3141\n",
      "77/224, train_loss: 0.6714, step time: 0.3135\n",
      "78/224, train_loss: 0.6568, step time: 0.3996\n",
      "79/224, train_loss: 0.6681, step time: 0.3636\n",
      "80/224, train_loss: 0.6704, step time: 0.4104\n",
      "81/224, train_loss: 0.6685, step time: 0.3975\n",
      "82/224, train_loss: 0.6706, step time: 0.3966\n",
      "83/224, train_loss: 0.6606, step time: 0.3696\n",
      "84/224, train_loss: 0.6694, step time: 0.3861\n",
      "85/224, train_loss: 0.6710, step time: 0.3670\n",
      "86/224, train_loss: 0.6666, step time: 0.3985\n",
      "87/224, train_loss: 0.6598, step time: 0.3142\n",
      "88/224, train_loss: 0.6621, step time: 0.3161\n",
      "89/224, train_loss: 0.6698, step time: 0.3183\n",
      "90/224, train_loss: 0.6685, step time: 0.3159\n",
      "91/224, train_loss: 0.6677, step time: 0.3728\n",
      "92/224, train_loss: 0.6676, step time: 0.3152\n",
      "93/224, train_loss: 0.6688, step time: 0.4058\n",
      "94/224, train_loss: 0.6696, step time: 0.4027\n",
      "95/224, train_loss: 0.6638, step time: 0.3900\n",
      "96/224, train_loss: 0.6615, step time: 0.3155\n",
      "97/224, train_loss: 0.6695, step time: 0.3157\n",
      "98/224, train_loss: 0.6710, step time: 0.3134\n",
      "99/224, train_loss: 0.6706, step time: 0.4004\n",
      "100/224, train_loss: 0.6712, step time: 0.3148\n",
      "101/224, train_loss: 0.6518, step time: 0.3132\n",
      "102/224, train_loss: 0.6668, step time: 0.4027\n",
      "103/224, train_loss: 0.6641, step time: 0.3947\n",
      "104/224, train_loss: 0.6589, step time: 0.3155\n",
      "105/224, train_loss: 0.6615, step time: 0.3160\n",
      "106/224, train_loss: 0.6656, step time: 0.3188\n",
      "107/224, train_loss: 0.6643, step time: 0.3177\n",
      "108/224, train_loss: 0.6622, step time: 0.3697\n",
      "109/224, train_loss: 0.6625, step time: 0.3872\n",
      "110/224, train_loss: 0.6655, step time: 0.3865\n",
      "111/224, train_loss: 0.6666, step time: 0.4086\n",
      "112/224, train_loss: 0.6682, step time: 0.3153\n",
      "113/224, train_loss: 0.6618, step time: 0.3718\n",
      "114/224, train_loss: 0.6690, step time: 0.3161\n",
      "115/224, train_loss: 0.6706, step time: 0.4032\n",
      "116/224, train_loss: 0.6568, step time: 0.3954\n",
      "117/224, train_loss: 0.6378, step time: 0.3157\n",
      "118/224, train_loss: 0.6718, step time: 0.3779\n",
      "119/224, train_loss: 0.6664, step time: 0.3154\n",
      "120/224, train_loss: 0.6608, step time: 0.3157\n",
      "121/224, train_loss: 0.6719, step time: 0.3129\n",
      "122/224, train_loss: 0.6579, step time: 0.4070\n",
      "123/224, train_loss: 0.6703, step time: 0.3994\n",
      "124/224, train_loss: 0.6661, step time: 0.3916\n",
      "125/224, train_loss: 0.6671, step time: 0.3892\n",
      "126/224, train_loss: 0.6694, step time: 0.3818\n",
      "127/224, train_loss: 0.6611, step time: 0.3706\n",
      "128/224, train_loss: 0.6631, step time: 0.3988\n",
      "129/224, train_loss: 0.6633, step time: 0.4085\n",
      "130/224, train_loss: 0.6576, step time: 0.3181\n",
      "131/224, train_loss: 0.6680, step time: 0.3152\n",
      "132/224, train_loss: 0.6656, step time: 0.3884\n",
      "133/224, train_loss: 0.6673, step time: 0.3152\n",
      "134/224, train_loss: 0.6628, step time: 0.3178\n",
      "135/224, train_loss: 0.6687, step time: 0.3878\n",
      "136/224, train_loss: 0.6666, step time: 0.3175\n",
      "137/224, train_loss: 0.6619, step time: 0.3934\n",
      "138/224, train_loss: 0.6604, step time: 0.3150\n",
      "139/224, train_loss: 0.6688, step time: 0.3658\n",
      "140/224, train_loss: 0.6687, step time: 0.3161\n",
      "141/224, train_loss: 0.6585, step time: 0.3665\n",
      "142/224, train_loss: 0.6639, step time: 0.3175\n",
      "143/224, train_loss: 0.6655, step time: 0.3148\n",
      "144/224, train_loss: 0.6725, step time: 0.3890\n",
      "145/224, train_loss: 0.6703, step time: 0.3154\n",
      "146/224, train_loss: 0.6691, step time: 0.3174\n",
      "147/224, train_loss: 0.6655, step time: 0.3812\n",
      "148/224, train_loss: 0.6623, step time: 0.3890\n",
      "149/224, train_loss: 0.6673, step time: 0.3840\n",
      "150/224, train_loss: 0.6577, step time: 0.3159\n",
      "151/224, train_loss: 0.6508, step time: 0.3143\n",
      "152/224, train_loss: 0.6698, step time: 0.3727\n",
      "153/224, train_loss: 0.6684, step time: 0.3674\n",
      "154/224, train_loss: 0.6500, step time: 0.3154\n",
      "155/224, train_loss: 0.6645, step time: 0.3954\n",
      "156/224, train_loss: 0.6593, step time: 0.3131\n",
      "157/224, train_loss: 0.6536, step time: 0.3151\n",
      "158/224, train_loss: 0.6699, step time: 0.3175\n",
      "159/224, train_loss: 0.6666, step time: 0.3159\n",
      "160/224, train_loss: 0.6544, step time: 0.4124\n",
      "161/224, train_loss: 0.6638, step time: 0.3173\n",
      "162/224, train_loss: 0.6711, step time: 0.3845\n",
      "163/224, train_loss: 0.6611, step time: 0.3977\n",
      "164/224, train_loss: 0.6551, step time: 0.3141\n",
      "165/224, train_loss: 0.6660, step time: 0.3762\n",
      "166/224, train_loss: 0.6625, step time: 0.3821\n",
      "167/224, train_loss: 0.6581, step time: 0.3154\n",
      "168/224, train_loss: 0.6634, step time: 0.3898\n",
      "169/224, train_loss: 0.6561, step time: 0.3156\n",
      "170/224, train_loss: 0.6520, step time: 0.3152\n",
      "171/224, train_loss: 0.6687, step time: 0.3906\n",
      "172/224, train_loss: 0.6683, step time: 0.4059\n",
      "173/224, train_loss: 0.6671, step time: 0.3150\n",
      "174/224, train_loss: 0.6561, step time: 0.3975\n",
      "175/224, train_loss: 0.6680, step time: 0.3774\n",
      "176/224, train_loss: 0.6622, step time: 0.3733\n",
      "177/224, train_loss: 0.6617, step time: 0.3176\n",
      "178/224, train_loss: 0.6644, step time: 0.3175\n",
      "179/224, train_loss: 0.6608, step time: 0.3737\n",
      "180/224, train_loss: 0.6630, step time: 0.3899\n",
      "181/224, train_loss: 0.6607, step time: 0.3154\n",
      "182/224, train_loss: 0.6639, step time: 0.3840\n",
      "183/224, train_loss: 0.6645, step time: 0.3158\n",
      "184/224, train_loss: 0.6594, step time: 0.3932\n",
      "185/224, train_loss: 0.6561, step time: 0.3182\n",
      "186/224, train_loss: 0.6531, step time: 0.3660\n",
      "187/224, train_loss: 0.6632, step time: 0.3939\n",
      "188/224, train_loss: 0.6622, step time: 0.3156\n",
      "189/224, train_loss: 0.6661, step time: 0.3160\n",
      "190/224, train_loss: 0.6649, step time: 0.3794\n",
      "191/224, train_loss: 0.6536, step time: 0.3138\n",
      "192/224, train_loss: 0.6680, step time: 0.3907\n",
      "193/224, train_loss: 0.6566, step time: 0.3152\n",
      "194/224, train_loss: 0.6711, step time: 0.3868\n",
      "195/224, train_loss: 0.6624, step time: 0.4015\n",
      "196/224, train_loss: 0.6602, step time: 0.3155\n",
      "197/224, train_loss: 0.6677, step time: 0.3136\n",
      "198/224, train_loss: 0.6482, step time: 0.3900\n",
      "199/224, train_loss: 0.6648, step time: 0.3707\n",
      "200/224, train_loss: 0.6675, step time: 0.3794\n",
      "201/224, train_loss: 0.6456, step time: 0.3140\n",
      "202/224, train_loss: 0.6626, step time: 0.3833\n",
      "203/224, train_loss: 0.6532, step time: 0.3843\n",
      "204/224, train_loss: 0.6650, step time: 0.3156\n",
      "205/224, train_loss: 0.6555, step time: 0.3162\n",
      "206/224, train_loss: 0.6265, step time: 0.3157\n",
      "207/224, train_loss: 0.6563, step time: 0.3158\n",
      "208/224, train_loss: 0.6542, step time: 0.3828\n",
      "209/224, train_loss: 0.6469, step time: 0.3154\n",
      "210/224, train_loss: 0.6606, step time: 0.3152\n",
      "211/224, train_loss: 0.6572, step time: 0.3930\n",
      "212/224, train_loss: 0.6596, step time: 0.3178\n",
      "213/224, train_loss: 0.6635, step time: 0.3798\n",
      "214/224, train_loss: 0.6602, step time: 0.3157\n",
      "215/224, train_loss: 0.6601, step time: 0.3966\n",
      "216/224, train_loss: 0.6493, step time: 0.3837\n",
      "217/224, train_loss: 0.6710, step time: 0.4089\n",
      "218/224, train_loss: 0.6551, step time: 0.3806\n",
      "219/224, train_loss: 0.6562, step time: 0.3789\n",
      "220/224, train_loss: 0.6640, step time: 0.3921\n",
      "221/224, train_loss: 0.6605, step time: 0.3845\n",
      "222/224, train_loss: 0.6505, step time: 0.3721\n",
      "223/224, train_loss: 0.6389, step time: 0.3156\n",
      "224/224, train_loss: 0.6331, step time: 0.3160\n",
      "epoch 2 average loss: 0.6643\n",
      "current epoch: 2 current mean dice: 0.3856 class1: 0.9984 class2: 0.1580 class3: 0.0005\n",
      "best mean dice: 0.3856 at epoch: 2\n",
      "time consuming of epoch 2 is: 841.1437\n",
      "hello\n",
      "----------\n",
      "epoch 3/100\n",
      "1/224, train_loss: 0.6606, step time: 0.3898\n",
      "2/224, train_loss: 0.6584, step time: 0.3177\n",
      "3/224, train_loss: 0.6499, step time: 0.3155\n",
      "4/224, train_loss: 0.6616, step time: 0.4080\n",
      "5/224, train_loss: 0.6623, step time: 0.4122\n",
      "6/224, train_loss: 0.6632, step time: 0.3137\n",
      "7/224, train_loss: 0.6494, step time: 0.4139\n",
      "8/224, train_loss: 0.6603, step time: 0.3956\n",
      "9/224, train_loss: 0.6677, step time: 0.3791\n",
      "10/224, train_loss: 0.6585, step time: 0.3850\n",
      "11/224, train_loss: 0.6572, step time: 0.3157\n",
      "12/224, train_loss: 0.6602, step time: 0.3151\n",
      "13/224, train_loss: 0.6490, step time: 0.3744\n",
      "14/224, train_loss: 0.6405, step time: 0.3154\n",
      "15/224, train_loss: 0.6582, step time: 0.3951\n",
      "16/224, train_loss: 0.6509, step time: 0.3800\n",
      "17/224, train_loss: 0.6545, step time: 0.3157\n",
      "18/224, train_loss: 0.6566, step time: 0.3158\n",
      "19/224, train_loss: 0.6441, step time: 0.3755\n",
      "20/224, train_loss: 0.6412, step time: 0.3179\n",
      "21/224, train_loss: 0.6686, step time: 0.3981\n",
      "22/224, train_loss: 0.6592, step time: 0.3800\n",
      "23/224, train_loss: 0.6519, step time: 0.3159\n",
      "24/224, train_loss: 0.6536, step time: 0.3938\n",
      "25/224, train_loss: 0.6563, step time: 0.3185\n",
      "26/224, train_loss: 0.6639, step time: 0.4082\n",
      "27/224, train_loss: 0.6504, step time: 0.3664\n",
      "28/224, train_loss: 0.6584, step time: 0.3161\n",
      "29/224, train_loss: 0.6476, step time: 0.4020\n",
      "30/224, train_loss: 0.6517, step time: 0.3859\n",
      "31/224, train_loss: 0.6560, step time: 0.3784\n",
      "32/224, train_loss: 0.6455, step time: 0.4123\n",
      "33/224, train_loss: 0.6605, step time: 0.3178\n",
      "34/224, train_loss: 0.6078, step time: 0.4031\n",
      "35/224, train_loss: 0.6507, step time: 0.3178\n",
      "36/224, train_loss: 0.6387, step time: 0.3883\n",
      "37/224, train_loss: 0.6559, step time: 0.4118\n",
      "38/224, train_loss: 0.6454, step time: 0.4022\n",
      "39/224, train_loss: 0.6243, step time: 0.3158\n",
      "40/224, train_loss: 0.6537, step time: 0.3156\n",
      "41/224, train_loss: 0.6508, step time: 0.3800\n",
      "42/224, train_loss: 0.6581, step time: 0.3160\n",
      "43/224, train_loss: 0.6601, step time: 0.3188\n",
      "44/224, train_loss: 0.6631, step time: 0.3701\n",
      "45/224, train_loss: 0.6617, step time: 0.4009\n",
      "46/224, train_loss: 0.6489, step time: 0.3180\n",
      "47/224, train_loss: 0.6711, step time: 0.3159\n",
      "48/224, train_loss: 0.6437, step time: 0.3177\n",
      "49/224, train_loss: 0.6617, step time: 0.3177\n",
      "50/224, train_loss: 0.6594, step time: 0.3760\n",
      "51/224, train_loss: 0.6435, step time: 0.3158\n",
      "52/224, train_loss: 0.6362, step time: 0.3784\n",
      "53/224, train_loss: 0.6387, step time: 0.3839\n",
      "54/224, train_loss: 0.6474, step time: 0.3774\n",
      "55/224, train_loss: 0.6581, step time: 0.3937\n",
      "56/224, train_loss: 0.6443, step time: 0.3182\n",
      "57/224, train_loss: 0.6590, step time: 0.3166\n",
      "58/224, train_loss: 0.6553, step time: 0.3164\n",
      "59/224, train_loss: 0.6234, step time: 0.3991\n",
      "60/224, train_loss: 0.6488, step time: 0.3692\n",
      "61/224, train_loss: 0.6552, step time: 0.4080\n",
      "62/224, train_loss: 0.6394, step time: 0.4003\n",
      "63/224, train_loss: 0.6248, step time: 0.4123\n",
      "64/224, train_loss: 0.6568, step time: 0.3185\n",
      "65/224, train_loss: 0.6373, step time: 0.3178\n",
      "66/224, train_loss: 0.6564, step time: 0.3734\n",
      "67/224, train_loss: 0.6445, step time: 0.3143\n",
      "68/224, train_loss: 0.6572, step time: 0.3165\n",
      "69/224, train_loss: 0.6531, step time: 0.4003\n",
      "70/224, train_loss: 0.6531, step time: 0.3187\n",
      "71/224, train_loss: 0.6631, step time: 0.3143\n",
      "72/224, train_loss: 0.6541, step time: 0.3164\n",
      "73/224, train_loss: 0.6640, step time: 0.3153\n",
      "74/224, train_loss: 0.6444, step time: 0.3184\n",
      "75/224, train_loss: 0.6299, step time: 0.3916\n",
      "76/224, train_loss: 0.6582, step time: 0.3164\n",
      "77/224, train_loss: 0.6566, step time: 0.3187\n",
      "78/224, train_loss: 0.6385, step time: 0.3741\n",
      "79/224, train_loss: 0.6690, step time: 0.3645\n",
      "80/224, train_loss: 0.6501, step time: 0.4105\n",
      "81/224, train_loss: 0.6573, step time: 0.3972\n",
      "82/224, train_loss: 0.6406, step time: 0.3158\n",
      "83/224, train_loss: 0.6605, step time: 0.3163\n",
      "84/224, train_loss: 0.6597, step time: 0.3186\n",
      "85/224, train_loss: 0.6445, step time: 0.3852\n",
      "86/224, train_loss: 0.6569, step time: 0.3166\n",
      "87/224, train_loss: 0.6410, step time: 0.4045\n",
      "88/224, train_loss: 0.6458, step time: 0.3746\n",
      "89/224, train_loss: 0.6630, step time: 0.3684\n",
      "90/224, train_loss: 0.6484, step time: 0.3666\n",
      "91/224, train_loss: 0.6538, step time: 0.3185\n",
      "92/224, train_loss: 0.6555, step time: 0.3159\n",
      "93/224, train_loss: 0.6521, step time: 0.3158\n",
      "94/224, train_loss: 0.6616, step time: 0.3160\n",
      "95/224, train_loss: 0.6510, step time: 0.3165\n",
      "96/224, train_loss: 0.6266, step time: 0.3160\n",
      "97/224, train_loss: 0.6308, step time: 0.3793\n",
      "98/224, train_loss: 0.6600, step time: 0.3156\n",
      "99/224, train_loss: 0.6586, step time: 0.3181\n",
      "100/224, train_loss: 0.6608, step time: 0.3891\n",
      "101/224, train_loss: 0.6588, step time: 0.3731\n",
      "102/224, train_loss: 0.6519, step time: 0.4031\n",
      "103/224, train_loss: 0.6391, step time: 0.3186\n",
      "104/224, train_loss: 0.6586, step time: 0.3870\n",
      "105/224, train_loss: 0.6428, step time: 0.3875\n",
      "106/224, train_loss: 0.6480, step time: 0.3696\n",
      "107/224, train_loss: 0.6559, step time: 0.3182\n",
      "108/224, train_loss: 0.6205, step time: 0.4106\n",
      "109/224, train_loss: 0.6615, step time: 0.3942\n",
      "110/224, train_loss: 0.6554, step time: 0.3882\n",
      "111/224, train_loss: 0.6417, step time: 0.3818\n",
      "112/224, train_loss: 0.6581, step time: 0.3922\n",
      "113/224, train_loss: 0.6429, step time: 0.3167\n",
      "114/224, train_loss: 0.6607, step time: 0.3165\n",
      "115/224, train_loss: 0.6381, step time: 0.3160\n",
      "116/224, train_loss: 0.6340, step time: 0.3884\n",
      "117/224, train_loss: 0.6363, step time: 0.3145\n",
      "118/224, train_loss: 0.6496, step time: 0.3185\n",
      "119/224, train_loss: 0.6514, step time: 0.3996\n",
      "120/224, train_loss: 0.6280, step time: 0.3148\n",
      "121/224, train_loss: 0.6388, step time: 0.3165\n",
      "122/224, train_loss: 0.6525, step time: 0.3163\n",
      "123/224, train_loss: 0.6532, step time: 0.3949\n",
      "124/224, train_loss: 0.6285, step time: 0.3183\n",
      "125/224, train_loss: 0.6422, step time: 0.3170\n",
      "126/224, train_loss: 0.6552, step time: 0.3163\n",
      "127/224, train_loss: 0.6426, step time: 0.3182\n",
      "128/224, train_loss: 0.6516, step time: 0.3146\n",
      "129/224, train_loss: 0.6549, step time: 0.3149\n",
      "130/224, train_loss: 0.6532, step time: 0.4011\n",
      "131/224, train_loss: 0.6601, step time: 0.4070\n",
      "132/224, train_loss: 0.6412, step time: 0.5994\n",
      "133/224, train_loss: 0.6571, step time: 0.3818\n",
      "134/224, train_loss: 0.6484, step time: 0.3755\n",
      "135/224, train_loss: 0.6437, step time: 0.3157\n",
      "136/224, train_loss: 0.6611, step time: 0.4034\n",
      "137/224, train_loss: 0.6593, step time: 0.3997\n",
      "138/224, train_loss: 0.6423, step time: 0.3126\n",
      "139/224, train_loss: 0.6432, step time: 0.3985\n",
      "140/224, train_loss: 0.6503, step time: 0.3983\n",
      "141/224, train_loss: 0.6538, step time: 0.3147\n",
      "142/224, train_loss: 0.6524, step time: 0.4004\n",
      "143/224, train_loss: 0.6445, step time: 0.3664\n",
      "144/224, train_loss: 0.6474, step time: 0.4113\n",
      "145/224, train_loss: 0.6395, step time: 0.3810\n",
      "146/224, train_loss: 0.6404, step time: 0.3124\n",
      "147/224, train_loss: 0.6062, step time: 0.3149\n",
      "148/224, train_loss: 0.6325, step time: 0.3149\n",
      "149/224, train_loss: 0.6305, step time: 0.3788\n",
      "150/224, train_loss: 0.6531, step time: 0.3155\n",
      "151/224, train_loss: 0.6603, step time: 0.3125\n",
      "152/224, train_loss: 0.6568, step time: 0.3844\n",
      "153/224, train_loss: 0.6439, step time: 0.3131\n",
      "154/224, train_loss: 0.6575, step time: 0.3175\n",
      "155/224, train_loss: 0.6664, step time: 0.4061\n",
      "156/224, train_loss: 0.6525, step time: 0.3169\n",
      "157/224, train_loss: 0.6384, step time: 0.3899\n",
      "158/224, train_loss: 0.6436, step time: 0.3823\n",
      "159/224, train_loss: 0.6421, step time: 0.3877\n",
      "160/224, train_loss: 0.6437, step time: 0.3152\n",
      "161/224, train_loss: 0.6600, step time: 0.3731\n",
      "162/224, train_loss: 0.6512, step time: 0.3168\n",
      "163/224, train_loss: 0.6389, step time: 0.3148\n",
      "164/224, train_loss: 0.6381, step time: 0.3147\n",
      "165/224, train_loss: 0.5903, step time: 0.4079\n",
      "166/224, train_loss: 0.6398, step time: 0.3153\n",
      "167/224, train_loss: 0.6437, step time: 0.3152\n",
      "168/224, train_loss: 0.6144, step time: 0.4050\n",
      "169/224, train_loss: 0.6433, step time: 0.3123\n",
      "170/224, train_loss: 0.6482, step time: 0.3152\n",
      "171/224, train_loss: 0.6589, step time: 0.3150\n",
      "172/224, train_loss: 0.6561, step time: 0.3918\n",
      "173/224, train_loss: 0.6523, step time: 0.3693\n",
      "174/224, train_loss: 0.6285, step time: 0.3734\n",
      "175/224, train_loss: 0.6359, step time: 0.3168\n",
      "176/224, train_loss: 0.6598, step time: 0.3167\n",
      "177/224, train_loss: 0.6533, step time: 0.3921\n",
      "178/224, train_loss: 0.6367, step time: 0.4018\n",
      "179/224, train_loss: 0.6557, step time: 0.3150\n",
      "180/224, train_loss: 0.6254, step time: 0.3167\n",
      "181/224, train_loss: 0.6447, step time: 0.3145\n",
      "182/224, train_loss: 0.6513, step time: 0.3683\n",
      "183/224, train_loss: 0.6323, step time: 0.3777\n",
      "184/224, train_loss: 0.6658, step time: 0.3150\n",
      "185/224, train_loss: 0.6434, step time: 0.4101\n",
      "186/224, train_loss: 0.6325, step time: 0.3145\n",
      "187/224, train_loss: 0.6231, step time: 0.3143\n",
      "188/224, train_loss: 0.6353, step time: 0.3127\n",
      "189/224, train_loss: 0.6298, step time: 0.3120\n",
      "190/224, train_loss: 0.6372, step time: 0.3174\n",
      "191/224, train_loss: 0.6550, step time: 0.3807\n",
      "192/224, train_loss: 0.6520, step time: 0.3151\n",
      "193/224, train_loss: 0.6182, step time: 0.3154\n",
      "194/224, train_loss: 0.6417, step time: 0.3156\n",
      "195/224, train_loss: 0.6243, step time: 0.3124\n",
      "196/224, train_loss: 0.6380, step time: 0.3780\n",
      "197/224, train_loss: 0.6161, step time: 0.3967\n",
      "198/224, train_loss: 0.6470, step time: 0.3976\n",
      "199/224, train_loss: 0.6427, step time: 0.3149\n",
      "200/224, train_loss: 0.6393, step time: 0.3900\n",
      "201/224, train_loss: 0.6197, step time: 0.3159\n",
      "202/224, train_loss: 0.6654, step time: 0.3156\n",
      "203/224, train_loss: 0.6198, step time: 0.3149\n",
      "204/224, train_loss: 0.6470, step time: 0.4023\n",
      "205/224, train_loss: 0.6616, step time: 0.3151\n",
      "206/224, train_loss: 0.6408, step time: 0.3151\n",
      "207/224, train_loss: 0.6198, step time: 0.3152\n",
      "208/224, train_loss: 0.6464, step time: 0.3637\n",
      "209/224, train_loss: 0.6336, step time: 0.3842\n",
      "210/224, train_loss: 0.6533, step time: 0.3800\n",
      "211/224, train_loss: 0.6143, step time: 0.3130\n",
      "212/224, train_loss: 0.6536, step time: 0.3853\n",
      "213/224, train_loss: 0.6462, step time: 0.3834\n",
      "214/224, train_loss: 0.6500, step time: 0.3151\n",
      "215/224, train_loss: 0.6390, step time: 0.3166\n",
      "216/224, train_loss: 0.6273, step time: 0.3687\n",
      "217/224, train_loss: 0.6463, step time: 0.3172\n",
      "218/224, train_loss: 0.6304, step time: 0.3848\n",
      "219/224, train_loss: 0.6401, step time: 0.3857\n",
      "220/224, train_loss: 0.6344, step time: 0.3622\n",
      "221/224, train_loss: 0.6381, step time: 0.4081\n",
      "222/224, train_loss: 0.6523, step time: 0.3127\n",
      "223/224, train_loss: 0.6256, step time: 0.3819\n",
      "224/224, train_loss: 0.6449, step time: 0.3154\n",
      "epoch 3 average loss: 0.6471\n",
      "current epoch: 3 current mean dice: 0.4256 class1: 0.9984 class2: 0.2780 class3: 0.0005\n",
      "best mean dice: 0.4256 at epoch: 3\n",
      "time consuming of epoch 3 is: 733.0090\n",
      "hello\n",
      "----------\n",
      "epoch 4/100\n",
      "1/224, train_loss: 0.6209, step time: 0.3684\n",
      "2/224, train_loss: 0.6322, step time: 0.3153\n",
      "3/224, train_loss: 0.6356, step time: 0.3153\n",
      "4/224, train_loss: 0.6423, step time: 0.3207\n",
      "5/224, train_loss: 0.6241, step time: 0.3995\n",
      "6/224, train_loss: 0.6323, step time: 0.3185\n",
      "7/224, train_loss: 0.6439, step time: 0.4031\n",
      "8/224, train_loss: 0.6277, step time: 0.3176\n",
      "9/224, train_loss: 0.6305, step time: 0.3802\n",
      "10/224, train_loss: 0.6512, step time: 0.3130\n",
      "11/224, train_loss: 0.6287, step time: 0.3779\n",
      "12/224, train_loss: 0.6166, step time: 0.3841\n",
      "13/224, train_loss: 0.6178, step time: 0.3155\n",
      "14/224, train_loss: 0.6362, step time: 0.3175\n",
      "15/224, train_loss: 0.6354, step time: 0.3865\n",
      "16/224, train_loss: 0.6182, step time: 0.3148\n",
      "17/224, train_loss: 0.6422, step time: 0.3174\n",
      "18/224, train_loss: 0.6454, step time: 0.3760\n",
      "19/224, train_loss: 0.6545, step time: 0.4081\n",
      "20/224, train_loss: 0.6198, step time: 0.3149\n",
      "21/224, train_loss: 0.6432, step time: 0.3148\n",
      "22/224, train_loss: 0.6415, step time: 0.3154\n",
      "23/224, train_loss: 0.6475, step time: 0.3152\n",
      "24/224, train_loss: 0.6359, step time: 0.3130\n",
      "25/224, train_loss: 0.6436, step time: 0.3155\n",
      "26/224, train_loss: 0.6228, step time: 0.3854\n",
      "27/224, train_loss: 0.6113, step time: 0.3804\n",
      "28/224, train_loss: 0.6164, step time: 0.3721\n",
      "29/224, train_loss: 0.6113, step time: 0.3184\n",
      "30/224, train_loss: 0.6186, step time: 0.3913\n",
      "31/224, train_loss: 0.6156, step time: 0.3163\n",
      "32/224, train_loss: 0.6303, step time: 0.3984\n",
      "33/224, train_loss: 0.6509, step time: 0.3173\n",
      "34/224, train_loss: 0.6525, step time: 0.3172\n",
      "35/224, train_loss: 0.6325, step time: 0.3803\n",
      "36/224, train_loss: 0.6194, step time: 0.3154\n",
      "37/224, train_loss: 0.6248, step time: 0.3178\n",
      "38/224, train_loss: 0.6290, step time: 0.3730\n",
      "39/224, train_loss: 0.6397, step time: 0.3155\n",
      "40/224, train_loss: 0.6383, step time: 0.3153\n",
      "41/224, train_loss: 0.6153, step time: 0.3899\n",
      "42/224, train_loss: 0.6036, step time: 0.3143\n",
      "43/224, train_loss: 0.6434, step time: 0.3167\n",
      "44/224, train_loss: 0.6471, step time: 0.3876\n",
      "45/224, train_loss: 0.6141, step time: 0.4008\n",
      "46/224, train_loss: 0.6223, step time: 0.3173\n",
      "47/224, train_loss: 0.6255, step time: 0.3152\n",
      "48/224, train_loss: 0.6432, step time: 0.3914\n",
      "49/224, train_loss: 0.6462, step time: 0.3132\n",
      "50/224, train_loss: 0.6407, step time: 0.3175\n",
      "51/224, train_loss: 0.6332, step time: 0.3672\n",
      "52/224, train_loss: 0.6554, step time: 0.3150\n",
      "53/224, train_loss: 0.6463, step time: 0.3156\n",
      "54/224, train_loss: 0.6252, step time: 0.3802\n",
      "55/224, train_loss: 0.6116, step time: 0.4008\n",
      "56/224, train_loss: 0.6535, step time: 0.3982\n",
      "57/224, train_loss: 0.6401, step time: 0.3815\n",
      "58/224, train_loss: 0.6391, step time: 0.3160\n",
      "59/224, train_loss: 0.6412, step time: 0.3187\n",
      "60/224, train_loss: 0.6344, step time: 0.3184\n",
      "61/224, train_loss: 0.6353, step time: 0.3636\n",
      "62/224, train_loss: 0.6221, step time: 0.3181\n",
      "63/224, train_loss: 0.6186, step time: 0.3157\n",
      "64/224, train_loss: 0.6328, step time: 0.3128\n",
      "65/224, train_loss: 0.6607, step time: 0.3159\n",
      "66/224, train_loss: 0.6235, step time: 0.4099\n",
      "67/224, train_loss: 0.6388, step time: 0.3677\n",
      "68/224, train_loss: 0.6497, step time: 0.3697\n",
      "69/224, train_loss: 0.6386, step time: 0.3164\n",
      "70/224, train_loss: 0.6091, step time: 0.3694\n",
      "71/224, train_loss: 0.6355, step time: 0.3163\n",
      "72/224, train_loss: 0.6335, step time: 0.3822\n",
      "73/224, train_loss: 0.6410, step time: 0.3685\n",
      "74/224, train_loss: 0.5970, step time: 0.3927\n",
      "75/224, train_loss: 0.6454, step time: 0.3959\n",
      "76/224, train_loss: 0.5992, step time: 0.3166\n",
      "77/224, train_loss: 0.6208, step time: 0.3880\n",
      "78/224, train_loss: 0.6217, step time: 0.3980\n",
      "79/224, train_loss: 0.6417, step time: 0.3185\n",
      "80/224, train_loss: 0.6031, step time: 0.4103\n",
      "81/224, train_loss: 0.6376, step time: 0.3860\n",
      "82/224, train_loss: 0.6290, step time: 0.3165\n",
      "83/224, train_loss: 0.6160, step time: 0.3921\n",
      "84/224, train_loss: 0.6144, step time: 0.3190\n",
      "85/224, train_loss: 0.6481, step time: 0.3162\n",
      "86/224, train_loss: 0.5689, step time: 0.3189\n",
      "87/224, train_loss: 0.6293, step time: 0.4011\n",
      "88/224, train_loss: 0.5773, step time: 0.3186\n",
      "89/224, train_loss: 0.6544, step time: 0.3140\n",
      "90/224, train_loss: 0.6195, step time: 0.3822\n",
      "91/224, train_loss: 0.6177, step time: 0.3180\n",
      "92/224, train_loss: 0.5999, step time: 0.3838\n",
      "93/224, train_loss: 0.6372, step time: 0.3795\n",
      "94/224, train_loss: 0.5946, step time: 0.3729\n",
      "95/224, train_loss: 0.5961, step time: 0.3176\n",
      "96/224, train_loss: 0.6072, step time: 0.3918\n",
      "97/224, train_loss: 0.5925, step time: 0.3652\n",
      "98/224, train_loss: 0.5376, step time: 0.3144\n",
      "99/224, train_loss: 0.6278, step time: 0.3144\n",
      "100/224, train_loss: 0.6306, step time: 0.3162\n",
      "101/224, train_loss: 0.6508, step time: 0.3957\n",
      "102/224, train_loss: 0.6283, step time: 0.3844\n",
      "103/224, train_loss: 0.5944, step time: 0.4120\n",
      "104/224, train_loss: 0.5893, step time: 0.3183\n",
      "105/224, train_loss: 0.6072, step time: 0.3155\n",
      "106/224, train_loss: 0.6330, step time: 0.3197\n",
      "107/224, train_loss: 0.6074, step time: 0.3179\n",
      "108/224, train_loss: 0.6310, step time: 0.3162\n",
      "109/224, train_loss: 0.5965, step time: 0.3160\n",
      "110/224, train_loss: 0.6497, step time: 0.3173\n",
      "111/224, train_loss: 0.6274, step time: 0.4001\n",
      "112/224, train_loss: 0.6195, step time: 0.3680\n",
      "113/224, train_loss: 0.6362, step time: 0.3719\n",
      "114/224, train_loss: 0.6377, step time: 0.3179\n",
      "115/224, train_loss: 0.5930, step time: 0.3166\n",
      "116/224, train_loss: 0.6330, step time: 0.3176\n",
      "117/224, train_loss: 0.6440, step time: 0.3192\n",
      "118/224, train_loss: 0.6196, step time: 0.3719\n",
      "119/224, train_loss: 0.6470, step time: 0.3872\n",
      "120/224, train_loss: 0.6221, step time: 0.3781\n",
      "121/224, train_loss: 0.6485, step time: 0.3780\n",
      "122/224, train_loss: 0.6350, step time: 0.4014\n",
      "123/224, train_loss: 0.6189, step time: 0.3988\n",
      "124/224, train_loss: 0.6174, step time: 0.3210\n",
      "125/224, train_loss: 0.6173, step time: 0.3158\n",
      "126/224, train_loss: 0.6108, step time: 0.4070\n",
      "127/224, train_loss: 0.5866, step time: 0.4084\n",
      "128/224, train_loss: 0.6043, step time: 0.3171\n",
      "129/224, train_loss: 0.6188, step time: 0.3194\n",
      "130/224, train_loss: 0.5952, step time: 0.3174\n",
      "131/224, train_loss: 0.6509, step time: 0.3778\n",
      "132/224, train_loss: 0.6112, step time: 0.3143\n",
      "133/224, train_loss: 0.6281, step time: 0.3996\n",
      "134/224, train_loss: 0.5670, step time: 0.3171\n",
      "135/224, train_loss: 0.6202, step time: 0.4124\n",
      "136/224, train_loss: 0.6137, step time: 0.3799\n",
      "137/224, train_loss: 0.6447, step time: 0.4066\n",
      "138/224, train_loss: 0.6228, step time: 0.3763\n",
      "139/224, train_loss: 0.6119, step time: 0.3184\n",
      "140/224, train_loss: 0.6432, step time: 0.3158\n",
      "141/224, train_loss: 0.6263, step time: 0.3156\n",
      "142/224, train_loss: 0.5998, step time: 0.3847\n",
      "143/224, train_loss: 0.6270, step time: 0.4031\n",
      "144/224, train_loss: 0.6192, step time: 0.3886\n",
      "145/224, train_loss: 0.6111, step time: 0.3185\n",
      "146/224, train_loss: 0.5874, step time: 0.3161\n",
      "147/224, train_loss: 0.6246, step time: 0.3807\n",
      "148/224, train_loss: 0.6156, step time: 0.3959\n",
      "149/224, train_loss: 0.5457, step time: 0.3977\n",
      "150/224, train_loss: 0.6386, step time: 0.3139\n",
      "151/224, train_loss: 0.5493, step time: 0.3989\n",
      "152/224, train_loss: 0.6131, step time: 0.3158\n",
      "153/224, train_loss: 0.6294, step time: 0.4017\n",
      "154/224, train_loss: 0.6432, step time: 0.3157\n",
      "155/224, train_loss: 0.6258, step time: 0.3154\n",
      "156/224, train_loss: 0.6414, step time: 0.3974\n",
      "157/224, train_loss: 0.6345, step time: 0.3709\n",
      "158/224, train_loss: 0.6233, step time: 0.4008\n",
      "159/224, train_loss: 0.6210, step time: 0.3706\n",
      "160/224, train_loss: 0.6068, step time: 0.4038\n",
      "161/224, train_loss: 0.6301, step time: 0.3137\n",
      "162/224, train_loss: 0.6182, step time: 0.3155\n",
      "163/224, train_loss: 0.6023, step time: 0.3159\n",
      "164/224, train_loss: 0.6326, step time: 0.3159\n",
      "165/224, train_loss: 0.6038, step time: 0.3913\n",
      "166/224, train_loss: 0.6145, step time: 0.3644\n",
      "167/224, train_loss: 0.5776, step time: 0.3171\n",
      "168/224, train_loss: 0.5786, step time: 0.3153\n",
      "169/224, train_loss: 0.6634, step time: 0.4070\n",
      "170/224, train_loss: 0.6351, step time: 0.3787\n",
      "171/224, train_loss: 0.6466, step time: 0.3643\n",
      "172/224, train_loss: 0.5898, step time: 0.3141\n",
      "173/224, train_loss: 0.6460, step time: 0.4136\n",
      "174/224, train_loss: 0.6446, step time: 0.3729\n",
      "175/224, train_loss: 0.5864, step time: 0.3143\n",
      "176/224, train_loss: 0.5675, step time: 0.3165\n",
      "177/224, train_loss: 0.6222, step time: 0.3811\n",
      "178/224, train_loss: 0.5488, step time: 0.4053\n",
      "179/224, train_loss: 0.5616, step time: 0.3157\n",
      "180/224, train_loss: 0.5731, step time: 0.3134\n",
      "181/224, train_loss: 0.5884, step time: 0.3158\n",
      "182/224, train_loss: 0.6338, step time: 0.3866\n",
      "183/224, train_loss: 0.6548, step time: 0.3163\n",
      "184/224, train_loss: 0.6021, step time: 0.3181\n",
      "185/224, train_loss: 0.5882, step time: 0.3154\n",
      "186/224, train_loss: 0.6052, step time: 0.3153\n",
      "187/224, train_loss: 0.6330, step time: 0.4063\n",
      "188/224, train_loss: 0.5746, step time: 0.3188\n",
      "189/224, train_loss: 0.6184, step time: 0.3165\n",
      "190/224, train_loss: 0.6254, step time: 0.3873\n",
      "191/224, train_loss: 0.6051, step time: 0.3670\n",
      "192/224, train_loss: 0.5871, step time: 0.3162\n",
      "193/224, train_loss: 0.6156, step time: 0.4146\n",
      "194/224, train_loss: 0.5775, step time: 0.3883\n",
      "195/224, train_loss: 0.5449, step time: 0.3151\n",
      "196/224, train_loss: 0.5974, step time: 0.3175\n",
      "197/224, train_loss: 0.5741, step time: 0.3688\n",
      "198/224, train_loss: 0.5890, step time: 0.3156\n",
      "199/224, train_loss: 0.6145, step time: 0.3163\n",
      "200/224, train_loss: 0.6008, step time: 0.3666\n",
      "201/224, train_loss: 0.6528, step time: 0.3790\n",
      "202/224, train_loss: 0.5646, step time: 0.3817\n",
      "203/224, train_loss: 0.5573, step time: 0.3788\n",
      "204/224, train_loss: 0.5679, step time: 0.3154\n",
      "205/224, train_loss: 0.5859, step time: 0.3787\n",
      "206/224, train_loss: 0.5739, step time: 0.3153\n",
      "207/224, train_loss: 0.5934, step time: 0.3836\n",
      "208/224, train_loss: 0.6273, step time: 0.3845\n",
      "209/224, train_loss: 0.5982, step time: 0.3176\n",
      "210/224, train_loss: 0.5910, step time: 0.3947\n",
      "211/224, train_loss: 0.6020, step time: 0.4086\n",
      "212/224, train_loss: 0.5938, step time: 0.3151\n",
      "213/224, train_loss: 0.6014, step time: 0.3150\n",
      "214/224, train_loss: 0.6117, step time: 0.3129\n",
      "215/224, train_loss: 0.5873, step time: 0.3151\n",
      "216/224, train_loss: 0.6228, step time: 0.3946\n",
      "217/224, train_loss: 0.5718, step time: 0.3176\n",
      "218/224, train_loss: 0.6483, step time: 0.4086\n",
      "219/224, train_loss: 0.5694, step time: 0.3157\n",
      "220/224, train_loss: 0.5554, step time: 0.3174\n",
      "221/224, train_loss: 0.5544, step time: 0.3149\n",
      "222/224, train_loss: 0.6041, step time: 0.3843\n",
      "223/224, train_loss: 0.6110, step time: 0.3175\n",
      "224/224, train_loss: 0.6130, step time: 0.3159\n",
      "epoch 4 average loss: 0.6175\n",
      "current epoch: 4 current mean dice: 0.4800 class1: 0.9984 class2: 0.4410 class3: 0.0005\n",
      "best mean dice: 0.4800 at epoch: 4\n",
      "time consuming of epoch 4 is: 729.6879\n",
      "hello\n",
      "----------\n",
      "epoch 5/100\n",
      "1/224, train_loss: 0.5871, step time: 0.3157\n",
      "2/224, train_loss: 0.5825, step time: 0.3739\n",
      "3/224, train_loss: 0.6236, step time: 0.3758\n",
      "4/224, train_loss: 0.5633, step time: 0.3187\n",
      "5/224, train_loss: 0.6035, step time: 0.3170\n",
      "6/224, train_loss: 0.5833, step time: 0.3745\n",
      "7/224, train_loss: 0.5424, step time: 0.3148\n",
      "8/224, train_loss: 0.5781, step time: 0.3665\n",
      "9/224, train_loss: 0.6053, step time: 0.4010\n",
      "10/224, train_loss: 0.6423, step time: 0.4131\n",
      "11/224, train_loss: 0.5905, step time: 0.4129\n",
      "12/224, train_loss: 0.6042, step time: 0.3150\n",
      "13/224, train_loss: 0.5883, step time: 0.3903\n",
      "14/224, train_loss: 0.6353, step time: 0.3841\n",
      "15/224, train_loss: 0.5459, step time: 0.3826\n",
      "16/224, train_loss: 0.6118, step time: 0.3177\n",
      "17/224, train_loss: 0.6277, step time: 0.4022\n",
      "18/224, train_loss: 0.6278, step time: 0.3212\n",
      "19/224, train_loss: 0.5388, step time: 0.3849\n",
      "20/224, train_loss: 0.5461, step time: 0.3176\n",
      "21/224, train_loss: 0.5660, step time: 0.3181\n",
      "22/224, train_loss: 0.6281, step time: 0.3867\n",
      "23/224, train_loss: 0.6136, step time: 0.4039\n",
      "24/224, train_loss: 0.5824, step time: 0.3149\n",
      "25/224, train_loss: 0.6251, step time: 0.3834\n",
      "26/224, train_loss: 0.5704, step time: 0.3164\n",
      "27/224, train_loss: 0.6219, step time: 0.3154\n",
      "28/224, train_loss: 0.6567, step time: 0.3806\n",
      "29/224, train_loss: 0.6083, step time: 0.3670\n",
      "30/224, train_loss: 0.6146, step time: 0.3831\n",
      "31/224, train_loss: 0.5506, step time: 0.4070\n",
      "32/224, train_loss: 0.6125, step time: 0.3820\n",
      "33/224, train_loss: 0.5854, step time: 0.3161\n",
      "34/224, train_loss: 0.5634, step time: 0.3156\n",
      "35/224, train_loss: 0.6033, step time: 0.3816\n",
      "36/224, train_loss: 0.5705, step time: 0.3128\n",
      "37/224, train_loss: 0.6131, step time: 0.3817\n",
      "38/224, train_loss: 0.5973, step time: 0.3185\n",
      "39/224, train_loss: 0.6117, step time: 0.3158\n",
      "40/224, train_loss: 0.6104, step time: 0.4002\n",
      "41/224, train_loss: 0.5957, step time: 0.3141\n",
      "42/224, train_loss: 0.5825, step time: 0.3681\n",
      "43/224, train_loss: 0.5517, step time: 0.3937\n",
      "44/224, train_loss: 0.6048, step time: 0.3174\n",
      "45/224, train_loss: 0.6050, step time: 0.3726\n",
      "46/224, train_loss: 0.5452, step time: 0.3130\n",
      "47/224, train_loss: 0.5664, step time: 0.3783\n",
      "48/224, train_loss: 0.5999, step time: 0.3807\n",
      "49/224, train_loss: 0.5871, step time: 0.4034\n",
      "50/224, train_loss: 0.5537, step time: 0.3153\n",
      "51/224, train_loss: 0.5793, step time: 0.3147\n",
      "52/224, train_loss: 0.5754, step time: 0.3177\n",
      "53/224, train_loss: 0.6327, step time: 0.4027\n",
      "54/224, train_loss: 0.5819, step time: 0.3765\n",
      "55/224, train_loss: 0.5406, step time: 0.3138\n",
      "56/224, train_loss: 0.5902, step time: 0.3878\n",
      "57/224, train_loss: 0.6047, step time: 0.3179\n",
      "58/224, train_loss: 0.5567, step time: 0.3887\n",
      "59/224, train_loss: 0.5777, step time: 0.3130\n",
      "60/224, train_loss: 0.6334, step time: 0.3177\n",
      "61/224, train_loss: 0.5667, step time: 0.3907\n",
      "62/224, train_loss: 0.6033, step time: 0.3158\n",
      "63/224, train_loss: 0.5551, step time: 0.3163\n",
      "64/224, train_loss: 0.6017, step time: 0.3159\n",
      "65/224, train_loss: 0.5984, step time: 0.3803\n",
      "66/224, train_loss: 0.6157, step time: 0.3162\n",
      "67/224, train_loss: 0.6085, step time: 0.3805\n",
      "68/224, train_loss: 0.5710, step time: 0.3776\n",
      "69/224, train_loss: 0.5567, step time: 0.3712\n",
      "70/224, train_loss: 0.5891, step time: 0.3181\n",
      "71/224, train_loss: 0.5670, step time: 0.3979\n",
      "72/224, train_loss: 0.5666, step time: 0.3680\n",
      "73/224, train_loss: 0.5783, step time: 0.3949\n",
      "74/224, train_loss: 0.5946, step time: 0.3153\n",
      "75/224, train_loss: 0.5698, step time: 0.3145\n",
      "76/224, train_loss: 0.5847, step time: 0.3148\n",
      "77/224, train_loss: 0.5554, step time: 0.3178\n",
      "78/224, train_loss: 0.5540, step time: 0.3948\n",
      "79/224, train_loss: 0.6076, step time: 0.3152\n",
      "80/224, train_loss: 0.5427, step time: 0.3150\n",
      "81/224, train_loss: 0.5374, step time: 0.3146\n",
      "82/224, train_loss: 0.5526, step time: 0.3175\n",
      "83/224, train_loss: 0.5840, step time: 0.3170\n",
      "84/224, train_loss: 0.5640, step time: 0.4096\n",
      "85/224, train_loss: 0.5227, step time: 0.3662\n",
      "86/224, train_loss: 0.5755, step time: 0.3175\n",
      "87/224, train_loss: 0.5630, step time: 0.3149\n",
      "88/224, train_loss: 0.6472, step time: 0.3767\n",
      "89/224, train_loss: 0.5738, step time: 0.3149\n",
      "90/224, train_loss: 0.6177, step time: 0.3851\n",
      "91/224, train_loss: 0.5398, step time: 0.3772\n",
      "92/224, train_loss: 0.5686, step time: 0.3148\n",
      "93/224, train_loss: 0.5017, step time: 0.3147\n",
      "94/224, train_loss: 0.5050, step time: 0.3176\n",
      "95/224, train_loss: 0.5408, step time: 0.3157\n",
      "96/224, train_loss: 0.5982, step time: 0.3922\n",
      "97/224, train_loss: 0.5709, step time: 0.4080\n",
      "98/224, train_loss: 0.5354, step time: 0.3128\n",
      "99/224, train_loss: 0.5904, step time: 0.4019\n",
      "100/224, train_loss: 0.5071, step time: 0.3183\n",
      "101/224, train_loss: 0.5807, step time: 0.3720\n",
      "102/224, train_loss: 0.5655, step time: 0.3697\n",
      "103/224, train_loss: 0.5656, step time: 0.4026\n",
      "104/224, train_loss: 0.5683, step time: 0.3151\n",
      "105/224, train_loss: 0.5300, step time: 0.3151\n",
      "106/224, train_loss: 0.6251, step time: 0.3153\n",
      "107/224, train_loss: 0.5218, step time: 0.3135\n",
      "108/224, train_loss: 0.5367, step time: 0.3780\n",
      "109/224, train_loss: 0.6181, step time: 0.3177\n",
      "110/224, train_loss: 0.6419, step time: 0.3795\n",
      "111/224, train_loss: 0.5335, step time: 0.3141\n",
      "112/224, train_loss: 0.5555, step time: 0.3151\n",
      "113/224, train_loss: 0.5964, step time: 0.3174\n",
      "114/224, train_loss: 0.5712, step time: 0.3165\n",
      "115/224, train_loss: 0.6179, step time: 0.3952\n",
      "116/224, train_loss: 0.6121, step time: 0.3890\n",
      "117/224, train_loss: 0.5575, step time: 0.4063\n",
      "118/224, train_loss: 0.5974, step time: 0.3792\n",
      "119/224, train_loss: 0.5758, step time: 0.3163\n",
      "120/224, train_loss: 0.5840, step time: 0.3191\n",
      "121/224, train_loss: 0.5876, step time: 0.3149\n",
      "122/224, train_loss: 0.5446, step time: 0.3151\n",
      "123/224, train_loss: 0.5842, step time: 0.3159\n",
      "124/224, train_loss: 0.5295, step time: 0.3174\n",
      "125/224, train_loss: 0.6165, step time: 0.3149\n",
      "126/224, train_loss: 0.5665, step time: 0.3145\n",
      "127/224, train_loss: 0.5071, step time: 0.3174\n",
      "128/224, train_loss: 0.5666, step time: 0.3156\n",
      "129/224, train_loss: 0.5549, step time: 0.3960\n",
      "130/224, train_loss: 0.5519, step time: 0.3725\n",
      "131/224, train_loss: 0.5508, step time: 0.3133\n",
      "132/224, train_loss: 0.5545, step time: 0.3174\n",
      "133/224, train_loss: 0.6413, step time: 0.4039\n",
      "134/224, train_loss: 0.6090, step time: 0.3147\n",
      "135/224, train_loss: 0.5093, step time: 0.3172\n",
      "136/224, train_loss: 0.6302, step time: 0.3794\n",
      "137/224, train_loss: 0.5445, step time: 0.4038\n",
      "138/224, train_loss: 0.6179, step time: 0.3172\n",
      "139/224, train_loss: 0.6069, step time: 0.3934\n",
      "140/224, train_loss: 0.4940, step time: 0.3144\n",
      "141/224, train_loss: 0.5735, step time: 0.3150\n",
      "142/224, train_loss: 0.5397, step time: 0.3141\n",
      "143/224, train_loss: 0.5704, step time: 0.3947\n",
      "144/224, train_loss: 0.5665, step time: 0.3167\n",
      "145/224, train_loss: 0.5163, step time: 0.3147\n",
      "146/224, train_loss: 0.5896, step time: 0.3746\n",
      "147/224, train_loss: 0.5457, step time: 0.3168\n",
      "148/224, train_loss: 0.5961, step time: 0.3937\n",
      "149/224, train_loss: 0.5303, step time: 0.3125\n",
      "150/224, train_loss: 0.6057, step time: 0.3140\n",
      "151/224, train_loss: 0.5667, step time: 0.3165\n",
      "152/224, train_loss: 0.5960, step time: 0.4015\n",
      "153/224, train_loss: 0.5936, step time: 0.3153\n",
      "154/224, train_loss: 0.5333, step time: 0.3703\n",
      "155/224, train_loss: 0.5943, step time: 0.3919\n",
      "156/224, train_loss: 0.5815, step time: 0.3147\n",
      "157/224, train_loss: 0.5970, step time: 0.3172\n",
      "158/224, train_loss: 0.5775, step time: 0.4010\n",
      "159/224, train_loss: 0.5601, step time: 0.3807\n",
      "160/224, train_loss: 0.5207, step time: 0.3121\n",
      "161/224, train_loss: 0.5726, step time: 0.3790\n",
      "162/224, train_loss: 0.5800, step time: 0.3127\n",
      "163/224, train_loss: 0.5595, step time: 0.3150\n",
      "164/224, train_loss: 0.5768, step time: 0.3170\n",
      "165/224, train_loss: 0.5414, step time: 0.4086\n",
      "166/224, train_loss: 0.5890, step time: 0.3175\n",
      "167/224, train_loss: 0.5030, step time: 0.3124\n",
      "168/224, train_loss: 0.5850, step time: 0.3683\n",
      "169/224, train_loss: 0.5616, step time: 0.4020\n",
      "170/224, train_loss: 0.5688, step time: 0.3122\n",
      "171/224, train_loss: 0.6027, step time: 0.3142\n",
      "172/224, train_loss: 0.5965, step time: 0.3169\n",
      "173/224, train_loss: 0.6263, step time: 0.3748\n",
      "174/224, train_loss: 0.5364, step time: 0.3850\n",
      "175/224, train_loss: 0.5113, step time: 0.3154\n",
      "176/224, train_loss: 0.6148, step time: 0.3175\n",
      "177/224, train_loss: 0.5213, step time: 0.3825\n",
      "178/224, train_loss: 0.5439, step time: 0.3828\n",
      "179/224, train_loss: 0.5904, step time: 0.3159\n",
      "180/224, train_loss: 0.5639, step time: 0.3159\n",
      "181/224, train_loss: 0.5158, step time: 0.3147\n",
      "182/224, train_loss: 0.5888, step time: 0.3749\n",
      "183/224, train_loss: 0.5417, step time: 0.3147\n",
      "184/224, train_loss: 0.6064, step time: 0.3721\n",
      "185/224, train_loss: 0.5656, step time: 0.3128\n",
      "186/224, train_loss: 0.5354, step time: 0.3168\n",
      "187/224, train_loss: 0.5854, step time: 0.3145\n",
      "188/224, train_loss: 0.6239, step time: 0.3647\n",
      "189/224, train_loss: 0.5659, step time: 0.3146\n",
      "190/224, train_loss: 0.5305, step time: 0.3126\n",
      "191/224, train_loss: 0.5370, step time: 0.3150\n",
      "192/224, train_loss: 0.5455, step time: 0.3142\n",
      "193/224, train_loss: 0.5442, step time: 0.3842\n",
      "194/224, train_loss: 0.5164, step time: 0.4044\n",
      "195/224, train_loss: 0.5708, step time: 0.4036\n",
      "196/224, train_loss: 0.5790, step time: 0.3186\n",
      "197/224, train_loss: 0.5698, step time: 0.3161\n",
      "198/224, train_loss: 0.5840, step time: 0.3131\n",
      "199/224, train_loss: 0.6029, step time: 0.3173\n",
      "200/224, train_loss: 0.5697, step time: 0.3992\n",
      "201/224, train_loss: 0.5632, step time: 0.3748\n",
      "202/224, train_loss: 0.5743, step time: 0.4080\n",
      "203/224, train_loss: 0.5148, step time: 0.3137\n",
      "204/224, train_loss: 0.5267, step time: 0.3822\n",
      "205/224, train_loss: 0.5677, step time: 0.4122\n",
      "206/224, train_loss: 0.5591, step time: 0.3177\n",
      "207/224, train_loss: 0.5124, step time: 0.3841\n",
      "208/224, train_loss: 0.5218, step time: 0.3991\n",
      "209/224, train_loss: 0.5323, step time: 0.3159\n",
      "210/224, train_loss: 0.5676, step time: 0.3941\n",
      "211/224, train_loss: 0.5362, step time: 0.3179\n",
      "212/224, train_loss: 0.5419, step time: 0.3149\n",
      "213/224, train_loss: 0.5917, step time: 0.4117\n",
      "214/224, train_loss: 0.5751, step time: 0.3142\n",
      "215/224, train_loss: 0.6360, step time: 0.3177\n",
      "216/224, train_loss: 0.5770, step time: 0.3916\n",
      "217/224, train_loss: 0.5860, step time: 0.3159\n",
      "218/224, train_loss: 0.5434, step time: 0.3157\n",
      "219/224, train_loss: 0.4690, step time: 0.3158\n",
      "220/224, train_loss: 0.5998, step time: 0.3827\n",
      "221/224, train_loss: 0.6168, step time: 0.3819\n",
      "222/224, train_loss: 0.5078, step time: 0.3161\n",
      "223/224, train_loss: 0.5540, step time: 0.3722\n",
      "224/224, train_loss: 0.4963, step time: 0.3154\n",
      "epoch 5 average loss: 0.5734\n",
      "current epoch: 5 current mean dice: 0.5053 class1: 0.9984 class2: 0.5169 class3: 0.0005\n",
      "best mean dice: 0.5053 at epoch: 5\n",
      "time consuming of epoch 5 is: 695.5350\n",
      "hello\n",
      "----------\n",
      "epoch 6/100\n",
      "1/224, train_loss: 0.5874, step time: 0.3894\n",
      "2/224, train_loss: 0.5526, step time: 0.3151\n",
      "3/224, train_loss: 0.5562, step time: 0.3152\n",
      "4/224, train_loss: 0.5463, step time: 0.3969\n",
      "5/224, train_loss: 0.5411, step time: 0.3167\n",
      "6/224, train_loss: 0.5212, step time: 0.3146\n",
      "7/224, train_loss: 0.5526, step time: 0.3162\n",
      "8/224, train_loss: 0.5393, step time: 0.3153\n",
      "9/224, train_loss: 0.4920, step time: 0.3152\n",
      "10/224, train_loss: 0.4927, step time: 0.3973\n",
      "11/224, train_loss: 0.5642, step time: 0.3895\n",
      "12/224, train_loss: 0.5215, step time: 0.3153\n",
      "13/224, train_loss: 0.5506, step time: 0.3155\n",
      "14/224, train_loss: 0.5356, step time: 0.3906\n",
      "15/224, train_loss: 0.5908, step time: 0.3141\n",
      "16/224, train_loss: 0.5254, step time: 0.3131\n",
      "17/224, train_loss: 0.6004, step time: 0.3162\n",
      "18/224, train_loss: 0.5991, step time: 0.3738\n",
      "19/224, train_loss: 0.6054, step time: 0.3741\n",
      "20/224, train_loss: 0.5459, step time: 0.3160\n",
      "21/224, train_loss: 0.5255, step time: 0.3992\n",
      "22/224, train_loss: 0.5391, step time: 0.3157\n",
      "23/224, train_loss: 0.5280, step time: 0.3165\n",
      "24/224, train_loss: 0.4949, step time: 0.3167\n",
      "25/224, train_loss: 0.5266, step time: 0.4103\n",
      "26/224, train_loss: 0.5420, step time: 0.3154\n",
      "27/224, train_loss: 0.5809, step time: 0.3134\n",
      "28/224, train_loss: 0.6180, step time: 0.3157\n",
      "29/224, train_loss: 0.6227, step time: 0.3163\n",
      "30/224, train_loss: 0.5395, step time: 0.3168\n",
      "31/224, train_loss: 0.5088, step time: 0.3148\n",
      "32/224, train_loss: 0.5713, step time: 0.3765\n",
      "33/224, train_loss: 0.5075, step time: 0.3911\n",
      "34/224, train_loss: 0.5807, step time: 0.3159\n",
      "35/224, train_loss: 0.5340, step time: 0.3926\n",
      "36/224, train_loss: 0.5038, step time: 0.3158\n",
      "37/224, train_loss: 0.5301, step time: 0.3161\n",
      "38/224, train_loss: 0.5997, step time: 0.3681\n",
      "39/224, train_loss: 0.5999, step time: 0.3886\n",
      "40/224, train_loss: 0.5465, step time: 0.3163\n",
      "41/224, train_loss: 0.5682, step time: 0.3823\n",
      "42/224, train_loss: 0.5490, step time: 0.3841\n",
      "43/224, train_loss: 0.5642, step time: 0.3181\n",
      "44/224, train_loss: 0.5084, step time: 0.3128\n",
      "45/224, train_loss: 0.5665, step time: 0.3154\n",
      "46/224, train_loss: 0.5319, step time: 0.3764\n",
      "47/224, train_loss: 0.6007, step time: 0.3821\n",
      "48/224, train_loss: 0.5182, step time: 0.3130\n",
      "49/224, train_loss: 0.5801, step time: 0.3152\n",
      "50/224, train_loss: 0.6318, step time: 0.3152\n",
      "51/224, train_loss: 0.5733, step time: 0.4058\n",
      "52/224, train_loss: 0.5557, step time: 0.3808\n",
      "53/224, train_loss: 0.5130, step time: 0.3161\n",
      "54/224, train_loss: 0.5606, step time: 0.3179\n",
      "55/224, train_loss: 0.5744, step time: 0.3694\n",
      "56/224, train_loss: 0.5176, step time: 0.3162\n",
      "57/224, train_loss: 0.5707, step time: 0.3161\n",
      "58/224, train_loss: 0.5528, step time: 0.3782\n",
      "59/224, train_loss: 0.5502, step time: 0.3180\n",
      "60/224, train_loss: 0.4994, step time: 0.3760\n",
      "61/224, train_loss: 0.5331, step time: 0.3183\n",
      "62/224, train_loss: 0.5163, step time: 0.4048\n",
      "63/224, train_loss: 0.4942, step time: 0.4137\n",
      "64/224, train_loss: 0.5297, step time: 0.3778\n",
      "65/224, train_loss: 0.5297, step time: 0.3182\n",
      "66/224, train_loss: 0.5550, step time: 0.3177\n",
      "67/224, train_loss: 0.5223, step time: 0.3154\n",
      "68/224, train_loss: 0.5451, step time: 0.3158\n",
      "69/224, train_loss: 0.5413, step time: 0.3157\n",
      "70/224, train_loss: 0.5266, step time: 0.3155\n",
      "71/224, train_loss: 0.4997, step time: 0.3948\n",
      "72/224, train_loss: 0.5241, step time: 0.3155\n",
      "73/224, train_loss: 0.5204, step time: 0.3159\n",
      "74/224, train_loss: 0.5346, step time: 0.3157\n",
      "75/224, train_loss: 0.5428, step time: 0.3154\n",
      "76/224, train_loss: 0.5258, step time: 0.3151\n",
      "77/224, train_loss: 0.5969, step time: 0.3156\n",
      "78/224, train_loss: 0.4877, step time: 0.3159\n",
      "79/224, train_loss: 0.4627, step time: 0.3688\n",
      "80/224, train_loss: 0.5522, step time: 0.3958\n",
      "81/224, train_loss: 0.5436, step time: 0.4064\n",
      "82/224, train_loss: 0.5872, step time: 0.4124\n",
      "83/224, train_loss: 0.5660, step time: 0.3163\n",
      "84/224, train_loss: 0.5259, step time: 0.3157\n",
      "85/224, train_loss: 0.4957, step time: 0.3898\n",
      "86/224, train_loss: 0.4940, step time: 0.3155\n",
      "87/224, train_loss: 0.5102, step time: 0.3772\n",
      "88/224, train_loss: 0.5802, step time: 0.4078\n",
      "89/224, train_loss: 0.5364, step time: 0.3922\n",
      "90/224, train_loss: 0.5661, step time: 0.3162\n",
      "91/224, train_loss: 0.4832, step time: 0.3184\n",
      "92/224, train_loss: 0.5639, step time: 0.4106\n",
      "93/224, train_loss: 0.5907, step time: 0.4046\n",
      "94/224, train_loss: 0.5989, step time: 0.3903\n",
      "95/224, train_loss: 0.5509, step time: 0.3870\n",
      "96/224, train_loss: 0.4980, step time: 0.3801\n",
      "97/224, train_loss: 0.5285, step time: 0.4035\n",
      "98/224, train_loss: 0.5507, step time: 0.3774\n",
      "99/224, train_loss: 0.5862, step time: 0.3734\n",
      "100/224, train_loss: 0.5429, step time: 0.4064\n",
      "101/224, train_loss: 0.4596, step time: 0.3161\n",
      "102/224, train_loss: 0.4937, step time: 0.3780\n",
      "103/224, train_loss: 0.5007, step time: 0.3831\n",
      "104/224, train_loss: 0.5795, step time: 0.3177\n",
      "105/224, train_loss: 0.4799, step time: 0.4037\n",
      "106/224, train_loss: 0.4678, step time: 0.3933\n",
      "107/224, train_loss: 0.5169, step time: 0.4125\n",
      "108/224, train_loss: 0.5221, step time: 0.3151\n",
      "109/224, train_loss: 0.4834, step time: 0.3158\n",
      "110/224, train_loss: 0.5154, step time: 0.3713\n",
      "111/224, train_loss: 0.4531, step time: 0.3687\n",
      "112/224, train_loss: 0.5470, step time: 0.3806\n",
      "113/224, train_loss: 0.4616, step time: 0.3707\n",
      "114/224, train_loss: 0.5038, step time: 0.3164\n",
      "115/224, train_loss: 0.5225, step time: 0.3150\n",
      "116/224, train_loss: 0.5889, step time: 0.3161\n",
      "117/224, train_loss: 0.5480, step time: 0.3808\n",
      "118/224, train_loss: 0.4603, step time: 0.3927\n",
      "119/224, train_loss: 0.5075, step time: 0.3132\n",
      "120/224, train_loss: 0.4802, step time: 0.3768\n",
      "121/224, train_loss: 0.4541, step time: 0.3159\n",
      "122/224, train_loss: 0.4980, step time: 0.3140\n",
      "123/224, train_loss: 0.5043, step time: 0.3156\n",
      "124/224, train_loss: 0.5494, step time: 0.3158\n",
      "125/224, train_loss: 0.5118, step time: 0.3972\n",
      "126/224, train_loss: 0.5006, step time: 0.3828\n",
      "127/224, train_loss: 0.4856, step time: 0.3162\n",
      "128/224, train_loss: 0.4765, step time: 0.3134\n",
      "129/224, train_loss: 0.5224, step time: 0.3156\n",
      "130/224, train_loss: 0.4772, step time: 0.3151\n",
      "131/224, train_loss: 0.5020, step time: 0.4123\n",
      "132/224, train_loss: 0.5243, step time: 0.3931\n",
      "133/224, train_loss: 0.5041, step time: 0.3876\n",
      "134/224, train_loss: 0.5087, step time: 0.3156\n",
      "135/224, train_loss: 0.4659, step time: 0.3175\n",
      "136/224, train_loss: 0.5086, step time: 0.3809\n",
      "137/224, train_loss: 0.5191, step time: 0.3186\n",
      "138/224, train_loss: 0.5626, step time: 0.3896\n",
      "139/224, train_loss: 0.6056, step time: 0.3718\n",
      "140/224, train_loss: 0.5804, step time: 0.3805\n",
      "141/224, train_loss: 0.5198, step time: 0.4089\n",
      "142/224, train_loss: 0.5757, step time: 0.3181\n",
      "143/224, train_loss: 0.5037, step time: 0.3992\n",
      "144/224, train_loss: 0.4913, step time: 0.3774\n",
      "145/224, train_loss: 0.4795, step time: 0.3838\n",
      "146/224, train_loss: 0.5050, step time: 0.3129\n",
      "147/224, train_loss: 0.5290, step time: 0.3153\n",
      "148/224, train_loss: 0.5205, step time: 0.3159\n",
      "149/224, train_loss: 0.5932, step time: 0.3815\n",
      "150/224, train_loss: 0.4927, step time: 0.3664\n",
      "151/224, train_loss: 0.4876, step time: 0.3177\n",
      "152/224, train_loss: 0.5121, step time: 0.3151\n",
      "153/224, train_loss: 0.5281, step time: 0.3912\n",
      "154/224, train_loss: 0.6036, step time: 0.3726\n",
      "155/224, train_loss: 0.4872, step time: 0.3715\n",
      "156/224, train_loss: 0.5361, step time: 0.3962\n",
      "157/224, train_loss: 0.4864, step time: 0.3158\n",
      "158/224, train_loss: 0.4659, step time: 0.3178\n",
      "159/224, train_loss: 0.5566, step time: 0.3154\n",
      "160/224, train_loss: 0.5077, step time: 0.4082\n",
      "161/224, train_loss: 0.6336, step time: 0.3174\n",
      "162/224, train_loss: 0.4847, step time: 0.3712\n",
      "163/224, train_loss: 0.4966, step time: 0.3951\n",
      "164/224, train_loss: 0.4819, step time: 0.3152\n",
      "165/224, train_loss: 0.5040, step time: 0.3177\n",
      "166/224, train_loss: 0.5688, step time: 0.3140\n",
      "167/224, train_loss: 0.4572, step time: 0.3162\n",
      "168/224, train_loss: 0.4738, step time: 0.3905\n",
      "169/224, train_loss: 0.4674, step time: 0.4041\n",
      "170/224, train_loss: 0.5069, step time: 0.3180\n",
      "171/224, train_loss: 0.5607, step time: 0.3138\n",
      "172/224, train_loss: 0.4780, step time: 0.3157\n",
      "173/224, train_loss: 0.6392, step time: 0.4069\n",
      "174/224, train_loss: 0.4990, step time: 0.3784\n",
      "175/224, train_loss: 0.4539, step time: 0.3180\n",
      "176/224, train_loss: 0.5354, step time: 0.3915\n",
      "177/224, train_loss: 0.4509, step time: 0.3177\n",
      "178/224, train_loss: 0.5349, step time: 0.3667\n",
      "179/224, train_loss: 0.5305, step time: 0.3150\n",
      "180/224, train_loss: 0.4758, step time: 0.3157\n",
      "181/224, train_loss: 0.5346, step time: 0.3986\n",
      "182/224, train_loss: 0.4732, step time: 0.3158\n",
      "183/224, train_loss: 0.5606, step time: 0.4024\n",
      "184/224, train_loss: 0.5857, step time: 0.3849\n",
      "185/224, train_loss: 0.4921, step time: 0.3141\n",
      "186/224, train_loss: 0.4936, step time: 0.3774\n",
      "187/224, train_loss: 0.5888, step time: 0.3130\n",
      "188/224, train_loss: 0.5318, step time: 0.3147\n",
      "189/224, train_loss: 0.4716, step time: 0.4064\n",
      "190/224, train_loss: 0.5454, step time: 0.3826\n",
      "191/224, train_loss: 0.4833, step time: 0.3153\n",
      "192/224, train_loss: 0.5167, step time: 0.4129\n",
      "193/224, train_loss: 0.4560, step time: 0.3178\n",
      "194/224, train_loss: 0.5046, step time: 0.4058\n",
      "195/224, train_loss: 0.4684, step time: 0.3179\n",
      "196/224, train_loss: 0.4789, step time: 0.3186\n",
      "197/224, train_loss: 0.4922, step time: 0.3158\n",
      "198/224, train_loss: 0.4591, step time: 0.3128\n",
      "199/224, train_loss: 0.4474, step time: 0.3151\n",
      "200/224, train_loss: 0.5560, step time: 0.3150\n",
      "201/224, train_loss: 0.5235, step time: 0.3156\n",
      "202/224, train_loss: 0.5033, step time: 0.3174\n",
      "203/224, train_loss: 0.4567, step time: 0.3156\n",
      "204/224, train_loss: 0.5762, step time: 0.3157\n",
      "205/224, train_loss: 0.5711, step time: 0.3940\n",
      "206/224, train_loss: 0.5501, step time: 0.3157\n",
      "207/224, train_loss: 0.5052, step time: 0.3157\n",
      "208/224, train_loss: 0.5229, step time: 0.4087\n",
      "209/224, train_loss: 0.5306, step time: 0.3691\n",
      "210/224, train_loss: 0.5351, step time: 0.3154\n",
      "211/224, train_loss: 0.4640, step time: 0.3716\n",
      "212/224, train_loss: 0.5785, step time: 0.3652\n",
      "213/224, train_loss: 0.5162, step time: 0.3942\n",
      "214/224, train_loss: 0.5361, step time: 0.3150\n",
      "215/224, train_loss: 0.4649, step time: 0.3148\n",
      "216/224, train_loss: 0.4588, step time: 0.3175\n",
      "217/224, train_loss: 0.4882, step time: 0.3153\n",
      "218/224, train_loss: 0.5016, step time: 0.3172\n",
      "219/224, train_loss: 0.5658, step time: 0.3883\n",
      "220/224, train_loss: 0.5540, step time: 0.3675\n",
      "221/224, train_loss: 0.5935, step time: 0.4019\n",
      "222/224, train_loss: 0.4593, step time: 0.3138\n",
      "223/224, train_loss: 0.4543, step time: 0.3155\n",
      "224/224, train_loss: 0.4530, step time: 0.3161\n",
      "epoch 6 average loss: 0.5269\n",
      "current epoch: 6 current mean dice: 0.5337 class1: 0.9984 class2: 0.6021 class3: 0.0005\n",
      "best mean dice: 0.5337 at epoch: 6\n",
      "time consuming of epoch 6 is: 673.9524\n",
      "hello\n",
      "----------\n",
      "epoch 7/100\n",
      "1/224, train_loss: 0.5015, step time: 0.3153\n",
      "2/224, train_loss: 0.5760, step time: 0.3152\n",
      "3/224, train_loss: 0.5670, step time: 0.4127\n",
      "4/224, train_loss: 0.4738, step time: 0.3833\n",
      "5/224, train_loss: 0.4520, step time: 0.3156\n",
      "6/224, train_loss: 0.4735, step time: 0.3153\n",
      "7/224, train_loss: 0.5013, step time: 0.3752\n",
      "8/224, train_loss: 0.5443, step time: 0.3793\n",
      "9/224, train_loss: 0.4623, step time: 0.3867\n",
      "10/224, train_loss: 0.5611, step time: 0.3188\n",
      "11/224, train_loss: 0.5588, step time: 0.4093\n",
      "12/224, train_loss: 0.4235, step time: 0.3172\n",
      "13/224, train_loss: 0.4775, step time: 0.3181\n",
      "14/224, train_loss: 0.4776, step time: 0.3680\n",
      "15/224, train_loss: 0.4438, step time: 0.3149\n",
      "16/224, train_loss: 0.4319, step time: 0.3156\n",
      "17/224, train_loss: 0.4594, step time: 0.3139\n",
      "18/224, train_loss: 0.5679, step time: 0.3156\n",
      "19/224, train_loss: 0.4865, step time: 0.3994\n",
      "20/224, train_loss: 0.5245, step time: 0.3895\n",
      "21/224, train_loss: 0.5026, step time: 0.3131\n",
      "22/224, train_loss: 0.4634, step time: 0.3130\n",
      "23/224, train_loss: 0.4675, step time: 0.3152\n",
      "24/224, train_loss: 0.4961, step time: 0.3155\n",
      "25/224, train_loss: 0.5026, step time: 0.4035\n",
      "26/224, train_loss: 0.4686, step time: 0.3716\n",
      "27/224, train_loss: 0.4627, step time: 0.3150\n",
      "28/224, train_loss: 0.5169, step time: 0.3946\n",
      "29/224, train_loss: 0.4634, step time: 0.3700\n",
      "30/224, train_loss: 0.4828, step time: 0.3164\n",
      "31/224, train_loss: 0.5645, step time: 0.3140\n",
      "32/224, train_loss: 0.5625, step time: 0.3185\n",
      "33/224, train_loss: 0.6317, step time: 0.4070\n",
      "34/224, train_loss: 0.5773, step time: 0.3932\n",
      "35/224, train_loss: 0.4848, step time: 0.3785\n",
      "36/224, train_loss: 0.4634, step time: 0.3151\n",
      "37/224, train_loss: 0.4511, step time: 0.3178\n",
      "38/224, train_loss: 0.4598, step time: 0.3178\n",
      "39/224, train_loss: 0.4441, step time: 0.3901\n",
      "40/224, train_loss: 0.4947, step time: 0.4103\n",
      "41/224, train_loss: 0.4968, step time: 0.3824\n",
      "42/224, train_loss: 0.5469, step time: 0.4035\n",
      "43/224, train_loss: 0.5632, step time: 0.3137\n",
      "44/224, train_loss: 0.5155, step time: 0.3159\n",
      "45/224, train_loss: 0.5619, step time: 0.3159\n",
      "46/224, train_loss: 0.4965, step time: 0.3943\n",
      "47/224, train_loss: 0.4480, step time: 0.3992\n",
      "48/224, train_loss: 0.5672, step time: 0.3133\n",
      "49/224, train_loss: 0.4799, step time: 0.3149\n",
      "50/224, train_loss: 0.4681, step time: 0.3700\n",
      "51/224, train_loss: 0.5206, step time: 0.3173\n",
      "52/224, train_loss: 0.4846, step time: 0.3149\n",
      "53/224, train_loss: 0.5055, step time: 0.3155\n",
      "54/224, train_loss: 0.5080, step time: 0.3176\n",
      "55/224, train_loss: 0.5132, step time: 0.3152\n",
      "56/224, train_loss: 0.4945, step time: 0.3822\n",
      "57/224, train_loss: 0.4827, step time: 0.3153\n",
      "58/224, train_loss: 0.5064, step time: 0.3173\n",
      "59/224, train_loss: 0.5054, step time: 0.3818\n",
      "60/224, train_loss: 0.4543, step time: 0.3157\n",
      "61/224, train_loss: 0.4865, step time: 0.3175\n",
      "62/224, train_loss: 0.5283, step time: 0.3749\n",
      "63/224, train_loss: 0.5993, step time: 0.3982\n",
      "64/224, train_loss: 0.5454, step time: 0.3782\n",
      "65/224, train_loss: 0.4238, step time: 0.3164\n",
      "66/224, train_loss: 0.4870, step time: 0.3760\n",
      "67/224, train_loss: 0.5232, step time: 0.3153\n",
      "68/224, train_loss: 0.5091, step time: 0.4061\n",
      "69/224, train_loss: 0.4625, step time: 0.3165\n",
      "70/224, train_loss: 0.4434, step time: 0.3881\n",
      "71/224, train_loss: 0.5579, step time: 0.4052\n",
      "72/224, train_loss: 0.5030, step time: 0.3176\n",
      "73/224, train_loss: 0.4975, step time: 0.3157\n",
      "74/224, train_loss: 0.5027, step time: 0.3177\n",
      "75/224, train_loss: 0.4476, step time: 0.3176\n",
      "76/224, train_loss: 0.4718, step time: 0.3129\n",
      "77/224, train_loss: 0.4514, step time: 0.3132\n",
      "78/224, train_loss: 0.4802, step time: 0.3137\n",
      "79/224, train_loss: 0.4483, step time: 0.3895\n",
      "80/224, train_loss: 0.4765, step time: 0.3688\n",
      "81/224, train_loss: 0.4897, step time: 0.3879\n",
      "82/224, train_loss: 0.4927, step time: 0.3970\n",
      "83/224, train_loss: 0.4679, step time: 0.4097\n",
      "84/224, train_loss: 0.4733, step time: 0.3714\n",
      "85/224, train_loss: 0.4691, step time: 0.3995\n",
      "86/224, train_loss: 0.4571, step time: 0.3696\n",
      "87/224, train_loss: 0.5916, step time: 0.4008\n",
      "88/224, train_loss: 0.5585, step time: 0.3726\n",
      "89/224, train_loss: 0.4955, step time: 0.3156\n",
      "90/224, train_loss: 0.4961, step time: 0.4118\n",
      "91/224, train_loss: 0.4649, step time: 0.4009\n",
      "92/224, train_loss: 0.5915, step time: 0.3918\n",
      "93/224, train_loss: 0.4570, step time: 0.3695\n",
      "94/224, train_loss: 0.5042, step time: 0.3154\n",
      "95/224, train_loss: 0.6436, step time: 0.3906\n",
      "96/224, train_loss: 0.5285, step time: 0.3669\n",
      "97/224, train_loss: 0.5000, step time: 0.3920\n",
      "98/224, train_loss: 0.4902, step time: 0.3941\n",
      "99/224, train_loss: 0.4972, step time: 0.3847\n",
      "100/224, train_loss: 0.5025, step time: 0.3147\n",
      "101/224, train_loss: 0.4471, step time: 0.3693\n",
      "102/224, train_loss: 0.5340, step time: 0.3129\n",
      "103/224, train_loss: 0.4658, step time: 0.3131\n",
      "104/224, train_loss: 0.4646, step time: 0.3159\n",
      "105/224, train_loss: 0.5610, step time: 0.3907\n",
      "106/224, train_loss: 0.4420, step time: 0.3730\n",
      "107/224, train_loss: 0.4663, step time: 0.3183\n",
      "108/224, train_loss: 0.4642, step time: 0.3164\n",
      "109/224, train_loss: 0.5373, step time: 0.3804\n",
      "110/224, train_loss: 0.5598, step time: 0.3778\n",
      "111/224, train_loss: 0.5217, step time: 0.4032\n",
      "112/224, train_loss: 0.5088, step time: 0.3809\n",
      "113/224, train_loss: 0.4365, step time: 0.3949\n",
      "114/224, train_loss: 0.4402, step time: 0.3160\n",
      "115/224, train_loss: 0.4863, step time: 0.3708\n",
      "116/224, train_loss: 0.4561, step time: 0.3925\n",
      "117/224, train_loss: 0.4759, step time: 0.3178\n",
      "118/224, train_loss: 0.5052, step time: 0.3178\n",
      "119/224, train_loss: 0.5282, step time: 0.3164\n",
      "120/224, train_loss: 0.4561, step time: 0.3842\n",
      "121/224, train_loss: 0.4783, step time: 0.3981\n",
      "122/224, train_loss: 0.5319, step time: 0.3711\n",
      "123/224, train_loss: 0.5117, step time: 0.3980\n",
      "124/224, train_loss: 0.4436, step time: 0.3178\n",
      "125/224, train_loss: 0.5492, step time: 0.3874\n",
      "126/224, train_loss: 0.4701, step time: 0.3149\n",
      "127/224, train_loss: 0.4621, step time: 0.3151\n",
      "128/224, train_loss: 0.4883, step time: 0.3150\n",
      "129/224, train_loss: 0.4481, step time: 0.3148\n",
      "130/224, train_loss: 0.5099, step time: 0.3172\n",
      "131/224, train_loss: 0.5293, step time: 0.3151\n",
      "132/224, train_loss: 0.4525, step time: 0.3772\n",
      "133/224, train_loss: 0.4832, step time: 0.3772\n",
      "134/224, train_loss: 0.4163, step time: 0.3745\n",
      "135/224, train_loss: 0.4475, step time: 0.3150\n",
      "136/224, train_loss: 0.4886, step time: 0.3668\n",
      "137/224, train_loss: 0.5041, step time: 0.4074\n",
      "138/224, train_loss: 0.5114, step time: 0.4066\n",
      "139/224, train_loss: 0.4318, step time: 0.3143\n",
      "140/224, train_loss: 0.5013, step time: 0.4136\n",
      "141/224, train_loss: 0.4379, step time: 0.3130\n",
      "142/224, train_loss: 0.4616, step time: 0.3717\n",
      "143/224, train_loss: 0.5307, step time: 0.3154\n",
      "144/224, train_loss: 0.4381, step time: 0.3176\n",
      "145/224, train_loss: 0.4599, step time: 0.3137\n",
      "146/224, train_loss: 0.5727, step time: 0.3177\n",
      "147/224, train_loss: 0.4609, step time: 0.4055\n",
      "148/224, train_loss: 0.4932, step time: 0.3172\n",
      "149/224, train_loss: 0.4622, step time: 0.3929\n",
      "150/224, train_loss: 0.5205, step time: 0.3996\n",
      "151/224, train_loss: 0.4640, step time: 0.3184\n",
      "152/224, train_loss: 0.5621, step time: 0.3823\n",
      "153/224, train_loss: 0.4744, step time: 0.3181\n",
      "154/224, train_loss: 0.5468, step time: 0.3149\n",
      "155/224, train_loss: 0.5296, step time: 0.3691\n",
      "156/224, train_loss: 0.4623, step time: 0.3998\n",
      "157/224, train_loss: 0.4223, step time: 0.3846\n",
      "158/224, train_loss: 0.4388, step time: 0.3179\n",
      "159/224, train_loss: 0.4674, step time: 0.3942\n",
      "160/224, train_loss: 0.5043, step time: 0.3193\n",
      "161/224, train_loss: 0.4857, step time: 0.3669\n",
      "162/224, train_loss: 0.4517, step time: 0.3174\n",
      "163/224, train_loss: 0.5201, step time: 0.3753\n",
      "164/224, train_loss: 0.4990, step time: 0.3171\n",
      "165/224, train_loss: 0.4796, step time: 0.3913\n",
      "166/224, train_loss: 0.4539, step time: 0.3148\n",
      "167/224, train_loss: 0.4471, step time: 0.4086\n",
      "168/224, train_loss: 0.4255, step time: 0.3156\n",
      "169/224, train_loss: 0.4489, step time: 0.3134\n",
      "170/224, train_loss: 0.4590, step time: 0.3173\n",
      "171/224, train_loss: 0.4596, step time: 0.4085\n",
      "172/224, train_loss: 0.4342, step time: 0.3156\n",
      "173/224, train_loss: 0.5264, step time: 0.3149\n",
      "174/224, train_loss: 0.5321, step time: 0.3132\n",
      "175/224, train_loss: 0.4988, step time: 0.3912\n",
      "176/224, train_loss: 0.4420, step time: 0.3165\n",
      "177/224, train_loss: 0.4949, step time: 0.3772\n",
      "178/224, train_loss: 0.5135, step time: 0.3890\n",
      "179/224, train_loss: 0.4834, step time: 0.3162\n",
      "180/224, train_loss: 0.4470, step time: 0.3821\n",
      "181/224, train_loss: 0.5738, step time: 0.3814\n",
      "182/224, train_loss: 0.4961, step time: 0.3134\n",
      "183/224, train_loss: 0.4893, step time: 0.3789\n",
      "184/224, train_loss: 0.5037, step time: 0.3832\n",
      "185/224, train_loss: 0.5489, step time: 0.4091\n",
      "186/224, train_loss: 0.4912, step time: 0.3182\n",
      "187/224, train_loss: 0.5558, step time: 0.3137\n",
      "188/224, train_loss: 0.4899, step time: 0.3162\n",
      "189/224, train_loss: 0.5004, step time: 0.3655\n",
      "190/224, train_loss: 0.4466, step time: 0.3704\n",
      "191/224, train_loss: 0.5151, step time: 0.3913\n",
      "192/224, train_loss: 0.5368, step time: 0.3153\n",
      "193/224, train_loss: 0.5247, step time: 0.3721\n",
      "194/224, train_loss: 0.5144, step time: 0.3135\n",
      "195/224, train_loss: 0.4834, step time: 0.3728\n",
      "196/224, train_loss: 0.4369, step time: 0.3161\n",
      "197/224, train_loss: 0.4296, step time: 0.3136\n",
      "198/224, train_loss: 0.5032, step time: 0.3945\n",
      "199/224, train_loss: 0.4716, step time: 0.3136\n",
      "200/224, train_loss: 0.4563, step time: 0.3128\n",
      "201/224, train_loss: 0.5702, step time: 0.3852\n",
      "202/224, train_loss: 0.4477, step time: 0.3768\n",
      "203/224, train_loss: 0.4947, step time: 0.3968\n",
      "204/224, train_loss: 0.5091, step time: 0.3152\n",
      "205/224, train_loss: 0.5009, step time: 0.3150\n",
      "206/224, train_loss: 0.4999, step time: 0.3139\n",
      "207/224, train_loss: 0.5189, step time: 0.3159\n",
      "208/224, train_loss: 0.4281, step time: 0.4054\n",
      "209/224, train_loss: 0.4611, step time: 0.3161\n",
      "210/224, train_loss: 0.4780, step time: 0.3892\n",
      "211/224, train_loss: 0.4738, step time: 0.3178\n",
      "212/224, train_loss: 0.4613, step time: 0.3971\n",
      "213/224, train_loss: 0.4534, step time: 0.3173\n",
      "214/224, train_loss: 0.4732, step time: 0.4039\n",
      "215/224, train_loss: 0.4519, step time: 0.3754\n",
      "216/224, train_loss: 0.4604, step time: 0.4053\n",
      "217/224, train_loss: 0.5028, step time: 0.3687\n",
      "218/224, train_loss: 0.4611, step time: 0.3155\n",
      "219/224, train_loss: 0.4365, step time: 0.3757\n",
      "220/224, train_loss: 0.4653, step time: 0.3800\n",
      "221/224, train_loss: 0.5060, step time: 0.3723\n",
      "222/224, train_loss: 0.4501, step time: 0.3897\n",
      "223/224, train_loss: 0.4581, step time: 0.3183\n",
      "224/224, train_loss: 0.4983, step time: 0.3154\n",
      "epoch 7 average loss: 0.4916\n",
      "current epoch: 7 current mean dice: 0.5354 class1: 0.9989 class2: 0.6055 class3: 0.0020\n",
      "best mean dice: 0.5354 at epoch: 7\n",
      "time consuming of epoch 7 is: 749.1447\n",
      "hello\n",
      "----------\n",
      "epoch 8/100\n",
      "1/224, train_loss: 0.4595, step time: 0.4059\n",
      "2/224, train_loss: 0.4285, step time: 0.3163\n",
      "3/224, train_loss: 0.4881, step time: 0.3168\n",
      "4/224, train_loss: 0.4231, step time: 0.3164\n",
      "5/224, train_loss: 0.5634, step time: 0.4102\n",
      "6/224, train_loss: 0.5019, step time: 0.4058\n",
      "7/224, train_loss: 0.4144, step time: 0.4139\n",
      "8/224, train_loss: 0.4873, step time: 0.3165\n",
      "9/224, train_loss: 0.4685, step time: 0.3178\n",
      "10/224, train_loss: 0.5171, step time: 0.3173\n",
      "11/224, train_loss: 0.5460, step time: 0.3850\n",
      "12/224, train_loss: 0.4694, step time: 0.3154\n",
      "13/224, train_loss: 0.4933, step time: 0.3857\n",
      "14/224, train_loss: 0.4654, step time: 0.4136\n",
      "15/224, train_loss: 0.5026, step time: 0.3827\n",
      "16/224, train_loss: 0.5365, step time: 0.3658\n",
      "17/224, train_loss: 0.4274, step time: 0.3160\n",
      "18/224, train_loss: 0.4610, step time: 0.4087\n",
      "19/224, train_loss: 0.4573, step time: 0.3149\n",
      "20/224, train_loss: 0.5198, step time: 0.3159\n",
      "21/224, train_loss: 0.4537, step time: 0.3753\n",
      "22/224, train_loss: 0.4779, step time: 0.3178\n",
      "23/224, train_loss: 0.4148, step time: 0.3176\n",
      "24/224, train_loss: 0.4815, step time: 0.4017\n",
      "25/224, train_loss: 0.4961, step time: 0.3786\n",
      "26/224, train_loss: 0.4499, step time: 0.3670\n",
      "27/224, train_loss: 0.4581, step time: 0.4138\n",
      "28/224, train_loss: 0.4879, step time: 0.3152\n",
      "29/224, train_loss: 0.4647, step time: 0.3148\n",
      "30/224, train_loss: 0.5668, step time: 0.3875\n",
      "31/224, train_loss: 0.4296, step time: 0.3155\n",
      "32/224, train_loss: 0.4566, step time: 0.3977\n",
      "33/224, train_loss: 0.4335, step time: 0.3134\n",
      "34/224, train_loss: 0.4642, step time: 0.4003\n",
      "35/224, train_loss: 0.5325, step time: 0.4037\n",
      "36/224, train_loss: 0.5003, step time: 0.3766\n",
      "37/224, train_loss: 0.5149, step time: 0.3166\n",
      "38/224, train_loss: 0.4966, step time: 0.4119\n",
      "39/224, train_loss: 0.4795, step time: 0.3135\n",
      "40/224, train_loss: 0.4182, step time: 0.3152\n",
      "41/224, train_loss: 0.4321, step time: 0.3745\n",
      "42/224, train_loss: 0.4473, step time: 0.3158\n",
      "43/224, train_loss: 0.4568, step time: 0.3896\n",
      "44/224, train_loss: 0.4298, step time: 0.3159\n",
      "45/224, train_loss: 0.5597, step time: 0.3138\n",
      "46/224, train_loss: 0.4593, step time: 0.3928\n",
      "47/224, train_loss: 0.4642, step time: 0.3165\n",
      "48/224, train_loss: 0.4883, step time: 0.3853\n",
      "49/224, train_loss: 0.4614, step time: 0.3785\n",
      "50/224, train_loss: 0.4910, step time: 0.3687\n",
      "51/224, train_loss: 0.4274, step time: 0.3154\n",
      "52/224, train_loss: 0.4534, step time: 0.3147\n",
      "53/224, train_loss: 0.4400, step time: 0.3137\n",
      "54/224, train_loss: 0.4581, step time: 0.3138\n",
      "55/224, train_loss: 0.5082, step time: 0.3778\n",
      "56/224, train_loss: 0.4920, step time: 0.3660\n",
      "57/224, train_loss: 0.4617, step time: 0.3665\n",
      "58/224, train_loss: 0.4424, step time: 0.3163\n",
      "59/224, train_loss: 0.4174, step time: 0.3804\n",
      "60/224, train_loss: 0.4400, step time: 0.3154\n",
      "61/224, train_loss: 0.5699, step time: 0.3155\n",
      "62/224, train_loss: 0.4301, step time: 0.3150\n",
      "63/224, train_loss: 0.4295, step time: 0.3182\n",
      "64/224, train_loss: 0.4416, step time: 0.3161\n",
      "65/224, train_loss: 0.4727, step time: 0.3143\n",
      "66/224, train_loss: 0.4232, step time: 0.3155\n",
      "67/224, train_loss: 0.4425, step time: 0.3174\n",
      "68/224, train_loss: 0.5360, step time: 0.3796\n",
      "69/224, train_loss: 0.4675, step time: 0.3175\n",
      "70/224, train_loss: 0.4619, step time: 0.3913\n",
      "71/224, train_loss: 0.4174, step time: 0.3131\n",
      "72/224, train_loss: 0.4019, step time: 0.3150\n",
      "73/224, train_loss: 0.4568, step time: 0.3159\n",
      "74/224, train_loss: 0.4537, step time: 0.3711\n",
      "75/224, train_loss: 0.5702, step time: 0.3730\n",
      "76/224, train_loss: 0.5156, step time: 0.3878\n",
      "77/224, train_loss: 0.4183, step time: 0.3157\n",
      "78/224, train_loss: 0.4360, step time: 0.3150\n",
      "79/224, train_loss: 0.4286, step time: 0.3158\n",
      "80/224, train_loss: 0.4389, step time: 0.3155\n",
      "81/224, train_loss: 0.4181, step time: 0.3151\n",
      "82/224, train_loss: 0.5115, step time: 0.3159\n",
      "83/224, train_loss: 0.4257, step time: 0.4089\n",
      "84/224, train_loss: 0.5232, step time: 0.3974\n",
      "85/224, train_loss: 0.4955, step time: 0.3982\n",
      "86/224, train_loss: 0.4181, step time: 0.4080\n",
      "87/224, train_loss: 0.4389, step time: 0.4020\n",
      "88/224, train_loss: 0.4896, step time: 0.3176\n",
      "89/224, train_loss: 0.4874, step time: 0.3149\n",
      "90/224, train_loss: 0.4574, step time: 0.3157\n",
      "91/224, train_loss: 0.4956, step time: 0.3154\n",
      "92/224, train_loss: 0.4632, step time: 0.3803\n",
      "93/224, train_loss: 0.4681, step time: 0.3939\n",
      "94/224, train_loss: 0.4795, step time: 0.3991\n",
      "95/224, train_loss: 0.4540, step time: 0.3140\n",
      "96/224, train_loss: 0.4444, step time: 0.3158\n",
      "97/224, train_loss: 0.4654, step time: 0.4002\n",
      "98/224, train_loss: 0.5513, step time: 0.4095\n",
      "99/224, train_loss: 0.4219, step time: 0.3673\n",
      "100/224, train_loss: 0.4345, step time: 0.3891\n",
      "101/224, train_loss: 0.5285, step time: 0.4112\n",
      "102/224, train_loss: 0.5444, step time: 0.3826\n",
      "103/224, train_loss: 0.4262, step time: 0.3144\n",
      "104/224, train_loss: 0.4862, step time: 0.3922\n",
      "105/224, train_loss: 0.4524, step time: 0.3175\n",
      "106/224, train_loss: 0.4756, step time: 0.3928\n",
      "107/224, train_loss: 0.4792, step time: 0.3683\n",
      "108/224, train_loss: 0.4445, step time: 0.3762\n",
      "109/224, train_loss: 0.4517, step time: 0.3983\n",
      "110/224, train_loss: 0.5224, step time: 0.3148\n",
      "111/224, train_loss: 0.4803, step time: 0.4027\n",
      "112/224, train_loss: 0.4875, step time: 0.3132\n",
      "113/224, train_loss: 0.4696, step time: 0.3172\n",
      "114/224, train_loss: 0.4458, step time: 0.3724\n",
      "115/224, train_loss: 0.5211, step time: 0.3672\n",
      "116/224, train_loss: 0.4565, step time: 0.3748\n",
      "117/224, train_loss: 0.5289, step time: 0.3949\n",
      "118/224, train_loss: 0.4535, step time: 0.3149\n",
      "119/224, train_loss: 0.4537, step time: 0.3710\n",
      "120/224, train_loss: 0.4360, step time: 0.4084\n",
      "121/224, train_loss: 0.4657, step time: 0.3175\n",
      "122/224, train_loss: 0.4148, step time: 0.3154\n",
      "123/224, train_loss: 0.5153, step time: 0.4064\n",
      "124/224, train_loss: 0.4987, step time: 0.3130\n",
      "125/224, train_loss: 0.4518, step time: 0.3148\n",
      "126/224, train_loss: 0.4291, step time: 0.3135\n",
      "127/224, train_loss: 0.4570, step time: 0.3808\n",
      "128/224, train_loss: 0.4987, step time: 0.3170\n",
      "129/224, train_loss: 0.4410, step time: 0.3181\n",
      "130/224, train_loss: 0.4577, step time: 0.3673\n",
      "131/224, train_loss: 0.4692, step time: 0.3149\n",
      "132/224, train_loss: 0.5539, step time: 0.4012\n",
      "133/224, train_loss: 0.5026, step time: 0.4039\n",
      "134/224, train_loss: 0.5097, step time: 0.3144\n",
      "135/224, train_loss: 0.4308, step time: 0.3728\n",
      "136/224, train_loss: 0.4300, step time: 0.3142\n",
      "137/224, train_loss: 0.4788, step time: 0.3861\n",
      "138/224, train_loss: 0.5065, step time: 0.3173\n",
      "139/224, train_loss: 0.4483, step time: 0.3828\n",
      "140/224, train_loss: 0.3965, step time: 0.3722\n",
      "141/224, train_loss: 0.4545, step time: 0.3144\n",
      "142/224, train_loss: 0.4442, step time: 0.3147\n",
      "143/224, train_loss: 0.4097, step time: 0.3165\n",
      "144/224, train_loss: 0.4966, step time: 0.3165\n",
      "145/224, train_loss: 0.4750, step time: 0.3824\n",
      "146/224, train_loss: 0.5583, step time: 0.4068\n",
      "147/224, train_loss: 0.4975, step time: 0.3745\n",
      "148/224, train_loss: 0.4309, step time: 0.4061\n",
      "149/224, train_loss: 0.4498, step time: 0.4085\n",
      "150/224, train_loss: 0.4050, step time: 0.3174\n",
      "151/224, train_loss: 0.4715, step time: 0.3156\n",
      "152/224, train_loss: 0.5791, step time: 0.3844\n",
      "153/224, train_loss: 0.4260, step time: 0.3140\n",
      "154/224, train_loss: 0.4843, step time: 0.3748\n",
      "155/224, train_loss: 0.4433, step time: 0.3166\n",
      "156/224, train_loss: 0.4044, step time: 0.3140\n",
      "157/224, train_loss: 0.4172, step time: 0.3979\n",
      "158/224, train_loss: 0.4199, step time: 0.3140\n",
      "159/224, train_loss: 0.4897, step time: 0.3757\n",
      "160/224, train_loss: 0.4494, step time: 0.3998\n",
      "161/224, train_loss: 0.4481, step time: 0.3131\n",
      "162/224, train_loss: 0.4319, step time: 0.3704\n",
      "163/224, train_loss: 0.4938, step time: 0.3151\n",
      "164/224, train_loss: 0.4264, step time: 0.3130\n",
      "165/224, train_loss: 0.4243, step time: 0.3148\n",
      "166/224, train_loss: 0.4523, step time: 0.4128\n",
      "167/224, train_loss: 0.4180, step time: 0.3130\n",
      "168/224, train_loss: 0.4663, step time: 0.3150\n",
      "169/224, train_loss: 0.4285, step time: 0.3152\n",
      "170/224, train_loss: 0.4444, step time: 0.3148\n",
      "171/224, train_loss: 0.5013, step time: 0.4127\n",
      "172/224, train_loss: 0.4592, step time: 0.3167\n",
      "173/224, train_loss: 0.4755, step time: 0.3837\n",
      "174/224, train_loss: 0.4220, step time: 0.3123\n",
      "175/224, train_loss: 0.4199, step time: 0.3142\n",
      "176/224, train_loss: 0.4501, step time: 0.3144\n",
      "177/224, train_loss: 0.4367, step time: 0.3662\n",
      "178/224, train_loss: 0.5350, step time: 0.3177\n",
      "179/224, train_loss: 0.4644, step time: 0.3143\n",
      "180/224, train_loss: 0.5438, step time: 0.3170\n",
      "181/224, train_loss: 0.3990, step time: 0.3146\n",
      "182/224, train_loss: 0.4226, step time: 0.3854\n",
      "183/224, train_loss: 0.4912, step time: 0.4013\n",
      "184/224, train_loss: 0.4185, step time: 0.4020\n",
      "185/224, train_loss: 0.4112, step time: 0.3967\n",
      "186/224, train_loss: 0.4349, step time: 0.3124\n",
      "187/224, train_loss: 0.3918, step time: 0.3955\n",
      "188/224, train_loss: 0.3935, step time: 0.3170\n",
      "189/224, train_loss: 0.4125, step time: 0.3721\n",
      "190/224, train_loss: 0.4436, step time: 0.3128\n",
      "191/224, train_loss: 0.4746, step time: 0.4009\n",
      "192/224, train_loss: 0.4803, step time: 0.3135\n",
      "193/224, train_loss: 0.4142, step time: 0.3153\n",
      "194/224, train_loss: 0.5372, step time: 0.3688\n",
      "195/224, train_loss: 0.4839, step time: 0.3127\n",
      "196/224, train_loss: 0.5000, step time: 0.3150\n",
      "197/224, train_loss: 0.4494, step time: 0.3808\n",
      "198/224, train_loss: 0.4398, step time: 0.3143\n",
      "199/224, train_loss: 0.4811, step time: 0.3719\n",
      "200/224, train_loss: 0.4121, step time: 0.3145\n",
      "201/224, train_loss: 0.5062, step time: 0.3147\n",
      "202/224, train_loss: 0.4441, step time: 0.4093\n",
      "203/224, train_loss: 0.4417, step time: 0.3124\n",
      "204/224, train_loss: 0.4005, step time: 0.3168\n",
      "205/224, train_loss: 0.4035, step time: 0.3131\n",
      "206/224, train_loss: 0.4369, step time: 0.3876\n",
      "207/224, train_loss: 0.4534, step time: 0.3148\n",
      "208/224, train_loss: 0.4167, step time: 0.4021\n",
      "209/224, train_loss: 0.4263, step time: 0.3143\n",
      "210/224, train_loss: 0.4575, step time: 0.3706\n",
      "211/224, train_loss: 0.4827, step time: 0.3145\n",
      "212/224, train_loss: 0.4539, step time: 0.3140\n",
      "213/224, train_loss: 0.4504, step time: 0.3165\n",
      "214/224, train_loss: 0.4598, step time: 0.3662\n",
      "215/224, train_loss: 0.4201, step time: 0.3136\n",
      "216/224, train_loss: 0.4596, step time: 0.3172\n",
      "217/224, train_loss: 0.5055, step time: 0.3819\n",
      "218/224, train_loss: 0.5245, step time: 0.3752\n",
      "219/224, train_loss: 0.4424, step time: 0.3127\n",
      "220/224, train_loss: 0.4270, step time: 0.3155\n",
      "221/224, train_loss: 0.4910, step time: 0.3182\n",
      "222/224, train_loss: 0.5052, step time: 0.4117\n",
      "223/224, train_loss: 0.4513, step time: 0.3183\n",
      "224/224, train_loss: 0.4250, step time: 0.3786\n",
      "epoch 8 average loss: 0.4639\n",
      "current epoch: 8 current mean dice: 0.5643 class1: 0.9991 class2: 0.6537 class3: 0.0401\n",
      "best mean dice: 0.5643 at epoch: 8\n",
      "time consuming of epoch 8 is: 673.4178\n",
      "hello\n",
      "----------\n",
      "epoch 9/100\n",
      "1/224, train_loss: 0.3956, step time: 0.4099\n",
      "2/224, train_loss: 0.4128, step time: 0.3809\n",
      "3/224, train_loss: 0.4140, step time: 0.3973\n",
      "4/224, train_loss: 0.4203, step time: 0.3193\n",
      "5/224, train_loss: 0.4404, step time: 0.3867\n",
      "6/224, train_loss: 0.5017, step time: 0.3857\n",
      "7/224, train_loss: 0.3898, step time: 0.3175\n",
      "8/224, train_loss: 0.4090, step time: 0.3915\n",
      "9/224, train_loss: 0.5056, step time: 0.4051\n",
      "10/224, train_loss: 0.4636, step time: 0.3169\n",
      "11/224, train_loss: 0.4723, step time: 0.3908\n",
      "12/224, train_loss: 0.4426, step time: 0.3145\n",
      "13/224, train_loss: 0.4334, step time: 0.3190\n",
      "14/224, train_loss: 0.4141, step time: 0.4112\n",
      "15/224, train_loss: 0.4647, step time: 0.4027\n",
      "16/224, train_loss: 0.4303, step time: 0.3171\n",
      "17/224, train_loss: 0.4071, step time: 0.3757\n",
      "18/224, train_loss: 0.4605, step time: 0.4119\n",
      "19/224, train_loss: 0.4741, step time: 0.3953\n",
      "20/224, train_loss: 0.4355, step time: 0.3874\n",
      "21/224, train_loss: 0.4384, step time: 0.3984\n",
      "22/224, train_loss: 0.4456, step time: 0.3191\n",
      "23/224, train_loss: 0.4103, step time: 0.3162\n",
      "24/224, train_loss: 0.4083, step time: 0.4016\n",
      "25/224, train_loss: 0.5068, step time: 0.3196\n",
      "26/224, train_loss: 0.4416, step time: 0.3174\n",
      "27/224, train_loss: 0.4625, step time: 0.3805\n",
      "28/224, train_loss: 0.4562, step time: 0.3924\n",
      "29/224, train_loss: 0.4666, step time: 0.3981\n",
      "30/224, train_loss: 0.4433, step time: 0.4137\n",
      "31/224, train_loss: 0.5859, step time: 0.4010\n",
      "32/224, train_loss: 0.5316, step time: 0.3828\n",
      "33/224, train_loss: 0.4781, step time: 0.3171\n",
      "34/224, train_loss: 0.4733, step time: 0.3930\n",
      "35/224, train_loss: 0.4549, step time: 0.3840\n",
      "36/224, train_loss: 0.4781, step time: 0.3147\n",
      "37/224, train_loss: 0.4737, step time: 0.3165\n",
      "38/224, train_loss: 0.4754, step time: 0.3970\n",
      "39/224, train_loss: 0.4319, step time: 0.3710\n",
      "40/224, train_loss: 0.4371, step time: 0.3694\n",
      "41/224, train_loss: 0.4187, step time: 0.3184\n",
      "42/224, train_loss: 0.5411, step time: 0.3142\n",
      "43/224, train_loss: 0.4494, step time: 0.3822\n",
      "44/224, train_loss: 0.4458, step time: 0.3190\n",
      "45/224, train_loss: 0.4705, step time: 0.3806\n",
      "46/224, train_loss: 0.5059, step time: 0.3935\n",
      "47/224, train_loss: 0.4481, step time: 0.3147\n",
      "48/224, train_loss: 0.4244, step time: 0.3919\n",
      "49/224, train_loss: 0.5349, step time: 0.3163\n",
      "50/224, train_loss: 0.4259, step time: 0.4058\n",
      "51/224, train_loss: 0.4498, step time: 0.3866\n",
      "52/224, train_loss: 0.4934, step time: 0.3865\n",
      "53/224, train_loss: 0.4291, step time: 0.3876\n",
      "54/224, train_loss: 0.4130, step time: 0.3180\n",
      "55/224, train_loss: 0.4987, step time: 0.3846\n",
      "56/224, train_loss: 0.4064, step time: 0.4030\n",
      "57/224, train_loss: 0.4301, step time: 0.3170\n",
      "58/224, train_loss: 0.4762, step time: 0.4098\n",
      "59/224, train_loss: 0.4437, step time: 0.3172\n",
      "60/224, train_loss: 0.4923, step time: 0.3877\n",
      "61/224, train_loss: 0.5471, step time: 0.4154\n",
      "62/224, train_loss: 0.4750, step time: 0.3160\n",
      "63/224, train_loss: 0.4010, step time: 0.3839\n",
      "64/224, train_loss: 0.5028, step time: 0.3164\n",
      "65/224, train_loss: 0.4439, step time: 0.4004\n",
      "66/224, train_loss: 0.4669, step time: 0.3901\n",
      "67/224, train_loss: 0.4186, step time: 0.3160\n",
      "68/224, train_loss: 0.4562, step time: 0.4056\n",
      "69/224, train_loss: 0.4547, step time: 0.3153\n",
      "70/224, train_loss: 0.4197, step time: 0.3906\n",
      "71/224, train_loss: 0.5332, step time: 0.3967\n",
      "72/224, train_loss: 0.4404, step time: 0.4069\n",
      "73/224, train_loss: 0.4094, step time: 0.3190\n",
      "74/224, train_loss: 0.4514, step time: 0.3174\n",
      "75/224, train_loss: 0.4622, step time: 0.3195\n",
      "76/224, train_loss: 0.4473, step time: 0.3813\n",
      "77/224, train_loss: 0.5070, step time: 0.3794\n",
      "78/224, train_loss: 0.4503, step time: 0.3159\n",
      "79/224, train_loss: 0.4817, step time: 0.3840\n",
      "80/224, train_loss: 0.4963, step time: 0.3740\n",
      "81/224, train_loss: 0.4864, step time: 0.3785\n",
      "82/224, train_loss: 0.4002, step time: 0.3959\n",
      "83/224, train_loss: 0.4737, step time: 0.3139\n",
      "84/224, train_loss: 0.4914, step time: 0.3902\n",
      "85/224, train_loss: 0.5040, step time: 0.4005\n",
      "86/224, train_loss: 0.4047, step time: 0.3884\n",
      "87/224, train_loss: 0.5298, step time: 0.3161\n",
      "88/224, train_loss: 0.4347, step time: 0.3161\n",
      "89/224, train_loss: 0.4203, step time: 0.3166\n",
      "90/224, train_loss: 0.5794, step time: 0.3802\n",
      "91/224, train_loss: 0.4175, step time: 0.3758\n",
      "92/224, train_loss: 0.4536, step time: 0.3162\n",
      "93/224, train_loss: 0.4974, step time: 0.3174\n",
      "94/224, train_loss: 0.4813, step time: 0.3899\n",
      "95/224, train_loss: 0.3964, step time: 0.3155\n",
      "96/224, train_loss: 0.4731, step time: 0.4087\n",
      "97/224, train_loss: 0.4529, step time: 0.3191\n",
      "98/224, train_loss: 0.5080, step time: 0.3738\n",
      "99/224, train_loss: 0.4047, step time: 0.3164\n",
      "100/224, train_loss: 0.4333, step time: 0.4078\n",
      "101/224, train_loss: 0.4447, step time: 0.3135\n",
      "102/224, train_loss: 0.3988, step time: 0.3155\n",
      "103/224, train_loss: 0.4178, step time: 0.3154\n",
      "104/224, train_loss: 0.4079, step time: 0.3153\n",
      "105/224, train_loss: 0.4752, step time: 0.3174\n",
      "106/224, train_loss: 0.4648, step time: 0.3895\n",
      "107/224, train_loss: 0.4305, step time: 0.3683\n",
      "108/224, train_loss: 0.4504, step time: 0.3139\n",
      "109/224, train_loss: 0.4117, step time: 0.3133\n",
      "110/224, train_loss: 0.4940, step time: 0.3153\n",
      "111/224, train_loss: 0.4357, step time: 0.3883\n",
      "112/224, train_loss: 0.4443, step time: 0.3165\n",
      "113/224, train_loss: 0.4414, step time: 0.4086\n",
      "114/224, train_loss: 0.4755, step time: 0.3131\n",
      "115/224, train_loss: 0.4657, step time: 0.3160\n",
      "116/224, train_loss: 0.4103, step time: 0.3139\n",
      "117/224, train_loss: 0.4385, step time: 0.3161\n",
      "118/224, train_loss: 0.4528, step time: 0.3832\n",
      "119/224, train_loss: 0.4624, step time: 0.3182\n",
      "120/224, train_loss: 0.5039, step time: 0.3975\n",
      "121/224, train_loss: 0.4519, step time: 0.3715\n",
      "122/224, train_loss: 0.3983, step time: 0.4003\n",
      "123/224, train_loss: 0.4318, step time: 0.4036\n",
      "124/224, train_loss: 0.4369, step time: 0.3168\n",
      "125/224, train_loss: 0.5501, step time: 0.3851\n",
      "126/224, train_loss: 0.4394, step time: 0.4130\n",
      "127/224, train_loss: 0.4488, step time: 0.3682\n",
      "128/224, train_loss: 0.4373, step time: 0.3937\n",
      "129/224, train_loss: 0.4626, step time: 0.3852\n",
      "130/224, train_loss: 0.4841, step time: 0.3180\n",
      "131/224, train_loss: 0.4426, step time: 0.3189\n",
      "132/224, train_loss: 0.4884, step time: 0.3835\n",
      "133/224, train_loss: 0.4120, step time: 0.3873\n",
      "134/224, train_loss: 0.4597, step time: 0.3173\n",
      "135/224, train_loss: 0.4244, step time: 0.3820\n",
      "136/224, train_loss: 0.4323, step time: 0.3838\n",
      "137/224, train_loss: 0.4317, step time: 0.3829\n",
      "138/224, train_loss: 0.4550, step time: 0.3167\n",
      "139/224, train_loss: 0.4422, step time: 0.3848\n",
      "140/224, train_loss: 0.4124, step time: 0.3711\n",
      "141/224, train_loss: 0.6258, step time: 0.3776\n",
      "142/224, train_loss: 0.4525, step time: 0.3947\n",
      "143/224, train_loss: 0.4549, step time: 0.3154\n",
      "144/224, train_loss: 0.4586, step time: 0.3130\n",
      "145/224, train_loss: 0.4252, step time: 0.3672\n",
      "146/224, train_loss: 0.4276, step time: 0.3138\n",
      "147/224, train_loss: 0.4353, step time: 0.4019\n",
      "148/224, train_loss: 0.4561, step time: 0.4047\n",
      "149/224, train_loss: 0.4211, step time: 0.4090\n",
      "150/224, train_loss: 0.4128, step time: 0.3152\n",
      "151/224, train_loss: 0.4853, step time: 0.3176\n",
      "152/224, train_loss: 0.5773, step time: 0.4043\n",
      "153/224, train_loss: 0.4326, step time: 0.3153\n",
      "154/224, train_loss: 0.4451, step time: 0.3998\n",
      "155/224, train_loss: 0.5017, step time: 0.3178\n",
      "156/224, train_loss: 0.4200, step time: 0.3180\n",
      "157/224, train_loss: 0.4093, step time: 0.3158\n",
      "158/224, train_loss: 0.4464, step time: 0.3655\n",
      "159/224, train_loss: 0.4675, step time: 0.4024\n",
      "160/224, train_loss: 0.4891, step time: 0.3716\n",
      "161/224, train_loss: 0.4074, step time: 0.4110\n",
      "162/224, train_loss: 0.5482, step time: 0.4068\n",
      "163/224, train_loss: 0.4127, step time: 0.3150\n",
      "164/224, train_loss: 0.4132, step time: 0.3676\n",
      "165/224, train_loss: 0.4227, step time: 0.3149\n",
      "166/224, train_loss: 0.4875, step time: 0.3157\n",
      "167/224, train_loss: 0.3920, step time: 0.3152\n",
      "168/224, train_loss: 0.4321, step time: 0.3149\n",
      "169/224, train_loss: 0.3999, step time: 0.3176\n",
      "170/224, train_loss: 0.4189, step time: 0.3124\n",
      "171/224, train_loss: 0.4333, step time: 0.4105\n",
      "172/224, train_loss: 0.4345, step time: 0.3906\n",
      "173/224, train_loss: 0.4864, step time: 0.3954\n",
      "174/224, train_loss: 0.4207, step time: 0.3150\n",
      "175/224, train_loss: 0.4579, step time: 0.3131\n",
      "176/224, train_loss: 0.4306, step time: 0.3697\n",
      "177/224, train_loss: 0.4335, step time: 0.3709\n",
      "178/224, train_loss: 0.4564, step time: 0.3152\n",
      "179/224, train_loss: 0.3998, step time: 0.3126\n",
      "180/224, train_loss: 0.4349, step time: 0.3152\n",
      "181/224, train_loss: 0.4750, step time: 0.3156\n",
      "182/224, train_loss: 0.5503, step time: 0.3136\n",
      "183/224, train_loss: 0.4028, step time: 0.3172\n",
      "184/224, train_loss: 0.4357, step time: 0.3786\n",
      "185/224, train_loss: 0.3939, step time: 0.3851\n",
      "186/224, train_loss: 0.4154, step time: 0.3177\n",
      "187/224, train_loss: 0.4345, step time: 0.3172\n",
      "188/224, train_loss: 0.4627, step time: 0.3712\n",
      "189/224, train_loss: 0.4691, step time: 0.3847\n",
      "190/224, train_loss: 0.4285, step time: 0.3841\n",
      "191/224, train_loss: 0.4395, step time: 0.3743\n",
      "192/224, train_loss: 0.4090, step time: 0.3180\n",
      "193/224, train_loss: 0.5010, step time: 0.3688\n",
      "194/224, train_loss: 0.4803, step time: 0.4104\n",
      "195/224, train_loss: 0.4255, step time: 0.3157\n",
      "196/224, train_loss: 0.4171, step time: 0.3149\n",
      "197/224, train_loss: 0.4151, step time: 0.3143\n",
      "198/224, train_loss: 0.4914, step time: 0.3169\n",
      "199/224, train_loss: 0.4126, step time: 0.3169\n",
      "200/224, train_loss: 0.4496, step time: 0.3697\n",
      "201/224, train_loss: 0.4092, step time: 0.3144\n",
      "202/224, train_loss: 0.4990, step time: 0.3902\n",
      "203/224, train_loss: 0.4067, step time: 0.3716\n",
      "204/224, train_loss: 0.4775, step time: 0.3169\n",
      "205/224, train_loss: 0.4280, step time: 0.3169\n",
      "206/224, train_loss: 0.4702, step time: 0.3812\n",
      "207/224, train_loss: 0.4174, step time: 0.3174\n",
      "208/224, train_loss: 0.4641, step time: 0.3166\n",
      "209/224, train_loss: 0.4061, step time: 0.3759\n",
      "210/224, train_loss: 0.4484, step time: 0.3149\n",
      "211/224, train_loss: 0.5115, step time: 0.4052\n",
      "212/224, train_loss: 0.3934, step time: 0.3158\n",
      "213/224, train_loss: 0.4928, step time: 0.4067\n",
      "214/224, train_loss: 0.4866, step time: 0.3171\n",
      "215/224, train_loss: 0.4313, step time: 0.3166\n",
      "216/224, train_loss: 0.4078, step time: 0.3171\n",
      "217/224, train_loss: 0.4522, step time: 0.3153\n",
      "218/224, train_loss: 0.4408, step time: 0.3902\n",
      "219/224, train_loss: 0.4643, step time: 0.3129\n",
      "220/224, train_loss: 0.4379, step time: 0.3659\n",
      "221/224, train_loss: 0.3893, step time: 0.3159\n",
      "222/224, train_loss: 0.4438, step time: 0.4083\n",
      "223/224, train_loss: 0.4126, step time: 0.3150\n",
      "224/224, train_loss: 0.5211, step time: 0.3656\n",
      "epoch 9 average loss: 0.4520\n",
      "current epoch: 9 current mean dice: 0.5780 class1: 0.9991 class2: 0.6787 class3: 0.0562\n",
      "best mean dice: 0.5780 at epoch: 9\n",
      "time consuming of epoch 9 is: 785.3109\n",
      "hello\n",
      "----------\n",
      "epoch 10/100\n",
      "1/224, train_loss: 0.4125, step time: 0.3774\n",
      "2/224, train_loss: 0.4503, step time: 0.3171\n",
      "3/224, train_loss: 0.4502, step time: 0.3803\n",
      "4/224, train_loss: 0.4588, step time: 0.3926\n",
      "5/224, train_loss: 0.4011, step time: 0.3710\n",
      "6/224, train_loss: 0.5125, step time: 0.3677\n",
      "7/224, train_loss: 0.3897, step time: 0.3152\n",
      "8/224, train_loss: 0.4821, step time: 0.4020\n",
      "9/224, train_loss: 0.4328, step time: 0.3185\n",
      "10/224, train_loss: 0.4025, step time: 0.3150\n",
      "11/224, train_loss: 0.4855, step time: 0.3136\n",
      "12/224, train_loss: 0.4542, step time: 0.3729\n",
      "13/224, train_loss: 0.4099, step time: 0.3817\n",
      "14/224, train_loss: 0.4320, step time: 0.3148\n",
      "15/224, train_loss: 0.4396, step time: 0.3786\n",
      "16/224, train_loss: 0.4069, step time: 0.3182\n",
      "17/224, train_loss: 0.4356, step time: 0.3152\n",
      "18/224, train_loss: 0.4025, step time: 0.3146\n",
      "19/224, train_loss: 0.4370, step time: 0.3855\n",
      "20/224, train_loss: 0.4096, step time: 0.3148\n",
      "21/224, train_loss: 0.4396, step time: 0.4014\n",
      "22/224, train_loss: 0.4691, step time: 0.3921\n",
      "23/224, train_loss: 0.4425, step time: 0.3990\n",
      "24/224, train_loss: 0.4895, step time: 0.3851\n",
      "25/224, train_loss: 0.4374, step time: 0.3780\n",
      "26/224, train_loss: 0.4374, step time: 0.3150\n",
      "27/224, train_loss: 0.4056, step time: 0.3154\n",
      "28/224, train_loss: 0.4994, step time: 0.3946\n",
      "29/224, train_loss: 0.4332, step time: 0.3169\n",
      "30/224, train_loss: 0.4083, step time: 0.3148\n",
      "31/224, train_loss: 0.4617, step time: 0.3124\n",
      "32/224, train_loss: 0.4311, step time: 0.3148\n",
      "33/224, train_loss: 0.4824, step time: 0.3714\n",
      "34/224, train_loss: 0.4427, step time: 0.3150\n",
      "35/224, train_loss: 0.4038, step time: 0.3130\n",
      "36/224, train_loss: 0.4654, step time: 0.3145\n",
      "37/224, train_loss: 0.4317, step time: 0.3828\n",
      "38/224, train_loss: 0.4492, step time: 0.3145\n",
      "39/224, train_loss: 0.4830, step time: 0.3837\n",
      "40/224, train_loss: 0.4191, step time: 0.3925\n",
      "41/224, train_loss: 0.4185, step time: 0.3842\n",
      "42/224, train_loss: 0.4086, step time: 0.3839\n",
      "43/224, train_loss: 0.4474, step time: 0.3812\n",
      "44/224, train_loss: 0.4464, step time: 0.3127\n",
      "45/224, train_loss: 0.4653, step time: 0.3842\n",
      "46/224, train_loss: 0.4211, step time: 0.3861\n",
      "47/224, train_loss: 0.4256, step time: 0.3886\n",
      "48/224, train_loss: 0.4246, step time: 0.3746\n",
      "49/224, train_loss: 0.5044, step time: 0.4138\n",
      "50/224, train_loss: 0.4111, step time: 0.3910\n",
      "51/224, train_loss: 0.4218, step time: 0.3709\n",
      "52/224, train_loss: 0.4694, step time: 0.3936\n",
      "53/224, train_loss: 0.4592, step time: 0.3940\n",
      "54/224, train_loss: 0.4510, step time: 0.3130\n",
      "55/224, train_loss: 0.4446, step time: 0.3957\n",
      "56/224, train_loss: 0.5705, step time: 0.3790\n",
      "57/224, train_loss: 0.4182, step time: 0.3703\n",
      "58/224, train_loss: 0.4368, step time: 0.3132\n",
      "59/224, train_loss: 0.3973, step time: 0.3849\n",
      "60/224, train_loss: 0.4136, step time: 0.3963\n",
      "61/224, train_loss: 0.4372, step time: 0.3149\n",
      "62/224, train_loss: 0.4329, step time: 0.4011\n",
      "63/224, train_loss: 0.4831, step time: 0.3653\n",
      "64/224, train_loss: 0.4695, step time: 0.3955\n",
      "65/224, train_loss: 0.4086, step time: 0.3147\n",
      "66/224, train_loss: 0.3841, step time: 0.3147\n",
      "67/224, train_loss: 0.3798, step time: 0.3168\n",
      "68/224, train_loss: 0.4094, step time: 0.3143\n",
      "69/224, train_loss: 0.4575, step time: 0.4130\n",
      "70/224, train_loss: 0.4118, step time: 0.3725\n",
      "71/224, train_loss: 0.4229, step time: 0.3933\n",
      "72/224, train_loss: 0.4157, step time: 0.3130\n",
      "73/224, train_loss: 0.3997, step time: 0.4123\n",
      "74/224, train_loss: 0.4279, step time: 0.3175\n",
      "75/224, train_loss: 0.4172, step time: 0.3174\n",
      "76/224, train_loss: 0.4314, step time: 0.3146\n",
      "77/224, train_loss: 0.4193, step time: 0.3175\n",
      "78/224, train_loss: 0.4356, step time: 0.3963\n",
      "79/224, train_loss: 0.4290, step time: 0.3150\n",
      "80/224, train_loss: 0.4133, step time: 0.3146\n",
      "81/224, train_loss: 0.4080, step time: 0.3162\n",
      "82/224, train_loss: 0.3890, step time: 0.3152\n",
      "83/224, train_loss: 0.4490, step time: 0.3147\n",
      "84/224, train_loss: 0.4327, step time: 0.3123\n",
      "85/224, train_loss: 0.4814, step time: 0.3718\n",
      "86/224, train_loss: 0.4283, step time: 0.4041\n",
      "87/224, train_loss: 0.3895, step time: 0.3174\n",
      "88/224, train_loss: 0.4054, step time: 0.3145\n",
      "89/224, train_loss: 0.3947, step time: 0.3939\n",
      "90/224, train_loss: 0.4106, step time: 0.3174\n",
      "91/224, train_loss: 0.4248, step time: 0.3672\n",
      "92/224, train_loss: 0.4806, step time: 0.3129\n",
      "93/224, train_loss: 0.4256, step time: 0.3170\n",
      "94/224, train_loss: 0.4413, step time: 0.4031\n",
      "95/224, train_loss: 0.4432, step time: 0.3878\n",
      "96/224, train_loss: 0.4969, step time: 0.3150\n",
      "97/224, train_loss: 0.4232, step time: 0.4015\n",
      "98/224, train_loss: 0.4060, step time: 0.3154\n",
      "99/224, train_loss: 0.4153, step time: 0.3719\n",
      "100/224, train_loss: 0.4727, step time: 0.3693\n",
      "101/224, train_loss: 0.4322, step time: 0.3886\n",
      "102/224, train_loss: 0.5092, step time: 0.3832\n",
      "103/224, train_loss: 0.5456, step time: 0.3931\n",
      "104/224, train_loss: 0.4259, step time: 0.3988\n",
      "105/224, train_loss: 0.4149, step time: 0.3187\n",
      "106/224, train_loss: 0.4028, step time: 0.3153\n",
      "107/224, train_loss: 0.4698, step time: 0.3808\n",
      "108/224, train_loss: 0.4137, step time: 0.3143\n",
      "109/224, train_loss: 0.4505, step time: 0.4107\n",
      "110/224, train_loss: 0.4528, step time: 0.3850\n",
      "111/224, train_loss: 0.4194, step time: 0.3879\n",
      "112/224, train_loss: 0.4060, step time: 0.3157\n",
      "113/224, train_loss: 0.4347, step time: 0.3847\n",
      "114/224, train_loss: 0.4464, step time: 0.3145\n",
      "115/224, train_loss: 0.4252, step time: 0.4061\n",
      "116/224, train_loss: 0.4770, step time: 0.3134\n",
      "117/224, train_loss: 0.4032, step time: 0.4031\n",
      "118/224, train_loss: 0.4019, step time: 0.3850\n",
      "119/224, train_loss: 0.4162, step time: 0.3167\n",
      "120/224, train_loss: 0.3840, step time: 0.3163\n",
      "121/224, train_loss: 0.4506, step time: 0.3717\n",
      "122/224, train_loss: 0.5211, step time: 0.4066\n",
      "123/224, train_loss: 0.5058, step time: 0.3174\n",
      "124/224, train_loss: 0.4875, step time: 0.3133\n",
      "125/224, train_loss: 0.5219, step time: 0.3179\n",
      "126/224, train_loss: 0.4063, step time: 0.3171\n",
      "127/224, train_loss: 0.4775, step time: 0.3161\n",
      "128/224, train_loss: 0.4394, step time: 0.4104\n",
      "129/224, train_loss: 0.4281, step time: 0.3894\n",
      "130/224, train_loss: 0.4673, step time: 0.3121\n",
      "131/224, train_loss: 0.4799, step time: 0.3163\n",
      "132/224, train_loss: 0.4257, step time: 0.3830\n",
      "133/224, train_loss: 0.4291, step time: 0.3147\n",
      "134/224, train_loss: 0.4004, step time: 0.4007\n",
      "135/224, train_loss: 0.3974, step time: 0.3704\n",
      "136/224, train_loss: 0.4261, step time: 0.3702\n",
      "137/224, train_loss: 0.3915, step time: 0.4035\n",
      "138/224, train_loss: 0.4091, step time: 0.3142\n",
      "139/224, train_loss: 0.4271, step time: 0.3152\n",
      "140/224, train_loss: 0.4229, step time: 0.3168\n",
      "141/224, train_loss: 0.4697, step time: 0.3145\n",
      "142/224, train_loss: 0.3930, step time: 0.3959\n",
      "143/224, train_loss: 0.4165, step time: 0.3145\n",
      "144/224, train_loss: 0.3971, step time: 0.3119\n",
      "145/224, train_loss: 0.4060, step time: 0.3997\n",
      "146/224, train_loss: 0.4104, step time: 0.3167\n",
      "147/224, train_loss: 0.4039, step time: 0.3162\n",
      "148/224, train_loss: 0.3774, step time: 0.3779\n",
      "149/224, train_loss: 0.3973, step time: 0.3970\n",
      "150/224, train_loss: 0.3927, step time: 0.3123\n",
      "151/224, train_loss: 0.3979, step time: 0.3162\n",
      "152/224, train_loss: 0.4544, step time: 0.3733\n",
      "153/224, train_loss: 0.4240, step time: 0.3914\n",
      "154/224, train_loss: 0.4322, step time: 0.3839\n",
      "155/224, train_loss: 0.4307, step time: 0.3911\n",
      "156/224, train_loss: 0.4661, step time: 0.3144\n",
      "157/224, train_loss: 0.5124, step time: 0.4046\n",
      "158/224, train_loss: 0.4436, step time: 0.3748\n",
      "159/224, train_loss: 0.4382, step time: 0.3151\n",
      "160/224, train_loss: 0.4413, step time: 0.3174\n",
      "161/224, train_loss: 0.4711, step time: 0.4013\n",
      "162/224, train_loss: 0.4629, step time: 0.3734\n",
      "163/224, train_loss: 0.4206, step time: 0.4001\n",
      "164/224, train_loss: 0.4070, step time: 0.3173\n",
      "165/224, train_loss: 0.4021, step time: 0.3805\n",
      "166/224, train_loss: 0.4991, step time: 0.4061\n",
      "167/224, train_loss: 0.4064, step time: 0.3144\n",
      "168/224, train_loss: 0.4416, step time: 0.3967\n",
      "169/224, train_loss: 0.4073, step time: 0.3908\n",
      "170/224, train_loss: 0.3968, step time: 0.3150\n",
      "171/224, train_loss: 0.4056, step time: 0.3128\n",
      "172/224, train_loss: 0.4669, step time: 0.4074\n",
      "173/224, train_loss: 0.4077, step time: 0.3148\n",
      "174/224, train_loss: 0.4340, step time: 0.3703\n",
      "175/224, train_loss: 0.5197, step time: 0.3168\n",
      "176/224, train_loss: 0.4062, step time: 0.3124\n",
      "177/224, train_loss: 0.5486, step time: 0.3175\n",
      "178/224, train_loss: 0.4813, step time: 0.3155\n",
      "179/224, train_loss: 0.3984, step time: 0.3893\n",
      "180/224, train_loss: 0.3845, step time: 0.3159\n",
      "181/224, train_loss: 0.4586, step time: 0.3151\n",
      "182/224, train_loss: 0.4697, step time: 0.3170\n",
      "183/224, train_loss: 0.4492, step time: 0.3931\n",
      "184/224, train_loss: 0.4412, step time: 0.3144\n",
      "185/224, train_loss: 0.5413, step time: 0.3924\n",
      "186/224, train_loss: 0.4563, step time: 0.3749\n",
      "187/224, train_loss: 0.4236, step time: 0.3957\n",
      "188/224, train_loss: 0.4965, step time: 0.3909\n",
      "189/224, train_loss: 0.4382, step time: 0.3150\n",
      "190/224, train_loss: 0.3810, step time: 0.3131\n",
      "191/224, train_loss: 0.3927, step time: 0.3149\n",
      "192/224, train_loss: 0.4983, step time: 0.3799\n",
      "193/224, train_loss: 0.4513, step time: 0.3158\n",
      "194/224, train_loss: 0.3977, step time: 0.3916\n",
      "195/224, train_loss: 0.4281, step time: 0.3851\n",
      "196/224, train_loss: 0.4341, step time: 0.3155\n",
      "197/224, train_loss: 0.4255, step time: 0.3817\n",
      "198/224, train_loss: 0.3938, step time: 0.3167\n",
      "199/224, train_loss: 0.4356, step time: 0.4020\n",
      "200/224, train_loss: 0.4312, step time: 0.3708\n",
      "201/224, train_loss: 0.4368, step time: 0.3151\n",
      "202/224, train_loss: 0.3881, step time: 0.3147\n",
      "203/224, train_loss: 0.3837, step time: 0.3686\n",
      "204/224, train_loss: 0.4267, step time: 0.3755\n",
      "205/224, train_loss: 0.4176, step time: 0.4097\n",
      "206/224, train_loss: 0.4507, step time: 0.4044\n",
      "207/224, train_loss: 0.3871, step time: 0.3156\n",
      "208/224, train_loss: 0.4335, step time: 0.3699\n",
      "209/224, train_loss: 0.4521, step time: 0.3176\n",
      "210/224, train_loss: 0.4527, step time: 0.3953\n",
      "211/224, train_loss: 0.4604, step time: 0.3169\n",
      "212/224, train_loss: 0.4176, step time: 0.3143\n",
      "213/224, train_loss: 0.4173, step time: 0.3127\n",
      "214/224, train_loss: 0.4987, step time: 0.3906\n",
      "215/224, train_loss: 0.4123, step time: 0.3171\n",
      "216/224, train_loss: 0.4766, step time: 0.3698\n",
      "217/224, train_loss: 0.4715, step time: 0.3942\n",
      "218/224, train_loss: 0.3982, step time: 0.3674\n",
      "219/224, train_loss: 0.4274, step time: 0.3146\n",
      "220/224, train_loss: 0.5732, step time: 0.3810\n",
      "221/224, train_loss: 0.4192, step time: 0.3152\n",
      "222/224, train_loss: 0.4214, step time: 0.3963\n",
      "223/224, train_loss: 0.3925, step time: 0.3850\n",
      "224/224, train_loss: 0.4271, step time: 0.3752\n",
      "epoch 10 average loss: 0.4366\n",
      "current epoch: 10 current mean dice: 0.5875 class1: 0.9991 class2: 0.6847 class3: 0.0788\n",
      "best mean dice: 0.5875 at epoch: 10\n",
      "time consuming of epoch 10 is: 814.0752\n",
      "hello\n",
      "----------\n",
      "epoch 11/100\n",
      "1/224, train_loss: 0.4038, step time: 0.4022\n",
      "2/224, train_loss: 0.4800, step time: 0.3152\n",
      "3/224, train_loss: 0.4298, step time: 0.3149\n",
      "4/224, train_loss: 0.4288, step time: 0.3732\n",
      "5/224, train_loss: 0.3905, step time: 0.3165\n",
      "6/224, train_loss: 0.4384, step time: 0.3849\n",
      "7/224, train_loss: 0.4122, step time: 0.3144\n",
      "8/224, train_loss: 0.3962, step time: 0.3146\n",
      "9/224, train_loss: 0.5878, step time: 0.3972\n",
      "10/224, train_loss: 0.4203, step time: 0.3807\n",
      "11/224, train_loss: 0.4503, step time: 0.4037\n",
      "12/224, train_loss: 0.4271, step time: 0.3146\n",
      "13/224, train_loss: 0.3878, step time: 0.3149\n",
      "14/224, train_loss: 0.4780, step time: 0.3838\n",
      "15/224, train_loss: 0.4114, step time: 0.3173\n",
      "16/224, train_loss: 0.4354, step time: 0.3166\n",
      "17/224, train_loss: 0.4538, step time: 0.3777\n",
      "18/224, train_loss: 0.4501, step time: 0.3938\n",
      "19/224, train_loss: 0.4667, step time: 0.3149\n",
      "20/224, train_loss: 0.3981, step time: 0.3807\n",
      "21/224, train_loss: 0.4486, step time: 0.3986\n",
      "22/224, train_loss: 0.3984, step time: 0.3154\n",
      "23/224, train_loss: 0.4116, step time: 0.3700\n",
      "24/224, train_loss: 0.4018, step time: 0.3791\n",
      "25/224, train_loss: 0.4520, step time: 0.3883\n",
      "26/224, train_loss: 0.4157, step time: 0.4071\n",
      "27/224, train_loss: 0.4394, step time: 0.4095\n",
      "28/224, train_loss: 0.4577, step time: 0.3170\n",
      "29/224, train_loss: 0.4519, step time: 0.3142\n",
      "30/224, train_loss: 0.4441, step time: 0.3141\n",
      "31/224, train_loss: 0.3832, step time: 0.3121\n",
      "32/224, train_loss: 0.3925, step time: 0.3119\n",
      "33/224, train_loss: 0.4076, step time: 0.4082\n",
      "34/224, train_loss: 0.4379, step time: 0.3729\n",
      "35/224, train_loss: 0.4395, step time: 0.4036\n",
      "36/224, train_loss: 0.4198, step time: 0.3146\n",
      "37/224, train_loss: 0.4672, step time: 0.3708\n",
      "38/224, train_loss: 0.4001, step time: 0.3164\n",
      "39/224, train_loss: 0.4527, step time: 0.4021\n",
      "40/224, train_loss: 0.5422, step time: 0.3123\n",
      "41/224, train_loss: 0.4557, step time: 0.3961\n",
      "42/224, train_loss: 0.3805, step time: 0.3148\n",
      "43/224, train_loss: 0.4498, step time: 0.4036\n",
      "44/224, train_loss: 0.4119, step time: 0.3143\n",
      "45/224, train_loss: 0.3903, step time: 0.3124\n",
      "46/224, train_loss: 0.3795, step time: 0.3163\n",
      "47/224, train_loss: 0.4183, step time: 0.3140\n",
      "48/224, train_loss: 0.3916, step time: 0.4025\n",
      "49/224, train_loss: 0.3968, step time: 0.3141\n",
      "50/224, train_loss: 0.4741, step time: 0.3140\n",
      "51/224, train_loss: 0.4069, step time: 0.3673\n",
      "52/224, train_loss: 0.4671, step time: 0.3181\n",
      "53/224, train_loss: 0.4278, step time: 0.3195\n",
      "54/224, train_loss: 0.4611, step time: 0.3174\n",
      "55/224, train_loss: 0.3981, step time: 0.3742\n",
      "56/224, train_loss: 0.4647, step time: 0.3775\n",
      "57/224, train_loss: 0.4174, step time: 0.3187\n",
      "58/224, train_loss: 0.4219, step time: 0.3151\n",
      "59/224, train_loss: 0.3971, step time: 0.3194\n",
      "60/224, train_loss: 0.4992, step time: 0.3181\n",
      "61/224, train_loss: 0.3908, step time: 0.3175\n",
      "62/224, train_loss: 0.4187, step time: 0.3208\n",
      "63/224, train_loss: 0.4811, step time: 0.4088\n",
      "64/224, train_loss: 0.4480, step time: 0.3983\n",
      "65/224, train_loss: 0.3961, step time: 0.3898\n",
      "66/224, train_loss: 0.4134, step time: 0.3179\n",
      "67/224, train_loss: 0.3935, step time: 0.3195\n",
      "68/224, train_loss: 0.4305, step time: 0.3207\n",
      "69/224, train_loss: 0.4593, step time: 0.3206\n",
      "70/224, train_loss: 0.4486, step time: 0.3728\n",
      "71/224, train_loss: 0.4692, step time: 0.3185\n",
      "72/224, train_loss: 0.4731, step time: 0.3979\n",
      "73/224, train_loss: 0.3886, step time: 0.3153\n",
      "74/224, train_loss: 0.5591, step time: 0.3790\n",
      "75/224, train_loss: 0.4260, step time: 0.3163\n",
      "76/224, train_loss: 0.4659, step time: 0.3183\n",
      "77/224, train_loss: 0.3985, step time: 0.4027\n",
      "78/224, train_loss: 0.4562, step time: 0.3903\n",
      "79/224, train_loss: 0.4338, step time: 0.3822\n",
      "80/224, train_loss: 0.3930, step time: 0.3927\n",
      "81/224, train_loss: 0.4402, step time: 0.3887\n",
      "82/224, train_loss: 0.4355, step time: 0.3909\n",
      "83/224, train_loss: 0.3857, step time: 0.3718\n",
      "84/224, train_loss: 0.4226, step time: 0.3153\n",
      "85/224, train_loss: 0.4190, step time: 0.3145\n",
      "86/224, train_loss: 0.4678, step time: 0.4077\n",
      "87/224, train_loss: 0.3755, step time: 0.3129\n",
      "88/224, train_loss: 0.4060, step time: 0.3172\n",
      "89/224, train_loss: 0.4852, step time: 0.3933\n",
      "90/224, train_loss: 0.4316, step time: 0.3688\n",
      "91/224, train_loss: 0.4175, step time: 0.3174\n",
      "92/224, train_loss: 0.4125, step time: 0.4047\n",
      "93/224, train_loss: 0.4025, step time: 0.3167\n",
      "94/224, train_loss: 0.4600, step time: 0.3852\n",
      "95/224, train_loss: 0.3917, step time: 0.3675\n",
      "96/224, train_loss: 0.4406, step time: 0.3827\n",
      "97/224, train_loss: 0.4353, step time: 0.3182\n",
      "98/224, train_loss: 0.4371, step time: 0.4018\n",
      "99/224, train_loss: 0.5268, step time: 0.3722\n",
      "100/224, train_loss: 0.4102, step time: 0.3145\n",
      "101/224, train_loss: 0.4213, step time: 0.3143\n",
      "102/224, train_loss: 0.4007, step time: 0.3153\n",
      "103/224, train_loss: 0.4364, step time: 0.3151\n",
      "104/224, train_loss: 0.4001, step time: 0.3173\n",
      "105/224, train_loss: 0.3919, step time: 0.3143\n",
      "106/224, train_loss: 0.5215, step time: 0.4060\n",
      "107/224, train_loss: 0.4064, step time: 0.3728\n",
      "108/224, train_loss: 0.5096, step time: 0.3698\n",
      "109/224, train_loss: 0.4839, step time: 0.3202\n",
      "110/224, train_loss: 0.4023, step time: 0.3940\n",
      "111/224, train_loss: 0.4417, step time: 0.3940\n",
      "112/224, train_loss: 0.4538, step time: 0.3179\n",
      "113/224, train_loss: 0.4180, step time: 0.3722\n",
      "114/224, train_loss: 0.5184, step time: 0.3175\n",
      "115/224, train_loss: 0.4981, step time: 0.3246\n",
      "116/224, train_loss: 0.4264, step time: 0.3189\n",
      "117/224, train_loss: 0.4861, step time: 0.3885\n",
      "118/224, train_loss: 0.4781, step time: 0.3712\n",
      "119/224, train_loss: 0.4656, step time: 0.3177\n",
      "120/224, train_loss: 0.4577, step time: 0.4152\n",
      "121/224, train_loss: 0.4061, step time: 0.3747\n",
      "122/224, train_loss: 0.4258, step time: 0.3928\n",
      "123/224, train_loss: 0.4768, step time: 0.3161\n",
      "124/224, train_loss: 0.4348, step time: 0.3841\n",
      "125/224, train_loss: 0.4158, step time: 0.3155\n",
      "126/224, train_loss: 0.4033, step time: 0.3727\n",
      "127/224, train_loss: 0.4140, step time: 0.3183\n",
      "128/224, train_loss: 0.4174, step time: 0.4063\n",
      "129/224, train_loss: 0.5052, step time: 0.3175\n",
      "130/224, train_loss: 0.4214, step time: 0.3150\n",
      "131/224, train_loss: 0.4178, step time: 0.3175\n",
      "132/224, train_loss: 0.4664, step time: 0.3982\n",
      "133/224, train_loss: 0.4565, step time: 0.3721\n",
      "134/224, train_loss: 0.4555, step time: 0.3960\n",
      "135/224, train_loss: 0.5294, step time: 0.3763\n",
      "136/224, train_loss: 0.4986, step time: 0.3151\n",
      "137/224, train_loss: 0.3993, step time: 0.3174\n",
      "138/224, train_loss: 0.3913, step time: 0.3792\n",
      "139/224, train_loss: 0.4100, step time: 0.3962\n",
      "140/224, train_loss: 0.4119, step time: 0.4094\n",
      "141/224, train_loss: 0.4207, step time: 0.3730\n",
      "142/224, train_loss: 0.4199, step time: 0.3863\n",
      "143/224, train_loss: 0.4408, step time: 0.3882\n",
      "144/224, train_loss: 0.3969, step time: 0.4024\n",
      "145/224, train_loss: 0.4604, step time: 0.4102\n",
      "146/224, train_loss: 0.3894, step time: 0.3155\n",
      "147/224, train_loss: 0.4478, step time: 0.3952\n",
      "148/224, train_loss: 0.4588, step time: 0.3836\n",
      "149/224, train_loss: 0.4000, step time: 0.3835\n",
      "150/224, train_loss: 0.4326, step time: 0.3896\n",
      "151/224, train_loss: 0.4699, step time: 0.3154\n",
      "152/224, train_loss: 0.4365, step time: 0.3847\n",
      "153/224, train_loss: 0.4089, step time: 0.3912\n",
      "154/224, train_loss: 0.4562, step time: 0.3978\n",
      "155/224, train_loss: 0.4078, step time: 0.3152\n",
      "156/224, train_loss: 0.4353, step time: 0.3172\n",
      "157/224, train_loss: 0.4174, step time: 0.3158\n",
      "158/224, train_loss: 0.4418, step time: 0.3802\n",
      "159/224, train_loss: 0.3998, step time: 0.3764\n",
      "160/224, train_loss: 0.4571, step time: 0.3178\n",
      "161/224, train_loss: 0.3858, step time: 0.3155\n",
      "162/224, train_loss: 0.4348, step time: 0.3183\n",
      "163/224, train_loss: 0.4015, step time: 0.3156\n",
      "164/224, train_loss: 0.4461, step time: 0.3981\n",
      "165/224, train_loss: 0.4291, step time: 0.3173\n",
      "166/224, train_loss: 0.4033, step time: 0.3155\n",
      "167/224, train_loss: 0.4667, step time: 0.3988\n",
      "168/224, train_loss: 0.3862, step time: 0.3684\n",
      "169/224, train_loss: 0.4428, step time: 0.4009\n",
      "170/224, train_loss: 0.4758, step time: 0.3182\n",
      "171/224, train_loss: 0.4738, step time: 0.3184\n",
      "172/224, train_loss: 0.4812, step time: 0.3158\n",
      "173/224, train_loss: 0.3749, step time: 0.3147\n",
      "174/224, train_loss: 0.4120, step time: 0.3670\n",
      "175/224, train_loss: 0.4328, step time: 0.3681\n",
      "176/224, train_loss: 0.4474, step time: 0.3167\n",
      "177/224, train_loss: 0.4090, step time: 0.3126\n",
      "178/224, train_loss: 0.4206, step time: 0.3124\n",
      "179/224, train_loss: 0.4885, step time: 0.3783\n",
      "180/224, train_loss: 0.4227, step time: 0.3183\n",
      "181/224, train_loss: 0.4466, step time: 0.3176\n",
      "182/224, train_loss: 0.3983, step time: 0.3753\n",
      "183/224, train_loss: 0.4146, step time: 0.3158\n",
      "184/224, train_loss: 0.3840, step time: 0.3974\n",
      "185/224, train_loss: 0.4153, step time: 0.3158\n",
      "186/224, train_loss: 0.4319, step time: 0.3995\n",
      "187/224, train_loss: 0.4529, step time: 0.4009\n",
      "188/224, train_loss: 0.4742, step time: 0.3974\n",
      "189/224, train_loss: 0.4253, step time: 0.3659\n",
      "190/224, train_loss: 0.4449, step time: 0.3158\n",
      "191/224, train_loss: 0.4200, step time: 0.3156\n",
      "192/224, train_loss: 0.4581, step time: 0.3965\n",
      "193/224, train_loss: 0.3794, step time: 0.4085\n",
      "194/224, train_loss: 0.4224, step time: 0.3785\n",
      "195/224, train_loss: 0.4070, step time: 0.3877\n",
      "196/224, train_loss: 0.4515, step time: 0.3803\n",
      "197/224, train_loss: 0.4089, step time: 0.4042\n",
      "198/224, train_loss: 0.4069, step time: 0.3910\n",
      "199/224, train_loss: 0.4244, step time: 0.3141\n",
      "200/224, train_loss: 0.4245, step time: 0.3185\n",
      "201/224, train_loss: 0.3927, step time: 0.3158\n",
      "202/224, train_loss: 0.4598, step time: 0.4101\n",
      "203/224, train_loss: 0.4056, step time: 0.3676\n",
      "204/224, train_loss: 0.4480, step time: 0.3149\n",
      "205/224, train_loss: 0.3815, step time: 0.3137\n",
      "206/224, train_loss: 0.3900, step time: 0.3153\n",
      "207/224, train_loss: 0.4031, step time: 0.3924\n",
      "208/224, train_loss: 0.3797, step time: 0.3155\n",
      "209/224, train_loss: 0.4781, step time: 0.3161\n",
      "210/224, train_loss: 0.4034, step time: 0.3996\n",
      "211/224, train_loss: 0.5836, step time: 0.3987\n",
      "212/224, train_loss: 0.4329, step time: 0.3758\n",
      "213/224, train_loss: 0.3865, step time: 0.3153\n",
      "214/224, train_loss: 0.3869, step time: 0.4121\n",
      "215/224, train_loss: 0.4114, step time: 0.3153\n",
      "216/224, train_loss: 0.4046, step time: 0.3690\n",
      "217/224, train_loss: 0.4109, step time: 0.3897\n",
      "218/224, train_loss: 0.4225, step time: 0.3133\n",
      "219/224, train_loss: 0.4428, step time: 0.3154\n",
      "220/224, train_loss: 0.4269, step time: 0.4002\n",
      "221/224, train_loss: 0.3875, step time: 0.3707\n",
      "222/224, train_loss: 0.4169, step time: 0.3153\n",
      "223/224, train_loss: 0.4226, step time: 0.3132\n",
      "224/224, train_loss: 0.4815, step time: 0.3688\n",
      "epoch 11 average loss: 0.4327\n",
      "current epoch: 11 current mean dice: 0.5898 class1: 0.9991 class2: 0.6935 class3: 0.0768\n",
      "best mean dice: 0.5898 at epoch: 11\n",
      "time consuming of epoch 11 is: 738.5532\n",
      "hello\n",
      "----------\n",
      "epoch 12/100\n",
      "1/224, train_loss: 0.4340, step time: 0.3153\n",
      "2/224, train_loss: 0.4210, step time: 0.3952\n",
      "3/224, train_loss: 0.4268, step time: 0.3731\n",
      "4/224, train_loss: 0.4613, step time: 0.4018\n",
      "5/224, train_loss: 0.3807, step time: 0.3943\n",
      "6/224, train_loss: 0.4257, step time: 0.3826\n",
      "7/224, train_loss: 0.4653, step time: 0.3798\n",
      "8/224, train_loss: 0.4256, step time: 0.3210\n",
      "9/224, train_loss: 0.4057, step time: 0.3189\n",
      "10/224, train_loss: 0.4443, step time: 0.3788\n",
      "11/224, train_loss: 0.4583, step time: 0.3177\n",
      "12/224, train_loss: 0.4440, step time: 0.3150\n",
      "13/224, train_loss: 0.5272, step time: 0.3948\n",
      "14/224, train_loss: 0.4076, step time: 0.4092\n",
      "15/224, train_loss: 0.4396, step time: 0.3684\n",
      "16/224, train_loss: 0.4427, step time: 0.4107\n",
      "17/224, train_loss: 0.4535, step time: 0.3694\n",
      "18/224, train_loss: 0.4345, step time: 0.3990\n",
      "19/224, train_loss: 0.3953, step time: 0.3149\n",
      "20/224, train_loss: 0.3882, step time: 0.3151\n",
      "21/224, train_loss: 0.4066, step time: 0.3171\n",
      "22/224, train_loss: 0.4048, step time: 0.3145\n",
      "23/224, train_loss: 0.3829, step time: 0.3176\n",
      "24/224, train_loss: 0.5016, step time: 0.3956\n",
      "25/224, train_loss: 0.4164, step time: 0.3761\n",
      "26/224, train_loss: 0.4792, step time: 0.3781\n",
      "27/224, train_loss: 0.3877, step time: 0.3944\n",
      "28/224, train_loss: 0.4244, step time: 0.4100\n",
      "29/224, train_loss: 0.3807, step time: 0.3127\n",
      "30/224, train_loss: 0.3917, step time: 0.3148\n",
      "31/224, train_loss: 0.3942, step time: 0.3148\n",
      "32/224, train_loss: 0.4959, step time: 0.3978\n",
      "33/224, train_loss: 0.4164, step time: 0.4075\n",
      "34/224, train_loss: 0.3798, step time: 0.3131\n",
      "35/224, train_loss: 0.3926, step time: 0.3680\n",
      "36/224, train_loss: 0.4107, step time: 0.3813\n",
      "37/224, train_loss: 0.4650, step time: 0.3931\n",
      "38/224, train_loss: 0.3821, step time: 0.3182\n",
      "39/224, train_loss: 0.4848, step time: 0.3155\n",
      "40/224, train_loss: 0.4101, step time: 0.3929\n",
      "41/224, train_loss: 0.3952, step time: 0.3886\n",
      "42/224, train_loss: 0.4124, step time: 0.3989\n",
      "43/224, train_loss: 0.4070, step time: 0.3156\n",
      "44/224, train_loss: 0.4054, step time: 0.3153\n",
      "45/224, train_loss: 0.4135, step time: 0.3172\n",
      "46/224, train_loss: 0.4162, step time: 0.3640\n",
      "47/224, train_loss: 0.3965, step time: 0.3128\n",
      "48/224, train_loss: 0.4006, step time: 0.3745\n",
      "49/224, train_loss: 0.3913, step time: 0.4028\n",
      "50/224, train_loss: 0.4452, step time: 0.3156\n",
      "51/224, train_loss: 0.4099, step time: 0.3777\n",
      "52/224, train_loss: 0.3811, step time: 0.3172\n",
      "53/224, train_loss: 0.4744, step time: 0.3126\n",
      "54/224, train_loss: 0.4054, step time: 0.4051\n",
      "55/224, train_loss: 0.4172, step time: 0.3831\n",
      "56/224, train_loss: 0.4328, step time: 0.3150\n",
      "57/224, train_loss: 0.3776, step time: 0.3173\n",
      "58/224, train_loss: 0.4230, step time: 0.3714\n",
      "59/224, train_loss: 0.4035, step time: 0.3149\n",
      "60/224, train_loss: 0.4004, step time: 0.3129\n",
      "61/224, train_loss: 0.4122, step time: 0.3177\n",
      "62/224, train_loss: 0.4174, step time: 0.3179\n",
      "63/224, train_loss: 0.4420, step time: 0.3677\n",
      "64/224, train_loss: 0.3953, step time: 0.3709\n",
      "65/224, train_loss: 0.4012, step time: 0.3955\n",
      "66/224, train_loss: 0.4531, step time: 0.3722\n",
      "67/224, train_loss: 0.3943, step time: 0.3803\n",
      "68/224, train_loss: 0.4112, step time: 0.3778\n",
      "69/224, train_loss: 0.4628, step time: 0.4045\n",
      "70/224, train_loss: 0.3885, step time: 0.3123\n",
      "71/224, train_loss: 0.4477, step time: 0.3819\n",
      "72/224, train_loss: 0.4391, step time: 0.3809\n",
      "73/224, train_loss: 0.3907, step time: 0.3874\n",
      "74/224, train_loss: 0.4346, step time: 0.3145\n",
      "75/224, train_loss: 0.4403, step time: 0.3806\n",
      "76/224, train_loss: 0.4137, step time: 0.3914\n",
      "77/224, train_loss: 0.4217, step time: 0.3817\n",
      "78/224, train_loss: 0.4513, step time: 0.3139\n",
      "79/224, train_loss: 0.4293, step time: 0.3153\n",
      "80/224, train_loss: 0.4393, step time: 0.3823\n",
      "81/224, train_loss: 0.4921, step time: 0.3796\n",
      "82/224, train_loss: 0.4529, step time: 0.3757\n",
      "83/224, train_loss: 0.3858, step time: 0.3156\n",
      "84/224, train_loss: 0.4350, step time: 0.3151\n",
      "85/224, train_loss: 0.4857, step time: 0.3888\n",
      "86/224, train_loss: 0.4052, step time: 0.3145\n",
      "87/224, train_loss: 0.3820, step time: 0.3710\n",
      "88/224, train_loss: 0.4347, step time: 0.3742\n",
      "89/224, train_loss: 0.4406, step time: 0.3187\n",
      "90/224, train_loss: 0.3896, step time: 0.3147\n",
      "91/224, train_loss: 0.3917, step time: 0.3154\n",
      "92/224, train_loss: 0.3893, step time: 0.3179\n",
      "93/224, train_loss: 0.5815, step time: 0.3659\n",
      "94/224, train_loss: 0.4192, step time: 0.3155\n",
      "95/224, train_loss: 0.3900, step time: 0.3155\n",
      "96/224, train_loss: 0.3885, step time: 0.3871\n",
      "97/224, train_loss: 0.4397, step time: 0.4007\n",
      "98/224, train_loss: 0.4214, step time: 0.4043\n",
      "99/224, train_loss: 0.4303, step time: 0.3176\n",
      "100/224, train_loss: 0.4296, step time: 0.3926\n",
      "101/224, train_loss: 0.4217, step time: 0.3154\n",
      "102/224, train_loss: 0.4702, step time: 0.3180\n",
      "103/224, train_loss: 0.4556, step time: 0.3160\n",
      "104/224, train_loss: 0.4301, step time: 0.3178\n",
      "105/224, train_loss: 0.4132, step time: 0.3182\n",
      "106/224, train_loss: 0.4229, step time: 0.4064\n",
      "107/224, train_loss: 0.4598, step time: 0.3137\n",
      "108/224, train_loss: 0.4126, step time: 0.3154\n",
      "109/224, train_loss: 0.5100, step time: 0.4076\n",
      "110/224, train_loss: 0.3859, step time: 0.3152\n",
      "111/224, train_loss: 0.3971, step time: 0.3175\n",
      "112/224, train_loss: 0.3950, step time: 0.3132\n",
      "113/224, train_loss: 0.3770, step time: 0.4095\n",
      "114/224, train_loss: 0.4189, step time: 0.3153\n",
      "115/224, train_loss: 0.5424, step time: 0.3855\n",
      "116/224, train_loss: 0.4449, step time: 0.3981\n",
      "117/224, train_loss: 0.3983, step time: 0.3713\n",
      "118/224, train_loss: 0.4334, step time: 0.3138\n",
      "119/224, train_loss: 0.3747, step time: 0.3731\n",
      "120/224, train_loss: 0.4284, step time: 0.3934\n",
      "121/224, train_loss: 0.4141, step time: 0.3159\n",
      "122/224, train_loss: 0.3872, step time: 0.3154\n",
      "123/224, train_loss: 0.4011, step time: 0.3129\n",
      "124/224, train_loss: 0.4330, step time: 0.3153\n",
      "125/224, train_loss: 0.4024, step time: 0.3182\n",
      "126/224, train_loss: 0.4885, step time: 0.4049\n",
      "127/224, train_loss: 0.3970, step time: 0.3824\n",
      "128/224, train_loss: 0.4218, step time: 0.3179\n",
      "129/224, train_loss: 0.3809, step time: 0.3178\n",
      "130/224, train_loss: 0.4319, step time: 0.3807\n",
      "131/224, train_loss: 0.4077, step time: 0.3820\n",
      "132/224, train_loss: 0.4282, step time: 0.3175\n",
      "133/224, train_loss: 0.4139, step time: 0.3157\n",
      "134/224, train_loss: 0.3871, step time: 0.3942\n",
      "135/224, train_loss: 0.3952, step time: 0.3789\n",
      "136/224, train_loss: 0.4501, step time: 0.3181\n",
      "137/224, train_loss: 0.3856, step time: 0.3154\n",
      "138/224, train_loss: 0.4043, step time: 0.3130\n",
      "139/224, train_loss: 0.3958, step time: 0.3151\n",
      "140/224, train_loss: 0.3861, step time: 0.3824\n",
      "141/224, train_loss: 0.3808, step time: 0.3726\n",
      "142/224, train_loss: 0.4054, step time: 0.3176\n",
      "143/224, train_loss: 0.4143, step time: 0.4030\n",
      "144/224, train_loss: 0.3972, step time: 0.3952\n",
      "145/224, train_loss: 0.4184, step time: 0.3162\n",
      "146/224, train_loss: 0.4214, step time: 0.3171\n",
      "147/224, train_loss: 0.3933, step time: 0.3163\n",
      "148/224, train_loss: 0.4226, step time: 0.3162\n",
      "149/224, train_loss: 0.4104, step time: 0.3837\n",
      "150/224, train_loss: 0.4154, step time: 0.3153\n",
      "151/224, train_loss: 0.3981, step time: 0.3710\n",
      "152/224, train_loss: 0.4450, step time: 0.3816\n",
      "153/224, train_loss: 0.4313, step time: 0.3987\n",
      "154/224, train_loss: 0.4068, step time: 0.3827\n",
      "155/224, train_loss: 0.3860, step time: 0.3185\n",
      "156/224, train_loss: 0.3926, step time: 0.3806\n",
      "157/224, train_loss: 0.4646, step time: 0.3153\n",
      "158/224, train_loss: 0.4077, step time: 0.3904\n",
      "159/224, train_loss: 0.4058, step time: 0.3157\n",
      "160/224, train_loss: 0.3938, step time: 0.4069\n",
      "161/224, train_loss: 0.4009, step time: 0.3782\n",
      "162/224, train_loss: 0.4466, step time: 0.3158\n",
      "163/224, train_loss: 0.4270, step time: 0.3152\n",
      "164/224, train_loss: 0.4301, step time: 0.3849\n",
      "165/224, train_loss: 0.3730, step time: 0.3160\n",
      "166/224, train_loss: 0.3983, step time: 0.3179\n",
      "167/224, train_loss: 0.4276, step time: 0.3177\n",
      "168/224, train_loss: 0.4149, step time: 0.3174\n",
      "169/224, train_loss: 0.4114, step time: 0.4026\n",
      "170/224, train_loss: 0.4216, step time: 0.3187\n",
      "171/224, train_loss: 0.4103, step time: 0.3178\n",
      "172/224, train_loss: 0.3834, step time: 0.3896\n",
      "173/224, train_loss: 0.4111, step time: 0.3184\n",
      "174/224, train_loss: 0.3901, step time: 0.3855\n",
      "175/224, train_loss: 0.3663, step time: 0.3151\n",
      "176/224, train_loss: 0.3695, step time: 0.3157\n",
      "177/224, train_loss: 0.4919, step time: 0.3946\n",
      "178/224, train_loss: 0.4300, step time: 0.3928\n",
      "179/224, train_loss: 0.3939, step time: 0.3913\n",
      "180/224, train_loss: 0.3984, step time: 0.3132\n",
      "181/224, train_loss: 0.4104, step time: 0.3133\n",
      "182/224, train_loss: 0.3963, step time: 0.3153\n",
      "183/224, train_loss: 0.3789, step time: 0.3182\n",
      "184/224, train_loss: 0.4055, step time: 0.3163\n",
      "185/224, train_loss: 0.3908, step time: 0.3152\n",
      "186/224, train_loss: 0.4247, step time: 0.3173\n",
      "187/224, train_loss: 0.4303, step time: 0.3159\n",
      "188/224, train_loss: 0.3961, step time: 0.3183\n",
      "189/224, train_loss: 0.3810, step time: 0.3156\n",
      "190/224, train_loss: 0.5587, step time: 0.3949\n",
      "191/224, train_loss: 0.3894, step time: 0.3179\n",
      "192/224, train_loss: 0.4145, step time: 0.4086\n",
      "193/224, train_loss: 0.3898, step time: 0.3879\n",
      "194/224, train_loss: 0.4267, step time: 0.3161\n",
      "195/224, train_loss: 0.4495, step time: 0.3158\n",
      "196/224, train_loss: 0.4141, step time: 0.3828\n",
      "197/224, train_loss: 0.4042, step time: 0.3152\n",
      "198/224, train_loss: 0.4140, step time: 0.3180\n",
      "199/224, train_loss: 0.3957, step time: 0.3900\n",
      "200/224, train_loss: 0.4444, step time: 0.3872\n",
      "201/224, train_loss: 0.5160, step time: 0.3170\n",
      "202/224, train_loss: 0.4068, step time: 0.3761\n",
      "203/224, train_loss: 0.4034, step time: 0.3155\n",
      "204/224, train_loss: 0.4430, step time: 0.3156\n",
      "205/224, train_loss: 0.4604, step time: 0.3867\n",
      "206/224, train_loss: 0.4342, step time: 0.4054\n",
      "207/224, train_loss: 0.3791, step time: 0.3798\n",
      "208/224, train_loss: 0.3914, step time: 0.4001\n",
      "209/224, train_loss: 0.4004, step time: 0.3837\n",
      "210/224, train_loss: 0.4335, step time: 0.4014\n",
      "211/224, train_loss: 0.3813, step time: 0.3163\n",
      "212/224, train_loss: 0.3837, step time: 0.4024\n",
      "213/224, train_loss: 0.4310, step time: 0.3704\n",
      "214/224, train_loss: 0.4607, step time: 0.3181\n",
      "215/224, train_loss: 0.3974, step time: 0.3767\n",
      "216/224, train_loss: 0.3976, step time: 0.3142\n",
      "217/224, train_loss: 0.4306, step time: 0.3824\n",
      "218/224, train_loss: 0.3742, step time: 0.3140\n",
      "219/224, train_loss: 0.4251, step time: 0.3736\n",
      "220/224, train_loss: 0.4844, step time: 0.3912\n",
      "221/224, train_loss: 0.4134, step time: 0.3839\n",
      "222/224, train_loss: 0.3775, step time: 0.4054\n",
      "223/224, train_loss: 0.4032, step time: 0.4036\n",
      "224/224, train_loss: 0.3881, step time: 0.3156\n",
      "epoch 12 average loss: 0.4192\n",
      "current epoch: 12 current mean dice: 0.5940 class1: 0.9991 class2: 0.6816 class3: 0.1012\n",
      "best mean dice: 0.5940 at epoch: 12\n",
      "time consuming of epoch 12 is: 759.6811\n",
      "hello\n",
      "----------\n",
      "epoch 13/100\n",
      "1/224, train_loss: 0.3841, step time: 0.3184\n",
      "2/224, train_loss: 0.3917, step time: 0.3160\n",
      "3/224, train_loss: 0.3887, step time: 0.3769\n",
      "4/224, train_loss: 0.3748, step time: 0.3837\n",
      "5/224, train_loss: 0.4293, step time: 0.3151\n",
      "6/224, train_loss: 0.4630, step time: 0.3133\n",
      "7/224, train_loss: 0.4116, step time: 0.4022\n",
      "8/224, train_loss: 0.4428, step time: 0.3864\n",
      "9/224, train_loss: 0.4304, step time: 0.3693\n",
      "10/224, train_loss: 0.3962, step time: 0.3153\n",
      "11/224, train_loss: 0.3836, step time: 0.3178\n",
      "12/224, train_loss: 0.4704, step time: 0.3998\n",
      "13/224, train_loss: 0.4129, step time: 0.3929\n",
      "14/224, train_loss: 0.3800, step time: 0.3734\n",
      "15/224, train_loss: 0.4137, step time: 0.3994\n",
      "16/224, train_loss: 0.4083, step time: 0.3874\n",
      "17/224, train_loss: 0.3760, step time: 0.3137\n",
      "18/224, train_loss: 0.3898, step time: 0.3690\n",
      "19/224, train_loss: 0.3847, step time: 0.3736\n",
      "20/224, train_loss: 0.3795, step time: 0.3154\n",
      "21/224, train_loss: 0.3848, step time: 0.3181\n",
      "22/224, train_loss: 0.4834, step time: 0.3829\n",
      "23/224, train_loss: 0.3970, step time: 0.3154\n",
      "24/224, train_loss: 0.4015, step time: 0.4017\n",
      "25/224, train_loss: 0.3950, step time: 0.3763\n",
      "26/224, train_loss: 0.4258, step time: 0.3969\n",
      "27/224, train_loss: 0.4099, step time: 0.3866\n",
      "28/224, train_loss: 0.3789, step time: 0.3159\n",
      "29/224, train_loss: 0.4194, step time: 0.3140\n",
      "30/224, train_loss: 0.3753, step time: 0.3155\n",
      "31/224, train_loss: 0.5460, step time: 0.3172\n",
      "32/224, train_loss: 0.4215, step time: 0.3979\n",
      "33/224, train_loss: 0.3820, step time: 0.4021\n",
      "34/224, train_loss: 0.4378, step time: 0.3174\n",
      "35/224, train_loss: 0.4080, step time: 0.3177\n",
      "36/224, train_loss: 0.4596, step time: 0.3150\n",
      "37/224, train_loss: 0.3697, step time: 0.3149\n",
      "38/224, train_loss: 0.4147, step time: 0.3181\n",
      "39/224, train_loss: 0.3800, step time: 0.3158\n",
      "40/224, train_loss: 0.4102, step time: 0.3994\n",
      "41/224, train_loss: 0.3890, step time: 0.3172\n",
      "42/224, train_loss: 0.4125, step time: 0.3150\n",
      "43/224, train_loss: 0.4299, step time: 0.3766\n",
      "44/224, train_loss: 0.4374, step time: 0.4084\n",
      "45/224, train_loss: 0.5781, step time: 0.4126\n",
      "46/224, train_loss: 0.3941, step time: 0.3159\n",
      "47/224, train_loss: 0.3941, step time: 0.3163\n",
      "48/224, train_loss: 0.4715, step time: 0.3874\n",
      "49/224, train_loss: 0.4028, step time: 0.3829\n",
      "50/224, train_loss: 0.5018, step time: 0.3984\n",
      "51/224, train_loss: 0.4060, step time: 0.3152\n",
      "52/224, train_loss: 0.4110, step time: 0.3675\n",
      "53/224, train_loss: 0.4134, step time: 0.3151\n",
      "54/224, train_loss: 0.3848, step time: 0.3151\n",
      "55/224, train_loss: 0.4498, step time: 0.3700\n",
      "56/224, train_loss: 0.4124, step time: 0.3152\n",
      "57/224, train_loss: 0.4328, step time: 0.3867\n",
      "58/224, train_loss: 0.3827, step time: 0.3160\n",
      "59/224, train_loss: 0.5399, step time: 0.3656\n",
      "60/224, train_loss: 0.4220, step time: 0.3898\n",
      "61/224, train_loss: 0.3878, step time: 0.3137\n",
      "62/224, train_loss: 0.3926, step time: 0.3179\n",
      "63/224, train_loss: 0.3999, step time: 0.4080\n",
      "64/224, train_loss: 0.4120, step time: 0.3844\n",
      "65/224, train_loss: 0.4048, step time: 0.3953\n",
      "66/224, train_loss: 0.4005, step time: 0.3678\n",
      "67/224, train_loss: 0.4791, step time: 0.3152\n",
      "68/224, train_loss: 0.4389, step time: 0.3164\n",
      "69/224, train_loss: 0.4120, step time: 0.3681\n",
      "70/224, train_loss: 0.3944, step time: 0.3816\n",
      "71/224, train_loss: 0.4284, step time: 0.3998\n",
      "72/224, train_loss: 0.4047, step time: 0.3142\n",
      "73/224, train_loss: 0.3986, step time: 0.3126\n",
      "74/224, train_loss: 0.3750, step time: 0.3651\n",
      "75/224, train_loss: 0.3757, step time: 0.3856\n",
      "76/224, train_loss: 0.4157, step time: 0.3128\n",
      "77/224, train_loss: 0.4460, step time: 0.3169\n",
      "78/224, train_loss: 0.4210, step time: 0.3145\n",
      "79/224, train_loss: 0.3985, step time: 0.3139\n",
      "80/224, train_loss: 0.4220, step time: 0.3140\n",
      "81/224, train_loss: 0.4081, step time: 0.3144\n",
      "82/224, train_loss: 0.4060, step time: 0.3665\n",
      "83/224, train_loss: 0.4436, step time: 0.3152\n",
      "84/224, train_loss: 0.4287, step time: 0.3128\n",
      "85/224, train_loss: 0.4457, step time: 0.3163\n",
      "86/224, train_loss: 0.3938, step time: 0.4001\n",
      "87/224, train_loss: 0.3752, step time: 0.3899\n",
      "88/224, train_loss: 0.3927, step time: 0.3147\n",
      "89/224, train_loss: 0.4243, step time: 0.3139\n",
      "90/224, train_loss: 0.4274, step time: 0.3162\n",
      "91/224, train_loss: 0.4905, step time: 0.3841\n",
      "92/224, train_loss: 0.4115, step time: 0.3173\n",
      "93/224, train_loss: 0.4601, step time: 0.3747\n",
      "94/224, train_loss: 0.4234, step time: 0.3174\n",
      "95/224, train_loss: 0.3827, step time: 0.3765\n",
      "96/224, train_loss: 0.4119, step time: 0.3148\n",
      "97/224, train_loss: 0.4086, step time: 0.3166\n",
      "98/224, train_loss: 0.3938, step time: 0.3142\n",
      "99/224, train_loss: 0.4039, step time: 0.3846\n",
      "100/224, train_loss: 0.3747, step time: 0.3147\n",
      "101/224, train_loss: 0.4256, step time: 0.3703\n",
      "102/224, train_loss: 0.3989, step time: 0.3881\n",
      "103/224, train_loss: 0.3817, step time: 0.3121\n",
      "104/224, train_loss: 0.3872, step time: 0.3165\n",
      "105/224, train_loss: 0.3866, step time: 0.3171\n",
      "106/224, train_loss: 0.4440, step time: 0.3125\n",
      "107/224, train_loss: 0.3675, step time: 0.3167\n",
      "108/224, train_loss: 0.3912, step time: 0.3686\n",
      "109/224, train_loss: 0.3968, step time: 0.3121\n",
      "110/224, train_loss: 0.3781, step time: 0.3165\n",
      "111/224, train_loss: 0.3921, step time: 0.3756\n",
      "112/224, train_loss: 0.4447, step time: 0.3141\n",
      "113/224, train_loss: 0.3776, step time: 0.3164\n",
      "114/224, train_loss: 0.4080, step time: 0.3648\n",
      "115/224, train_loss: 0.3987, step time: 0.3786\n",
      "116/224, train_loss: 0.3795, step time: 0.3144\n",
      "117/224, train_loss: 0.4571, step time: 0.3817\n",
      "118/224, train_loss: 0.4148, step time: 0.3170\n",
      "119/224, train_loss: 0.4195, step time: 0.3144\n",
      "120/224, train_loss: 0.4258, step time: 0.3741\n",
      "121/224, train_loss: 0.3892, step time: 0.3965\n",
      "122/224, train_loss: 0.3918, step time: 0.3140\n",
      "123/224, train_loss: 0.3951, step time: 0.4054\n",
      "124/224, train_loss: 0.4003, step time: 0.3166\n",
      "125/224, train_loss: 0.3730, step time: 0.3671\n",
      "126/224, train_loss: 0.4307, step time: 0.3892\n",
      "127/224, train_loss: 0.4921, step time: 0.3784\n",
      "128/224, train_loss: 0.3758, step time: 0.3846\n",
      "129/224, train_loss: 0.3738, step time: 0.3148\n",
      "130/224, train_loss: 0.4244, step time: 0.3124\n",
      "131/224, train_loss: 0.4259, step time: 0.3161\n",
      "132/224, train_loss: 0.4090, step time: 0.3140\n",
      "133/224, train_loss: 0.4302, step time: 0.3935\n",
      "134/224, train_loss: 0.3740, step time: 0.3956\n",
      "135/224, train_loss: 0.4267, step time: 0.3702\n",
      "136/224, train_loss: 0.4022, step time: 0.3146\n",
      "137/224, train_loss: 0.3916, step time: 0.3141\n",
      "138/224, train_loss: 0.3771, step time: 0.3171\n",
      "139/224, train_loss: 0.3915, step time: 0.3154\n",
      "140/224, train_loss: 0.4025, step time: 0.3145\n",
      "141/224, train_loss: 0.4405, step time: 0.3904\n",
      "142/224, train_loss: 0.3948, step time: 0.3140\n",
      "143/224, train_loss: 0.3602, step time: 0.3144\n",
      "144/224, train_loss: 0.4113, step time: 0.3151\n",
      "145/224, train_loss: 0.4075, step time: 0.3893\n",
      "146/224, train_loss: 0.4076, step time: 0.3883\n",
      "147/224, train_loss: 0.4014, step time: 0.3150\n",
      "148/224, train_loss: 0.5027, step time: 0.3656\n",
      "149/224, train_loss: 0.4120, step time: 0.3163\n",
      "150/224, train_loss: 0.4176, step time: 0.4051\n",
      "151/224, train_loss: 0.3610, step time: 0.3170\n",
      "152/224, train_loss: 0.3687, step time: 0.3993\n",
      "153/224, train_loss: 0.3836, step time: 0.3144\n",
      "154/224, train_loss: 0.4057, step time: 0.3147\n",
      "155/224, train_loss: 0.3727, step time: 0.3744\n",
      "156/224, train_loss: 0.3878, step time: 0.3641\n",
      "157/224, train_loss: 0.3797, step time: 0.3164\n",
      "158/224, train_loss: 0.3707, step time: 0.3809\n",
      "159/224, train_loss: 0.3671, step time: 0.3786\n",
      "160/224, train_loss: 0.3922, step time: 0.3161\n",
      "161/224, train_loss: 0.4026, step time: 0.3981\n",
      "162/224, train_loss: 0.4133, step time: 0.3989\n",
      "163/224, train_loss: 0.3897, step time: 0.3143\n",
      "164/224, train_loss: 0.3739, step time: 0.3144\n",
      "165/224, train_loss: 0.4285, step time: 0.4106\n",
      "166/224, train_loss: 0.3956, step time: 0.3118\n",
      "167/224, train_loss: 0.4145, step time: 0.3739\n",
      "168/224, train_loss: 0.4254, step time: 0.3812\n",
      "169/224, train_loss: 0.3865, step time: 0.3169\n",
      "170/224, train_loss: 0.3919, step time: 0.3138\n",
      "171/224, train_loss: 0.3759, step time: 0.3159\n",
      "172/224, train_loss: 0.4470, step time: 0.3137\n",
      "173/224, train_loss: 0.4797, step time: 0.4110\n",
      "174/224, train_loss: 0.3886, step time: 0.3912\n",
      "175/224, train_loss: 0.3755, step time: 0.3142\n",
      "176/224, train_loss: 0.3904, step time: 0.3137\n",
      "177/224, train_loss: 0.3917, step time: 0.3158\n",
      "178/224, train_loss: 0.3592, step time: 0.3849\n",
      "179/224, train_loss: 0.4562, step time: 0.3165\n",
      "180/224, train_loss: 0.3978, step time: 0.4099\n",
      "181/224, train_loss: 0.4018, step time: 0.3905\n",
      "182/224, train_loss: 0.3839, step time: 0.3830\n",
      "183/224, train_loss: 0.3752, step time: 0.3143\n",
      "184/224, train_loss: 0.3993, step time: 0.3901\n",
      "185/224, train_loss: 0.4566, step time: 0.3820\n",
      "186/224, train_loss: 0.4721, step time: 0.3707\n",
      "187/224, train_loss: 0.4218, step time: 0.4000\n",
      "188/224, train_loss: 0.3700, step time: 0.3162\n",
      "189/224, train_loss: 0.3648, step time: 0.3121\n",
      "190/224, train_loss: 0.4276, step time: 0.3139\n",
      "191/224, train_loss: 0.3703, step time: 0.3118\n",
      "192/224, train_loss: 0.3862, step time: 0.3785\n",
      "193/224, train_loss: 0.3742, step time: 0.3886\n",
      "194/224, train_loss: 0.3823, step time: 0.3140\n",
      "195/224, train_loss: 0.3877, step time: 0.3144\n",
      "196/224, train_loss: 0.4190, step time: 0.3983\n",
      "197/224, train_loss: 0.4134, step time: 0.4044\n",
      "198/224, train_loss: 0.4296, step time: 0.3125\n",
      "199/224, train_loss: 0.4046, step time: 0.3701\n",
      "200/224, train_loss: 0.4608, step time: 0.3139\n",
      "201/224, train_loss: 0.4162, step time: 0.3885\n",
      "202/224, train_loss: 0.3872, step time: 0.3144\n",
      "203/224, train_loss: 0.3693, step time: 0.3862\n",
      "204/224, train_loss: 0.3699, step time: 0.4016\n",
      "205/224, train_loss: 0.4099, step time: 0.3837\n",
      "206/224, train_loss: 0.3817, step time: 0.3171\n",
      "207/224, train_loss: 0.3739, step time: 0.3164\n",
      "208/224, train_loss: 0.3891, step time: 0.4102\n",
      "209/224, train_loss: 0.3678, step time: 0.3141\n",
      "210/224, train_loss: 0.3621, step time: 0.3935\n",
      "211/224, train_loss: 0.5466, step time: 0.3771\n",
      "212/224, train_loss: 0.4157, step time: 0.3122\n",
      "213/224, train_loss: 0.3882, step time: 0.3995\n",
      "214/224, train_loss: 0.4066, step time: 0.3146\n",
      "215/224, train_loss: 0.4364, step time: 0.3166\n",
      "216/224, train_loss: 0.4056, step time: 0.3729\n",
      "217/224, train_loss: 0.4298, step time: 0.3685\n",
      "218/224, train_loss: 0.3774, step time: 0.3150\n",
      "219/224, train_loss: 0.3858, step time: 0.3166\n",
      "220/224, train_loss: 0.3670, step time: 0.3742\n",
      "221/224, train_loss: 0.3735, step time: 0.3147\n",
      "222/224, train_loss: 0.4649, step time: 0.3147\n",
      "223/224, train_loss: 0.3717, step time: 0.3156\n",
      "224/224, train_loss: 0.3731, step time: 0.3176\n",
      "epoch 13 average loss: 0.4082\n",
      "current epoch: 13 current mean dice: 0.6011 class1: 0.9992 class2: 0.7132 class3: 0.0908\n",
      "best mean dice: 0.6011 at epoch: 13\n",
      "time consuming of epoch 13 is: 693.2856\n",
      "hello\n",
      "----------\n",
      "epoch 14/100\n",
      "1/224, train_loss: 0.4213, step time: 0.3170\n",
      "2/224, train_loss: 0.3726, step time: 0.3684\n",
      "3/224, train_loss: 0.4606, step time: 0.3767\n",
      "4/224, train_loss: 0.3893, step time: 0.3132\n",
      "5/224, train_loss: 0.3776, step time: 0.3177\n",
      "6/224, train_loss: 0.3803, step time: 0.3983\n",
      "7/224, train_loss: 0.4444, step time: 0.3673\n",
      "8/224, train_loss: 0.3748, step time: 0.3148\n",
      "9/224, train_loss: 0.3674, step time: 0.3773\n",
      "10/224, train_loss: 0.4075, step time: 0.3694\n",
      "11/224, train_loss: 0.3873, step time: 0.3743\n",
      "12/224, train_loss: 0.3658, step time: 0.3172\n",
      "13/224, train_loss: 0.4224, step time: 0.3734\n",
      "14/224, train_loss: 0.4587, step time: 0.3162\n",
      "15/224, train_loss: 0.4011, step time: 0.3165\n",
      "16/224, train_loss: 0.3741, step time: 0.3169\n",
      "17/224, train_loss: 0.4113, step time: 0.3123\n",
      "18/224, train_loss: 0.3531, step time: 0.3143\n",
      "19/224, train_loss: 0.4048, step time: 0.3174\n",
      "20/224, train_loss: 0.3771, step time: 0.3153\n",
      "21/224, train_loss: 0.3964, step time: 0.4095\n",
      "22/224, train_loss: 0.3741, step time: 0.3168\n",
      "23/224, train_loss: 0.4445, step time: 0.3939\n",
      "24/224, train_loss: 0.3630, step time: 0.3167\n",
      "25/224, train_loss: 0.3955, step time: 0.3140\n",
      "26/224, train_loss: 0.3834, step time: 0.3139\n",
      "27/224, train_loss: 0.4068, step time: 0.3696\n",
      "28/224, train_loss: 0.3875, step time: 0.3139\n",
      "29/224, train_loss: 0.3761, step time: 0.4054\n",
      "30/224, train_loss: 0.4277, step time: 0.4069\n",
      "31/224, train_loss: 0.4022, step time: 0.3126\n",
      "32/224, train_loss: 0.4130, step time: 0.3149\n",
      "33/224, train_loss: 0.4007, step time: 0.3800\n",
      "34/224, train_loss: 0.3667, step time: 0.3821\n",
      "35/224, train_loss: 0.4070, step time: 0.3816\n",
      "36/224, train_loss: 0.3802, step time: 0.4098\n",
      "37/224, train_loss: 0.3909, step time: 0.3153\n",
      "38/224, train_loss: 0.4042, step time: 0.3124\n",
      "39/224, train_loss: 0.3753, step time: 0.3125\n",
      "40/224, train_loss: 0.4348, step time: 0.3153\n",
      "41/224, train_loss: 0.3429, step time: 0.3752\n",
      "42/224, train_loss: 0.3823, step time: 0.3149\n",
      "43/224, train_loss: 0.3922, step time: 0.3145\n",
      "44/224, train_loss: 0.3910, step time: 0.3143\n",
      "45/224, train_loss: 0.3844, step time: 0.3173\n",
      "46/224, train_loss: 0.3741, step time: 0.3130\n",
      "47/224, train_loss: 0.4006, step time: 0.3886\n",
      "48/224, train_loss: 0.3968, step time: 0.3954\n",
      "49/224, train_loss: 0.4161, step time: 0.3128\n",
      "50/224, train_loss: 0.3857, step time: 0.3993\n",
      "51/224, train_loss: 0.3662, step time: 0.3145\n",
      "52/224, train_loss: 0.3717, step time: 0.3145\n",
      "53/224, train_loss: 0.3865, step time: 0.3989\n",
      "54/224, train_loss: 0.3917, step time: 0.3163\n",
      "55/224, train_loss: 0.3684, step time: 0.4039\n",
      "56/224, train_loss: 0.3944, step time: 0.3145\n",
      "57/224, train_loss: 0.3622, step time: 0.3793\n",
      "58/224, train_loss: 0.3889, step time: 0.3940\n",
      "59/224, train_loss: 0.3882, step time: 0.3673\n",
      "60/224, train_loss: 0.3736, step time: 0.3750\n",
      "61/224, train_loss: 0.4271, step time: 0.4041\n",
      "62/224, train_loss: 0.4158, step time: 0.3157\n",
      "63/224, train_loss: 0.4083, step time: 0.3147\n",
      "64/224, train_loss: 0.3883, step time: 0.3172\n",
      "65/224, train_loss: 0.3712, step time: 0.4122\n",
      "66/224, train_loss: 0.3576, step time: 0.3123\n",
      "67/224, train_loss: 0.3876, step time: 0.3938\n",
      "68/224, train_loss: 0.4378, step time: 0.3156\n",
      "69/224, train_loss: 0.3827, step time: 0.3177\n",
      "70/224, train_loss: 0.3675, step time: 0.3147\n",
      "71/224, train_loss: 0.4171, step time: 0.3957\n",
      "72/224, train_loss: 0.4148, step time: 0.3149\n",
      "73/224, train_loss: 0.3559, step time: 0.3125\n",
      "74/224, train_loss: 0.4443, step time: 0.3166\n",
      "75/224, train_loss: 0.3880, step time: 0.3687\n",
      "76/224, train_loss: 0.3742, step time: 0.4053\n",
      "77/224, train_loss: 0.3607, step time: 0.3153\n",
      "78/224, train_loss: 0.3722, step time: 0.3143\n",
      "79/224, train_loss: 0.3876, step time: 0.3648\n",
      "80/224, train_loss: 0.4225, step time: 0.3914\n",
      "81/224, train_loss: 0.4170, step time: 0.3143\n",
      "82/224, train_loss: 0.3652, step time: 0.3120\n",
      "83/224, train_loss: 0.3897, step time: 0.3144\n",
      "84/224, train_loss: 0.3991, step time: 0.3139\n",
      "85/224, train_loss: 0.3536, step time: 0.3763\n",
      "86/224, train_loss: 0.3765, step time: 0.3148\n",
      "87/224, train_loss: 0.3657, step time: 0.3929\n",
      "88/224, train_loss: 0.4289, step time: 0.3694\n",
      "89/224, train_loss: 0.4187, step time: 0.3793\n",
      "90/224, train_loss: 0.3991, step time: 0.4139\n",
      "91/224, train_loss: 0.3806, step time: 0.3134\n",
      "92/224, train_loss: 0.3781, step time: 0.3151\n",
      "93/224, train_loss: 0.3818, step time: 0.3756\n",
      "94/224, train_loss: 0.4189, step time: 0.3905\n",
      "95/224, train_loss: 0.3969, step time: 0.3894\n",
      "96/224, train_loss: 0.3811, step time: 0.3129\n",
      "97/224, train_loss: 0.3890, step time: 0.3767\n",
      "98/224, train_loss: 0.4050, step time: 0.3822\n",
      "99/224, train_loss: 0.4320, step time: 0.3958\n",
      "100/224, train_loss: 0.4868, step time: 0.3862\n",
      "101/224, train_loss: 0.3722, step time: 0.3755\n",
      "102/224, train_loss: 0.3728, step time: 0.4018\n",
      "103/224, train_loss: 0.4113, step time: 0.4121\n",
      "104/224, train_loss: 0.4525, step time: 0.3173\n",
      "105/224, train_loss: 0.4530, step time: 0.3989\n",
      "106/224, train_loss: 0.3868, step time: 0.3164\n",
      "107/224, train_loss: 0.3956, step time: 0.3142\n",
      "108/224, train_loss: 0.3892, step time: 0.3869\n",
      "109/224, train_loss: 0.3870, step time: 0.3965\n",
      "110/224, train_loss: 0.3678, step time: 0.3908\n",
      "111/224, train_loss: 0.3909, step time: 0.3167\n",
      "112/224, train_loss: 0.4289, step time: 0.3141\n",
      "113/224, train_loss: 0.3659, step time: 0.4105\n",
      "114/224, train_loss: 0.4161, step time: 0.3756\n",
      "115/224, train_loss: 0.3882, step time: 0.4094\n",
      "116/224, train_loss: 0.3572, step time: 0.3144\n",
      "117/224, train_loss: 0.3877, step time: 0.3148\n",
      "118/224, train_loss: 0.3780, step time: 0.3143\n",
      "119/224, train_loss: 0.3629, step time: 0.3140\n",
      "120/224, train_loss: 0.4305, step time: 0.4031\n",
      "121/224, train_loss: 0.5305, step time: 0.3871\n",
      "122/224, train_loss: 0.3725, step time: 0.3901\n",
      "123/224, train_loss: 0.4299, step time: 0.3736\n",
      "124/224, train_loss: 0.4024, step time: 0.3727\n",
      "125/224, train_loss: 0.4098, step time: 0.3915\n",
      "126/224, train_loss: 0.3623, step time: 0.4016\n",
      "127/224, train_loss: 0.3745, step time: 0.3150\n",
      "128/224, train_loss: 0.3738, step time: 0.3809\n",
      "129/224, train_loss: 0.3650, step time: 0.3126\n",
      "130/224, train_loss: 0.3613, step time: 0.3174\n",
      "131/224, train_loss: 0.4059, step time: 0.3168\n",
      "132/224, train_loss: 0.4490, step time: 0.3127\n",
      "133/224, train_loss: 0.5072, step time: 0.4043\n",
      "134/224, train_loss: 0.4195, step time: 0.3948\n",
      "135/224, train_loss: 0.3779, step time: 0.3798\n",
      "136/224, train_loss: 0.3734, step time: 0.3927\n",
      "137/224, train_loss: 0.3935, step time: 0.4088\n",
      "138/224, train_loss: 0.4093, step time: 0.3149\n",
      "139/224, train_loss: 0.4086, step time: 0.5418\n",
      "140/224, train_loss: 0.3815, step time: 0.3809\n",
      "141/224, train_loss: 0.3655, step time: 0.3180\n",
      "142/224, train_loss: 0.3981, step time: 0.3173\n",
      "143/224, train_loss: 0.3774, step time: 0.3898\n",
      "144/224, train_loss: 0.4482, step time: 0.3900\n",
      "145/224, train_loss: 0.3539, step time: 0.3152\n",
      "146/224, train_loss: 0.4088, step time: 0.3177\n",
      "147/224, train_loss: 0.4260, step time: 0.4011\n",
      "148/224, train_loss: 0.3568, step time: 0.3166\n",
      "149/224, train_loss: 0.3973, step time: 0.3132\n",
      "150/224, train_loss: 0.4076, step time: 0.3960\n",
      "151/224, train_loss: 0.3636, step time: 0.3148\n",
      "152/224, train_loss: 0.4123, step time: 0.4006\n",
      "153/224, train_loss: 0.4072, step time: 0.3126\n",
      "154/224, train_loss: 0.3779, step time: 0.3712\n",
      "155/224, train_loss: 0.3598, step time: 0.3783\n",
      "156/224, train_loss: 0.4353, step time: 0.3820\n",
      "157/224, train_loss: 0.3679, step time: 0.3130\n",
      "158/224, train_loss: 0.3985, step time: 0.3126\n",
      "159/224, train_loss: 0.4020, step time: 0.3171\n",
      "160/224, train_loss: 0.3986, step time: 0.4101\n",
      "161/224, train_loss: 0.3707, step time: 0.3787\n",
      "162/224, train_loss: 0.3603, step time: 0.3150\n",
      "163/224, train_loss: 0.3682, step time: 0.3120\n",
      "164/224, train_loss: 0.3817, step time: 0.3826\n",
      "165/224, train_loss: 0.3658, step time: 0.3801\n",
      "166/224, train_loss: 0.4111, step time: 0.3177\n",
      "167/224, train_loss: 0.4435, step time: 0.3769\n",
      "168/224, train_loss: 0.3675, step time: 0.3175\n",
      "169/224, train_loss: 0.4288, step time: 0.3700\n",
      "170/224, train_loss: 0.4236, step time: 0.3777\n",
      "171/224, train_loss: 0.3655, step time: 0.3123\n",
      "172/224, train_loss: 0.4001, step time: 0.3147\n",
      "173/224, train_loss: 0.3693, step time: 0.4045\n",
      "174/224, train_loss: 0.3874, step time: 0.3699\n",
      "175/224, train_loss: 0.3440, step time: 0.4006\n",
      "176/224, train_loss: 0.3770, step time: 0.4029\n",
      "177/224, train_loss: 0.4460, step time: 0.3149\n",
      "178/224, train_loss: 0.3675, step time: 0.3154\n",
      "179/224, train_loss: 0.4350, step time: 0.4039\n",
      "180/224, train_loss: 0.4301, step time: 0.3653\n",
      "181/224, train_loss: 0.3630, step time: 0.3900\n",
      "182/224, train_loss: 0.3801, step time: 0.3883\n",
      "183/224, train_loss: 0.4115, step time: 0.3772\n",
      "184/224, train_loss: 0.3838, step time: 0.3832\n",
      "185/224, train_loss: 0.3776, step time: 0.3829\n",
      "186/224, train_loss: 0.3866, step time: 0.3158\n",
      "187/224, train_loss: 0.4055, step time: 0.4103\n",
      "188/224, train_loss: 0.4219, step time: 0.3914\n",
      "189/224, train_loss: 0.4073, step time: 0.4078\n",
      "190/224, train_loss: 0.3642, step time: 0.3802\n",
      "191/224, train_loss: 0.4119, step time: 0.3934\n",
      "192/224, train_loss: 0.4730, step time: 0.3716\n",
      "193/224, train_loss: 0.3744, step time: 0.3745\n",
      "194/224, train_loss: 0.3651, step time: 0.4108\n",
      "195/224, train_loss: 0.4903, step time: 0.3199\n",
      "196/224, train_loss: 0.4377, step time: 0.4167\n",
      "197/224, train_loss: 0.4214, step time: 0.3825\n",
      "198/224, train_loss: 0.4328, step time: 0.3181\n",
      "199/224, train_loss: 0.4411, step time: 0.4025\n",
      "200/224, train_loss: 0.4005, step time: 0.3155\n",
      "201/224, train_loss: 0.3625, step time: 0.3183\n",
      "202/224, train_loss: 0.3692, step time: 0.3191\n",
      "203/224, train_loss: 0.3428, step time: 0.3787\n",
      "204/224, train_loss: 0.6126, step time: 0.3785\n",
      "205/224, train_loss: 0.3825, step time: 0.3181\n",
      "206/224, train_loss: 0.3667, step time: 0.3184\n",
      "207/224, train_loss: 0.3834, step time: 0.3936\n",
      "208/224, train_loss: 0.3709, step time: 0.3888\n",
      "209/224, train_loss: 0.4049, step time: 0.3798\n",
      "210/224, train_loss: 0.3842, step time: 0.3161\n",
      "211/224, train_loss: 0.4091, step time: 0.4054\n",
      "212/224, train_loss: 0.4465, step time: 0.4111\n",
      "213/224, train_loss: 0.3740, step time: 0.4012\n",
      "214/224, train_loss: 0.3749, step time: 0.3144\n",
      "215/224, train_loss: 0.3701, step time: 0.4021\n",
      "216/224, train_loss: 0.3782, step time: 0.3858\n",
      "217/224, train_loss: 0.3468, step time: 0.3148\n",
      "218/224, train_loss: 0.3780, step time: 0.3189\n",
      "219/224, train_loss: 0.4407, step time: 0.4111\n",
      "220/224, train_loss: 0.3961, step time: 0.4074\n",
      "221/224, train_loss: 0.3953, step time: 0.3143\n",
      "222/224, train_loss: 0.3528, step time: 0.3138\n",
      "223/224, train_loss: 0.3704, step time: 0.3155\n",
      "224/224, train_loss: 0.3897, step time: 0.3941\n",
      "epoch 14 average loss: 0.3957\n",
      "current epoch: 14 current mean dice: 0.5954 class1: 0.9991 class2: 0.6792 class3: 0.1078\n",
      "best mean dice: 0.6011 at epoch: 13\n",
      "time consuming of epoch 14 is: 798.5807\n",
      "hello\n",
      "----------\n",
      "epoch 15/100\n",
      "1/224, train_loss: 0.3613, step time: 0.3165\n",
      "2/224, train_loss: 0.3700, step time: 0.3160\n",
      "3/224, train_loss: 0.4414, step time: 0.3781\n",
      "4/224, train_loss: 0.3716, step time: 0.4022\n",
      "5/224, train_loss: 0.5339, step time: 0.3757\n",
      "6/224, train_loss: 0.3894, step time: 0.3862\n",
      "7/224, train_loss: 0.3886, step time: 0.3159\n",
      "8/224, train_loss: 0.4347, step time: 0.3957\n",
      "9/224, train_loss: 0.3686, step time: 0.3688\n",
      "10/224, train_loss: 0.3743, step time: 0.3178\n",
      "11/224, train_loss: 0.3914, step time: 0.3158\n",
      "12/224, train_loss: 0.4947, step time: 0.3859\n",
      "13/224, train_loss: 0.4510, step time: 0.3166\n",
      "14/224, train_loss: 0.3576, step time: 0.3746\n",
      "15/224, train_loss: 0.4604, step time: 0.3708\n",
      "16/224, train_loss: 0.4446, step time: 0.3817\n",
      "17/224, train_loss: 0.4374, step time: 0.3696\n",
      "18/224, train_loss: 0.3874, step time: 0.3155\n",
      "19/224, train_loss: 0.4529, step time: 0.4043\n",
      "20/224, train_loss: 0.3829, step time: 0.3184\n",
      "21/224, train_loss: 0.4404, step time: 0.3863\n",
      "22/224, train_loss: 0.4126, step time: 0.4030\n",
      "23/224, train_loss: 0.3939, step time: 0.4125\n",
      "24/224, train_loss: 0.3821, step time: 0.3158\n",
      "25/224, train_loss: 0.3822, step time: 0.3846\n",
      "26/224, train_loss: 0.3814, step time: 0.3836\n",
      "27/224, train_loss: 0.4803, step time: 0.3181\n",
      "28/224, train_loss: 0.4589, step time: 0.3727\n",
      "29/224, train_loss: 0.3945, step time: 0.3150\n",
      "30/224, train_loss: 0.3888, step time: 0.4062\n",
      "31/224, train_loss: 0.3855, step time: 0.3150\n",
      "32/224, train_loss: 0.3909, step time: 0.3152\n",
      "33/224, train_loss: 0.3899, step time: 0.3759\n",
      "34/224, train_loss: 0.4020, step time: 0.3128\n",
      "35/224, train_loss: 0.3947, step time: 0.4068\n",
      "36/224, train_loss: 0.3637, step time: 0.3146\n",
      "37/224, train_loss: 0.4797, step time: 0.4046\n",
      "38/224, train_loss: 0.3486, step time: 0.3153\n",
      "39/224, train_loss: 0.3503, step time: 0.3178\n",
      "40/224, train_loss: 0.3545, step time: 0.3155\n",
      "41/224, train_loss: 0.3798, step time: 0.3977\n",
      "42/224, train_loss: 0.3584, step time: 0.3172\n",
      "43/224, train_loss: 0.4115, step time: 0.3171\n",
      "44/224, train_loss: 0.4001, step time: 0.3154\n",
      "45/224, train_loss: 0.3455, step time: 0.3161\n",
      "46/224, train_loss: 0.3719, step time: 0.3132\n",
      "47/224, train_loss: 0.4693, step time: 0.3146\n",
      "48/224, train_loss: 0.4134, step time: 0.3935\n",
      "49/224, train_loss: 0.3692, step time: 0.3773\n",
      "50/224, train_loss: 0.3979, step time: 0.3148\n",
      "51/224, train_loss: 0.3870, step time: 0.3855\n",
      "52/224, train_loss: 0.3520, step time: 0.3152\n",
      "53/224, train_loss: 0.3971, step time: 0.3152\n",
      "54/224, train_loss: 0.3790, step time: 0.3174\n",
      "55/224, train_loss: 0.4513, step time: 0.3794\n",
      "56/224, train_loss: 0.3776, step time: 0.3773\n",
      "57/224, train_loss: 0.4508, step time: 0.3808\n",
      "58/224, train_loss: 0.3786, step time: 0.3836\n",
      "59/224, train_loss: 0.3638, step time: 0.3130\n",
      "60/224, train_loss: 0.4048, step time: 0.3146\n",
      "61/224, train_loss: 0.4384, step time: 0.3799\n",
      "62/224, train_loss: 0.3101, step time: 0.3173\n",
      "63/224, train_loss: 0.3794, step time: 0.3138\n",
      "64/224, train_loss: 0.4135, step time: 0.4087\n",
      "65/224, train_loss: 0.3554, step time: 0.3153\n",
      "66/224, train_loss: 0.3414, step time: 0.3946\n",
      "67/224, train_loss: 0.3801, step time: 0.3698\n",
      "68/224, train_loss: 0.3763, step time: 0.3960\n",
      "69/224, train_loss: 0.4265, step time: 0.3149\n",
      "70/224, train_loss: 0.3927, step time: 0.3962\n",
      "71/224, train_loss: 0.3480, step time: 0.3126\n",
      "72/224, train_loss: 0.4266, step time: 0.3145\n",
      "73/224, train_loss: 0.3691, step time: 0.3167\n",
      "74/224, train_loss: 0.3765, step time: 0.3152\n",
      "75/224, train_loss: 0.3400, step time: 0.3744\n",
      "76/224, train_loss: 0.3583, step time: 0.3959\n",
      "77/224, train_loss: 0.3955, step time: 0.3167\n",
      "78/224, train_loss: 0.4021, step time: 0.3153\n",
      "79/224, train_loss: 0.4051, step time: 0.3187\n",
      "80/224, train_loss: 0.3832, step time: 0.3180\n",
      "81/224, train_loss: 0.3561, step time: 0.3909\n",
      "82/224, train_loss: 0.4074, step time: 0.3182\n",
      "83/224, train_loss: 0.3874, step time: 0.3929\n",
      "84/224, train_loss: 0.3899, step time: 0.4053\n",
      "85/224, train_loss: 0.3480, step time: 0.3948\n",
      "86/224, train_loss: 0.3688, step time: 0.3155\n",
      "87/224, train_loss: 0.3867, step time: 0.3175\n",
      "88/224, train_loss: 0.3330, step time: 0.3149\n",
      "89/224, train_loss: 0.3514, step time: 0.3144\n",
      "90/224, train_loss: 0.3256, step time: 0.3146\n",
      "91/224, train_loss: 0.3668, step time: 0.3150\n",
      "92/224, train_loss: 0.3616, step time: 0.3668\n",
      "93/224, train_loss: 0.5321, step time: 0.3753\n",
      "94/224, train_loss: 0.3418, step time: 0.3161\n",
      "95/224, train_loss: 0.4516, step time: 0.3865\n",
      "96/224, train_loss: 0.3627, step time: 0.4085\n",
      "97/224, train_loss: 0.3429, step time: 0.3125\n",
      "98/224, train_loss: 0.3944, step time: 0.4123\n",
      "99/224, train_loss: 0.3983, step time: 0.3156\n",
      "100/224, train_loss: 0.3575, step time: 0.3920\n",
      "101/224, train_loss: 0.3649, step time: 0.3146\n",
      "102/224, train_loss: 0.4132, step time: 0.3990\n",
      "103/224, train_loss: 0.3883, step time: 0.3149\n",
      "104/224, train_loss: 0.4315, step time: 0.3768\n",
      "105/224, train_loss: 0.3520, step time: 0.3904\n",
      "106/224, train_loss: 0.4064, step time: 0.3153\n",
      "107/224, train_loss: 0.3747, step time: 0.3169\n",
      "108/224, train_loss: 0.3489, step time: 0.3174\n",
      "109/224, train_loss: 0.4017, step time: 0.3966\n",
      "110/224, train_loss: 0.3573, step time: 0.3857\n",
      "111/224, train_loss: 0.3925, step time: 0.3868\n",
      "112/224, train_loss: 0.3574, step time: 0.3162\n",
      "113/224, train_loss: 0.3527, step time: 0.3157\n",
      "114/224, train_loss: 0.3844, step time: 0.3662\n",
      "115/224, train_loss: 0.3754, step time: 0.3157\n",
      "116/224, train_loss: 0.4037, step time: 0.3153\n",
      "117/224, train_loss: 0.3836, step time: 0.3158\n",
      "118/224, train_loss: 0.3728, step time: 0.3998\n",
      "119/224, train_loss: 0.3561, step time: 0.3963\n",
      "120/224, train_loss: 0.4761, step time: 0.3807\n",
      "121/224, train_loss: 0.3802, step time: 0.3160\n",
      "122/224, train_loss: 0.4258, step time: 0.3721\n",
      "123/224, train_loss: 0.3429, step time: 0.3895\n",
      "124/224, train_loss: 0.3533, step time: 0.3166\n",
      "125/224, train_loss: 0.3631, step time: 0.4064\n",
      "126/224, train_loss: 0.3718, step time: 0.3178\n",
      "127/224, train_loss: 0.4573, step time: 0.4031\n",
      "128/224, train_loss: 0.4507, step time: 0.4101\n",
      "129/224, train_loss: 0.3707, step time: 0.3157\n",
      "130/224, train_loss: 0.3956, step time: 0.4139\n",
      "131/224, train_loss: 0.3595, step time: 0.3657\n",
      "132/224, train_loss: 0.4084, step time: 0.3152\n",
      "133/224, train_loss: 0.4305, step time: 0.3857\n",
      "134/224, train_loss: 0.4573, step time: 0.3174\n",
      "135/224, train_loss: 0.4069, step time: 0.3823\n",
      "136/224, train_loss: 0.3197, step time: 0.3789\n",
      "137/224, train_loss: 0.4380, step time: 0.3776\n",
      "138/224, train_loss: 0.3614, step time: 0.3175\n",
      "139/224, train_loss: 0.3797, step time: 0.4095\n",
      "140/224, train_loss: 0.3534, step time: 0.3155\n",
      "141/224, train_loss: 0.3633, step time: 0.3179\n",
      "142/224, train_loss: 0.3532, step time: 0.3156\n",
      "143/224, train_loss: 0.4933, step time: 0.3985\n",
      "144/224, train_loss: 0.3560, step time: 0.3177\n",
      "145/224, train_loss: 0.5135, step time: 0.4091\n",
      "146/224, train_loss: 0.3563, step time: 0.4090\n",
      "147/224, train_loss: 0.3793, step time: 0.3175\n",
      "148/224, train_loss: 0.3758, step time: 0.3178\n",
      "149/224, train_loss: 0.4209, step time: 0.4098\n",
      "150/224, train_loss: 0.3549, step time: 0.3750\n",
      "151/224, train_loss: 0.3678, step time: 0.3883\n",
      "152/224, train_loss: 0.3893, step time: 0.3848\n",
      "153/224, train_loss: 0.3496, step time: 0.3145\n",
      "154/224, train_loss: 0.4163, step time: 0.3140\n",
      "155/224, train_loss: 0.3562, step time: 0.3184\n",
      "156/224, train_loss: 0.3744, step time: 0.3157\n",
      "157/224, train_loss: 0.3440, step time: 0.3955\n",
      "158/224, train_loss: 0.4404, step time: 0.3145\n",
      "159/224, train_loss: 0.6000, step time: 0.3777\n",
      "160/224, train_loss: 0.4890, step time: 0.3155\n",
      "161/224, train_loss: 0.3645, step time: 0.3928\n",
      "162/224, train_loss: 0.3722, step time: 0.3729\n",
      "163/224, train_loss: 0.4035, step time: 0.3152\n",
      "164/224, train_loss: 0.3824, step time: 0.3701\n",
      "165/224, train_loss: 0.4299, step time: 0.3760\n",
      "166/224, train_loss: 0.3882, step time: 0.3197\n",
      "167/224, train_loss: 0.3888, step time: 0.3865\n",
      "168/224, train_loss: 0.3903, step time: 0.3154\n",
      "169/224, train_loss: 0.3762, step time: 0.3821\n",
      "170/224, train_loss: 0.4061, step time: 0.3745\n",
      "171/224, train_loss: 0.3864, step time: 0.3866\n",
      "172/224, train_loss: 0.3700, step time: 0.4196\n",
      "173/224, train_loss: 0.3865, step time: 0.3175\n",
      "174/224, train_loss: 0.2800, step time: 0.3175\n",
      "175/224, train_loss: 0.3462, step time: 0.3165\n",
      "176/224, train_loss: 0.3808, step time: 0.3174\n",
      "177/224, train_loss: 0.4250, step time: 0.3665\n",
      "178/224, train_loss: 0.3714, step time: 0.3176\n",
      "179/224, train_loss: 0.4060, step time: 0.4056\n",
      "180/224, train_loss: 0.3662, step time: 0.3199\n",
      "181/224, train_loss: 0.3715, step time: 0.3897\n",
      "182/224, train_loss: 0.3240, step time: 0.3701\n",
      "183/224, train_loss: 0.3962, step time: 0.3961\n",
      "184/224, train_loss: 0.3399, step time: 0.3195\n",
      "185/224, train_loss: 0.3968, step time: 0.3893\n",
      "186/224, train_loss: 0.3939, step time: 0.3150\n",
      "187/224, train_loss: 0.3741, step time: 0.3926\n",
      "188/224, train_loss: 0.3236, step time: 0.3165\n",
      "189/224, train_loss: 0.3640, step time: 0.3207\n",
      "190/224, train_loss: 0.3735, step time: 0.4002\n",
      "191/224, train_loss: 0.3400, step time: 0.3152\n",
      "192/224, train_loss: 0.3854, step time: 0.3744\n",
      "193/224, train_loss: 0.3603, step time: 0.3154\n",
      "194/224, train_loss: 0.3827, step time: 0.3172\n",
      "195/224, train_loss: 0.3750, step time: 0.3166\n",
      "196/224, train_loss: 0.3881, step time: 0.3702\n",
      "197/224, train_loss: 0.3599, step time: 0.3916\n",
      "198/224, train_loss: 0.3681, step time: 0.3846\n",
      "199/224, train_loss: 0.3673, step time: 0.3901\n",
      "200/224, train_loss: 0.3808, step time: 0.3796\n",
      "201/224, train_loss: 0.3931, step time: 0.3195\n",
      "202/224, train_loss: 0.3388, step time: 0.3194\n",
      "203/224, train_loss: 0.3483, step time: 0.3984\n",
      "204/224, train_loss: 0.3545, step time: 0.3174\n",
      "205/224, train_loss: 0.3792, step time: 0.3167\n",
      "206/224, train_loss: 0.4183, step time: 0.3165\n",
      "207/224, train_loss: 0.3440, step time: 0.3169\n",
      "208/224, train_loss: 0.3339, step time: 0.3179\n",
      "209/224, train_loss: 0.3866, step time: 0.3198\n",
      "210/224, train_loss: 0.4142, step time: 0.3779\n",
      "211/224, train_loss: 0.3320, step time: 0.3907\n",
      "212/224, train_loss: 0.3528, step time: 0.3150\n",
      "213/224, train_loss: 0.3353, step time: 0.3721\n",
      "214/224, train_loss: 0.4254, step time: 0.3167\n",
      "215/224, train_loss: 0.4549, step time: 0.4097\n",
      "216/224, train_loss: 0.3544, step time: 0.3145\n",
      "217/224, train_loss: 0.3853, step time: 0.3195\n",
      "218/224, train_loss: 0.3423, step time: 0.3149\n",
      "219/224, train_loss: 0.3253, step time: 0.3797\n",
      "220/224, train_loss: 0.4049, step time: 0.3188\n",
      "221/224, train_loss: 0.3671, step time: 0.3931\n",
      "222/224, train_loss: 0.3387, step time: 0.3156\n",
      "223/224, train_loss: 0.3699, step time: 0.3194\n",
      "224/224, train_loss: 0.3714, step time: 0.4037\n",
      "epoch 15 average loss: 0.3874\n",
      "current epoch: 15 current mean dice: 0.6129 class1: 0.9986 class2: 0.7221 class3: 0.1179\n",
      "best mean dice: 0.6129 at epoch: 15\n",
      "time consuming of epoch 15 is: 739.0334\n",
      "hello\n",
      "----------\n",
      "epoch 16/100\n",
      "1/224, train_loss: 0.3567, step time: 0.3763\n",
      "2/224, train_loss: 0.3935, step time: 0.3986\n",
      "3/224, train_loss: 0.3971, step time: 0.3175\n",
      "4/224, train_loss: 0.2953, step time: 0.4014\n",
      "5/224, train_loss: 0.3337, step time: 0.3732\n",
      "6/224, train_loss: 0.3574, step time: 0.3158\n",
      "7/224, train_loss: 0.4023, step time: 0.3938\n",
      "8/224, train_loss: 0.3833, step time: 0.3137\n",
      "9/224, train_loss: 0.3607, step time: 0.3166\n",
      "10/224, train_loss: 0.3693, step time: 0.3877\n",
      "11/224, train_loss: 0.3675, step time: 0.3177\n",
      "12/224, train_loss: 0.3879, step time: 0.3668\n",
      "13/224, train_loss: 0.4214, step time: 0.3731\n",
      "14/224, train_loss: 0.5565, step time: 0.3786\n",
      "15/224, train_loss: 0.3896, step time: 0.3982\n",
      "16/224, train_loss: 0.3739, step time: 0.3138\n",
      "17/224, train_loss: 0.3742, step time: 0.3933\n",
      "18/224, train_loss: 0.3419, step time: 0.3155\n",
      "19/224, train_loss: 0.3647, step time: 0.3158\n",
      "20/224, train_loss: 0.3618, step time: 0.3179\n",
      "21/224, train_loss: 0.4305, step time: 0.4117\n",
      "22/224, train_loss: 0.3517, step time: 0.3183\n",
      "23/224, train_loss: 0.3873, step time: 0.3987\n",
      "24/224, train_loss: 0.3872, step time: 0.3778\n",
      "25/224, train_loss: 0.3971, step time: 0.3865\n",
      "26/224, train_loss: 0.3973, step time: 0.3791\n",
      "27/224, train_loss: 0.3596, step time: 0.3865\n",
      "28/224, train_loss: 0.3945, step time: 0.3156\n",
      "29/224, train_loss: 0.3427, step time: 0.4028\n",
      "30/224, train_loss: 0.3121, step time: 0.3166\n",
      "31/224, train_loss: 0.3564, step time: 0.3163\n",
      "32/224, train_loss: 0.3780, step time: 0.3748\n",
      "33/224, train_loss: 0.3405, step time: 0.4108\n",
      "34/224, train_loss: 0.3596, step time: 0.3154\n",
      "35/224, train_loss: 0.4024, step time: 0.3151\n",
      "36/224, train_loss: 0.3728, step time: 0.3183\n",
      "37/224, train_loss: 0.3451, step time: 0.3919\n",
      "38/224, train_loss: 0.3612, step time: 0.3154\n",
      "39/224, train_loss: 0.3815, step time: 0.3153\n",
      "40/224, train_loss: 0.3985, step time: 0.3159\n",
      "41/224, train_loss: 0.3473, step time: 0.3181\n",
      "42/224, train_loss: 0.3635, step time: 0.4088\n",
      "43/224, train_loss: 0.3696, step time: 0.3932\n",
      "44/224, train_loss: 0.3652, step time: 0.3139\n",
      "45/224, train_loss: 0.3510, step time: 0.3910\n",
      "46/224, train_loss: 0.3783, step time: 0.3158\n",
      "47/224, train_loss: 0.3733, step time: 0.3911\n",
      "48/224, train_loss: 0.3395, step time: 0.3173\n",
      "49/224, train_loss: 0.3493, step time: 0.3172\n",
      "50/224, train_loss: 0.3610, step time: 0.3184\n",
      "51/224, train_loss: 0.3810, step time: 0.3184\n",
      "52/224, train_loss: 0.3884, step time: 0.4044\n",
      "53/224, train_loss: 0.3663, step time: 0.4125\n",
      "54/224, train_loss: 0.3496, step time: 0.3148\n",
      "55/224, train_loss: 0.3731, step time: 0.3824\n",
      "56/224, train_loss: 0.3714, step time: 0.3187\n",
      "57/224, train_loss: 0.3906, step time: 0.3185\n",
      "58/224, train_loss: 0.3506, step time: 0.3139\n",
      "59/224, train_loss: 0.3746, step time: 0.3163\n",
      "60/224, train_loss: 0.3304, step time: 0.3987\n",
      "61/224, train_loss: 0.3811, step time: 0.3184\n",
      "62/224, train_loss: 0.4034, step time: 0.3145\n",
      "63/224, train_loss: 0.3181, step time: 0.3165\n",
      "64/224, train_loss: 0.3175, step time: 0.3156\n",
      "65/224, train_loss: 0.3532, step time: 0.4082\n",
      "66/224, train_loss: 0.3217, step time: 0.4076\n",
      "67/224, train_loss: 0.3328, step time: 0.3181\n",
      "68/224, train_loss: 0.3727, step time: 0.3156\n",
      "69/224, train_loss: 0.4109, step time: 0.3796\n",
      "70/224, train_loss: 0.3784, step time: 0.3979\n",
      "71/224, train_loss: 0.3740, step time: 0.3165\n",
      "72/224, train_loss: 0.3692, step time: 0.3184\n",
      "73/224, train_loss: 0.3504, step time: 0.4042\n",
      "74/224, train_loss: 0.3868, step time: 0.3911\n",
      "75/224, train_loss: 0.3435, step time: 0.3960\n",
      "76/224, train_loss: 0.3353, step time: 0.3145\n",
      "77/224, train_loss: 0.3750, step time: 0.3919\n",
      "78/224, train_loss: 0.3681, step time: 0.3172\n",
      "79/224, train_loss: 0.3322, step time: 0.3806\n",
      "80/224, train_loss: 0.4028, step time: 0.4122\n",
      "81/224, train_loss: 0.4726, step time: 0.3931\n",
      "82/224, train_loss: 0.3908, step time: 0.3864\n",
      "83/224, train_loss: 0.3871, step time: 0.3165\n",
      "84/224, train_loss: 0.3758, step time: 0.3158\n",
      "85/224, train_loss: 0.3365, step time: 0.3907\n",
      "86/224, train_loss: 0.3361, step time: 0.3169\n",
      "87/224, train_loss: 0.3248, step time: 0.3775\n",
      "88/224, train_loss: 0.3974, step time: 0.3160\n",
      "89/224, train_loss: 0.2730, step time: 0.3158\n",
      "90/224, train_loss: 0.3454, step time: 0.3140\n",
      "91/224, train_loss: 0.3422, step time: 0.3725\n",
      "92/224, train_loss: 0.3460, step time: 0.3162\n",
      "93/224, train_loss: 0.3250, step time: 0.4083\n",
      "94/224, train_loss: 0.3192, step time: 0.3162\n",
      "95/224, train_loss: 0.3972, step time: 0.3144\n",
      "96/224, train_loss: 0.3556, step time: 0.4017\n",
      "97/224, train_loss: 0.3566, step time: 0.3988\n",
      "98/224, train_loss: 0.3910, step time: 0.3684\n",
      "99/224, train_loss: 0.3948, step time: 0.3145\n",
      "100/224, train_loss: 0.4691, step time: 0.3772\n",
      "101/224, train_loss: 0.2649, step time: 0.3159\n",
      "102/224, train_loss: 0.3647, step time: 0.3187\n",
      "103/224, train_loss: 0.3767, step time: 0.3860\n",
      "104/224, train_loss: 0.3426, step time: 0.3139\n",
      "105/224, train_loss: 0.4241, step time: 0.3179\n",
      "106/224, train_loss: 0.3499, step time: 0.3884\n",
      "107/224, train_loss: 0.3773, step time: 0.3167\n",
      "108/224, train_loss: 0.3686, step time: 0.3833\n",
      "109/224, train_loss: 0.3324, step time: 0.4102\n",
      "110/224, train_loss: 0.3780, step time: 0.3743\n",
      "111/224, train_loss: 0.3845, step time: 0.3180\n",
      "112/224, train_loss: 0.3372, step time: 0.3181\n",
      "113/224, train_loss: 0.4638, step time: 0.3720\n",
      "114/224, train_loss: 0.3628, step time: 0.3671\n",
      "115/224, train_loss: 0.3509, step time: 0.3741\n",
      "116/224, train_loss: 0.3825, step time: 0.3192\n",
      "117/224, train_loss: 0.3264, step time: 0.3146\n",
      "118/224, train_loss: 0.3708, step time: 0.3934\n",
      "119/224, train_loss: 0.3521, step time: 0.3164\n",
      "120/224, train_loss: 0.3611, step time: 0.3845\n",
      "121/224, train_loss: 0.4272, step time: 0.4087\n",
      "122/224, train_loss: 0.5198, step time: 0.3772\n",
      "123/224, train_loss: 0.3655, step time: 0.3179\n",
      "124/224, train_loss: 0.4116, step time: 0.4051\n",
      "125/224, train_loss: 0.3388, step time: 0.3140\n",
      "126/224, train_loss: 0.3409, step time: 0.3164\n",
      "127/224, train_loss: 0.3771, step time: 0.3178\n",
      "128/224, train_loss: 0.3366, step time: 0.3865\n",
      "129/224, train_loss: 0.4279, step time: 0.4046\n",
      "130/224, train_loss: 0.3309, step time: 0.3742\n",
      "131/224, train_loss: 0.3403, step time: 0.3146\n",
      "132/224, train_loss: 0.3469, step time: 0.3159\n",
      "133/224, train_loss: 0.3578, step time: 0.3187\n",
      "134/224, train_loss: 0.4088, step time: 0.3766\n",
      "135/224, train_loss: 0.3079, step time: 0.3984\n",
      "136/224, train_loss: 0.2971, step time: 0.3162\n",
      "137/224, train_loss: 0.3753, step time: 0.3863\n",
      "138/224, train_loss: 0.3871, step time: 0.4072\n",
      "139/224, train_loss: 0.3723, step time: 0.3753\n",
      "140/224, train_loss: 0.5166, step time: 0.3930\n",
      "141/224, train_loss: 0.3972, step time: 0.3169\n",
      "142/224, train_loss: 0.3922, step time: 0.3918\n",
      "143/224, train_loss: 0.3915, step time: 0.3659\n",
      "144/224, train_loss: 0.3012, step time: 0.3748\n",
      "145/224, train_loss: 0.3885, step time: 0.3787\n",
      "146/224, train_loss: 0.5813, step time: 0.4071\n",
      "147/224, train_loss: 0.3666, step time: 0.3126\n",
      "148/224, train_loss: 0.3436, step time: 0.3807\n",
      "149/224, train_loss: 0.3843, step time: 0.3148\n",
      "150/224, train_loss: 0.3784, step time: 0.3127\n",
      "151/224, train_loss: 0.3586, step time: 0.4085\n",
      "152/224, train_loss: 0.4482, step time: 0.3787\n",
      "153/224, train_loss: 0.3905, step time: 0.4086\n",
      "154/224, train_loss: 0.3138, step time: 0.3975\n",
      "155/224, train_loss: 0.3146, step time: 0.3998\n",
      "156/224, train_loss: 0.3564, step time: 0.3182\n",
      "157/224, train_loss: 0.3378, step time: 0.4116\n",
      "158/224, train_loss: 0.4629, step time: 0.4018\n",
      "159/224, train_loss: 0.2843, step time: 0.3188\n",
      "160/224, train_loss: 0.3199, step time: 0.3172\n",
      "161/224, train_loss: 0.2997, step time: 0.3191\n",
      "162/224, train_loss: 0.3363, step time: 0.4096\n",
      "163/224, train_loss: 0.3773, step time: 0.3174\n",
      "164/224, train_loss: 0.3088, step time: 0.3173\n",
      "165/224, train_loss: 0.2913, step time: 0.3991\n",
      "166/224, train_loss: 0.2773, step time: 0.3176\n",
      "167/224, train_loss: 0.4148, step time: 0.3942\n",
      "168/224, train_loss: 0.2864, step time: 0.3191\n",
      "169/224, train_loss: 0.4144, step time: 0.3152\n",
      "170/224, train_loss: 0.3810, step time: 0.3210\n",
      "171/224, train_loss: 0.3883, step time: 0.4055\n",
      "172/224, train_loss: 0.2879, step time: 0.3860\n",
      "173/224, train_loss: 0.3840, step time: 0.3173\n",
      "174/224, train_loss: 0.3372, step time: 0.4107\n",
      "175/224, train_loss: 0.3788, step time: 0.3921\n",
      "176/224, train_loss: 0.3826, step time: 0.3165\n",
      "177/224, train_loss: 0.3460, step time: 0.3147\n",
      "178/224, train_loss: 0.2966, step time: 0.3166\n",
      "179/224, train_loss: 0.3926, step time: 0.3172\n",
      "180/224, train_loss: 0.4773, step time: 0.3804\n",
      "181/224, train_loss: 0.3517, step time: 0.3901\n",
      "182/224, train_loss: 0.3376, step time: 0.3168\n",
      "183/224, train_loss: 0.3716, step time: 0.3200\n",
      "184/224, train_loss: 0.3795, step time: 0.3828\n",
      "185/224, train_loss: 0.3735, step time: 0.3864\n",
      "186/224, train_loss: 0.3080, step time: 0.3977\n",
      "187/224, train_loss: 0.3057, step time: 0.3156\n",
      "188/224, train_loss: 0.3067, step time: 0.3982\n",
      "189/224, train_loss: 0.3892, step time: 0.3172\n",
      "190/224, train_loss: 0.2646, step time: 0.3153\n",
      "191/224, train_loss: 0.3630, step time: 0.3179\n",
      "192/224, train_loss: 0.3491, step time: 0.3202\n",
      "193/224, train_loss: 0.3636, step time: 0.3174\n",
      "194/224, train_loss: 0.3612, step time: 0.3775\n",
      "195/224, train_loss: 0.3269, step time: 0.3173\n",
      "196/224, train_loss: 0.3380, step time: 0.3155\n",
      "197/224, train_loss: 0.3381, step time: 0.3926\n",
      "198/224, train_loss: 0.3508, step time: 0.3178\n",
      "199/224, train_loss: 0.2977, step time: 0.3787\n",
      "200/224, train_loss: 0.3400, step time: 0.3774\n",
      "201/224, train_loss: 0.3565, step time: 0.3211\n",
      "202/224, train_loss: 0.2515, step time: 0.3177\n",
      "203/224, train_loss: 0.3514, step time: 0.3176\n",
      "204/224, train_loss: 0.3267, step time: 0.3178\n",
      "205/224, train_loss: 0.3256, step time: 0.3187\n",
      "206/224, train_loss: 0.3625, step time: 0.4040\n",
      "207/224, train_loss: 0.3261, step time: 0.3157\n",
      "208/224, train_loss: 0.3311, step time: 0.3661\n",
      "209/224, train_loss: 0.4000, step time: 0.3155\n",
      "210/224, train_loss: 0.3571, step time: 0.3155\n",
      "211/224, train_loss: 0.2987, step time: 0.3157\n",
      "212/224, train_loss: 0.3269, step time: 0.3158\n",
      "213/224, train_loss: 0.2754, step time: 0.3706\n",
      "214/224, train_loss: 0.2465, step time: 0.3183\n",
      "215/224, train_loss: 0.2218, step time: 0.3163\n",
      "216/224, train_loss: 0.3775, step time: 0.3715\n",
      "217/224, train_loss: 0.3786, step time: 0.3755\n",
      "218/224, train_loss: 0.2567, step time: 0.3136\n",
      "219/224, train_loss: 0.3507, step time: 0.3183\n",
      "220/224, train_loss: 0.3127, step time: 0.3155\n",
      "221/224, train_loss: 0.3781, step time: 0.3824\n",
      "222/224, train_loss: 0.3559, step time: 0.3151\n",
      "223/224, train_loss: 0.3306, step time: 0.3191\n",
      "224/224, train_loss: 0.3945, step time: 0.3192\n",
      "epoch 16 average loss: 0.3617\n",
      "current epoch: 16 current mean dice: 0.6337 class1: 0.9987 class2: 0.7082 class3: 0.1942\n",
      "best mean dice: 0.6337 at epoch: 16\n",
      "time consuming of epoch 16 is: 713.7234\n",
      "hello\n",
      "----------\n",
      "epoch 17/100\n",
      "1/224, train_loss: 0.2776, step time: 0.3770\n",
      "2/224, train_loss: 0.3409, step time: 0.3147\n",
      "3/224, train_loss: 0.3615, step time: 0.3185\n",
      "4/224, train_loss: 0.3956, step time: 0.3841\n",
      "5/224, train_loss: 0.3132, step time: 0.3170\n",
      "6/224, train_loss: 0.2182, step time: 0.3163\n",
      "7/224, train_loss: 0.4467, step time: 0.3988\n",
      "8/224, train_loss: 0.3022, step time: 0.3938\n",
      "9/224, train_loss: 0.3956, step time: 0.3142\n",
      "10/224, train_loss: 0.3652, step time: 0.3183\n",
      "11/224, train_loss: 0.2949, step time: 0.3151\n",
      "12/224, train_loss: 0.2815, step time: 0.3184\n",
      "13/224, train_loss: 0.2997, step time: 0.4119\n",
      "14/224, train_loss: 0.3632, step time: 0.3131\n",
      "15/224, train_loss: 0.3243, step time: 0.3685\n",
      "16/224, train_loss: 0.3420, step time: 0.3180\n",
      "17/224, train_loss: 0.3805, step time: 0.3177\n",
      "18/224, train_loss: 0.2850, step time: 0.3900\n",
      "19/224, train_loss: 0.3935, step time: 0.3158\n",
      "20/224, train_loss: 0.3826, step time: 0.3833\n",
      "21/224, train_loss: 0.3441, step time: 0.3176\n",
      "22/224, train_loss: 0.4880, step time: 0.4040\n",
      "23/224, train_loss: 0.3915, step time: 0.3144\n",
      "24/224, train_loss: 0.3037, step time: 0.3754\n",
      "25/224, train_loss: 0.3102, step time: 0.3156\n",
      "26/224, train_loss: 0.3241, step time: 0.4056\n",
      "27/224, train_loss: 0.2816, step time: 0.3144\n",
      "28/224, train_loss: 0.3519, step time: 0.3192\n",
      "29/224, train_loss: 0.3531, step time: 0.3180\n",
      "30/224, train_loss: 0.3637, step time: 0.3162\n",
      "31/224, train_loss: 0.3116, step time: 0.3167\n",
      "32/224, train_loss: 0.4246, step time: 0.3755\n",
      "33/224, train_loss: 0.3750, step time: 0.3157\n",
      "34/224, train_loss: 0.3388, step time: 0.3805\n",
      "35/224, train_loss: 0.3195, step time: 0.3159\n",
      "36/224, train_loss: 0.2810, step time: 0.3959\n",
      "37/224, train_loss: 0.3358, step time: 0.4114\n",
      "38/224, train_loss: 0.3220, step time: 0.3895\n",
      "39/224, train_loss: 0.2841, step time: 0.3138\n",
      "40/224, train_loss: 0.3187, step time: 0.3136\n",
      "41/224, train_loss: 0.3207, step time: 0.3156\n",
      "42/224, train_loss: 0.3701, step time: 0.3186\n",
      "43/224, train_loss: 0.2908, step time: 0.3770\n",
      "44/224, train_loss: 0.3986, step time: 0.3768\n",
      "45/224, train_loss: 0.3758, step time: 0.3161\n",
      "46/224, train_loss: 0.4035, step time: 0.3712\n",
      "47/224, train_loss: 0.3479, step time: 0.3154\n",
      "48/224, train_loss: 0.3869, step time: 0.3777\n",
      "49/224, train_loss: 0.4848, step time: 0.3157\n",
      "50/224, train_loss: 0.2706, step time: 0.3735\n",
      "51/224, train_loss: 0.3170, step time: 0.3721\n",
      "52/224, train_loss: 0.3398, step time: 0.3157\n",
      "53/224, train_loss: 0.3159, step time: 0.3157\n",
      "54/224, train_loss: 0.3552, step time: 0.3161\n",
      "55/224, train_loss: 0.2402, step time: 0.3951\n",
      "56/224, train_loss: 0.4097, step time: 0.3155\n",
      "57/224, train_loss: 0.3778, step time: 0.3155\n",
      "58/224, train_loss: 0.2849, step time: 0.3153\n",
      "59/224, train_loss: 0.4416, step time: 0.3155\n",
      "60/224, train_loss: 0.3438, step time: 0.3178\n",
      "61/224, train_loss: 0.3647, step time: 0.3668\n",
      "62/224, train_loss: 0.3938, step time: 0.4146\n",
      "63/224, train_loss: 0.3662, step time: 0.3884\n",
      "64/224, train_loss: 0.4146, step time: 0.3800\n",
      "65/224, train_loss: 0.2535, step time: 0.3156\n",
      "66/224, train_loss: 0.2467, step time: 0.3747\n",
      "67/224, train_loss: 0.3114, step time: 0.3994\n",
      "68/224, train_loss: 0.3439, step time: 0.3853\n",
      "69/224, train_loss: 0.4132, step time: 0.3159\n",
      "70/224, train_loss: 0.4766, step time: 0.3699\n",
      "71/224, train_loss: 0.3620, step time: 0.3162\n",
      "72/224, train_loss: 0.3802, step time: 0.4037\n",
      "73/224, train_loss: 0.3124, step time: 0.3171\n",
      "74/224, train_loss: 0.4219, step time: 0.3841\n",
      "75/224, train_loss: 0.3222, step time: 0.3806\n",
      "76/224, train_loss: 0.3260, step time: 0.4069\n",
      "77/224, train_loss: 0.3538, step time: 0.3188\n",
      "78/224, train_loss: 0.3589, step time: 0.3173\n",
      "79/224, train_loss: 0.2655, step time: 0.3170\n",
      "80/224, train_loss: 0.2624, step time: 0.3166\n",
      "81/224, train_loss: 0.2755, step time: 0.3195\n",
      "82/224, train_loss: 0.3322, step time: 0.3938\n",
      "83/224, train_loss: 0.2834, step time: 0.3169\n",
      "84/224, train_loss: 0.2217, step time: 0.3148\n",
      "85/224, train_loss: 0.3014, step time: 0.4147\n",
      "86/224, train_loss: 0.3757, step time: 0.3203\n",
      "87/224, train_loss: 0.3640, step time: 0.3930\n",
      "88/224, train_loss: 0.5107, step time: 0.3192\n",
      "89/224, train_loss: 0.3959, step time: 0.3873\n",
      "90/224, train_loss: 0.3675, step time: 0.4009\n",
      "91/224, train_loss: 0.3427, step time: 0.3186\n",
      "92/224, train_loss: 0.3359, step time: 0.3803\n",
      "93/224, train_loss: 0.3040, step time: 0.3909\n",
      "94/224, train_loss: 0.2718, step time: 0.3722\n",
      "95/224, train_loss: 0.2682, step time: 0.3204\n",
      "96/224, train_loss: 0.2374, step time: 0.3841\n",
      "97/224, train_loss: 0.2242, step time: 0.3172\n",
      "98/224, train_loss: 0.2568, step time: 0.3178\n",
      "99/224, train_loss: 0.5028, step time: 0.3709\n",
      "100/224, train_loss: 0.3178, step time: 0.3759\n",
      "101/224, train_loss: 0.3448, step time: 0.3847\n",
      "102/224, train_loss: 0.3431, step time: 0.3889\n",
      "103/224, train_loss: 0.3443, step time: 0.3175\n",
      "104/224, train_loss: 0.4015, step time: 0.3176\n",
      "105/224, train_loss: 0.2876, step time: 0.3185\n",
      "106/224, train_loss: 0.4032, step time: 0.3201\n",
      "107/224, train_loss: 0.2744, step time: 0.3985\n",
      "108/224, train_loss: 0.4294, step time: 0.3916\n",
      "109/224, train_loss: 0.2596, step time: 0.3193\n",
      "110/224, train_loss: 0.3259, step time: 0.3173\n",
      "111/224, train_loss: 0.3835, step time: 0.3195\n",
      "112/224, train_loss: 0.2893, step time: 0.3165\n",
      "113/224, train_loss: 0.3722, step time: 0.3167\n",
      "114/224, train_loss: 0.4030, step time: 0.3165\n",
      "115/224, train_loss: 0.2811, step time: 0.3154\n",
      "116/224, train_loss: 0.2468, step time: 0.3179\n",
      "117/224, train_loss: 0.2954, step time: 0.4094\n",
      "118/224, train_loss: 0.2858, step time: 0.4122\n",
      "119/224, train_loss: 0.4288, step time: 0.3164\n",
      "120/224, train_loss: 0.3019, step time: 0.3881\n",
      "121/224, train_loss: 0.3026, step time: 0.3903\n",
      "122/224, train_loss: 0.5045, step time: 0.3894\n",
      "123/224, train_loss: 0.4268, step time: 0.3158\n",
      "124/224, train_loss: 0.3419, step time: 0.3175\n",
      "125/224, train_loss: 0.2776, step time: 0.3174\n",
      "126/224, train_loss: 0.3488, step time: 0.3170\n",
      "127/224, train_loss: 0.3148, step time: 0.3207\n",
      "128/224, train_loss: 0.3731, step time: 0.3177\n",
      "129/224, train_loss: 0.2771, step time: 0.3185\n",
      "130/224, train_loss: 0.3146, step time: 0.3174\n",
      "131/224, train_loss: 0.3466, step time: 0.3195\n",
      "132/224, train_loss: 0.2224, step time: 0.3186\n",
      "133/224, train_loss: 0.3177, step time: 0.3724\n",
      "134/224, train_loss: 0.3400, step time: 0.3214\n",
      "135/224, train_loss: 0.3694, step time: 0.3204\n",
      "136/224, train_loss: 0.3651, step time: 0.3174\n",
      "137/224, train_loss: 0.3349, step time: 0.3788\n",
      "138/224, train_loss: 0.3967, step time: 0.3167\n",
      "139/224, train_loss: 0.4022, step time: 0.4105\n",
      "140/224, train_loss: 0.4171, step time: 0.3207\n",
      "141/224, train_loss: 0.3679, step time: 0.3204\n",
      "142/224, train_loss: 0.2964, step time: 0.3177\n",
      "143/224, train_loss: 0.3082, step time: 0.3805\n",
      "144/224, train_loss: 0.3716, step time: 0.3182\n",
      "145/224, train_loss: 0.4323, step time: 0.4044\n",
      "146/224, train_loss: 0.6063, step time: 0.3941\n",
      "147/224, train_loss: 0.3009, step time: 0.3919\n",
      "148/224, train_loss: 0.3092, step time: 0.4070\n",
      "149/224, train_loss: 0.3073, step time: 0.4063\n",
      "150/224, train_loss: 0.2778, step time: 0.3139\n",
      "151/224, train_loss: 0.4652, step time: 0.4036\n",
      "152/224, train_loss: 0.3084, step time: 0.3159\n",
      "153/224, train_loss: 0.4010, step time: 0.4139\n",
      "154/224, train_loss: 0.2887, step time: 0.3186\n",
      "155/224, train_loss: 0.3786, step time: 0.3932\n",
      "156/224, train_loss: 0.2899, step time: 0.3192\n",
      "157/224, train_loss: 0.3104, step time: 0.3144\n",
      "158/224, train_loss: 0.3696, step time: 0.3956\n",
      "159/224, train_loss: 0.3393, step time: 0.3794\n",
      "160/224, train_loss: 0.4805, step time: 0.3163\n",
      "161/224, train_loss: 0.3757, step time: 0.3189\n",
      "162/224, train_loss: 0.2410, step time: 0.3168\n",
      "163/224, train_loss: 0.2394, step time: 0.3142\n",
      "164/224, train_loss: 0.2676, step time: 0.3169\n",
      "165/224, train_loss: 0.3760, step time: 0.3194\n",
      "166/224, train_loss: 0.3813, step time: 0.4082\n",
      "167/224, train_loss: 0.3596, step time: 0.3193\n",
      "168/224, train_loss: 0.3722, step time: 0.3968\n",
      "169/224, train_loss: 0.3576, step time: 0.3802\n",
      "170/224, train_loss: 0.2930, step time: 0.3828\n",
      "171/224, train_loss: 0.3888, step time: 0.3891\n",
      "172/224, train_loss: 0.3995, step time: 0.3728\n",
      "173/224, train_loss: 0.2517, step time: 0.3166\n",
      "174/224, train_loss: 0.4326, step time: 0.3160\n",
      "175/224, train_loss: 0.2517, step time: 0.3667\n",
      "176/224, train_loss: 0.4001, step time: 0.3161\n",
      "177/224, train_loss: 0.2669, step time: 0.3156\n",
      "178/224, train_loss: 0.4932, step time: 0.3959\n",
      "179/224, train_loss: 0.3252, step time: 0.3705\n",
      "180/224, train_loss: 0.3632, step time: 0.3163\n",
      "181/224, train_loss: 0.3291, step time: 0.3162\n",
      "182/224, train_loss: 0.4153, step time: 0.3174\n",
      "183/224, train_loss: 0.3381, step time: 0.3165\n",
      "184/224, train_loss: 0.3453, step time: 0.3190\n",
      "185/224, train_loss: 0.3424, step time: 0.3892\n",
      "186/224, train_loss: 0.3721, step time: 0.3156\n",
      "187/224, train_loss: 0.3583, step time: 0.3656\n",
      "188/224, train_loss: 0.2659, step time: 0.3956\n",
      "189/224, train_loss: 0.3655, step time: 0.3125\n",
      "190/224, train_loss: 0.3348, step time: 0.4095\n",
      "191/224, train_loss: 0.3680, step time: 0.4011\n",
      "192/224, train_loss: 0.2623, step time: 0.3136\n",
      "193/224, train_loss: 0.3616, step time: 0.3671\n",
      "194/224, train_loss: 0.3538, step time: 0.3955\n",
      "195/224, train_loss: 0.4012, step time: 0.4007\n",
      "196/224, train_loss: 0.3802, step time: 0.3790\n",
      "197/224, train_loss: 0.2651, step time: 0.3174\n",
      "198/224, train_loss: 0.4103, step time: 0.3982\n",
      "199/224, train_loss: 0.3269, step time: 0.3190\n",
      "200/224, train_loss: 0.2742, step time: 0.3161\n",
      "201/224, train_loss: 0.2569, step time: 0.3157\n",
      "202/224, train_loss: 0.1794, step time: 0.4061\n",
      "203/224, train_loss: 0.3841, step time: 0.3730\n",
      "204/224, train_loss: 0.3734, step time: 0.3203\n",
      "205/224, train_loss: 0.3626, step time: 0.3163\n",
      "206/224, train_loss: 0.3589, step time: 0.3781\n",
      "207/224, train_loss: 0.2456, step time: 0.3153\n",
      "208/224, train_loss: 0.4003, step time: 0.3145\n",
      "209/224, train_loss: 0.3586, step time: 0.3145\n",
      "210/224, train_loss: 0.3385, step time: 0.3961\n",
      "211/224, train_loss: 0.3799, step time: 0.3735\n",
      "212/224, train_loss: 0.4516, step time: 0.3979\n",
      "213/224, train_loss: 0.3665, step time: 0.3998\n",
      "214/224, train_loss: 0.3387, step time: 0.3180\n",
      "215/224, train_loss: 0.3191, step time: 0.3169\n",
      "216/224, train_loss: 0.3355, step time: 0.3752\n",
      "217/224, train_loss: 0.2494, step time: 0.4070\n",
      "218/224, train_loss: 0.2839, step time: 0.3188\n",
      "219/224, train_loss: 0.2264, step time: 0.4023\n",
      "220/224, train_loss: 0.4453, step time: 0.3190\n",
      "221/224, train_loss: 0.4148, step time: 0.3717\n",
      "222/224, train_loss: 0.3155, step time: 0.3816\n",
      "223/224, train_loss: 0.3820, step time: 0.3178\n",
      "224/224, train_loss: 0.4564, step time: 0.3949\n",
      "epoch 17 average loss: 0.3435\n",
      "current epoch: 17 current mean dice: 0.6493 class1: 0.9986 class2: 0.7022 class3: 0.2470\n",
      "best mean dice: 0.6493 at epoch: 17\n",
      "time consuming of epoch 17 is: 702.4169\n",
      "hello\n",
      "----------\n",
      "epoch 18/100\n",
      "1/224, train_loss: 0.2747, step time: 0.3196\n",
      "2/224, train_loss: 0.2217, step time: 0.3166\n",
      "3/224, train_loss: 0.3494, step time: 0.3175\n",
      "4/224, train_loss: 0.2668, step time: 0.3176\n",
      "5/224, train_loss: 0.2604, step time: 0.3177\n",
      "6/224, train_loss: 0.3474, step time: 0.3190\n",
      "7/224, train_loss: 0.3664, step time: 0.3149\n",
      "8/224, train_loss: 0.4016, step time: 0.3176\n",
      "9/224, train_loss: 0.3279, step time: 0.3987\n",
      "10/224, train_loss: 0.2998, step time: 0.3939\n",
      "11/224, train_loss: 0.2089, step time: 0.3198\n",
      "12/224, train_loss: 0.2354, step time: 0.3995\n",
      "13/224, train_loss: 0.2826, step time: 0.3167\n",
      "14/224, train_loss: 0.4313, step time: 0.3190\n",
      "15/224, train_loss: 0.5009, step time: 0.3175\n",
      "16/224, train_loss: 0.3715, step time: 0.4048\n",
      "17/224, train_loss: 0.3648, step time: 0.4025\n",
      "18/224, train_loss: 0.2885, step time: 0.3173\n",
      "19/224, train_loss: 0.3243, step time: 0.3167\n",
      "20/224, train_loss: 0.2804, step time: 0.3195\n",
      "21/224, train_loss: 0.3649, step time: 0.3870\n",
      "22/224, train_loss: 0.2717, step time: 0.3166\n",
      "23/224, train_loss: 0.5242, step time: 0.3165\n",
      "24/224, train_loss: 0.3496, step time: 0.3186\n",
      "25/224, train_loss: 0.3754, step time: 0.3824\n",
      "26/224, train_loss: 0.2053, step time: 0.3758\n",
      "27/224, train_loss: 0.2981, step time: 0.3897\n",
      "28/224, train_loss: 0.3726, step time: 0.4006\n",
      "29/224, train_loss: 0.3868, step time: 0.3166\n",
      "30/224, train_loss: 0.3649, step time: 0.3173\n",
      "31/224, train_loss: 0.3263, step time: 0.3915\n",
      "32/224, train_loss: 0.4832, step time: 0.3768\n",
      "33/224, train_loss: 0.2717, step time: 0.3181\n",
      "34/224, train_loss: 0.2367, step time: 0.3197\n",
      "35/224, train_loss: 0.3684, step time: 0.4029\n",
      "36/224, train_loss: 0.3963, step time: 0.4069\n",
      "37/224, train_loss: 0.4039, step time: 0.3776\n",
      "38/224, train_loss: 0.2971, step time: 0.3195\n",
      "39/224, train_loss: 0.3787, step time: 0.4049\n",
      "40/224, train_loss: 0.4239, step time: 0.3194\n",
      "41/224, train_loss: 0.2829, step time: 0.3907\n",
      "42/224, train_loss: 0.3729, step time: 0.4040\n",
      "43/224, train_loss: 0.2039, step time: 0.3176\n",
      "44/224, train_loss: 0.3816, step time: 0.4133\n",
      "45/224, train_loss: 0.4266, step time: 0.3768\n",
      "46/224, train_loss: 0.4169, step time: 0.4080\n",
      "47/224, train_loss: 0.3573, step time: 0.3172\n",
      "48/224, train_loss: 0.2234, step time: 0.3187\n",
      "49/224, train_loss: 0.3758, step time: 0.3188\n",
      "50/224, train_loss: 0.4564, step time: 0.3187\n",
      "51/224, train_loss: 0.4488, step time: 0.3681\n",
      "52/224, train_loss: 0.2589, step time: 0.3162\n",
      "53/224, train_loss: 0.3586, step time: 0.3794\n",
      "54/224, train_loss: 0.2600, step time: 0.3158\n",
      "55/224, train_loss: 0.3399, step time: 0.3672\n",
      "56/224, train_loss: 0.3436, step time: 0.4011\n",
      "57/224, train_loss: 0.3171, step time: 0.4018\n",
      "58/224, train_loss: 0.2726, step time: 0.3737\n",
      "59/224, train_loss: 0.4407, step time: 0.3182\n",
      "60/224, train_loss: 0.3611, step time: 0.4067\n",
      "61/224, train_loss: 0.4059, step time: 0.3194\n",
      "62/224, train_loss: 0.3827, step time: 0.4023\n",
      "63/224, train_loss: 0.3476, step time: 0.3145\n",
      "64/224, train_loss: 0.3007, step time: 0.3193\n",
      "65/224, train_loss: 0.2369, step time: 0.3793\n",
      "66/224, train_loss: 0.3702, step time: 0.3182\n",
      "67/224, train_loss: 0.2158, step time: 0.4072\n",
      "68/224, train_loss: 0.4063, step time: 0.3150\n",
      "69/224, train_loss: 0.2754, step time: 0.3924\n",
      "70/224, train_loss: 0.3848, step time: 0.3828\n",
      "71/224, train_loss: 0.3619, step time: 0.4126\n",
      "72/224, train_loss: 0.4353, step time: 0.3989\n",
      "73/224, train_loss: 0.2876, step time: 0.3165\n",
      "74/224, train_loss: 0.2971, step time: 0.3977\n",
      "75/224, train_loss: 0.2493, step time: 0.3168\n",
      "76/224, train_loss: 0.3283, step time: 0.3191\n",
      "77/224, train_loss: 0.3561, step time: 0.3715\n",
      "78/224, train_loss: 0.3727, step time: 0.3165\n",
      "79/224, train_loss: 0.4075, step time: 0.3727\n",
      "80/224, train_loss: 0.2631, step time: 0.3161\n",
      "81/224, train_loss: 0.4015, step time: 0.3197\n",
      "82/224, train_loss: 0.2318, step time: 0.3167\n",
      "83/224, train_loss: 0.3380, step time: 0.3169\n",
      "84/224, train_loss: 0.2059, step time: 0.4151\n",
      "85/224, train_loss: 0.2865, step time: 0.4034\n",
      "86/224, train_loss: 0.3594, step time: 0.3839\n",
      "87/224, train_loss: 0.2429, step time: 0.3155\n",
      "88/224, train_loss: 0.3010, step time: 0.3179\n",
      "89/224, train_loss: 0.3306, step time: 0.3134\n",
      "90/224, train_loss: 0.2789, step time: 0.3156\n",
      "91/224, train_loss: 0.3204, step time: 0.4057\n",
      "92/224, train_loss: 0.2475, step time: 0.3176\n",
      "93/224, train_loss: 0.2742, step time: 0.3804\n",
      "94/224, train_loss: 0.3567, step time: 0.4003\n",
      "95/224, train_loss: 0.3786, step time: 0.3957\n",
      "96/224, train_loss: 0.4004, step time: 0.3849\n",
      "97/224, train_loss: 0.2163, step time: 0.3988\n",
      "98/224, train_loss: 0.3595, step time: 0.3805\n",
      "99/224, train_loss: 0.3422, step time: 0.3823\n",
      "100/224, train_loss: 0.3020, step time: 0.4063\n",
      "101/224, train_loss: 0.2729, step time: 0.3882\n",
      "102/224, train_loss: 0.2966, step time: 0.3762\n",
      "103/224, train_loss: 0.3827, step time: 0.3783\n",
      "104/224, train_loss: 0.2761, step time: 0.3689\n",
      "105/224, train_loss: 0.2592, step time: 0.3203\n",
      "106/224, train_loss: 0.3595, step time: 0.3164\n",
      "107/224, train_loss: 0.3338, step time: 0.3771\n",
      "108/224, train_loss: 0.2851, step time: 0.3170\n",
      "109/224, train_loss: 0.2851, step time: 0.3937\n",
      "110/224, train_loss: 0.2177, step time: 0.3161\n",
      "111/224, train_loss: 0.2450, step time: 0.3748\n",
      "112/224, train_loss: 0.3543, step time: 0.4118\n",
      "113/224, train_loss: 0.3200, step time: 0.3196\n",
      "114/224, train_loss: 0.1944, step time: 0.3171\n",
      "115/224, train_loss: 0.2096, step time: 0.3195\n",
      "116/224, train_loss: 0.2814, step time: 0.4116\n",
      "117/224, train_loss: 0.3318, step time: 0.3202\n",
      "118/224, train_loss: 0.2837, step time: 0.3982\n",
      "119/224, train_loss: 0.3633, step time: 0.3157\n",
      "120/224, train_loss: 0.2724, step time: 0.3161\n",
      "121/224, train_loss: 0.4370, step time: 0.3166\n",
      "122/224, train_loss: 0.3769, step time: 0.3144\n",
      "123/224, train_loss: 0.3785, step time: 0.3868\n",
      "124/224, train_loss: 0.3756, step time: 0.3794\n",
      "125/224, train_loss: 0.2070, step time: 0.3134\n",
      "126/224, train_loss: 0.3549, step time: 0.4066\n",
      "127/224, train_loss: 0.2469, step time: 0.3208\n",
      "128/224, train_loss: 0.2924, step time: 0.3823\n",
      "129/224, train_loss: 0.2758, step time: 0.3149\n",
      "130/224, train_loss: 0.2437, step time: 0.3162\n",
      "131/224, train_loss: 0.3061, step time: 0.3863\n",
      "132/224, train_loss: 0.3150, step time: 0.3744\n",
      "133/224, train_loss: 0.3164, step time: 0.3161\n",
      "134/224, train_loss: 0.2542, step time: 0.3144\n",
      "135/224, train_loss: 0.3657, step time: 0.3158\n",
      "136/224, train_loss: 0.2313, step time: 0.3145\n",
      "137/224, train_loss: 0.2823, step time: 0.3164\n",
      "138/224, train_loss: 0.2018, step time: 0.3967\n",
      "139/224, train_loss: 0.2321, step time: 0.3671\n",
      "140/224, train_loss: 0.2646, step time: 0.3163\n",
      "141/224, train_loss: 0.3046, step time: 0.3176\n",
      "142/224, train_loss: 0.2789, step time: 0.3990\n",
      "143/224, train_loss: 0.2223, step time: 0.4149\n",
      "144/224, train_loss: 0.3860, step time: 0.3187\n",
      "145/224, train_loss: 0.3347, step time: 0.3175\n",
      "146/224, train_loss: 0.3001, step time: 0.3173\n",
      "147/224, train_loss: 0.2163, step time: 0.3148\n",
      "148/224, train_loss: 0.3391, step time: 0.3195\n",
      "149/224, train_loss: 0.3413, step time: 0.3140\n",
      "150/224, train_loss: 0.5338, step time: 0.3653\n",
      "151/224, train_loss: 0.2523, step time: 0.3180\n",
      "152/224, train_loss: 0.2842, step time: 0.4032\n",
      "153/224, train_loss: 0.3258, step time: 0.3153\n",
      "154/224, train_loss: 0.3849, step time: 0.4075\n",
      "155/224, train_loss: 0.3872, step time: 0.3199\n",
      "156/224, train_loss: 0.2227, step time: 0.3685\n",
      "157/224, train_loss: 0.2290, step time: 0.3147\n",
      "158/224, train_loss: 0.3474, step time: 0.3170\n",
      "159/224, train_loss: 0.3791, step time: 0.3169\n",
      "160/224, train_loss: 0.3299, step time: 0.3199\n",
      "161/224, train_loss: 0.2807, step time: 0.3198\n",
      "162/224, train_loss: 0.2093, step time: 0.3205\n",
      "163/224, train_loss: 0.2715, step time: 0.3182\n",
      "164/224, train_loss: 0.2820, step time: 0.3183\n",
      "165/224, train_loss: 0.3431, step time: 0.3174\n",
      "166/224, train_loss: 0.2014, step time: 0.3187\n",
      "167/224, train_loss: 0.2561, step time: 0.3733\n",
      "168/224, train_loss: 0.3943, step time: 0.3989\n",
      "169/224, train_loss: 0.3578, step time: 0.3166\n",
      "170/224, train_loss: 0.3135, step time: 0.3168\n",
      "171/224, train_loss: 0.2404, step time: 0.3188\n",
      "172/224, train_loss: 0.3963, step time: 0.4050\n",
      "173/224, train_loss: 0.2389, step time: 0.3189\n",
      "174/224, train_loss: 0.2862, step time: 0.3170\n",
      "175/224, train_loss: 0.3094, step time: 0.4115\n",
      "176/224, train_loss: 0.2250, step time: 0.4074\n",
      "177/224, train_loss: 0.3769, step time: 0.3190\n",
      "178/224, train_loss: 0.3904, step time: 0.3195\n",
      "179/224, train_loss: 0.4024, step time: 0.3870\n",
      "180/224, train_loss: 0.3638, step time: 0.4021\n",
      "181/224, train_loss: 0.3434, step time: 0.3148\n",
      "182/224, train_loss: 0.3242, step time: 0.3151\n",
      "183/224, train_loss: 0.2860, step time: 0.4100\n",
      "184/224, train_loss: 0.3822, step time: 0.3164\n",
      "185/224, train_loss: 0.4071, step time: 0.3801\n",
      "186/224, train_loss: 0.2953, step time: 0.3178\n",
      "187/224, train_loss: 0.1815, step time: 0.3185\n",
      "188/224, train_loss: 0.2413, step time: 0.4035\n",
      "189/224, train_loss: 0.3073, step time: 0.3152\n",
      "190/224, train_loss: 0.2409, step time: 0.3159\n",
      "191/224, train_loss: 0.3037, step time: 0.3183\n",
      "192/224, train_loss: 0.3617, step time: 0.3158\n",
      "193/224, train_loss: 0.3148, step time: 0.3153\n",
      "194/224, train_loss: 0.4153, step time: 0.3857\n",
      "195/224, train_loss: 0.2200, step time: 0.3156\n",
      "196/224, train_loss: 0.2103, step time: 0.3164\n",
      "197/224, train_loss: 0.3597, step time: 0.3732\n",
      "198/224, train_loss: 0.3228, step time: 0.3989\n",
      "199/224, train_loss: 0.2313, step time: 0.3921\n",
      "200/224, train_loss: 0.2795, step time: 0.3158\n",
      "201/224, train_loss: 0.3719, step time: 0.3155\n",
      "202/224, train_loss: 0.2693, step time: 0.4184\n",
      "203/224, train_loss: 0.2380, step time: 0.3187\n",
      "204/224, train_loss: 0.3073, step time: 0.3899\n",
      "205/224, train_loss: 0.3439, step time: 0.3157\n",
      "206/224, train_loss: 0.2337, step time: 0.3156\n",
      "207/224, train_loss: 0.2859, step time: 0.3153\n",
      "208/224, train_loss: 0.4065, step time: 0.4117\n",
      "209/224, train_loss: 0.2091, step time: 0.3802\n",
      "210/224, train_loss: 0.2589, step time: 0.4043\n",
      "211/224, train_loss: 0.3688, step time: 0.3769\n",
      "212/224, train_loss: 0.3786, step time: 0.3799\n",
      "213/224, train_loss: 0.2123, step time: 0.3192\n",
      "214/224, train_loss: 0.3571, step time: 0.3220\n",
      "215/224, train_loss: 0.2306, step time: 0.3207\n",
      "216/224, train_loss: 0.3834, step time: 0.4029\n",
      "217/224, train_loss: 0.1960, step time: 0.3164\n",
      "218/224, train_loss: 0.3363, step time: 0.3770\n",
      "219/224, train_loss: 0.2598, step time: 0.3196\n",
      "220/224, train_loss: 0.2371, step time: 0.3175\n",
      "221/224, train_loss: 0.4771, step time: 0.3176\n",
      "222/224, train_loss: 0.3994, step time: 0.3725\n",
      "223/224, train_loss: 0.1859, step time: 0.3681\n",
      "224/224, train_loss: 0.3369, step time: 0.3168\n",
      "epoch 18 average loss: 0.3165\n",
      "current epoch: 18 current mean dice: 0.6475 class1: 0.9985 class2: 0.6953 class3: 0.2487\n",
      "best mean dice: 0.6493 at epoch: 17\n",
      "time consuming of epoch 18 is: 659.9481\n",
      "hello\n",
      "----------\n",
      "epoch 19/100\n",
      "1/224, train_loss: 0.3640, step time: 0.4136\n",
      "2/224, train_loss: 0.3027, step time: 0.3901\n",
      "3/224, train_loss: 0.3107, step time: 0.3176\n",
      "4/224, train_loss: 0.2799, step time: 0.3167\n",
      "5/224, train_loss: 0.3238, step time: 0.3171\n",
      "6/224, train_loss: 0.2590, step time: 0.3849\n",
      "7/224, train_loss: 0.2284, step time: 0.3773\n",
      "8/224, train_loss: 0.4047, step time: 0.3843\n",
      "9/224, train_loss: 0.4637, step time: 0.3169\n",
      "10/224, train_loss: 0.3873, step time: 0.3166\n",
      "11/224, train_loss: 0.2592, step time: 0.3888\n",
      "12/224, train_loss: 0.2668, step time: 0.3738\n",
      "13/224, train_loss: 0.2473, step time: 0.4065\n",
      "14/224, train_loss: 0.4916, step time: 0.3143\n",
      "15/224, train_loss: 0.4027, step time: 0.4023\n",
      "16/224, train_loss: 0.1810, step time: 0.3188\n",
      "17/224, train_loss: 0.4517, step time: 0.3742\n",
      "18/224, train_loss: 0.3487, step time: 0.3161\n",
      "19/224, train_loss: 0.3748, step time: 0.4006\n",
      "20/224, train_loss: 0.1955, step time: 0.3168\n",
      "21/224, train_loss: 0.4445, step time: 0.3146\n",
      "22/224, train_loss: 0.1750, step time: 0.3197\n",
      "23/224, train_loss: 0.2576, step time: 0.3176\n",
      "24/224, train_loss: 0.3239, step time: 0.3742\n",
      "25/224, train_loss: 0.3207, step time: 0.3164\n",
      "26/224, train_loss: 0.1862, step time: 0.3192\n",
      "27/224, train_loss: 0.3466, step time: 0.3176\n",
      "28/224, train_loss: 0.2627, step time: 0.3195\n",
      "29/224, train_loss: 0.3885, step time: 0.3741\n",
      "30/224, train_loss: 0.2040, step time: 0.3171\n",
      "31/224, train_loss: 0.2886, step time: 0.4024\n",
      "32/224, train_loss: 0.1840, step time: 0.3168\n",
      "33/224, train_loss: 0.2226, step time: 0.3153\n",
      "34/224, train_loss: 0.3687, step time: 0.3808\n",
      "35/224, train_loss: 0.4401, step time: 0.4092\n",
      "36/224, train_loss: 0.2991, step time: 0.3933\n",
      "37/224, train_loss: 0.2036, step time: 0.3190\n",
      "38/224, train_loss: 0.3980, step time: 0.4110\n",
      "39/224, train_loss: 0.2307, step time: 0.3173\n",
      "40/224, train_loss: 0.3311, step time: 0.3816\n",
      "41/224, train_loss: 0.1972, step time: 0.3148\n",
      "42/224, train_loss: 0.2463, step time: 0.3702\n",
      "43/224, train_loss: 0.3840, step time: 0.3875\n",
      "44/224, train_loss: 0.3726, step time: 0.3150\n",
      "45/224, train_loss: 0.3867, step time: 0.4073\n",
      "46/224, train_loss: 0.3684, step time: 0.4019\n",
      "47/224, train_loss: 0.3934, step time: 0.3197\n",
      "48/224, train_loss: 0.2819, step time: 0.3183\n",
      "49/224, train_loss: 0.2989, step time: 0.3791\n",
      "50/224, train_loss: 0.2131, step time: 0.3175\n",
      "51/224, train_loss: 0.3607, step time: 0.3173\n",
      "52/224, train_loss: 0.2134, step time: 0.3899\n",
      "53/224, train_loss: 0.3256, step time: 0.3167\n",
      "54/224, train_loss: 0.2600, step time: 0.3967\n",
      "55/224, train_loss: 0.2218, step time: 0.3181\n",
      "56/224, train_loss: 0.4549, step time: 0.3715\n",
      "57/224, train_loss: 0.3639, step time: 0.3165\n",
      "58/224, train_loss: 0.3533, step time: 0.3188\n",
      "59/224, train_loss: 0.3137, step time: 0.3714\n",
      "60/224, train_loss: 0.3686, step time: 0.3164\n",
      "61/224, train_loss: 0.1619, step time: 0.3160\n",
      "62/224, train_loss: 0.1884, step time: 0.3189\n",
      "63/224, train_loss: 0.1564, step time: 0.3893\n",
      "64/224, train_loss: 0.4522, step time: 0.3816\n",
      "65/224, train_loss: 0.3532, step time: 0.3904\n",
      "66/224, train_loss: 0.2125, step time: 0.3190\n",
      "67/224, train_loss: 0.3045, step time: 0.4120\n",
      "68/224, train_loss: 0.3732, step time: 0.4004\n",
      "69/224, train_loss: 0.2718, step time: 0.3882\n",
      "70/224, train_loss: 0.3294, step time: 0.3172\n",
      "71/224, train_loss: 0.2561, step time: 0.3171\n",
      "72/224, train_loss: 0.3633, step time: 0.3768\n",
      "73/224, train_loss: 0.1879, step time: 0.3160\n",
      "74/224, train_loss: 0.3308, step time: 0.3979\n",
      "75/224, train_loss: 0.4445, step time: 0.3158\n",
      "76/224, train_loss: 0.1882, step time: 0.3993\n",
      "77/224, train_loss: 0.2225, step time: 0.3137\n",
      "78/224, train_loss: 0.2626, step time: 0.3180\n",
      "79/224, train_loss: 0.3812, step time: 0.3838\n",
      "80/224, train_loss: 0.3454, step time: 0.3884\n",
      "81/224, train_loss: 0.3778, step time: 0.4029\n",
      "82/224, train_loss: 0.3535, step time: 0.3164\n",
      "83/224, train_loss: 0.3925, step time: 0.3151\n",
      "84/224, train_loss: 0.4051, step time: 0.3157\n",
      "85/224, train_loss: 0.2745, step time: 0.3986\n",
      "86/224, train_loss: 0.2775, step time: 0.3182\n",
      "87/224, train_loss: 0.2584, step time: 0.3905\n",
      "88/224, train_loss: 0.3922, step time: 0.3168\n",
      "89/224, train_loss: 0.3865, step time: 0.3170\n",
      "90/224, train_loss: 0.1900, step time: 0.3169\n",
      "91/224, train_loss: 0.2764, step time: 0.3806\n",
      "92/224, train_loss: 0.2761, step time: 0.4050\n",
      "93/224, train_loss: 0.2248, step time: 0.3188\n",
      "94/224, train_loss: 0.3650, step time: 0.3193\n",
      "95/224, train_loss: 0.3838, step time: 0.4146\n",
      "96/224, train_loss: 0.1808, step time: 0.3156\n",
      "97/224, train_loss: 0.2195, step time: 0.3159\n",
      "98/224, train_loss: 0.3115, step time: 0.3194\n",
      "99/224, train_loss: 0.3057, step time: 0.3870\n",
      "100/224, train_loss: 0.2539, step time: 0.3711\n",
      "101/224, train_loss: 0.3418, step time: 0.3176\n",
      "102/224, train_loss: 0.4113, step time: 0.3907\n",
      "103/224, train_loss: 0.2670, step time: 0.3192\n",
      "104/224, train_loss: 0.3365, step time: 0.4049\n",
      "105/224, train_loss: 0.2874, step time: 0.4015\n",
      "106/224, train_loss: 0.2156, step time: 0.3751\n",
      "107/224, train_loss: 0.2859, step time: 0.3139\n",
      "108/224, train_loss: 0.3787, step time: 0.3162\n",
      "109/224, train_loss: 0.2192, step time: 0.3158\n",
      "110/224, train_loss: 0.2359, step time: 0.3158\n",
      "111/224, train_loss: 0.2041, step time: 0.3189\n",
      "112/224, train_loss: 0.2935, step time: 0.3170\n",
      "113/224, train_loss: 0.3576, step time: 0.3914\n",
      "114/224, train_loss: 0.2884, step time: 0.3792\n",
      "115/224, train_loss: 0.2565, step time: 0.3186\n",
      "116/224, train_loss: 0.3434, step time: 0.3862\n",
      "117/224, train_loss: 0.2520, step time: 0.3174\n",
      "118/224, train_loss: 0.3630, step time: 0.3154\n",
      "119/224, train_loss: 0.3478, step time: 0.3180\n",
      "120/224, train_loss: 0.2663, step time: 0.3159\n",
      "121/224, train_loss: 0.2345, step time: 0.4043\n",
      "122/224, train_loss: 0.5096, step time: 0.3681\n",
      "123/224, train_loss: 0.2124, step time: 0.3183\n",
      "124/224, train_loss: 0.2988, step time: 0.3747\n",
      "125/224, train_loss: 0.3908, step time: 0.3206\n",
      "126/224, train_loss: 0.2804, step time: 0.3923\n",
      "127/224, train_loss: 0.3745, step time: 0.3944\n",
      "128/224, train_loss: 0.3471, step time: 0.3168\n",
      "129/224, train_loss: 0.2904, step time: 0.3752\n",
      "130/224, train_loss: 0.4200, step time: 0.3820\n",
      "131/224, train_loss: 0.3169, step time: 0.3183\n",
      "132/224, train_loss: 0.3144, step time: 0.3815\n",
      "133/224, train_loss: 0.4216, step time: 0.3944\n",
      "134/224, train_loss: 0.2644, step time: 0.3162\n",
      "135/224, train_loss: 0.2389, step time: 0.3939\n",
      "136/224, train_loss: 0.3634, step time: 0.3175\n",
      "137/224, train_loss: 0.3779, step time: 0.3191\n",
      "138/224, train_loss: 0.2002, step time: 0.3192\n",
      "139/224, train_loss: 0.2996, step time: 0.4003\n",
      "140/224, train_loss: 0.2505, step time: 0.3181\n",
      "141/224, train_loss: 0.4620, step time: 0.3790\n",
      "142/224, train_loss: 0.2047, step time: 0.4146\n",
      "143/224, train_loss: 0.2631, step time: 0.3199\n",
      "144/224, train_loss: 0.1985, step time: 0.3158\n",
      "145/224, train_loss: 0.2044, step time: 0.3193\n",
      "146/224, train_loss: 0.3184, step time: 0.3154\n",
      "147/224, train_loss: 0.3624, step time: 0.3184\n",
      "148/224, train_loss: 0.3283, step time: 0.3668\n",
      "149/224, train_loss: 0.2399, step time: 0.3773\n",
      "150/224, train_loss: 0.2851, step time: 0.4008\n",
      "151/224, train_loss: 0.3670, step time: 0.3168\n",
      "152/224, train_loss: 0.3611, step time: 0.3855\n",
      "153/224, train_loss: 0.3672, step time: 0.3165\n",
      "154/224, train_loss: 0.2845, step time: 0.3885\n",
      "155/224, train_loss: 0.3203, step time: 0.3935\n",
      "156/224, train_loss: 0.2916, step time: 0.3812\n",
      "157/224, train_loss: 0.2643, step time: 0.4104\n",
      "158/224, train_loss: 0.2108, step time: 0.3791\n",
      "159/224, train_loss: 0.2475, step time: 0.3178\n",
      "160/224, train_loss: 0.2290, step time: 0.3845\n",
      "161/224, train_loss: 0.2914, step time: 0.3805\n",
      "162/224, train_loss: 0.3899, step time: 0.3871\n",
      "163/224, train_loss: 0.3011, step time: 0.4033\n",
      "164/224, train_loss: 0.2749, step time: 0.3173\n",
      "165/224, train_loss: 0.3844, step time: 0.3155\n",
      "166/224, train_loss: 0.2473, step time: 0.3154\n",
      "167/224, train_loss: 0.3897, step time: 0.3182\n",
      "168/224, train_loss: 0.2289, step time: 0.3166\n",
      "169/224, train_loss: 0.2491, step time: 0.3166\n",
      "170/224, train_loss: 0.4181, step time: 0.4102\n",
      "171/224, train_loss: 0.4144, step time: 0.3899\n",
      "172/224, train_loss: 0.2490, step time: 0.3137\n",
      "173/224, train_loss: 0.3957, step time: 0.3152\n",
      "174/224, train_loss: 0.3635, step time: 0.3157\n",
      "175/224, train_loss: 0.2717, step time: 0.3938\n",
      "176/224, train_loss: 0.2811, step time: 0.3767\n",
      "177/224, train_loss: 0.4660, step time: 0.3135\n",
      "178/224, train_loss: 0.2668, step time: 0.3925\n",
      "179/224, train_loss: 0.2102, step time: 0.4008\n",
      "180/224, train_loss: 0.3933, step time: 0.4043\n",
      "181/224, train_loss: 0.2505, step time: 0.3189\n",
      "182/224, train_loss: 0.4026, step time: 0.3161\n",
      "183/224, train_loss: 0.3256, step time: 0.3208\n",
      "184/224, train_loss: 0.3506, step time: 0.3179\n",
      "185/224, train_loss: 0.3117, step time: 0.4034\n",
      "186/224, train_loss: 0.2412, step time: 0.3966\n",
      "187/224, train_loss: 0.3269, step time: 0.3838\n",
      "188/224, train_loss: 0.3127, step time: 0.3156\n",
      "189/224, train_loss: 0.2075, step time: 0.3971\n",
      "190/224, train_loss: 0.3689, step time: 0.3182\n",
      "191/224, train_loss: 0.2181, step time: 0.3948\n",
      "192/224, train_loss: 0.3623, step time: 0.3680\n",
      "193/224, train_loss: 0.2791, step time: 0.3161\n",
      "194/224, train_loss: 0.2935, step time: 0.3141\n",
      "195/224, train_loss: 0.3743, step time: 0.3177\n",
      "196/224, train_loss: 0.3718, step time: 0.4057\n",
      "197/224, train_loss: 0.1672, step time: 0.3181\n",
      "198/224, train_loss: 0.3284, step time: 0.3888\n",
      "199/224, train_loss: 0.3682, step time: 0.3181\n",
      "200/224, train_loss: 0.1924, step time: 0.3650\n",
      "201/224, train_loss: 0.2733, step time: 0.3930\n",
      "202/224, train_loss: 0.3738, step time: 0.3923\n",
      "203/224, train_loss: 0.2445, step time: 0.4099\n",
      "204/224, train_loss: 0.1573, step time: 0.3840\n",
      "205/224, train_loss: 0.2826, step time: 0.3179\n",
      "206/224, train_loss: 0.3453, step time: 0.3182\n",
      "207/224, train_loss: 0.4966, step time: 0.4091\n",
      "208/224, train_loss: 0.1773, step time: 0.3175\n",
      "209/224, train_loss: 0.2523, step time: 0.3202\n",
      "210/224, train_loss: 0.2360, step time: 0.3175\n",
      "211/224, train_loss: 0.2820, step time: 0.3180\n",
      "212/224, train_loss: 0.1894, step time: 0.3892\n",
      "213/224, train_loss: 0.3384, step time: 0.3161\n",
      "214/224, train_loss: 0.2666, step time: 0.3180\n",
      "215/224, train_loss: 0.3993, step time: 0.3681\n",
      "216/224, train_loss: 0.3130, step time: 0.3968\n",
      "217/224, train_loss: 0.3390, step time: 0.3796\n",
      "218/224, train_loss: 0.3503, step time: 0.3177\n",
      "219/224, train_loss: 0.2336, step time: 0.3174\n",
      "220/224, train_loss: 0.3468, step time: 0.3809\n",
      "221/224, train_loss: 0.4585, step time: 0.3224\n",
      "222/224, train_loss: 0.2653, step time: 0.3841\n",
      "223/224, train_loss: 0.4372, step time: 0.3827\n",
      "224/224, train_loss: 0.3185, step time: 0.4012\n",
      "epoch 19 average loss: 0.3070\n",
      "current epoch: 19 current mean dice: 0.6525 class1: 0.9986 class2: 0.6860 class3: 0.2730\n",
      "best mean dice: 0.6525 at epoch: 19\n",
      "time consuming of epoch 19 is: 705.7106\n",
      "hello\n",
      "----------\n",
      "epoch 20/100\n",
      "1/224, train_loss: 0.3779, step time: 0.3827\n",
      "2/224, train_loss: 0.2929, step time: 0.5655\n",
      "3/224, train_loss: 0.2487, step time: 0.3177\n",
      "4/224, train_loss: 0.3012, step time: 0.3689\n",
      "5/224, train_loss: 0.3433, step time: 0.3692\n",
      "6/224, train_loss: 0.3224, step time: 0.3846\n",
      "7/224, train_loss: 0.3511, step time: 0.3155\n",
      "8/224, train_loss: 0.2197, step time: 0.4069\n",
      "9/224, train_loss: 0.2063, step time: 0.3822\n",
      "10/224, train_loss: 0.3472, step time: 0.3642\n",
      "11/224, train_loss: 0.3113, step time: 0.3164\n",
      "12/224, train_loss: 0.2440, step time: 0.4042\n",
      "13/224, train_loss: 0.4246, step time: 0.3154\n",
      "14/224, train_loss: 0.4060, step time: 0.4075\n",
      "15/224, train_loss: 0.2450, step time: 0.3885\n",
      "16/224, train_loss: 0.1979, step time: 0.3135\n",
      "17/224, train_loss: 0.3014, step time: 0.3154\n",
      "18/224, train_loss: 0.2585, step time: 0.3766\n",
      "19/224, train_loss: 0.4356, step time: 0.3826\n",
      "20/224, train_loss: 0.4000, step time: 0.3165\n",
      "21/224, train_loss: 0.3820, step time: 0.3161\n",
      "22/224, train_loss: 0.2561, step time: 0.3152\n",
      "23/224, train_loss: 0.3876, step time: 0.3907\n",
      "24/224, train_loss: 0.2786, step time: 0.3867\n",
      "25/224, train_loss: 0.1364, step time: 0.3732\n",
      "26/224, train_loss: 0.3045, step time: 0.4070\n",
      "27/224, train_loss: 0.3922, step time: 0.4042\n",
      "28/224, train_loss: 0.2712, step time: 0.3838\n",
      "29/224, train_loss: 0.2117, step time: 0.3157\n",
      "30/224, train_loss: 0.2259, step time: 0.3825\n",
      "31/224, train_loss: 0.2066, step time: 0.3795\n",
      "32/224, train_loss: 0.4587, step time: 0.3185\n",
      "33/224, train_loss: 0.2615, step time: 0.3187\n",
      "34/224, train_loss: 0.2260, step time: 0.3181\n",
      "35/224, train_loss: 0.1879, step time: 0.3188\n",
      "36/224, train_loss: 0.2181, step time: 0.3188\n",
      "37/224, train_loss: 0.3265, step time: 0.3815\n",
      "38/224, train_loss: 0.3777, step time: 0.3160\n",
      "39/224, train_loss: 0.1576, step time: 0.3164\n",
      "40/224, train_loss: 0.1791, step time: 0.3713\n",
      "41/224, train_loss: 0.2643, step time: 0.3867\n",
      "42/224, train_loss: 0.1792, step time: 0.3842\n",
      "43/224, train_loss: 0.1990, step time: 0.3763\n",
      "44/224, train_loss: 0.3170, step time: 0.3757\n",
      "45/224, train_loss: 0.2184, step time: 0.4071\n",
      "46/224, train_loss: 0.2277, step time: 0.3161\n",
      "47/224, train_loss: 0.4827, step time: 0.3843\n",
      "48/224, train_loss: 0.2861, step time: 0.3155\n",
      "49/224, train_loss: 0.3576, step time: 0.3156\n",
      "50/224, train_loss: 0.2029, step time: 0.3898\n",
      "51/224, train_loss: 0.1444, step time: 0.3161\n",
      "52/224, train_loss: 0.2171, step time: 0.3890\n",
      "53/224, train_loss: 0.2269, step time: 0.3159\n",
      "54/224, train_loss: 0.2261, step time: 0.3155\n",
      "55/224, train_loss: 0.3463, step time: 0.3135\n",
      "56/224, train_loss: 0.3752, step time: 0.3152\n",
      "57/224, train_loss: 0.2841, step time: 0.3133\n",
      "58/224, train_loss: 0.3589, step time: 0.3152\n",
      "59/224, train_loss: 0.2775, step time: 0.3136\n",
      "60/224, train_loss: 0.3858, step time: 0.3868\n",
      "61/224, train_loss: 0.2745, step time: 0.3165\n",
      "62/224, train_loss: 0.2128, step time: 0.3890\n",
      "63/224, train_loss: 0.3605, step time: 0.3139\n",
      "64/224, train_loss: 0.2062, step time: 0.3154\n",
      "65/224, train_loss: 0.5826, step time: 0.3706\n",
      "66/224, train_loss: 0.2333, step time: 0.3963\n",
      "67/224, train_loss: 0.2016, step time: 0.3204\n",
      "68/224, train_loss: 0.3087, step time: 0.3182\n",
      "69/224, train_loss: 0.2469, step time: 0.3769\n",
      "70/224, train_loss: 0.2380, step time: 0.3185\n",
      "71/224, train_loss: 0.2033, step time: 0.3138\n",
      "72/224, train_loss: 0.1532, step time: 0.3741\n",
      "73/224, train_loss: 0.5385, step time: 0.4022\n",
      "74/224, train_loss: 0.3827, step time: 0.3717\n",
      "75/224, train_loss: 0.3246, step time: 0.3831\n",
      "76/224, train_loss: 0.2410, step time: 0.3152\n",
      "77/224, train_loss: 0.1619, step time: 0.3187\n",
      "78/224, train_loss: 0.1851, step time: 0.3183\n",
      "79/224, train_loss: 0.3101, step time: 0.3188\n",
      "80/224, train_loss: 0.2526, step time: 0.3822\n",
      "81/224, train_loss: 0.3708, step time: 0.4120\n",
      "82/224, train_loss: 0.2764, step time: 0.3183\n",
      "83/224, train_loss: 0.2302, step time: 0.3158\n",
      "84/224, train_loss: 0.2550, step time: 0.3157\n",
      "85/224, train_loss: 0.3079, step time: 0.3168\n",
      "86/224, train_loss: 0.2979, step time: 0.4096\n",
      "87/224, train_loss: 0.3752, step time: 0.3751\n",
      "88/224, train_loss: 0.3824, step time: 0.3824\n",
      "89/224, train_loss: 0.2169, step time: 0.3189\n",
      "90/224, train_loss: 0.2000, step time: 0.3740\n",
      "91/224, train_loss: 0.4063, step time: 0.3770\n",
      "92/224, train_loss: 0.2244, step time: 0.3167\n",
      "93/224, train_loss: 0.4640, step time: 0.3703\n",
      "94/224, train_loss: 0.2538, step time: 0.3915\n",
      "95/224, train_loss: 0.1977, step time: 0.3196\n",
      "96/224, train_loss: 0.3656, step time: 0.3179\n",
      "97/224, train_loss: 0.2589, step time: 0.3944\n",
      "98/224, train_loss: 0.2278, step time: 0.3149\n",
      "99/224, train_loss: 0.2603, step time: 0.3170\n",
      "100/224, train_loss: 0.2945, step time: 0.3200\n",
      "101/224, train_loss: 0.3441, step time: 0.3763\n",
      "102/224, train_loss: 0.2079, step time: 0.4023\n",
      "103/224, train_loss: 0.3960, step time: 0.3158\n",
      "104/224, train_loss: 0.4119, step time: 0.3851\n",
      "105/224, train_loss: 0.1860, step time: 0.4150\n",
      "106/224, train_loss: 0.3354, step time: 0.3199\n",
      "107/224, train_loss: 0.1833, step time: 0.3204\n",
      "108/224, train_loss: 0.3492, step time: 0.4096\n",
      "109/224, train_loss: 0.2048, step time: 0.3138\n",
      "110/224, train_loss: 0.3232, step time: 0.3819\n",
      "111/224, train_loss: 0.3241, step time: 0.3175\n",
      "112/224, train_loss: 0.2503, step time: 0.3158\n",
      "113/224, train_loss: 0.3013, step time: 0.3863\n",
      "114/224, train_loss: 0.2251, step time: 0.3133\n",
      "115/224, train_loss: 0.3912, step time: 0.3173\n",
      "116/224, train_loss: 0.3786, step time: 0.3156\n",
      "117/224, train_loss: 0.4125, step time: 0.3163\n",
      "118/224, train_loss: 0.4107, step time: 0.3155\n",
      "119/224, train_loss: 0.3642, step time: 0.3150\n",
      "120/224, train_loss: 0.3467, step time: 0.3843\n",
      "121/224, train_loss: 0.1780, step time: 0.4109\n",
      "122/224, train_loss: 0.3020, step time: 0.4029\n",
      "123/224, train_loss: 0.3131, step time: 0.3149\n",
      "124/224, train_loss: 0.2105, step time: 0.3125\n",
      "125/224, train_loss: 0.2050, step time: 0.3150\n",
      "126/224, train_loss: 0.1993, step time: 0.3701\n",
      "127/224, train_loss: 0.2705, step time: 0.3127\n",
      "128/224, train_loss: 0.3202, step time: 0.3732\n",
      "129/224, train_loss: 0.2717, step time: 0.3149\n",
      "130/224, train_loss: 0.1602, step time: 0.3146\n",
      "131/224, train_loss: 0.3068, step time: 0.3866\n",
      "132/224, train_loss: 0.1472, step time: 0.4167\n",
      "133/224, train_loss: 0.2974, step time: 0.4090\n",
      "134/224, train_loss: 0.2768, step time: 0.3706\n",
      "135/224, train_loss: 0.2611, step time: 0.3905\n",
      "136/224, train_loss: 0.1748, step time: 0.3947\n",
      "137/224, train_loss: 0.2243, step time: 0.3748\n",
      "138/224, train_loss: 0.2008, step time: 0.3873\n",
      "139/224, train_loss: 0.2746, step time: 0.3750\n",
      "140/224, train_loss: 0.4009, step time: 0.3859\n",
      "141/224, train_loss: 0.2951, step time: 0.3685\n",
      "142/224, train_loss: 0.3641, step time: 0.3173\n",
      "143/224, train_loss: 0.1915, step time: 0.3151\n",
      "144/224, train_loss: 0.2866, step time: 0.4124\n",
      "145/224, train_loss: 0.2001, step time: 0.3177\n",
      "146/224, train_loss: 0.3079, step time: 0.3157\n",
      "147/224, train_loss: 0.2597, step time: 0.3965\n",
      "148/224, train_loss: 0.2606, step time: 0.3831\n",
      "149/224, train_loss: 0.2502, step time: 0.3184\n",
      "150/224, train_loss: 0.3806, step time: 0.3903\n",
      "151/224, train_loss: 0.4838, step time: 0.3864\n",
      "152/224, train_loss: 0.3244, step time: 0.4014\n",
      "153/224, train_loss: 0.3241, step time: 0.3739\n",
      "154/224, train_loss: 0.2108, step time: 0.3795\n",
      "155/224, train_loss: 0.3743, step time: 0.3649\n",
      "156/224, train_loss: 0.3526, step time: 0.3154\n",
      "157/224, train_loss: 0.2106, step time: 0.3171\n",
      "158/224, train_loss: 0.3475, step time: 0.3146\n",
      "159/224, train_loss: 0.3395, step time: 0.3146\n",
      "160/224, train_loss: 0.2848, step time: 0.3830\n",
      "161/224, train_loss: 0.3392, step time: 0.3195\n",
      "162/224, train_loss: 0.3248, step time: 0.3180\n",
      "163/224, train_loss: 0.3870, step time: 0.3156\n",
      "164/224, train_loss: 0.2276, step time: 0.3862\n",
      "165/224, train_loss: 0.3439, step time: 0.3141\n",
      "166/224, train_loss: 0.2194, step time: 0.3985\n",
      "167/224, train_loss: 0.3689, step time: 0.3938\n",
      "168/224, train_loss: 0.3779, step time: 0.3156\n",
      "169/224, train_loss: 0.4230, step time: 0.3927\n",
      "170/224, train_loss: 0.2745, step time: 0.3185\n",
      "171/224, train_loss: 0.2527, step time: 0.3162\n",
      "172/224, train_loss: 0.2495, step time: 0.3231\n",
      "173/224, train_loss: 0.4748, step time: 0.3917\n",
      "174/224, train_loss: 0.2212, step time: 0.3169\n",
      "175/224, train_loss: 0.1732, step time: 0.4060\n",
      "176/224, train_loss: 0.2473, step time: 0.3183\n",
      "177/224, train_loss: 0.3198, step time: 0.3156\n",
      "178/224, train_loss: 0.4190, step time: 0.3135\n",
      "179/224, train_loss: 0.1538, step time: 0.3862\n",
      "180/224, train_loss: 0.2643, step time: 0.3700\n",
      "181/224, train_loss: 0.3921, step time: 0.3155\n",
      "182/224, train_loss: 0.3198, step time: 0.3807\n",
      "183/224, train_loss: 0.5154, step time: 0.3912\n",
      "184/224, train_loss: 0.2993, step time: 0.3135\n",
      "185/224, train_loss: 0.2272, step time: 0.3903\n",
      "186/224, train_loss: 0.3128, step time: 0.3159\n",
      "187/224, train_loss: 0.1642, step time: 0.3171\n",
      "188/224, train_loss: 0.3700, step time: 0.4016\n",
      "189/224, train_loss: 0.3527, step time: 0.3959\n",
      "190/224, train_loss: 0.2829, step time: 0.4065\n",
      "191/224, train_loss: 0.3073, step time: 0.3179\n",
      "192/224, train_loss: 0.1571, step time: 0.4147\n",
      "193/224, train_loss: 0.2363, step time: 0.3969\n",
      "194/224, train_loss: 0.3558, step time: 0.4036\n",
      "195/224, train_loss: 0.3798, step time: 0.3145\n",
      "196/224, train_loss: 0.3926, step time: 0.3153\n",
      "197/224, train_loss: 0.2243, step time: 0.3858\n",
      "198/224, train_loss: 0.3396, step time: 0.3159\n",
      "199/224, train_loss: 0.2696, step time: 0.3176\n",
      "200/224, train_loss: 0.2398, step time: 0.3146\n",
      "201/224, train_loss: 0.2320, step time: 0.3888\n",
      "202/224, train_loss: 0.3594, step time: 0.3168\n",
      "203/224, train_loss: 0.2527, step time: 0.3146\n",
      "204/224, train_loss: 0.3828, step time: 0.3826\n",
      "205/224, train_loss: 0.3868, step time: 0.3126\n",
      "206/224, train_loss: 0.2742, step time: 0.4157\n",
      "207/224, train_loss: 0.2127, step time: 0.4057\n",
      "208/224, train_loss: 0.1964, step time: 0.3146\n",
      "209/224, train_loss: 0.2008, step time: 0.3698\n",
      "210/224, train_loss: 0.2848, step time: 0.3792\n",
      "211/224, train_loss: 0.3848, step time: 0.4011\n",
      "212/224, train_loss: 0.5272, step time: 0.3947\n",
      "213/224, train_loss: 0.1935, step time: 0.3166\n",
      "214/224, train_loss: 0.3761, step time: 0.3794\n",
      "215/224, train_loss: 0.4670, step time: 0.3143\n",
      "216/224, train_loss: 0.1478, step time: 0.3143\n",
      "217/224, train_loss: 0.4014, step time: 0.3120\n",
      "218/224, train_loss: 0.2062, step time: 0.3121\n",
      "219/224, train_loss: 0.2435, step time: 0.3118\n",
      "220/224, train_loss: 0.4403, step time: 0.3736\n",
      "221/224, train_loss: 0.2980, step time: 0.3811\n",
      "222/224, train_loss: 0.2331, step time: 0.3890\n",
      "223/224, train_loss: 0.3114, step time: 0.3708\n",
      "224/224, train_loss: 0.2091, step time: 0.4014\n",
      "epoch 20 average loss: 0.2927\n",
      "current epoch: 20 current mean dice: 0.6631 class1: 0.9988 class2: 0.7203 class3: 0.2702\n",
      "best mean dice: 0.6631 at epoch: 20\n",
      "time consuming of epoch 20 is: 772.8288\n",
      "hello\n",
      "----------\n",
      "epoch 21/100\n",
      "1/224, train_loss: 0.1717, step time: 0.3150\n",
      "2/224, train_loss: 0.1181, step time: 0.3675\n",
      "3/224, train_loss: 0.3629, step time: 0.3143\n",
      "4/224, train_loss: 0.2643, step time: 0.4105\n",
      "5/224, train_loss: 0.4063, step time: 0.3804\n",
      "6/224, train_loss: 0.2096, step time: 0.3169\n",
      "7/224, train_loss: 0.2152, step time: 0.4003\n",
      "8/224, train_loss: 0.2520, step time: 0.3126\n",
      "9/224, train_loss: 0.1339, step time: 0.3983\n",
      "10/224, train_loss: 0.2688, step time: 0.3948\n",
      "11/224, train_loss: 0.3234, step time: 0.3749\n",
      "12/224, train_loss: 0.5413, step time: 0.3812\n",
      "13/224, train_loss: 0.1287, step time: 0.3761\n",
      "14/224, train_loss: 0.1865, step time: 0.3158\n",
      "15/224, train_loss: 0.1746, step time: 0.3893\n",
      "16/224, train_loss: 0.2849, step time: 0.3959\n",
      "17/224, train_loss: 0.3939, step time: 0.3686\n",
      "18/224, train_loss: 0.3727, step time: 0.3176\n",
      "19/224, train_loss: 0.3408, step time: 0.3159\n",
      "20/224, train_loss: 0.1464, step time: 0.3758\n",
      "21/224, train_loss: 0.3317, step time: 0.3179\n",
      "22/224, train_loss: 0.1546, step time: 0.3154\n",
      "23/224, train_loss: 0.2175, step time: 0.3977\n",
      "24/224, train_loss: 0.2972, step time: 0.3863\n",
      "25/224, train_loss: 0.1886, step time: 0.3153\n",
      "26/224, train_loss: 0.1628, step time: 0.3130\n",
      "27/224, train_loss: 0.2586, step time: 0.3172\n",
      "28/224, train_loss: 0.2895, step time: 0.4135\n",
      "29/224, train_loss: 0.3815, step time: 0.3153\n",
      "30/224, train_loss: 0.1821, step time: 0.3179\n",
      "31/224, train_loss: 0.2546, step time: 0.3710\n",
      "32/224, train_loss: 0.1422, step time: 0.3985\n",
      "33/224, train_loss: 0.4574, step time: 0.3163\n",
      "34/224, train_loss: 0.1370, step time: 0.4111\n",
      "35/224, train_loss: 0.1948, step time: 0.3151\n",
      "36/224, train_loss: 0.1982, step time: 0.3994\n",
      "37/224, train_loss: 0.2792, step time: 0.3808\n",
      "38/224, train_loss: 0.2596, step time: 0.3139\n",
      "39/224, train_loss: 0.2368, step time: 0.3154\n",
      "40/224, train_loss: 0.1793, step time: 0.3748\n",
      "41/224, train_loss: 0.3858, step time: 0.3154\n",
      "42/224, train_loss: 0.1834, step time: 0.3172\n",
      "43/224, train_loss: 0.1879, step time: 0.3173\n",
      "44/224, train_loss: 0.2064, step time: 0.4117\n",
      "45/224, train_loss: 0.2040, step time: 0.3148\n",
      "46/224, train_loss: 0.2435, step time: 0.3167\n",
      "47/224, train_loss: 0.2177, step time: 0.3153\n",
      "48/224, train_loss: 0.3446, step time: 0.3816\n",
      "49/224, train_loss: 0.3900, step time: 0.3891\n",
      "50/224, train_loss: 0.3609, step time: 0.3939\n",
      "51/224, train_loss: 0.3161, step time: 0.3148\n",
      "52/224, train_loss: 0.2067, step time: 0.3151\n",
      "53/224, train_loss: 0.4295, step time: 0.3143\n",
      "54/224, train_loss: 0.3581, step time: 0.3138\n",
      "55/224, train_loss: 0.1737, step time: 0.4078\n",
      "56/224, train_loss: 0.4845, step time: 0.4058\n",
      "57/224, train_loss: 0.2643, step time: 0.3122\n",
      "58/224, train_loss: 0.3834, step time: 0.3119\n",
      "59/224, train_loss: 0.2097, step time: 0.3718\n",
      "60/224, train_loss: 0.2074, step time: 0.3767\n",
      "61/224, train_loss: 0.1691, step time: 0.3145\n",
      "62/224, train_loss: 0.2649, step time: 0.3841\n",
      "63/224, train_loss: 0.3657, step time: 0.3777\n",
      "64/224, train_loss: 0.2692, step time: 0.3163\n",
      "65/224, train_loss: 0.2213, step time: 0.3163\n",
      "66/224, train_loss: 0.3833, step time: 0.3719\n",
      "67/224, train_loss: 0.2562, step time: 0.4048\n",
      "68/224, train_loss: 0.3099, step time: 0.4023\n",
      "69/224, train_loss: 0.3388, step time: 0.3734\n",
      "70/224, train_loss: 0.1911, step time: 0.3144\n",
      "71/224, train_loss: 0.1937, step time: 0.3163\n",
      "72/224, train_loss: 0.2868, step time: 0.3121\n",
      "73/224, train_loss: 0.1628, step time: 0.3757\n",
      "74/224, train_loss: 0.2312, step time: 0.3163\n",
      "75/224, train_loss: 0.2318, step time: 0.3142\n",
      "76/224, train_loss: 0.1400, step time: 0.3148\n",
      "77/224, train_loss: 0.2557, step time: 0.3124\n",
      "78/224, train_loss: 0.4717, step time: 0.3172\n",
      "79/224, train_loss: 0.2984, step time: 0.3781\n",
      "80/224, train_loss: 0.3579, step time: 0.3151\n",
      "81/224, train_loss: 0.2478, step time: 0.3145\n",
      "82/224, train_loss: 0.2326, step time: 0.4021\n",
      "83/224, train_loss: 0.3076, step time: 0.3124\n",
      "84/224, train_loss: 0.3345, step time: 0.3144\n",
      "85/224, train_loss: 0.2610, step time: 0.3758\n",
      "86/224, train_loss: 0.3867, step time: 0.3854\n",
      "87/224, train_loss: 0.3545, step time: 0.3171\n",
      "88/224, train_loss: 0.2870, step time: 0.3173\n",
      "89/224, train_loss: 0.3554, step time: 0.3957\n",
      "90/224, train_loss: 0.3322, step time: 0.3953\n",
      "91/224, train_loss: 0.3912, step time: 0.3977\n",
      "92/224, train_loss: 0.3125, step time: 0.3136\n",
      "93/224, train_loss: 0.2137, step time: 0.3152\n",
      "94/224, train_loss: 0.2622, step time: 0.3797\n",
      "95/224, train_loss: 0.3210, step time: 0.3140\n",
      "96/224, train_loss: 0.1606, step time: 0.3120\n",
      "97/224, train_loss: 0.2653, step time: 0.3756\n",
      "98/224, train_loss: 0.4246, step time: 0.3982\n",
      "99/224, train_loss: 0.3679, step time: 0.3884\n",
      "100/224, train_loss: 0.2087, step time: 0.3149\n",
      "101/224, train_loss: 0.2445, step time: 0.3845\n",
      "102/224, train_loss: 0.3248, step time: 0.3991\n",
      "103/224, train_loss: 0.2730, step time: 0.3149\n",
      "104/224, train_loss: 0.1919, step time: 0.3162\n",
      "105/224, train_loss: 0.2143, step time: 0.4063\n",
      "106/224, train_loss: 0.2683, step time: 0.3147\n",
      "107/224, train_loss: 0.2046, step time: 0.3148\n",
      "108/224, train_loss: 0.3284, step time: 0.3779\n",
      "109/224, train_loss: 0.3448, step time: 0.3149\n",
      "110/224, train_loss: 0.2458, step time: 0.3781\n",
      "111/224, train_loss: 0.2283, step time: 0.3942\n",
      "112/224, train_loss: 0.4375, step time: 0.3847\n",
      "113/224, train_loss: 0.4332, step time: 0.3898\n",
      "114/224, train_loss: 0.3383, step time: 0.3168\n",
      "115/224, train_loss: 0.2999, step time: 0.3144\n",
      "116/224, train_loss: 0.2827, step time: 0.3141\n",
      "117/224, train_loss: 0.2094, step time: 0.3865\n",
      "118/224, train_loss: 0.2621, step time: 0.3145\n",
      "119/224, train_loss: 0.1599, step time: 0.3140\n",
      "120/224, train_loss: 0.4129, step time: 0.3629\n",
      "121/224, train_loss: 0.1501, step time: 0.3712\n",
      "122/224, train_loss: 0.1081, step time: 0.3991\n",
      "123/224, train_loss: 0.4588, step time: 0.3145\n",
      "124/224, train_loss: 0.4246, step time: 0.3646\n",
      "125/224, train_loss: 0.5876, step time: 0.4013\n",
      "126/224, train_loss: 0.2773, step time: 0.3126\n",
      "127/224, train_loss: 0.2577, step time: 0.4117\n",
      "128/224, train_loss: 0.2725, step time: 0.4089\n",
      "129/224, train_loss: 0.3490, step time: 0.3723\n",
      "130/224, train_loss: 0.3034, step time: 0.3935\n",
      "131/224, train_loss: 0.2075, step time: 0.3145\n",
      "132/224, train_loss: 0.1955, step time: 0.3729\n",
      "133/224, train_loss: 0.3611, step time: 0.3816\n",
      "134/224, train_loss: 0.2400, step time: 0.3703\n",
      "135/224, train_loss: 0.1820, step time: 0.3155\n",
      "136/224, train_loss: 0.3749, step time: 0.3723\n",
      "137/224, train_loss: 0.3023, step time: 0.3949\n",
      "138/224, train_loss: 0.2778, step time: 0.3914\n",
      "139/224, train_loss: 0.3817, step time: 0.3841\n",
      "140/224, train_loss: 0.1481, step time: 0.3148\n",
      "141/224, train_loss: 0.1727, step time: 0.3146\n",
      "142/224, train_loss: 0.3692, step time: 0.3828\n",
      "143/224, train_loss: 0.1747, step time: 0.3747\n",
      "144/224, train_loss: 0.1567, step time: 0.3971\n",
      "145/224, train_loss: 0.2018, step time: 0.3173\n",
      "146/224, train_loss: 0.3772, step time: 0.3172\n",
      "147/224, train_loss: 0.1776, step time: 0.3128\n",
      "148/224, train_loss: 0.1564, step time: 0.3136\n",
      "149/224, train_loss: 0.2456, step time: 0.3180\n",
      "150/224, train_loss: 0.1717, step time: 0.4002\n",
      "151/224, train_loss: 0.2797, step time: 0.3145\n",
      "152/224, train_loss: 0.2449, step time: 0.4089\n",
      "153/224, train_loss: 0.2817, step time: 0.3920\n",
      "154/224, train_loss: 0.1731, step time: 0.3149\n",
      "155/224, train_loss: 0.3541, step time: 0.3150\n",
      "156/224, train_loss: 0.2614, step time: 0.3732\n",
      "157/224, train_loss: 0.2779, step time: 0.3897\n",
      "158/224, train_loss: 0.3720, step time: 0.3875\n",
      "159/224, train_loss: 0.3920, step time: 0.3916\n",
      "160/224, train_loss: 0.2618, step time: 0.3153\n",
      "161/224, train_loss: 0.2968, step time: 0.3909\n",
      "162/224, train_loss: 0.3055, step time: 0.3858\n",
      "163/224, train_loss: 0.5098, step time: 0.3785\n",
      "164/224, train_loss: 0.3970, step time: 0.3152\n",
      "165/224, train_loss: 0.3988, step time: 0.4087\n",
      "166/224, train_loss: 0.2923, step time: 0.3915\n",
      "167/224, train_loss: 0.2387, step time: 0.3146\n",
      "168/224, train_loss: 0.3017, step time: 0.3142\n",
      "169/224, train_loss: 0.3520, step time: 0.3129\n",
      "170/224, train_loss: 0.2360, step time: 0.3789\n",
      "171/224, train_loss: 0.2931, step time: 0.4088\n",
      "172/224, train_loss: 0.1916, step time: 0.3148\n",
      "173/224, train_loss: 0.3606, step time: 0.3154\n",
      "174/224, train_loss: 0.3243, step time: 0.3166\n",
      "175/224, train_loss: 0.3859, step time: 0.3165\n",
      "176/224, train_loss: 0.2199, step time: 0.3154\n",
      "177/224, train_loss: 0.2355, step time: 0.4087\n",
      "178/224, train_loss: 0.2511, step time: 0.3169\n",
      "179/224, train_loss: 0.1478, step time: 0.3663\n",
      "180/224, train_loss: 0.2983, step time: 0.3910\n",
      "181/224, train_loss: 0.3174, step time: 0.3181\n",
      "182/224, train_loss: 0.3746, step time: 0.3177\n",
      "183/224, train_loss: 0.3320, step time: 0.4189\n",
      "184/224, train_loss: 0.3566, step time: 0.3182\n",
      "185/224, train_loss: 0.3094, step time: 0.4226\n",
      "186/224, train_loss: 0.4369, step time: 0.3877\n",
      "187/224, train_loss: 0.2489, step time: 0.3952\n",
      "188/224, train_loss: 0.3004, step time: 0.3183\n",
      "189/224, train_loss: 0.3772, step time: 0.3149\n",
      "190/224, train_loss: 0.5106, step time: 0.3816\n",
      "191/224, train_loss: 0.3087, step time: 0.3172\n",
      "192/224, train_loss: 0.3843, step time: 0.3947\n",
      "193/224, train_loss: 0.3429, step time: 0.3971\n",
      "194/224, train_loss: 0.3616, step time: 0.3975\n",
      "195/224, train_loss: 0.2018, step time: 0.3838\n",
      "196/224, train_loss: 0.1975, step time: 0.3146\n",
      "197/224, train_loss: 0.3834, step time: 0.3163\n",
      "198/224, train_loss: 0.4138, step time: 0.3197\n",
      "199/224, train_loss: 0.2750, step time: 0.4055\n",
      "200/224, train_loss: 0.2822, step time: 0.4013\n",
      "201/224, train_loss: 0.2269, step time: 0.3198\n",
      "202/224, train_loss: 0.3858, step time: 0.3173\n",
      "203/224, train_loss: 0.3945, step time: 0.3148\n",
      "204/224, train_loss: 0.2236, step time: 0.4034\n",
      "205/224, train_loss: 0.2520, step time: 0.3155\n",
      "206/224, train_loss: 0.3751, step time: 0.3172\n",
      "207/224, train_loss: 0.2827, step time: 0.3145\n",
      "208/224, train_loss: 0.3300, step time: 0.3175\n",
      "209/224, train_loss: 0.3913, step time: 0.3195\n",
      "210/224, train_loss: 0.1851, step time: 0.3173\n",
      "211/224, train_loss: 0.4018, step time: 0.3708\n",
      "212/224, train_loss: 0.2966, step time: 0.3811\n",
      "213/224, train_loss: 0.2092, step time: 0.3872\n",
      "214/224, train_loss: 0.2544, step time: 0.3932\n",
      "215/224, train_loss: 0.4195, step time: 0.3716\n",
      "216/224, train_loss: 0.3421, step time: 0.3950\n",
      "217/224, train_loss: 0.3237, step time: 0.3781\n",
      "218/224, train_loss: 0.2488, step time: 0.3178\n",
      "219/224, train_loss: 0.3907, step time: 0.3156\n",
      "220/224, train_loss: 0.3602, step time: 0.3174\n",
      "221/224, train_loss: 0.4030, step time: 0.3823\n",
      "222/224, train_loss: 0.2429, step time: 0.3173\n",
      "223/224, train_loss: 0.4363, step time: 0.3905\n",
      "224/224, train_loss: 0.2101, step time: 0.3992\n",
      "epoch 21 average loss: 0.2870\n",
      "current epoch: 21 current mean dice: 0.6650 class1: 0.9987 class2: 0.7101 class3: 0.2863\n",
      "best mean dice: 0.6650 at epoch: 21\n",
      "time consuming of epoch 21 is: 743.9477\n",
      "hello\n",
      "----------\n",
      "epoch 22/100\n",
      "1/224, train_loss: 0.2289, step time: 0.3152\n",
      "2/224, train_loss: 0.2271, step time: 0.3178\n",
      "3/224, train_loss: 0.2840, step time: 0.3919\n",
      "4/224, train_loss: 0.3145, step time: 0.3895\n",
      "5/224, train_loss: 0.3587, step time: 0.3142\n",
      "6/224, train_loss: 0.3677, step time: 0.3171\n",
      "7/224, train_loss: 0.1666, step time: 0.3159\n",
      "8/224, train_loss: 0.2060, step time: 0.4001\n",
      "9/224, train_loss: 0.2686, step time: 0.3180\n",
      "10/224, train_loss: 0.1906, step time: 0.3156\n",
      "11/224, train_loss: 0.3041, step time: 0.3174\n",
      "12/224, train_loss: 0.1349, step time: 0.3145\n",
      "13/224, train_loss: 0.2158, step time: 0.4026\n",
      "14/224, train_loss: 0.2995, step time: 0.3177\n",
      "15/224, train_loss: 0.2503, step time: 0.3175\n",
      "16/224, train_loss: 0.2090, step time: 0.3131\n",
      "17/224, train_loss: 0.1835, step time: 0.3921\n",
      "18/224, train_loss: 0.2273, step time: 0.3180\n",
      "19/224, train_loss: 0.3720, step time: 0.4110\n",
      "20/224, train_loss: 0.2493, step time: 0.3172\n",
      "21/224, train_loss: 0.2845, step time: 0.3946\n",
      "22/224, train_loss: 0.1470, step time: 0.3147\n",
      "23/224, train_loss: 0.3588, step time: 0.3841\n",
      "24/224, train_loss: 0.1517, step time: 0.3169\n",
      "25/224, train_loss: 0.5042, step time: 0.3905\n",
      "26/224, train_loss: 0.3412, step time: 0.3153\n",
      "27/224, train_loss: 0.3117, step time: 0.4090\n",
      "28/224, train_loss: 0.2230, step time: 0.3131\n",
      "29/224, train_loss: 0.2661, step time: 0.3149\n",
      "30/224, train_loss: 0.3757, step time: 0.3130\n",
      "31/224, train_loss: 0.2233, step time: 0.3169\n",
      "32/224, train_loss: 0.1709, step time: 0.3125\n",
      "33/224, train_loss: 0.2627, step time: 0.3140\n",
      "34/224, train_loss: 0.1627, step time: 0.3964\n",
      "35/224, train_loss: 0.1824, step time: 0.3146\n",
      "36/224, train_loss: 0.1983, step time: 0.3814\n",
      "37/224, train_loss: 0.4660, step time: 0.3995\n",
      "38/224, train_loss: 0.3134, step time: 0.3141\n",
      "39/224, train_loss: 0.4087, step time: 0.3145\n",
      "40/224, train_loss: 0.2542, step time: 0.3678\n",
      "41/224, train_loss: 0.3008, step time: 0.3807\n",
      "42/224, train_loss: 0.2293, step time: 0.3147\n",
      "43/224, train_loss: 0.1465, step time: 0.3124\n",
      "44/224, train_loss: 0.2736, step time: 0.3146\n",
      "45/224, train_loss: 0.2779, step time: 0.3148\n",
      "46/224, train_loss: 0.3613, step time: 0.3808\n",
      "47/224, train_loss: 0.2196, step time: 0.3694\n",
      "48/224, train_loss: 0.1731, step time: 0.4138\n",
      "49/224, train_loss: 0.2135, step time: 0.4065\n",
      "50/224, train_loss: 0.2271, step time: 0.4108\n",
      "51/224, train_loss: 0.4163, step time: 0.3174\n",
      "52/224, train_loss: 0.1731, step time: 0.3149\n",
      "53/224, train_loss: 0.2605, step time: 0.3730\n",
      "54/224, train_loss: 0.1137, step time: 0.3915\n",
      "55/224, train_loss: 0.4337, step time: 0.3665\n",
      "56/224, train_loss: 0.3165, step time: 0.3716\n",
      "57/224, train_loss: 0.3291, step time: 0.3157\n",
      "58/224, train_loss: 0.3979, step time: 0.3830\n",
      "59/224, train_loss: 0.3268, step time: 0.3733\n",
      "60/224, train_loss: 0.1264, step time: 0.3836\n",
      "61/224, train_loss: 0.2021, step time: 0.3155\n",
      "62/224, train_loss: 0.3301, step time: 0.3693\n",
      "63/224, train_loss: 0.3663, step time: 0.3819\n",
      "64/224, train_loss: 0.2202, step time: 0.3163\n",
      "65/224, train_loss: 0.2222, step time: 0.3682\n",
      "66/224, train_loss: 0.3340, step time: 0.3949\n",
      "67/224, train_loss: 0.3756, step time: 0.3180\n",
      "68/224, train_loss: 0.3941, step time: 0.3133\n",
      "69/224, train_loss: 0.4536, step time: 0.3157\n",
      "70/224, train_loss: 0.1737, step time: 0.3179\n",
      "71/224, train_loss: 0.2424, step time: 0.3131\n",
      "72/224, train_loss: 0.3683, step time: 0.3151\n",
      "73/224, train_loss: 0.3584, step time: 0.3153\n",
      "74/224, train_loss: 0.1759, step time: 0.3162\n",
      "75/224, train_loss: 0.1441, step time: 0.3181\n",
      "76/224, train_loss: 0.3931, step time: 0.3713\n",
      "77/224, train_loss: 0.1949, step time: 0.3932\n",
      "78/224, train_loss: 0.2048, step time: 0.3155\n",
      "79/224, train_loss: 0.2765, step time: 0.4008\n",
      "80/224, train_loss: 0.2700, step time: 0.3180\n",
      "81/224, train_loss: 0.1420, step time: 0.3179\n",
      "82/224, train_loss: 0.4216, step time: 0.3805\n",
      "83/224, train_loss: 0.4022, step time: 0.3154\n",
      "84/224, train_loss: 0.3482, step time: 0.4107\n",
      "85/224, train_loss: 0.4743, step time: 0.3964\n",
      "86/224, train_loss: 0.2734, step time: 0.3714\n",
      "87/224, train_loss: 0.2990, step time: 0.3152\n",
      "88/224, train_loss: 0.1852, step time: 0.3153\n",
      "89/224, train_loss: 0.1663, step time: 0.4040\n",
      "90/224, train_loss: 0.3372, step time: 0.3155\n",
      "91/224, train_loss: 0.1542, step time: 0.3716\n",
      "92/224, train_loss: 0.3919, step time: 0.3176\n",
      "93/224, train_loss: 0.5208, step time: 0.4046\n",
      "94/224, train_loss: 0.2925, step time: 0.3909\n",
      "95/224, train_loss: 0.3001, step time: 0.3137\n",
      "96/224, train_loss: 0.2982, step time: 0.3153\n",
      "97/224, train_loss: 0.3898, step time: 0.3184\n",
      "98/224, train_loss: 0.3304, step time: 0.3180\n",
      "99/224, train_loss: 0.1733, step time: 0.3793\n",
      "100/224, train_loss: 0.2027, step time: 0.3166\n",
      "101/224, train_loss: 0.2623, step time: 0.3161\n",
      "102/224, train_loss: 0.3583, step time: 0.3905\n",
      "103/224, train_loss: 0.1785, step time: 0.3707\n",
      "104/224, train_loss: 0.3342, step time: 0.3163\n",
      "105/224, train_loss: 0.4039, step time: 0.4046\n",
      "106/224, train_loss: 0.3857, step time: 0.3156\n",
      "107/224, train_loss: 0.5657, step time: 0.3872\n",
      "108/224, train_loss: 0.2183, step time: 0.3162\n",
      "109/224, train_loss: 0.2128, step time: 0.3162\n",
      "110/224, train_loss: 0.2227, step time: 0.3162\n",
      "111/224, train_loss: 0.2761, step time: 0.3156\n",
      "112/224, train_loss: 0.2983, step time: 0.3153\n",
      "113/224, train_loss: 0.2077, step time: 0.3153\n",
      "114/224, train_loss: 0.2039, step time: 0.3156\n",
      "115/224, train_loss: 0.1490, step time: 0.3151\n",
      "116/224, train_loss: 0.1233, step time: 0.3160\n",
      "117/224, train_loss: 0.3626, step time: 0.3160\n",
      "118/224, train_loss: 0.1776, step time: 0.3801\n",
      "119/224, train_loss: 0.3098, step time: 0.3161\n",
      "120/224, train_loss: 0.3027, step time: 0.3184\n",
      "121/224, train_loss: 0.2419, step time: 0.3141\n",
      "122/224, train_loss: 0.2356, step time: 0.3161\n",
      "123/224, train_loss: 0.2642, step time: 0.3717\n",
      "124/224, train_loss: 0.2311, step time: 0.3161\n",
      "125/224, train_loss: 0.2744, step time: 0.3696\n",
      "126/224, train_loss: 0.1990, step time: 0.3138\n",
      "127/224, train_loss: 0.2665, step time: 0.3848\n",
      "128/224, train_loss: 0.2202, step time: 0.3181\n",
      "129/224, train_loss: 0.1166, step time: 0.3158\n",
      "130/224, train_loss: 0.2419, step time: 0.3892\n",
      "131/224, train_loss: 0.2546, step time: 0.3734\n",
      "132/224, train_loss: 0.2863, step time: 0.3154\n",
      "133/224, train_loss: 0.4007, step time: 0.3173\n",
      "134/224, train_loss: 0.3098, step time: 0.3153\n",
      "135/224, train_loss: 0.2577, step time: 0.3977\n",
      "136/224, train_loss: 0.2728, step time: 0.3177\n",
      "137/224, train_loss: 0.1569, step time: 0.3749\n",
      "138/224, train_loss: 0.3995, step time: 0.3190\n",
      "139/224, train_loss: 0.1092, step time: 0.3908\n",
      "140/224, train_loss: 0.3106, step time: 0.3179\n",
      "141/224, train_loss: 0.2409, step time: 0.3159\n",
      "142/224, train_loss: 0.3489, step time: 0.3775\n",
      "143/224, train_loss: 0.3920, step time: 0.4037\n",
      "144/224, train_loss: 0.1096, step time: 0.4095\n",
      "145/224, train_loss: 0.3242, step time: 0.4004\n",
      "146/224, train_loss: 0.2319, step time: 0.4113\n",
      "147/224, train_loss: 0.2743, step time: 0.3755\n",
      "148/224, train_loss: 0.3662, step time: 0.3137\n",
      "149/224, train_loss: 0.2511, step time: 0.3854\n",
      "150/224, train_loss: 0.1733, step time: 0.3754\n",
      "151/224, train_loss: 0.1440, step time: 0.3154\n",
      "152/224, train_loss: 0.3618, step time: 0.4034\n",
      "153/224, train_loss: 0.1834, step time: 0.3180\n",
      "154/224, train_loss: 0.3340, step time: 0.3727\n",
      "155/224, train_loss: 0.2366, step time: 0.3148\n",
      "156/224, train_loss: 0.3648, step time: 0.3996\n",
      "157/224, train_loss: 0.2963, step time: 0.3730\n",
      "158/224, train_loss: 0.4607, step time: 0.3141\n",
      "159/224, train_loss: 0.2729, step time: 0.3867\n",
      "160/224, train_loss: 0.4076, step time: 0.3665\n",
      "161/224, train_loss: 0.2105, step time: 0.3155\n",
      "162/224, train_loss: 0.3126, step time: 0.3151\n",
      "163/224, train_loss: 0.3037, step time: 0.3153\n",
      "164/224, train_loss: 0.2069, step time: 0.3153\n",
      "165/224, train_loss: 0.2285, step time: 0.4000\n",
      "166/224, train_loss: 0.1688, step time: 0.3162\n",
      "167/224, train_loss: 0.1818, step time: 0.3180\n",
      "168/224, train_loss: 0.1608, step time: 0.3130\n",
      "169/224, train_loss: 0.3555, step time: 0.3180\n",
      "170/224, train_loss: 0.4470, step time: 0.3157\n",
      "171/224, train_loss: 0.3034, step time: 0.3722\n",
      "172/224, train_loss: 0.2002, step time: 0.4069\n",
      "173/224, train_loss: 0.3755, step time: 0.4061\n",
      "174/224, train_loss: 0.2757, step time: 0.3183\n",
      "175/224, train_loss: 0.1847, step time: 0.3977\n",
      "176/224, train_loss: 0.2768, step time: 0.3202\n",
      "177/224, train_loss: 0.2049, step time: 0.3767\n",
      "178/224, train_loss: 0.2262, step time: 0.3773\n",
      "179/224, train_loss: 0.2259, step time: 0.3143\n",
      "180/224, train_loss: 0.2781, step time: 0.3189\n",
      "181/224, train_loss: 0.1755, step time: 0.3170\n",
      "182/224, train_loss: 0.3723, step time: 0.3156\n",
      "183/224, train_loss: 0.3494, step time: 0.3886\n",
      "184/224, train_loss: 0.1410, step time: 0.3804\n",
      "185/224, train_loss: 0.1302, step time: 0.3181\n",
      "186/224, train_loss: 0.5063, step time: 0.3996\n",
      "187/224, train_loss: 0.3197, step time: 0.3189\n",
      "188/224, train_loss: 0.2812, step time: 0.4006\n",
      "189/224, train_loss: 0.1847, step time: 0.3202\n",
      "190/224, train_loss: 0.3178, step time: 0.3850\n",
      "191/224, train_loss: 0.2719, step time: 0.3956\n",
      "192/224, train_loss: 0.6397, step time: 0.3969\n",
      "193/224, train_loss: 0.3427, step time: 0.3820\n",
      "194/224, train_loss: 0.1727, step time: 0.3173\n",
      "195/224, train_loss: 0.2467, step time: 0.3179\n",
      "196/224, train_loss: 0.4054, step time: 0.3841\n",
      "197/224, train_loss: 0.3804, step time: 0.3164\n",
      "198/224, train_loss: 0.3045, step time: 0.3173\n",
      "199/224, train_loss: 0.2767, step time: 0.3168\n",
      "200/224, train_loss: 0.1109, step time: 0.3168\n",
      "201/224, train_loss: 0.2222, step time: 0.3964\n",
      "202/224, train_loss: 0.2505, step time: 0.3806\n",
      "203/224, train_loss: 0.2484, step time: 0.3170\n",
      "204/224, train_loss: 0.2565, step time: 0.3162\n",
      "205/224, train_loss: 0.3832, step time: 0.3677\n",
      "206/224, train_loss: 0.1786, step time: 0.3146\n",
      "207/224, train_loss: 0.3781, step time: 0.3184\n",
      "208/224, train_loss: 0.1880, step time: 0.3160\n",
      "209/224, train_loss: 0.2765, step time: 0.3163\n",
      "210/224, train_loss: 0.2959, step time: 0.3188\n",
      "211/224, train_loss: 0.1428, step time: 0.3159\n",
      "212/224, train_loss: 0.3625, step time: 0.3162\n",
      "213/224, train_loss: 0.1553, step time: 0.3163\n",
      "214/224, train_loss: 0.1400, step time: 0.3173\n",
      "215/224, train_loss: 0.1994, step time: 0.3681\n",
      "216/224, train_loss: 0.1903, step time: 0.3160\n",
      "217/224, train_loss: 0.2605, step time: 0.3821\n",
      "218/224, train_loss: 0.2798, step time: 0.3181\n",
      "219/224, train_loss: 0.1267, step time: 0.3175\n",
      "220/224, train_loss: 0.2556, step time: 0.4037\n",
      "221/224, train_loss: 0.2074, step time: 0.3163\n",
      "222/224, train_loss: 0.2637, step time: 0.3208\n",
      "223/224, train_loss: 0.2653, step time: 0.3158\n",
      "224/224, train_loss: 0.3816, step time: 0.3913\n",
      "epoch 22 average loss: 0.2729\n",
      "current epoch: 22 current mean dice: 0.6715 class1: 0.9987 class2: 0.7060 class3: 0.3097\n",
      "best mean dice: 0.6715 at epoch: 22\n",
      "time consuming of epoch 22 is: 632.0972\n",
      "hello\n",
      "----------\n",
      "epoch 23/100\n",
      "1/224, train_loss: 0.2240, step time: 0.3155\n",
      "2/224, train_loss: 0.3171, step time: 0.4041\n",
      "3/224, train_loss: 0.3101, step time: 0.3190\n",
      "4/224, train_loss: 0.1792, step time: 0.3186\n",
      "5/224, train_loss: 0.2052, step time: 0.3143\n",
      "6/224, train_loss: 0.2845, step time: 0.3726\n",
      "7/224, train_loss: 0.1784, step time: 0.3166\n",
      "8/224, train_loss: 0.1263, step time: 0.3174\n",
      "9/224, train_loss: 0.4213, step time: 0.3175\n",
      "10/224, train_loss: 0.2444, step time: 0.3167\n",
      "11/224, train_loss: 0.2249, step time: 0.3196\n",
      "12/224, train_loss: 0.1663, step time: 0.3171\n",
      "13/224, train_loss: 0.3950, step time: 0.3873\n",
      "14/224, train_loss: 0.1365, step time: 0.3171\n",
      "15/224, train_loss: 0.4096, step time: 0.3173\n",
      "16/224, train_loss: 0.4467, step time: 0.3903\n",
      "17/224, train_loss: 0.2329, step time: 0.3193\n",
      "18/224, train_loss: 0.3191, step time: 0.4003\n",
      "19/224, train_loss: 0.2648, step time: 0.4088\n",
      "20/224, train_loss: 0.2345, step time: 0.3927\n",
      "21/224, train_loss: 0.2394, step time: 0.3677\n",
      "22/224, train_loss: 0.3468, step time: 0.3174\n",
      "23/224, train_loss: 0.1787, step time: 0.4101\n",
      "24/224, train_loss: 0.4121, step time: 0.3176\n",
      "25/224, train_loss: 0.2136, step time: 0.3171\n",
      "26/224, train_loss: 0.1696, step time: 0.3190\n",
      "27/224, train_loss: 0.1754, step time: 0.4035\n",
      "28/224, train_loss: 0.1264, step time: 0.3147\n",
      "29/224, train_loss: 0.3230, step time: 0.3172\n",
      "30/224, train_loss: 0.3435, step time: 0.3985\n",
      "31/224, train_loss: 0.2486, step time: 0.3154\n",
      "32/224, train_loss: 0.2176, step time: 0.3178\n",
      "33/224, train_loss: 0.4060, step time: 0.4025\n",
      "34/224, train_loss: 0.2252, step time: 0.3808\n",
      "35/224, train_loss: 0.2106, step time: 0.3842\n",
      "36/224, train_loss: 0.3370, step time: 0.3178\n",
      "37/224, train_loss: 0.2482, step time: 0.3168\n",
      "38/224, train_loss: 0.2375, step time: 0.4022\n",
      "39/224, train_loss: 0.1995, step time: 0.3828\n",
      "40/224, train_loss: 0.1272, step time: 0.3169\n",
      "41/224, train_loss: 0.4604, step time: 0.3839\n",
      "42/224, train_loss: 0.1417, step time: 0.3781\n",
      "43/224, train_loss: 0.3206, step time: 0.3939\n",
      "44/224, train_loss: 0.2100, step time: 0.3862\n",
      "45/224, train_loss: 0.1386, step time: 0.3708\n",
      "46/224, train_loss: 0.1347, step time: 0.3972\n",
      "47/224, train_loss: 0.2343, step time: 0.3195\n",
      "48/224, train_loss: 0.3629, step time: 0.3157\n",
      "49/224, train_loss: 0.2377, step time: 0.3159\n",
      "50/224, train_loss: 0.2206, step time: 0.3156\n",
      "51/224, train_loss: 0.2217, step time: 0.3158\n",
      "52/224, train_loss: 0.3960, step time: 0.3144\n",
      "53/224, train_loss: 0.3292, step time: 0.3732\n",
      "54/224, train_loss: 0.2129, step time: 0.3806\n",
      "55/224, train_loss: 0.3623, step time: 0.4000\n",
      "56/224, train_loss: 0.2881, step time: 0.4063\n",
      "57/224, train_loss: 0.4431, step time: 0.3773\n",
      "58/224, train_loss: 0.2063, step time: 0.3148\n",
      "59/224, train_loss: 0.2734, step time: 0.4102\n",
      "60/224, train_loss: 0.2263, step time: 0.3170\n",
      "61/224, train_loss: 0.2120, step time: 0.3148\n",
      "62/224, train_loss: 0.1518, step time: 0.3150\n",
      "63/224, train_loss: 0.2265, step time: 0.4093\n",
      "64/224, train_loss: 0.3996, step time: 0.4011\n",
      "65/224, train_loss: 0.2605, step time: 0.3184\n",
      "66/224, train_loss: 0.2645, step time: 0.4031\n",
      "67/224, train_loss: 0.3393, step time: 0.3170\n",
      "68/224, train_loss: 0.1429, step time: 0.3167\n",
      "69/224, train_loss: 0.3540, step time: 0.3166\n",
      "70/224, train_loss: 0.2804, step time: 0.3964\n",
      "71/224, train_loss: 0.1279, step time: 0.3158\n",
      "72/224, train_loss: 0.2099, step time: 0.3956\n",
      "73/224, train_loss: 0.0925, step time: 0.3162\n",
      "74/224, train_loss: 0.4404, step time: 0.3871\n",
      "75/224, train_loss: 0.2031, step time: 0.3768\n",
      "76/224, train_loss: 0.2813, step time: 0.3814\n",
      "77/224, train_loss: 0.1732, step time: 0.4062\n",
      "78/224, train_loss: 0.1905, step time: 0.3151\n",
      "79/224, train_loss: 0.3524, step time: 0.3930\n",
      "80/224, train_loss: 0.1150, step time: 0.3152\n",
      "81/224, train_loss: 0.2066, step time: 0.3149\n",
      "82/224, train_loss: 0.2211, step time: 0.3130\n",
      "83/224, train_loss: 0.1695, step time: 0.3135\n",
      "84/224, train_loss: 0.1022, step time: 0.3156\n",
      "85/224, train_loss: 0.2891, step time: 0.3954\n",
      "86/224, train_loss: 0.2956, step time: 0.4028\n",
      "87/224, train_loss: 0.3911, step time: 0.3178\n",
      "88/224, train_loss: 0.1907, step time: 0.3151\n",
      "89/224, train_loss: 0.3023, step time: 0.4131\n",
      "90/224, train_loss: 0.4158, step time: 0.3822\n",
      "91/224, train_loss: 0.3179, step time: 0.3184\n",
      "92/224, train_loss: 0.2288, step time: 0.4006\n",
      "93/224, train_loss: 0.2261, step time: 0.3181\n",
      "94/224, train_loss: 0.1165, step time: 0.3698\n",
      "95/224, train_loss: 0.3652, step time: 0.3852\n",
      "96/224, train_loss: 0.3567, step time: 0.3132\n",
      "97/224, train_loss: 0.4724, step time: 0.3926\n",
      "98/224, train_loss: 0.3702, step time: 0.3134\n",
      "99/224, train_loss: 0.1810, step time: 0.3920\n",
      "100/224, train_loss: 0.4223, step time: 0.3183\n",
      "101/224, train_loss: 0.2593, step time: 0.3756\n",
      "102/224, train_loss: 0.1986, step time: 0.3155\n",
      "103/224, train_loss: 0.2252, step time: 0.4076\n",
      "104/224, train_loss: 0.3326, step time: 0.3159\n",
      "105/224, train_loss: 0.3807, step time: 0.4091\n",
      "106/224, train_loss: 0.2537, step time: 0.3164\n",
      "107/224, train_loss: 0.2333, step time: 0.3726\n",
      "108/224, train_loss: 0.3056, step time: 0.3762\n",
      "109/224, train_loss: 0.1827, step time: 0.4098\n",
      "110/224, train_loss: 0.1628, step time: 0.3165\n",
      "111/224, train_loss: 0.1803, step time: 0.3941\n",
      "112/224, train_loss: 0.3884, step time: 0.3169\n",
      "113/224, train_loss: 0.3256, step time: 0.3173\n",
      "114/224, train_loss: 0.3021, step time: 0.3810\n",
      "115/224, train_loss: 0.3826, step time: 0.4032\n",
      "116/224, train_loss: 0.2591, step time: 0.3194\n",
      "117/224, train_loss: 0.3228, step time: 0.3668\n",
      "118/224, train_loss: 0.4326, step time: 0.3996\n",
      "119/224, train_loss: 0.2395, step time: 0.3827\n",
      "120/224, train_loss: 0.4186, step time: 0.3189\n",
      "121/224, train_loss: 0.3887, step time: 0.3168\n",
      "122/224, train_loss: 0.2639, step time: 0.3722\n",
      "123/224, train_loss: 0.1390, step time: 0.4101\n",
      "124/224, train_loss: 0.2272, step time: 0.3781\n",
      "125/224, train_loss: 0.1684, step time: 0.3986\n",
      "126/224, train_loss: 0.2378, step time: 0.3172\n",
      "127/224, train_loss: 0.2151, step time: 0.3907\n",
      "128/224, train_loss: 0.2003, step time: 0.3176\n",
      "129/224, train_loss: 0.2212, step time: 0.3731\n",
      "130/224, train_loss: 0.2101, step time: 0.3976\n",
      "131/224, train_loss: 0.2620, step time: 0.3198\n",
      "132/224, train_loss: 0.3781, step time: 0.3151\n",
      "133/224, train_loss: 0.2398, step time: 0.3887\n",
      "134/224, train_loss: 0.3472, step time: 0.3930\n",
      "135/224, train_loss: 0.2267, step time: 0.3971\n",
      "136/224, train_loss: 0.2250, step time: 0.3159\n",
      "137/224, train_loss: 0.2375, step time: 0.4156\n",
      "138/224, train_loss: 0.2789, step time: 0.4122\n",
      "139/224, train_loss: 0.3648, step time: 0.3894\n",
      "140/224, train_loss: 0.1467, step time: 0.3798\n",
      "141/224, train_loss: 0.2676, step time: 0.3159\n",
      "142/224, train_loss: 0.2517, step time: 0.3131\n",
      "143/224, train_loss: 0.4516, step time: 0.3713\n",
      "144/224, train_loss: 0.4569, step time: 0.3777\n",
      "145/224, train_loss: 0.2448, step time: 0.3133\n",
      "146/224, train_loss: 0.3356, step time: 0.3958\n",
      "147/224, train_loss: 0.1192, step time: 0.3168\n",
      "148/224, train_loss: 0.2322, step time: 0.3168\n",
      "149/224, train_loss: 0.2439, step time: 0.3879\n",
      "150/224, train_loss: 0.2099, step time: 0.3181\n",
      "151/224, train_loss: 0.1204, step time: 0.3855\n",
      "152/224, train_loss: 0.1603, step time: 0.3160\n",
      "153/224, train_loss: 0.1659, step time: 0.3134\n",
      "154/224, train_loss: 0.2250, step time: 0.3139\n",
      "155/224, train_loss: 0.2774, step time: 0.3180\n",
      "156/224, train_loss: 0.3739, step time: 0.3175\n",
      "157/224, train_loss: 0.1267, step time: 0.3129\n",
      "158/224, train_loss: 0.3276, step time: 0.3139\n",
      "159/224, train_loss: 0.4639, step time: 0.3814\n",
      "160/224, train_loss: 0.2547, step time: 0.3155\n",
      "161/224, train_loss: 0.4140, step time: 0.3887\n",
      "162/224, train_loss: 0.2703, step time: 0.3138\n",
      "163/224, train_loss: 0.1886, step time: 0.3760\n",
      "164/224, train_loss: 0.3022, step time: 0.3971\n",
      "165/224, train_loss: 0.2749, step time: 0.3182\n",
      "166/224, train_loss: 0.2016, step time: 0.4099\n",
      "167/224, train_loss: 0.1456, step time: 0.3189\n",
      "168/224, train_loss: 0.2007, step time: 0.3180\n",
      "169/224, train_loss: 0.3464, step time: 0.3992\n",
      "170/224, train_loss: 0.2798, step time: 0.3862\n",
      "171/224, train_loss: 0.5176, step time: 0.3888\n",
      "172/224, train_loss: 0.3652, step time: 0.3183\n",
      "173/224, train_loss: 0.2019, step time: 0.3776\n",
      "174/224, train_loss: 0.1407, step time: 0.3147\n",
      "175/224, train_loss: 0.3242, step time: 0.3130\n",
      "176/224, train_loss: 0.3399, step time: 0.3133\n",
      "177/224, train_loss: 0.3587, step time: 0.3151\n",
      "178/224, train_loss: 0.1883, step time: 0.3155\n",
      "179/224, train_loss: 0.1924, step time: 0.3176\n",
      "180/224, train_loss: 0.1988, step time: 0.3147\n",
      "181/224, train_loss: 0.2447, step time: 0.3145\n",
      "182/224, train_loss: 0.2012, step time: 0.3691\n",
      "183/224, train_loss: 0.1586, step time: 0.4042\n",
      "184/224, train_loss: 0.2929, step time: 0.3205\n",
      "185/224, train_loss: 0.1684, step time: 0.3166\n",
      "186/224, train_loss: 0.4400, step time: 0.3158\n",
      "187/224, train_loss: 0.0947, step time: 0.3128\n",
      "188/224, train_loss: 0.1921, step time: 0.3933\n",
      "189/224, train_loss: 0.1344, step time: 0.3148\n",
      "190/224, train_loss: 0.2380, step time: 0.3178\n",
      "191/224, train_loss: 0.1605, step time: 0.3761\n",
      "192/224, train_loss: 0.3256, step time: 0.3141\n",
      "193/224, train_loss: 0.3527, step time: 0.3135\n",
      "194/224, train_loss: 0.3688, step time: 0.3706\n",
      "195/224, train_loss: 0.1451, step time: 0.4013\n",
      "196/224, train_loss: 0.2656, step time: 0.3173\n",
      "197/224, train_loss: 0.3049, step time: 0.3702\n",
      "198/224, train_loss: 0.1522, step time: 0.3183\n",
      "199/224, train_loss: 0.3043, step time: 0.3740\n",
      "200/224, train_loss: 0.1923, step time: 0.3172\n",
      "201/224, train_loss: 0.1872, step time: 0.4041\n",
      "202/224, train_loss: 0.1597, step time: 0.3149\n",
      "203/224, train_loss: 0.1664, step time: 0.4051\n",
      "204/224, train_loss: 0.4003, step time: 0.3827\n",
      "205/224, train_loss: 0.3395, step time: 0.3893\n",
      "206/224, train_loss: 0.1296, step time: 0.3916\n",
      "207/224, train_loss: 0.3705, step time: 0.3158\n",
      "208/224, train_loss: 0.2706, step time: 0.3722\n",
      "209/224, train_loss: 0.3131, step time: 0.3875\n",
      "210/224, train_loss: 0.2875, step time: 0.3794\n",
      "211/224, train_loss: 0.1886, step time: 0.3155\n",
      "212/224, train_loss: 0.3554, step time: 0.3174\n",
      "213/224, train_loss: 0.2078, step time: 0.3176\n",
      "214/224, train_loss: 0.2875, step time: 0.3825\n",
      "215/224, train_loss: 0.1757, step time: 0.4021\n",
      "216/224, train_loss: 0.2168, step time: 0.3179\n",
      "217/224, train_loss: 0.2402, step time: 0.3956\n",
      "218/224, train_loss: 0.3806, step time: 0.3175\n",
      "219/224, train_loss: 0.1866, step time: 0.4084\n",
      "220/224, train_loss: 0.3792, step time: 0.3166\n",
      "221/224, train_loss: 0.1892, step time: 0.4013\n",
      "222/224, train_loss: 0.1130, step time: 0.3149\n",
      "223/224, train_loss: 0.1920, step time: 0.3195\n",
      "224/224, train_loss: 0.3677, step time: 0.3724\n",
      "epoch 23 average loss: 0.2614\n",
      "current epoch: 23 current mean dice: 0.6835 class1: 0.9987 class2: 0.7289 class3: 0.3228\n",
      "best mean dice: 0.6835 at epoch: 23\n",
      "time consuming of epoch 23 is: 734.5455\n",
      "hello\n",
      "----------\n",
      "epoch 24/100\n",
      "1/224, train_loss: 0.4126, step time: 0.3173\n",
      "2/224, train_loss: 0.1603, step time: 0.3709\n",
      "3/224, train_loss: 0.1626, step time: 0.3165\n",
      "4/224, train_loss: 0.1775, step time: 0.3855\n",
      "5/224, train_loss: 0.1542, step time: 0.3144\n",
      "6/224, train_loss: 0.1407, step time: 0.3169\n",
      "7/224, train_loss: 0.3429, step time: 0.3163\n",
      "8/224, train_loss: 0.2320, step time: 0.4017\n",
      "9/224, train_loss: 0.2261, step time: 0.3953\n",
      "10/224, train_loss: 0.1748, step time: 0.3918\n",
      "11/224, train_loss: 0.1229, step time: 0.3173\n",
      "12/224, train_loss: 0.3313, step time: 0.3960\n",
      "13/224, train_loss: 0.3474, step time: 0.3982\n",
      "14/224, train_loss: 0.1503, step time: 0.4101\n",
      "15/224, train_loss: 0.3018, step time: 0.3176\n",
      "16/224, train_loss: 0.3062, step time: 0.3148\n",
      "17/224, train_loss: 0.2686, step time: 0.3200\n",
      "18/224, train_loss: 0.3634, step time: 0.4090\n",
      "19/224, train_loss: 0.2108, step time: 0.3167\n",
      "20/224, train_loss: 0.2572, step time: 0.3150\n",
      "21/224, train_loss: 0.2718, step time: 0.3180\n",
      "22/224, train_loss: 0.1580, step time: 0.4003\n",
      "23/224, train_loss: 0.3783, step time: 0.3928\n",
      "24/224, train_loss: 0.1979, step time: 0.3784\n",
      "25/224, train_loss: 0.1747, step time: 0.3912\n",
      "26/224, train_loss: 0.3711, step time: 0.3140\n",
      "27/224, train_loss: 0.1147, step time: 0.3915\n",
      "28/224, train_loss: 0.2016, step time: 0.3814\n",
      "29/224, train_loss: 0.1368, step time: 0.3801\n",
      "30/224, train_loss: 0.2208, step time: 0.3171\n",
      "31/224, train_loss: 0.3448, step time: 0.3828\n",
      "32/224, train_loss: 0.2012, step time: 0.3781\n",
      "33/224, train_loss: 0.3921, step time: 0.4134\n",
      "34/224, train_loss: 0.2288, step time: 0.3977\n",
      "35/224, train_loss: 0.1465, step time: 0.3174\n",
      "36/224, train_loss: 0.1426, step time: 0.4008\n",
      "37/224, train_loss: 0.2175, step time: 0.3196\n",
      "38/224, train_loss: 0.2319, step time: 0.3762\n",
      "39/224, train_loss: 0.1457, step time: 0.3653\n",
      "40/224, train_loss: 0.1239, step time: 0.3147\n",
      "41/224, train_loss: 0.3663, step time: 0.3989\n",
      "42/224, train_loss: 0.1481, step time: 0.3748\n",
      "43/224, train_loss: 0.2825, step time: 0.4049\n",
      "44/224, train_loss: 0.1824, step time: 0.3991\n",
      "45/224, train_loss: 0.4460, step time: 0.4160\n",
      "46/224, train_loss: 0.4049, step time: 0.3176\n",
      "47/224, train_loss: 0.2094, step time: 0.3825\n",
      "48/224, train_loss: 0.2436, step time: 0.3796\n",
      "49/224, train_loss: 0.1539, step time: 0.3709\n",
      "50/224, train_loss: 0.3593, step time: 0.3183\n",
      "51/224, train_loss: 0.2698, step time: 0.3856\n",
      "52/224, train_loss: 0.2414, step time: 0.3955\n",
      "53/224, train_loss: 0.2290, step time: 0.3160\n",
      "54/224, train_loss: 0.3602, step time: 0.3160\n",
      "55/224, train_loss: 0.2248, step time: 0.3187\n",
      "56/224, train_loss: 0.3727, step time: 0.3163\n",
      "57/224, train_loss: 0.1581, step time: 0.3806\n",
      "58/224, train_loss: 0.1599, step time: 0.3138\n",
      "59/224, train_loss: 0.2133, step time: 0.3191\n",
      "60/224, train_loss: 0.2364, step time: 0.3190\n",
      "61/224, train_loss: 0.2141, step time: 0.3170\n",
      "62/224, train_loss: 0.2365, step time: 0.3787\n",
      "63/224, train_loss: 0.4692, step time: 0.3771\n",
      "64/224, train_loss: 0.1642, step time: 0.3943\n",
      "65/224, train_loss: 0.2785, step time: 0.3849\n",
      "66/224, train_loss: 0.1935, step time: 0.3813\n",
      "67/224, train_loss: 0.3402, step time: 0.4061\n",
      "68/224, train_loss: 0.2758, step time: 0.3921\n",
      "69/224, train_loss: 0.1764, step time: 0.3808\n",
      "70/224, train_loss: 0.2236, step time: 0.3749\n",
      "71/224, train_loss: 0.2570, step time: 0.3929\n",
      "72/224, train_loss: 0.3527, step time: 0.3834\n",
      "73/224, train_loss: 0.3732, step time: 0.3133\n",
      "74/224, train_loss: 0.1945, step time: 0.3808\n",
      "75/224, train_loss: 0.2714, step time: 0.3174\n",
      "76/224, train_loss: 0.2954, step time: 0.3148\n",
      "77/224, train_loss: 0.2022, step time: 0.3182\n",
      "78/224, train_loss: 0.4693, step time: 0.4086\n",
      "79/224, train_loss: 0.1550, step time: 0.3184\n",
      "80/224, train_loss: 0.2366, step time: 0.3917\n",
      "81/224, train_loss: 0.1458, step time: 0.4029\n",
      "82/224, train_loss: 0.1938, step time: 0.3160\n",
      "83/224, train_loss: 0.4372, step time: 0.3157\n",
      "84/224, train_loss: 0.1610, step time: 0.3906\n",
      "85/224, train_loss: 0.3304, step time: 0.3136\n",
      "86/224, train_loss: 0.2606, step time: 0.3185\n",
      "87/224, train_loss: 0.1578, step time: 0.3713\n",
      "88/224, train_loss: 0.3647, step time: 0.3741\n",
      "89/224, train_loss: 0.3866, step time: 0.3161\n",
      "90/224, train_loss: 0.3881, step time: 0.4012\n",
      "91/224, train_loss: 0.2956, step time: 0.3714\n",
      "92/224, train_loss: 0.2146, step time: 0.3202\n",
      "93/224, train_loss: 0.3014, step time: 0.3175\n",
      "94/224, train_loss: 0.4675, step time: 0.3853\n",
      "95/224, train_loss: 0.3786, step time: 0.3211\n",
      "96/224, train_loss: 0.1795, step time: 0.3179\n",
      "97/224, train_loss: 0.1529, step time: 0.3183\n",
      "98/224, train_loss: 0.2903, step time: 0.3877\n",
      "99/224, train_loss: 0.2454, step time: 0.3781\n",
      "100/224, train_loss: 0.3535, step time: 0.3180\n",
      "101/224, train_loss: 0.1545, step time: 0.3890\n",
      "102/224, train_loss: 0.1834, step time: 0.3173\n",
      "103/224, train_loss: 0.1377, step time: 0.3173\n",
      "104/224, train_loss: 0.3593, step time: 0.3206\n",
      "105/224, train_loss: 0.3465, step time: 0.3684\n",
      "106/224, train_loss: 0.3481, step time: 0.3755\n",
      "107/224, train_loss: 0.1265, step time: 0.3190\n",
      "108/224, train_loss: 0.1999, step time: 0.3173\n",
      "109/224, train_loss: 0.1225, step time: 0.3824\n",
      "110/224, train_loss: 0.2269, step time: 0.3185\n",
      "111/224, train_loss: 0.4391, step time: 0.3788\n",
      "112/224, train_loss: 0.2774, step time: 0.3199\n",
      "113/224, train_loss: 0.3772, step time: 0.3165\n",
      "114/224, train_loss: 0.3724, step time: 0.3823\n",
      "115/224, train_loss: 0.2592, step time: 0.3872\n",
      "116/224, train_loss: 0.2076, step time: 0.3186\n",
      "117/224, train_loss: 0.1497, step time: 0.4109\n",
      "118/224, train_loss: 0.2578, step time: 0.3173\n",
      "119/224, train_loss: 0.2469, step time: 0.3199\n",
      "120/224, train_loss: 0.2908, step time: 0.3146\n",
      "121/224, train_loss: 0.1928, step time: 0.3168\n",
      "122/224, train_loss: 0.2921, step time: 0.3856\n",
      "123/224, train_loss: 0.1483, step time: 0.3164\n",
      "124/224, train_loss: 0.1480, step time: 0.3193\n",
      "125/224, train_loss: 0.2797, step time: 0.3848\n",
      "126/224, train_loss: 0.3126, step time: 0.3184\n",
      "127/224, train_loss: 0.2786, step time: 0.3186\n",
      "128/224, train_loss: 0.3949, step time: 0.3859\n",
      "129/224, train_loss: 0.3235, step time: 0.3803\n",
      "130/224, train_loss: 0.4437, step time: 0.3778\n",
      "131/224, train_loss: 0.2025, step time: 0.3946\n",
      "132/224, train_loss: 0.1806, step time: 0.3668\n",
      "133/224, train_loss: 0.1663, step time: 0.3168\n",
      "134/224, train_loss: 0.1587, step time: 0.3999\n",
      "135/224, train_loss: 0.3598, step time: 0.4030\n",
      "136/224, train_loss: 0.2653, step time: 0.4138\n",
      "137/224, train_loss: 0.3138, step time: 0.3882\n",
      "138/224, train_loss: 0.3313, step time: 0.3172\n",
      "139/224, train_loss: 0.2270, step time: 0.3756\n",
      "140/224, train_loss: 0.2077, step time: 0.3189\n",
      "141/224, train_loss: 0.3206, step time: 0.3165\n",
      "142/224, train_loss: 0.1805, step time: 0.3170\n",
      "143/224, train_loss: 0.2372, step time: 0.3156\n",
      "144/224, train_loss: 0.1188, step time: 0.3195\n",
      "145/224, train_loss: 0.2270, step time: 0.3168\n",
      "146/224, train_loss: 0.1533, step time: 0.3917\n",
      "147/224, train_loss: 0.3799, step time: 0.3164\n",
      "148/224, train_loss: 0.4545, step time: 0.3170\n",
      "149/224, train_loss: 0.2873, step time: 0.4136\n",
      "150/224, train_loss: 0.1472, step time: 0.3166\n",
      "151/224, train_loss: 0.3714, step time: 0.3144\n",
      "152/224, train_loss: 0.2562, step time: 0.3164\n",
      "153/224, train_loss: 0.1759, step time: 0.3188\n",
      "154/224, train_loss: 0.2928, step time: 0.3163\n",
      "155/224, train_loss: 0.2144, step time: 0.3170\n",
      "156/224, train_loss: 0.2407, step time: 0.3172\n",
      "157/224, train_loss: 0.1939, step time: 0.3905\n",
      "158/224, train_loss: 0.1638, step time: 0.3799\n",
      "159/224, train_loss: 0.1058, step time: 0.4041\n",
      "160/224, train_loss: 0.2585, step time: 0.3148\n",
      "161/224, train_loss: 0.3233, step time: 0.3186\n",
      "162/224, train_loss: 0.1520, step time: 0.3721\n",
      "163/224, train_loss: 0.2533, step time: 0.3152\n",
      "164/224, train_loss: 0.3408, step time: 0.3871\n",
      "165/224, train_loss: 0.3838, step time: 0.3943\n",
      "166/224, train_loss: 0.1565, step time: 0.3834\n",
      "167/224, train_loss: 0.4182, step time: 0.4057\n",
      "168/224, train_loss: 0.1405, step time: 0.3882\n",
      "169/224, train_loss: 0.3206, step time: 0.4058\n",
      "170/224, train_loss: 0.3839, step time: 0.4009\n",
      "171/224, train_loss: 0.1848, step time: 0.3171\n",
      "172/224, train_loss: 0.1768, step time: 0.3168\n",
      "173/224, train_loss: 0.3129, step time: 0.3166\n",
      "174/224, train_loss: 0.1957, step time: 0.3153\n",
      "175/224, train_loss: 0.4555, step time: 0.3191\n",
      "176/224, train_loss: 0.2663, step time: 0.3691\n",
      "177/224, train_loss: 0.2826, step time: 0.3693\n",
      "178/224, train_loss: 0.3244, step time: 0.3818\n",
      "179/224, train_loss: 0.2385, step time: 0.3186\n",
      "180/224, train_loss: 0.1104, step time: 0.3166\n",
      "181/224, train_loss: 0.3689, step time: 0.3171\n",
      "182/224, train_loss: 0.3149, step time: 0.3173\n",
      "183/224, train_loss: 0.3456, step time: 0.3826\n",
      "184/224, train_loss: 0.4006, step time: 0.3178\n",
      "185/224, train_loss: 0.1599, step time: 0.3806\n",
      "186/224, train_loss: 0.3672, step time: 0.3181\n",
      "187/224, train_loss: 0.3265, step time: 0.3982\n",
      "188/224, train_loss: 0.3250, step time: 0.3917\n",
      "189/224, train_loss: 0.1425, step time: 0.3195\n",
      "190/224, train_loss: 0.3700, step time: 0.3175\n",
      "191/224, train_loss: 0.1212, step time: 0.4072\n",
      "192/224, train_loss: 0.3661, step time: 0.4067\n",
      "193/224, train_loss: 0.3620, step time: 0.4117\n",
      "194/224, train_loss: 0.2618, step time: 0.3670\n",
      "195/224, train_loss: 0.3711, step time: 0.3722\n",
      "196/224, train_loss: 0.2419, step time: 0.3997\n",
      "197/224, train_loss: 0.2477, step time: 0.3722\n",
      "198/224, train_loss: 0.2964, step time: 0.3162\n",
      "199/224, train_loss: 0.2558, step time: 0.3145\n",
      "200/224, train_loss: 0.2000, step time: 0.3163\n",
      "201/224, train_loss: 0.2807, step time: 0.3172\n",
      "202/224, train_loss: 0.3873, step time: 0.3171\n",
      "203/224, train_loss: 0.2701, step time: 0.3172\n",
      "204/224, train_loss: 0.3024, step time: 0.3175\n",
      "205/224, train_loss: 0.2958, step time: 0.4123\n",
      "206/224, train_loss: 0.1680, step time: 0.3853\n",
      "207/224, train_loss: 0.2932, step time: 0.3181\n",
      "208/224, train_loss: 0.3887, step time: 0.3921\n",
      "209/224, train_loss: 0.2511, step time: 0.4035\n",
      "210/224, train_loss: 0.2139, step time: 0.3164\n",
      "211/224, train_loss: 0.2063, step time: 0.3865\n",
      "212/224, train_loss: 0.1770, step time: 0.3770\n",
      "213/224, train_loss: 0.2385, step time: 0.3879\n",
      "214/224, train_loss: 0.3169, step time: 0.3158\n",
      "215/224, train_loss: 0.1961, step time: 0.3160\n",
      "216/224, train_loss: 0.3235, step time: 0.3957\n",
      "217/224, train_loss: 0.1912, step time: 0.3949\n",
      "218/224, train_loss: 0.1264, step time: 0.3157\n",
      "219/224, train_loss: 0.3399, step time: 0.3829\n",
      "220/224, train_loss: 0.4318, step time: 0.3698\n",
      "221/224, train_loss: 0.1485, step time: 0.4160\n",
      "222/224, train_loss: 0.2316, step time: 0.3179\n",
      "223/224, train_loss: 0.2166, step time: 0.3180\n",
      "224/224, train_loss: 0.3825, step time: 0.3194\n",
      "epoch 24 average loss: 0.2604\n",
      "current epoch: 24 current mean dice: 0.6661 class1: 0.9987 class2: 0.7121 class3: 0.2876\n",
      "best mean dice: 0.6835 at epoch: 23\n",
      "time consuming of epoch 24 is: 764.1213\n",
      "hello\n",
      "----------\n",
      "epoch 25/100\n",
      "1/224, train_loss: 0.3523, step time: 0.3196\n",
      "2/224, train_loss: 0.1815, step time: 0.4089\n",
      "3/224, train_loss: 0.1513, step time: 0.3903\n",
      "4/224, train_loss: 0.1760, step time: 0.3957\n",
      "5/224, train_loss: 0.1749, step time: 0.3912\n",
      "6/224, train_loss: 0.3055, step time: 0.3186\n",
      "7/224, train_loss: 0.2217, step time: 0.3824\n",
      "8/224, train_loss: 0.1643, step time: 0.3166\n",
      "9/224, train_loss: 0.2292, step time: 0.3898\n",
      "10/224, train_loss: 0.2764, step time: 0.3151\n",
      "11/224, train_loss: 0.4887, step time: 0.3877\n",
      "12/224, train_loss: 0.2359, step time: 0.3830\n",
      "13/224, train_loss: 0.1626, step time: 0.3934\n",
      "14/224, train_loss: 0.3448, step time: 0.3150\n",
      "15/224, train_loss: 0.1603, step time: 0.3197\n",
      "16/224, train_loss: 0.3112, step time: 0.3965\n",
      "17/224, train_loss: 0.4498, step time: 0.3729\n",
      "18/224, train_loss: 0.2743, step time: 0.3193\n",
      "19/224, train_loss: 0.4020, step time: 0.3171\n",
      "20/224, train_loss: 0.2914, step time: 0.3766\n",
      "21/224, train_loss: 0.3556, step time: 0.3161\n",
      "22/224, train_loss: 0.0878, step time: 0.4007\n",
      "23/224, train_loss: 0.2227, step time: 0.3935\n",
      "24/224, train_loss: 0.1420, step time: 0.3891\n",
      "25/224, train_loss: 0.1146, step time: 0.4053\n",
      "26/224, train_loss: 0.2807, step time: 0.3735\n",
      "27/224, train_loss: 0.3186, step time: 0.3174\n",
      "28/224, train_loss: 0.3320, step time: 0.3181\n",
      "29/224, train_loss: 0.3234, step time: 0.4062\n",
      "30/224, train_loss: 0.3805, step time: 0.3997\n",
      "31/224, train_loss: 0.2036, step time: 0.3690\n",
      "32/224, train_loss: 0.2454, step time: 0.4038\n",
      "33/224, train_loss: 0.2769, step time: 0.3795\n",
      "34/224, train_loss: 0.2523, step time: 0.3200\n",
      "35/224, train_loss: 0.3276, step time: 0.3178\n",
      "36/224, train_loss: 0.2392, step time: 0.3801\n",
      "37/224, train_loss: 0.2302, step time: 0.3688\n",
      "38/224, train_loss: 0.1872, step time: 0.3172\n",
      "39/224, train_loss: 0.3552, step time: 0.3179\n",
      "40/224, train_loss: 0.2017, step time: 0.4017\n",
      "41/224, train_loss: 0.3051, step time: 0.4074\n",
      "42/224, train_loss: 0.1428, step time: 0.3979\n",
      "43/224, train_loss: 0.1656, step time: 0.3168\n",
      "44/224, train_loss: 0.2228, step time: 0.3196\n",
      "45/224, train_loss: 0.1974, step time: 0.3763\n",
      "46/224, train_loss: 0.1979, step time: 0.4014\n",
      "47/224, train_loss: 0.1480, step time: 0.3957\n",
      "48/224, train_loss: 0.1248, step time: 0.4037\n",
      "49/224, train_loss: 0.2058, step time: 0.3193\n",
      "50/224, train_loss: 0.3537, step time: 0.3737\n",
      "51/224, train_loss: 0.1517, step time: 0.3197\n",
      "52/224, train_loss: 0.3035, step time: 0.4077\n",
      "53/224, train_loss: 0.3753, step time: 0.3197\n",
      "54/224, train_loss: 0.2597, step time: 0.3162\n",
      "55/224, train_loss: 0.2040, step time: 0.3760\n",
      "56/224, train_loss: 0.3930, step time: 0.3197\n",
      "57/224, train_loss: 0.1171, step time: 0.4050\n",
      "58/224, train_loss: 0.1373, step time: 0.3179\n",
      "59/224, train_loss: 0.4022, step time: 0.3177\n",
      "60/224, train_loss: 0.3135, step time: 0.3833\n",
      "61/224, train_loss: 0.1552, step time: 0.3930\n",
      "62/224, train_loss: 0.2685, step time: 0.3873\n",
      "63/224, train_loss: 0.4603, step time: 0.3823\n",
      "64/224, train_loss: 0.3624, step time: 0.3718\n",
      "65/224, train_loss: 0.1529, step time: 0.3159\n",
      "66/224, train_loss: 0.3889, step time: 0.3175\n",
      "67/224, train_loss: 0.3630, step time: 0.3178\n",
      "68/224, train_loss: 0.1801, step time: 0.3951\n",
      "69/224, train_loss: 0.2908, step time: 0.3917\n",
      "70/224, train_loss: 0.1369, step time: 0.3179\n",
      "71/224, train_loss: 0.3780, step time: 0.3839\n",
      "72/224, train_loss: 0.4608, step time: 0.3158\n",
      "73/224, train_loss: 0.3314, step time: 0.3666\n",
      "74/224, train_loss: 0.3726, step time: 0.3761\n",
      "75/224, train_loss: 0.3068, step time: 0.3826\n",
      "76/224, train_loss: 0.2075, step time: 0.3173\n",
      "77/224, train_loss: 0.1725, step time: 0.3791\n",
      "78/224, train_loss: 0.1573, step time: 0.3153\n",
      "79/224, train_loss: 0.2317, step time: 0.3131\n",
      "80/224, train_loss: 0.4344, step time: 0.3927\n",
      "81/224, train_loss: 0.4206, step time: 0.3726\n",
      "82/224, train_loss: 0.1960, step time: 0.4092\n",
      "83/224, train_loss: 0.1613, step time: 0.3149\n",
      "84/224, train_loss: 0.3529, step time: 0.3179\n",
      "85/224, train_loss: 0.2411, step time: 0.3175\n",
      "86/224, train_loss: 0.2115, step time: 0.3873\n",
      "87/224, train_loss: 0.3914, step time: 0.3709\n",
      "88/224, train_loss: 0.2897, step time: 0.3751\n",
      "89/224, train_loss: 0.1044, step time: 0.4003\n",
      "90/224, train_loss: 0.4604, step time: 0.3903\n",
      "91/224, train_loss: 0.3262, step time: 0.3701\n",
      "92/224, train_loss: 0.1169, step time: 0.3184\n",
      "93/224, train_loss: 0.3253, step time: 0.4010\n",
      "94/224, train_loss: 0.3543, step time: 0.3158\n",
      "95/224, train_loss: 0.2209, step time: 0.3165\n",
      "96/224, train_loss: 0.3535, step time: 0.3164\n",
      "97/224, train_loss: 0.1537, step time: 0.3747\n",
      "98/224, train_loss: 0.2525, step time: 0.3163\n",
      "99/224, train_loss: 0.2252, step time: 0.3775\n",
      "100/224, train_loss: 0.1793, step time: 0.3711\n",
      "101/224, train_loss: 0.3515, step time: 0.3695\n",
      "102/224, train_loss: 0.1750, step time: 0.3192\n",
      "103/224, train_loss: 0.2976, step time: 0.3872\n",
      "104/224, train_loss: 0.1537, step time: 0.3149\n",
      "105/224, train_loss: 0.2164, step time: 0.3200\n",
      "106/224, train_loss: 0.3467, step time: 0.3156\n",
      "107/224, train_loss: 0.2047, step time: 0.3196\n",
      "108/224, train_loss: 0.1413, step time: 0.3691\n",
      "109/224, train_loss: 0.2350, step time: 0.3862\n",
      "110/224, train_loss: 0.3393, step time: 0.3165\n",
      "111/224, train_loss: 0.3402, step time: 0.3808\n",
      "112/224, train_loss: 0.2458, step time: 0.3178\n",
      "113/224, train_loss: 0.2317, step time: 0.3189\n",
      "114/224, train_loss: 0.2178, step time: 0.3184\n",
      "115/224, train_loss: 0.1950, step time: 0.3162\n",
      "116/224, train_loss: 0.2507, step time: 0.3190\n",
      "117/224, train_loss: 0.1679, step time: 0.4048\n",
      "118/224, train_loss: 0.1422, step time: 0.3168\n",
      "119/224, train_loss: 0.4439, step time: 0.3177\n",
      "120/224, train_loss: 0.4474, step time: 0.3663\n",
      "121/224, train_loss: 0.1738, step time: 0.3176\n",
      "122/224, train_loss: 0.1939, step time: 0.3199\n",
      "123/224, train_loss: 0.3696, step time: 0.3183\n",
      "124/224, train_loss: 0.1860, step time: 0.3905\n",
      "125/224, train_loss: 0.1258, step time: 0.3174\n",
      "126/224, train_loss: 0.1749, step time: 0.3168\n",
      "127/224, train_loss: 0.2507, step time: 0.4000\n",
      "128/224, train_loss: 0.2793, step time: 0.3174\n",
      "129/224, train_loss: 0.2483, step time: 0.4062\n",
      "130/224, train_loss: 0.3642, step time: 0.3189\n",
      "131/224, train_loss: 0.2788, step time: 0.4025\n",
      "132/224, train_loss: 0.4442, step time: 0.3849\n",
      "133/224, train_loss: 0.2956, step time: 0.3175\n",
      "134/224, train_loss: 0.1322, step time: 0.3155\n",
      "135/224, train_loss: 0.2170, step time: 0.3188\n",
      "136/224, train_loss: 0.3942, step time: 0.4131\n",
      "137/224, train_loss: 0.1301, step time: 0.3177\n",
      "138/224, train_loss: 0.1050, step time: 0.4152\n",
      "139/224, train_loss: 0.1585, step time: 0.3161\n",
      "140/224, train_loss: 0.1603, step time: 0.3160\n",
      "141/224, train_loss: 0.2045, step time: 0.3150\n",
      "142/224, train_loss: 0.1855, step time: 0.3199\n",
      "143/224, train_loss: 0.1913, step time: 0.3167\n",
      "144/224, train_loss: 0.2221, step time: 0.3167\n",
      "145/224, train_loss: 0.4008, step time: 0.4083\n",
      "146/224, train_loss: 0.3209, step time: 0.3791\n",
      "147/224, train_loss: 0.2608, step time: 0.3170\n",
      "148/224, train_loss: 0.1809, step time: 0.3169\n",
      "149/224, train_loss: 0.3361, step time: 0.3182\n",
      "150/224, train_loss: 0.3808, step time: 0.3167\n",
      "151/224, train_loss: 0.1903, step time: 0.3946\n",
      "152/224, train_loss: 0.2442, step time: 0.3189\n",
      "153/224, train_loss: 0.4367, step time: 0.3930\n",
      "154/224, train_loss: 0.1062, step time: 0.3173\n",
      "155/224, train_loss: 0.1765, step time: 0.3159\n",
      "156/224, train_loss: 0.3583, step time: 0.3180\n",
      "157/224, train_loss: 0.1522, step time: 0.3695\n",
      "158/224, train_loss: 0.3952, step time: 0.5498\n",
      "159/224, train_loss: 0.1473, step time: 0.3198\n",
      "160/224, train_loss: 0.1265, step time: 0.3173\n",
      "161/224, train_loss: 0.3068, step time: 0.3174\n",
      "162/224, train_loss: 0.1262, step time: 0.3175\n",
      "163/224, train_loss: 0.1898, step time: 0.3154\n",
      "164/224, train_loss: 0.3564, step time: 0.3905\n",
      "165/224, train_loss: 0.2866, step time: 0.3765\n",
      "166/224, train_loss: 0.3697, step time: 0.3976\n",
      "167/224, train_loss: 0.2356, step time: 0.3953\n",
      "168/224, train_loss: 0.2347, step time: 0.3879\n",
      "169/224, train_loss: 0.0924, step time: 0.3178\n",
      "170/224, train_loss: 0.2253, step time: 0.3832\n",
      "171/224, train_loss: 0.1294, step time: 0.3150\n",
      "172/224, train_loss: 0.1371, step time: 0.3147\n",
      "173/224, train_loss: 0.3795, step time: 0.3148\n",
      "174/224, train_loss: 0.4370, step time: 0.3149\n",
      "175/224, train_loss: 0.3678, step time: 0.3146\n",
      "176/224, train_loss: 0.1870, step time: 0.3171\n",
      "177/224, train_loss: 0.3618, step time: 0.3126\n",
      "178/224, train_loss: 0.1891, step time: 0.3683\n",
      "179/224, train_loss: 0.3624, step time: 0.3675\n",
      "180/224, train_loss: 0.1377, step time: 0.3134\n",
      "181/224, train_loss: 0.2428, step time: 0.3131\n",
      "182/224, train_loss: 0.1332, step time: 0.3124\n",
      "183/224, train_loss: 0.1782, step time: 0.3124\n",
      "184/224, train_loss: 0.1790, step time: 0.3148\n",
      "185/224, train_loss: 0.1690, step time: 0.3146\n",
      "186/224, train_loss: 0.2563, step time: 0.3152\n",
      "187/224, train_loss: 0.3589, step time: 0.3146\n",
      "188/224, train_loss: 0.2553, step time: 0.3147\n",
      "189/224, train_loss: 0.3442, step time: 0.3168\n",
      "190/224, train_loss: 0.2769, step time: 0.3955\n",
      "191/224, train_loss: 0.2039, step time: 0.3160\n",
      "192/224, train_loss: 0.2479, step time: 0.3885\n",
      "193/224, train_loss: 0.2367, step time: 0.3853\n",
      "194/224, train_loss: 0.1235, step time: 0.3172\n",
      "195/224, train_loss: 0.3062, step time: 0.3833\n",
      "196/224, train_loss: 0.2053, step time: 0.3874\n",
      "197/224, train_loss: 0.2025, step time: 0.3164\n",
      "198/224, train_loss: 0.3521, step time: 0.3189\n",
      "199/224, train_loss: 0.3578, step time: 0.3775\n",
      "200/224, train_loss: 0.1602, step time: 0.3164\n",
      "201/224, train_loss: 0.1982, step time: 0.3914\n",
      "202/224, train_loss: 0.2330, step time: 0.3194\n",
      "203/224, train_loss: 0.3301, step time: 0.3183\n",
      "204/224, train_loss: 0.3176, step time: 0.3185\n",
      "205/224, train_loss: 0.1469, step time: 0.4137\n",
      "206/224, train_loss: 0.1804, step time: 0.3166\n",
      "207/224, train_loss: 0.3528, step time: 0.3804\n",
      "208/224, train_loss: 0.1180, step time: 0.3188\n",
      "209/224, train_loss: 0.2721, step time: 0.3188\n",
      "210/224, train_loss: 0.2052, step time: 0.3731\n",
      "211/224, train_loss: 0.2955, step time: 0.3172\n",
      "212/224, train_loss: 0.2176, step time: 0.3192\n",
      "213/224, train_loss: 0.1490, step time: 0.3935\n",
      "214/224, train_loss: 0.2482, step time: 0.3157\n",
      "215/224, train_loss: 0.1792, step time: 0.3813\n",
      "216/224, train_loss: 0.1371, step time: 0.3799\n",
      "217/224, train_loss: 0.4637, step time: 0.4017\n",
      "218/224, train_loss: 0.2159, step time: 0.3945\n",
      "219/224, train_loss: 0.2018, step time: 0.3967\n",
      "220/224, train_loss: 0.2427, step time: 0.3169\n",
      "221/224, train_loss: 0.2547, step time: 0.4005\n",
      "222/224, train_loss: 0.2990, step time: 0.4129\n",
      "223/224, train_loss: 0.1287, step time: 0.3170\n",
      "224/224, train_loss: 0.2989, step time: 0.3638\n",
      "epoch 25 average loss: 0.2533\n",
      "current epoch: 25 current mean dice: 0.6741 class1: 0.9990 class2: 0.7026 class3: 0.3207\n",
      "best mean dice: 0.6835 at epoch: 23\n",
      "time consuming of epoch 25 is: 708.6109\n",
      "hello\n",
      "----------\n",
      "epoch 26/100\n",
      "1/224, train_loss: 0.1178, step time: 0.3174\n",
      "2/224, train_loss: 0.1977, step time: 0.3726\n",
      "3/224, train_loss: 0.2618, step time: 0.3176\n",
      "4/224, train_loss: 0.1136, step time: 0.3181\n",
      "5/224, train_loss: 0.3620, step time: 0.3874\n",
      "6/224, train_loss: 0.2030, step time: 0.3931\n",
      "7/224, train_loss: 0.1726, step time: 0.3169\n",
      "8/224, train_loss: 0.1994, step time: 0.4112\n",
      "9/224, train_loss: 0.1637, step time: 0.3175\n",
      "10/224, train_loss: 0.2459, step time: 0.3203\n",
      "11/224, train_loss: 0.3205, step time: 0.3174\n",
      "12/224, train_loss: 0.1572, step time: 0.3901\n",
      "13/224, train_loss: 0.1835, step time: 0.3182\n",
      "14/224, train_loss: 0.1702, step time: 0.3871\n",
      "15/224, train_loss: 0.3698, step time: 0.3144\n",
      "16/224, train_loss: 0.3764, step time: 0.3187\n",
      "17/224, train_loss: 0.3458, step time: 0.3169\n",
      "18/224, train_loss: 0.1088, step time: 0.3742\n",
      "19/224, train_loss: 0.1646, step time: 0.4123\n",
      "20/224, train_loss: 0.3746, step time: 0.3850\n",
      "21/224, train_loss: 0.3884, step time: 0.4105\n",
      "22/224, train_loss: 0.2216, step time: 0.3673\n",
      "23/224, train_loss: 0.3792, step time: 0.3881\n",
      "24/224, train_loss: 0.1397, step time: 0.3171\n",
      "25/224, train_loss: 0.3799, step time: 0.3171\n",
      "26/224, train_loss: 0.3599, step time: 0.3174\n",
      "27/224, train_loss: 0.3556, step time: 0.4098\n",
      "28/224, train_loss: 0.1433, step time: 0.3171\n",
      "29/224, train_loss: 0.3769, step time: 0.3889\n",
      "30/224, train_loss: 0.2439, step time: 0.3195\n",
      "31/224, train_loss: 0.1474, step time: 0.3171\n",
      "32/224, train_loss: 0.2161, step time: 0.3167\n",
      "33/224, train_loss: 0.2985, step time: 0.3165\n",
      "34/224, train_loss: 0.1730, step time: 0.3750\n",
      "35/224, train_loss: 0.1441, step time: 0.3850\n",
      "36/224, train_loss: 0.1950, step time: 0.3189\n",
      "37/224, train_loss: 0.1121, step time: 0.3141\n",
      "38/224, train_loss: 0.1164, step time: 0.3960\n",
      "39/224, train_loss: 0.2745, step time: 0.3817\n",
      "40/224, train_loss: 0.1872, step time: 0.3158\n",
      "41/224, train_loss: 0.4434, step time: 0.3903\n",
      "42/224, train_loss: 0.1800, step time: 0.4108\n",
      "43/224, train_loss: 0.1507, step time: 0.3170\n",
      "44/224, train_loss: 0.1712, step time: 0.3158\n",
      "45/224, train_loss: 0.1636, step time: 0.3141\n",
      "46/224, train_loss: 0.1326, step time: 0.3959\n",
      "47/224, train_loss: 0.1896, step time: 0.3147\n",
      "48/224, train_loss: 0.2099, step time: 0.3170\n",
      "49/224, train_loss: 0.3354, step time: 0.3831\n",
      "50/224, train_loss: 0.1811, step time: 0.3182\n",
      "51/224, train_loss: 0.2312, step time: 0.3180\n",
      "52/224, train_loss: 0.4299, step time: 0.3760\n",
      "53/224, train_loss: 0.2140, step time: 0.3712\n",
      "54/224, train_loss: 0.2146, step time: 0.3895\n",
      "55/224, train_loss: 0.2734, step time: 0.3164\n",
      "56/224, train_loss: 0.1670, step time: 0.3867\n",
      "57/224, train_loss: 0.2767, step time: 0.3804\n",
      "58/224, train_loss: 0.3248, step time: 0.3168\n",
      "59/224, train_loss: 0.1673, step time: 0.3149\n",
      "60/224, train_loss: 0.1049, step time: 0.3167\n",
      "61/224, train_loss: 0.1660, step time: 0.3172\n",
      "62/224, train_loss: 0.0998, step time: 0.3176\n",
      "63/224, train_loss: 0.2743, step time: 0.3878\n",
      "64/224, train_loss: 0.2562, step time: 0.3822\n",
      "65/224, train_loss: 0.2699, step time: 0.3903\n",
      "66/224, train_loss: 0.1400, step time: 0.4093\n",
      "67/224, train_loss: 0.1651, step time: 0.3829\n",
      "68/224, train_loss: 0.1517, step time: 0.4019\n",
      "69/224, train_loss: 0.2891, step time: 0.3779\n",
      "70/224, train_loss: 0.3761, step time: 0.3994\n",
      "71/224, train_loss: 0.2523, step time: 0.3721\n",
      "72/224, train_loss: 0.2467, step time: 0.3846\n",
      "73/224, train_loss: 0.2589, step time: 0.3698\n",
      "74/224, train_loss: 0.2490, step time: 0.4021\n",
      "75/224, train_loss: 0.3519, step time: 0.4116\n",
      "76/224, train_loss: 0.2148, step time: 0.3966\n",
      "77/224, train_loss: 0.1563, step time: 0.4055\n",
      "78/224, train_loss: 0.1227, step time: 0.4110\n",
      "79/224, train_loss: 0.1609, step time: 0.3168\n",
      "80/224, train_loss: 0.1386, step time: 0.3162\n",
      "81/224, train_loss: 0.2387, step time: 0.3153\n",
      "82/224, train_loss: 0.4196, step time: 0.3152\n",
      "83/224, train_loss: 0.0843, step time: 0.3159\n",
      "84/224, train_loss: 0.2606, step time: 0.4066\n",
      "85/224, train_loss: 0.2210, step time: 0.3178\n",
      "86/224, train_loss: 0.1517, step time: 0.3917\n",
      "87/224, train_loss: 0.2829, step time: 0.3183\n",
      "88/224, train_loss: 0.1612, step time: 0.4099\n",
      "89/224, train_loss: 0.3202, step time: 0.3179\n",
      "90/224, train_loss: 0.1299, step time: 0.3190\n",
      "91/224, train_loss: 0.4138, step time: 0.3881\n",
      "92/224, train_loss: 0.3840, step time: 0.3990\n",
      "93/224, train_loss: 0.1830, step time: 0.3165\n",
      "94/224, train_loss: 0.4414, step time: 0.3168\n",
      "95/224, train_loss: 0.1502, step time: 0.3991\n",
      "96/224, train_loss: 0.1540, step time: 0.3174\n",
      "97/224, train_loss: 0.3720, step time: 0.4106\n",
      "98/224, train_loss: 0.1752, step time: 0.3949\n",
      "99/224, train_loss: 0.3909, step time: 0.3188\n",
      "100/224, train_loss: 0.1216, step time: 0.3164\n",
      "101/224, train_loss: 0.2494, step time: 0.3913\n",
      "102/224, train_loss: 0.2001, step time: 0.3193\n",
      "103/224, train_loss: 0.3381, step time: 0.3154\n",
      "104/224, train_loss: 0.1897, step time: 0.3710\n",
      "105/224, train_loss: 0.1733, step time: 0.3805\n",
      "106/224, train_loss: 0.6004, step time: 0.4124\n",
      "107/224, train_loss: 0.1809, step time: 0.3984\n",
      "108/224, train_loss: 0.3803, step time: 0.4117\n",
      "109/224, train_loss: 0.2068, step time: 0.3157\n",
      "110/224, train_loss: 0.2165, step time: 0.3897\n",
      "111/224, train_loss: 0.2672, step time: 0.3135\n",
      "112/224, train_loss: 0.3453, step time: 0.3179\n",
      "113/224, train_loss: 0.1663, step time: 0.3166\n",
      "114/224, train_loss: 0.2157, step time: 0.3734\n",
      "115/224, train_loss: 0.1521, step time: 0.3968\n",
      "116/224, train_loss: 0.3085, step time: 0.3733\n",
      "117/224, train_loss: 0.3004, step time: 0.3768\n",
      "118/224, train_loss: 0.1526, step time: 0.3943\n",
      "119/224, train_loss: 0.2792, step time: 0.3832\n",
      "120/224, train_loss: 0.4142, step time: 0.3995\n",
      "121/224, train_loss: 0.2213, step time: 0.3166\n",
      "122/224, train_loss: 0.0867, step time: 0.3178\n",
      "123/224, train_loss: 0.2340, step time: 0.3954\n",
      "124/224, train_loss: 0.2107, step time: 0.3125\n",
      "125/224, train_loss: 0.1174, step time: 0.3131\n",
      "126/224, train_loss: 0.1458, step time: 0.3130\n",
      "127/224, train_loss: 0.3616, step time: 0.3150\n",
      "128/224, train_loss: 0.1856, step time: 0.3130\n",
      "129/224, train_loss: 0.3211, step time: 0.3807\n",
      "130/224, train_loss: 0.3109, step time: 0.4003\n",
      "131/224, train_loss: 0.3965, step time: 0.3646\n",
      "132/224, train_loss: 0.2071, step time: 0.3923\n",
      "133/224, train_loss: 0.2233, step time: 0.3829\n",
      "134/224, train_loss: 0.2481, step time: 0.3153\n",
      "135/224, train_loss: 0.4107, step time: 0.3839\n",
      "136/224, train_loss: 0.3663, step time: 0.3870\n",
      "137/224, train_loss: 0.2092, step time: 0.3705\n",
      "138/224, train_loss: 0.2778, step time: 0.3910\n",
      "139/224, train_loss: 0.1588, step time: 0.3982\n",
      "140/224, train_loss: 0.2312, step time: 0.3739\n",
      "141/224, train_loss: 0.1663, step time: 0.3930\n",
      "142/224, train_loss: 0.3896, step time: 0.3839\n",
      "143/224, train_loss: 0.1729, step time: 0.4046\n",
      "144/224, train_loss: 0.1296, step time: 0.3151\n",
      "145/224, train_loss: 0.2299, step time: 0.3722\n",
      "146/224, train_loss: 0.1725, step time: 0.3159\n",
      "147/224, train_loss: 0.3020, step time: 0.3756\n",
      "148/224, train_loss: 0.3793, step time: 0.3889\n",
      "149/224, train_loss: 0.2102, step time: 0.3716\n",
      "150/224, train_loss: 0.1370, step time: 0.3136\n",
      "151/224, train_loss: 0.2646, step time: 0.3162\n",
      "152/224, train_loss: 0.2251, step time: 0.3928\n",
      "153/224, train_loss: 0.2759, step time: 0.3884\n",
      "154/224, train_loss: 0.2349, step time: 0.3793\n",
      "155/224, train_loss: 0.2382, step time: 0.3185\n",
      "156/224, train_loss: 0.0984, step time: 0.3164\n",
      "157/224, train_loss: 0.4578, step time: 0.4016\n",
      "158/224, train_loss: 0.3379, step time: 0.3976\n",
      "159/224, train_loss: 0.0854, step time: 0.3169\n",
      "160/224, train_loss: 0.2305, step time: 0.3157\n",
      "161/224, train_loss: 0.2229, step time: 0.3152\n",
      "162/224, train_loss: 0.1930, step time: 0.3178\n",
      "163/224, train_loss: 0.1616, step time: 0.3902\n",
      "164/224, train_loss: 0.4082, step time: 0.3157\n",
      "165/224, train_loss: 0.1546, step time: 0.3887\n",
      "166/224, train_loss: 0.1057, step time: 0.3936\n",
      "167/224, train_loss: 0.3534, step time: 0.3722\n",
      "168/224, train_loss: 0.3756, step time: 0.3158\n",
      "169/224, train_loss: 0.2577, step time: 0.3911\n",
      "170/224, train_loss: 0.1278, step time: 0.3156\n",
      "171/224, train_loss: 0.2219, step time: 0.3637\n",
      "172/224, train_loss: 0.2498, step time: 0.4003\n",
      "173/224, train_loss: 0.0942, step time: 0.3156\n",
      "174/224, train_loss: 0.4505, step time: 0.3659\n",
      "175/224, train_loss: 0.2162, step time: 0.3157\n",
      "176/224, train_loss: 0.1103, step time: 0.3176\n",
      "177/224, train_loss: 0.2812, step time: 0.3131\n",
      "178/224, train_loss: 0.4975, step time: 0.3668\n",
      "179/224, train_loss: 0.1905, step time: 0.3186\n",
      "180/224, train_loss: 0.2424, step time: 0.3159\n",
      "181/224, train_loss: 0.1696, step time: 0.3181\n",
      "182/224, train_loss: 0.1454, step time: 0.4023\n",
      "183/224, train_loss: 0.1622, step time: 0.3773\n",
      "184/224, train_loss: 0.4232, step time: 0.3939\n",
      "185/224, train_loss: 0.2093, step time: 0.3954\n",
      "186/224, train_loss: 0.2737, step time: 0.3167\n",
      "187/224, train_loss: 0.3576, step time: 0.3648\n",
      "188/224, train_loss: 0.1488, step time: 0.3182\n",
      "189/224, train_loss: 0.3097, step time: 0.3191\n",
      "190/224, train_loss: 0.2512, step time: 0.3163\n",
      "191/224, train_loss: 0.2548, step time: 0.4054\n",
      "192/224, train_loss: 0.1633, step time: 0.4003\n",
      "193/224, train_loss: 0.2930, step time: 0.4092\n",
      "194/224, train_loss: 0.1892, step time: 0.3139\n",
      "195/224, train_loss: 0.2898, step time: 0.3139\n",
      "196/224, train_loss: 0.1890, step time: 0.3175\n",
      "197/224, train_loss: 0.2643, step time: 0.3154\n",
      "198/224, train_loss: 0.1941, step time: 0.3152\n",
      "199/224, train_loss: 0.2987, step time: 0.3158\n",
      "200/224, train_loss: 0.3875, step time: 0.3158\n",
      "201/224, train_loss: 0.2788, step time: 0.3150\n",
      "202/224, train_loss: 0.3146, step time: 0.3175\n",
      "203/224, train_loss: 0.3688, step time: 0.3181\n",
      "204/224, train_loss: 0.2813, step time: 0.3855\n",
      "205/224, train_loss: 0.3305, step time: 0.3132\n",
      "206/224, train_loss: 0.1751, step time: 0.3159\n",
      "207/224, train_loss: 0.2088, step time: 0.3158\n",
      "208/224, train_loss: 0.1256, step time: 0.3134\n",
      "209/224, train_loss: 0.3295, step time: 0.3173\n",
      "210/224, train_loss: 0.3209, step time: 0.3158\n",
      "211/224, train_loss: 0.3447, step time: 0.3138\n",
      "212/224, train_loss: 0.1570, step time: 0.3179\n",
      "213/224, train_loss: 0.4404, step time: 0.3819\n",
      "214/224, train_loss: 0.4971, step time: 0.3714\n",
      "215/224, train_loss: 0.3717, step time: 0.3672\n",
      "216/224, train_loss: 0.2066, step time: 0.4013\n",
      "217/224, train_loss: 0.3696, step time: 0.3871\n",
      "218/224, train_loss: 0.3700, step time: 0.3895\n",
      "219/224, train_loss: 0.2608, step time: 0.3686\n",
      "220/224, train_loss: 0.3772, step time: 0.3848\n",
      "221/224, train_loss: 0.2040, step time: 0.3773\n",
      "222/224, train_loss: 0.1790, step time: 0.3993\n",
      "223/224, train_loss: 0.2258, step time: 0.3160\n",
      "224/224, train_loss: 0.1420, step time: 0.3152\n",
      "epoch 26 average loss: 0.2464\n",
      "current epoch: 26 current mean dice: 0.6574 class1: 0.9989 class2: 0.7187 class3: 0.2548\n",
      "best mean dice: 0.6835 at epoch: 23\n",
      "time consuming of epoch 26 is: 777.1984\n",
      "hello\n",
      "----------\n",
      "epoch 27/100\n",
      "1/224, train_loss: 0.2127, step time: 0.3997\n",
      "2/224, train_loss: 0.2657, step time: 0.4113\n",
      "3/224, train_loss: 0.2344, step time: 0.3678\n",
      "4/224, train_loss: 0.1836, step time: 0.3198\n",
      "5/224, train_loss: 0.1786, step time: 0.4015\n",
      "6/224, train_loss: 0.3076, step time: 0.4059\n",
      "7/224, train_loss: 0.1258, step time: 0.3154\n",
      "8/224, train_loss: 0.1889, step time: 0.3157\n",
      "9/224, train_loss: 0.2575, step time: 0.3644\n",
      "10/224, train_loss: 0.3654, step time: 0.4023\n",
      "11/224, train_loss: 0.2094, step time: 0.3136\n",
      "12/224, train_loss: 0.2459, step time: 0.3182\n",
      "13/224, train_loss: 0.1351, step time: 0.3743\n",
      "14/224, train_loss: 0.1439, step time: 0.3173\n",
      "15/224, train_loss: 0.2041, step time: 0.3154\n",
      "16/224, train_loss: 0.2471, step time: 0.3772\n",
      "17/224, train_loss: 0.1977, step time: 0.3180\n",
      "18/224, train_loss: 0.1071, step time: 0.3156\n",
      "19/224, train_loss: 0.2402, step time: 0.3145\n",
      "20/224, train_loss: 0.2746, step time: 0.3147\n",
      "21/224, train_loss: 0.1877, step time: 0.3154\n",
      "22/224, train_loss: 0.3154, step time: 0.3156\n",
      "23/224, train_loss: 0.1848, step time: 0.3141\n",
      "24/224, train_loss: 0.2596, step time: 0.3912\n",
      "25/224, train_loss: 0.1430, step time: 0.3172\n",
      "26/224, train_loss: 0.0889, step time: 0.3947\n",
      "27/224, train_loss: 0.1831, step time: 0.3700\n",
      "28/224, train_loss: 0.1065, step time: 0.3986\n",
      "29/224, train_loss: 0.2433, step time: 0.3158\n",
      "30/224, train_loss: 0.2076, step time: 0.3133\n",
      "31/224, train_loss: 0.2026, step time: 0.3142\n",
      "32/224, train_loss: 0.3441, step time: 0.3690\n",
      "33/224, train_loss: 0.2566, step time: 0.3174\n",
      "34/224, train_loss: 0.2475, step time: 0.3173\n",
      "35/224, train_loss: 0.2058, step time: 0.3178\n",
      "36/224, train_loss: 0.2899, step time: 0.3770\n",
      "37/224, train_loss: 0.2732, step time: 0.3937\n",
      "38/224, train_loss: 0.4290, step time: 0.3841\n",
      "39/224, train_loss: 0.3144, step time: 0.3187\n",
      "40/224, train_loss: 0.2808, step time: 0.3136\n",
      "41/224, train_loss: 0.4153, step time: 0.3178\n",
      "42/224, train_loss: 0.2458, step time: 0.3180\n",
      "43/224, train_loss: 0.1222, step time: 0.3628\n",
      "44/224, train_loss: 0.1540, step time: 0.3156\n",
      "45/224, train_loss: 0.1290, step time: 0.4086\n",
      "46/224, train_loss: 0.3854, step time: 0.3923\n",
      "47/224, train_loss: 0.3602, step time: 0.3174\n",
      "48/224, train_loss: 0.1587, step time: 0.3127\n",
      "49/224, train_loss: 0.2111, step time: 0.3823\n",
      "50/224, train_loss: 0.3478, step time: 0.3134\n",
      "51/224, train_loss: 0.1672, step time: 0.3860\n",
      "52/224, train_loss: 0.2111, step time: 0.3873\n",
      "53/224, train_loss: 0.1984, step time: 0.4084\n",
      "54/224, train_loss: 0.3762, step time: 0.3869\n",
      "55/224, train_loss: 0.1937, step time: 0.3159\n",
      "56/224, train_loss: 0.1483, step time: 0.3948\n",
      "57/224, train_loss: 0.2869, step time: 0.3129\n",
      "58/224, train_loss: 0.2965, step time: 0.3148\n",
      "59/224, train_loss: 0.1796, step time: 0.3150\n",
      "60/224, train_loss: 0.1411, step time: 0.3162\n",
      "61/224, train_loss: 0.3322, step time: 0.3154\n",
      "62/224, train_loss: 0.1242, step time: 0.3967\n",
      "63/224, train_loss: 0.2362, step time: 0.4027\n",
      "64/224, train_loss: 0.1594, step time: 0.3926\n",
      "65/224, train_loss: 0.1895, step time: 0.3743\n",
      "66/224, train_loss: 0.4433, step time: 0.3958\n",
      "67/224, train_loss: 0.1859, step time: 0.3174\n",
      "68/224, train_loss: 0.3183, step time: 0.3971\n",
      "69/224, train_loss: 0.2752, step time: 0.3653\n",
      "70/224, train_loss: 0.3479, step time: 0.3691\n",
      "71/224, train_loss: 0.1134, step time: 0.3818\n",
      "72/224, train_loss: 0.3178, step time: 0.3786\n",
      "73/224, train_loss: 0.3719, step time: 0.3829\n",
      "74/224, train_loss: 0.4426, step time: 0.3672\n",
      "75/224, train_loss: 0.2303, step time: 0.3884\n",
      "76/224, train_loss: 0.1121, step time: 0.3155\n",
      "77/224, train_loss: 0.3545, step time: 0.3136\n",
      "78/224, train_loss: 0.1343, step time: 0.3133\n",
      "79/224, train_loss: 0.2767, step time: 0.4010\n",
      "80/224, train_loss: 0.1713, step time: 0.3151\n",
      "81/224, train_loss: 0.4293, step time: 0.4060\n",
      "82/224, train_loss: 0.2013, step time: 0.3850\n",
      "83/224, train_loss: 0.1741, step time: 0.3768\n",
      "84/224, train_loss: 0.1448, step time: 0.3714\n",
      "85/224, train_loss: 0.2135, step time: 0.3795\n",
      "86/224, train_loss: 0.1124, step time: 0.3177\n",
      "87/224, train_loss: 0.1968, step time: 0.3180\n",
      "88/224, train_loss: 0.1878, step time: 0.3156\n",
      "89/224, train_loss: 0.1701, step time: 0.3159\n",
      "90/224, train_loss: 0.1836, step time: 0.3759\n",
      "91/224, train_loss: 0.1835, step time: 0.3704\n",
      "92/224, train_loss: 0.3739, step time: 0.3695\n",
      "93/224, train_loss: 0.1685, step time: 0.3135\n",
      "94/224, train_loss: 0.3514, step time: 0.4121\n",
      "95/224, train_loss: 0.3661, step time: 0.4030\n",
      "96/224, train_loss: 0.1195, step time: 0.3971\n",
      "97/224, train_loss: 0.4316, step time: 0.3802\n",
      "98/224, train_loss: 0.1568, step time: 0.3176\n",
      "99/224, train_loss: 0.2040, step time: 0.3741\n",
      "100/224, train_loss: 0.1804, step time: 0.4128\n",
      "101/224, train_loss: 0.1802, step time: 0.4065\n",
      "102/224, train_loss: 0.4481, step time: 0.3777\n",
      "103/224, train_loss: 0.2508, step time: 0.4090\n",
      "104/224, train_loss: 0.2382, step time: 0.3862\n",
      "105/224, train_loss: 0.1651, step time: 0.3131\n",
      "106/224, train_loss: 0.1480, step time: 0.3148\n",
      "107/224, train_loss: 0.4611, step time: 0.3935\n",
      "108/224, train_loss: 0.2969, step time: 0.3154\n",
      "109/224, train_loss: 0.3034, step time: 0.3961\n",
      "110/224, train_loss: 0.4033, step time: 0.4089\n",
      "111/224, train_loss: 0.0993, step time: 0.3177\n",
      "112/224, train_loss: 0.2207, step time: 0.3153\n",
      "113/224, train_loss: 0.2255, step time: 0.4094\n",
      "114/224, train_loss: 0.2135, step time: 0.3767\n",
      "115/224, train_loss: 0.4206, step time: 0.4137\n",
      "116/224, train_loss: 0.2755, step time: 0.3922\n",
      "117/224, train_loss: 0.3574, step time: 0.3132\n",
      "118/224, train_loss: 0.3633, step time: 0.3932\n",
      "119/224, train_loss: 0.1545, step time: 0.3138\n",
      "120/224, train_loss: 0.1710, step time: 0.3159\n",
      "121/224, train_loss: 0.1300, step time: 0.3153\n",
      "122/224, train_loss: 0.3552, step time: 0.3178\n",
      "123/224, train_loss: 0.1590, step time: 0.3161\n",
      "124/224, train_loss: 0.1285, step time: 0.3899\n",
      "125/224, train_loss: 0.3614, step time: 0.3888\n",
      "126/224, train_loss: 0.4495, step time: 0.3149\n",
      "127/224, train_loss: 0.1561, step time: 0.4019\n",
      "128/224, train_loss: 0.0886, step time: 0.3737\n",
      "129/224, train_loss: 0.3578, step time: 0.3971\n",
      "130/224, train_loss: 0.1576, step time: 0.4095\n",
      "131/224, train_loss: 0.2186, step time: 0.3156\n",
      "132/224, train_loss: 0.3668, step time: 0.4015\n",
      "133/224, train_loss: 0.3962, step time: 0.4072\n",
      "134/224, train_loss: 0.2074, step time: 0.3160\n",
      "135/224, train_loss: 0.2103, step time: 0.3754\n",
      "136/224, train_loss: 0.1321, step time: 0.3153\n",
      "137/224, train_loss: 0.1962, step time: 0.3172\n",
      "138/224, train_loss: 0.1661, step time: 0.3148\n",
      "139/224, train_loss: 0.1553, step time: 0.3149\n",
      "140/224, train_loss: 0.2470, step time: 0.3153\n",
      "141/224, train_loss: 0.3271, step time: 0.3942\n",
      "142/224, train_loss: 0.1639, step time: 0.4074\n",
      "143/224, train_loss: 0.1537, step time: 0.3136\n",
      "144/224, train_loss: 0.1518, step time: 0.3906\n",
      "145/224, train_loss: 0.1469, step time: 0.3170\n",
      "146/224, train_loss: 0.2107, step time: 0.3152\n",
      "147/224, train_loss: 0.3924, step time: 0.3921\n",
      "148/224, train_loss: 0.1190, step time: 0.3146\n",
      "149/224, train_loss: 0.3636, step time: 0.3171\n",
      "150/224, train_loss: 0.1592, step time: 0.3891\n",
      "151/224, train_loss: 0.3234, step time: 0.3178\n",
      "152/224, train_loss: 0.3752, step time: 0.3155\n",
      "153/224, train_loss: 0.4244, step time: 0.3174\n",
      "154/224, train_loss: 0.4035, step time: 0.3145\n",
      "155/224, train_loss: 0.1701, step time: 0.3906\n",
      "156/224, train_loss: 0.4266, step time: 0.3948\n",
      "157/224, train_loss: 0.1524, step time: 0.3960\n",
      "158/224, train_loss: 0.1511, step time: 0.3185\n",
      "159/224, train_loss: 0.3595, step time: 0.3148\n",
      "160/224, train_loss: 0.1993, step time: 0.3177\n",
      "161/224, train_loss: 0.1908, step time: 0.3159\n",
      "162/224, train_loss: 0.3379, step time: 0.3144\n",
      "163/224, train_loss: 0.4612, step time: 0.4078\n",
      "164/224, train_loss: 0.3979, step time: 0.3152\n",
      "165/224, train_loss: 0.5378, step time: 0.3789\n",
      "166/224, train_loss: 0.3645, step time: 0.3867\n",
      "167/224, train_loss: 0.1325, step time: 0.3148\n",
      "168/224, train_loss: 0.1785, step time: 0.3939\n",
      "169/224, train_loss: 0.0987, step time: 0.3144\n",
      "170/224, train_loss: 0.4784, step time: 0.3876\n",
      "171/224, train_loss: 0.5240, step time: 0.3940\n",
      "172/224, train_loss: 0.3513, step time: 0.3858\n",
      "173/224, train_loss: 0.3520, step time: 0.3166\n",
      "174/224, train_loss: 0.3128, step time: 0.3128\n",
      "175/224, train_loss: 0.2495, step time: 0.3172\n",
      "176/224, train_loss: 0.2914, step time: 0.3167\n",
      "177/224, train_loss: 0.2155, step time: 0.3172\n",
      "178/224, train_loss: 0.3061, step time: 0.3767\n",
      "179/224, train_loss: 0.4142, step time: 0.3918\n",
      "180/224, train_loss: 0.2384, step time: 0.3884\n",
      "181/224, train_loss: 0.2142, step time: 0.3159\n",
      "182/224, train_loss: 0.3404, step time: 0.3177\n",
      "183/224, train_loss: 0.1523, step time: 0.3679\n",
      "184/224, train_loss: 0.3338, step time: 0.3167\n",
      "185/224, train_loss: 0.4150, step time: 0.3857\n",
      "186/224, train_loss: 0.4860, step time: 0.3915\n",
      "187/224, train_loss: 0.3123, step time: 0.3157\n",
      "188/224, train_loss: 0.2355, step time: 0.3835\n",
      "189/224, train_loss: 0.3932, step time: 0.3901\n",
      "190/224, train_loss: 0.2796, step time: 0.3153\n",
      "191/224, train_loss: 0.3123, step time: 0.3895\n",
      "192/224, train_loss: 0.2480, step time: 0.3778\n",
      "193/224, train_loss: 0.1456, step time: 0.4026\n",
      "194/224, train_loss: 0.2203, step time: 0.3765\n",
      "195/224, train_loss: 0.2011, step time: 0.3183\n",
      "196/224, train_loss: 0.1275, step time: 0.4055\n",
      "197/224, train_loss: 0.2697, step time: 0.4001\n",
      "198/224, train_loss: 0.2268, step time: 0.3142\n",
      "199/224, train_loss: 0.1254, step time: 0.3165\n",
      "200/224, train_loss: 0.2678, step time: 0.3182\n",
      "201/224, train_loss: 0.1792, step time: 0.3667\n",
      "202/224, train_loss: 0.1812, step time: 0.4088\n",
      "203/224, train_loss: 0.2238, step time: 0.3683\n",
      "204/224, train_loss: 0.1848, step time: 0.3999\n",
      "205/224, train_loss: 0.2279, step time: 0.3845\n",
      "206/224, train_loss: 0.2589, step time: 0.3920\n",
      "207/224, train_loss: 0.2558, step time: 0.3187\n",
      "208/224, train_loss: 0.2342, step time: 0.3791\n",
      "209/224, train_loss: 0.3194, step time: 0.3166\n",
      "210/224, train_loss: 0.1205, step time: 0.3180\n",
      "211/224, train_loss: 0.2761, step time: 0.3152\n",
      "212/224, train_loss: 0.1384, step time: 0.3156\n",
      "213/224, train_loss: 0.3620, step time: 0.3141\n",
      "214/224, train_loss: 0.4060, step time: 0.3801\n",
      "215/224, train_loss: 0.2395, step time: 0.4110\n",
      "216/224, train_loss: 0.4318, step time: 0.3158\n",
      "217/224, train_loss: 0.1931, step time: 0.3135\n",
      "218/224, train_loss: 0.1726, step time: 0.3157\n",
      "219/224, train_loss: 0.1017, step time: 0.3139\n",
      "220/224, train_loss: 0.3253, step time: 0.3158\n",
      "221/224, train_loss: 0.1081, step time: 0.3160\n",
      "222/224, train_loss: 0.3582, step time: 0.4017\n",
      "223/224, train_loss: 0.1738, step time: 0.3185\n",
      "224/224, train_loss: 0.4604, step time: 0.3177\n",
      "epoch 27 average loss: 0.2517\n",
      "current epoch: 27 current mean dice: 0.6839 class1: 0.9992 class2: 0.7294 class3: 0.3233\n",
      "best mean dice: 0.6839 at epoch: 27\n",
      "time consuming of epoch 27 is: 746.5249\n",
      "hello\n",
      "----------\n",
      "epoch 28/100\n",
      "1/224, train_loss: 0.4126, step time: 0.3778\n",
      "2/224, train_loss: 0.3048, step time: 0.3733\n",
      "3/224, train_loss: 0.1116, step time: 0.3156\n",
      "4/224, train_loss: 0.3709, step time: 0.4055\n",
      "5/224, train_loss: 0.2957, step time: 0.4080\n",
      "6/224, train_loss: 0.3171, step time: 0.3174\n",
      "7/224, train_loss: 0.2027, step time: 0.4112\n",
      "8/224, train_loss: 0.1616, step time: 0.3146\n",
      "9/224, train_loss: 0.3635, step time: 0.3688\n",
      "10/224, train_loss: 0.3462, step time: 0.4032\n",
      "11/224, train_loss: 0.3969, step time: 0.3995\n",
      "12/224, train_loss: 0.1824, step time: 0.3160\n",
      "13/224, train_loss: 0.2058, step time: 0.3941\n",
      "14/224, train_loss: 0.2347, step time: 0.3970\n",
      "15/224, train_loss: 0.2957, step time: 0.3930\n",
      "16/224, train_loss: 0.2394, step time: 0.3158\n",
      "17/224, train_loss: 0.4713, step time: 0.3821\n",
      "18/224, train_loss: 0.1729, step time: 0.3856\n",
      "19/224, train_loss: 0.1569, step time: 0.4031\n",
      "20/224, train_loss: 0.3524, step time: 0.4099\n",
      "21/224, train_loss: 0.2532, step time: 0.3776\n",
      "22/224, train_loss: 0.2665, step time: 0.3889\n",
      "23/224, train_loss: 0.4367, step time: 0.3957\n",
      "24/224, train_loss: 0.1491, step time: 0.3156\n",
      "25/224, train_loss: 0.1992, step time: 0.3700\n",
      "26/224, train_loss: 0.1972, step time: 0.3155\n",
      "27/224, train_loss: 0.3280, step time: 0.3908\n",
      "28/224, train_loss: 0.2643, step time: 0.3970\n",
      "29/224, train_loss: 0.2138, step time: 0.3178\n",
      "30/224, train_loss: 0.1130, step time: 0.3149\n",
      "31/224, train_loss: 0.2216, step time: 0.3933\n",
      "32/224, train_loss: 0.1336, step time: 0.3213\n",
      "33/224, train_loss: 0.1349, step time: 0.3747\n",
      "34/224, train_loss: 0.1414, step time: 0.3177\n",
      "35/224, train_loss: 0.1661, step time: 0.3978\n",
      "36/224, train_loss: 0.2525, step time: 0.3808\n",
      "37/224, train_loss: 0.3873, step time: 0.4014\n",
      "38/224, train_loss: 0.0956, step time: 0.3896\n",
      "39/224, train_loss: 0.2451, step time: 0.3179\n",
      "40/224, train_loss: 0.1862, step time: 0.3153\n",
      "41/224, train_loss: 0.1435, step time: 0.3155\n",
      "42/224, train_loss: 0.2178, step time: 0.3157\n",
      "43/224, train_loss: 0.1543, step time: 0.3799\n",
      "44/224, train_loss: 0.2760, step time: 0.3187\n",
      "45/224, train_loss: 0.1827, step time: 0.4014\n",
      "46/224, train_loss: 0.2127, step time: 0.3159\n",
      "47/224, train_loss: 0.4666, step time: 0.3932\n",
      "48/224, train_loss: 0.2495, step time: 0.3185\n",
      "49/224, train_loss: 0.3473, step time: 0.4057\n",
      "50/224, train_loss: 0.4171, step time: 0.3934\n",
      "51/224, train_loss: 0.1875, step time: 0.4096\n",
      "52/224, train_loss: 0.3768, step time: 0.3764\n",
      "53/224, train_loss: 0.1459, step time: 0.3158\n",
      "54/224, train_loss: 0.4886, step time: 0.3909\n",
      "55/224, train_loss: 0.2146, step time: 0.3673\n",
      "56/224, train_loss: 0.1467, step time: 0.3147\n",
      "57/224, train_loss: 0.4704, step time: 0.3152\n",
      "58/224, train_loss: 0.1352, step time: 0.4088\n",
      "59/224, train_loss: 0.1306, step time: 0.3161\n",
      "60/224, train_loss: 0.0858, step time: 0.3157\n",
      "61/224, train_loss: 0.1606, step time: 0.3843\n",
      "62/224, train_loss: 0.3516, step time: 0.3768\n",
      "63/224, train_loss: 0.2727, step time: 0.3150\n",
      "64/224, train_loss: 0.3012, step time: 0.3779\n",
      "65/224, train_loss: 0.4010, step time: 0.3177\n",
      "66/224, train_loss: 0.1008, step time: 0.3136\n",
      "67/224, train_loss: 0.1250, step time: 0.3728\n",
      "68/224, train_loss: 0.2285, step time: 0.3735\n",
      "69/224, train_loss: 0.3840, step time: 0.3157\n",
      "70/224, train_loss: 0.2537, step time: 0.3862\n",
      "71/224, train_loss: 0.2483, step time: 0.3963\n",
      "72/224, train_loss: 0.1653, step time: 0.3154\n",
      "73/224, train_loss: 0.3981, step time: 0.4113\n",
      "74/224, train_loss: 0.2315, step time: 0.3869\n",
      "75/224, train_loss: 0.2063, step time: 0.3177\n",
      "76/224, train_loss: 0.1143, step time: 0.3155\n",
      "77/224, train_loss: 0.1178, step time: 0.3889\n",
      "78/224, train_loss: 0.1362, step time: 0.3690\n",
      "79/224, train_loss: 0.1124, step time: 0.3162\n",
      "80/224, train_loss: 0.3596, step time: 0.3151\n",
      "81/224, train_loss: 0.2818, step time: 0.3178\n",
      "82/224, train_loss: 0.2266, step time: 0.3880\n",
      "83/224, train_loss: 0.2709, step time: 0.4048\n",
      "84/224, train_loss: 0.1454, step time: 0.3881\n",
      "85/224, train_loss: 0.1784, step time: 0.3182\n",
      "86/224, train_loss: 0.2167, step time: 0.3925\n",
      "87/224, train_loss: 0.3121, step time: 0.4099\n",
      "88/224, train_loss: 0.1288, step time: 0.3978\n",
      "89/224, train_loss: 0.3615, step time: 0.3152\n",
      "90/224, train_loss: 0.2127, step time: 0.3150\n",
      "91/224, train_loss: 0.2696, step time: 0.3132\n",
      "92/224, train_loss: 0.1544, step time: 0.3167\n",
      "93/224, train_loss: 0.1536, step time: 0.4118\n",
      "94/224, train_loss: 0.5071, step time: 0.3624\n",
      "95/224, train_loss: 0.3547, step time: 0.3150\n",
      "96/224, train_loss: 0.1911, step time: 0.3154\n",
      "97/224, train_loss: 0.2794, step time: 0.3150\n",
      "98/224, train_loss: 0.2412, step time: 0.3178\n",
      "99/224, train_loss: 0.1531, step time: 0.3158\n",
      "100/224, train_loss: 0.2303, step time: 0.3964\n",
      "101/224, train_loss: 0.0891, step time: 0.3159\n",
      "102/224, train_loss: 0.2785, step time: 0.3154\n",
      "103/224, train_loss: 0.1303, step time: 0.3952\n",
      "104/224, train_loss: 0.2011, step time: 0.3165\n",
      "105/224, train_loss: 0.4488, step time: 0.3769\n",
      "106/224, train_loss: 0.2063, step time: 0.3925\n",
      "107/224, train_loss: 0.2239, step time: 0.3153\n",
      "108/224, train_loss: 0.2042, step time: 0.3835\n",
      "109/224, train_loss: 0.1538, step time: 0.3149\n",
      "110/224, train_loss: 0.3733, step time: 0.3150\n",
      "111/224, train_loss: 0.2948, step time: 0.3744\n",
      "112/224, train_loss: 0.2750, step time: 0.3850\n",
      "113/224, train_loss: 0.3696, step time: 0.3154\n",
      "114/224, train_loss: 0.1756, step time: 0.4046\n",
      "115/224, train_loss: 0.1307, step time: 0.4133\n",
      "116/224, train_loss: 0.3289, step time: 0.3989\n",
      "117/224, train_loss: 0.3604, step time: 0.3803\n",
      "118/224, train_loss: 0.2599, step time: 0.3732\n",
      "119/224, train_loss: 0.3237, step time: 0.3180\n",
      "120/224, train_loss: 0.1636, step time: 0.3159\n",
      "121/224, train_loss: 0.1203, step time: 0.3152\n",
      "122/224, train_loss: 0.2054, step time: 0.3145\n",
      "123/224, train_loss: 0.2355, step time: 0.4109\n",
      "124/224, train_loss: 0.3115, step time: 0.3160\n",
      "125/224, train_loss: 0.3734, step time: 0.3780\n",
      "126/224, train_loss: 0.1627, step time: 0.3155\n",
      "127/224, train_loss: 0.2459, step time: 0.3162\n",
      "128/224, train_loss: 0.1869, step time: 0.3160\n",
      "129/224, train_loss: 0.3633, step time: 0.3172\n",
      "130/224, train_loss: 0.4413, step time: 0.3864\n",
      "131/224, train_loss: 0.4187, step time: 0.3177\n",
      "132/224, train_loss: 0.2616, step time: 0.3680\n",
      "133/224, train_loss: 0.2899, step time: 0.3157\n",
      "134/224, train_loss: 0.4438, step time: 0.3179\n",
      "135/224, train_loss: 0.3939, step time: 0.3714\n",
      "136/224, train_loss: 0.2479, step time: 0.3786\n",
      "137/224, train_loss: 0.1227, step time: 0.3166\n",
      "138/224, train_loss: 0.2200, step time: 0.3169\n",
      "139/224, train_loss: 0.1542, step time: 0.3157\n",
      "140/224, train_loss: 0.1240, step time: 0.3888\n",
      "141/224, train_loss: 0.1830, step time: 0.3178\n",
      "142/224, train_loss: 0.1604, step time: 0.3156\n",
      "143/224, train_loss: 0.1135, step time: 0.3131\n",
      "144/224, train_loss: 0.1624, step time: 0.3854\n",
      "145/224, train_loss: 0.3790, step time: 0.3162\n",
      "146/224, train_loss: 0.3526, step time: 0.3164\n",
      "147/224, train_loss: 0.1249, step time: 0.3992\n",
      "148/224, train_loss: 0.2064, step time: 0.3137\n",
      "149/224, train_loss: 0.2097, step time: 0.3153\n",
      "150/224, train_loss: 0.1242, step time: 0.3692\n",
      "151/224, train_loss: 0.1755, step time: 0.3163\n",
      "152/224, train_loss: 0.1899, step time: 0.3163\n",
      "153/224, train_loss: 0.2282, step time: 0.3152\n",
      "154/224, train_loss: 0.2043, step time: 0.3968\n",
      "155/224, train_loss: 0.4162, step time: 0.4131\n",
      "156/224, train_loss: 0.4032, step time: 0.4110\n",
      "157/224, train_loss: 0.2994, step time: 0.3134\n",
      "158/224, train_loss: 0.3002, step time: 0.3153\n",
      "159/224, train_loss: 0.2697, step time: 0.3158\n",
      "160/224, train_loss: 0.4237, step time: 0.3718\n",
      "161/224, train_loss: 0.3088, step time: 0.4085\n",
      "162/224, train_loss: 0.1758, step time: 0.4051\n",
      "163/224, train_loss: 0.4162, step time: 0.3835\n",
      "164/224, train_loss: 0.2372, step time: 0.3180\n",
      "165/224, train_loss: 0.2455, step time: 0.3863\n",
      "166/224, train_loss: 0.1785, step time: 0.3162\n",
      "167/224, train_loss: 0.4350, step time: 0.3135\n",
      "168/224, train_loss: 0.2351, step time: 0.3983\n",
      "169/224, train_loss: 0.3231, step time: 0.3839\n",
      "170/224, train_loss: 0.2399, step time: 0.3963\n",
      "171/224, train_loss: 0.4330, step time: 0.4135\n",
      "172/224, train_loss: 0.1999, step time: 0.3153\n",
      "173/224, train_loss: 0.3450, step time: 0.3768\n",
      "174/224, train_loss: 0.2629, step time: 0.3161\n",
      "175/224, train_loss: 0.3431, step time: 0.3162\n",
      "176/224, train_loss: 0.2073, step time: 0.3162\n",
      "177/224, train_loss: 0.2725, step time: 0.3157\n",
      "178/224, train_loss: 0.1979, step time: 0.3134\n",
      "179/224, train_loss: 0.2879, step time: 0.3178\n",
      "180/224, train_loss: 0.3574, step time: 0.3831\n",
      "181/224, train_loss: 0.2628, step time: 0.3717\n",
      "182/224, train_loss: 0.1206, step time: 0.3161\n",
      "183/224, train_loss: 0.0824, step time: 0.3159\n",
      "184/224, train_loss: 0.1130, step time: 0.3825\n",
      "185/224, train_loss: 0.1385, step time: 0.3161\n",
      "186/224, train_loss: 0.2383, step time: 0.3714\n",
      "187/224, train_loss: 0.2852, step time: 0.3820\n",
      "188/224, train_loss: 0.2799, step time: 0.3167\n",
      "189/224, train_loss: 0.1631, step time: 0.3181\n",
      "190/224, train_loss: 0.2791, step time: 0.3152\n",
      "191/224, train_loss: 0.3755, step time: 0.3848\n",
      "192/224, train_loss: 0.2076, step time: 0.3155\n",
      "193/224, train_loss: 0.2296, step time: 0.3971\n",
      "194/224, train_loss: 0.3226, step time: 0.3163\n",
      "195/224, train_loss: 0.1942, step time: 0.3815\n",
      "196/224, train_loss: 0.2050, step time: 0.3174\n",
      "197/224, train_loss: 0.4360, step time: 0.3634\n",
      "198/224, train_loss: 0.1654, step time: 0.3153\n",
      "199/224, train_loss: 0.2342, step time: 0.3161\n",
      "200/224, train_loss: 0.3988, step time: 0.3162\n",
      "201/224, train_loss: 0.1782, step time: 0.3693\n",
      "202/224, train_loss: 0.1634, step time: 0.3131\n",
      "203/224, train_loss: 0.2830, step time: 0.4109\n",
      "204/224, train_loss: 0.3234, step time: 0.3677\n",
      "205/224, train_loss: 0.3615, step time: 0.3184\n",
      "206/224, train_loss: 0.2273, step time: 0.3737\n",
      "207/224, train_loss: 0.1918, step time: 0.3989\n",
      "208/224, train_loss: 0.1484, step time: 0.3165\n",
      "209/224, train_loss: 0.1416, step time: 0.3172\n",
      "210/224, train_loss: 0.4032, step time: 0.3838\n",
      "211/224, train_loss: 0.1776, step time: 0.4107\n",
      "212/224, train_loss: 0.0999, step time: 0.3164\n",
      "213/224, train_loss: 0.1207, step time: 0.3162\n",
      "214/224, train_loss: 0.1613, step time: 0.3714\n",
      "215/224, train_loss: 0.3993, step time: 0.3849\n",
      "216/224, train_loss: 0.3551, step time: 0.3915\n",
      "217/224, train_loss: 0.3066, step time: 0.3153\n",
      "218/224, train_loss: 0.1137, step time: 0.3140\n",
      "219/224, train_loss: 0.2193, step time: 0.3159\n",
      "220/224, train_loss: 0.1809, step time: 0.3180\n",
      "221/224, train_loss: 0.3011, step time: 0.3176\n",
      "222/224, train_loss: 0.1010, step time: 0.3186\n",
      "223/224, train_loss: 0.3379, step time: 0.3835\n",
      "224/224, train_loss: 0.1393, step time: 0.4095\n",
      "epoch 28 average loss: 0.2486\n",
      "current epoch: 28 current mean dice: 0.6856 class1: 0.9991 class2: 0.7237 class3: 0.3342\n",
      "best mean dice: 0.6856 at epoch: 28\n",
      "time consuming of epoch 28 is: 760.0586\n",
      "hello\n",
      "----------\n",
      "epoch 29/100\n",
      "1/224, train_loss: 0.3501, step time: 0.3933\n",
      "2/224, train_loss: 0.1251, step time: 0.4146\n",
      "3/224, train_loss: 0.1876, step time: 0.3899\n",
      "4/224, train_loss: 0.1330, step time: 0.3820\n",
      "5/224, train_loss: 0.1331, step time: 0.3159\n",
      "6/224, train_loss: 0.2185, step time: 0.3151\n",
      "7/224, train_loss: 0.3341, step time: 0.4042\n",
      "8/224, train_loss: 0.2254, step time: 0.3152\n",
      "9/224, train_loss: 0.2552, step time: 0.3823\n",
      "10/224, train_loss: 0.1793, step time: 0.3137\n",
      "11/224, train_loss: 0.2350, step time: 0.3908\n",
      "12/224, train_loss: 0.2704, step time: 0.3137\n",
      "13/224, train_loss: 0.2803, step time: 0.3154\n",
      "14/224, train_loss: 0.1901, step time: 0.4173\n",
      "15/224, train_loss: 0.3013, step time: 0.3156\n",
      "16/224, train_loss: 0.2549, step time: 0.3162\n",
      "17/224, train_loss: 0.3562, step time: 0.3726\n",
      "18/224, train_loss: 0.1729, step time: 0.3717\n",
      "19/224, train_loss: 0.2472, step time: 0.3159\n",
      "20/224, train_loss: 0.3007, step time: 0.3180\n",
      "21/224, train_loss: 0.1734, step time: 0.3809\n",
      "22/224, train_loss: 0.1358, step time: 0.4044\n",
      "23/224, train_loss: 0.1093, step time: 0.4091\n",
      "24/224, train_loss: 0.1385, step time: 0.3750\n",
      "25/224, train_loss: 0.2462, step time: 0.3759\n",
      "26/224, train_loss: 0.1640, step time: 0.3792\n",
      "27/224, train_loss: 0.2361, step time: 0.3888\n",
      "28/224, train_loss: 0.1891, step time: 0.3183\n",
      "29/224, train_loss: 0.3532, step time: 0.4078\n",
      "30/224, train_loss: 0.1000, step time: 0.3156\n",
      "31/224, train_loss: 0.1171, step time: 0.3971\n",
      "32/224, train_loss: 0.3906, step time: 0.3876\n",
      "33/224, train_loss: 0.3032, step time: 0.3178\n",
      "34/224, train_loss: 0.3047, step time: 0.3785\n",
      "35/224, train_loss: 0.3618, step time: 0.3126\n",
      "36/224, train_loss: 0.3689, step time: 0.3790\n",
      "37/224, train_loss: 0.2156, step time: 0.3183\n",
      "38/224, train_loss: 0.1638, step time: 0.3159\n",
      "39/224, train_loss: 0.2286, step time: 0.3175\n",
      "40/224, train_loss: 0.2202, step time: 0.3129\n",
      "41/224, train_loss: 0.2477, step time: 0.3123\n",
      "42/224, train_loss: 0.3005, step time: 0.3787\n",
      "43/224, train_loss: 0.2402, step time: 0.3132\n",
      "44/224, train_loss: 0.2347, step time: 0.3149\n",
      "45/224, train_loss: 0.2025, step time: 0.3767\n",
      "46/224, train_loss: 0.2618, step time: 0.3737\n",
      "47/224, train_loss: 0.2377, step time: 0.3752\n",
      "48/224, train_loss: 0.1269, step time: 0.3649\n",
      "49/224, train_loss: 0.1697, step time: 0.3684\n",
      "50/224, train_loss: 0.1218, step time: 0.3151\n",
      "51/224, train_loss: 0.1312, step time: 0.3176\n",
      "52/224, train_loss: 0.1080, step time: 0.3865\n",
      "53/224, train_loss: 0.1018, step time: 0.3949\n",
      "54/224, train_loss: 0.1312, step time: 0.3800\n",
      "55/224, train_loss: 0.3680, step time: 0.3940\n",
      "56/224, train_loss: 0.3583, step time: 0.3142\n",
      "57/224, train_loss: 0.2698, step time: 0.3121\n",
      "58/224, train_loss: 0.2091, step time: 0.4133\n",
      "59/224, train_loss: 0.3065, step time: 0.3177\n",
      "60/224, train_loss: 0.4314, step time: 0.3974\n",
      "61/224, train_loss: 0.2207, step time: 0.3160\n",
      "62/224, train_loss: 0.1628, step time: 0.3158\n",
      "63/224, train_loss: 0.1063, step time: 0.3172\n",
      "64/224, train_loss: 0.1330, step time: 0.3841\n",
      "65/224, train_loss: 0.1981, step time: 0.3798\n",
      "66/224, train_loss: 0.2258, step time: 0.3743\n",
      "67/224, train_loss: 0.2602, step time: 0.4071\n",
      "68/224, train_loss: 0.1233, step time: 0.3867\n",
      "69/224, train_loss: 0.1630, step time: 0.3147\n",
      "70/224, train_loss: 0.2628, step time: 0.3145\n",
      "71/224, train_loss: 0.1734, step time: 0.4001\n",
      "72/224, train_loss: 0.4121, step time: 0.4141\n",
      "73/224, train_loss: 0.1248, step time: 0.3152\n",
      "74/224, train_loss: 0.1051, step time: 0.3702\n",
      "75/224, train_loss: 0.1248, step time: 0.3181\n",
      "76/224, train_loss: 0.1948, step time: 0.3173\n",
      "77/224, train_loss: 0.1439, step time: 0.3171\n",
      "78/224, train_loss: 0.1535, step time: 0.4045\n",
      "79/224, train_loss: 0.3681, step time: 0.3148\n",
      "80/224, train_loss: 0.3425, step time: 0.3837\n",
      "81/224, train_loss: 0.5005, step time: 0.3835\n",
      "82/224, train_loss: 0.3322, step time: 0.3826\n",
      "83/224, train_loss: 0.1392, step time: 0.4039\n",
      "84/224, train_loss: 0.1007, step time: 0.4117\n",
      "85/224, train_loss: 0.2286, step time: 0.3771\n",
      "86/224, train_loss: 0.3226, step time: 0.4009\n",
      "87/224, train_loss: 0.1222, step time: 0.3151\n",
      "88/224, train_loss: 0.3290, step time: 0.3804\n",
      "89/224, train_loss: 0.2582, step time: 0.3173\n",
      "90/224, train_loss: 0.0818, step time: 0.3868\n",
      "91/224, train_loss: 0.2082, step time: 0.3716\n",
      "92/224, train_loss: 0.1480, step time: 0.3152\n",
      "93/224, train_loss: 0.2631, step time: 0.3174\n",
      "94/224, train_loss: 0.1095, step time: 0.3123\n",
      "95/224, train_loss: 0.2101, step time: 0.3829\n",
      "96/224, train_loss: 0.4517, step time: 0.3910\n",
      "97/224, train_loss: 0.1781, step time: 0.4118\n",
      "98/224, train_loss: 0.2345, step time: 0.3915\n",
      "99/224, train_loss: 0.2325, step time: 0.3152\n",
      "100/224, train_loss: 0.3829, step time: 0.3153\n",
      "101/224, train_loss: 0.1585, step time: 0.3147\n",
      "102/224, train_loss: 0.2125, step time: 0.3177\n",
      "103/224, train_loss: 0.1865, step time: 0.3160\n",
      "104/224, train_loss: 0.3957, step time: 0.3145\n",
      "105/224, train_loss: 0.1978, step time: 0.4055\n",
      "106/224, train_loss: 0.3692, step time: 0.3145\n",
      "107/224, train_loss: 0.2636, step time: 0.3997\n",
      "108/224, train_loss: 0.1472, step time: 0.3644\n",
      "109/224, train_loss: 0.2450, step time: 0.3749\n",
      "110/224, train_loss: 0.1687, step time: 0.4118\n",
      "111/224, train_loss: 0.2113, step time: 0.4070\n",
      "112/224, train_loss: 0.1230, step time: 0.3147\n",
      "113/224, train_loss: 0.2649, step time: 0.3735\n",
      "114/224, train_loss: 0.1918, step time: 0.3656\n",
      "115/224, train_loss: 0.4134, step time: 0.4006\n",
      "116/224, train_loss: 0.1525, step time: 0.3134\n",
      "117/224, train_loss: 0.1277, step time: 0.4042\n",
      "118/224, train_loss: 0.4264, step time: 0.3151\n",
      "119/224, train_loss: 0.1326, step time: 0.3831\n",
      "120/224, train_loss: 0.2161, step time: 0.3176\n",
      "121/224, train_loss: 0.3843, step time: 0.3837\n",
      "122/224, train_loss: 0.1812, step time: 0.3926\n",
      "123/224, train_loss: 0.2711, step time: 0.3161\n",
      "124/224, train_loss: 0.2244, step time: 0.3151\n",
      "125/224, train_loss: 0.1343, step time: 0.3145\n",
      "126/224, train_loss: 0.3017, step time: 0.3121\n",
      "127/224, train_loss: 0.3121, step time: 0.3646\n",
      "128/224, train_loss: 0.2027, step time: 0.3144\n",
      "129/224, train_loss: 0.3010, step time: 0.3148\n",
      "130/224, train_loss: 0.0751, step time: 0.3165\n",
      "131/224, train_loss: 0.2889, step time: 0.3812\n",
      "132/224, train_loss: 0.3511, step time: 0.3870\n",
      "133/224, train_loss: 0.1662, step time: 0.3126\n",
      "134/224, train_loss: 0.3343, step time: 0.3679\n",
      "135/224, train_loss: 0.1920, step time: 0.3944\n",
      "136/224, train_loss: 0.1140, step time: 0.3152\n",
      "137/224, train_loss: 0.2366, step time: 0.3938\n",
      "138/224, train_loss: 0.1720, step time: 0.3149\n",
      "139/224, train_loss: 0.1028, step time: 0.3159\n",
      "140/224, train_loss: 0.1299, step time: 0.3145\n",
      "141/224, train_loss: 0.2419, step time: 0.3655\n",
      "142/224, train_loss: 0.4032, step time: 0.3169\n",
      "143/224, train_loss: 0.3760, step time: 0.3147\n",
      "144/224, train_loss: 0.1402, step time: 0.3152\n",
      "145/224, train_loss: 0.3581, step time: 0.3148\n",
      "146/224, train_loss: 0.3673, step time: 0.3143\n",
      "147/224, train_loss: 0.3598, step time: 0.3143\n",
      "148/224, train_loss: 0.1107, step time: 0.3150\n",
      "149/224, train_loss: 0.1643, step time: 0.3743\n",
      "150/224, train_loss: 0.3386, step time: 0.3818\n",
      "151/224, train_loss: 0.1851, step time: 0.3679\n",
      "152/224, train_loss: 0.3598, step time: 0.3724\n",
      "153/224, train_loss: 0.2558, step time: 0.4035\n",
      "154/224, train_loss: 0.3913, step time: 0.3918\n",
      "155/224, train_loss: 0.0870, step time: 0.3145\n",
      "156/224, train_loss: 0.1507, step time: 0.3900\n",
      "157/224, train_loss: 0.4235, step time: 0.4070\n",
      "158/224, train_loss: 0.3575, step time: 0.3126\n",
      "159/224, train_loss: 0.3122, step time: 0.3697\n",
      "160/224, train_loss: 0.4230, step time: 0.3918\n",
      "161/224, train_loss: 0.0969, step time: 0.4055\n",
      "162/224, train_loss: 0.1795, step time: 0.3174\n",
      "163/224, train_loss: 0.2263, step time: 0.3722\n",
      "164/224, train_loss: 0.1910, step time: 0.3127\n",
      "165/224, train_loss: 0.1483, step time: 0.3145\n",
      "166/224, train_loss: 0.1904, step time: 0.3142\n",
      "167/224, train_loss: 0.1863, step time: 0.3143\n",
      "168/224, train_loss: 0.1952, step time: 0.3141\n",
      "169/224, train_loss: 0.3347, step time: 0.3851\n",
      "170/224, train_loss: 0.2154, step time: 0.3162\n",
      "171/224, train_loss: 0.3048, step time: 0.3942\n",
      "172/224, train_loss: 0.2652, step time: 0.3144\n",
      "173/224, train_loss: 0.2715, step time: 0.3760\n",
      "174/224, train_loss: 0.1417, step time: 0.3156\n",
      "175/224, train_loss: 0.1344, step time: 0.3151\n",
      "176/224, train_loss: 0.2912, step time: 0.3728\n",
      "177/224, train_loss: 0.2597, step time: 0.3151\n",
      "178/224, train_loss: 0.4304, step time: 0.3956\n",
      "179/224, train_loss: 0.4104, step time: 0.3173\n",
      "180/224, train_loss: 0.1537, step time: 0.3156\n",
      "181/224, train_loss: 0.1887, step time: 0.3153\n",
      "182/224, train_loss: 0.1472, step time: 0.3773\n",
      "183/224, train_loss: 0.1292, step time: 0.3155\n",
      "184/224, train_loss: 0.4570, step time: 0.4075\n",
      "185/224, train_loss: 0.2892, step time: 0.3151\n",
      "186/224, train_loss: 0.2402, step time: 0.3155\n",
      "187/224, train_loss: 0.1856, step time: 0.3147\n",
      "188/224, train_loss: 0.1251, step time: 0.3142\n",
      "189/224, train_loss: 0.2349, step time: 0.3975\n",
      "190/224, train_loss: 0.2552, step time: 0.3767\n",
      "191/224, train_loss: 0.1921, step time: 0.3137\n",
      "192/224, train_loss: 0.1797, step time: 0.3932\n",
      "193/224, train_loss: 0.1179, step time: 0.3129\n",
      "194/224, train_loss: 0.3710, step time: 0.3932\n",
      "195/224, train_loss: 0.1379, step time: 0.3177\n",
      "196/224, train_loss: 0.2025, step time: 0.3176\n",
      "197/224, train_loss: 0.2071, step time: 0.4104\n",
      "198/224, train_loss: 0.3335, step time: 0.3160\n",
      "199/224, train_loss: 0.1646, step time: 0.3787\n",
      "200/224, train_loss: 0.2692, step time: 0.3768\n",
      "201/224, train_loss: 0.2963, step time: 0.3147\n",
      "202/224, train_loss: 0.2246, step time: 0.3169\n",
      "203/224, train_loss: 0.1511, step time: 0.3899\n",
      "204/224, train_loss: 0.1773, step time: 0.3153\n",
      "205/224, train_loss: 0.2596, step time: 0.3153\n",
      "206/224, train_loss: 0.2317, step time: 0.3154\n",
      "207/224, train_loss: 0.2003, step time: 0.4011\n",
      "208/224, train_loss: 0.2478, step time: 0.3797\n",
      "209/224, train_loss: 0.2516, step time: 0.3786\n",
      "210/224, train_loss: 0.2258, step time: 0.3772\n",
      "211/224, train_loss: 0.0706, step time: 0.4013\n",
      "212/224, train_loss: 0.2698, step time: 0.3645\n",
      "213/224, train_loss: 0.1995, step time: 0.3149\n",
      "214/224, train_loss: 0.2317, step time: 0.3148\n",
      "215/224, train_loss: 0.1449, step time: 0.3687\n",
      "216/224, train_loss: 0.1532, step time: 0.3715\n",
      "217/224, train_loss: 0.1570, step time: 0.4006\n",
      "218/224, train_loss: 0.3474, step time: 0.3862\n",
      "219/224, train_loss: 0.1800, step time: 0.3157\n",
      "220/224, train_loss: 0.1911, step time: 0.3156\n",
      "221/224, train_loss: 0.1802, step time: 0.3132\n",
      "222/224, train_loss: 0.1620, step time: 0.3179\n",
      "223/224, train_loss: 0.1663, step time: 0.4144\n",
      "224/224, train_loss: 0.2710, step time: 0.3758\n",
      "epoch 29 average loss: 0.2303\n",
      "current epoch: 29 current mean dice: 0.6814 class1: 0.9990 class2: 0.7082 class3: 0.3370\n",
      "best mean dice: 0.6856 at epoch: 28\n",
      "time consuming of epoch 29 is: 733.7352\n",
      "hello\n",
      "----------\n",
      "epoch 30/100\n",
      "1/224, train_loss: 0.0980, step time: 0.3964\n",
      "2/224, train_loss: 0.1407, step time: 0.4064\n",
      "3/224, train_loss: 0.2538, step time: 0.3789\n",
      "4/224, train_loss: 0.3276, step time: 0.3891\n",
      "5/224, train_loss: 0.3123, step time: 0.3945\n",
      "6/224, train_loss: 0.2802, step time: 0.3172\n",
      "7/224, train_loss: 0.2561, step time: 0.3703\n",
      "8/224, train_loss: 0.1302, step time: 0.3744\n",
      "9/224, train_loss: 0.3510, step time: 0.3627\n",
      "10/224, train_loss: 0.2377, step time: 0.3149\n",
      "11/224, train_loss: 0.2735, step time: 0.3149\n",
      "12/224, train_loss: 0.2552, step time: 0.3732\n",
      "13/224, train_loss: 0.2738, step time: 0.3808\n",
      "14/224, train_loss: 0.1874, step time: 0.3840\n",
      "15/224, train_loss: 0.1442, step time: 0.3174\n",
      "16/224, train_loss: 0.3523, step time: 0.3148\n",
      "17/224, train_loss: 0.2464, step time: 0.3699\n",
      "18/224, train_loss: 0.1818, step time: 0.3136\n",
      "19/224, train_loss: 0.2585, step time: 0.4083\n",
      "20/224, train_loss: 0.1314, step time: 0.3815\n",
      "21/224, train_loss: 0.1314, step time: 0.3177\n",
      "22/224, train_loss: 0.1399, step time: 0.3839\n",
      "23/224, train_loss: 0.2513, step time: 0.3175\n",
      "24/224, train_loss: 0.1643, step time: 0.3700\n",
      "25/224, train_loss: 0.2998, step time: 0.3148\n",
      "26/224, train_loss: 0.2664, step time: 0.3146\n",
      "27/224, train_loss: 0.3516, step time: 0.3984\n",
      "28/224, train_loss: 0.1788, step time: 0.3144\n",
      "29/224, train_loss: 0.2146, step time: 0.3153\n",
      "30/224, train_loss: 0.1932, step time: 0.3870\n",
      "31/224, train_loss: 0.2051, step time: 0.3892\n",
      "32/224, train_loss: 0.2419, step time: 0.3658\n",
      "33/224, train_loss: 0.2539, step time: 0.3141\n",
      "34/224, train_loss: 0.1185, step time: 0.3122\n",
      "35/224, train_loss: 0.3622, step time: 0.3861\n",
      "36/224, train_loss: 0.1145, step time: 0.3178\n",
      "37/224, train_loss: 0.3177, step time: 0.3151\n",
      "38/224, train_loss: 0.1315, step time: 0.3715\n",
      "39/224, train_loss: 0.1304, step time: 0.3171\n",
      "40/224, train_loss: 0.2365, step time: 0.3893\n",
      "41/224, train_loss: 0.3880, step time: 0.3164\n",
      "42/224, train_loss: 0.1670, step time: 0.3142\n",
      "43/224, train_loss: 0.0984, step time: 0.3738\n",
      "44/224, train_loss: 0.2638, step time: 0.3180\n",
      "45/224, train_loss: 0.2181, step time: 0.3157\n",
      "46/224, train_loss: 0.4362, step time: 0.3672\n",
      "47/224, train_loss: 0.1655, step time: 0.3166\n",
      "48/224, train_loss: 0.3099, step time: 0.3141\n",
      "49/224, train_loss: 0.2660, step time: 0.3655\n",
      "50/224, train_loss: 0.1335, step time: 0.3145\n",
      "51/224, train_loss: 0.1150, step time: 0.3877\n",
      "52/224, train_loss: 0.1449, step time: 0.3925\n",
      "53/224, train_loss: 0.1188, step time: 0.4043\n",
      "54/224, train_loss: 0.0837, step time: 0.3174\n",
      "55/224, train_loss: 0.1412, step time: 0.3133\n",
      "56/224, train_loss: 0.4166, step time: 0.3928\n",
      "57/224, train_loss: 0.1282, step time: 0.3155\n",
      "58/224, train_loss: 0.0918, step time: 0.3152\n",
      "59/224, train_loss: 0.1703, step time: 0.3179\n",
      "60/224, train_loss: 0.1553, step time: 0.3175\n",
      "61/224, train_loss: 0.1647, step time: 0.3888\n",
      "62/224, train_loss: 0.1600, step time: 0.3966\n",
      "63/224, train_loss: 0.2922, step time: 0.3797\n",
      "64/224, train_loss: 0.3171, step time: 0.3978\n",
      "65/224, train_loss: 0.0895, step time: 0.3888\n",
      "66/224, train_loss: 0.2656, step time: 0.3131\n",
      "67/224, train_loss: 0.1542, step time: 0.3672\n",
      "68/224, train_loss: 0.2399, step time: 0.3124\n",
      "69/224, train_loss: 0.3650, step time: 0.3151\n",
      "70/224, train_loss: 0.1081, step time: 0.3174\n",
      "71/224, train_loss: 0.1097, step time: 0.3170\n",
      "72/224, train_loss: 0.1124, step time: 0.3755\n",
      "73/224, train_loss: 0.0884, step time: 0.3842\n",
      "74/224, train_loss: 0.4349, step time: 0.3720\n",
      "75/224, train_loss: 0.2156, step time: 0.3911\n",
      "76/224, train_loss: 0.1724, step time: 0.4105\n",
      "77/224, train_loss: 0.3173, step time: 0.3145\n",
      "78/224, train_loss: 0.1313, step time: 0.3695\n",
      "79/224, train_loss: 0.1483, step time: 0.3962\n",
      "80/224, train_loss: 0.1420, step time: 0.4125\n",
      "81/224, train_loss: 0.0895, step time: 0.3127\n",
      "82/224, train_loss: 0.1430, step time: 0.3896\n",
      "83/224, train_loss: 0.2046, step time: 0.3125\n",
      "84/224, train_loss: 0.3459, step time: 0.4082\n",
      "85/224, train_loss: 0.3540, step time: 0.4029\n",
      "86/224, train_loss: 0.0923, step time: 0.3144\n",
      "87/224, train_loss: 0.1399, step time: 0.3652\n",
      "88/224, train_loss: 0.2607, step time: 0.4121\n",
      "89/224, train_loss: 0.1231, step time: 0.3167\n",
      "90/224, train_loss: 0.1315, step time: 0.3794\n",
      "91/224, train_loss: 0.1659, step time: 0.3124\n",
      "92/224, train_loss: 0.1424, step time: 0.3865\n",
      "93/224, train_loss: 0.2280, step time: 0.3122\n",
      "94/224, train_loss: 0.3124, step time: 0.3715\n",
      "95/224, train_loss: 0.1455, step time: 0.3174\n",
      "96/224, train_loss: 0.2226, step time: 0.3146\n",
      "97/224, train_loss: 0.2301, step time: 0.3167\n",
      "98/224, train_loss: 0.0962, step time: 0.4120\n",
      "99/224, train_loss: 0.4410, step time: 0.4008\n",
      "100/224, train_loss: 0.3332, step time: 0.3768\n",
      "101/224, train_loss: 0.2782, step time: 0.3903\n",
      "102/224, train_loss: 0.1041, step time: 0.3126\n",
      "103/224, train_loss: 0.1774, step time: 0.3873\n",
      "104/224, train_loss: 0.1349, step time: 0.3155\n",
      "105/224, train_loss: 0.1144, step time: 0.3150\n",
      "106/224, train_loss: 0.2071, step time: 0.3145\n",
      "107/224, train_loss: 0.2149, step time: 0.3810\n",
      "108/224, train_loss: 0.2065, step time: 0.3172\n",
      "109/224, train_loss: 0.3173, step time: 0.3915\n",
      "110/224, train_loss: 0.3894, step time: 0.4126\n",
      "111/224, train_loss: 0.2778, step time: 0.3845\n",
      "112/224, train_loss: 0.2391, step time: 0.3813\n",
      "113/224, train_loss: 0.4509, step time: 0.4017\n",
      "114/224, train_loss: 0.0932, step time: 0.3154\n",
      "115/224, train_loss: 0.1894, step time: 0.3810\n",
      "116/224, train_loss: 0.3657, step time: 0.3169\n",
      "117/224, train_loss: 0.1963, step time: 0.4056\n",
      "118/224, train_loss: 0.1481, step time: 0.3149\n",
      "119/224, train_loss: 0.3854, step time: 0.3148\n",
      "120/224, train_loss: 0.3148, step time: 0.3178\n",
      "121/224, train_loss: 0.3819, step time: 0.3851\n",
      "122/224, train_loss: 0.1615, step time: 0.3898\n",
      "123/224, train_loss: 0.2026, step time: 0.3777\n",
      "124/224, train_loss: 0.1444, step time: 0.3880\n",
      "125/224, train_loss: 0.2274, step time: 0.3152\n",
      "126/224, train_loss: 0.2313, step time: 0.3151\n",
      "127/224, train_loss: 0.3594, step time: 0.3754\n",
      "128/224, train_loss: 0.2225, step time: 0.3131\n",
      "129/224, train_loss: 0.3906, step time: 0.3168\n",
      "130/224, train_loss: 0.1515, step time: 0.3122\n",
      "131/224, train_loss: 0.2075, step time: 0.3123\n",
      "132/224, train_loss: 0.3876, step time: 0.3982\n",
      "133/224, train_loss: 0.1742, step time: 0.4110\n",
      "134/224, train_loss: 0.1617, step time: 0.3143\n",
      "135/224, train_loss: 0.1324, step time: 0.3152\n",
      "136/224, train_loss: 0.3564, step time: 0.3925\n",
      "137/224, train_loss: 0.3656, step time: 0.3785\n",
      "138/224, train_loss: 0.2410, step time: 0.4026\n",
      "139/224, train_loss: 0.2467, step time: 0.3144\n",
      "140/224, train_loss: 0.2142, step time: 0.3141\n",
      "141/224, train_loss: 0.1384, step time: 0.3147\n",
      "142/224, train_loss: 0.1069, step time: 0.4071\n",
      "143/224, train_loss: 0.1050, step time: 0.3685\n",
      "144/224, train_loss: 0.1295, step time: 0.3972\n",
      "145/224, train_loss: 0.2303, step time: 0.3159\n",
      "146/224, train_loss: 0.1393, step time: 0.3770\n",
      "147/224, train_loss: 0.1935, step time: 0.3881\n",
      "148/224, train_loss: 0.2341, step time: 0.3152\n",
      "149/224, train_loss: 0.1463, step time: 0.3152\n",
      "150/224, train_loss: 0.3276, step time: 0.3131\n",
      "151/224, train_loss: 0.3745, step time: 0.3996\n",
      "152/224, train_loss: 0.2934, step time: 0.4074\n",
      "153/224, train_loss: 0.1107, step time: 0.3703\n",
      "154/224, train_loss: 0.2361, step time: 0.3145\n",
      "155/224, train_loss: 0.1867, step time: 0.3825\n",
      "156/224, train_loss: 0.4150, step time: 0.3679\n",
      "157/224, train_loss: 0.3589, step time: 0.3812\n",
      "158/224, train_loss: 0.2309, step time: 0.3156\n",
      "159/224, train_loss: 0.1254, step time: 0.3173\n",
      "160/224, train_loss: 0.1017, step time: 0.3123\n",
      "161/224, train_loss: 0.1306, step time: 0.3950\n",
      "162/224, train_loss: 0.1719, step time: 0.3159\n",
      "163/224, train_loss: 0.3481, step time: 0.3977\n",
      "164/224, train_loss: 0.1180, step time: 0.3135\n",
      "165/224, train_loss: 0.2814, step time: 0.3951\n",
      "166/224, train_loss: 0.3414, step time: 0.3154\n",
      "167/224, train_loss: 0.1990, step time: 0.3737\n",
      "168/224, train_loss: 0.1237, step time: 0.3964\n",
      "169/224, train_loss: 0.2059, step time: 0.3685\n",
      "170/224, train_loss: 0.3479, step time: 0.3908\n",
      "171/224, train_loss: 0.3197, step time: 0.3849\n",
      "172/224, train_loss: 0.2054, step time: 0.3180\n",
      "173/224, train_loss: 0.1060, step time: 0.3137\n",
      "174/224, train_loss: 0.1139, step time: 0.3131\n",
      "175/224, train_loss: 0.2409, step time: 0.3146\n",
      "176/224, train_loss: 0.2201, step time: 0.3866\n",
      "177/224, train_loss: 0.2206, step time: 0.3155\n",
      "178/224, train_loss: 0.3753, step time: 0.3147\n",
      "179/224, train_loss: 0.3688, step time: 0.3177\n",
      "180/224, train_loss: 0.4176, step time: 0.3159\n",
      "181/224, train_loss: 0.3773, step time: 0.3840\n",
      "182/224, train_loss: 0.0790, step time: 0.3126\n",
      "183/224, train_loss: 0.2419, step time: 0.3826\n",
      "184/224, train_loss: 0.3761, step time: 0.3176\n",
      "185/224, train_loss: 0.3421, step time: 0.3775\n",
      "186/224, train_loss: 0.1393, step time: 0.3182\n",
      "187/224, train_loss: 0.2231, step time: 0.3914\n",
      "188/224, train_loss: 0.2270, step time: 0.3133\n",
      "189/224, train_loss: 0.3210, step time: 0.3147\n",
      "190/224, train_loss: 0.3606, step time: 0.3723\n",
      "191/224, train_loss: 0.1029, step time: 0.3170\n",
      "192/224, train_loss: 0.0778, step time: 0.3902\n",
      "193/224, train_loss: 0.1223, step time: 0.3140\n",
      "194/224, train_loss: 0.1120, step time: 0.3155\n",
      "195/224, train_loss: 0.0905, step time: 0.3148\n",
      "196/224, train_loss: 0.4181, step time: 0.3948\n",
      "197/224, train_loss: 0.2149, step time: 0.3157\n",
      "198/224, train_loss: 0.2288, step time: 0.3967\n",
      "199/224, train_loss: 0.2171, step time: 0.3147\n",
      "200/224, train_loss: 0.2451, step time: 0.3889\n",
      "201/224, train_loss: 0.3019, step time: 0.3154\n",
      "202/224, train_loss: 0.1792, step time: 0.4010\n",
      "203/224, train_loss: 0.1372, step time: 0.3132\n",
      "204/224, train_loss: 0.1471, step time: 0.3838\n",
      "205/224, train_loss: 0.2493, step time: 0.3171\n",
      "206/224, train_loss: 0.1940, step time: 0.3140\n",
      "207/224, train_loss: 0.2517, step time: 0.3176\n",
      "208/224, train_loss: 0.1375, step time: 0.3921\n",
      "209/224, train_loss: 0.3893, step time: 0.4109\n",
      "210/224, train_loss: 0.4162, step time: 0.3806\n",
      "211/224, train_loss: 0.1110, step time: 0.3964\n",
      "212/224, train_loss: 0.1575, step time: 0.3170\n",
      "213/224, train_loss: 0.4861, step time: 0.3894\n",
      "214/224, train_loss: 0.2472, step time: 0.3151\n",
      "215/224, train_loss: 0.2466, step time: 0.4089\n",
      "216/224, train_loss: 0.2206, step time: 0.4090\n",
      "217/224, train_loss: 0.1999, step time: 0.3798\n",
      "218/224, train_loss: 0.1471, step time: 0.3150\n",
      "219/224, train_loss: 0.3068, step time: 0.3155\n",
      "220/224, train_loss: 0.2495, step time: 0.3871\n",
      "221/224, train_loss: 0.0911, step time: 0.3885\n",
      "222/224, train_loss: 0.1629, step time: 0.3963\n",
      "223/224, train_loss: 0.1854, step time: 0.3780\n",
      "224/224, train_loss: 0.1975, step time: 0.3720\n",
      "epoch 30 average loss: 0.2231\n",
      "current epoch: 30 current mean dice: 0.6784 class1: 0.9992 class2: 0.7237 class3: 0.3124\n",
      "best mean dice: 0.6856 at epoch: 28\n",
      "time consuming of epoch 30 is: 786.8488\n",
      "hello\n",
      "----------\n",
      "epoch 31/100\n",
      "1/224, train_loss: 0.2504, step time: 0.3713\n",
      "2/224, train_loss: 0.0851, step time: 0.3176\n",
      "3/224, train_loss: 0.1227, step time: 0.4049\n",
      "4/224, train_loss: 0.2207, step time: 0.3153\n",
      "5/224, train_loss: 0.1123, step time: 0.3170\n",
      "6/224, train_loss: 0.0892, step time: 0.3678\n",
      "7/224, train_loss: 0.3555, step time: 0.3155\n",
      "8/224, train_loss: 0.1423, step time: 0.3134\n",
      "9/224, train_loss: 0.3508, step time: 0.3726\n",
      "10/224, train_loss: 0.3099, step time: 0.3690\n",
      "11/224, train_loss: 0.2008, step time: 0.3876\n",
      "12/224, train_loss: 0.1729, step time: 0.3156\n",
      "13/224, train_loss: 0.4363, step time: 0.3770\n",
      "14/224, train_loss: 0.1093, step time: 0.3174\n",
      "15/224, train_loss: 0.2513, step time: 0.3994\n",
      "16/224, train_loss: 0.1495, step time: 0.3161\n",
      "17/224, train_loss: 0.3497, step time: 0.3130\n",
      "18/224, train_loss: 0.2486, step time: 0.3172\n",
      "19/224, train_loss: 0.1804, step time: 0.3816\n",
      "20/224, train_loss: 0.1480, step time: 0.3150\n",
      "21/224, train_loss: 0.2080, step time: 0.5565\n",
      "22/224, train_loss: 0.3523, step time: 0.3813\n",
      "23/224, train_loss: 0.0942, step time: 0.3149\n",
      "24/224, train_loss: 0.1791, step time: 0.3174\n",
      "25/224, train_loss: 0.0906, step time: 0.3710\n",
      "26/224, train_loss: 0.3539, step time: 0.3706\n",
      "27/224, train_loss: 0.1404, step time: 0.3149\n",
      "28/224, train_loss: 0.1160, step time: 0.3149\n",
      "29/224, train_loss: 0.1519, step time: 0.3171\n",
      "30/224, train_loss: 0.0829, step time: 0.3127\n",
      "31/224, train_loss: 0.1222, step time: 0.3828\n",
      "32/224, train_loss: 0.1073, step time: 0.4037\n",
      "33/224, train_loss: 0.0551, step time: 0.3796\n",
      "34/224, train_loss: 0.0942, step time: 0.3739\n",
      "35/224, train_loss: 0.3370, step time: 0.3760\n",
      "36/224, train_loss: 0.1014, step time: 0.3156\n",
      "37/224, train_loss: 0.1045, step time: 0.3154\n",
      "38/224, train_loss: 0.1016, step time: 0.3873\n",
      "39/224, train_loss: 0.1255, step time: 0.3155\n",
      "40/224, train_loss: 0.1464, step time: 0.3159\n",
      "41/224, train_loss: 0.3270, step time: 0.3157\n",
      "42/224, train_loss: 0.1473, step time: 0.3834\n",
      "43/224, train_loss: 0.3387, step time: 0.3796\n",
      "44/224, train_loss: 0.2042, step time: 0.3182\n",
      "45/224, train_loss: 0.1466, step time: 0.3789\n",
      "46/224, train_loss: 0.0904, step time: 0.4069\n",
      "47/224, train_loss: 0.2640, step time: 0.3181\n",
      "48/224, train_loss: 0.2023, step time: 0.3143\n",
      "49/224, train_loss: 0.1700, step time: 0.3182\n",
      "50/224, train_loss: 0.3963, step time: 0.4010\n",
      "51/224, train_loss: 0.2135, step time: 0.3809\n",
      "52/224, train_loss: 0.3685, step time: 0.3925\n",
      "53/224, train_loss: 0.4171, step time: 0.4021\n",
      "54/224, train_loss: 0.1660, step time: 0.3179\n",
      "55/224, train_loss: 0.1566, step time: 0.3172\n",
      "56/224, train_loss: 0.4366, step time: 0.3125\n",
      "57/224, train_loss: 0.3715, step time: 0.3915\n",
      "58/224, train_loss: 0.1037, step time: 0.4096\n",
      "59/224, train_loss: 0.1278, step time: 0.3753\n",
      "60/224, train_loss: 0.3576, step time: 0.4096\n",
      "61/224, train_loss: 0.4076, step time: 0.3978\n",
      "62/224, train_loss: 0.2104, step time: 0.3753\n",
      "63/224, train_loss: 0.1843, step time: 0.3134\n",
      "64/224, train_loss: 0.3096, step time: 0.3927\n",
      "65/224, train_loss: 0.2342, step time: 0.4046\n",
      "66/224, train_loss: 0.0924, step time: 0.3176\n",
      "67/224, train_loss: 0.1208, step time: 0.3836\n",
      "68/224, train_loss: 0.2393, step time: 0.4084\n",
      "69/224, train_loss: 0.1428, step time: 0.3885\n",
      "70/224, train_loss: 0.1542, step time: 0.3126\n",
      "71/224, train_loss: 0.3974, step time: 0.3946\n",
      "72/224, train_loss: 0.0872, step time: 0.3169\n",
      "73/224, train_loss: 0.1425, step time: 0.3178\n",
      "74/224, train_loss: 0.4158, step time: 0.3153\n",
      "75/224, train_loss: 0.1406, step time: 0.3719\n",
      "76/224, train_loss: 0.2440, step time: 0.3766\n",
      "77/224, train_loss: 0.1564, step time: 0.3735\n",
      "78/224, train_loss: 0.3096, step time: 0.3174\n",
      "79/224, train_loss: 0.1630, step time: 0.3182\n",
      "80/224, train_loss: 0.3407, step time: 0.3150\n",
      "81/224, train_loss: 0.2258, step time: 0.3964\n",
      "82/224, train_loss: 0.3125, step time: 0.3988\n",
      "83/224, train_loss: 0.1262, step time: 0.3147\n",
      "84/224, train_loss: 0.1417, step time: 0.3175\n",
      "85/224, train_loss: 0.1234, step time: 0.3175\n",
      "86/224, train_loss: 0.1406, step time: 0.3172\n",
      "87/224, train_loss: 0.1623, step time: 0.3735\n",
      "88/224, train_loss: 0.1321, step time: 0.3137\n",
      "89/224, train_loss: 0.2254, step time: 0.4085\n",
      "90/224, train_loss: 0.2006, step time: 0.3176\n",
      "91/224, train_loss: 0.1829, step time: 0.4081\n",
      "92/224, train_loss: 0.1893, step time: 0.3883\n",
      "93/224, train_loss: 0.2583, step time: 0.3876\n",
      "94/224, train_loss: 0.1786, step time: 0.3149\n",
      "95/224, train_loss: 0.2815, step time: 0.3744\n",
      "96/224, train_loss: 0.1165, step time: 0.3151\n",
      "97/224, train_loss: 0.1512, step time: 0.3176\n",
      "98/224, train_loss: 0.1056, step time: 0.3155\n",
      "99/224, train_loss: 0.1607, step time: 0.3153\n",
      "100/224, train_loss: 0.2110, step time: 0.3718\n",
      "101/224, train_loss: 0.2567, step time: 0.4008\n",
      "102/224, train_loss: 0.3634, step time: 0.4059\n",
      "103/224, train_loss: 0.2061, step time: 0.3155\n",
      "104/224, train_loss: 0.3310, step time: 0.3174\n",
      "105/224, train_loss: 0.1179, step time: 0.3835\n",
      "106/224, train_loss: 0.1058, step time: 0.3174\n",
      "107/224, train_loss: 0.1962, step time: 0.3125\n",
      "108/224, train_loss: 0.1038, step time: 0.3153\n",
      "109/224, train_loss: 0.1962, step time: 0.3150\n",
      "110/224, train_loss: 0.3225, step time: 0.3677\n",
      "111/224, train_loss: 0.2459, step time: 0.3806\n",
      "112/224, train_loss: 0.1307, step time: 0.3173\n",
      "113/224, train_loss: 0.4324, step time: 0.3885\n",
      "114/224, train_loss: 0.1501, step time: 0.3179\n",
      "115/224, train_loss: 0.1961, step time: 0.3751\n",
      "116/224, train_loss: 0.2580, step time: 0.3162\n",
      "117/224, train_loss: 0.3833, step time: 0.4046\n",
      "118/224, train_loss: 0.0603, step time: 0.3145\n",
      "119/224, train_loss: 0.1856, step time: 0.3657\n",
      "120/224, train_loss: 0.0583, step time: 0.3816\n",
      "121/224, train_loss: 0.2470, step time: 0.3783\n",
      "122/224, train_loss: 0.2207, step time: 0.3745\n",
      "123/224, train_loss: 0.2269, step time: 0.4050\n",
      "124/224, train_loss: 0.3773, step time: 0.3154\n",
      "125/224, train_loss: 0.1134, step time: 0.3171\n",
      "126/224, train_loss: 0.1766, step time: 0.3174\n",
      "127/224, train_loss: 0.1171, step time: 0.3168\n",
      "128/224, train_loss: 0.2990, step time: 0.3889\n",
      "129/224, train_loss: 0.3674, step time: 0.4059\n",
      "130/224, train_loss: 0.1727, step time: 0.3700\n",
      "131/224, train_loss: 0.2545, step time: 0.3789\n",
      "132/224, train_loss: 0.2769, step time: 0.3146\n",
      "133/224, train_loss: 0.2910, step time: 0.3148\n",
      "134/224, train_loss: 0.1503, step time: 0.3146\n",
      "135/224, train_loss: 0.2794, step time: 0.3743\n",
      "136/224, train_loss: 0.1699, step time: 0.3707\n",
      "137/224, train_loss: 0.1897, step time: 0.3708\n",
      "138/224, train_loss: 0.2516, step time: 0.3123\n",
      "139/224, train_loss: 0.2479, step time: 0.3677\n",
      "140/224, train_loss: 0.1323, step time: 0.3132\n",
      "141/224, train_loss: 0.2908, step time: 0.4128\n",
      "142/224, train_loss: 0.1836, step time: 0.3169\n",
      "143/224, train_loss: 0.1482, step time: 0.3148\n",
      "144/224, train_loss: 0.1791, step time: 0.3678\n",
      "145/224, train_loss: 0.3776, step time: 0.3668\n",
      "146/224, train_loss: 0.3984, step time: 0.3169\n",
      "147/224, train_loss: 0.1326, step time: 0.3142\n",
      "148/224, train_loss: 0.1520, step time: 0.3150\n",
      "149/224, train_loss: 0.1678, step time: 0.4075\n",
      "150/224, train_loss: 0.2239, step time: 0.3662\n",
      "151/224, train_loss: 0.1773, step time: 0.3744\n",
      "152/224, train_loss: 0.1333, step time: 0.3172\n",
      "153/224, train_loss: 0.1727, step time: 0.3122\n",
      "154/224, train_loss: 0.3619, step time: 0.3121\n",
      "155/224, train_loss: 0.1832, step time: 0.4126\n",
      "156/224, train_loss: 0.3905, step time: 0.3718\n",
      "157/224, train_loss: 0.2700, step time: 0.3789\n",
      "158/224, train_loss: 0.3640, step time: 0.3183\n",
      "159/224, train_loss: 0.3895, step time: 0.4005\n",
      "160/224, train_loss: 0.2222, step time: 0.3150\n",
      "161/224, train_loss: 0.2323, step time: 0.3723\n",
      "162/224, train_loss: 0.1806, step time: 0.3937\n",
      "163/224, train_loss: 0.2424, step time: 0.3993\n",
      "164/224, train_loss: 0.3062, step time: 0.3736\n",
      "165/224, train_loss: 0.1592, step time: 0.3170\n",
      "166/224, train_loss: 0.2755, step time: 0.3965\n",
      "167/224, train_loss: 0.1806, step time: 0.3725\n",
      "168/224, train_loss: 0.2935, step time: 0.3676\n",
      "169/224, train_loss: 0.2079, step time: 0.4034\n",
      "170/224, train_loss: 0.3912, step time: 0.3142\n",
      "171/224, train_loss: 0.1864, step time: 0.3143\n",
      "172/224, train_loss: 0.2307, step time: 0.3124\n",
      "173/224, train_loss: 0.3811, step time: 0.3843\n",
      "174/224, train_loss: 0.1508, step time: 0.3171\n",
      "175/224, train_loss: 0.2261, step time: 0.3134\n",
      "176/224, train_loss: 0.3662, step time: 0.3967\n",
      "177/224, train_loss: 0.3129, step time: 0.4133\n",
      "178/224, train_loss: 0.3462, step time: 0.3142\n",
      "179/224, train_loss: 0.1188, step time: 0.3967\n",
      "180/224, train_loss: 0.1040, step time: 0.3790\n",
      "181/224, train_loss: 0.2268, step time: 0.3145\n",
      "182/224, train_loss: 0.1144, step time: 0.3167\n",
      "183/224, train_loss: 0.0894, step time: 0.4052\n",
      "184/224, train_loss: 0.0975, step time: 0.3953\n",
      "185/224, train_loss: 0.1426, step time: 0.3957\n",
      "186/224, train_loss: 0.3593, step time: 0.4096\n",
      "187/224, train_loss: 0.0912, step time: 0.3144\n",
      "188/224, train_loss: 0.3003, step time: 0.3145\n",
      "189/224, train_loss: 0.1938, step time: 0.3159\n",
      "190/224, train_loss: 0.1684, step time: 0.3974\n",
      "191/224, train_loss: 0.2609, step time: 0.3167\n",
      "192/224, train_loss: 0.2396, step time: 0.3129\n",
      "193/224, train_loss: 0.1177, step time: 0.3176\n",
      "194/224, train_loss: 0.1205, step time: 0.3144\n",
      "195/224, train_loss: 0.2180, step time: 0.3968\n",
      "196/224, train_loss: 0.1816, step time: 0.3147\n",
      "197/224, train_loss: 0.1270, step time: 0.4029\n",
      "198/224, train_loss: 0.0859, step time: 0.3171\n",
      "199/224, train_loss: 0.2506, step time: 0.3664\n",
      "200/224, train_loss: 0.1468, step time: 0.3135\n",
      "201/224, train_loss: 0.1527, step time: 0.4087\n",
      "202/224, train_loss: 0.1321, step time: 0.3690\n",
      "203/224, train_loss: 0.1632, step time: 0.3989\n",
      "204/224, train_loss: 0.2946, step time: 0.3135\n",
      "205/224, train_loss: 0.1145, step time: 0.3135\n",
      "206/224, train_loss: 0.1356, step time: 0.3154\n",
      "207/224, train_loss: 0.3909, step time: 0.3692\n",
      "208/224, train_loss: 0.1492, step time: 0.4021\n",
      "209/224, train_loss: 0.1075, step time: 0.3712\n",
      "210/224, train_loss: 0.3641, step time: 0.4090\n",
      "211/224, train_loss: 0.2551, step time: 0.3172\n",
      "212/224, train_loss: 0.1818, step time: 0.3133\n",
      "213/224, train_loss: 0.3894, step time: 0.3153\n",
      "214/224, train_loss: 0.2187, step time: 0.3944\n",
      "215/224, train_loss: 0.0791, step time: 0.3928\n",
      "216/224, train_loss: 0.1372, step time: 0.4095\n",
      "217/224, train_loss: 0.1799, step time: 0.3781\n",
      "218/224, train_loss: 0.1182, step time: 0.3125\n",
      "219/224, train_loss: 0.2304, step time: 0.4040\n",
      "220/224, train_loss: 0.3466, step time: 0.3929\n",
      "221/224, train_loss: 0.3768, step time: 0.3185\n",
      "222/224, train_loss: 0.3758, step time: 0.3956\n",
      "223/224, train_loss: 0.2044, step time: 0.3983\n",
      "224/224, train_loss: 0.1383, step time: 0.4033\n",
      "epoch 31 average loss: 0.2139\n",
      "current epoch: 31 current mean dice: 0.6890 class1: 0.9993 class2: 0.7319 class3: 0.3359\n",
      "best mean dice: 0.6890 at epoch: 31\n",
      "time consuming of epoch 31 is: 793.1739\n",
      "hello\n",
      "----------\n",
      "epoch 32/100\n",
      "1/224, train_loss: 0.3064, step time: 0.3941\n",
      "2/224, train_loss: 0.3381, step time: 0.3917\n",
      "3/224, train_loss: 0.1092, step time: 0.3159\n",
      "4/224, train_loss: 0.1008, step time: 0.3155\n",
      "5/224, train_loss: 0.1795, step time: 0.3151\n",
      "6/224, train_loss: 0.0949, step time: 0.3171\n",
      "7/224, train_loss: 0.1583, step time: 0.3147\n",
      "8/224, train_loss: 0.3629, step time: 0.3153\n",
      "9/224, train_loss: 0.1607, step time: 0.3922\n",
      "10/224, train_loss: 0.1251, step time: 0.3173\n",
      "11/224, train_loss: 0.3182, step time: 0.3154\n",
      "12/224, train_loss: 0.3283, step time: 0.4003\n",
      "13/224, train_loss: 0.0808, step time: 0.3152\n",
      "14/224, train_loss: 0.1805, step time: 0.3976\n",
      "15/224, train_loss: 0.3983, step time: 0.3876\n",
      "16/224, train_loss: 0.3091, step time: 0.3670\n",
      "17/224, train_loss: 0.1811, step time: 0.3130\n",
      "18/224, train_loss: 0.1240, step time: 0.3147\n",
      "19/224, train_loss: 0.2249, step time: 0.3133\n",
      "20/224, train_loss: 0.2559, step time: 0.3802\n",
      "21/224, train_loss: 0.2376, step time: 0.3807\n",
      "22/224, train_loss: 0.2089, step time: 0.3810\n",
      "23/224, train_loss: 0.1140, step time: 0.3158\n",
      "24/224, train_loss: 0.3177, step time: 0.4033\n",
      "25/224, train_loss: 0.1664, step time: 0.3161\n",
      "26/224, train_loss: 0.1852, step time: 0.3183\n",
      "27/224, train_loss: 0.2591, step time: 0.3816\n",
      "28/224, train_loss: 0.2315, step time: 0.3961\n",
      "29/224, train_loss: 0.3403, step time: 0.4047\n",
      "30/224, train_loss: 0.1582, step time: 0.3871\n",
      "31/224, train_loss: 0.0999, step time: 0.3631\n",
      "32/224, train_loss: 0.4233, step time: 0.3817\n",
      "33/224, train_loss: 0.2176, step time: 0.3196\n",
      "34/224, train_loss: 0.2481, step time: 0.3178\n",
      "35/224, train_loss: 0.2021, step time: 0.3210\n",
      "36/224, train_loss: 0.3516, step time: 0.3972\n",
      "37/224, train_loss: 0.4315, step time: 0.3201\n",
      "38/224, train_loss: 0.2274, step time: 0.3154\n",
      "39/224, train_loss: 0.3549, step time: 0.3201\n",
      "40/224, train_loss: 0.1520, step time: 0.3180\n",
      "41/224, train_loss: 0.1424, step time: 0.3198\n",
      "42/224, train_loss: 0.1160, step time: 0.3987\n",
      "43/224, train_loss: 0.3602, step time: 0.3161\n",
      "44/224, train_loss: 0.1310, step time: 0.3188\n",
      "45/224, train_loss: 0.3036, step time: 0.3190\n",
      "46/224, train_loss: 0.2705, step time: 0.3142\n",
      "47/224, train_loss: 0.1657, step time: 0.3183\n",
      "48/224, train_loss: 0.2023, step time: 0.3151\n",
      "49/224, train_loss: 0.1906, step time: 0.3966\n",
      "50/224, train_loss: 0.3259, step time: 0.4065\n",
      "51/224, train_loss: 0.2152, step time: 0.3184\n",
      "52/224, train_loss: 0.1644, step time: 0.3154\n",
      "53/224, train_loss: 0.4190, step time: 0.3153\n",
      "54/224, train_loss: 0.4702, step time: 0.4029\n",
      "55/224, train_loss: 0.1138, step time: 0.3142\n",
      "56/224, train_loss: 0.1426, step time: 0.3136\n",
      "57/224, train_loss: 0.0893, step time: 0.4104\n",
      "58/224, train_loss: 0.2215, step time: 0.3161\n",
      "59/224, train_loss: 0.1021, step time: 0.3162\n",
      "60/224, train_loss: 0.1759, step time: 0.3705\n",
      "61/224, train_loss: 0.2002, step time: 0.3141\n",
      "62/224, train_loss: 0.2049, step time: 0.3134\n",
      "63/224, train_loss: 0.1372, step time: 0.3969\n",
      "64/224, train_loss: 0.4005, step time: 0.3770\n",
      "65/224, train_loss: 0.1628, step time: 0.3871\n",
      "66/224, train_loss: 0.1429, step time: 0.3712\n",
      "67/224, train_loss: 0.3673, step time: 0.3181\n",
      "68/224, train_loss: 0.1560, step time: 0.3139\n",
      "69/224, train_loss: 0.2182, step time: 0.3162\n",
      "70/224, train_loss: 0.2330, step time: 0.3711\n",
      "71/224, train_loss: 0.3038, step time: 0.3155\n",
      "72/224, train_loss: 0.1538, step time: 0.3903\n",
      "73/224, train_loss: 0.1052, step time: 0.3898\n",
      "74/224, train_loss: 0.2379, step time: 0.3163\n",
      "75/224, train_loss: 0.3757, step time: 0.3791\n",
      "76/224, train_loss: 0.3531, step time: 0.3692\n",
      "77/224, train_loss: 0.3703, step time: 0.3136\n",
      "78/224, train_loss: 0.3384, step time: 0.3176\n",
      "79/224, train_loss: 0.4707, step time: 0.4129\n",
      "80/224, train_loss: 0.1095, step time: 0.3808\n",
      "81/224, train_loss: 0.0930, step time: 0.4076\n",
      "82/224, train_loss: 0.1574, step time: 0.3905\n",
      "83/224, train_loss: 0.1079, step time: 0.3164\n",
      "84/224, train_loss: 0.1556, step time: 0.4090\n",
      "85/224, train_loss: 0.2105, step time: 0.3739\n",
      "86/224, train_loss: 0.1838, step time: 0.3144\n",
      "87/224, train_loss: 0.3911, step time: 0.3746\n",
      "88/224, train_loss: 0.3328, step time: 0.3820\n",
      "89/224, train_loss: 0.3458, step time: 0.3716\n",
      "90/224, train_loss: 0.2781, step time: 0.3688\n",
      "91/224, train_loss: 0.2203, step time: 0.3915\n",
      "92/224, train_loss: 0.1828, step time: 0.4063\n",
      "93/224, train_loss: 0.2287, step time: 0.3966\n",
      "94/224, train_loss: 0.1892, step time: 0.3153\n",
      "95/224, train_loss: 0.3020, step time: 0.3982\n",
      "96/224, train_loss: 0.1910, step time: 0.3745\n",
      "97/224, train_loss: 0.1242, step time: 0.3178\n",
      "98/224, train_loss: 0.1029, step time: 0.3151\n",
      "99/224, train_loss: 0.3324, step time: 0.3978\n",
      "100/224, train_loss: 0.2171, step time: 0.3771\n",
      "101/224, train_loss: 0.1663, step time: 0.3160\n",
      "102/224, train_loss: 0.2157, step time: 0.4036\n",
      "103/224, train_loss: 0.1011, step time: 0.3154\n",
      "104/224, train_loss: 0.1837, step time: 0.3182\n",
      "105/224, train_loss: 0.0968, step time: 0.3957\n",
      "106/224, train_loss: 0.1106, step time: 0.3782\n",
      "107/224, train_loss: 0.2271, step time: 0.3667\n",
      "108/224, train_loss: 0.1493, step time: 0.3140\n",
      "109/224, train_loss: 0.1105, step time: 0.4058\n",
      "110/224, train_loss: 0.1689, step time: 0.3138\n",
      "111/224, train_loss: 0.2215, step time: 0.3689\n",
      "112/224, train_loss: 0.1627, step time: 0.3178\n",
      "113/224, train_loss: 0.1309, step time: 0.3942\n",
      "114/224, train_loss: 0.1521, step time: 0.3159\n",
      "115/224, train_loss: 0.1123, step time: 0.3159\n",
      "116/224, train_loss: 0.1763, step time: 0.3152\n",
      "117/224, train_loss: 0.4111, step time: 0.3928\n",
      "118/224, train_loss: 0.2171, step time: 0.4029\n",
      "119/224, train_loss: 0.0556, step time: 0.3676\n",
      "120/224, train_loss: 0.2386, step time: 0.3160\n",
      "121/224, train_loss: 0.4139, step time: 0.3762\n",
      "122/224, train_loss: 0.4217, step time: 0.3950\n",
      "123/224, train_loss: 0.1291, step time: 0.3899\n",
      "124/224, train_loss: 0.0880, step time: 0.4028\n",
      "125/224, train_loss: 0.1454, step time: 0.3703\n",
      "126/224, train_loss: 0.1999, step time: 0.3824\n",
      "127/224, train_loss: 0.1654, step time: 0.3174\n",
      "128/224, train_loss: 0.1175, step time: 0.4033\n",
      "129/224, train_loss: 0.1641, step time: 0.3130\n",
      "130/224, train_loss: 0.3745, step time: 0.3986\n",
      "131/224, train_loss: 0.2100, step time: 0.3149\n",
      "132/224, train_loss: 0.2513, step time: 0.3890\n",
      "133/224, train_loss: 0.1976, step time: 0.3986\n",
      "134/224, train_loss: 0.0864, step time: 0.3150\n",
      "135/224, train_loss: 0.2523, step time: 0.3847\n",
      "136/224, train_loss: 0.3381, step time: 0.3173\n",
      "137/224, train_loss: 0.1379, step time: 0.3689\n",
      "138/224, train_loss: 0.3065, step time: 0.3998\n",
      "139/224, train_loss: 0.0904, step time: 0.3149\n",
      "140/224, train_loss: 0.3793, step time: 0.3738\n",
      "141/224, train_loss: 0.1438, step time: 0.3793\n",
      "142/224, train_loss: 0.1508, step time: 0.3158\n",
      "143/224, train_loss: 0.2157, step time: 0.3851\n",
      "144/224, train_loss: 0.3635, step time: 0.4066\n",
      "145/224, train_loss: 0.3854, step time: 0.3155\n",
      "146/224, train_loss: 0.2941, step time: 0.3847\n",
      "147/224, train_loss: 0.1520, step time: 0.3177\n",
      "148/224, train_loss: 0.1049, step time: 0.4087\n",
      "149/224, train_loss: 0.1843, step time: 0.3669\n",
      "150/224, train_loss: 0.1218, step time: 0.3169\n",
      "151/224, train_loss: 0.1377, step time: 0.3145\n",
      "152/224, train_loss: 0.2103, step time: 0.3144\n",
      "153/224, train_loss: 0.1438, step time: 0.3905\n",
      "154/224, train_loss: 0.1395, step time: 0.3160\n",
      "155/224, train_loss: 0.2557, step time: 0.3945\n",
      "156/224, train_loss: 0.1514, step time: 0.4105\n",
      "157/224, train_loss: 0.1416, step time: 0.3979\n",
      "158/224, train_loss: 0.1584, step time: 0.3151\n",
      "159/224, train_loss: 0.3757, step time: 0.3172\n",
      "160/224, train_loss: 0.2005, step time: 0.3724\n",
      "161/224, train_loss: 0.1692, step time: 0.3844\n",
      "162/224, train_loss: 0.1641, step time: 0.3750\n",
      "163/224, train_loss: 0.2095, step time: 0.3871\n",
      "164/224, train_loss: 0.3654, step time: 0.3145\n",
      "165/224, train_loss: 0.1993, step time: 0.3845\n",
      "166/224, train_loss: 0.1694, step time: 0.3178\n",
      "167/224, train_loss: 0.3759, step time: 0.3722\n",
      "168/224, train_loss: 0.1547, step time: 0.4017\n",
      "169/224, train_loss: 0.0972, step time: 0.3156\n",
      "170/224, train_loss: 0.3890, step time: 0.3776\n",
      "171/224, train_loss: 0.0812, step time: 0.3148\n",
      "172/224, train_loss: 0.1900, step time: 0.3767\n",
      "173/224, train_loss: 0.3750, step time: 0.3125\n",
      "174/224, train_loss: 0.1693, step time: 0.3955\n",
      "175/224, train_loss: 0.1598, step time: 0.3970\n",
      "176/224, train_loss: 0.1788, step time: 0.3155\n",
      "177/224, train_loss: 0.1014, step time: 0.4110\n",
      "178/224, train_loss: 0.1370, step time: 0.3125\n",
      "179/224, train_loss: 0.2537, step time: 0.3907\n",
      "180/224, train_loss: 0.1885, step time: 0.3799\n",
      "181/224, train_loss: 0.2291, step time: 0.3153\n",
      "182/224, train_loss: 0.0979, step time: 0.3147\n",
      "183/224, train_loss: 0.3327, step time: 0.3685\n",
      "184/224, train_loss: 0.1352, step time: 0.3150\n",
      "185/224, train_loss: 0.0874, step time: 0.3176\n",
      "186/224, train_loss: 0.0811, step time: 0.4114\n",
      "187/224, train_loss: 0.1337, step time: 0.3144\n",
      "188/224, train_loss: 0.3509, step time: 0.3173\n",
      "189/224, train_loss: 0.2932, step time: 0.3798\n",
      "190/224, train_loss: 0.1346, step time: 0.3935\n",
      "191/224, train_loss: 0.3364, step time: 0.3656\n",
      "192/224, train_loss: 0.2474, step time: 0.3880\n",
      "193/224, train_loss: 0.2240, step time: 0.3148\n",
      "194/224, train_loss: 0.2398, step time: 0.3935\n",
      "195/224, train_loss: 0.2401, step time: 0.4013\n",
      "196/224, train_loss: 0.2708, step time: 0.3973\n",
      "197/224, train_loss: 0.1708, step time: 0.3185\n",
      "198/224, train_loss: 0.4304, step time: 0.3839\n",
      "199/224, train_loss: 0.3127, step time: 0.3149\n",
      "200/224, train_loss: 0.2364, step time: 0.3147\n",
      "201/224, train_loss: 0.2705, step time: 0.3951\n",
      "202/224, train_loss: 0.1784, step time: 0.3150\n",
      "203/224, train_loss: 0.1902, step time: 0.3179\n",
      "204/224, train_loss: 0.2178, step time: 0.3153\n",
      "205/224, train_loss: 0.1769, step time: 0.3694\n",
      "206/224, train_loss: 0.1127, step time: 0.3125\n",
      "207/224, train_loss: 0.2594, step time: 0.3168\n",
      "208/224, train_loss: 0.1849, step time: 0.3978\n",
      "209/224, train_loss: 0.1316, step time: 0.3125\n",
      "210/224, train_loss: 0.2360, step time: 0.3665\n",
      "211/224, train_loss: 0.1990, step time: 0.3652\n",
      "212/224, train_loss: 0.3464, step time: 0.3135\n",
      "213/224, train_loss: 0.1984, step time: 0.3176\n",
      "214/224, train_loss: 0.4173, step time: 0.4084\n",
      "215/224, train_loss: 0.2797, step time: 0.3185\n",
      "216/224, train_loss: 0.1305, step time: 0.3178\n",
      "217/224, train_loss: 0.1418, step time: 0.3142\n",
      "218/224, train_loss: 0.1433, step time: 0.3787\n",
      "219/224, train_loss: 0.3576, step time: 0.3842\n",
      "220/224, train_loss: 0.1968, step time: 0.3976\n",
      "221/224, train_loss: 0.1218, step time: 0.3995\n",
      "222/224, train_loss: 0.3419, step time: 0.3984\n",
      "223/224, train_loss: 0.3660, step time: 0.3153\n",
      "224/224, train_loss: 0.3369, step time: 0.3175\n",
      "epoch 32 average loss: 0.2193\n",
      "current epoch: 32 current mean dice: 0.6794 class1: 0.9992 class2: 0.7242 class3: 0.3146\n",
      "best mean dice: 0.6890 at epoch: 31\n",
      "time consuming of epoch 32 is: 769.7148\n",
      "hello\n",
      "----------\n",
      "epoch 33/100\n",
      "1/224, train_loss: 0.1576, step time: 0.3172\n",
      "2/224, train_loss: 0.1352, step time: 0.3170\n",
      "3/224, train_loss: 0.3824, step time: 0.3737\n",
      "4/224, train_loss: 0.3182, step time: 0.3157\n",
      "5/224, train_loss: 0.3424, step time: 0.3991\n",
      "6/224, train_loss: 0.1333, step time: 0.3153\n",
      "7/224, train_loss: 0.4378, step time: 0.3821\n",
      "8/224, train_loss: 0.1462, step time: 0.3782\n",
      "9/224, train_loss: 0.2792, step time: 0.3130\n",
      "10/224, train_loss: 0.0919, step time: 0.4052\n",
      "11/224, train_loss: 0.0965, step time: 0.3174\n",
      "12/224, train_loss: 0.1143, step time: 0.3943\n",
      "13/224, train_loss: 0.2377, step time: 0.4149\n",
      "14/224, train_loss: 0.0887, step time: 0.3180\n",
      "15/224, train_loss: 0.2296, step time: 0.4085\n",
      "16/224, train_loss: 0.2924, step time: 0.3149\n",
      "17/224, train_loss: 0.1777, step time: 0.3149\n",
      "18/224, train_loss: 0.2465, step time: 0.3821\n",
      "19/224, train_loss: 0.1039, step time: 0.3154\n",
      "20/224, train_loss: 0.2156, step time: 0.4113\n",
      "21/224, train_loss: 0.1274, step time: 0.3180\n",
      "22/224, train_loss: 0.3269, step time: 0.3183\n",
      "23/224, train_loss: 0.3645, step time: 0.4050\n",
      "24/224, train_loss: 0.1211, step time: 0.3140\n",
      "25/224, train_loss: 0.3278, step time: 0.3160\n",
      "26/224, train_loss: 0.4754, step time: 0.3792\n",
      "27/224, train_loss: 0.2233, step time: 0.3946\n",
      "28/224, train_loss: 0.2185, step time: 0.3959\n",
      "29/224, train_loss: 0.0986, step time: 0.3179\n",
      "30/224, train_loss: 0.2392, step time: 0.3180\n",
      "31/224, train_loss: 0.1409, step time: 0.3154\n",
      "32/224, train_loss: 0.2634, step time: 0.4040\n",
      "33/224, train_loss: 0.3132, step time: 0.3768\n",
      "34/224, train_loss: 0.3559, step time: 0.3836\n",
      "35/224, train_loss: 0.2146, step time: 0.3155\n",
      "36/224, train_loss: 0.3372, step time: 0.3965\n",
      "37/224, train_loss: 0.1275, step time: 0.3893\n",
      "38/224, train_loss: 0.0790, step time: 0.3851\n",
      "39/224, train_loss: 0.3045, step time: 0.3160\n",
      "40/224, train_loss: 0.3570, step time: 0.3152\n",
      "41/224, train_loss: 0.2876, step time: 0.3765\n",
      "42/224, train_loss: 0.2201, step time: 0.3163\n",
      "43/224, train_loss: 0.1445, step time: 0.3164\n",
      "44/224, train_loss: 0.2102, step time: 0.3769\n",
      "45/224, train_loss: 0.2100, step time: 0.3151\n",
      "46/224, train_loss: 0.0798, step time: 0.4006\n",
      "47/224, train_loss: 0.2679, step time: 0.3999\n",
      "48/224, train_loss: 0.2398, step time: 0.3152\n",
      "49/224, train_loss: 0.2070, step time: 0.3153\n",
      "50/224, train_loss: 0.1138, step time: 0.3149\n",
      "51/224, train_loss: 0.2597, step time: 0.3854\n",
      "52/224, train_loss: 0.5603, step time: 0.3790\n",
      "53/224, train_loss: 0.2115, step time: 0.3678\n",
      "54/224, train_loss: 0.4399, step time: 0.3713\n",
      "55/224, train_loss: 0.2145, step time: 0.3142\n",
      "56/224, train_loss: 0.2896, step time: 0.3652\n",
      "57/224, train_loss: 0.0914, step time: 0.3153\n",
      "58/224, train_loss: 0.2338, step time: 0.3124\n",
      "59/224, train_loss: 0.2334, step time: 0.3148\n",
      "60/224, train_loss: 0.1543, step time: 0.3148\n",
      "61/224, train_loss: 0.1204, step time: 0.3165\n",
      "62/224, train_loss: 0.3424, step time: 0.3990\n",
      "63/224, train_loss: 0.1242, step time: 0.3166\n",
      "64/224, train_loss: 0.0914, step time: 0.3173\n",
      "65/224, train_loss: 0.1607, step time: 0.3705\n",
      "66/224, train_loss: 0.1235, step time: 0.4008\n",
      "67/224, train_loss: 0.1171, step time: 0.3186\n",
      "68/224, train_loss: 0.0531, step time: 0.3159\n",
      "69/224, train_loss: 0.4252, step time: 0.3155\n",
      "70/224, train_loss: 0.1689, step time: 0.3129\n",
      "71/224, train_loss: 0.0602, step time: 0.3787\n",
      "72/224, train_loss: 0.1353, step time: 0.3770\n",
      "73/224, train_loss: 0.3866, step time: 0.3136\n",
      "74/224, train_loss: 0.5469, step time: 0.3808\n",
      "75/224, train_loss: 0.3345, step time: 0.4102\n",
      "76/224, train_loss: 0.1291, step time: 0.3172\n",
      "77/224, train_loss: 0.2281, step time: 0.3171\n",
      "78/224, train_loss: 0.2562, step time: 0.4107\n",
      "79/224, train_loss: 0.3874, step time: 0.3845\n",
      "80/224, train_loss: 0.2411, step time: 0.3989\n",
      "81/224, train_loss: 0.1432, step time: 0.3683\n",
      "82/224, train_loss: 0.2771, step time: 0.3144\n",
      "83/224, train_loss: 0.3978, step time: 0.3909\n",
      "84/224, train_loss: 0.3324, step time: 0.3683\n",
      "85/224, train_loss: 0.3566, step time: 0.3174\n",
      "86/224, train_loss: 0.2387, step time: 0.3716\n",
      "87/224, train_loss: 0.1300, step time: 0.3674\n",
      "88/224, train_loss: 0.3122, step time: 0.3966\n",
      "89/224, train_loss: 0.1910, step time: 0.3177\n",
      "90/224, train_loss: 0.0868, step time: 0.4028\n",
      "91/224, train_loss: 0.1911, step time: 0.4032\n",
      "92/224, train_loss: 0.3180, step time: 0.4112\n",
      "93/224, train_loss: 0.2168, step time: 0.3145\n",
      "94/224, train_loss: 0.1617, step time: 0.3148\n",
      "95/224, train_loss: 0.2280, step time: 0.3177\n",
      "96/224, train_loss: 0.1372, step time: 0.3158\n",
      "97/224, train_loss: 0.1307, step time: 0.3169\n",
      "98/224, train_loss: 0.1593, step time: 0.3147\n",
      "99/224, train_loss: 0.0980, step time: 0.3145\n",
      "100/224, train_loss: 0.1161, step time: 0.3148\n",
      "101/224, train_loss: 0.2790, step time: 0.3166\n",
      "102/224, train_loss: 0.0991, step time: 0.3128\n",
      "103/224, train_loss: 0.0842, step time: 0.3823\n",
      "104/224, train_loss: 0.1432, step time: 0.3154\n",
      "105/224, train_loss: 0.2492, step time: 0.3795\n",
      "106/224, train_loss: 0.3423, step time: 0.3157\n",
      "107/224, train_loss: 0.1122, step time: 0.3170\n",
      "108/224, train_loss: 0.1589, step time: 0.3125\n",
      "109/224, train_loss: 0.2010, step time: 0.3169\n",
      "110/224, train_loss: 0.3931, step time: 0.3152\n",
      "111/224, train_loss: 0.3447, step time: 0.3173\n",
      "112/224, train_loss: 0.1544, step time: 0.3147\n",
      "113/224, train_loss: 0.3610, step time: 0.3697\n",
      "114/224, train_loss: 0.1885, step time: 0.3766\n",
      "115/224, train_loss: 0.3944, step time: 0.3152\n",
      "116/224, train_loss: 0.1768, step time: 0.4146\n",
      "117/224, train_loss: 0.1097, step time: 0.3793\n",
      "118/224, train_loss: 0.0549, step time: 0.3125\n",
      "119/224, train_loss: 0.3015, step time: 0.3999\n",
      "120/224, train_loss: 0.0901, step time: 0.3142\n",
      "121/224, train_loss: 0.0965, step time: 0.3143\n",
      "122/224, train_loss: 0.2870, step time: 0.3989\n",
      "123/224, train_loss: 0.2013, step time: 0.4070\n",
      "124/224, train_loss: 0.1983, step time: 0.3796\n",
      "125/224, train_loss: 0.2708, step time: 0.3970\n",
      "126/224, train_loss: 0.3912, step time: 0.3146\n",
      "127/224, train_loss: 0.3707, step time: 0.4005\n",
      "128/224, train_loss: 0.1586, step time: 0.4044\n",
      "129/224, train_loss: 0.3949, step time: 0.3948\n",
      "130/224, train_loss: 0.0972, step time: 0.3955\n",
      "131/224, train_loss: 0.2229, step time: 0.3651\n",
      "132/224, train_loss: 0.1542, step time: 0.3150\n",
      "133/224, train_loss: 0.1547, step time: 0.4121\n",
      "134/224, train_loss: 0.1650, step time: 0.3989\n",
      "135/224, train_loss: 0.2810, step time: 0.3923\n",
      "136/224, train_loss: 0.2988, step time: 0.3145\n",
      "137/224, train_loss: 0.1692, step time: 0.3143\n",
      "138/224, train_loss: 0.1322, step time: 0.3980\n",
      "139/224, train_loss: 0.1785, step time: 0.3690\n",
      "140/224, train_loss: 0.2481, step time: 0.3147\n",
      "141/224, train_loss: 0.1432, step time: 0.4009\n",
      "142/224, train_loss: 0.1438, step time: 0.3177\n",
      "143/224, train_loss: 0.1006, step time: 0.3157\n",
      "144/224, train_loss: 0.0972, step time: 0.3128\n",
      "145/224, train_loss: 0.1926, step time: 0.3144\n",
      "146/224, train_loss: 0.1732, step time: 0.3164\n",
      "147/224, train_loss: 0.1482, step time: 0.3166\n",
      "148/224, train_loss: 0.1836, step time: 0.3141\n",
      "149/224, train_loss: 0.3578, step time: 0.3145\n",
      "150/224, train_loss: 0.1052, step time: 0.3961\n",
      "151/224, train_loss: 0.1161, step time: 0.3168\n",
      "152/224, train_loss: 0.3102, step time: 0.3170\n",
      "153/224, train_loss: 0.2699, step time: 0.3910\n",
      "154/224, train_loss: 0.3683, step time: 0.3144\n",
      "155/224, train_loss: 0.1416, step time: 0.3166\n",
      "156/224, train_loss: 0.1790, step time: 0.4080\n",
      "157/224, train_loss: 0.1610, step time: 0.3177\n",
      "158/224, train_loss: 0.1399, step time: 0.3146\n",
      "159/224, train_loss: 0.1652, step time: 0.3146\n",
      "160/224, train_loss: 0.1808, step time: 0.3712\n",
      "161/224, train_loss: 0.1065, step time: 0.3155\n",
      "162/224, train_loss: 0.2692, step time: 0.4018\n",
      "163/224, train_loss: 0.1547, step time: 0.3865\n",
      "164/224, train_loss: 0.0910, step time: 0.3144\n",
      "165/224, train_loss: 0.1271, step time: 0.3986\n",
      "166/224, train_loss: 0.2428, step time: 0.3665\n",
      "167/224, train_loss: 0.1611, step time: 0.3150\n",
      "168/224, train_loss: 0.2169, step time: 0.3913\n",
      "169/224, train_loss: 0.4126, step time: 0.3175\n",
      "170/224, train_loss: 0.1749, step time: 0.3143\n",
      "171/224, train_loss: 0.1631, step time: 0.3142\n",
      "172/224, train_loss: 0.1705, step time: 0.3949\n",
      "173/224, train_loss: 0.3709, step time: 0.4045\n",
      "174/224, train_loss: 0.3683, step time: 0.3151\n",
      "175/224, train_loss: 0.3475, step time: 0.4105\n",
      "176/224, train_loss: 0.0845, step time: 0.3151\n",
      "177/224, train_loss: 0.5235, step time: 0.3779\n",
      "178/224, train_loss: 0.2398, step time: 0.3850\n",
      "179/224, train_loss: 0.3294, step time: 0.4095\n",
      "180/224, train_loss: 0.1006, step time: 0.3127\n",
      "181/224, train_loss: 0.2440, step time: 0.3924\n",
      "182/224, train_loss: 0.1930, step time: 0.3152\n",
      "183/224, train_loss: 0.3108, step time: 0.3746\n",
      "184/224, train_loss: 0.2025, step time: 0.3169\n",
      "185/224, train_loss: 0.1151, step time: 0.4043\n",
      "186/224, train_loss: 0.1644, step time: 0.3125\n",
      "187/224, train_loss: 0.3276, step time: 0.3168\n",
      "188/224, train_loss: 0.1269, step time: 0.3988\n",
      "189/224, train_loss: 0.2239, step time: 0.4017\n",
      "190/224, train_loss: 0.1053, step time: 0.3171\n",
      "191/224, train_loss: 0.3730, step time: 0.4015\n",
      "192/224, train_loss: 0.2018, step time: 0.4070\n",
      "193/224, train_loss: 0.1299, step time: 0.3154\n",
      "194/224, train_loss: 0.2467, step time: 0.4059\n",
      "195/224, train_loss: 0.3835, step time: 0.4007\n",
      "196/224, train_loss: 0.1120, step time: 0.3974\n",
      "197/224, train_loss: 0.1877, step time: 0.3163\n",
      "198/224, train_loss: 0.1713, step time: 0.3178\n",
      "199/224, train_loss: 0.1440, step time: 0.3150\n",
      "200/224, train_loss: 0.2199, step time: 0.3135\n",
      "201/224, train_loss: 0.1537, step time: 0.3893\n",
      "202/224, train_loss: 0.2092, step time: 0.3841\n",
      "203/224, train_loss: 0.1354, step time: 0.3975\n",
      "204/224, train_loss: 0.2946, step time: 0.4002\n",
      "205/224, train_loss: 0.2871, step time: 0.3155\n",
      "206/224, train_loss: 0.1147, step time: 0.4066\n",
      "207/224, train_loss: 0.1629, step time: 0.3886\n",
      "208/224, train_loss: 0.3267, step time: 0.3167\n",
      "209/224, train_loss: 0.4374, step time: 0.3788\n",
      "210/224, train_loss: 0.1056, step time: 0.3148\n",
      "211/224, train_loss: 0.2162, step time: 0.3122\n",
      "212/224, train_loss: 0.2238, step time: 0.3144\n",
      "213/224, train_loss: 0.1388, step time: 0.3155\n",
      "214/224, train_loss: 0.0796, step time: 0.3150\n",
      "215/224, train_loss: 0.3860, step time: 0.3789\n",
      "216/224, train_loss: 0.3113, step time: 0.3178\n",
      "217/224, train_loss: 0.1038, step time: 0.4124\n",
      "218/224, train_loss: 0.3791, step time: 0.3966\n",
      "219/224, train_loss: 0.3546, step time: 0.3921\n",
      "220/224, train_loss: 0.3954, step time: 0.3885\n",
      "221/224, train_loss: 0.2847, step time: 0.3153\n",
      "222/224, train_loss: 0.1788, step time: 0.3146\n",
      "223/224, train_loss: 0.3491, step time: 0.3143\n",
      "224/224, train_loss: 0.1993, step time: 0.3872\n",
      "epoch 33 average loss: 0.2215\n",
      "current epoch: 33 current mean dice: 0.6956 class1: 0.9993 class2: 0.7330 class3: 0.3544\n",
      "best mean dice: 0.6956 at epoch: 33\n",
      "time consuming of epoch 33 is: 755.8805\n",
      "hello\n",
      "----------\n",
      "epoch 34/100\n",
      "1/224, train_loss: 0.2298, step time: 0.3962\n",
      "2/224, train_loss: 0.1083, step time: 0.3133\n",
      "3/224, train_loss: 0.1088, step time: 0.3934\n",
      "4/224, train_loss: 0.1084, step time: 0.3158\n",
      "5/224, train_loss: 0.1634, step time: 0.3860\n",
      "6/224, train_loss: 0.3561, step time: 0.3145\n",
      "7/224, train_loss: 0.0599, step time: 0.3784\n",
      "8/224, train_loss: 0.3704, step time: 0.3127\n",
      "9/224, train_loss: 0.0689, step time: 0.3122\n",
      "10/224, train_loss: 0.1908, step time: 0.3146\n",
      "11/224, train_loss: 0.1338, step time: 0.3947\n",
      "12/224, train_loss: 0.1113, step time: 0.3719\n",
      "13/224, train_loss: 0.1253, step time: 0.3175\n",
      "14/224, train_loss: 0.4175, step time: 0.3817\n",
      "15/224, train_loss: 0.1518, step time: 0.3155\n",
      "16/224, train_loss: 0.3475, step time: 0.4023\n",
      "17/224, train_loss: 0.2225, step time: 0.3123\n",
      "18/224, train_loss: 0.2330, step time: 0.3845\n",
      "19/224, train_loss: 0.1799, step time: 0.3953\n",
      "20/224, train_loss: 0.2986, step time: 0.3157\n",
      "21/224, train_loss: 0.1331, step time: 0.3171\n",
      "22/224, train_loss: 0.1142, step time: 0.3966\n",
      "23/224, train_loss: 0.3838, step time: 0.3170\n",
      "24/224, train_loss: 0.2404, step time: 0.3700\n",
      "25/224, train_loss: 0.1429, step time: 0.3822\n",
      "26/224, train_loss: 0.1312, step time: 0.3808\n",
      "27/224, train_loss: 0.2009, step time: 0.3642\n",
      "28/224, train_loss: 0.1664, step time: 0.3758\n",
      "29/224, train_loss: 0.2068, step time: 0.3691\n",
      "30/224, train_loss: 0.0843, step time: 0.3661\n",
      "31/224, train_loss: 0.0749, step time: 0.4006\n",
      "32/224, train_loss: 0.1298, step time: 0.3982\n",
      "33/224, train_loss: 0.2098, step time: 0.3661\n",
      "34/224, train_loss: 0.2899, step time: 0.4132\n",
      "35/224, train_loss: 0.1545, step time: 0.3135\n",
      "36/224, train_loss: 0.1891, step time: 0.3669\n",
      "37/224, train_loss: 0.1190, step time: 0.3152\n",
      "38/224, train_loss: 0.2021, step time: 0.3897\n",
      "39/224, train_loss: 0.3397, step time: 0.3136\n",
      "40/224, train_loss: 0.2217, step time: 0.3920\n",
      "41/224, train_loss: 0.3361, step time: 0.3916\n",
      "42/224, train_loss: 0.1451, step time: 0.3994\n",
      "43/224, train_loss: 0.2279, step time: 0.3147\n",
      "44/224, train_loss: 0.2235, step time: 0.3905\n",
      "45/224, train_loss: 0.1672, step time: 0.3151\n",
      "46/224, train_loss: 0.1692, step time: 0.3132\n",
      "47/224, train_loss: 0.2010, step time: 0.3149\n",
      "48/224, train_loss: 0.1083, step time: 0.3124\n",
      "49/224, train_loss: 0.2074, step time: 0.3877\n",
      "50/224, train_loss: 0.1477, step time: 0.3177\n",
      "51/224, train_loss: 0.2252, step time: 0.3826\n",
      "52/224, train_loss: 0.0628, step time: 0.3144\n",
      "53/224, train_loss: 0.4125, step time: 0.3119\n",
      "54/224, train_loss: 0.1397, step time: 0.3877\n",
      "55/224, train_loss: 0.3481, step time: 0.3924\n",
      "56/224, train_loss: 0.1232, step time: 0.3173\n",
      "57/224, train_loss: 0.1162, step time: 0.3644\n",
      "58/224, train_loss: 0.4423, step time: 0.3964\n",
      "59/224, train_loss: 0.4155, step time: 0.3147\n",
      "60/224, train_loss: 0.2999, step time: 0.3132\n",
      "61/224, train_loss: 0.2011, step time: 0.3125\n",
      "62/224, train_loss: 0.1755, step time: 0.3171\n",
      "63/224, train_loss: 0.3765, step time: 0.4017\n",
      "64/224, train_loss: 0.3196, step time: 0.4082\n",
      "65/224, train_loss: 0.3489, step time: 0.4097\n",
      "66/224, train_loss: 0.3109, step time: 0.4119\n",
      "67/224, train_loss: 0.1599, step time: 0.3148\n",
      "68/224, train_loss: 0.0721, step time: 0.3945\n",
      "69/224, train_loss: 0.3970, step time: 0.3807\n",
      "70/224, train_loss: 0.1744, step time: 0.3776\n",
      "71/224, train_loss: 0.1166, step time: 0.3157\n",
      "72/224, train_loss: 0.3524, step time: 0.3867\n",
      "73/224, train_loss: 0.1795, step time: 0.3177\n",
      "74/224, train_loss: 0.1416, step time: 0.3177\n",
      "75/224, train_loss: 0.3960, step time: 0.3134\n",
      "76/224, train_loss: 0.1529, step time: 0.4007\n",
      "77/224, train_loss: 0.2045, step time: 0.3145\n",
      "78/224, train_loss: 0.2221, step time: 0.3142\n",
      "79/224, train_loss: 0.2707, step time: 0.3695\n",
      "80/224, train_loss: 0.1595, step time: 0.3182\n",
      "81/224, train_loss: 0.0837, step time: 0.3907\n",
      "82/224, train_loss: 0.1416, step time: 0.4090\n",
      "83/224, train_loss: 0.0912, step time: 0.3149\n",
      "84/224, train_loss: 0.1055, step time: 0.3145\n",
      "85/224, train_loss: 0.1584, step time: 0.4032\n",
      "86/224, train_loss: 0.3261, step time: 0.3136\n",
      "87/224, train_loss: 0.1024, step time: 0.3802\n",
      "88/224, train_loss: 0.2183, step time: 0.3940\n",
      "89/224, train_loss: 0.0963, step time: 0.3141\n",
      "90/224, train_loss: 0.1159, step time: 0.3143\n",
      "91/224, train_loss: 0.1201, step time: 0.3166\n",
      "92/224, train_loss: 0.3159, step time: 0.3171\n",
      "93/224, train_loss: 0.1878, step time: 0.3838\n",
      "94/224, train_loss: 0.2666, step time: 0.3825\n",
      "95/224, train_loss: 0.1621, step time: 0.4101\n",
      "96/224, train_loss: 0.3838, step time: 0.3978\n",
      "97/224, train_loss: 0.3798, step time: 0.3140\n",
      "98/224, train_loss: 0.1233, step time: 0.3122\n",
      "99/224, train_loss: 0.0746, step time: 0.3140\n",
      "100/224, train_loss: 0.2292, step time: 0.3125\n",
      "101/224, train_loss: 0.1628, step time: 0.3777\n",
      "102/224, train_loss: 0.1857, step time: 0.3156\n",
      "103/224, train_loss: 0.2666, step time: 0.3838\n",
      "104/224, train_loss: 0.0622, step time: 0.3148\n",
      "105/224, train_loss: 0.1520, step time: 0.4048\n",
      "106/224, train_loss: 0.3008, step time: 0.3769\n",
      "107/224, train_loss: 0.1131, step time: 0.3732\n",
      "108/224, train_loss: 0.1258, step time: 0.3812\n",
      "109/224, train_loss: 0.1598, step time: 0.3885\n",
      "110/224, train_loss: 0.3397, step time: 0.3936\n",
      "111/224, train_loss: 0.1125, step time: 0.3158\n",
      "112/224, train_loss: 0.4197, step time: 0.3156\n",
      "113/224, train_loss: 0.3538, step time: 0.4118\n",
      "114/224, train_loss: 0.1604, step time: 0.3926\n",
      "115/224, train_loss: 0.2186, step time: 0.3157\n",
      "116/224, train_loss: 0.2440, step time: 0.3994\n",
      "117/224, train_loss: 0.3676, step time: 0.3177\n",
      "118/224, train_loss: 0.1377, step time: 0.3137\n",
      "119/224, train_loss: 0.2219, step time: 0.4119\n",
      "120/224, train_loss: 0.2014, step time: 0.3154\n",
      "121/224, train_loss: 0.4014, step time: 0.3149\n",
      "122/224, train_loss: 0.1200, step time: 0.3964\n",
      "123/224, train_loss: 0.3769, step time: 0.3746\n",
      "124/224, train_loss: 0.1452, step time: 0.3836\n",
      "125/224, train_loss: 0.1700, step time: 0.3674\n",
      "126/224, train_loss: 0.1008, step time: 0.3735\n",
      "127/224, train_loss: 0.3100, step time: 0.3857\n",
      "128/224, train_loss: 0.1222, step time: 0.3133\n",
      "129/224, train_loss: 0.1137, step time: 0.3951\n",
      "130/224, train_loss: 0.1569, step time: 0.4025\n",
      "131/224, train_loss: 0.3736, step time: 0.3768\n",
      "132/224, train_loss: 0.1273, step time: 0.3203\n",
      "133/224, train_loss: 0.1666, step time: 0.3184\n",
      "134/224, train_loss: 0.3453, step time: 0.3189\n",
      "135/224, train_loss: 0.1257, step time: 0.4084\n",
      "136/224, train_loss: 0.4252, step time: 0.4085\n",
      "137/224, train_loss: 0.4237, step time: 0.4010\n",
      "138/224, train_loss: 0.3902, step time: 0.3720\n",
      "139/224, train_loss: 0.2643, step time: 0.4062\n",
      "140/224, train_loss: 0.1323, step time: 0.3165\n",
      "141/224, train_loss: 0.1077, step time: 0.3137\n",
      "142/224, train_loss: 0.2758, step time: 0.3953\n",
      "143/224, train_loss: 0.1765, step time: 0.3182\n",
      "144/224, train_loss: 0.2387, step time: 0.3142\n",
      "145/224, train_loss: 0.2267, step time: 0.3160\n",
      "146/224, train_loss: 0.3575, step time: 0.3145\n",
      "147/224, train_loss: 0.1286, step time: 0.3170\n",
      "148/224, train_loss: 0.2427, step time: 0.3171\n",
      "149/224, train_loss: 0.2640, step time: 0.3755\n",
      "150/224, train_loss: 0.3290, step time: 0.3870\n",
      "151/224, train_loss: 0.2048, step time: 0.3975\n",
      "152/224, train_loss: 0.3249, step time: 0.3732\n",
      "153/224, train_loss: 0.1555, step time: 0.4104\n",
      "154/224, train_loss: 0.2690, step time: 0.3779\n",
      "155/224, train_loss: 0.2305, step time: 0.4046\n",
      "156/224, train_loss: 0.3632, step time: 0.3699\n",
      "157/224, train_loss: 0.2859, step time: 0.3163\n",
      "158/224, train_loss: 0.1452, step time: 0.3142\n",
      "159/224, train_loss: 0.1479, step time: 0.3179\n",
      "160/224, train_loss: 0.1499, step time: 0.3185\n",
      "161/224, train_loss: 0.2303, step time: 0.3149\n",
      "162/224, train_loss: 0.2540, step time: 0.3156\n",
      "163/224, train_loss: 0.1429, step time: 0.4139\n",
      "164/224, train_loss: 0.1682, step time: 0.4072\n",
      "165/224, train_loss: 0.2794, step time: 0.3209\n",
      "166/224, train_loss: 0.1392, step time: 0.3151\n",
      "167/224, train_loss: 0.3575, step time: 0.3169\n",
      "168/224, train_loss: 0.4019, step time: 0.3982\n",
      "169/224, train_loss: 0.0609, step time: 0.4103\n",
      "170/224, train_loss: 0.1574, step time: 0.3723\n",
      "171/224, train_loss: 0.1819, step time: 0.4053\n",
      "172/224, train_loss: 0.2594, step time: 0.3999\n",
      "173/224, train_loss: 0.1656, step time: 0.4108\n",
      "174/224, train_loss: 0.3570, step time: 0.3120\n",
      "175/224, train_loss: 0.1419, step time: 0.3871\n",
      "176/224, train_loss: 0.1291, step time: 0.3131\n",
      "177/224, train_loss: 0.2731, step time: 0.3853\n",
      "178/224, train_loss: 0.1298, step time: 0.4083\n",
      "179/224, train_loss: 0.1533, step time: 0.3171\n",
      "180/224, train_loss: 0.3599, step time: 0.3863\n",
      "181/224, train_loss: 0.2688, step time: 0.3907\n",
      "182/224, train_loss: 0.2467, step time: 0.3154\n",
      "183/224, train_loss: 0.0897, step time: 0.3145\n",
      "184/224, train_loss: 0.2537, step time: 0.3718\n",
      "185/224, train_loss: 0.3551, step time: 0.3993\n",
      "186/224, train_loss: 0.0846, step time: 0.3141\n",
      "187/224, train_loss: 0.2760, step time: 0.4031\n",
      "188/224, train_loss: 0.4423, step time: 0.3978\n",
      "189/224, train_loss: 0.1818, step time: 0.3962\n",
      "190/224, train_loss: 0.3395, step time: 0.4129\n",
      "191/224, train_loss: 0.1042, step time: 0.3156\n",
      "192/224, train_loss: 0.3389, step time: 0.4059\n",
      "193/224, train_loss: 0.2189, step time: 0.3177\n",
      "194/224, train_loss: 0.0984, step time: 0.3150\n",
      "195/224, train_loss: 0.1485, step time: 0.3145\n",
      "196/224, train_loss: 0.2080, step time: 0.3790\n",
      "197/224, train_loss: 0.1473, step time: 0.3176\n",
      "198/224, train_loss: 0.2198, step time: 0.3147\n",
      "199/224, train_loss: 0.3199, step time: 0.3883\n",
      "200/224, train_loss: 0.1222, step time: 0.3172\n",
      "201/224, train_loss: 0.0972, step time: 0.3757\n",
      "202/224, train_loss: 0.1294, step time: 0.3146\n",
      "203/224, train_loss: 0.2629, step time: 0.3926\n",
      "204/224, train_loss: 0.1529, step time: 0.3694\n",
      "205/224, train_loss: 0.1237, step time: 0.3154\n",
      "206/224, train_loss: 0.2884, step time: 0.3833\n",
      "207/224, train_loss: 0.2370, step time: 0.3145\n",
      "208/224, train_loss: 0.1481, step time: 0.3141\n",
      "209/224, train_loss: 0.1387, step time: 0.3826\n",
      "210/224, train_loss: 0.3996, step time: 0.3905\n",
      "211/224, train_loss: 0.1901, step time: 0.3121\n",
      "212/224, train_loss: 0.1530, step time: 0.3723\n",
      "213/224, train_loss: 0.2016, step time: 0.3143\n",
      "214/224, train_loss: 0.3282, step time: 0.3853\n",
      "215/224, train_loss: 0.2633, step time: 0.3183\n",
      "216/224, train_loss: 0.1066, step time: 0.3913\n",
      "217/224, train_loss: 0.3857, step time: 0.3881\n",
      "218/224, train_loss: 0.2963, step time: 0.3153\n",
      "219/224, train_loss: 0.1066, step time: 0.3147\n",
      "220/224, train_loss: 0.0909, step time: 0.3669\n",
      "221/224, train_loss: 0.2672, step time: 0.3841\n",
      "222/224, train_loss: 0.3400, step time: 0.3800\n",
      "223/224, train_loss: 0.2284, step time: 0.4080\n",
      "224/224, train_loss: 0.1099, step time: 0.3849\n",
      "epoch 34 average loss: 0.2153\n",
      "current epoch: 34 current mean dice: 0.6898 class1: 0.9993 class2: 0.7233 class3: 0.3468\n",
      "best mean dice: 0.6956 at epoch: 33\n",
      "time consuming of epoch 34 is: 811.3778\n",
      "hello\n",
      "----------\n",
      "epoch 35/100\n",
      "1/224, train_loss: 0.2919, step time: 0.3223\n",
      "2/224, train_loss: 0.3469, step time: 0.3913\n",
      "3/224, train_loss: 0.4704, step time: 0.4114\n",
      "4/224, train_loss: 0.1674, step time: 0.3172\n",
      "5/224, train_loss: 0.2830, step time: 0.3687\n",
      "6/224, train_loss: 0.1184, step time: 0.3177\n",
      "7/224, train_loss: 0.1229, step time: 0.3172\n",
      "8/224, train_loss: 0.1780, step time: 0.3194\n",
      "9/224, train_loss: 0.1493, step time: 0.3167\n",
      "10/224, train_loss: 0.1687, step time: 0.3193\n",
      "11/224, train_loss: 0.1522, step time: 0.3817\n",
      "12/224, train_loss: 0.1956, step time: 0.3775\n",
      "13/224, train_loss: 0.4983, step time: 0.4044\n",
      "14/224, train_loss: 0.3219, step time: 0.4095\n",
      "15/224, train_loss: 0.2288, step time: 0.3810\n",
      "16/224, train_loss: 0.1037, step time: 0.3181\n",
      "17/224, train_loss: 0.1420, step time: 0.3184\n",
      "18/224, train_loss: 0.1807, step time: 0.3882\n",
      "19/224, train_loss: 0.2257, step time: 0.3198\n",
      "20/224, train_loss: 0.3786, step time: 0.3828\n",
      "21/224, train_loss: 0.3418, step time: 0.3919\n",
      "22/224, train_loss: 0.1213, step time: 0.3855\n",
      "23/224, train_loss: 0.1819, step time: 0.3200\n",
      "24/224, train_loss: 0.1354, step time: 0.3194\n",
      "25/224, train_loss: 0.3218, step time: 0.3946\n",
      "26/224, train_loss: 0.3218, step time: 0.3717\n",
      "27/224, train_loss: 0.2184, step time: 0.4043\n",
      "28/224, train_loss: 0.4299, step time: 0.3907\n",
      "29/224, train_loss: 0.2226, step time: 0.3152\n",
      "30/224, train_loss: 0.3757, step time: 0.4054\n",
      "31/224, train_loss: 0.1160, step time: 0.3199\n",
      "32/224, train_loss: 0.3547, step time: 0.3196\n",
      "33/224, train_loss: 0.1225, step time: 0.3707\n",
      "34/224, train_loss: 0.0945, step time: 0.3153\n",
      "35/224, train_loss: 0.2847, step time: 0.3815\n",
      "36/224, train_loss: 0.2049, step time: 0.3919\n",
      "37/224, train_loss: 0.1717, step time: 0.3904\n",
      "38/224, train_loss: 0.1193, step time: 0.3729\n",
      "39/224, train_loss: 0.1380, step time: 0.3970\n",
      "40/224, train_loss: 0.1393, step time: 0.3206\n",
      "41/224, train_loss: 0.2287, step time: 0.3673\n",
      "42/224, train_loss: 0.1524, step time: 0.3807\n",
      "43/224, train_loss: 0.2847, step time: 0.3937\n",
      "44/224, train_loss: 0.1461, step time: 0.3150\n",
      "45/224, train_loss: 0.1454, step time: 0.3173\n",
      "46/224, train_loss: 0.1254, step time: 0.3170\n",
      "47/224, train_loss: 0.2277, step time: 0.3201\n",
      "48/224, train_loss: 0.1643, step time: 0.3746\n",
      "49/224, train_loss: 0.1608, step time: 0.3199\n",
      "50/224, train_loss: 0.2502, step time: 0.3181\n",
      "51/224, train_loss: 0.1790, step time: 0.3178\n",
      "52/224, train_loss: 0.1016, step time: 0.3947\n",
      "53/224, train_loss: 0.2564, step time: 0.3736\n",
      "54/224, train_loss: 0.2064, step time: 0.3188\n",
      "55/224, train_loss: 0.1510, step time: 0.3182\n",
      "56/224, train_loss: 0.0986, step time: 0.3157\n",
      "57/224, train_loss: 0.2201, step time: 0.4178\n",
      "58/224, train_loss: 0.1477, step time: 0.4029\n",
      "59/224, train_loss: 0.3716, step time: 0.3881\n",
      "60/224, train_loss: 0.1480, step time: 0.3164\n",
      "61/224, train_loss: 0.2239, step time: 0.3166\n",
      "62/224, train_loss: 0.1775, step time: 0.3147\n",
      "63/224, train_loss: 0.1880, step time: 0.3164\n",
      "64/224, train_loss: 0.3141, step time: 0.3142\n",
      "65/224, train_loss: 0.2220, step time: 0.3158\n",
      "66/224, train_loss: 0.2566, step time: 0.3964\n",
      "67/224, train_loss: 0.0985, step time: 0.3190\n",
      "68/224, train_loss: 0.1822, step time: 0.3889\n",
      "69/224, train_loss: 0.2255, step time: 0.3164\n",
      "70/224, train_loss: 0.1398, step time: 0.3679\n",
      "71/224, train_loss: 0.0959, step time: 0.3168\n",
      "72/224, train_loss: 0.3479, step time: 0.3191\n",
      "73/224, train_loss: 0.1914, step time: 0.3664\n",
      "74/224, train_loss: 0.3216, step time: 0.3903\n",
      "75/224, train_loss: 0.2163, step time: 0.3158\n",
      "76/224, train_loss: 0.1362, step time: 0.3992\n",
      "77/224, train_loss: 0.2545, step time: 0.3702\n",
      "78/224, train_loss: 0.1982, step time: 0.3749\n",
      "79/224, train_loss: 0.3407, step time: 0.3180\n",
      "80/224, train_loss: 0.3570, step time: 0.3728\n",
      "81/224, train_loss: 0.1870, step time: 0.3900\n",
      "82/224, train_loss: 0.1710, step time: 0.3178\n",
      "83/224, train_loss: 0.1502, step time: 0.3175\n",
      "84/224, train_loss: 0.2056, step time: 0.3751\n",
      "85/224, train_loss: 0.1265, step time: 0.3155\n",
      "86/224, train_loss: 0.0559, step time: 0.3181\n",
      "87/224, train_loss: 0.0890, step time: 0.3148\n",
      "88/224, train_loss: 0.3327, step time: 0.3766\n",
      "89/224, train_loss: 0.3588, step time: 0.3179\n",
      "90/224, train_loss: 0.1699, step time: 0.3168\n",
      "91/224, train_loss: 0.2820, step time: 0.4106\n",
      "92/224, train_loss: 0.2423, step time: 0.3830\n",
      "93/224, train_loss: 0.0532, step time: 0.3188\n",
      "94/224, train_loss: 0.0978, step time: 0.3981\n",
      "95/224, train_loss: 0.3257, step time: 0.3174\n",
      "96/224, train_loss: 0.1648, step time: 0.3171\n",
      "97/224, train_loss: 0.1701, step time: 0.3147\n",
      "98/224, train_loss: 0.3677, step time: 0.3927\n",
      "99/224, train_loss: 0.1361, step time: 0.4099\n",
      "100/224, train_loss: 0.1429, step time: 0.3170\n",
      "101/224, train_loss: 0.0872, step time: 0.3795\n",
      "102/224, train_loss: 0.4463, step time: 0.3179\n",
      "103/224, train_loss: 0.1027, step time: 0.3157\n",
      "104/224, train_loss: 0.1116, step time: 0.3874\n",
      "105/224, train_loss: 0.0805, step time: 0.3208\n",
      "106/224, train_loss: 0.2152, step time: 0.3717\n",
      "107/224, train_loss: 0.0996, step time: 0.3843\n",
      "108/224, train_loss: 0.1401, step time: 0.3179\n",
      "109/224, train_loss: 0.2923, step time: 0.3961\n",
      "110/224, train_loss: 0.3519, step time: 0.3700\n",
      "111/224, train_loss: 0.1456, step time: 0.3804\n",
      "112/224, train_loss: 0.3907, step time: 0.3182\n",
      "113/224, train_loss: 0.1565, step time: 0.3204\n",
      "114/224, train_loss: 0.3394, step time: 0.4124\n",
      "115/224, train_loss: 0.2996, step time: 0.3208\n",
      "116/224, train_loss: 0.1958, step time: 0.3203\n",
      "117/224, train_loss: 0.0960, step time: 0.3203\n",
      "118/224, train_loss: 0.1884, step time: 0.3877\n",
      "119/224, train_loss: 0.2760, step time: 0.4123\n",
      "120/224, train_loss: 0.2015, step time: 0.4109\n",
      "121/224, train_loss: 0.3907, step time: 0.3184\n",
      "122/224, train_loss: 0.3875, step time: 0.3707\n",
      "123/224, train_loss: 0.2750, step time: 0.3731\n",
      "124/224, train_loss: 0.1078, step time: 0.3790\n",
      "125/224, train_loss: 0.1932, step time: 0.3673\n",
      "126/224, train_loss: 0.1884, step time: 0.3762\n",
      "127/224, train_loss: 0.3713, step time: 0.3909\n",
      "128/224, train_loss: 0.1261, step time: 0.3971\n",
      "129/224, train_loss: 0.2327, step time: 0.3170\n",
      "130/224, train_loss: 0.1503, step time: 0.3178\n",
      "131/224, train_loss: 0.0883, step time: 0.3912\n",
      "132/224, train_loss: 0.3218, step time: 0.3791\n",
      "133/224, train_loss: 0.1472, step time: 0.3969\n",
      "134/224, train_loss: 0.2258, step time: 0.3163\n",
      "135/224, train_loss: 0.3498, step time: 0.3166\n",
      "136/224, train_loss: 0.1771, step time: 0.3148\n",
      "137/224, train_loss: 0.3632, step time: 0.3684\n",
      "138/224, train_loss: 0.2410, step time: 0.3743\n",
      "139/224, train_loss: 0.0941, step time: 0.3161\n",
      "140/224, train_loss: 0.1178, step time: 0.4112\n",
      "141/224, train_loss: 0.1767, step time: 0.3770\n",
      "142/224, train_loss: 0.1142, step time: 0.3163\n",
      "143/224, train_loss: 0.2048, step time: 0.3783\n",
      "144/224, train_loss: 0.0832, step time: 0.3177\n",
      "145/224, train_loss: 0.0734, step time: 0.4055\n",
      "146/224, train_loss: 0.1773, step time: 0.3765\n",
      "147/224, train_loss: 0.1295, step time: 0.3866\n",
      "148/224, train_loss: 0.1779, step time: 0.3180\n",
      "149/224, train_loss: 0.0879, step time: 0.4081\n",
      "150/224, train_loss: 0.1501, step time: 0.3157\n",
      "151/224, train_loss: 0.0933, step time: 0.4097\n",
      "152/224, train_loss: 0.4270, step time: 0.3148\n",
      "153/224, train_loss: 0.2308, step time: 0.3170\n",
      "154/224, train_loss: 0.1390, step time: 0.3131\n",
      "155/224, train_loss: 0.1300, step time: 0.3156\n",
      "156/224, train_loss: 0.1064, step time: 0.4004\n",
      "157/224, train_loss: 0.2376, step time: 0.3731\n",
      "158/224, train_loss: 0.2188, step time: 0.3942\n",
      "159/224, train_loss: 0.1364, step time: 0.4055\n",
      "160/224, train_loss: 0.1257, step time: 0.3179\n",
      "161/224, train_loss: 0.3650, step time: 0.3796\n",
      "162/224, train_loss: 0.3836, step time: 0.3722\n",
      "163/224, train_loss: 0.4459, step time: 0.3950\n",
      "164/224, train_loss: 0.1023, step time: 0.4050\n",
      "165/224, train_loss: 0.3761, step time: 0.3163\n",
      "166/224, train_loss: 0.3676, step time: 0.4022\n",
      "167/224, train_loss: 0.1645, step time: 0.3154\n",
      "168/224, train_loss: 0.0864, step time: 0.4105\n",
      "169/224, train_loss: 0.1327, step time: 0.3151\n",
      "170/224, train_loss: 0.0624, step time: 0.3217\n",
      "171/224, train_loss: 0.0830, step time: 0.3209\n",
      "172/224, train_loss: 0.1354, step time: 0.3183\n",
      "173/224, train_loss: 0.2518, step time: 0.3155\n",
      "174/224, train_loss: 0.3974, step time: 0.3746\n",
      "175/224, train_loss: 0.2220, step time: 0.4003\n",
      "176/224, train_loss: 0.1099, step time: 0.3151\n",
      "177/224, train_loss: 0.3267, step time: 0.3192\n",
      "178/224, train_loss: 0.2424, step time: 0.4045\n",
      "179/224, train_loss: 0.3838, step time: 0.3169\n",
      "180/224, train_loss: 0.1293, step time: 0.3183\n",
      "181/224, train_loss: 0.1856, step time: 0.3227\n",
      "182/224, train_loss: 0.2468, step time: 0.4051\n",
      "183/224, train_loss: 0.2817, step time: 0.3177\n",
      "184/224, train_loss: 0.1632, step time: 0.3200\n",
      "185/224, train_loss: 0.1402, step time: 0.3179\n",
      "186/224, train_loss: 0.4137, step time: 0.3155\n",
      "187/224, train_loss: 0.1673, step time: 0.4027\n",
      "188/224, train_loss: 0.4019, step time: 0.3870\n",
      "189/224, train_loss: 0.1979, step time: 0.4013\n",
      "190/224, train_loss: 0.1331, step time: 0.3703\n",
      "191/224, train_loss: 0.1880, step time: 0.3776\n",
      "192/224, train_loss: 0.1959, step time: 0.3733\n",
      "193/224, train_loss: 0.1675, step time: 0.4074\n",
      "194/224, train_loss: 0.1619, step time: 0.3979\n",
      "195/224, train_loss: 0.2454, step time: 0.3726\n",
      "196/224, train_loss: 0.3325, step time: 0.3188\n",
      "197/224, train_loss: 0.1932, step time: 0.3907\n",
      "198/224, train_loss: 0.3734, step time: 0.4143\n",
      "199/224, train_loss: 0.1320, step time: 0.3162\n",
      "200/224, train_loss: 0.1052, step time: 0.4025\n",
      "201/224, train_loss: 0.3526, step time: 0.3158\n",
      "202/224, train_loss: 0.1997, step time: 0.3179\n",
      "203/224, train_loss: 0.1597, step time: 0.3134\n",
      "204/224, train_loss: 0.3041, step time: 0.3975\n",
      "205/224, train_loss: 0.1502, step time: 0.3924\n",
      "206/224, train_loss: 0.1338, step time: 0.3136\n",
      "207/224, train_loss: 0.2411, step time: 0.3851\n",
      "208/224, train_loss: 0.1876, step time: 0.3174\n",
      "209/224, train_loss: 0.1670, step time: 0.3153\n",
      "210/224, train_loss: 0.1916, step time: 0.4083\n",
      "211/224, train_loss: 0.1222, step time: 0.3132\n",
      "212/224, train_loss: 0.1189, step time: 0.4012\n",
      "213/224, train_loss: 0.0877, step time: 0.3914\n",
      "214/224, train_loss: 0.3479, step time: 0.3988\n",
      "215/224, train_loss: 0.1457, step time: 0.3155\n",
      "216/224, train_loss: 0.3070, step time: 0.3801\n",
      "217/224, train_loss: 0.0814, step time: 0.4039\n",
      "218/224, train_loss: 0.1276, step time: 0.3918\n",
      "219/224, train_loss: 0.2973, step time: 0.3686\n",
      "220/224, train_loss: 0.0672, step time: 0.3146\n",
      "221/224, train_loss: 0.1636, step time: 0.3761\n",
      "222/224, train_loss: 0.1023, step time: 0.3182\n",
      "223/224, train_loss: 0.1106, step time: 0.3160\n",
      "224/224, train_loss: 0.3334, step time: 0.3162\n",
      "epoch 35 average loss: 0.2094\n",
      "current epoch: 35 current mean dice: 0.6921 class1: 0.9993 class2: 0.7237 class3: 0.3533\n",
      "best mean dice: 0.6956 at epoch: 33\n",
      "time consuming of epoch 35 is: 818.2300\n",
      "hello\n",
      "----------\n",
      "epoch 36/100\n",
      "1/224, train_loss: 0.3073, step time: 0.3134\n",
      "2/224, train_loss: 0.0920, step time: 0.3156\n",
      "3/224, train_loss: 0.3358, step time: 0.3154\n",
      "4/224, train_loss: 0.1556, step time: 0.3161\n",
      "5/224, train_loss: 0.1860, step time: 0.3689\n",
      "6/224, train_loss: 0.3016, step time: 0.3705\n",
      "7/224, train_loss: 0.3132, step time: 0.3944\n",
      "8/224, train_loss: 0.3752, step time: 0.3150\n",
      "9/224, train_loss: 0.0831, step time: 0.3172\n",
      "10/224, train_loss: 0.2356, step time: 0.3180\n",
      "11/224, train_loss: 0.2134, step time: 0.3729\n",
      "12/224, train_loss: 0.1179, step time: 0.3691\n",
      "13/224, train_loss: 0.1519, step time: 0.3175\n",
      "14/224, train_loss: 0.1621, step time: 0.3149\n",
      "15/224, train_loss: 0.1073, step time: 0.3174\n",
      "16/224, train_loss: 0.1001, step time: 0.3159\n",
      "17/224, train_loss: 0.2419, step time: 0.3793\n",
      "18/224, train_loss: 0.1369, step time: 0.3157\n",
      "19/224, train_loss: 0.0955, step time: 0.4014\n",
      "20/224, train_loss: 0.1367, step time: 0.3173\n",
      "21/224, train_loss: 0.2626, step time: 0.3979\n",
      "22/224, train_loss: 0.4086, step time: 0.3827\n",
      "23/224, train_loss: 0.1320, step time: 0.3179\n",
      "24/224, train_loss: 0.2618, step time: 0.3181\n",
      "25/224, train_loss: 0.3242, step time: 0.3905\n",
      "26/224, train_loss: 0.1015, step time: 0.3160\n",
      "27/224, train_loss: 0.3793, step time: 0.4007\n",
      "28/224, train_loss: 0.1883, step time: 0.3154\n",
      "29/224, train_loss: 0.0877, step time: 0.3148\n",
      "30/224, train_loss: 0.3676, step time: 0.3175\n",
      "31/224, train_loss: 0.1748, step time: 0.3152\n",
      "32/224, train_loss: 0.1725, step time: 0.3861\n",
      "33/224, train_loss: 0.1406, step time: 0.3159\n",
      "34/224, train_loss: 0.4231, step time: 0.4038\n",
      "35/224, train_loss: 0.2031, step time: 0.4064\n",
      "36/224, train_loss: 0.2576, step time: 0.4139\n",
      "37/224, train_loss: 0.1867, step time: 0.3738\n",
      "38/224, train_loss: 0.3925, step time: 0.4098\n",
      "39/224, train_loss: 0.1230, step time: 0.3172\n",
      "40/224, train_loss: 0.1747, step time: 0.4108\n",
      "41/224, train_loss: 0.0559, step time: 0.3155\n",
      "42/224, train_loss: 0.1421, step time: 0.3135\n",
      "43/224, train_loss: 0.1686, step time: 0.3888\n",
      "44/224, train_loss: 0.3037, step time: 0.3970\n",
      "45/224, train_loss: 0.4080, step time: 0.3172\n",
      "46/224, train_loss: 0.3415, step time: 0.3813\n",
      "47/224, train_loss: 0.1186, step time: 0.3160\n",
      "48/224, train_loss: 0.1450, step time: 0.3998\n",
      "49/224, train_loss: 0.2921, step time: 0.3688\n",
      "50/224, train_loss: 0.1728, step time: 0.3845\n",
      "51/224, train_loss: 0.2109, step time: 0.3648\n",
      "52/224, train_loss: 0.3508, step time: 0.3694\n",
      "53/224, train_loss: 0.3434, step time: 0.3750\n",
      "54/224, train_loss: 0.1533, step time: 0.3804\n",
      "55/224, train_loss: 0.3382, step time: 0.3154\n",
      "56/224, train_loss: 0.0859, step time: 0.3683\n",
      "57/224, train_loss: 0.0819, step time: 0.3737\n",
      "58/224, train_loss: 0.1336, step time: 0.3688\n",
      "59/224, train_loss: 0.1117, step time: 0.3154\n",
      "60/224, train_loss: 0.1391, step time: 0.3884\n",
      "61/224, train_loss: 0.3883, step time: 0.3877\n",
      "62/224, train_loss: 0.1672, step time: 0.3631\n",
      "63/224, train_loss: 0.1273, step time: 0.3160\n",
      "64/224, train_loss: 0.2192, step time: 0.3693\n",
      "65/224, train_loss: 0.1231, step time: 0.3132\n",
      "66/224, train_loss: 0.1524, step time: 0.3838\n",
      "67/224, train_loss: 0.2763, step time: 0.3862\n",
      "68/224, train_loss: 0.1898, step time: 0.4009\n",
      "69/224, train_loss: 0.2282, step time: 0.3896\n",
      "70/224, train_loss: 0.1091, step time: 0.3747\n",
      "71/224, train_loss: 0.1570, step time: 0.3152\n",
      "72/224, train_loss: 0.3079, step time: 0.3154\n",
      "73/224, train_loss: 0.1808, step time: 0.3176\n",
      "74/224, train_loss: 0.2331, step time: 0.3709\n",
      "75/224, train_loss: 0.0991, step time: 0.3154\n",
      "76/224, train_loss: 0.1607, step time: 0.3867\n",
      "77/224, train_loss: 0.1853, step time: 0.3878\n",
      "78/224, train_loss: 0.2068, step time: 0.3806\n",
      "79/224, train_loss: 0.1214, step time: 0.3775\n",
      "80/224, train_loss: 0.2059, step time: 0.3148\n",
      "81/224, train_loss: 0.1489, step time: 0.3819\n",
      "82/224, train_loss: 0.2275, step time: 0.3882\n",
      "83/224, train_loss: 0.2072, step time: 0.3128\n",
      "84/224, train_loss: 0.2070, step time: 0.3142\n",
      "85/224, train_loss: 0.1283, step time: 0.3759\n",
      "86/224, train_loss: 0.2561, step time: 0.3741\n",
      "87/224, train_loss: 0.3382, step time: 0.3170\n",
      "88/224, train_loss: 0.1547, step time: 0.3144\n",
      "89/224, train_loss: 0.1406, step time: 0.3121\n",
      "90/224, train_loss: 0.2569, step time: 0.3939\n",
      "91/224, train_loss: 0.4417, step time: 0.3713\n",
      "92/224, train_loss: 0.1533, step time: 0.3730\n",
      "93/224, train_loss: 0.2960, step time: 0.3977\n",
      "94/224, train_loss: 0.1451, step time: 0.3717\n",
      "95/224, train_loss: 0.0884, step time: 0.3147\n",
      "96/224, train_loss: 0.1348, step time: 0.3144\n",
      "97/224, train_loss: 0.2204, step time: 0.3990\n",
      "98/224, train_loss: 0.1219, step time: 0.3150\n",
      "99/224, train_loss: 0.4821, step time: 0.3725\n",
      "100/224, train_loss: 0.1407, step time: 0.3171\n",
      "101/224, train_loss: 0.1211, step time: 0.3823\n",
      "102/224, train_loss: 0.1791, step time: 0.3148\n",
      "103/224, train_loss: 0.1236, step time: 0.3143\n",
      "104/224, train_loss: 0.1992, step time: 0.3142\n",
      "105/224, train_loss: 0.1047, step time: 0.3144\n",
      "106/224, train_loss: 0.2498, step time: 0.3145\n",
      "107/224, train_loss: 0.1899, step time: 0.3860\n",
      "108/224, train_loss: 0.1207, step time: 0.3133\n",
      "109/224, train_loss: 0.1552, step time: 0.3751\n",
      "110/224, train_loss: 0.3553, step time: 0.3149\n",
      "111/224, train_loss: 0.1757, step time: 0.3154\n",
      "112/224, train_loss: 0.1218, step time: 0.3691\n",
      "113/224, train_loss: 0.1464, step time: 0.3845\n",
      "114/224, train_loss: 0.1552, step time: 0.3155\n",
      "115/224, train_loss: 0.2089, step time: 0.4093\n",
      "116/224, train_loss: 0.3914, step time: 0.3822\n",
      "117/224, train_loss: 0.2721, step time: 0.3123\n",
      "118/224, train_loss: 0.0955, step time: 0.3944\n",
      "119/224, train_loss: 0.4108, step time: 0.3683\n",
      "120/224, train_loss: 0.2255, step time: 0.3932\n",
      "121/224, train_loss: 0.1391, step time: 0.3174\n",
      "122/224, train_loss: 0.1145, step time: 0.3122\n",
      "123/224, train_loss: 0.0659, step time: 0.3125\n",
      "124/224, train_loss: 0.2587, step time: 0.3154\n",
      "125/224, train_loss: 0.2231, step time: 0.3738\n",
      "126/224, train_loss: 0.3902, step time: 0.3157\n",
      "127/224, train_loss: 0.0893, step time: 0.3146\n",
      "128/224, train_loss: 0.1182, step time: 0.3142\n",
      "129/224, train_loss: 0.2482, step time: 0.3129\n",
      "130/224, train_loss: 0.2842, step time: 0.3846\n",
      "131/224, train_loss: 0.1161, step time: 0.4032\n",
      "132/224, train_loss: 0.2127, step time: 0.3127\n",
      "133/224, train_loss: 0.1040, step time: 0.3770\n",
      "134/224, train_loss: 0.2874, step time: 0.3770\n",
      "135/224, train_loss: 0.3999, step time: 0.3798\n",
      "136/224, train_loss: 0.0897, step time: 0.3147\n",
      "137/224, train_loss: 0.1059, step time: 0.3972\n",
      "138/224, train_loss: 0.1139, step time: 0.3861\n",
      "139/224, train_loss: 0.1257, step time: 0.3149\n",
      "140/224, train_loss: 0.1661, step time: 0.3929\n",
      "141/224, train_loss: 0.3246, step time: 0.3170\n",
      "142/224, train_loss: 0.1328, step time: 0.3143\n",
      "143/224, train_loss: 0.1510, step time: 0.3141\n",
      "144/224, train_loss: 0.1936, step time: 0.3854\n",
      "145/224, train_loss: 0.1803, step time: 0.3847\n",
      "146/224, train_loss: 0.1615, step time: 0.3153\n",
      "147/224, train_loss: 0.1405, step time: 0.3152\n",
      "148/224, train_loss: 0.2394, step time: 0.4097\n",
      "149/224, train_loss: 0.1621, step time: 0.3879\n",
      "150/224, train_loss: 0.1933, step time: 0.3149\n",
      "151/224, train_loss: 0.1418, step time: 0.3147\n",
      "152/224, train_loss: 0.1437, step time: 0.3173\n",
      "153/224, train_loss: 0.2566, step time: 0.3722\n",
      "154/224, train_loss: 0.3631, step time: 0.3152\n",
      "155/224, train_loss: 0.4136, step time: 0.3972\n",
      "156/224, train_loss: 0.2064, step time: 0.4025\n",
      "157/224, train_loss: 0.1005, step time: 0.3168\n",
      "158/224, train_loss: 0.2849, step time: 0.3153\n",
      "159/224, train_loss: 0.0893, step time: 0.3156\n",
      "160/224, train_loss: 0.2231, step time: 0.3985\n",
      "161/224, train_loss: 0.1502, step time: 0.3143\n",
      "162/224, train_loss: 0.2955, step time: 0.3167\n",
      "163/224, train_loss: 0.2512, step time: 0.3972\n",
      "164/224, train_loss: 0.1850, step time: 0.3124\n",
      "165/224, train_loss: 0.1131, step time: 0.3144\n",
      "166/224, train_loss: 0.1099, step time: 0.3122\n",
      "167/224, train_loss: 0.1453, step time: 0.3141\n",
      "168/224, train_loss: 0.1003, step time: 0.4037\n",
      "169/224, train_loss: 0.1515, step time: 0.3981\n",
      "170/224, train_loss: 0.2175, step time: 0.3146\n",
      "171/224, train_loss: 0.1987, step time: 0.3924\n",
      "172/224, train_loss: 0.1552, step time: 0.3915\n",
      "173/224, train_loss: 0.3634, step time: 0.3799\n",
      "174/224, train_loss: 0.1531, step time: 0.3787\n",
      "175/224, train_loss: 0.3400, step time: 0.3717\n",
      "176/224, train_loss: 0.2230, step time: 0.3174\n",
      "177/224, train_loss: 0.0839, step time: 0.4730\n",
      "178/224, train_loss: 0.0727, step time: 0.4018\n",
      "179/224, train_loss: 0.1651, step time: 0.3190\n",
      "180/224, train_loss: 0.2327, step time: 0.3941\n",
      "181/224, train_loss: 0.2465, step time: 0.3155\n",
      "182/224, train_loss: 0.2148, step time: 0.3780\n",
      "183/224, train_loss: 0.1210, step time: 0.3152\n",
      "184/224, train_loss: 0.1802, step time: 0.4099\n",
      "185/224, train_loss: 0.3360, step time: 0.3971\n",
      "186/224, train_loss: 0.2269, step time: 0.3140\n",
      "187/224, train_loss: 0.1266, step time: 0.3155\n",
      "188/224, train_loss: 0.0822, step time: 0.3174\n",
      "189/224, train_loss: 0.2672, step time: 0.3919\n",
      "190/224, train_loss: 0.3815, step time: 0.3136\n",
      "191/224, train_loss: 0.1012, step time: 0.3911\n",
      "192/224, train_loss: 0.3464, step time: 0.3133\n",
      "193/224, train_loss: 0.3784, step time: 0.4072\n",
      "194/224, train_loss: 0.3277, step time: 0.4057\n",
      "195/224, train_loss: 0.3595, step time: 0.3738\n",
      "196/224, train_loss: 0.2798, step time: 0.3857\n",
      "197/224, train_loss: 0.1591, step time: 0.3154\n",
      "198/224, train_loss: 0.0633, step time: 0.3150\n",
      "199/224, train_loss: 0.4121, step time: 0.4011\n",
      "200/224, train_loss: 0.1366, step time: 0.3133\n",
      "201/224, train_loss: 0.0732, step time: 0.3150\n",
      "202/224, train_loss: 0.3629, step time: 0.3130\n",
      "203/224, train_loss: 0.2147, step time: 0.4033\n",
      "204/224, train_loss: 0.3862, step time: 0.3895\n",
      "205/224, train_loss: 0.1969, step time: 0.3676\n",
      "206/224, train_loss: 0.3415, step time: 0.3165\n",
      "207/224, train_loss: 0.1819, step time: 0.4018\n",
      "208/224, train_loss: 0.0932, step time: 0.3912\n",
      "209/224, train_loss: 0.2772, step time: 0.3152\n",
      "210/224, train_loss: 0.1532, step time: 0.3969\n",
      "211/224, train_loss: 0.0800, step time: 0.3138\n",
      "212/224, train_loss: 0.2558, step time: 0.3818\n",
      "213/224, train_loss: 0.3780, step time: 0.3145\n",
      "214/224, train_loss: 0.1867, step time: 0.3793\n",
      "215/224, train_loss: 0.3697, step time: 0.4007\n",
      "216/224, train_loss: 0.0835, step time: 0.3181\n",
      "217/224, train_loss: 0.2497, step time: 0.4111\n",
      "218/224, train_loss: 0.2852, step time: 0.3821\n",
      "219/224, train_loss: 0.1646, step time: 0.4020\n",
      "220/224, train_loss: 0.1423, step time: 0.3974\n",
      "221/224, train_loss: 0.2611, step time: 0.3794\n",
      "222/224, train_loss: 0.3412, step time: 0.3937\n",
      "223/224, train_loss: 0.1116, step time: 0.4076\n",
      "224/224, train_loss: 0.0626, step time: 0.3159\n",
      "epoch 36 average loss: 0.2067\n",
      "current epoch: 36 current mean dice: 0.6949 class1: 0.9993 class2: 0.7175 class3: 0.3679\n",
      "best mean dice: 0.6956 at epoch: 33\n",
      "time consuming of epoch 36 is: 753.1310\n",
      "hello\n",
      "----------\n",
      "epoch 37/100\n",
      "1/224, train_loss: 0.2073, step time: 0.4052\n",
      "2/224, train_loss: 0.1802, step time: 0.3729\n",
      "3/224, train_loss: 0.3266, step time: 0.3166\n",
      "4/224, train_loss: 0.0836, step time: 0.3192\n",
      "5/224, train_loss: 0.1013, step time: 0.3901\n",
      "6/224, train_loss: 0.0790, step time: 0.3139\n",
      "7/224, train_loss: 0.1626, step time: 0.3827\n",
      "8/224, train_loss: 0.1477, step time: 0.3154\n",
      "9/224, train_loss: 0.2785, step time: 0.3845\n",
      "10/224, train_loss: 0.2572, step time: 0.3165\n",
      "11/224, train_loss: 0.1486, step time: 0.3160\n",
      "12/224, train_loss: 0.1120, step time: 0.3894\n",
      "13/224, train_loss: 0.0917, step time: 0.3176\n",
      "14/224, train_loss: 0.1870, step time: 0.3764\n",
      "15/224, train_loss: 0.2807, step time: 0.3794\n",
      "16/224, train_loss: 0.0618, step time: 0.3847\n",
      "17/224, train_loss: 0.1108, step time: 0.3169\n",
      "18/224, train_loss: 0.3641, step time: 0.3147\n",
      "19/224, train_loss: 0.1517, step time: 0.3745\n",
      "20/224, train_loss: 0.1124, step time: 0.3705\n",
      "21/224, train_loss: 0.4587, step time: 0.4023\n",
      "22/224, train_loss: 0.1731, step time: 0.3184\n",
      "23/224, train_loss: 0.2908, step time: 0.3933\n",
      "24/224, train_loss: 0.2078, step time: 0.3881\n",
      "25/224, train_loss: 0.1271, step time: 0.3153\n",
      "26/224, train_loss: 0.3742, step time: 0.3966\n",
      "27/224, train_loss: 0.1292, step time: 0.3153\n",
      "28/224, train_loss: 0.3652, step time: 0.3149\n",
      "29/224, train_loss: 0.2417, step time: 0.3830\n",
      "30/224, train_loss: 0.2326, step time: 0.3160\n",
      "31/224, train_loss: 0.1258, step time: 0.3158\n",
      "32/224, train_loss: 0.3960, step time: 0.3177\n",
      "33/224, train_loss: 0.1779, step time: 0.3152\n",
      "34/224, train_loss: 0.1292, step time: 0.3174\n",
      "35/224, train_loss: 0.3296, step time: 0.3922\n",
      "36/224, train_loss: 0.2295, step time: 0.3980\n",
      "37/224, train_loss: 0.0970, step time: 0.3157\n",
      "38/224, train_loss: 0.0762, step time: 0.3173\n",
      "39/224, train_loss: 0.0930, step time: 0.3689\n",
      "40/224, train_loss: 0.1976, step time: 0.3155\n",
      "41/224, train_loss: 0.1483, step time: 0.3176\n",
      "42/224, train_loss: 0.1024, step time: 0.3181\n",
      "43/224, train_loss: 0.2938, step time: 0.3712\n",
      "44/224, train_loss: 0.2094, step time: 0.4057\n",
      "45/224, train_loss: 0.1317, step time: 0.3159\n",
      "46/224, train_loss: 0.0555, step time: 0.3719\n",
      "47/224, train_loss: 0.3329, step time: 0.3158\n",
      "48/224, train_loss: 0.1834, step time: 0.3175\n",
      "49/224, train_loss: 0.3273, step time: 0.3968\n",
      "50/224, train_loss: 0.1795, step time: 0.3894\n",
      "51/224, train_loss: 0.0842, step time: 0.4074\n",
      "52/224, train_loss: 0.2367, step time: 0.3948\n",
      "53/224, train_loss: 0.1954, step time: 0.3158\n",
      "54/224, train_loss: 0.2383, step time: 0.3693\n",
      "55/224, train_loss: 0.1575, step time: 0.3159\n",
      "56/224, train_loss: 0.2189, step time: 0.3912\n",
      "57/224, train_loss: 0.3655, step time: 0.3127\n",
      "58/224, train_loss: 0.3383, step time: 0.3173\n",
      "59/224, train_loss: 0.3335, step time: 0.3908\n",
      "60/224, train_loss: 0.0996, step time: 0.3131\n",
      "61/224, train_loss: 0.0959, step time: 0.4007\n",
      "62/224, train_loss: 0.1095, step time: 0.3171\n",
      "63/224, train_loss: 0.1273, step time: 0.3150\n",
      "64/224, train_loss: 0.0957, step time: 0.3147\n",
      "65/224, train_loss: 0.1310, step time: 0.3854\n",
      "66/224, train_loss: 0.1650, step time: 0.3150\n",
      "67/224, train_loss: 0.1521, step time: 0.3154\n",
      "68/224, train_loss: 0.3360, step time: 0.3154\n",
      "69/224, train_loss: 0.1615, step time: 0.3150\n",
      "70/224, train_loss: 0.1753, step time: 0.3869\n",
      "71/224, train_loss: 0.2387, step time: 0.3878\n",
      "72/224, train_loss: 0.2462, step time: 0.3719\n",
      "73/224, train_loss: 0.3655, step time: 0.3149\n",
      "74/224, train_loss: 0.0953, step time: 0.3908\n",
      "75/224, train_loss: 0.3748, step time: 0.4120\n",
      "76/224, train_loss: 0.1018, step time: 0.3148\n",
      "77/224, train_loss: 0.3232, step time: 0.3152\n",
      "78/224, train_loss: 0.3689, step time: 0.3130\n",
      "79/224, train_loss: 0.0800, step time: 0.3172\n",
      "80/224, train_loss: 0.1939, step time: 0.4045\n",
      "81/224, train_loss: 0.2567, step time: 0.3967\n",
      "82/224, train_loss: 0.1408, step time: 0.3148\n",
      "83/224, train_loss: 0.1248, step time: 0.3849\n",
      "84/224, train_loss: 0.2234, step time: 0.3709\n",
      "85/224, train_loss: 0.1235, step time: 0.3168\n",
      "86/224, train_loss: 0.1259, step time: 0.3767\n",
      "87/224, train_loss: 0.2791, step time: 0.3157\n",
      "88/224, train_loss: 0.3420, step time: 0.4084\n",
      "89/224, train_loss: 0.1607, step time: 0.3159\n",
      "90/224, train_loss: 0.2118, step time: 0.3183\n",
      "91/224, train_loss: 0.1438, step time: 0.4002\n",
      "92/224, train_loss: 0.1382, step time: 0.3159\n",
      "93/224, train_loss: 0.4123, step time: 0.3673\n",
      "94/224, train_loss: 0.1185, step time: 0.3928\n",
      "95/224, train_loss: 0.1032, step time: 0.3157\n",
      "96/224, train_loss: 0.1022, step time: 0.3762\n",
      "97/224, train_loss: 0.2263, step time: 0.3912\n",
      "98/224, train_loss: 0.2036, step time: 0.3868\n",
      "99/224, train_loss: 0.2460, step time: 0.4037\n",
      "100/224, train_loss: 0.1089, step time: 0.3839\n",
      "101/224, train_loss: 0.3618, step time: 0.3152\n",
      "102/224, train_loss: 0.2120, step time: 0.3150\n",
      "103/224, train_loss: 0.1242, step time: 0.3153\n",
      "104/224, train_loss: 0.1366, step time: 0.3155\n",
      "105/224, train_loss: 0.3237, step time: 0.3134\n",
      "106/224, train_loss: 0.1196, step time: 0.3880\n",
      "107/224, train_loss: 0.0851, step time: 0.3161\n",
      "108/224, train_loss: 0.2851, step time: 0.3161\n",
      "109/224, train_loss: 0.4587, step time: 0.4085\n",
      "110/224, train_loss: 0.2898, step time: 0.3150\n",
      "111/224, train_loss: 0.1113, step time: 0.3159\n",
      "112/224, train_loss: 0.3165, step time: 0.3942\n",
      "113/224, train_loss: 0.3094, step time: 0.3555\n",
      "114/224, train_loss: 0.1383, step time: 0.3721\n",
      "115/224, train_loss: 0.1476, step time: 0.3160\n",
      "116/224, train_loss: 0.1376, step time: 0.4009\n",
      "117/224, train_loss: 0.1341, step time: 0.3941\n",
      "118/224, train_loss: 0.5371, step time: 0.3781\n",
      "119/224, train_loss: 0.3107, step time: 0.3676\n",
      "120/224, train_loss: 0.2294, step time: 0.3151\n",
      "121/224, train_loss: 0.0793, step time: 0.3915\n",
      "122/224, train_loss: 0.1874, step time: 0.3923\n",
      "123/224, train_loss: 0.1628, step time: 0.3152\n",
      "124/224, train_loss: 0.1572, step time: 0.3947\n",
      "125/224, train_loss: 0.2143, step time: 0.3679\n",
      "126/224, train_loss: 0.2757, step time: 0.3152\n",
      "127/224, train_loss: 0.1432, step time: 0.3148\n",
      "128/224, train_loss: 0.2281, step time: 0.3745\n",
      "129/224, train_loss: 0.1070, step time: 0.3991\n",
      "130/224, train_loss: 0.1177, step time: 0.3159\n",
      "131/224, train_loss: 0.2903, step time: 0.3841\n",
      "132/224, train_loss: 0.1664, step time: 0.3685\n",
      "133/224, train_loss: 0.2602, step time: 0.3178\n",
      "134/224, train_loss: 0.1974, step time: 0.3172\n",
      "135/224, train_loss: 0.2398, step time: 0.3148\n",
      "136/224, train_loss: 0.1191, step time: 0.3156\n",
      "137/224, train_loss: 0.1495, step time: 0.3965\n",
      "138/224, train_loss: 0.1514, step time: 0.3171\n",
      "139/224, train_loss: 0.1586, step time: 0.3772\n",
      "140/224, train_loss: 0.1468, step time: 0.3986\n",
      "141/224, train_loss: 0.4067, step time: 0.3656\n",
      "142/224, train_loss: 0.1328, step time: 0.3167\n",
      "143/224, train_loss: 0.2490, step time: 0.3770\n",
      "144/224, train_loss: 0.1841, step time: 0.3646\n",
      "145/224, train_loss: 0.3080, step time: 0.3993\n",
      "146/224, train_loss: 0.1044, step time: 0.3175\n",
      "147/224, train_loss: 0.2153, step time: 0.3846\n",
      "148/224, train_loss: 0.1720, step time: 0.3175\n",
      "149/224, train_loss: 0.2659, step time: 0.3757\n",
      "150/224, train_loss: 0.2313, step time: 0.3189\n",
      "151/224, train_loss: 0.1635, step time: 0.4015\n",
      "152/224, train_loss: 0.0808, step time: 0.3197\n",
      "153/224, train_loss: 0.0679, step time: 0.3172\n",
      "154/224, train_loss: 0.1136, step time: 0.3166\n",
      "155/224, train_loss: 0.1241, step time: 0.3700\n",
      "156/224, train_loss: 0.1506, step time: 0.3152\n",
      "157/224, train_loss: 0.1603, step time: 0.3187\n",
      "158/224, train_loss: 0.3077, step time: 0.3806\n",
      "159/224, train_loss: 0.2430, step time: 0.4029\n",
      "160/224, train_loss: 0.1613, step time: 0.3195\n",
      "161/224, train_loss: 0.1499, step time: 0.3177\n",
      "162/224, train_loss: 0.2714, step time: 0.3180\n",
      "163/224, train_loss: 0.1397, step time: 0.4035\n",
      "164/224, train_loss: 0.3263, step time: 0.3830\n",
      "165/224, train_loss: 0.0940, step time: 0.3168\n",
      "166/224, train_loss: 0.1349, step time: 0.3190\n",
      "167/224, train_loss: 0.1981, step time: 0.3199\n",
      "168/224, train_loss: 0.2412, step time: 0.4098\n",
      "169/224, train_loss: 0.2126, step time: 0.4131\n",
      "170/224, train_loss: 0.3770, step time: 0.3167\n",
      "171/224, train_loss: 0.3555, step time: 0.3980\n",
      "172/224, train_loss: 0.2560, step time: 0.3893\n",
      "173/224, train_loss: 0.2709, step time: 0.4083\n",
      "174/224, train_loss: 0.1783, step time: 0.3194\n",
      "175/224, train_loss: 0.1195, step time: 0.4103\n",
      "176/224, train_loss: 0.2159, step time: 0.3691\n",
      "177/224, train_loss: 0.1070, step time: 0.3911\n",
      "178/224, train_loss: 0.3349, step time: 0.3141\n",
      "179/224, train_loss: 0.2154, step time: 0.3179\n",
      "180/224, train_loss: 0.0950, step time: 0.3156\n",
      "181/224, train_loss: 0.1283, step time: 0.3155\n",
      "182/224, train_loss: 0.0610, step time: 0.3754\n",
      "183/224, train_loss: 0.1837, step time: 0.3155\n",
      "184/224, train_loss: 0.0990, step time: 0.3182\n",
      "185/224, train_loss: 0.1387, step time: 0.3183\n",
      "186/224, train_loss: 0.0991, step time: 0.3161\n",
      "187/224, train_loss: 0.0930, step time: 0.3180\n",
      "188/224, train_loss: 0.2417, step time: 0.3898\n",
      "189/224, train_loss: 0.3682, step time: 0.4077\n",
      "190/224, train_loss: 0.2723, step time: 0.3862\n",
      "191/224, train_loss: 0.1292, step time: 0.3180\n",
      "192/224, train_loss: 0.1835, step time: 0.4115\n",
      "193/224, train_loss: 0.1655, step time: 0.3143\n",
      "194/224, train_loss: 0.1605, step time: 0.3725\n",
      "195/224, train_loss: 0.1708, step time: 0.4042\n",
      "196/224, train_loss: 0.2558, step time: 0.3864\n",
      "197/224, train_loss: 0.2234, step time: 0.3982\n",
      "198/224, train_loss: 0.3039, step time: 0.3765\n",
      "199/224, train_loss: 0.1736, step time: 0.3195\n",
      "200/224, train_loss: 0.3591, step time: 0.3165\n",
      "201/224, train_loss: 0.1598, step time: 0.3171\n",
      "202/224, train_loss: 0.1726, step time: 0.3186\n",
      "203/224, train_loss: 0.4566, step time: 0.4011\n",
      "204/224, train_loss: 0.1902, step time: 0.4080\n",
      "205/224, train_loss: 0.2226, step time: 0.3156\n",
      "206/224, train_loss: 0.1449, step time: 0.3187\n",
      "207/224, train_loss: 0.3216, step time: 0.4117\n",
      "208/224, train_loss: 0.2022, step time: 0.4006\n",
      "209/224, train_loss: 0.1291, step time: 0.3136\n",
      "210/224, train_loss: 0.1617, step time: 0.3881\n",
      "211/224, train_loss: 0.0909, step time: 0.3184\n",
      "212/224, train_loss: 0.2643, step time: 0.3163\n",
      "213/224, train_loss: 0.1329, step time: 0.3968\n",
      "214/224, train_loss: 0.1106, step time: 0.3172\n",
      "215/224, train_loss: 0.0876, step time: 0.3189\n",
      "216/224, train_loss: 0.2113, step time: 0.4010\n",
      "217/224, train_loss: 0.1415, step time: 0.3757\n",
      "218/224, train_loss: 0.1005, step time: 0.3997\n",
      "219/224, train_loss: 0.1863, step time: 0.3965\n",
      "220/224, train_loss: 0.1171, step time: 0.3160\n",
      "221/224, train_loss: 0.2484, step time: 0.4105\n",
      "222/224, train_loss: 0.1127, step time: 0.3161\n",
      "223/224, train_loss: 0.2713, step time: 0.3702\n",
      "224/224, train_loss: 0.1605, step time: 0.3671\n",
      "epoch 37 average loss: 0.1988\n",
      "current epoch: 37 current mean dice: 0.6914 class1: 0.9993 class2: 0.7331 class3: 0.3417\n",
      "best mean dice: 0.6956 at epoch: 33\n",
      "time consuming of epoch 37 is: 750.5303\n",
      "hello\n",
      "----------\n",
      "epoch 38/100\n",
      "1/224, train_loss: 0.0856, step time: 0.3162\n",
      "2/224, train_loss: 0.1515, step time: 0.3167\n",
      "3/224, train_loss: 0.2825, step time: 0.3167\n",
      "4/224, train_loss: 0.2931, step time: 0.3917\n",
      "5/224, train_loss: 0.3545, step time: 0.3171\n",
      "6/224, train_loss: 0.0755, step time: 0.3149\n",
      "7/224, train_loss: 0.0776, step time: 0.3946\n",
      "8/224, train_loss: 0.1463, step time: 0.3142\n",
      "9/224, train_loss: 0.3359, step time: 0.3169\n",
      "10/224, train_loss: 0.2057, step time: 0.3167\n",
      "11/224, train_loss: 0.1261, step time: 0.3898\n",
      "12/224, train_loss: 0.0882, step time: 0.4023\n",
      "13/224, train_loss: 0.4274, step time: 0.4024\n",
      "14/224, train_loss: 0.2969, step time: 0.3169\n",
      "15/224, train_loss: 0.3400, step time: 0.3209\n",
      "16/224, train_loss: 0.4063, step time: 0.3153\n",
      "17/224, train_loss: 0.1097, step time: 0.3742\n",
      "18/224, train_loss: 0.2357, step time: 0.3858\n",
      "19/224, train_loss: 0.1797, step time: 0.4071\n",
      "20/224, train_loss: 0.2272, step time: 0.3822\n",
      "21/224, train_loss: 0.2142, step time: 0.3187\n",
      "22/224, train_loss: 0.0829, step time: 0.4018\n",
      "23/224, train_loss: 0.1476, step time: 0.3191\n",
      "24/224, train_loss: 0.1008, step time: 0.3156\n",
      "25/224, train_loss: 0.4205, step time: 0.3190\n",
      "26/224, train_loss: 0.1458, step time: 0.3164\n",
      "27/224, train_loss: 0.3263, step time: 0.3783\n",
      "28/224, train_loss: 0.1014, step time: 0.3157\n",
      "29/224, train_loss: 0.1543, step time: 0.3672\n",
      "30/224, train_loss: 0.1333, step time: 0.3189\n",
      "31/224, train_loss: 0.1677, step time: 0.3176\n",
      "32/224, train_loss: 0.2777, step time: 0.4051\n",
      "33/224, train_loss: 0.1376, step time: 0.3190\n",
      "34/224, train_loss: 0.2023, step time: 0.3781\n",
      "35/224, train_loss: 0.2497, step time: 0.3809\n",
      "36/224, train_loss: 0.1054, step time: 0.3179\n",
      "37/224, train_loss: 0.1948, step time: 0.3194\n",
      "38/224, train_loss: 0.1570, step time: 0.4086\n",
      "39/224, train_loss: 0.0969, step time: 0.3142\n",
      "40/224, train_loss: 0.1054, step time: 0.3172\n",
      "41/224, train_loss: 0.1857, step time: 0.3184\n",
      "42/224, train_loss: 0.0949, step time: 0.3163\n",
      "43/224, train_loss: 0.3352, step time: 0.3822\n",
      "44/224, train_loss: 0.3298, step time: 0.3178\n",
      "45/224, train_loss: 0.3425, step time: 0.3244\n",
      "46/224, train_loss: 0.3570, step time: 0.3867\n",
      "47/224, train_loss: 0.1931, step time: 0.3153\n",
      "48/224, train_loss: 0.2755, step time: 0.3167\n",
      "49/224, train_loss: 0.1107, step time: 0.3192\n",
      "50/224, train_loss: 0.1590, step time: 0.3198\n",
      "51/224, train_loss: 0.1498, step time: 0.3759\n",
      "52/224, train_loss: 0.3287, step time: 0.3973\n",
      "53/224, train_loss: 0.1312, step time: 0.4083\n",
      "54/224, train_loss: 0.1965, step time: 0.3990\n",
      "55/224, train_loss: 0.1664, step time: 0.3167\n",
      "56/224, train_loss: 0.1753, step time: 0.3784\n",
      "57/224, train_loss: 0.0905, step time: 0.3785\n",
      "58/224, train_loss: 0.1124, step time: 0.3170\n",
      "59/224, train_loss: 0.1025, step time: 0.3191\n",
      "60/224, train_loss: 0.1021, step time: 0.3166\n",
      "61/224, train_loss: 0.4078, step time: 0.3999\n",
      "62/224, train_loss: 0.1158, step time: 0.4011\n",
      "63/224, train_loss: 0.2181, step time: 0.3832\n",
      "64/224, train_loss: 0.2476, step time: 0.3164\n",
      "65/224, train_loss: 0.1316, step time: 0.3148\n",
      "66/224, train_loss: 0.1438, step time: 0.3178\n",
      "67/224, train_loss: 0.1898, step time: 0.3201\n",
      "68/224, train_loss: 0.2199, step time: 0.3154\n",
      "69/224, train_loss: 0.3536, step time: 0.3182\n",
      "70/224, train_loss: 0.1956, step time: 0.3863\n",
      "71/224, train_loss: 0.3133, step time: 0.3171\n",
      "72/224, train_loss: 0.3587, step time: 0.3831\n",
      "73/224, train_loss: 0.3744, step time: 0.4082\n",
      "74/224, train_loss: 0.2448, step time: 0.3171\n",
      "75/224, train_loss: 0.1744, step time: 0.3981\n",
      "76/224, train_loss: 0.3875, step time: 0.3852\n",
      "77/224, train_loss: 0.2106, step time: 0.3168\n",
      "78/224, train_loss: 0.1613, step time: 0.3167\n",
      "79/224, train_loss: 0.1396, step time: 0.3732\n",
      "80/224, train_loss: 0.2356, step time: 0.3196\n",
      "81/224, train_loss: 0.2885, step time: 0.3743\n",
      "82/224, train_loss: 0.0888, step time: 0.4003\n",
      "83/224, train_loss: 0.0834, step time: 0.3158\n",
      "84/224, train_loss: 0.0939, step time: 0.3134\n",
      "85/224, train_loss: 0.0733, step time: 0.3803\n",
      "86/224, train_loss: 0.1151, step time: 0.3186\n",
      "87/224, train_loss: 0.2908, step time: 0.3155\n",
      "88/224, train_loss: 0.1575, step time: 0.3181\n",
      "89/224, train_loss: 0.2031, step time: 0.3154\n",
      "90/224, train_loss: 0.1026, step time: 0.3739\n",
      "91/224, train_loss: 0.1291, step time: 0.3160\n",
      "92/224, train_loss: 0.3410, step time: 0.3165\n",
      "93/224, train_loss: 0.1538, step time: 0.3165\n",
      "94/224, train_loss: 0.1030, step time: 0.3190\n",
      "95/224, train_loss: 0.1945, step time: 0.3955\n",
      "96/224, train_loss: 0.1710, step time: 0.3685\n",
      "97/224, train_loss: 0.1345, step time: 0.3898\n",
      "98/224, train_loss: 0.1164, step time: 0.3164\n",
      "99/224, train_loss: 0.4074, step time: 0.3155\n",
      "100/224, train_loss: 0.1143, step time: 0.3154\n",
      "101/224, train_loss: 0.3854, step time: 0.3974\n",
      "102/224, train_loss: 0.1557, step time: 0.3186\n",
      "103/224, train_loss: 0.1576, step time: 0.3182\n",
      "104/224, train_loss: 0.1445, step time: 0.3152\n",
      "105/224, train_loss: 0.2543, step time: 0.3832\n",
      "106/224, train_loss: 0.0893, step time: 0.3131\n",
      "107/224, train_loss: 0.1059, step time: 0.3152\n",
      "108/224, train_loss: 0.2941, step time: 0.3684\n",
      "109/224, train_loss: 0.1694, step time: 0.3978\n",
      "110/224, train_loss: 0.1426, step time: 0.3175\n",
      "111/224, train_loss: 0.0713, step time: 0.3140\n",
      "112/224, train_loss: 0.1132, step time: 0.3143\n",
      "113/224, train_loss: 0.2013, step time: 0.3838\n",
      "114/224, train_loss: 0.1422, step time: 0.3174\n",
      "115/224, train_loss: 0.1296, step time: 0.3823\n",
      "116/224, train_loss: 0.1746, step time: 0.3153\n",
      "117/224, train_loss: 0.1743, step time: 0.3130\n",
      "118/224, train_loss: 0.1518, step time: 0.4052\n",
      "119/224, train_loss: 0.0905, step time: 0.3159\n",
      "120/224, train_loss: 0.2154, step time: 0.3932\n",
      "121/224, train_loss: 0.1288, step time: 0.3172\n",
      "122/224, train_loss: 0.4214, step time: 0.3735\n",
      "123/224, train_loss: 0.1178, step time: 0.3181\n",
      "124/224, train_loss: 0.1233, step time: 0.3154\n",
      "125/224, train_loss: 0.0890, step time: 0.3131\n",
      "126/224, train_loss: 0.4055, step time: 0.3929\n",
      "127/224, train_loss: 0.2017, step time: 0.3682\n",
      "128/224, train_loss: 0.0729, step time: 0.3158\n",
      "129/224, train_loss: 0.3174, step time: 0.3822\n",
      "130/224, train_loss: 0.2135, step time: 0.3803\n",
      "131/224, train_loss: 0.1637, step time: 0.3156\n",
      "132/224, train_loss: 0.1577, step time: 0.3181\n",
      "133/224, train_loss: 0.2068, step time: 0.3698\n",
      "134/224, train_loss: 0.2650, step time: 0.3856\n",
      "135/224, train_loss: 0.3723, step time: 0.3750\n",
      "136/224, train_loss: 0.1906, step time: 0.3715\n",
      "137/224, train_loss: 0.3825, step time: 0.4069\n",
      "138/224, train_loss: 0.1505, step time: 0.3975\n",
      "139/224, train_loss: 0.0823, step time: 0.3701\n",
      "140/224, train_loss: 0.1519, step time: 0.3896\n",
      "141/224, train_loss: 0.1520, step time: 0.3948\n",
      "142/224, train_loss: 0.1980, step time: 0.3781\n",
      "143/224, train_loss: 0.0872, step time: 0.3749\n",
      "144/224, train_loss: 0.2284, step time: 0.3754\n",
      "145/224, train_loss: 0.1086, step time: 0.3126\n",
      "146/224, train_loss: 0.1545, step time: 0.3988\n",
      "147/224, train_loss: 0.2628, step time: 0.3172\n",
      "148/224, train_loss: 0.2283, step time: 0.3625\n",
      "149/224, train_loss: 0.1683, step time: 0.3173\n",
      "150/224, train_loss: 0.3521, step time: 0.3920\n",
      "151/224, train_loss: 0.1851, step time: 0.3883\n",
      "152/224, train_loss: 0.1099, step time: 0.4070\n",
      "153/224, train_loss: 0.1291, step time: 0.3933\n",
      "154/224, train_loss: 0.1395, step time: 0.3149\n",
      "155/224, train_loss: 0.1025, step time: 0.4034\n",
      "156/224, train_loss: 0.0822, step time: 0.3676\n",
      "157/224, train_loss: 0.4516, step time: 0.3871\n",
      "158/224, train_loss: 0.2758, step time: 0.3778\n",
      "159/224, train_loss: 0.0868, step time: 0.3156\n",
      "160/224, train_loss: 0.1967, step time: 0.3674\n",
      "161/224, train_loss: 0.1046, step time: 0.3179\n",
      "162/224, train_loss: 0.2226, step time: 0.3723\n",
      "163/224, train_loss: 0.2417, step time: 0.3867\n",
      "164/224, train_loss: 0.3643, step time: 0.4017\n",
      "165/224, train_loss: 0.3705, step time: 0.3161\n",
      "166/224, train_loss: 0.2174, step time: 0.4076\n",
      "167/224, train_loss: 0.0927, step time: 0.3180\n",
      "168/224, train_loss: 0.1631, step time: 0.3154\n",
      "169/224, train_loss: 0.1222, step time: 0.3167\n",
      "170/224, train_loss: 0.1748, step time: 0.3155\n",
      "171/224, train_loss: 0.2104, step time: 0.3178\n",
      "172/224, train_loss: 0.1676, step time: 0.3151\n",
      "173/224, train_loss: 0.1585, step time: 0.3179\n",
      "174/224, train_loss: 0.3725, step time: 0.3672\n",
      "175/224, train_loss: 0.1635, step time: 0.4115\n",
      "176/224, train_loss: 0.1109, step time: 0.3175\n",
      "177/224, train_loss: 0.2171, step time: 0.3151\n",
      "178/224, train_loss: 0.1666, step time: 0.3984\n",
      "179/224, train_loss: 0.1195, step time: 0.3790\n",
      "180/224, train_loss: 0.0947, step time: 0.4010\n",
      "181/224, train_loss: 0.1537, step time: 0.3160\n",
      "182/224, train_loss: 0.1581, step time: 0.4005\n",
      "183/224, train_loss: 0.3481, step time: 0.3155\n",
      "184/224, train_loss: 0.1018, step time: 0.4023\n",
      "185/224, train_loss: 0.1339, step time: 0.3165\n",
      "186/224, train_loss: 0.1609, step time: 0.4001\n",
      "187/224, train_loss: 0.1030, step time: 0.3180\n",
      "188/224, train_loss: 0.1829, step time: 0.3175\n",
      "189/224, train_loss: 0.0944, step time: 0.3156\n",
      "190/224, train_loss: 0.1244, step time: 0.3183\n",
      "191/224, train_loss: 0.1286, step time: 0.3173\n",
      "192/224, train_loss: 0.1283, step time: 0.4117\n",
      "193/224, train_loss: 0.1187, step time: 0.4027\n",
      "194/224, train_loss: 0.1504, step time: 0.4000\n",
      "195/224, train_loss: 0.3731, step time: 0.3990\n",
      "196/224, train_loss: 0.1668, step time: 0.3143\n",
      "197/224, train_loss: 0.1812, step time: 0.3835\n",
      "198/224, train_loss: 0.2174, step time: 0.3158\n",
      "199/224, train_loss: 0.1244, step time: 0.3695\n",
      "200/224, train_loss: 0.1822, step time: 0.3180\n",
      "201/224, train_loss: 0.0929, step time: 0.3844\n",
      "202/224, train_loss: 0.3344, step time: 0.3161\n",
      "203/224, train_loss: 0.2676, step time: 0.3884\n",
      "204/224, train_loss: 0.0913, step time: 0.3189\n",
      "205/224, train_loss: 0.3389, step time: 0.3796\n",
      "206/224, train_loss: 0.0669, step time: 0.3162\n",
      "207/224, train_loss: 0.2692, step time: 0.3163\n",
      "208/224, train_loss: 0.2158, step time: 0.3140\n",
      "209/224, train_loss: 0.1061, step time: 0.3665\n",
      "210/224, train_loss: 0.0908, step time: 0.3180\n",
      "211/224, train_loss: 0.1526, step time: 0.3161\n",
      "212/224, train_loss: 0.2129, step time: 0.3140\n",
      "213/224, train_loss: 0.0684, step time: 0.3175\n",
      "214/224, train_loss: 0.1261, step time: 0.3156\n",
      "215/224, train_loss: 0.2591, step time: 0.3132\n",
      "216/224, train_loss: 0.2007, step time: 0.3657\n",
      "217/224, train_loss: 0.1595, step time: 0.3137\n",
      "218/224, train_loss: 0.2179, step time: 0.4076\n",
      "219/224, train_loss: 0.1646, step time: 0.3162\n",
      "220/224, train_loss: 0.0655, step time: 0.3845\n",
      "221/224, train_loss: 0.2852, step time: 0.3899\n",
      "222/224, train_loss: 0.1568, step time: 0.3180\n",
      "223/224, train_loss: 0.2518, step time: 0.3157\n",
      "224/224, train_loss: 0.3319, step time: 0.3133\n",
      "epoch 38 average loss: 0.1923\n",
      "current epoch: 38 current mean dice: 0.7003 class1: 0.9993 class2: 0.7360 class3: 0.3655\n",
      "best mean dice: 0.7003 at epoch: 38\n",
      "time consuming of epoch 38 is: 645.1233\n",
      "hello\n",
      "----------\n",
      "epoch 39/100\n",
      "1/224, train_loss: 0.1066, step time: 0.3160\n",
      "2/224, train_loss: 0.1327, step time: 0.3185\n",
      "3/224, train_loss: 0.2555, step time: 0.3861\n",
      "4/224, train_loss: 0.2008, step time: 0.3188\n",
      "5/224, train_loss: 0.1682, step time: 0.3860\n",
      "6/224, train_loss: 0.1300, step time: 0.3188\n",
      "7/224, train_loss: 0.2211, step time: 0.3158\n",
      "8/224, train_loss: 0.0901, step time: 0.3180\n",
      "9/224, train_loss: 0.2728, step time: 0.3769\n",
      "10/224, train_loss: 0.2597, step time: 0.3664\n",
      "11/224, train_loss: 0.1068, step time: 0.4117\n",
      "12/224, train_loss: 0.0715, step time: 0.3163\n",
      "13/224, train_loss: 0.1989, step time: 0.3144\n",
      "14/224, train_loss: 0.2272, step time: 0.3142\n",
      "15/224, train_loss: 0.3338, step time: 0.3157\n",
      "16/224, train_loss: 0.1070, step time: 0.3177\n",
      "17/224, train_loss: 0.1918, step time: 0.4120\n",
      "18/224, train_loss: 0.2370, step time: 0.3901\n",
      "19/224, train_loss: 0.3863, step time: 0.3701\n",
      "20/224, train_loss: 0.1678, step time: 0.4025\n",
      "21/224, train_loss: 0.3164, step time: 0.3159\n",
      "22/224, train_loss: 0.3856, step time: 0.4135\n",
      "23/224, train_loss: 0.3590, step time: 0.3766\n",
      "24/224, train_loss: 0.3588, step time: 0.3737\n",
      "25/224, train_loss: 0.1159, step time: 0.3166\n",
      "26/224, train_loss: 0.0736, step time: 0.4049\n",
      "27/224, train_loss: 0.1088, step time: 0.3824\n",
      "28/224, train_loss: 0.3677, step time: 0.3741\n",
      "29/224, train_loss: 0.0982, step time: 0.3995\n",
      "30/224, train_loss: 0.2293, step time: 0.4034\n",
      "31/224, train_loss: 0.1744, step time: 0.3185\n",
      "32/224, train_loss: 0.3907, step time: 0.4064\n",
      "33/224, train_loss: 0.1218, step time: 0.3172\n",
      "34/224, train_loss: 0.1222, step time: 0.3134\n",
      "35/224, train_loss: 0.2793, step time: 0.3159\n",
      "36/224, train_loss: 0.3296, step time: 0.3830\n",
      "37/224, train_loss: 0.0746, step time: 0.3177\n",
      "38/224, train_loss: 0.1125, step time: 0.3674\n",
      "39/224, train_loss: 0.2943, step time: 0.3151\n",
      "40/224, train_loss: 0.1968, step time: 0.3971\n",
      "41/224, train_loss: 0.2253, step time: 0.3683\n",
      "42/224, train_loss: 0.3490, step time: 0.4047\n",
      "43/224, train_loss: 0.1373, step time: 0.3153\n",
      "44/224, train_loss: 0.1356, step time: 0.3175\n",
      "45/224, train_loss: 0.2888, step time: 0.3827\n",
      "46/224, train_loss: 0.1529, step time: 0.3178\n",
      "47/224, train_loss: 0.1044, step time: 0.3134\n",
      "48/224, train_loss: 0.2425, step time: 0.3784\n",
      "49/224, train_loss: 0.0733, step time: 0.3191\n",
      "50/224, train_loss: 0.1796, step time: 0.3904\n",
      "51/224, train_loss: 0.1683, step time: 0.4096\n",
      "52/224, train_loss: 0.1519, step time: 0.3219\n",
      "53/224, train_loss: 0.1416, step time: 0.3164\n",
      "54/224, train_loss: 0.1355, step time: 0.3748\n",
      "55/224, train_loss: 0.1443, step time: 0.3159\n",
      "56/224, train_loss: 0.3863, step time: 0.3139\n",
      "57/224, train_loss: 0.3368, step time: 0.3156\n",
      "58/224, train_loss: 0.1382, step time: 0.3152\n",
      "59/224, train_loss: 0.1645, step time: 0.3152\n",
      "60/224, train_loss: 0.1087, step time: 0.3765\n",
      "61/224, train_loss: 0.1176, step time: 0.3162\n",
      "62/224, train_loss: 0.0910, step time: 0.3679\n",
      "63/224, train_loss: 0.1303, step time: 0.3817\n",
      "64/224, train_loss: 0.0976, step time: 0.3133\n",
      "65/224, train_loss: 0.1237, step time: 0.3175\n",
      "66/224, train_loss: 0.3640, step time: 0.3871\n",
      "67/224, train_loss: 0.2995, step time: 0.3139\n",
      "68/224, train_loss: 0.1077, step time: 0.3162\n",
      "69/224, train_loss: 0.1325, step time: 0.3180\n",
      "70/224, train_loss: 0.1363, step time: 0.3156\n",
      "71/224, train_loss: 0.1001, step time: 0.3925\n",
      "72/224, train_loss: 0.1072, step time: 0.4096\n",
      "73/224, train_loss: 0.0628, step time: 0.3979\n",
      "74/224, train_loss: 0.0931, step time: 0.3943\n",
      "75/224, train_loss: 0.2268, step time: 0.3840\n",
      "76/224, train_loss: 0.2758, step time: 0.3746\n",
      "77/224, train_loss: 0.1708, step time: 0.4046\n",
      "78/224, train_loss: 0.0649, step time: 0.4020\n",
      "79/224, train_loss: 0.1613, step time: 0.3155\n",
      "80/224, train_loss: 0.1504, step time: 0.3153\n",
      "81/224, train_loss: 0.1860, step time: 0.3176\n",
      "82/224, train_loss: 0.2518, step time: 0.4100\n",
      "83/224, train_loss: 0.0823, step time: 0.4082\n",
      "84/224, train_loss: 0.1564, step time: 0.3721\n",
      "85/224, train_loss: 0.1807, step time: 0.3138\n",
      "86/224, train_loss: 0.4070, step time: 0.3965\n",
      "87/224, train_loss: 0.0704, step time: 0.4007\n",
      "88/224, train_loss: 0.3929, step time: 0.3171\n",
      "89/224, train_loss: 0.0619, step time: 0.3146\n",
      "90/224, train_loss: 0.0928, step time: 0.3765\n",
      "91/224, train_loss: 0.2605, step time: 0.3149\n",
      "92/224, train_loss: 0.0978, step time: 0.3899\n",
      "93/224, train_loss: 0.1249, step time: 0.3884\n",
      "94/224, train_loss: 0.2218, step time: 0.3852\n",
      "95/224, train_loss: 0.3345, step time: 0.3144\n",
      "96/224, train_loss: 0.3584, step time: 0.3786\n",
      "97/224, train_loss: 0.1317, step time: 0.3152\n",
      "98/224, train_loss: 0.3634, step time: 0.4073\n",
      "99/224, train_loss: 0.3680, step time: 0.3844\n",
      "100/224, train_loss: 0.1845, step time: 0.3153\n",
      "101/224, train_loss: 0.1401, step time: 0.3159\n",
      "102/224, train_loss: 0.2318, step time: 0.3921\n",
      "103/224, train_loss: 0.1371, step time: 0.3159\n",
      "104/224, train_loss: 0.1911, step time: 0.3987\n",
      "105/224, train_loss: 0.1335, step time: 0.3157\n",
      "106/224, train_loss: 0.0995, step time: 0.4063\n",
      "107/224, train_loss: 0.2052, step time: 0.3773\n",
      "108/224, train_loss: 0.1312, step time: 0.3181\n",
      "109/224, train_loss: 0.1014, step time: 0.3157\n",
      "110/224, train_loss: 0.1514, step time: 0.3183\n",
      "111/224, train_loss: 0.0969, step time: 0.3159\n",
      "112/224, train_loss: 0.1434, step time: 0.3785\n",
      "113/224, train_loss: 0.1536, step time: 0.3758\n",
      "114/224, train_loss: 0.1275, step time: 0.3164\n",
      "115/224, train_loss: 0.1883, step time: 0.4084\n",
      "116/224, train_loss: 0.1190, step time: 0.3743\n",
      "117/224, train_loss: 0.2314, step time: 0.3677\n",
      "118/224, train_loss: 0.1498, step time: 0.4026\n",
      "119/224, train_loss: 0.1079, step time: 0.3181\n",
      "120/224, train_loss: 0.2872, step time: 0.3164\n",
      "121/224, train_loss: 0.1558, step time: 0.3180\n",
      "122/224, train_loss: 0.4018, step time: 0.3758\n",
      "123/224, train_loss: 0.2297, step time: 0.3904\n",
      "124/224, train_loss: 0.2537, step time: 0.3152\n",
      "125/224, train_loss: 0.1170, step time: 0.3131\n",
      "126/224, train_loss: 0.1227, step time: 0.4085\n",
      "127/224, train_loss: 0.1652, step time: 0.3917\n",
      "128/224, train_loss: 0.4405, step time: 0.3729\n",
      "129/224, train_loss: 0.1055, step time: 0.3155\n",
      "130/224, train_loss: 0.1594, step time: 0.3132\n",
      "131/224, train_loss: 0.1293, step time: 0.3151\n",
      "132/224, train_loss: 0.1433, step time: 0.3150\n",
      "133/224, train_loss: 0.1809, step time: 0.3916\n",
      "134/224, train_loss: 0.0628, step time: 0.3993\n",
      "135/224, train_loss: 0.1539, step time: 0.3174\n",
      "136/224, train_loss: 0.1993, step time: 0.3159\n",
      "137/224, train_loss: 0.1673, step time: 0.3742\n",
      "138/224, train_loss: 0.1953, step time: 0.3160\n",
      "139/224, train_loss: 0.1933, step time: 0.3997\n",
      "140/224, train_loss: 0.3976, step time: 0.3986\n",
      "141/224, train_loss: 0.1207, step time: 0.3872\n",
      "142/224, train_loss: 0.0835, step time: 0.3819\n",
      "143/224, train_loss: 0.3202, step time: 0.4018\n",
      "144/224, train_loss: 0.1187, step time: 0.3153\n",
      "145/224, train_loss: 0.0820, step time: 0.3997\n",
      "146/224, train_loss: 0.0876, step time: 0.3159\n",
      "147/224, train_loss: 0.2540, step time: 0.4079\n",
      "148/224, train_loss: 0.1967, step time: 0.4063\n",
      "149/224, train_loss: 0.1477, step time: 0.3172\n",
      "150/224, train_loss: 0.2234, step time: 0.3160\n",
      "151/224, train_loss: 0.0906, step time: 0.4062\n",
      "152/224, train_loss: 0.2352, step time: 0.3158\n",
      "153/224, train_loss: 0.1893, step time: 0.3175\n",
      "154/224, train_loss: 0.2797, step time: 0.3961\n",
      "155/224, train_loss: 0.2592, step time: 0.4004\n",
      "156/224, train_loss: 0.3761, step time: 0.3174\n",
      "157/224, train_loss: 0.1521, step time: 0.3173\n",
      "158/224, train_loss: 0.3763, step time: 0.3805\n",
      "159/224, train_loss: 0.1570, step time: 0.3726\n",
      "160/224, train_loss: 0.2123, step time: 0.3155\n",
      "161/224, train_loss: 0.0601, step time: 0.3157\n",
      "162/224, train_loss: 0.2025, step time: 0.4036\n",
      "163/224, train_loss: 0.1116, step time: 0.3135\n",
      "164/224, train_loss: 0.1945, step time: 0.3950\n",
      "165/224, train_loss: 0.1701, step time: 0.3151\n",
      "166/224, train_loss: 0.3090, step time: 0.3176\n",
      "167/224, train_loss: 0.1398, step time: 0.4014\n",
      "168/224, train_loss: 0.2139, step time: 0.3161\n",
      "169/224, train_loss: 0.1322, step time: 0.3727\n",
      "170/224, train_loss: 0.2213, step time: 0.4073\n",
      "171/224, train_loss: 0.1908, step time: 0.3182\n",
      "172/224, train_loss: 0.0877, step time: 0.3141\n",
      "173/224, train_loss: 0.1018, step time: 0.3140\n",
      "174/224, train_loss: 0.2562, step time: 0.4128\n",
      "175/224, train_loss: 0.2106, step time: 0.3188\n",
      "176/224, train_loss: 0.1580, step time: 0.3904\n",
      "177/224, train_loss: 0.2921, step time: 0.3135\n",
      "178/224, train_loss: 0.1081, step time: 0.3882\n",
      "179/224, train_loss: 0.1719, step time: 0.3151\n",
      "180/224, train_loss: 0.1569, step time: 0.3160\n",
      "181/224, train_loss: 0.1394, step time: 0.3995\n",
      "182/224, train_loss: 0.3288, step time: 0.4024\n",
      "183/224, train_loss: 0.1831, step time: 0.3944\n",
      "184/224, train_loss: 0.2706, step time: 0.3862\n",
      "185/224, train_loss: 0.0860, step time: 0.3150\n",
      "186/224, train_loss: 0.0983, step time: 0.3130\n",
      "187/224, train_loss: 0.2469, step time: 0.3668\n",
      "188/224, train_loss: 0.2187, step time: 0.3779\n",
      "189/224, train_loss: 0.1313, step time: 0.3690\n",
      "190/224, train_loss: 0.1678, step time: 0.3919\n",
      "191/224, train_loss: 0.0904, step time: 0.3139\n",
      "192/224, train_loss: 0.1277, step time: 0.4020\n",
      "193/224, train_loss: 0.0910, step time: 0.3138\n",
      "194/224, train_loss: 0.1769, step time: 0.3156\n",
      "195/224, train_loss: 0.1250, step time: 0.3160\n",
      "196/224, train_loss: 0.2205, step time: 0.3882\n",
      "197/224, train_loss: 0.2319, step time: 0.3659\n",
      "198/224, train_loss: 0.1480, step time: 0.3173\n",
      "199/224, train_loss: 0.3684, step time: 0.3135\n",
      "200/224, train_loss: 0.0908, step time: 0.3165\n",
      "201/224, train_loss: 0.1137, step time: 0.4005\n",
      "202/224, train_loss: 0.1347, step time: 0.3161\n",
      "203/224, train_loss: 0.1182, step time: 0.3164\n",
      "204/224, train_loss: 0.1777, step time: 0.3144\n",
      "205/224, train_loss: 0.4037, step time: 0.4044\n",
      "206/224, train_loss: 0.4084, step time: 0.3904\n",
      "207/224, train_loss: 0.0897, step time: 0.3138\n",
      "208/224, train_loss: 0.2286, step time: 0.3965\n",
      "209/224, train_loss: 0.0674, step time: 0.4064\n",
      "210/224, train_loss: 0.1385, step time: 0.3179\n",
      "211/224, train_loss: 0.3036, step time: 0.3138\n",
      "212/224, train_loss: 0.3710, step time: 0.3162\n",
      "213/224, train_loss: 0.1470, step time: 0.3171\n",
      "214/224, train_loss: 0.1290, step time: 0.3162\n",
      "215/224, train_loss: 0.1231, step time: 0.4026\n",
      "216/224, train_loss: 0.2579, step time: 0.4099\n",
      "217/224, train_loss: 0.1255, step time: 0.3153\n",
      "218/224, train_loss: 0.1800, step time: 0.3177\n",
      "219/224, train_loss: 0.1328, step time: 0.3163\n",
      "220/224, train_loss: 0.1445, step time: 0.3903\n",
      "221/224, train_loss: 0.4218, step time: 0.3943\n",
      "222/224, train_loss: 0.0780, step time: 0.3146\n",
      "223/224, train_loss: 0.1394, step time: 0.4105\n",
      "224/224, train_loss: 0.1162, step time: 0.3140\n",
      "epoch 39 average loss: 0.1881\n",
      "current epoch: 39 current mean dice: 0.6921 class1: 0.9992 class2: 0.6971 class3: 0.3799\n",
      "best mean dice: 0.7003 at epoch: 38\n",
      "time consuming of epoch 39 is: 757.1282\n",
      "hello\n",
      "----------\n",
      "epoch 40/100\n",
      "1/224, train_loss: 0.1653, step time: 0.3837\n",
      "2/224, train_loss: 0.1772, step time: 0.3934\n",
      "3/224, train_loss: 0.0975, step time: 0.3146\n",
      "4/224, train_loss: 0.2336, step time: 0.3967\n",
      "5/224, train_loss: 0.0687, step time: 0.3163\n",
      "6/224, train_loss: 0.1953, step time: 0.3831\n",
      "7/224, train_loss: 0.1105, step time: 0.3167\n",
      "8/224, train_loss: 0.0905, step time: 0.4075\n",
      "9/224, train_loss: 0.3327, step time: 0.3875\n",
      "10/224, train_loss: 0.1953, step time: 0.4114\n",
      "11/224, train_loss: 0.1919, step time: 0.4003\n",
      "12/224, train_loss: 0.1757, step time: 0.3985\n",
      "13/224, train_loss: 0.1484, step time: 0.4100\n",
      "14/224, train_loss: 0.1471, step time: 0.4090\n",
      "15/224, train_loss: 0.1068, step time: 0.3176\n",
      "16/224, train_loss: 0.1401, step time: 0.3185\n",
      "17/224, train_loss: 0.1721, step time: 0.3181\n",
      "18/224, train_loss: 0.0973, step time: 0.3176\n",
      "19/224, train_loss: 0.1279, step time: 0.3150\n",
      "20/224, train_loss: 0.2253, step time: 0.4114\n",
      "21/224, train_loss: 0.3556, step time: 0.3179\n",
      "22/224, train_loss: 0.2611, step time: 0.3142\n",
      "23/224, train_loss: 0.0764, step time: 0.3181\n",
      "24/224, train_loss: 0.1924, step time: 0.3892\n",
      "25/224, train_loss: 0.1120, step time: 0.4105\n",
      "26/224, train_loss: 0.0926, step time: 0.3129\n",
      "27/224, train_loss: 0.1062, step time: 0.3134\n",
      "28/224, train_loss: 0.2252, step time: 0.3182\n",
      "29/224, train_loss: 0.2380, step time: 0.3185\n",
      "30/224, train_loss: 0.1465, step time: 0.3151\n",
      "31/224, train_loss: 0.1227, step time: 0.3753\n",
      "32/224, train_loss: 0.2177, step time: 0.3177\n",
      "33/224, train_loss: 0.1872, step time: 0.3869\n",
      "34/224, train_loss: 0.1028, step time: 0.3132\n",
      "35/224, train_loss: 0.3086, step time: 0.3828\n",
      "36/224, train_loss: 0.3663, step time: 0.3846\n",
      "37/224, train_loss: 0.4409, step time: 0.3832\n",
      "38/224, train_loss: 0.1745, step time: 0.3982\n",
      "39/224, train_loss: 0.1945, step time: 0.3156\n",
      "40/224, train_loss: 0.2145, step time: 0.3682\n",
      "41/224, train_loss: 0.2551, step time: 0.3881\n",
      "42/224, train_loss: 0.0834, step time: 0.3862\n",
      "43/224, train_loss: 0.3031, step time: 0.3741\n",
      "44/224, train_loss: 0.1377, step time: 0.3940\n",
      "45/224, train_loss: 0.1206, step time: 0.3173\n",
      "46/224, train_loss: 0.2594, step time: 0.3151\n",
      "47/224, train_loss: 0.0936, step time: 0.3769\n",
      "48/224, train_loss: 0.3789, step time: 0.3176\n",
      "49/224, train_loss: 0.3268, step time: 0.3666\n",
      "50/224, train_loss: 0.1319, step time: 0.3152\n",
      "51/224, train_loss: 0.1074, step time: 0.3953\n",
      "52/224, train_loss: 0.0910, step time: 0.3158\n",
      "53/224, train_loss: 0.2651, step time: 0.3807\n",
      "54/224, train_loss: 0.1228, step time: 0.3700\n",
      "55/224, train_loss: 0.1385, step time: 0.3760\n",
      "56/224, train_loss: 0.1093, step time: 0.3158\n",
      "57/224, train_loss: 0.1134, step time: 0.3143\n",
      "58/224, train_loss: 0.1091, step time: 0.3141\n",
      "59/224, train_loss: 0.1547, step time: 0.3142\n",
      "60/224, train_loss: 0.1117, step time: 0.3144\n",
      "61/224, train_loss: 0.3064, step time: 0.3156\n",
      "62/224, train_loss: 0.1829, step time: 0.3871\n",
      "63/224, train_loss: 0.0873, step time: 0.3141\n",
      "64/224, train_loss: 0.0683, step time: 0.3943\n",
      "65/224, train_loss: 0.1920, step time: 0.3149\n",
      "66/224, train_loss: 0.2891, step time: 0.3168\n",
      "67/224, train_loss: 0.2962, step time: 0.3123\n",
      "68/224, train_loss: 0.3888, step time: 0.3653\n",
      "69/224, train_loss: 0.1470, step time: 0.3709\n",
      "70/224, train_loss: 0.1898, step time: 0.4019\n",
      "71/224, train_loss: 0.1355, step time: 0.3163\n",
      "72/224, train_loss: 0.1302, step time: 0.3139\n",
      "73/224, train_loss: 0.0729, step time: 0.4034\n",
      "74/224, train_loss: 0.1998, step time: 0.3150\n",
      "75/224, train_loss: 0.0972, step time: 0.3755\n",
      "76/224, train_loss: 0.1209, step time: 0.3145\n",
      "77/224, train_loss: 0.1852, step time: 0.3683\n",
      "78/224, train_loss: 0.1354, step time: 0.3152\n",
      "79/224, train_loss: 0.1527, step time: 0.3808\n",
      "80/224, train_loss: 0.1093, step time: 0.3144\n",
      "81/224, train_loss: 0.1742, step time: 0.3126\n",
      "82/224, train_loss: 0.2960, step time: 0.3828\n",
      "83/224, train_loss: 0.1566, step time: 0.3124\n",
      "84/224, train_loss: 0.1204, step time: 0.3968\n",
      "85/224, train_loss: 0.1576, step time: 0.3930\n",
      "86/224, train_loss: 0.1080, step time: 0.4032\n",
      "87/224, train_loss: 0.2341, step time: 0.3719\n",
      "88/224, train_loss: 0.2560, step time: 0.3788\n",
      "89/224, train_loss: 0.1376, step time: 0.3121\n",
      "90/224, train_loss: 0.1486, step time: 0.3898\n",
      "91/224, train_loss: 0.1445, step time: 0.3149\n",
      "92/224, train_loss: 0.1648, step time: 0.3169\n",
      "93/224, train_loss: 0.0929, step time: 0.3888\n",
      "94/224, train_loss: 0.1664, step time: 0.3169\n",
      "95/224, train_loss: 0.2753, step time: 0.3461\n",
      "96/224, train_loss: 0.1048, step time: 0.3743\n",
      "97/224, train_loss: 0.1002, step time: 0.3133\n",
      "98/224, train_loss: 0.1404, step time: 0.3700\n",
      "99/224, train_loss: 0.3979, step time: 0.3178\n",
      "100/224, train_loss: 0.2715, step time: 0.4043\n",
      "101/224, train_loss: 0.2047, step time: 0.3179\n",
      "102/224, train_loss: 0.1729, step time: 0.4026\n",
      "103/224, train_loss: 0.0958, step time: 0.3152\n",
      "104/224, train_loss: 0.0915, step time: 0.3152\n",
      "105/224, train_loss: 0.1775, step time: 0.3980\n",
      "106/224, train_loss: 0.2572, step time: 0.3153\n",
      "107/224, train_loss: 0.1524, step time: 0.4116\n",
      "108/224, train_loss: 0.1603, step time: 0.4059\n",
      "109/224, train_loss: 0.3687, step time: 0.4067\n",
      "110/224, train_loss: 0.3029, step time: 0.3184\n",
      "111/224, train_loss: 0.1203, step time: 0.3135\n",
      "112/224, train_loss: 0.2039, step time: 0.3670\n",
      "113/224, train_loss: 0.3302, step time: 0.4108\n",
      "114/224, train_loss: 0.0811, step time: 0.3150\n",
      "115/224, train_loss: 0.2693, step time: 0.3152\n",
      "116/224, train_loss: 0.1267, step time: 0.3151\n",
      "117/224, train_loss: 0.1686, step time: 0.3706\n",
      "118/224, train_loss: 0.1791, step time: 0.3675\n",
      "119/224, train_loss: 0.0806, step time: 0.3181\n",
      "120/224, train_loss: 0.0912, step time: 0.3154\n",
      "121/224, train_loss: 0.1756, step time: 0.3690\n",
      "122/224, train_loss: 0.2850, step time: 0.3156\n",
      "123/224, train_loss: 0.1624, step time: 0.3148\n",
      "124/224, train_loss: 0.3304, step time: 0.3804\n",
      "125/224, train_loss: 0.0852, step time: 0.4037\n",
      "126/224, train_loss: 0.1381, step time: 0.3712\n",
      "127/224, train_loss: 0.1804, step time: 0.4059\n",
      "128/224, train_loss: 0.0940, step time: 0.3686\n",
      "129/224, train_loss: 0.1316, step time: 0.3177\n",
      "130/224, train_loss: 0.2357, step time: 0.3174\n",
      "131/224, train_loss: 0.3587, step time: 0.3177\n",
      "132/224, train_loss: 0.2081, step time: 0.4112\n",
      "133/224, train_loss: 0.3743, step time: 0.3153\n",
      "134/224, train_loss: 0.1678, step time: 0.3181\n",
      "135/224, train_loss: 0.1638, step time: 0.3155\n",
      "136/224, train_loss: 0.1177, step time: 0.3140\n",
      "137/224, train_loss: 0.1748, step time: 0.4092\n",
      "138/224, train_loss: 0.2126, step time: 0.3148\n",
      "139/224, train_loss: 0.1721, step time: 0.3893\n",
      "140/224, train_loss: 0.1400, step time: 0.3809\n",
      "141/224, train_loss: 0.2028, step time: 0.3890\n",
      "142/224, train_loss: 0.1232, step time: 0.3160\n",
      "143/224, train_loss: 0.1784, step time: 0.3159\n",
      "144/224, train_loss: 0.3338, step time: 0.3133\n",
      "145/224, train_loss: 0.1522, step time: 0.3131\n",
      "146/224, train_loss: 0.1895, step time: 0.3149\n",
      "147/224, train_loss: 0.1428, step time: 0.3174\n",
      "148/224, train_loss: 0.1160, step time: 0.3153\n",
      "149/224, train_loss: 0.3007, step time: 0.3742\n",
      "150/224, train_loss: 0.1116, step time: 0.3153\n",
      "151/224, train_loss: 0.0793, step time: 0.3180\n",
      "152/224, train_loss: 0.3397, step time: 0.3940\n",
      "153/224, train_loss: 0.2474, step time: 0.3179\n",
      "154/224, train_loss: 0.3380, step time: 0.3929\n",
      "155/224, train_loss: 0.1490, step time: 0.3163\n",
      "156/224, train_loss: 0.1229, step time: 0.3156\n",
      "157/224, train_loss: 0.1855, step time: 0.3848\n",
      "158/224, train_loss: 0.1182, step time: 0.3175\n",
      "159/224, train_loss: 0.2233, step time: 0.3711\n",
      "160/224, train_loss: 0.0717, step time: 0.4003\n",
      "161/224, train_loss: 0.1665, step time: 0.3182\n",
      "162/224, train_loss: 0.2297, step time: 0.3184\n",
      "163/224, train_loss: 0.1956, step time: 0.4001\n",
      "164/224, train_loss: 0.1035, step time: 0.3752\n",
      "165/224, train_loss: 0.1829, step time: 0.3990\n",
      "166/224, train_loss: 0.0918, step time: 0.3156\n",
      "167/224, train_loss: 0.1541, step time: 0.3971\n",
      "168/224, train_loss: 0.2684, step time: 0.3156\n",
      "169/224, train_loss: 0.1996, step time: 0.3155\n",
      "170/224, train_loss: 0.1550, step time: 0.3176\n",
      "171/224, train_loss: 0.1145, step time: 0.3178\n",
      "172/224, train_loss: 0.0995, step time: 0.3178\n",
      "173/224, train_loss: 0.5023, step time: 0.3964\n",
      "174/224, train_loss: 0.1628, step time: 0.3174\n",
      "175/224, train_loss: 0.3477, step time: 0.3143\n",
      "176/224, train_loss: 0.0738, step time: 0.3151\n",
      "177/224, train_loss: 0.1494, step time: 0.3998\n",
      "178/224, train_loss: 0.1543, step time: 0.3151\n",
      "179/224, train_loss: 0.1464, step time: 0.3186\n",
      "180/224, train_loss: 0.0968, step time: 0.3168\n",
      "181/224, train_loss: 0.4883, step time: 0.3158\n",
      "182/224, train_loss: 0.1203, step time: 0.3152\n",
      "183/224, train_loss: 0.4346, step time: 0.3974\n",
      "184/224, train_loss: 0.1529, step time: 0.3151\n",
      "185/224, train_loss: 0.1080, step time: 0.3174\n",
      "186/224, train_loss: 0.4628, step time: 0.3735\n",
      "187/224, train_loss: 0.2597, step time: 0.3980\n",
      "188/224, train_loss: 0.1918, step time: 0.4017\n",
      "189/224, train_loss: 0.0701, step time: 0.3895\n",
      "190/224, train_loss: 0.1070, step time: 0.3804\n",
      "191/224, train_loss: 0.1090, step time: 0.3202\n",
      "192/224, train_loss: 0.1482, step time: 0.3188\n",
      "193/224, train_loss: 0.1413, step time: 0.3169\n",
      "194/224, train_loss: 0.2667, step time: 0.3787\n",
      "195/224, train_loss: 0.1073, step time: 0.3196\n",
      "196/224, train_loss: 0.1497, step time: 0.4124\n",
      "197/224, train_loss: 0.3077, step time: 0.3432\n",
      "198/224, train_loss: 0.2027, step time: 0.3366\n",
      "199/224, train_loss: 0.1047, step time: 0.3238\n",
      "200/224, train_loss: 0.1102, step time: 0.3210\n",
      "201/224, train_loss: 0.3697, step time: 0.4198\n",
      "202/224, train_loss: 0.0781, step time: 0.3234\n",
      "203/224, train_loss: 0.1545, step time: 0.4137\n",
      "204/224, train_loss: 0.1588, step time: 0.3228\n",
      "205/224, train_loss: 0.1960, step time: 0.3232\n",
      "206/224, train_loss: 0.1200, step time: 0.3242\n",
      "207/224, train_loss: 0.3255, step time: 0.4161\n",
      "208/224, train_loss: 0.1608, step time: 0.3746\n",
      "209/224, train_loss: 0.2176, step time: 0.4266\n",
      "210/224, train_loss: 0.0776, step time: 0.3284\n",
      "211/224, train_loss: 0.1404, step time: 0.4213\n",
      "212/224, train_loss: 0.1000, step time: 0.3278\n",
      "213/224, train_loss: 0.1334, step time: 0.4139\n",
      "214/224, train_loss: 0.3477, step time: 0.3221\n",
      "215/224, train_loss: 0.3790, step time: 0.3224\n",
      "216/224, train_loss: 0.1696, step time: 0.3199\n",
      "217/224, train_loss: 0.0948, step time: 0.3215\n",
      "218/224, train_loss: 0.1388, step time: 0.4067\n",
      "219/224, train_loss: 0.2480, step time: 0.3978\n",
      "220/224, train_loss: 0.4295, step time: 0.3828\n",
      "221/224, train_loss: 0.2257, step time: 0.4119\n",
      "222/224, train_loss: 0.0787, step time: 0.3203\n",
      "223/224, train_loss: 0.1321, step time: 0.3211\n",
      "224/224, train_loss: 0.3831, step time: 0.3861\n",
      "epoch 40 average loss: 0.1859\n",
      "current epoch: 40 current mean dice: 0.6593 class1: 0.9993 class2: 0.7378 class3: 0.2408\n",
      "best mean dice: 0.7003 at epoch: 38\n",
      "time consuming of epoch 40 is: 748.9793\n",
      "hello\n",
      "----------\n",
      "epoch 41/100\n",
      "1/224, train_loss: 0.3774, step time: 0.3478\n",
      "2/224, train_loss: 0.1036, step time: 0.3492\n",
      "3/224, train_loss: 0.1741, step time: 0.3456\n",
      "4/224, train_loss: 0.1925, step time: 0.3475\n",
      "5/224, train_loss: 0.1166, step time: 0.3452\n",
      "6/224, train_loss: 0.1365, step time: 0.3460\n",
      "7/224, train_loss: 0.3202, step time: 0.3776\n",
      "8/224, train_loss: 0.2671, step time: 0.3754\n",
      "9/224, train_loss: 0.1834, step time: 0.3134\n",
      "10/224, train_loss: 0.1108, step time: 0.3177\n",
      "11/224, train_loss: 0.2419, step time: 0.3762\n",
      "12/224, train_loss: 0.1370, step time: 0.3179\n",
      "13/224, train_loss: 0.2540, step time: 0.3944\n",
      "14/224, train_loss: 0.1798, step time: 0.3150\n",
      "15/224, train_loss: 0.0814, step time: 0.3151\n",
      "16/224, train_loss: 0.1881, step time: 0.3128\n",
      "17/224, train_loss: 0.0957, step time: 0.3173\n",
      "18/224, train_loss: 0.2907, step time: 0.3710\n",
      "19/224, train_loss: 0.2221, step time: 0.4012\n",
      "20/224, train_loss: 0.2188, step time: 0.4052\n",
      "21/224, train_loss: 0.1518, step time: 0.3151\n",
      "22/224, train_loss: 0.0636, step time: 0.3156\n",
      "23/224, train_loss: 0.1427, step time: 0.3140\n",
      "24/224, train_loss: 0.1432, step time: 0.3156\n",
      "25/224, train_loss: 0.1926, step time: 0.3942\n",
      "26/224, train_loss: 0.1782, step time: 0.3177\n",
      "27/224, train_loss: 0.1101, step time: 0.3155\n",
      "28/224, train_loss: 0.0925, step time: 0.3172\n",
      "29/224, train_loss: 0.1697, step time: 0.3908\n",
      "30/224, train_loss: 0.1546, step time: 0.3833\n",
      "31/224, train_loss: 0.3201, step time: 0.3180\n",
      "32/224, train_loss: 0.1446, step time: 0.4070\n",
      "33/224, train_loss: 0.2983, step time: 0.3131\n",
      "34/224, train_loss: 0.1808, step time: 0.3151\n",
      "35/224, train_loss: 0.2744, step time: 0.3736\n",
      "36/224, train_loss: 0.1204, step time: 0.3167\n",
      "37/224, train_loss: 0.3520, step time: 0.4078\n",
      "38/224, train_loss: 0.0600, step time: 0.3147\n",
      "39/224, train_loss: 0.1281, step time: 0.3170\n",
      "40/224, train_loss: 0.1828, step time: 0.3989\n",
      "41/224, train_loss: 0.1086, step time: 0.3673\n",
      "42/224, train_loss: 0.0833, step time: 0.3174\n",
      "43/224, train_loss: 0.0756, step time: 0.3996\n",
      "44/224, train_loss: 0.2453, step time: 0.4011\n",
      "45/224, train_loss: 0.0932, step time: 0.4102\n",
      "46/224, train_loss: 0.1715, step time: 0.3776\n",
      "47/224, train_loss: 0.0992, step time: 0.3133\n",
      "48/224, train_loss: 0.1483, step time: 0.3660\n",
      "49/224, train_loss: 0.2417, step time: 0.3776\n",
      "50/224, train_loss: 0.1532, step time: 0.3868\n",
      "51/224, train_loss: 0.1080, step time: 0.3129\n",
      "52/224, train_loss: 0.0926, step time: 0.3152\n",
      "53/224, train_loss: 0.0737, step time: 0.3125\n",
      "54/224, train_loss: 0.1038, step time: 0.3142\n",
      "55/224, train_loss: 0.3715, step time: 0.3888\n",
      "56/224, train_loss: 0.3896, step time: 0.3955\n",
      "57/224, train_loss: 0.0823, step time: 0.4065\n",
      "58/224, train_loss: 0.2448, step time: 0.3143\n",
      "59/224, train_loss: 0.2975, step time: 0.3913\n",
      "60/224, train_loss: 0.2508, step time: 0.3803\n",
      "61/224, train_loss: 0.0856, step time: 0.3155\n",
      "62/224, train_loss: 0.0721, step time: 0.3149\n",
      "63/224, train_loss: 0.0699, step time: 0.3147\n",
      "64/224, train_loss: 0.3030, step time: 0.3144\n",
      "65/224, train_loss: 0.2170, step time: 0.3154\n",
      "66/224, train_loss: 0.1719, step time: 0.3898\n",
      "67/224, train_loss: 0.1019, step time: 0.3145\n",
      "68/224, train_loss: 0.1012, step time: 0.3853\n",
      "69/224, train_loss: 0.1355, step time: 0.3152\n",
      "70/224, train_loss: 0.1445, step time: 0.3149\n",
      "71/224, train_loss: 0.1541, step time: 0.3153\n",
      "72/224, train_loss: 0.1405, step time: 0.3875\n",
      "73/224, train_loss: 0.3940, step time: 0.3178\n",
      "74/224, train_loss: 0.2405, step time: 0.4028\n",
      "75/224, train_loss: 0.2486, step time: 0.3803\n",
      "76/224, train_loss: 0.1895, step time: 0.3123\n",
      "77/224, train_loss: 0.3438, step time: 0.3968\n",
      "78/224, train_loss: 0.1047, step time: 0.3152\n",
      "79/224, train_loss: 0.3789, step time: 0.3142\n",
      "80/224, train_loss: 0.1691, step time: 0.3953\n",
      "81/224, train_loss: 0.1579, step time: 0.3965\n",
      "82/224, train_loss: 0.1117, step time: 0.3154\n",
      "83/224, train_loss: 0.1350, step time: 0.4112\n",
      "84/224, train_loss: 0.1916, step time: 0.3849\n",
      "85/224, train_loss: 0.1778, step time: 0.3152\n",
      "86/224, train_loss: 0.4192, step time: 0.3685\n",
      "87/224, train_loss: 0.2147, step time: 0.3142\n",
      "88/224, train_loss: 0.0781, step time: 0.3139\n",
      "89/224, train_loss: 0.2716, step time: 0.4012\n",
      "90/224, train_loss: 0.0657, step time: 0.3122\n",
      "91/224, train_loss: 0.1647, step time: 0.3144\n",
      "92/224, train_loss: 0.2160, step time: 0.3149\n",
      "93/224, train_loss: 0.1785, step time: 0.3665\n",
      "94/224, train_loss: 0.3654, step time: 0.3148\n",
      "95/224, train_loss: 0.2901, step time: 0.3141\n",
      "96/224, train_loss: 0.1434, step time: 0.3766\n",
      "97/224, train_loss: 0.1017, step time: 0.3147\n",
      "98/224, train_loss: 0.1793, step time: 0.3150\n",
      "99/224, train_loss: 0.1505, step time: 0.3174\n",
      "100/224, train_loss: 0.3615, step time: 0.3753\n",
      "101/224, train_loss: 0.1751, step time: 0.3122\n",
      "102/224, train_loss: 0.1417, step time: 0.3121\n",
      "103/224, train_loss: 0.1798, step time: 0.3125\n",
      "104/224, train_loss: 0.1278, step time: 0.3149\n",
      "105/224, train_loss: 0.1035, step time: 0.4012\n",
      "106/224, train_loss: 0.0587, step time: 0.4052\n",
      "107/224, train_loss: 0.0915, step time: 0.3144\n",
      "108/224, train_loss: 0.0754, step time: 0.3166\n",
      "109/224, train_loss: 0.1290, step time: 0.3123\n",
      "110/224, train_loss: 0.1115, step time: 0.4094\n",
      "111/224, train_loss: 0.1484, step time: 0.3164\n",
      "112/224, train_loss: 0.1170, step time: 0.3201\n",
      "113/224, train_loss: 0.0859, step time: 0.3174\n",
      "114/224, train_loss: 0.1721, step time: 0.3153\n",
      "115/224, train_loss: 0.1538, step time: 0.3744\n",
      "116/224, train_loss: 0.1457, step time: 0.4018\n",
      "117/224, train_loss: 0.2688, step time: 0.3812\n",
      "118/224, train_loss: 0.3127, step time: 0.3661\n",
      "119/224, train_loss: 0.1253, step time: 0.3820\n",
      "120/224, train_loss: 0.0981, step time: 0.3831\n",
      "121/224, train_loss: 0.2262, step time: 0.3175\n",
      "122/224, train_loss: 0.2435, step time: 0.3736\n",
      "123/224, train_loss: 0.1324, step time: 0.3177\n",
      "124/224, train_loss: 0.0841, step time: 0.3198\n",
      "125/224, train_loss: 0.2221, step time: 0.3728\n",
      "126/224, train_loss: 0.3861, step time: 0.3155\n",
      "127/224, train_loss: 0.2974, step time: 0.3172\n",
      "128/224, train_loss: 0.1225, step time: 0.3151\n",
      "129/224, train_loss: 0.1754, step time: 0.4048\n",
      "130/224, train_loss: 0.4195, step time: 0.3910\n",
      "131/224, train_loss: 0.2946, step time: 0.4379\n",
      "132/224, train_loss: 0.3790, step time: 0.3492\n",
      "133/224, train_loss: 0.1658, step time: 0.3452\n",
      "134/224, train_loss: 0.1193, step time: 0.3474\n",
      "135/224, train_loss: 0.1691, step time: 0.3461\n",
      "136/224, train_loss: 0.1364, step time: 0.3457\n",
      "137/224, train_loss: 0.1531, step time: 0.4375\n",
      "138/224, train_loss: 0.0989, step time: 0.3460\n",
      "139/224, train_loss: 0.1341, step time: 0.3434\n",
      "140/224, train_loss: 0.3326, step time: 0.3459\n",
      "141/224, train_loss: 0.1301, step time: 0.3467\n",
      "142/224, train_loss: 0.1465, step time: 0.3448\n",
      "143/224, train_loss: 0.4222, step time: 0.3915\n",
      "144/224, train_loss: 0.1208, step time: 0.3148\n",
      "145/224, train_loss: 0.0851, step time: 0.3168\n",
      "146/224, train_loss: 0.0896, step time: 0.3141\n",
      "147/224, train_loss: 0.1930, step time: 0.4051\n",
      "148/224, train_loss: 0.0609, step time: 0.3162\n",
      "149/224, train_loss: 0.1185, step time: 0.3141\n",
      "150/224, train_loss: 0.1063, step time: 0.3172\n",
      "151/224, train_loss: 0.1373, step time: 0.3177\n",
      "152/224, train_loss: 0.0922, step time: 0.3152\n",
      "153/224, train_loss: 0.3729, step time: 0.3151\n",
      "154/224, train_loss: 0.3732, step time: 0.3834\n",
      "155/224, train_loss: 0.1559, step time: 0.3163\n",
      "156/224, train_loss: 0.2841, step time: 0.3166\n",
      "157/224, train_loss: 0.1872, step time: 0.4006\n",
      "158/224, train_loss: 0.2092, step time: 0.3771\n",
      "159/224, train_loss: 0.0966, step time: 0.3810\n",
      "160/224, train_loss: 0.1759, step time: 0.3166\n",
      "161/224, train_loss: 0.1604, step time: 0.3174\n",
      "162/224, train_loss: 0.1806, step time: 0.3980\n",
      "163/224, train_loss: 0.0804, step time: 0.3156\n",
      "164/224, train_loss: 0.2437, step time: 0.4028\n",
      "165/224, train_loss: 0.1132, step time: 0.3192\n",
      "166/224, train_loss: 0.2650, step time: 0.3695\n",
      "167/224, train_loss: 0.1003, step time: 0.3186\n",
      "168/224, train_loss: 0.1318, step time: 0.3191\n",
      "169/224, train_loss: 0.2446, step time: 0.3779\n",
      "170/224, train_loss: 0.3793, step time: 0.4039\n",
      "171/224, train_loss: 0.1105, step time: 0.3691\n",
      "172/224, train_loss: 0.2386, step time: 0.3177\n",
      "173/224, train_loss: 0.2613, step time: 0.3153\n",
      "174/224, train_loss: 0.1270, step time: 0.3860\n",
      "175/224, train_loss: 0.3608, step time: 0.4008\n",
      "176/224, train_loss: 0.0868, step time: 0.3703\n",
      "177/224, train_loss: 0.2629, step time: 0.3155\n",
      "178/224, train_loss: 0.2316, step time: 0.3182\n",
      "179/224, train_loss: 0.2206, step time: 0.3905\n",
      "180/224, train_loss: 0.1699, step time: 0.3151\n",
      "181/224, train_loss: 0.2467, step time: 0.3144\n",
      "182/224, train_loss: 0.2164, step time: 0.3742\n",
      "183/224, train_loss: 0.1311, step time: 0.4071\n",
      "184/224, train_loss: 0.0940, step time: 0.3169\n",
      "185/224, train_loss: 0.1398, step time: 0.3942\n",
      "186/224, train_loss: 0.1540, step time: 0.3164\n",
      "187/224, train_loss: 0.2807, step time: 0.3194\n",
      "188/224, train_loss: 0.2999, step time: 0.3160\n",
      "189/224, train_loss: 0.1064, step time: 0.4014\n",
      "190/224, train_loss: 0.2334, step time: 0.3981\n",
      "191/224, train_loss: 0.3634, step time: 0.3131\n",
      "192/224, train_loss: 0.1597, step time: 0.3173\n",
      "193/224, train_loss: 0.2232, step time: 0.3132\n",
      "194/224, train_loss: 0.1140, step time: 0.3689\n",
      "195/224, train_loss: 0.0901, step time: 0.3155\n",
      "196/224, train_loss: 0.1297, step time: 0.3191\n",
      "197/224, train_loss: 0.1804, step time: 0.3157\n",
      "198/224, train_loss: 0.0554, step time: 0.3137\n",
      "199/224, train_loss: 0.3384, step time: 0.4033\n",
      "200/224, train_loss: 0.3805, step time: 0.3940\n",
      "201/224, train_loss: 0.3677, step time: 0.3706\n",
      "202/224, train_loss: 0.0979, step time: 0.3184\n",
      "203/224, train_loss: 0.1468, step time: 0.3160\n",
      "204/224, train_loss: 0.0962, step time: 0.3173\n",
      "205/224, train_loss: 0.2186, step time: 0.4085\n",
      "206/224, train_loss: 0.1399, step time: 0.3154\n",
      "207/224, train_loss: 0.1172, step time: 0.3133\n",
      "208/224, train_loss: 0.3863, step time: 0.4102\n",
      "209/224, train_loss: 0.1291, step time: 0.3172\n",
      "210/224, train_loss: 0.2048, step time: 0.3176\n",
      "211/224, train_loss: 0.2026, step time: 0.3764\n",
      "212/224, train_loss: 0.3442, step time: 0.4053\n",
      "213/224, train_loss: 0.0931, step time: 0.3148\n",
      "214/224, train_loss: 0.1371, step time: 0.3960\n",
      "215/224, train_loss: 0.1521, step time: 0.3708\n",
      "216/224, train_loss: 0.2044, step time: 0.3133\n",
      "217/224, train_loss: 0.1754, step time: 0.3138\n",
      "218/224, train_loss: 0.1842, step time: 0.3751\n",
      "219/224, train_loss: 0.3014, step time: 0.3678\n",
      "220/224, train_loss: 0.2765, step time: 0.3885\n",
      "221/224, train_loss: 0.1542, step time: 0.3149\n",
      "222/224, train_loss: 0.2577, step time: 0.3980\n",
      "223/224, train_loss: 0.1838, step time: 0.3157\n",
      "224/224, train_loss: 0.2818, step time: 0.3989\n",
      "epoch 41 average loss: 0.1873\n",
      "current epoch: 41 current mean dice: 0.6823 class1: 0.9993 class2: 0.7211 class3: 0.3265\n",
      "best mean dice: 0.7003 at epoch: 38\n",
      "time consuming of epoch 41 is: 670.1628\n",
      "hello\n",
      "----------\n",
      "epoch 42/100\n",
      "1/224, train_loss: 0.1455, step time: 0.3947\n",
      "2/224, train_loss: 0.1481, step time: 0.3799\n",
      "3/224, train_loss: 0.1625, step time: 0.3155\n",
      "4/224, train_loss: 0.3359, step time: 0.3177\n",
      "5/224, train_loss: 0.1034, step time: 0.3127\n",
      "6/224, train_loss: 0.0935, step time: 0.3145\n",
      "7/224, train_loss: 0.1631, step time: 0.3150\n",
      "8/224, train_loss: 0.1262, step time: 0.4080\n",
      "9/224, train_loss: 0.3869, step time: 0.4009\n",
      "10/224, train_loss: 0.2214, step time: 0.3174\n",
      "11/224, train_loss: 0.1756, step time: 0.3151\n",
      "12/224, train_loss: 0.1295, step time: 0.3175\n",
      "13/224, train_loss: 0.3799, step time: 0.4095\n",
      "14/224, train_loss: 0.2598, step time: 0.3156\n",
      "15/224, train_loss: 0.2841, step time: 0.3744\n",
      "16/224, train_loss: 0.1017, step time: 0.3883\n",
      "17/224, train_loss: 0.0937, step time: 0.3656\n",
      "18/224, train_loss: 0.2112, step time: 0.4051\n",
      "19/224, train_loss: 0.1553, step time: 0.3165\n",
      "20/224, train_loss: 0.0953, step time: 0.3157\n",
      "21/224, train_loss: 0.1334, step time: 0.3147\n",
      "22/224, train_loss: 0.3273, step time: 0.3898\n",
      "23/224, train_loss: 0.0730, step time: 0.3716\n",
      "24/224, train_loss: 0.3954, step time: 0.3872\n",
      "25/224, train_loss: 0.1643, step time: 0.3152\n",
      "26/224, train_loss: 0.1157, step time: 0.4029\n",
      "27/224, train_loss: 0.0898, step time: 0.3130\n",
      "28/224, train_loss: 0.1181, step time: 0.3829\n",
      "29/224, train_loss: 0.2303, step time: 0.3743\n",
      "30/224, train_loss: 0.0922, step time: 0.3145\n",
      "31/224, train_loss: 0.4188, step time: 0.3779\n",
      "32/224, train_loss: 0.1914, step time: 0.3158\n",
      "33/224, train_loss: 0.1216, step time: 0.3127\n",
      "34/224, train_loss: 0.1441, step time: 0.3147\n",
      "35/224, train_loss: 0.1225, step time: 0.3889\n",
      "36/224, train_loss: 0.1867, step time: 0.3169\n",
      "37/224, train_loss: 0.3071, step time: 0.3168\n",
      "38/224, train_loss: 0.1236, step time: 0.3121\n",
      "39/224, train_loss: 0.1031, step time: 0.3149\n",
      "40/224, train_loss: 0.2139, step time: 0.5640\n",
      "41/224, train_loss: 0.0753, step time: 0.3166\n",
      "42/224, train_loss: 0.1238, step time: 0.3171\n",
      "43/224, train_loss: 0.0882, step time: 0.3148\n",
      "44/224, train_loss: 0.0758, step time: 0.3681\n",
      "45/224, train_loss: 0.1366, step time: 0.3161\n",
      "46/224, train_loss: 0.0716, step time: 0.4035\n",
      "47/224, train_loss: 0.1537, step time: 0.3872\n",
      "48/224, train_loss: 0.0843, step time: 0.3148\n",
      "49/224, train_loss: 0.1192, step time: 0.3164\n",
      "50/224, train_loss: 0.1436, step time: 0.4080\n",
      "51/224, train_loss: 0.2492, step time: 0.3168\n",
      "52/224, train_loss: 0.2186, step time: 0.3702\n",
      "53/224, train_loss: 0.1160, step time: 0.3143\n",
      "54/224, train_loss: 0.3351, step time: 0.4118\n",
      "55/224, train_loss: 0.0896, step time: 0.3125\n",
      "56/224, train_loss: 0.1148, step time: 0.3141\n",
      "57/224, train_loss: 0.1966, step time: 0.3119\n",
      "58/224, train_loss: 0.0844, step time: 0.3120\n",
      "59/224, train_loss: 0.2331, step time: 0.4068\n",
      "60/224, train_loss: 0.1380, step time: 0.3147\n",
      "61/224, train_loss: 0.1657, step time: 0.3128\n",
      "62/224, train_loss: 0.3448, step time: 0.3147\n",
      "63/224, train_loss: 0.2403, step time: 0.3691\n",
      "64/224, train_loss: 0.3586, step time: 0.3752\n",
      "65/224, train_loss: 0.1635, step time: 0.3169\n",
      "66/224, train_loss: 0.1741, step time: 0.3146\n",
      "67/224, train_loss: 0.1367, step time: 0.3860\n",
      "68/224, train_loss: 0.1691, step time: 0.3150\n",
      "69/224, train_loss: 0.1463, step time: 0.4045\n",
      "70/224, train_loss: 0.1089, step time: 0.3122\n",
      "71/224, train_loss: 0.1117, step time: 0.3171\n",
      "72/224, train_loss: 0.1264, step time: 0.3869\n",
      "73/224, train_loss: 0.3219, step time: 0.3746\n",
      "74/224, train_loss: 0.0756, step time: 0.3167\n",
      "75/224, train_loss: 0.2051, step time: 0.3730\n",
      "76/224, train_loss: 0.3296, step time: 0.3176\n",
      "77/224, train_loss: 0.0951, step time: 0.3128\n",
      "78/224, train_loss: 0.2073, step time: 0.3143\n",
      "79/224, train_loss: 0.1094, step time: 0.3843\n",
      "80/224, train_loss: 0.0534, step time: 0.3171\n",
      "81/224, train_loss: 0.0719, step time: 0.3140\n",
      "82/224, train_loss: 0.4249, step time: 0.3866\n",
      "83/224, train_loss: 0.2468, step time: 0.4096\n",
      "84/224, train_loss: 0.2659, step time: 0.3127\n",
      "85/224, train_loss: 0.1489, step time: 0.3126\n",
      "86/224, train_loss: 0.1154, step time: 0.3138\n",
      "87/224, train_loss: 0.3470, step time: 0.3896\n",
      "88/224, train_loss: 0.1499, step time: 0.3920\n",
      "89/224, train_loss: 0.2370, step time: 0.4003\n",
      "90/224, train_loss: 0.1311, step time: 0.3173\n",
      "91/224, train_loss: 0.2454, step time: 0.4071\n",
      "92/224, train_loss: 0.1919, step time: 0.3674\n",
      "93/224, train_loss: 0.3574, step time: 0.3894\n",
      "94/224, train_loss: 0.3344, step time: 0.3748\n",
      "95/224, train_loss: 0.1086, step time: 0.3148\n",
      "96/224, train_loss: 0.0840, step time: 0.3148\n",
      "97/224, train_loss: 0.1745, step time: 0.3150\n",
      "98/224, train_loss: 0.1686, step time: 0.3152\n",
      "99/224, train_loss: 0.1455, step time: 0.3134\n",
      "100/224, train_loss: 0.1068, step time: 0.3170\n",
      "101/224, train_loss: 0.1165, step time: 0.3171\n",
      "102/224, train_loss: 0.1654, step time: 0.3129\n",
      "103/224, train_loss: 0.3722, step time: 0.4106\n",
      "104/224, train_loss: 0.1107, step time: 0.3178\n",
      "105/224, train_loss: 0.1575, step time: 0.3896\n",
      "106/224, train_loss: 0.0917, step time: 0.3150\n",
      "107/224, train_loss: 0.0597, step time: 0.3147\n",
      "108/224, train_loss: 0.1118, step time: 0.3167\n",
      "109/224, train_loss: 0.0773, step time: 0.3146\n",
      "110/224, train_loss: 0.2951, step time: 0.3983\n",
      "111/224, train_loss: 0.1581, step time: 0.3150\n",
      "112/224, train_loss: 0.1825, step time: 0.3147\n",
      "113/224, train_loss: 0.1549, step time: 0.3861\n",
      "114/224, train_loss: 0.1937, step time: 0.3165\n",
      "115/224, train_loss: 0.1849, step time: 0.3833\n",
      "116/224, train_loss: 0.4504, step time: 0.3833\n",
      "117/224, train_loss: 0.1625, step time: 0.3942\n",
      "118/224, train_loss: 0.1412, step time: 0.3700\n",
      "119/224, train_loss: 0.2227, step time: 0.3848\n",
      "120/224, train_loss: 0.0884, step time: 0.4080\n",
      "121/224, train_loss: 0.1502, step time: 0.3954\n",
      "122/224, train_loss: 0.4010, step time: 0.3774\n",
      "123/224, train_loss: 0.3070, step time: 0.3140\n",
      "124/224, train_loss: 0.1372, step time: 0.3729\n",
      "125/224, train_loss: 0.0988, step time: 0.4074\n",
      "126/224, train_loss: 0.2041, step time: 0.4026\n",
      "127/224, train_loss: 0.1306, step time: 0.3167\n",
      "128/224, train_loss: 0.2200, step time: 0.3710\n",
      "129/224, train_loss: 0.1212, step time: 0.3966\n",
      "130/224, train_loss: 0.2675, step time: 0.4048\n",
      "131/224, train_loss: 0.1395, step time: 0.3177\n",
      "132/224, train_loss: 0.1305, step time: 0.3829\n",
      "133/224, train_loss: 0.1758, step time: 0.3915\n",
      "134/224, train_loss: 0.3583, step time: 0.4016\n",
      "135/224, train_loss: 0.1610, step time: 0.4119\n",
      "136/224, train_loss: 0.2072, step time: 0.4143\n",
      "137/224, train_loss: 0.1972, step time: 0.3157\n",
      "138/224, train_loss: 0.4679, step time: 0.3824\n",
      "139/224, train_loss: 0.1760, step time: 0.3809\n",
      "140/224, train_loss: 0.2263, step time: 0.3662\n",
      "141/224, train_loss: 0.1611, step time: 0.4073\n",
      "142/224, train_loss: 0.1384, step time: 0.3135\n",
      "143/224, train_loss: 0.1118, step time: 0.3154\n",
      "144/224, train_loss: 0.0944, step time: 0.3782\n",
      "145/224, train_loss: 0.1126, step time: 0.4122\n",
      "146/224, train_loss: 0.3951, step time: 0.3135\n",
      "147/224, train_loss: 0.3196, step time: 0.3140\n",
      "148/224, train_loss: 0.2146, step time: 0.3161\n",
      "149/224, train_loss: 0.1524, step time: 0.3152\n",
      "150/224, train_loss: 0.1616, step time: 0.3896\n",
      "151/224, train_loss: 0.2780, step time: 0.3156\n",
      "152/224, train_loss: 0.0862, step time: 0.3152\n",
      "153/224, train_loss: 0.1071, step time: 0.3873\n",
      "154/224, train_loss: 0.2651, step time: 0.3145\n",
      "155/224, train_loss: 0.1251, step time: 0.4108\n",
      "156/224, train_loss: 0.0790, step time: 0.3956\n",
      "157/224, train_loss: 0.1006, step time: 0.3182\n",
      "158/224, train_loss: 0.1319, step time: 0.3185\n",
      "159/224, train_loss: 0.2154, step time: 0.3136\n",
      "160/224, train_loss: 0.3593, step time: 0.3640\n",
      "161/224, train_loss: 0.2997, step time: 0.3156\n",
      "162/224, train_loss: 0.2105, step time: 0.3174\n",
      "163/224, train_loss: 0.1503, step time: 0.3154\n",
      "164/224, train_loss: 0.1315, step time: 0.3140\n",
      "165/224, train_loss: 0.0806, step time: 0.3157\n",
      "166/224, train_loss: 0.0611, step time: 0.4024\n",
      "167/224, train_loss: 0.2285, step time: 0.3781\n",
      "168/224, train_loss: 0.0710, step time: 0.3662\n",
      "169/224, train_loss: 0.1534, step time: 0.3163\n",
      "170/224, train_loss: 0.1628, step time: 0.3138\n",
      "171/224, train_loss: 0.2695, step time: 0.3673\n",
      "172/224, train_loss: 0.1907, step time: 0.3856\n",
      "173/224, train_loss: 0.0762, step time: 0.3157\n",
      "174/224, train_loss: 0.2070, step time: 0.3989\n",
      "175/224, train_loss: 0.1021, step time: 0.3163\n",
      "176/224, train_loss: 0.0757, step time: 0.3152\n",
      "177/224, train_loss: 0.1468, step time: 0.3150\n",
      "178/224, train_loss: 0.1808, step time: 0.3181\n",
      "179/224, train_loss: 0.0805, step time: 0.3162\n",
      "180/224, train_loss: 0.2052, step time: 0.3803\n",
      "181/224, train_loss: 0.2095, step time: 0.3714\n",
      "182/224, train_loss: 0.0828, step time: 0.3155\n",
      "183/224, train_loss: 0.1382, step time: 0.3780\n",
      "184/224, train_loss: 0.2956, step time: 0.4045\n",
      "185/224, train_loss: 0.0857, step time: 0.3139\n",
      "186/224, train_loss: 0.3335, step time: 0.3675\n",
      "187/224, train_loss: 0.2313, step time: 0.3157\n",
      "188/224, train_loss: 0.3486, step time: 0.3154\n",
      "189/224, train_loss: 0.0933, step time: 0.3752\n",
      "190/224, train_loss: 0.1009, step time: 0.3680\n",
      "191/224, train_loss: 0.3626, step time: 0.3951\n",
      "192/224, train_loss: 0.2562, step time: 0.3878\n",
      "193/224, train_loss: 0.0886, step time: 0.3811\n",
      "194/224, train_loss: 0.1497, step time: 0.3184\n",
      "195/224, train_loss: 0.1633, step time: 0.3993\n",
      "196/224, train_loss: 0.1063, step time: 0.3680\n",
      "197/224, train_loss: 0.1168, step time: 0.3173\n",
      "198/224, train_loss: 0.1376, step time: 0.3153\n",
      "199/224, train_loss: 0.1377, step time: 0.3151\n",
      "200/224, train_loss: 0.1577, step time: 0.3126\n",
      "201/224, train_loss: 0.3993, step time: 0.3147\n",
      "202/224, train_loss: 0.2133, step time: 0.3834\n",
      "203/224, train_loss: 0.1522, step time: 0.3152\n",
      "204/224, train_loss: 0.1679, step time: 0.3177\n",
      "205/224, train_loss: 0.1882, step time: 0.4040\n",
      "206/224, train_loss: 0.3318, step time: 0.3157\n",
      "207/224, train_loss: 0.0590, step time: 0.3154\n",
      "208/224, train_loss: 0.2671, step time: 0.3731\n",
      "209/224, train_loss: 0.1172, step time: 0.3153\n",
      "210/224, train_loss: 0.2640, step time: 0.3154\n",
      "211/224, train_loss: 0.2736, step time: 0.3160\n",
      "212/224, train_loss: 0.1020, step time: 0.3177\n",
      "213/224, train_loss: 0.1152, step time: 0.3987\n",
      "214/224, train_loss: 0.2507, step time: 0.3742\n",
      "215/224, train_loss: 0.2145, step time: 0.3896\n",
      "216/224, train_loss: 0.1785, step time: 0.3771\n",
      "217/224, train_loss: 0.1076, step time: 0.3706\n",
      "218/224, train_loss: 0.2848, step time: 0.3174\n",
      "219/224, train_loss: 0.1956, step time: 0.3733\n",
      "220/224, train_loss: 0.0892, step time: 0.4112\n",
      "221/224, train_loss: 0.1648, step time: 0.3182\n",
      "222/224, train_loss: 0.2998, step time: 0.3921\n",
      "223/224, train_loss: 0.1696, step time: 0.3675\n",
      "224/224, train_loss: 0.1079, step time: 0.3172\n",
      "epoch 42 average loss: 0.1820\n",
      "current epoch: 42 current mean dice: 0.6862 class1: 0.9992 class2: 0.6979 class3: 0.3616\n",
      "best mean dice: 0.7003 at epoch: 38\n",
      "time consuming of epoch 42 is: 705.3039\n",
      "hello\n",
      "----------\n",
      "epoch 43/100\n",
      "1/224, train_loss: 0.1368, step time: 0.3166\n",
      "2/224, train_loss: 0.0772, step time: 0.4067\n",
      "3/224, train_loss: 0.0721, step time: 0.3130\n",
      "4/224, train_loss: 0.3673, step time: 0.3955\n",
      "5/224, train_loss: 0.1786, step time: 0.3981\n",
      "6/224, train_loss: 0.3959, step time: 0.3155\n",
      "7/224, train_loss: 0.3655, step time: 0.3810\n",
      "8/224, train_loss: 0.1354, step time: 0.3740\n",
      "9/224, train_loss: 0.2103, step time: 0.3670\n",
      "10/224, train_loss: 0.2585, step time: 0.4106\n",
      "11/224, train_loss: 0.2031, step time: 0.3155\n",
      "12/224, train_loss: 0.1268, step time: 0.3159\n",
      "13/224, train_loss: 0.1109, step time: 0.3717\n",
      "14/224, train_loss: 0.1119, step time: 0.3187\n",
      "15/224, train_loss: 0.1548, step time: 0.3159\n",
      "16/224, train_loss: 0.1009, step time: 0.3699\n",
      "17/224, train_loss: 0.1594, step time: 0.3189\n",
      "18/224, train_loss: 0.2762, step time: 0.3706\n",
      "19/224, train_loss: 0.2549, step time: 0.3794\n",
      "20/224, train_loss: 0.0801, step time: 0.3162\n",
      "21/224, train_loss: 0.1662, step time: 0.3801\n",
      "22/224, train_loss: 0.0830, step time: 0.3152\n",
      "23/224, train_loss: 0.2524, step time: 0.3870\n",
      "24/224, train_loss: 0.1722, step time: 0.3901\n",
      "25/224, train_loss: 0.1778, step time: 0.3726\n",
      "26/224, train_loss: 0.4703, step time: 0.3948\n",
      "27/224, train_loss: 0.2259, step time: 0.3878\n",
      "28/224, train_loss: 0.0656, step time: 0.4072\n",
      "29/224, train_loss: 0.1143, step time: 0.3161\n",
      "30/224, train_loss: 0.2867, step time: 0.3983\n",
      "31/224, train_loss: 0.1588, step time: 0.4077\n",
      "32/224, train_loss: 0.1177, step time: 0.3154\n",
      "33/224, train_loss: 0.1541, step time: 0.3970\n",
      "34/224, train_loss: 0.1505, step time: 0.3906\n",
      "35/224, train_loss: 0.0867, step time: 0.3160\n",
      "36/224, train_loss: 0.1298, step time: 0.3730\n",
      "37/224, train_loss: 0.0741, step time: 0.3766\n",
      "38/224, train_loss: 0.2915, step time: 0.4012\n",
      "39/224, train_loss: 0.1899, step time: 0.3147\n",
      "40/224, train_loss: 0.1946, step time: 0.3996\n",
      "41/224, train_loss: 0.4391, step time: 0.3950\n",
      "42/224, train_loss: 0.2255, step time: 0.3910\n",
      "43/224, train_loss: 0.1358, step time: 0.3168\n",
      "44/224, train_loss: 0.2494, step time: 0.3880\n",
      "45/224, train_loss: 0.4000, step time: 0.3910\n",
      "46/224, train_loss: 0.4445, step time: 0.3834\n",
      "47/224, train_loss: 0.2513, step time: 0.4010\n",
      "48/224, train_loss: 0.1823, step time: 0.3138\n",
      "49/224, train_loss: 0.2421, step time: 0.3666\n",
      "50/224, train_loss: 0.1517, step time: 0.3144\n",
      "51/224, train_loss: 0.3554, step time: 0.3827\n",
      "52/224, train_loss: 0.2468, step time: 0.3698\n",
      "53/224, train_loss: 0.1034, step time: 0.3784\n",
      "54/224, train_loss: 0.3517, step time: 0.3814\n",
      "55/224, train_loss: 0.0795, step time: 0.3708\n",
      "56/224, train_loss: 0.3051, step time: 0.4040\n",
      "57/224, train_loss: 0.2115, step time: 0.3759\n",
      "58/224, train_loss: 0.3700, step time: 0.3722\n",
      "59/224, train_loss: 0.3110, step time: 0.4019\n",
      "60/224, train_loss: 0.1652, step time: 0.3148\n",
      "61/224, train_loss: 0.3452, step time: 0.3759\n",
      "62/224, train_loss: 0.1173, step time: 0.3153\n",
      "63/224, train_loss: 0.3295, step time: 0.3171\n",
      "64/224, train_loss: 0.2863, step time: 0.3687\n",
      "65/224, train_loss: 0.1307, step time: 0.4005\n",
      "66/224, train_loss: 0.2856, step time: 0.3973\n",
      "67/224, train_loss: 0.1112, step time: 0.3146\n",
      "68/224, train_loss: 0.2744, step time: 0.3155\n",
      "69/224, train_loss: 0.2271, step time: 0.3679\n",
      "70/224, train_loss: 0.0962, step time: 0.3759\n",
      "71/224, train_loss: 0.2092, step time: 0.3156\n",
      "72/224, train_loss: 0.1601, step time: 0.3660\n",
      "73/224, train_loss: 0.1894, step time: 0.3155\n",
      "74/224, train_loss: 0.3475, step time: 0.3913\n",
      "75/224, train_loss: 0.1162, step time: 0.3174\n",
      "76/224, train_loss: 0.0923, step time: 0.4035\n",
      "77/224, train_loss: 0.2257, step time: 0.4125\n",
      "78/224, train_loss: 0.1229, step time: 0.3929\n",
      "79/224, train_loss: 0.2593, step time: 0.3154\n",
      "80/224, train_loss: 0.1007, step time: 0.3139\n",
      "81/224, train_loss: 0.2105, step time: 0.3977\n",
      "82/224, train_loss: 0.2057, step time: 0.3176\n",
      "83/224, train_loss: 0.2445, step time: 0.3939\n",
      "84/224, train_loss: 0.1605, step time: 0.3146\n",
      "85/224, train_loss: 0.2178, step time: 0.3148\n",
      "86/224, train_loss: 0.3102, step time: 0.4091\n",
      "87/224, train_loss: 0.1134, step time: 0.3155\n",
      "88/224, train_loss: 0.2100, step time: 0.3149\n",
      "89/224, train_loss: 0.1773, step time: 0.3999\n",
      "90/224, train_loss: 0.3340, step time: 0.3192\n",
      "91/224, train_loss: 0.2578, step time: 0.3183\n",
      "92/224, train_loss: 0.2347, step time: 0.3951\n",
      "93/224, train_loss: 0.1789, step time: 0.3152\n",
      "94/224, train_loss: 0.3295, step time: 0.3804\n",
      "95/224, train_loss: 0.3341, step time: 0.3162\n",
      "96/224, train_loss: 0.1850, step time: 0.3142\n",
      "97/224, train_loss: 0.2001, step time: 0.3710\n",
      "98/224, train_loss: 0.1717, step time: 0.4143\n",
      "99/224, train_loss: 0.1856, step time: 0.3953\n",
      "100/224, train_loss: 0.4366, step time: 0.4016\n",
      "101/224, train_loss: 0.1544, step time: 0.3161\n",
      "102/224, train_loss: 0.1337, step time: 0.3160\n",
      "103/224, train_loss: 0.2953, step time: 0.3183\n",
      "104/224, train_loss: 0.3445, step time: 0.3161\n",
      "105/224, train_loss: 0.1316, step time: 0.3183\n",
      "106/224, train_loss: 0.1732, step time: 0.3178\n",
      "107/224, train_loss: 0.2235, step time: 0.3823\n",
      "108/224, train_loss: 0.1879, step time: 0.3158\n",
      "109/224, train_loss: 0.2107, step time: 0.3152\n",
      "110/224, train_loss: 0.0564, step time: 0.3155\n",
      "111/224, train_loss: 0.0803, step time: 0.3172\n",
      "112/224, train_loss: 0.3708, step time: 0.4029\n",
      "113/224, train_loss: 0.1580, step time: 0.3693\n",
      "114/224, train_loss: 0.3633, step time: 0.4003\n",
      "115/224, train_loss: 0.5006, step time: 0.4014\n",
      "116/224, train_loss: 0.3773, step time: 0.3912\n",
      "117/224, train_loss: 0.1137, step time: 0.3156\n",
      "118/224, train_loss: 0.4021, step time: 0.3133\n",
      "119/224, train_loss: 0.1606, step time: 0.3126\n",
      "120/224, train_loss: 0.0990, step time: 0.3157\n",
      "121/224, train_loss: 0.1512, step time: 0.3171\n",
      "122/224, train_loss: 0.3977, step time: 0.4145\n",
      "123/224, train_loss: 0.3112, step time: 0.3679\n",
      "124/224, train_loss: 0.3797, step time: 0.3935\n",
      "125/224, train_loss: 0.2992, step time: 0.3849\n",
      "126/224, train_loss: 0.1568, step time: 0.3696\n",
      "127/224, train_loss: 0.1529, step time: 0.3151\n",
      "128/224, train_loss: 0.0530, step time: 0.3147\n",
      "129/224, train_loss: 0.1249, step time: 0.4087\n",
      "130/224, train_loss: 0.1201, step time: 0.3152\n",
      "131/224, train_loss: 0.2214, step time: 0.3157\n",
      "132/224, train_loss: 0.3877, step time: 0.3817\n",
      "133/224, train_loss: 0.1351, step time: 0.3894\n",
      "134/224, train_loss: 0.1772, step time: 0.3139\n",
      "135/224, train_loss: 0.1485, step time: 0.3816\n",
      "136/224, train_loss: 0.1438, step time: 0.3911\n",
      "137/224, train_loss: 0.1028, step time: 0.3935\n",
      "138/224, train_loss: 0.0848, step time: 0.3152\n",
      "139/224, train_loss: 0.1052, step time: 0.3154\n",
      "140/224, train_loss: 0.0988, step time: 0.3171\n",
      "141/224, train_loss: 0.1596, step time: 0.3146\n",
      "142/224, train_loss: 0.1629, step time: 0.3822\n",
      "143/224, train_loss: 0.1100, step time: 0.3177\n",
      "144/224, train_loss: 0.1194, step time: 0.3175\n",
      "145/224, train_loss: 0.1677, step time: 0.3123\n",
      "146/224, train_loss: 0.1944, step time: 0.3149\n",
      "147/224, train_loss: 0.0888, step time: 0.4107\n",
      "148/224, train_loss: 0.1341, step time: 0.3755\n",
      "149/224, train_loss: 0.1779, step time: 0.3174\n",
      "150/224, train_loss: 0.1382, step time: 0.3699\n",
      "151/224, train_loss: 0.3346, step time: 0.3127\n",
      "152/224, train_loss: 0.0864, step time: 0.3144\n",
      "153/224, train_loss: 0.0898, step time: 0.3151\n",
      "154/224, train_loss: 0.1341, step time: 0.3875\n",
      "155/224, train_loss: 0.3037, step time: 0.3149\n",
      "156/224, train_loss: 0.3679, step time: 0.4061\n",
      "157/224, train_loss: 0.1141, step time: 0.4141\n",
      "158/224, train_loss: 0.2647, step time: 0.4012\n",
      "159/224, train_loss: 0.1283, step time: 0.3177\n",
      "160/224, train_loss: 0.1827, step time: 0.3788\n",
      "161/224, train_loss: 0.1223, step time: 0.3672\n",
      "162/224, train_loss: 0.2057, step time: 0.3966\n",
      "163/224, train_loss: 0.4176, step time: 0.3873\n",
      "164/224, train_loss: 0.2120, step time: 0.3700\n",
      "165/224, train_loss: 0.3458, step time: 0.3913\n",
      "166/224, train_loss: 0.1425, step time: 0.3173\n",
      "167/224, train_loss: 0.1488, step time: 0.4024\n",
      "168/224, train_loss: 0.1258, step time: 0.3847\n",
      "169/224, train_loss: 0.3675, step time: 0.3157\n",
      "170/224, train_loss: 0.2569, step time: 0.3931\n",
      "171/224, train_loss: 0.1807, step time: 0.3953\n",
      "172/224, train_loss: 0.0677, step time: 0.3864\n",
      "173/224, train_loss: 0.2321, step time: 0.3769\n",
      "174/224, train_loss: 0.1038, step time: 0.3151\n",
      "175/224, train_loss: 0.2976, step time: 0.3126\n",
      "176/224, train_loss: 0.0914, step time: 0.3172\n",
      "177/224, train_loss: 0.1904, step time: 0.3810\n",
      "178/224, train_loss: 0.2600, step time: 0.3143\n",
      "179/224, train_loss: 0.3106, step time: 0.3738\n",
      "180/224, train_loss: 0.1641, step time: 0.4058\n",
      "181/224, train_loss: 0.0671, step time: 0.3667\n",
      "182/224, train_loss: 0.1367, step time: 0.3160\n",
      "183/224, train_loss: 0.1808, step time: 0.3146\n",
      "184/224, train_loss: 0.3626, step time: 0.3820\n",
      "185/224, train_loss: 0.0881, step time: 0.3173\n",
      "186/224, train_loss: 0.3645, step time: 0.3677\n",
      "187/224, train_loss: 0.1742, step time: 0.3166\n",
      "188/224, train_loss: 0.3115, step time: 0.3140\n",
      "189/224, train_loss: 0.0976, step time: 0.3166\n",
      "190/224, train_loss: 0.1388, step time: 0.3969\n",
      "191/224, train_loss: 0.1041, step time: 0.3995\n",
      "192/224, train_loss: 0.1433, step time: 0.3157\n",
      "193/224, train_loss: 0.3047, step time: 0.3139\n",
      "194/224, train_loss: 0.1334, step time: 0.3936\n",
      "195/224, train_loss: 0.2229, step time: 0.4050\n",
      "196/224, train_loss: 0.2538, step time: 0.3149\n",
      "197/224, train_loss: 0.2480, step time: 0.3901\n",
      "198/224, train_loss: 0.1380, step time: 0.3925\n",
      "199/224, train_loss: 0.1765, step time: 0.3147\n",
      "200/224, train_loss: 0.4160, step time: 0.3170\n",
      "201/224, train_loss: 0.1030, step time: 0.3169\n",
      "202/224, train_loss: 0.2237, step time: 0.3696\n",
      "203/224, train_loss: 0.1218, step time: 0.3168\n",
      "204/224, train_loss: 0.1038, step time: 0.3140\n",
      "205/224, train_loss: 0.1120, step time: 0.3138\n",
      "206/224, train_loss: 0.1555, step time: 0.3771\n",
      "207/224, train_loss: 0.3513, step time: 0.3122\n",
      "208/224, train_loss: 0.1008, step time: 0.3811\n",
      "209/224, train_loss: 0.1196, step time: 0.3142\n",
      "210/224, train_loss: 0.0751, step time: 0.3167\n",
      "211/224, train_loss: 0.2085, step time: 0.3890\n",
      "212/224, train_loss: 0.1073, step time: 0.3162\n",
      "213/224, train_loss: 0.1773, step time: 0.3168\n",
      "214/224, train_loss: 0.1516, step time: 0.3793\n",
      "215/224, train_loss: 0.1089, step time: 0.3172\n",
      "216/224, train_loss: 0.1216, step time: 0.3140\n",
      "217/224, train_loss: 0.0750, step time: 0.3778\n",
      "218/224, train_loss: 0.2081, step time: 0.3143\n",
      "219/224, train_loss: 0.1850, step time: 0.3139\n",
      "220/224, train_loss: 0.0955, step time: 0.3150\n",
      "221/224, train_loss: 0.2165, step time: 0.3870\n",
      "222/224, train_loss: 0.4547, step time: 0.3681\n",
      "223/224, train_loss: 0.1682, step time: 0.3170\n",
      "224/224, train_loss: 0.1126, step time: 0.3148\n",
      "epoch 43 average loss: 0.2018\n",
      "current epoch: 43 current mean dice: 0.6959 class1: 0.9993 class2: 0.7359 class3: 0.3525\n",
      "best mean dice: 0.7003 at epoch: 38\n",
      "time consuming of epoch 43 is: 754.0992\n",
      "hello\n",
      "----------\n",
      "epoch 44/100\n",
      "1/224, train_loss: 0.1283, step time: 0.3815\n",
      "2/224, train_loss: 0.0829, step time: 0.3635\n",
      "3/224, train_loss: 0.1017, step time: 0.3166\n",
      "4/224, train_loss: 0.1456, step time: 0.3848\n",
      "5/224, train_loss: 0.0835, step time: 0.3119\n",
      "6/224, train_loss: 0.1624, step time: 0.3149\n",
      "7/224, train_loss: 0.0981, step time: 0.3129\n",
      "8/224, train_loss: 0.0925, step time: 0.3144\n",
      "9/224, train_loss: 0.3809, step time: 0.4076\n",
      "10/224, train_loss: 0.1248, step time: 0.3168\n",
      "11/224, train_loss: 0.1695, step time: 0.4071\n",
      "12/224, train_loss: 0.1440, step time: 0.3768\n",
      "13/224, train_loss: 0.1166, step time: 0.3915\n",
      "14/224, train_loss: 0.0775, step time: 0.3138\n",
      "15/224, train_loss: 0.1744, step time: 0.3143\n",
      "16/224, train_loss: 0.2099, step time: 0.4020\n",
      "17/224, train_loss: 0.1286, step time: 0.3166\n",
      "18/224, train_loss: 0.1767, step time: 0.3146\n",
      "19/224, train_loss: 0.0883, step time: 0.3990\n",
      "20/224, train_loss: 0.3594, step time: 0.3978\n",
      "21/224, train_loss: 0.1517, step time: 0.3119\n",
      "22/224, train_loss: 0.0960, step time: 0.4069\n",
      "23/224, train_loss: 0.2177, step time: 0.3142\n",
      "24/224, train_loss: 0.1159, step time: 0.3143\n",
      "25/224, train_loss: 0.2218, step time: 0.4082\n",
      "26/224, train_loss: 0.0975, step time: 0.3147\n",
      "27/224, train_loss: 0.4261, step time: 0.3886\n",
      "28/224, train_loss: 0.3695, step time: 0.4028\n",
      "29/224, train_loss: 0.0955, step time: 0.3121\n",
      "30/224, train_loss: 0.0714, step time: 0.3139\n",
      "31/224, train_loss: 0.3011, step time: 0.3142\n",
      "32/224, train_loss: 0.3048, step time: 0.3808\n",
      "33/224, train_loss: 0.1475, step time: 0.3815\n",
      "34/224, train_loss: 0.3039, step time: 0.3174\n",
      "35/224, train_loss: 0.3854, step time: 0.3147\n",
      "36/224, train_loss: 0.1342, step time: 0.3161\n",
      "37/224, train_loss: 0.1615, step time: 0.3138\n",
      "38/224, train_loss: 0.1049, step time: 0.3139\n",
      "39/224, train_loss: 0.2622, step time: 0.3143\n",
      "40/224, train_loss: 0.0906, step time: 0.3149\n",
      "41/224, train_loss: 0.1613, step time: 0.3154\n",
      "42/224, train_loss: 0.3318, step time: 0.3148\n",
      "43/224, train_loss: 0.1496, step time: 0.3162\n",
      "44/224, train_loss: 0.1824, step time: 0.4099\n",
      "45/224, train_loss: 0.1039, step time: 0.3145\n",
      "46/224, train_loss: 0.0794, step time: 0.4100\n",
      "47/224, train_loss: 0.0907, step time: 0.3145\n",
      "48/224, train_loss: 0.1314, step time: 0.4137\n",
      "49/224, train_loss: 0.0812, step time: 0.3149\n",
      "50/224, train_loss: 0.2025, step time: 0.3143\n",
      "51/224, train_loss: 0.2396, step time: 0.3688\n",
      "52/224, train_loss: 0.1587, step time: 0.3149\n",
      "53/224, train_loss: 0.1507, step time: 0.3151\n",
      "54/224, train_loss: 0.1855, step time: 0.3145\n",
      "55/224, train_loss: 0.3387, step time: 0.4080\n",
      "56/224, train_loss: 0.2420, step time: 0.3748\n",
      "57/224, train_loss: 0.2653, step time: 0.3170\n",
      "58/224, train_loss: 0.1108, step time: 0.4003\n",
      "59/224, train_loss: 0.1005, step time: 0.3145\n",
      "60/224, train_loss: 0.0832, step time: 0.3128\n",
      "61/224, train_loss: 0.1435, step time: 0.3122\n",
      "62/224, train_loss: 0.0858, step time: 0.3138\n",
      "63/224, train_loss: 0.1015, step time: 0.3121\n",
      "64/224, train_loss: 0.0987, step time: 0.3125\n",
      "65/224, train_loss: 0.1868, step time: 0.3168\n",
      "66/224, train_loss: 0.1650, step time: 0.3144\n",
      "67/224, train_loss: 0.1275, step time: 0.3147\n",
      "68/224, train_loss: 0.3716, step time: 0.3708\n",
      "69/224, train_loss: 0.1022, step time: 0.3166\n",
      "70/224, train_loss: 0.0919, step time: 0.3138\n",
      "71/224, train_loss: 0.0945, step time: 0.3141\n",
      "72/224, train_loss: 0.1562, step time: 0.3145\n",
      "73/224, train_loss: 0.1616, step time: 0.3675\n",
      "74/224, train_loss: 0.1535, step time: 0.3147\n",
      "75/224, train_loss: 0.0844, step time: 0.3168\n",
      "76/224, train_loss: 0.4388, step time: 0.3717\n",
      "77/224, train_loss: 0.1186, step time: 0.3891\n",
      "78/224, train_loss: 0.1112, step time: 0.3776\n",
      "79/224, train_loss: 0.2542, step time: 0.4123\n",
      "80/224, train_loss: 0.1042, step time: 0.3170\n",
      "81/224, train_loss: 0.1040, step time: 0.3128\n",
      "82/224, train_loss: 0.1625, step time: 0.3147\n",
      "83/224, train_loss: 0.0802, step time: 0.3160\n",
      "84/224, train_loss: 0.1017, step time: 0.3122\n",
      "85/224, train_loss: 0.1607, step time: 0.3911\n",
      "86/224, train_loss: 0.3395, step time: 0.3870\n",
      "87/224, train_loss: 0.0739, step time: 0.3130\n",
      "88/224, train_loss: 0.0932, step time: 0.3121\n",
      "89/224, train_loss: 0.2283, step time: 0.4068\n",
      "90/224, train_loss: 0.1787, step time: 0.3775\n",
      "91/224, train_loss: 0.2555, step time: 0.3772\n",
      "92/224, train_loss: 0.1458, step time: 0.3119\n",
      "93/224, train_loss: 0.1234, step time: 0.4133\n",
      "94/224, train_loss: 0.1598, step time: 0.3154\n",
      "95/224, train_loss: 0.1022, step time: 0.3154\n",
      "96/224, train_loss: 0.1149, step time: 0.3177\n",
      "97/224, train_loss: 0.1726, step time: 0.3144\n",
      "98/224, train_loss: 0.1558, step time: 0.3140\n",
      "99/224, train_loss: 0.3495, step time: 0.3862\n",
      "100/224, train_loss: 0.1172, step time: 0.4070\n",
      "101/224, train_loss: 0.2222, step time: 0.3820\n",
      "102/224, train_loss: 0.3182, step time: 0.3943\n",
      "103/224, train_loss: 0.1725, step time: 0.3123\n",
      "104/224, train_loss: 0.0844, step time: 0.3153\n",
      "105/224, train_loss: 0.1822, step time: 0.4093\n",
      "106/224, train_loss: 0.0951, step time: 0.3126\n",
      "107/224, train_loss: 0.2788, step time: 0.3945\n",
      "108/224, train_loss: 0.1964, step time: 0.3145\n",
      "109/224, train_loss: 0.1945, step time: 0.3149\n",
      "110/224, train_loss: 0.1239, step time: 0.3742\n",
      "111/224, train_loss: 0.2934, step time: 0.3655\n",
      "112/224, train_loss: 0.1785, step time: 0.3140\n",
      "113/224, train_loss: 0.0888, step time: 0.3168\n",
      "114/224, train_loss: 0.2254, step time: 0.4099\n",
      "115/224, train_loss: 0.2712, step time: 0.3152\n",
      "116/224, train_loss: 0.1111, step time: 0.3919\n",
      "117/224, train_loss: 0.1946, step time: 0.3148\n",
      "118/224, train_loss: 0.0993, step time: 0.3170\n",
      "119/224, train_loss: 0.1309, step time: 0.3171\n",
      "120/224, train_loss: 0.2640, step time: 0.4081\n",
      "121/224, train_loss: 0.2484, step time: 0.3761\n",
      "122/224, train_loss: 0.2947, step time: 0.3156\n",
      "123/224, train_loss: 0.2396, step time: 0.3657\n",
      "124/224, train_loss: 0.3671, step time: 0.3124\n",
      "125/224, train_loss: 0.1400, step time: 0.3147\n",
      "126/224, train_loss: 0.2302, step time: 0.4073\n",
      "127/224, train_loss: 0.1207, step time: 0.3910\n",
      "128/224, train_loss: 0.1034, step time: 0.3147\n",
      "129/224, train_loss: 0.1345, step time: 0.3126\n",
      "130/224, train_loss: 0.4269, step time: 0.3763\n",
      "131/224, train_loss: 0.2316, step time: 0.3165\n",
      "132/224, train_loss: 0.2006, step time: 0.3773\n",
      "133/224, train_loss: 0.1532, step time: 0.3843\n",
      "134/224, train_loss: 0.3549, step time: 0.3848\n",
      "135/224, train_loss: 0.3681, step time: 0.3696\n",
      "136/224, train_loss: 0.2418, step time: 0.3140\n",
      "137/224, train_loss: 0.0943, step time: 0.3138\n",
      "138/224, train_loss: 0.1856, step time: 0.3157\n",
      "139/224, train_loss: 0.1379, step time: 0.3919\n",
      "140/224, train_loss: 0.1777, step time: 0.3872\n",
      "141/224, train_loss: 0.1280, step time: 0.3169\n",
      "142/224, train_loss: 0.0971, step time: 0.3650\n",
      "143/224, train_loss: 0.0844, step time: 0.3148\n",
      "144/224, train_loss: 0.2812, step time: 0.3143\n",
      "145/224, train_loss: 0.0969, step time: 0.3142\n",
      "146/224, train_loss: 0.2435, step time: 0.3143\n",
      "147/224, train_loss: 0.1126, step time: 0.3165\n",
      "148/224, train_loss: 0.1045, step time: 0.3171\n",
      "149/224, train_loss: 0.0760, step time: 0.3143\n",
      "150/224, train_loss: 0.2816, step time: 0.3913\n",
      "151/224, train_loss: 0.0702, step time: 0.3961\n",
      "152/224, train_loss: 0.0969, step time: 0.3165\n",
      "153/224, train_loss: 0.1816, step time: 0.3651\n",
      "154/224, train_loss: 0.1396, step time: 0.3162\n",
      "155/224, train_loss: 0.1314, step time: 0.3142\n",
      "156/224, train_loss: 0.3614, step time: 0.4107\n",
      "157/224, train_loss: 0.1885, step time: 0.3151\n",
      "158/224, train_loss: 0.1281, step time: 0.3888\n",
      "159/224, train_loss: 0.1766, step time: 0.3128\n",
      "160/224, train_loss: 0.0656, step time: 0.3148\n",
      "161/224, train_loss: 0.3932, step time: 0.3168\n",
      "162/224, train_loss: 0.3062, step time: 0.4121\n",
      "163/224, train_loss: 0.0761, step time: 0.3887\n",
      "164/224, train_loss: 0.0781, step time: 0.3675\n",
      "165/224, train_loss: 0.0971, step time: 0.3140\n",
      "166/224, train_loss: 0.1525, step time: 0.3877\n",
      "167/224, train_loss: 0.2540, step time: 0.4074\n",
      "168/224, train_loss: 0.1167, step time: 0.3148\n",
      "169/224, train_loss: 0.1659, step time: 0.3145\n",
      "170/224, train_loss: 0.1495, step time: 0.3159\n",
      "171/224, train_loss: 0.1699, step time: 0.3147\n",
      "172/224, train_loss: 0.3508, step time: 0.3146\n",
      "173/224, train_loss: 0.2790, step time: 0.3116\n",
      "174/224, train_loss: 0.4353, step time: 0.3687\n",
      "175/224, train_loss: 0.3768, step time: 0.3942\n",
      "176/224, train_loss: 0.0953, step time: 0.3755\n",
      "177/224, train_loss: 0.0689, step time: 0.3170\n",
      "178/224, train_loss: 0.1493, step time: 0.3644\n",
      "179/224, train_loss: 0.2882, step time: 0.3128\n",
      "180/224, train_loss: 0.1114, step time: 0.3144\n",
      "181/224, train_loss: 0.3594, step time: 0.3142\n",
      "182/224, train_loss: 0.3360, step time: 0.3811\n",
      "183/224, train_loss: 0.2206, step time: 0.3824\n",
      "184/224, train_loss: 0.0826, step time: 0.3124\n",
      "185/224, train_loss: 0.2700, step time: 0.3952\n",
      "186/224, train_loss: 0.1334, step time: 0.3149\n",
      "187/224, train_loss: 0.1029, step time: 0.3650\n",
      "188/224, train_loss: 0.1257, step time: 0.3672\n",
      "189/224, train_loss: 0.1241, step time: 0.3157\n",
      "190/224, train_loss: 0.2314, step time: 0.3172\n",
      "191/224, train_loss: 0.1765, step time: 0.3782\n",
      "192/224, train_loss: 0.0548, step time: 0.3167\n",
      "193/224, train_loss: 0.0921, step time: 0.3789\n",
      "194/224, train_loss: 0.0998, step time: 0.4055\n",
      "195/224, train_loss: 0.1543, step time: 0.3818\n",
      "196/224, train_loss: 0.1298, step time: 0.3976\n",
      "197/224, train_loss: 0.3366, step time: 0.3964\n",
      "198/224, train_loss: 0.1277, step time: 0.3164\n",
      "199/224, train_loss: 0.0679, step time: 0.3739\n",
      "200/224, train_loss: 0.1292, step time: 0.3652\n",
      "201/224, train_loss: 0.1127, step time: 0.3150\n",
      "202/224, train_loss: 0.1293, step time: 0.3658\n",
      "203/224, train_loss: 0.1579, step time: 0.3131\n",
      "204/224, train_loss: 0.1299, step time: 0.3134\n",
      "205/224, train_loss: 0.3552, step time: 0.3143\n",
      "206/224, train_loss: 0.2222, step time: 0.3737\n",
      "207/224, train_loss: 0.1937, step time: 0.3720\n",
      "208/224, train_loss: 0.2885, step time: 0.3891\n",
      "209/224, train_loss: 0.0883, step time: 0.3139\n",
      "210/224, train_loss: 0.1017, step time: 0.3161\n",
      "211/224, train_loss: 0.0891, step time: 0.3140\n",
      "212/224, train_loss: 0.1249, step time: 0.3165\n",
      "213/224, train_loss: 0.1686, step time: 0.3662\n",
      "214/224, train_loss: 0.1154, step time: 0.3817\n",
      "215/224, train_loss: 0.1693, step time: 0.3163\n",
      "216/224, train_loss: 0.2263, step time: 0.3763\n",
      "217/224, train_loss: 0.2454, step time: 0.3972\n",
      "218/224, train_loss: 0.1311, step time: 0.3157\n",
      "219/224, train_loss: 0.1294, step time: 0.3173\n",
      "220/224, train_loss: 0.2128, step time: 0.3717\n",
      "221/224, train_loss: 0.1447, step time: 0.3920\n",
      "222/224, train_loss: 0.0718, step time: 0.3825\n",
      "223/224, train_loss: 0.3978, step time: 0.3140\n",
      "224/224, train_loss: 0.3602, step time: 0.3837\n",
      "epoch 44 average loss: 0.1782\n",
      "current epoch: 44 current mean dice: 0.6911 class1: 0.9993 class2: 0.7137 class3: 0.3602\n",
      "best mean dice: 0.7003 at epoch: 38\n",
      "time consuming of epoch 44 is: 659.4256\n",
      "hello\n",
      "----------\n",
      "epoch 45/100\n",
      "1/224, train_loss: 0.1758, step time: 0.3892\n",
      "2/224, train_loss: 0.0624, step time: 0.3138\n",
      "3/224, train_loss: 0.3512, step time: 0.3811\n",
      "4/224, train_loss: 0.3585, step time: 0.3169\n",
      "5/224, train_loss: 0.1284, step time: 0.3148\n",
      "6/224, train_loss: 0.2563, step time: 0.3151\n",
      "7/224, train_loss: 0.0695, step time: 0.3143\n",
      "8/224, train_loss: 0.0806, step time: 0.4038\n",
      "9/224, train_loss: 0.0882, step time: 0.4107\n",
      "10/224, train_loss: 0.1044, step time: 0.3163\n",
      "11/224, train_loss: 0.1274, step time: 0.3137\n",
      "12/224, train_loss: 0.4051, step time: 0.3754\n",
      "13/224, train_loss: 0.1144, step time: 0.3120\n",
      "14/224, train_loss: 0.1443, step time: 0.3907\n",
      "15/224, train_loss: 0.0766, step time: 0.3170\n",
      "16/224, train_loss: 0.1042, step time: 0.3161\n",
      "17/224, train_loss: 0.2205, step time: 0.3731\n",
      "18/224, train_loss: 0.1303, step time: 0.4009\n",
      "19/224, train_loss: 0.2219, step time: 0.3141\n",
      "20/224, train_loss: 0.3577, step time: 0.3145\n",
      "21/224, train_loss: 0.0679, step time: 0.3172\n",
      "22/224, train_loss: 0.0983, step time: 0.3140\n",
      "23/224, train_loss: 0.0990, step time: 0.3146\n",
      "24/224, train_loss: 0.0722, step time: 0.3150\n",
      "25/224, train_loss: 0.1643, step time: 0.3150\n",
      "26/224, train_loss: 0.1703, step time: 0.3147\n",
      "27/224, train_loss: 0.1542, step time: 0.3767\n",
      "28/224, train_loss: 0.1350, step time: 0.3937\n",
      "29/224, train_loss: 0.1392, step time: 0.3144\n",
      "30/224, train_loss: 0.3830, step time: 0.3140\n",
      "31/224, train_loss: 0.0939, step time: 0.3145\n",
      "32/224, train_loss: 0.1318, step time: 0.3153\n",
      "33/224, train_loss: 0.1037, step time: 0.3171\n",
      "34/224, train_loss: 0.2056, step time: 0.3803\n",
      "35/224, train_loss: 0.1546, step time: 0.4002\n",
      "36/224, train_loss: 0.1692, step time: 0.3867\n",
      "37/224, train_loss: 0.1161, step time: 0.3165\n",
      "38/224, train_loss: 0.2462, step time: 0.3161\n",
      "39/224, train_loss: 0.3328, step time: 0.3168\n",
      "40/224, train_loss: 0.2194, step time: 0.3707\n",
      "41/224, train_loss: 0.3123, step time: 0.3148\n",
      "42/224, train_loss: 0.0923, step time: 0.4096\n",
      "43/224, train_loss: 0.0546, step time: 0.3166\n",
      "44/224, train_loss: 0.1664, step time: 0.3872\n",
      "45/224, train_loss: 0.0804, step time: 0.3888\n",
      "46/224, train_loss: 0.0948, step time: 0.3889\n",
      "47/224, train_loss: 0.1198, step time: 0.3119\n",
      "48/224, train_loss: 0.1523, step time: 0.3136\n",
      "49/224, train_loss: 0.1907, step time: 0.3762\n",
      "50/224, train_loss: 0.1089, step time: 0.3680\n",
      "51/224, train_loss: 0.1431, step time: 0.3148\n",
      "52/224, train_loss: 0.1950, step time: 0.3810\n",
      "53/224, train_loss: 0.0649, step time: 0.3727\n",
      "54/224, train_loss: 0.2287, step time: 0.4096\n",
      "55/224, train_loss: 0.3480, step time: 0.3128\n",
      "56/224, train_loss: 0.1803, step time: 0.3141\n",
      "57/224, train_loss: 0.1501, step time: 0.3911\n",
      "58/224, train_loss: 0.3012, step time: 0.3117\n",
      "59/224, train_loss: 0.3523, step time: 0.3141\n",
      "60/224, train_loss: 0.3586, step time: 0.3143\n",
      "61/224, train_loss: 0.0837, step time: 0.3813\n",
      "62/224, train_loss: 0.1345, step time: 0.3119\n",
      "63/224, train_loss: 0.1617, step time: 0.3150\n",
      "64/224, train_loss: 0.0937, step time: 0.4006\n",
      "65/224, train_loss: 0.1025, step time: 0.3715\n",
      "66/224, train_loss: 0.1167, step time: 0.3146\n",
      "67/224, train_loss: 0.1583, step time: 0.3119\n",
      "68/224, train_loss: 0.1569, step time: 0.3747\n",
      "69/224, train_loss: 0.1385, step time: 0.3164\n",
      "70/224, train_loss: 0.1273, step time: 0.3804\n",
      "71/224, train_loss: 0.2727, step time: 0.3154\n",
      "72/224, train_loss: 0.4808, step time: 0.3927\n",
      "73/224, train_loss: 0.0971, step time: 0.3162\n",
      "74/224, train_loss: 0.1149, step time: 0.3166\n",
      "75/224, train_loss: 0.0765, step time: 0.3790\n",
      "76/224, train_loss: 0.3299, step time: 0.4004\n",
      "77/224, train_loss: 0.1850, step time: 0.3886\n",
      "78/224, train_loss: 0.2476, step time: 0.3718\n",
      "79/224, train_loss: 0.3198, step time: 0.3170\n",
      "80/224, train_loss: 0.1370, step time: 0.4101\n",
      "81/224, train_loss: 0.1508, step time: 0.3174\n",
      "82/224, train_loss: 0.3666, step time: 0.3174\n",
      "83/224, train_loss: 0.2348, step time: 0.3991\n",
      "84/224, train_loss: 0.2166, step time: 0.3149\n",
      "85/224, train_loss: 0.1541, step time: 0.3170\n",
      "86/224, train_loss: 0.3876, step time: 0.3957\n",
      "87/224, train_loss: 0.0715, step time: 0.3983\n",
      "88/224, train_loss: 0.2515, step time: 0.3922\n",
      "89/224, train_loss: 0.2142, step time: 0.4007\n",
      "90/224, train_loss: 0.2089, step time: 0.4063\n",
      "91/224, train_loss: 0.0932, step time: 0.3143\n",
      "92/224, train_loss: 0.1725, step time: 0.3833\n",
      "93/224, train_loss: 0.2095, step time: 0.3151\n",
      "94/224, train_loss: 0.1927, step time: 0.3172\n",
      "95/224, train_loss: 0.1779, step time: 0.3915\n",
      "96/224, train_loss: 0.1073, step time: 0.3143\n",
      "97/224, train_loss: 0.3815, step time: 0.3670\n",
      "98/224, train_loss: 0.1850, step time: 0.3174\n",
      "99/224, train_loss: 0.1216, step time: 0.3152\n",
      "100/224, train_loss: 0.4545, step time: 0.3716\n",
      "101/224, train_loss: 0.2198, step time: 0.4025\n",
      "102/224, train_loss: 0.2498, step time: 0.3808\n",
      "103/224, train_loss: 0.1920, step time: 0.3796\n",
      "104/224, train_loss: 0.1147, step time: 0.3879\n",
      "105/224, train_loss: 0.1478, step time: 0.3148\n",
      "106/224, train_loss: 0.0998, step time: 0.3175\n",
      "107/224, train_loss: 0.3202, step time: 0.3954\n",
      "108/224, train_loss: 0.1664, step time: 0.3144\n",
      "109/224, train_loss: 0.3446, step time: 0.4065\n",
      "110/224, train_loss: 0.1906, step time: 0.3684\n",
      "111/224, train_loss: 0.1160, step time: 0.3152\n",
      "112/224, train_loss: 0.0922, step time: 0.3146\n",
      "113/224, train_loss: 0.1748, step time: 0.3866\n",
      "114/224, train_loss: 0.1316, step time: 0.3165\n",
      "115/224, train_loss: 0.3597, step time: 0.3171\n",
      "116/224, train_loss: 0.3222, step time: 0.3986\n",
      "117/224, train_loss: 0.1510, step time: 0.4027\n",
      "118/224, train_loss: 0.2779, step time: 0.3710\n",
      "119/224, train_loss: 0.1184, step time: 0.3846\n",
      "120/224, train_loss: 0.3000, step time: 0.3133\n",
      "121/224, train_loss: 0.0926, step time: 0.3179\n",
      "122/224, train_loss: 0.1122, step time: 0.3845\n",
      "123/224, train_loss: 0.1126, step time: 0.3156\n",
      "124/224, train_loss: 0.0879, step time: 0.3171\n",
      "125/224, train_loss: 0.2400, step time: 0.3838\n",
      "126/224, train_loss: 0.0928, step time: 0.3135\n",
      "127/224, train_loss: 0.1542, step time: 0.3687\n",
      "128/224, train_loss: 0.1982, step time: 0.3162\n",
      "129/224, train_loss: 0.1161, step time: 0.3164\n",
      "130/224, train_loss: 0.0770, step time: 0.3137\n",
      "131/224, train_loss: 0.1424, step time: 0.3178\n",
      "132/224, train_loss: 0.1060, step time: 0.3806\n",
      "133/224, train_loss: 0.1946, step time: 0.3868\n",
      "134/224, train_loss: 0.2429, step time: 0.3153\n",
      "135/224, train_loss: 0.1383, step time: 0.3135\n",
      "136/224, train_loss: 0.1125, step time: 0.3948\n",
      "137/224, train_loss: 0.1600, step time: 0.3152\n",
      "138/224, train_loss: 0.2021, step time: 0.3695\n",
      "139/224, train_loss: 0.1029, step time: 0.3651\n",
      "140/224, train_loss: 0.1783, step time: 0.3165\n",
      "141/224, train_loss: 0.0829, step time: 0.3183\n",
      "142/224, train_loss: 0.0789, step time: 0.3158\n",
      "143/224, train_loss: 0.0717, step time: 0.3175\n",
      "144/224, train_loss: 0.2000, step time: 0.3788\n",
      "145/224, train_loss: 0.1756, step time: 0.3187\n",
      "146/224, train_loss: 0.1743, step time: 0.3162\n",
      "147/224, train_loss: 0.1729, step time: 0.4099\n",
      "148/224, train_loss: 0.1470, step time: 0.3164\n",
      "149/224, train_loss: 0.2327, step time: 0.3709\n",
      "150/224, train_loss: 0.1117, step time: 0.3181\n",
      "151/224, train_loss: 0.2692, step time: 0.3180\n",
      "152/224, train_loss: 0.1151, step time: 0.3155\n",
      "153/224, train_loss: 0.3223, step time: 0.3155\n",
      "154/224, train_loss: 0.0820, step time: 0.3156\n",
      "155/224, train_loss: 0.1016, step time: 0.3750\n",
      "156/224, train_loss: 0.0907, step time: 0.3182\n",
      "157/224, train_loss: 0.1093, step time: 0.3180\n",
      "158/224, train_loss: 0.2140, step time: 0.3885\n",
      "159/224, train_loss: 0.1751, step time: 0.3175\n",
      "160/224, train_loss: 0.1558, step time: 0.3157\n",
      "161/224, train_loss: 0.2238, step time: 0.3148\n",
      "162/224, train_loss: 0.1657, step time: 0.3825\n",
      "163/224, train_loss: 0.2044, step time: 0.3186\n",
      "164/224, train_loss: 0.3538, step time: 0.3968\n",
      "165/224, train_loss: 0.0906, step time: 0.3160\n",
      "166/224, train_loss: 0.1270, step time: 0.3780\n",
      "167/224, train_loss: 0.1230, step time: 0.3731\n",
      "168/224, train_loss: 0.1333, step time: 0.3159\n",
      "169/224, train_loss: 0.1739, step time: 0.3153\n",
      "170/224, train_loss: 0.2143, step time: 0.3974\n",
      "171/224, train_loss: 0.1110, step time: 0.3181\n",
      "172/224, train_loss: 0.1204, step time: 0.4132\n",
      "173/224, train_loss: 0.1407, step time: 0.3710\n",
      "174/224, train_loss: 0.1598, step time: 0.3163\n",
      "175/224, train_loss: 0.0911, step time: 0.3165\n",
      "176/224, train_loss: 0.2121, step time: 0.4029\n",
      "177/224, train_loss: 0.1308, step time: 0.3162\n",
      "178/224, train_loss: 0.2042, step time: 0.3159\n",
      "179/224, train_loss: 0.0896, step time: 0.3178\n",
      "180/224, train_loss: 0.1480, step time: 0.3678\n",
      "181/224, train_loss: 0.1157, step time: 0.3153\n",
      "182/224, train_loss: 0.1367, step time: 0.3781\n",
      "183/224, train_loss: 0.1378, step time: 0.3171\n",
      "184/224, train_loss: 0.2725, step time: 0.3160\n",
      "185/224, train_loss: 0.1065, step time: 0.3687\n",
      "186/224, train_loss: 0.0711, step time: 0.3153\n",
      "187/224, train_loss: 0.1508, step time: 0.3677\n",
      "188/224, train_loss: 0.1919, step time: 0.3829\n",
      "189/224, train_loss: 0.0985, step time: 0.3158\n",
      "190/224, train_loss: 0.1259, step time: 0.3161\n",
      "191/224, train_loss: 0.0999, step time: 0.3187\n",
      "192/224, train_loss: 0.3627, step time: 0.3724\n",
      "193/224, train_loss: 0.1386, step time: 0.3145\n",
      "194/224, train_loss: 0.2078, step time: 0.3813\n",
      "195/224, train_loss: 0.2382, step time: 0.3857\n",
      "196/224, train_loss: 0.2693, step time: 0.3734\n",
      "197/224, train_loss: 0.0919, step time: 0.3180\n",
      "198/224, train_loss: 0.2390, step time: 0.3928\n",
      "199/224, train_loss: 0.0994, step time: 0.3169\n",
      "200/224, train_loss: 0.1678, step time: 0.3916\n",
      "201/224, train_loss: 0.1366, step time: 0.3153\n",
      "202/224, train_loss: 0.1750, step time: 0.3170\n",
      "203/224, train_loss: 0.2087, step time: 0.3859\n",
      "204/224, train_loss: 0.1007, step time: 0.3975\n",
      "205/224, train_loss: 0.1051, step time: 0.3178\n",
      "206/224, train_loss: 0.1241, step time: 0.3150\n",
      "207/224, train_loss: 0.0932, step time: 0.3146\n",
      "208/224, train_loss: 0.0524, step time: 0.3865\n",
      "209/224, train_loss: 0.2537, step time: 0.3659\n",
      "210/224, train_loss: 0.2385, step time: 0.3663\n",
      "211/224, train_loss: 0.1744, step time: 0.3150\n",
      "212/224, train_loss: 0.2171, step time: 0.4045\n",
      "213/224, train_loss: 0.3502, step time: 0.3864\n",
      "214/224, train_loss: 0.2097, step time: 0.3755\n",
      "215/224, train_loss: 0.0783, step time: 0.3803\n",
      "216/224, train_loss: 0.0874, step time: 0.3177\n",
      "217/224, train_loss: 0.1349, step time: 0.3175\n",
      "218/224, train_loss: 0.1699, step time: 0.3152\n",
      "219/224, train_loss: 0.3135, step time: 0.3973\n",
      "220/224, train_loss: 0.1016, step time: 0.3151\n",
      "221/224, train_loss: 0.1061, step time: 0.3664\n",
      "222/224, train_loss: 0.1403, step time: 0.3153\n",
      "223/224, train_loss: 0.1111, step time: 0.3952\n",
      "224/224, train_loss: 0.1600, step time: 0.3991\n",
      "epoch 45 average loss: 0.1734\n",
      "current epoch: 45 current mean dice: 0.7031 class1: 0.9993 class2: 0.7363 class3: 0.3736\n",
      "best mean dice: 0.7031 at epoch: 45\n",
      "time consuming of epoch 45 is: 652.7990\n",
      "hello\n",
      "----------\n",
      "epoch 46/100\n",
      "1/224, train_loss: 0.0886, step time: 0.3133\n",
      "2/224, train_loss: 0.0863, step time: 0.3153\n",
      "3/224, train_loss: 0.1729, step time: 0.3833\n",
      "4/224, train_loss: 0.0785, step time: 0.3155\n",
      "5/224, train_loss: 0.1044, step time: 0.3126\n",
      "6/224, train_loss: 0.3483, step time: 0.3134\n",
      "7/224, train_loss: 0.1553, step time: 0.3152\n",
      "8/224, train_loss: 0.3239, step time: 0.4006\n",
      "9/224, train_loss: 0.0578, step time: 0.3176\n",
      "10/224, train_loss: 0.0829, step time: 0.3920\n",
      "11/224, train_loss: 0.2932, step time: 0.3883\n",
      "12/224, train_loss: 0.0741, step time: 0.3683\n",
      "13/224, train_loss: 0.2811, step time: 0.3872\n",
      "14/224, train_loss: 0.2754, step time: 0.3751\n",
      "15/224, train_loss: 0.1133, step time: 0.4021\n",
      "16/224, train_loss: 0.3876, step time: 0.4070\n",
      "17/224, train_loss: 0.0745, step time: 0.4108\n",
      "18/224, train_loss: 0.1524, step time: 0.3148\n",
      "19/224, train_loss: 0.1858, step time: 0.3156\n",
      "20/224, train_loss: 0.2650, step time: 0.3156\n",
      "21/224, train_loss: 0.1325, step time: 0.3154\n",
      "22/224, train_loss: 0.2708, step time: 0.3944\n",
      "23/224, train_loss: 0.0909, step time: 0.3730\n",
      "24/224, train_loss: 0.2152, step time: 0.4014\n",
      "25/224, train_loss: 0.1315, step time: 0.3153\n",
      "26/224, train_loss: 0.2282, step time: 0.4108\n",
      "27/224, train_loss: 0.1133, step time: 0.3150\n",
      "28/224, train_loss: 0.1275, step time: 0.3966\n",
      "29/224, train_loss: 0.1812, step time: 0.3158\n",
      "30/224, train_loss: 0.1430, step time: 0.4100\n",
      "31/224, train_loss: 0.2021, step time: 0.4074\n",
      "32/224, train_loss: 0.1412, step time: 0.3154\n",
      "33/224, train_loss: 0.3464, step time: 0.3905\n",
      "34/224, train_loss: 0.1314, step time: 0.3692\n",
      "35/224, train_loss: 0.0895, step time: 0.3150\n",
      "36/224, train_loss: 0.1512, step time: 0.3170\n",
      "37/224, train_loss: 0.2556, step time: 0.3977\n",
      "38/224, train_loss: 0.2031, step time: 0.3837\n",
      "39/224, train_loss: 0.2333, step time: 0.3787\n",
      "40/224, train_loss: 0.1173, step time: 0.3899\n",
      "41/224, train_loss: 0.0893, step time: 0.3178\n",
      "42/224, train_loss: 0.3804, step time: 0.3797\n",
      "43/224, train_loss: 0.0757, step time: 0.3152\n",
      "44/224, train_loss: 0.2813, step time: 0.4008\n",
      "45/224, train_loss: 0.2060, step time: 0.3863\n",
      "46/224, train_loss: 0.1545, step time: 0.3969\n",
      "47/224, train_loss: 0.3098, step time: 0.3152\n",
      "48/224, train_loss: 0.2699, step time: 0.3150\n",
      "49/224, train_loss: 0.1624, step time: 0.3729\n",
      "50/224, train_loss: 0.1326, step time: 0.3719\n",
      "51/224, train_loss: 0.1800, step time: 0.3749\n",
      "52/224, train_loss: 0.1234, step time: 0.3165\n",
      "53/224, train_loss: 0.1169, step time: 0.3818\n",
      "54/224, train_loss: 0.1368, step time: 0.3135\n",
      "55/224, train_loss: 0.0786, step time: 0.3155\n",
      "56/224, train_loss: 0.2734, step time: 0.3152\n",
      "57/224, train_loss: 0.1389, step time: 0.4077\n",
      "58/224, train_loss: 0.1135, step time: 0.3157\n",
      "59/224, train_loss: 0.1452, step time: 0.3833\n",
      "60/224, train_loss: 0.1028, step time: 0.3762\n",
      "61/224, train_loss: 0.2749, step time: 0.3152\n",
      "62/224, train_loss: 0.2636, step time: 0.3132\n",
      "63/224, train_loss: 0.1374, step time: 0.3904\n",
      "64/224, train_loss: 0.2546, step time: 0.3162\n",
      "65/224, train_loss: 0.1460, step time: 0.3931\n",
      "66/224, train_loss: 0.1677, step time: 0.3939\n",
      "67/224, train_loss: 0.3617, step time: 0.3951\n",
      "68/224, train_loss: 0.2045, step time: 0.3184\n",
      "69/224, train_loss: 0.1248, step time: 0.3888\n",
      "70/224, train_loss: 0.1506, step time: 0.3150\n",
      "71/224, train_loss: 0.2276, step time: 0.3153\n",
      "72/224, train_loss: 0.1330, step time: 0.3155\n",
      "73/224, train_loss: 0.3343, step time: 0.3846\n",
      "74/224, train_loss: 0.1056, step time: 0.3148\n",
      "75/224, train_loss: 0.1066, step time: 0.3146\n",
      "76/224, train_loss: 0.1065, step time: 0.3143\n",
      "77/224, train_loss: 0.1559, step time: 0.4070\n",
      "78/224, train_loss: 0.1076, step time: 0.3146\n",
      "79/224, train_loss: 0.2629, step time: 0.3677\n",
      "80/224, train_loss: 0.1430, step time: 0.3678\n",
      "81/224, train_loss: 0.2031, step time: 0.3174\n",
      "82/224, train_loss: 0.0888, step time: 0.3133\n",
      "83/224, train_loss: 0.0745, step time: 0.3136\n",
      "84/224, train_loss: 0.0914, step time: 0.3961\n",
      "85/224, train_loss: 0.0858, step time: 0.3206\n",
      "86/224, train_loss: 0.1086, step time: 0.3675\n",
      "87/224, train_loss: 0.1274, step time: 0.3765\n",
      "88/224, train_loss: 0.0546, step time: 0.3183\n",
      "89/224, train_loss: 0.2359, step time: 0.3192\n",
      "90/224, train_loss: 0.2751, step time: 0.3798\n",
      "91/224, train_loss: 0.0741, step time: 0.3777\n",
      "92/224, train_loss: 0.3481, step time: 0.3164\n",
      "93/224, train_loss: 0.1215, step time: 0.3179\n",
      "94/224, train_loss: 0.2965, step time: 0.3911\n",
      "95/224, train_loss: 0.1157, step time: 0.3869\n",
      "96/224, train_loss: 0.1586, step time: 0.3170\n",
      "97/224, train_loss: 0.0797, step time: 0.3746\n",
      "98/224, train_loss: 0.2834, step time: 0.3901\n",
      "99/224, train_loss: 0.1283, step time: 0.3152\n",
      "100/224, train_loss: 0.1468, step time: 0.3174\n",
      "101/224, train_loss: 0.1948, step time: 0.3159\n",
      "102/224, train_loss: 0.2817, step time: 0.3807\n",
      "103/224, train_loss: 0.3258, step time: 0.4052\n",
      "104/224, train_loss: 0.1355, step time: 0.3187\n",
      "105/224, train_loss: 0.0984, step time: 0.3167\n",
      "106/224, train_loss: 0.0611, step time: 0.3158\n",
      "107/224, train_loss: 0.1393, step time: 0.3976\n",
      "108/224, train_loss: 0.0969, step time: 0.3165\n",
      "109/224, train_loss: 0.1887, step time: 0.3816\n",
      "110/224, train_loss: 0.0599, step time: 0.3138\n",
      "111/224, train_loss: 0.0934, step time: 0.3155\n",
      "112/224, train_loss: 0.1091, step time: 0.3958\n",
      "113/224, train_loss: 0.1132, step time: 0.4058\n",
      "114/224, train_loss: 0.1175, step time: 0.3155\n",
      "115/224, train_loss: 0.1674, step time: 0.3683\n",
      "116/224, train_loss: 0.2598, step time: 0.3861\n",
      "117/224, train_loss: 0.1651, step time: 0.3885\n",
      "118/224, train_loss: 0.1126, step time: 0.3141\n",
      "119/224, train_loss: 0.0911, step time: 0.3142\n",
      "120/224, train_loss: 0.1579, step time: 0.3866\n",
      "121/224, train_loss: 0.0821, step time: 0.3759\n",
      "122/224, train_loss: 0.1336, step time: 0.3186\n",
      "123/224, train_loss: 0.1436, step time: 0.3184\n",
      "124/224, train_loss: 0.1989, step time: 0.3799\n",
      "125/224, train_loss: 0.1352, step time: 0.3158\n",
      "126/224, train_loss: 0.2146, step time: 0.3183\n",
      "127/224, train_loss: 0.1362, step time: 0.3969\n",
      "128/224, train_loss: 0.1560, step time: 0.3939\n",
      "129/224, train_loss: 0.1207, step time: 0.3161\n",
      "130/224, train_loss: 0.0676, step time: 0.3171\n",
      "131/224, train_loss: 0.1099, step time: 0.3168\n",
      "132/224, train_loss: 0.0935, step time: 0.3157\n",
      "133/224, train_loss: 0.1560, step time: 0.3152\n",
      "134/224, train_loss: 0.0750, step time: 0.3159\n",
      "135/224, train_loss: 0.3389, step time: 0.3165\n",
      "136/224, train_loss: 0.1848, step time: 0.3181\n",
      "137/224, train_loss: 0.0912, step time: 0.3164\n",
      "138/224, train_loss: 0.1815, step time: 0.3154\n",
      "139/224, train_loss: 0.0839, step time: 0.3163\n",
      "140/224, train_loss: 0.1447, step time: 0.3137\n",
      "141/224, train_loss: 0.1003, step time: 0.3155\n",
      "142/224, train_loss: 0.1780, step time: 0.3161\n",
      "143/224, train_loss: 0.1740, step time: 0.3884\n",
      "144/224, train_loss: 0.1313, step time: 0.3175\n",
      "145/224, train_loss: 0.0995, step time: 0.4127\n",
      "146/224, train_loss: 0.2941, step time: 0.3949\n",
      "147/224, train_loss: 0.1136, step time: 0.3906\n",
      "148/224, train_loss: 0.2108, step time: 0.3674\n",
      "149/224, train_loss: 0.3951, step time: 0.4040\n",
      "150/224, train_loss: 0.1560, step time: 0.3975\n",
      "151/224, train_loss: 0.2648, step time: 0.3959\n",
      "152/224, train_loss: 0.0765, step time: 0.3182\n",
      "153/224, train_loss: 0.1140, step time: 0.3155\n",
      "154/224, train_loss: 0.1211, step time: 0.3874\n",
      "155/224, train_loss: 0.1712, step time: 0.3143\n",
      "156/224, train_loss: 0.1412, step time: 0.3691\n",
      "157/224, train_loss: 0.2952, step time: 0.3177\n",
      "158/224, train_loss: 0.0972, step time: 0.3857\n",
      "159/224, train_loss: 0.2748, step time: 0.3136\n",
      "160/224, train_loss: 0.1373, step time: 0.3138\n",
      "161/224, train_loss: 0.0943, step time: 0.3159\n",
      "162/224, train_loss: 0.0990, step time: 0.3176\n",
      "163/224, train_loss: 0.0856, step time: 0.3902\n",
      "164/224, train_loss: 0.2260, step time: 0.3767\n",
      "165/224, train_loss: 0.3393, step time: 0.3159\n",
      "166/224, train_loss: 0.1281, step time: 0.3155\n",
      "167/224, train_loss: 0.2946, step time: 0.3895\n",
      "168/224, train_loss: 0.1241, step time: 0.3743\n",
      "169/224, train_loss: 0.0779, step time: 0.3156\n",
      "170/224, train_loss: 0.1845, step time: 0.3195\n",
      "171/224, train_loss: 0.3087, step time: 0.3152\n",
      "172/224, train_loss: 0.0815, step time: 0.3169\n",
      "173/224, train_loss: 0.2163, step time: 0.3921\n",
      "174/224, train_loss: 0.1357, step time: 0.3153\n",
      "175/224, train_loss: 0.1709, step time: 0.3926\n",
      "176/224, train_loss: 0.3777, step time: 0.3881\n",
      "177/224, train_loss: 0.2211, step time: 0.3910\n",
      "178/224, train_loss: 0.2733, step time: 0.3679\n",
      "179/224, train_loss: 0.1654, step time: 0.4054\n",
      "180/224, train_loss: 0.1606, step time: 0.3712\n",
      "181/224, train_loss: 0.1193, step time: 0.3177\n",
      "182/224, train_loss: 0.3412, step time: 0.3774\n",
      "183/224, train_loss: 0.0940, step time: 0.3211\n",
      "184/224, train_loss: 0.1792, step time: 0.3190\n",
      "185/224, train_loss: 0.3592, step time: 0.4035\n",
      "186/224, train_loss: 0.1392, step time: 0.3186\n",
      "187/224, train_loss: 0.2329, step time: 0.3800\n",
      "188/224, train_loss: 0.1288, step time: 0.3131\n",
      "189/224, train_loss: 0.2021, step time: 0.3905\n",
      "190/224, train_loss: 0.1453, step time: 0.3803\n",
      "191/224, train_loss: 0.2390, step time: 0.4065\n",
      "192/224, train_loss: 0.3246, step time: 0.3757\n",
      "193/224, train_loss: 0.1375, step time: 0.3173\n",
      "194/224, train_loss: 0.0784, step time: 0.3810\n",
      "195/224, train_loss: 0.1190, step time: 0.3156\n",
      "196/224, train_loss: 0.2345, step time: 0.4009\n",
      "197/224, train_loss: 0.2855, step time: 0.3942\n",
      "198/224, train_loss: 0.0882, step time: 0.3746\n",
      "199/224, train_loss: 0.1213, step time: 0.3730\n",
      "200/224, train_loss: 0.1254, step time: 0.3718\n",
      "201/224, train_loss: 0.2488, step time: 0.3170\n",
      "202/224, train_loss: 0.2214, step time: 0.3147\n",
      "203/224, train_loss: 0.1570, step time: 0.3153\n",
      "204/224, train_loss: 0.1513, step time: 0.3792\n",
      "205/224, train_loss: 0.3227, step time: 0.3780\n",
      "206/224, train_loss: 0.1353, step time: 0.3128\n",
      "207/224, train_loss: 0.1510, step time: 0.3146\n",
      "208/224, train_loss: 0.1955, step time: 0.3167\n",
      "209/224, train_loss: 0.1003, step time: 0.3146\n",
      "210/224, train_loss: 0.1069, step time: 0.3127\n",
      "211/224, train_loss: 0.1761, step time: 0.3802\n",
      "212/224, train_loss: 0.1667, step time: 0.3132\n",
      "213/224, train_loss: 0.3400, step time: 0.3789\n",
      "214/224, train_loss: 0.2963, step time: 0.3982\n",
      "215/224, train_loss: 0.0612, step time: 0.3988\n",
      "216/224, train_loss: 0.3940, step time: 0.3772\n",
      "217/224, train_loss: 0.1952, step time: 0.3882\n",
      "218/224, train_loss: 0.1708, step time: 0.3764\n",
      "219/224, train_loss: 0.1194, step time: 0.3154\n",
      "220/224, train_loss: 0.1793, step time: 0.3152\n",
      "221/224, train_loss: 0.3328, step time: 0.3977\n",
      "222/224, train_loss: 0.2386, step time: 0.4048\n",
      "223/224, train_loss: 0.2025, step time: 0.4040\n",
      "224/224, train_loss: 0.1409, step time: 0.3883\n",
      "epoch 46 average loss: 0.1744\n",
      "current epoch: 46 current mean dice: 0.6875 class1: 0.9993 class2: 0.7269 class3: 0.3363\n",
      "best mean dice: 0.7031 at epoch: 45\n",
      "time consuming of epoch 46 is: 798.6538\n",
      "hello\n",
      "----------\n",
      "epoch 47/100\n",
      "1/224, train_loss: 0.1581, step time: 0.3174\n",
      "2/224, train_loss: 0.4105, step time: 0.4049\n",
      "3/224, train_loss: 0.0906, step time: 0.3185\n",
      "4/224, train_loss: 0.2560, step time: 0.3927\n",
      "5/224, train_loss: 0.3917, step time: 0.4094\n",
      "6/224, train_loss: 0.1636, step time: 0.3134\n",
      "7/224, train_loss: 0.2831, step time: 0.3695\n",
      "8/224, train_loss: 0.1111, step time: 0.3143\n",
      "9/224, train_loss: 0.2759, step time: 0.3862\n",
      "10/224, train_loss: 0.1498, step time: 0.3130\n",
      "11/224, train_loss: 0.0815, step time: 0.3916\n",
      "12/224, train_loss: 0.1885, step time: 0.3153\n",
      "13/224, train_loss: 0.0902, step time: 0.3983\n",
      "14/224, train_loss: 0.2144, step time: 0.3147\n",
      "15/224, train_loss: 0.0938, step time: 0.3130\n",
      "16/224, train_loss: 0.1587, step time: 0.3151\n",
      "17/224, train_loss: 0.0915, step time: 0.4094\n",
      "18/224, train_loss: 0.1091, step time: 0.3696\n",
      "19/224, train_loss: 0.0766, step time: 0.3152\n",
      "20/224, train_loss: 0.1329, step time: 0.3126\n",
      "21/224, train_loss: 0.1933, step time: 0.3888\n",
      "22/224, train_loss: 0.0926, step time: 0.3158\n",
      "23/224, train_loss: 0.1010, step time: 0.3173\n",
      "24/224, train_loss: 0.3732, step time: 0.4087\n",
      "25/224, train_loss: 0.1258, step time: 0.4079\n",
      "26/224, train_loss: 0.0865, step time: 0.3772\n",
      "27/224, train_loss: 0.1193, step time: 0.3149\n",
      "28/224, train_loss: 0.1872, step time: 0.4026\n",
      "29/224, train_loss: 0.1375, step time: 0.3150\n",
      "30/224, train_loss: 0.2003, step time: 0.4019\n",
      "31/224, train_loss: 0.1624, step time: 0.3721\n",
      "32/224, train_loss: 0.1233, step time: 0.3151\n",
      "33/224, train_loss: 0.2037, step time: 0.3776\n",
      "34/224, train_loss: 0.1202, step time: 0.3178\n",
      "35/224, train_loss: 0.3743, step time: 0.3822\n",
      "36/224, train_loss: 0.0700, step time: 0.3173\n",
      "37/224, train_loss: 0.3567, step time: 0.3142\n",
      "38/224, train_loss: 0.1244, step time: 0.3125\n",
      "39/224, train_loss: 0.0773, step time: 0.3144\n",
      "40/224, train_loss: 0.1192, step time: 0.3150\n",
      "41/224, train_loss: 0.1405, step time: 0.4090\n",
      "42/224, train_loss: 0.1831, step time: 0.3172\n",
      "43/224, train_loss: 0.3288, step time: 0.3918\n",
      "44/224, train_loss: 0.1487, step time: 0.3687\n",
      "45/224, train_loss: 0.1295, step time: 0.3151\n",
      "46/224, train_loss: 0.1879, step time: 0.3791\n",
      "47/224, train_loss: 0.0668, step time: 0.3833\n",
      "48/224, train_loss: 0.1097, step time: 0.3895\n",
      "49/224, train_loss: 0.4584, step time: 0.3678\n",
      "50/224, train_loss: 0.1761, step time: 0.3138\n",
      "51/224, train_loss: 0.2334, step time: 0.3834\n",
      "52/224, train_loss: 0.1147, step time: 0.3825\n",
      "53/224, train_loss: 0.1379, step time: 0.3169\n",
      "54/224, train_loss: 0.1878, step time: 0.3145\n",
      "55/224, train_loss: 0.2633, step time: 0.3983\n",
      "56/224, train_loss: 0.1558, step time: 0.3147\n",
      "57/224, train_loss: 0.2181, step time: 0.3753\n",
      "58/224, train_loss: 0.2082, step time: 0.3906\n",
      "59/224, train_loss: 0.1589, step time: 0.3173\n",
      "60/224, train_loss: 0.1339, step time: 0.3713\n",
      "61/224, train_loss: 0.0775, step time: 0.3979\n",
      "62/224, train_loss: 0.1148, step time: 0.3175\n",
      "63/224, train_loss: 0.1562, step time: 0.3652\n",
      "64/224, train_loss: 0.0769, step time: 0.4070\n",
      "65/224, train_loss: 0.1082, step time: 0.4047\n",
      "66/224, train_loss: 0.1206, step time: 0.3814\n",
      "67/224, train_loss: 0.0786, step time: 0.3844\n",
      "68/224, train_loss: 0.1171, step time: 0.3825\n",
      "69/224, train_loss: 0.3340, step time: 0.4064\n",
      "70/224, train_loss: 0.2062, step time: 0.3130\n",
      "71/224, train_loss: 0.0930, step time: 0.3773\n",
      "72/224, train_loss: 0.1525, step time: 0.4020\n",
      "73/224, train_loss: 0.1043, step time: 0.3167\n",
      "74/224, train_loss: 0.3291, step time: 0.4095\n",
      "75/224, train_loss: 0.1671, step time: 0.3174\n",
      "76/224, train_loss: 0.2280, step time: 0.3170\n",
      "77/224, train_loss: 0.1356, step time: 0.3136\n",
      "78/224, train_loss: 0.3058, step time: 0.3155\n",
      "79/224, train_loss: 0.3053, step time: 0.3138\n",
      "80/224, train_loss: 0.1095, step time: 0.3831\n",
      "81/224, train_loss: 0.1677, step time: 0.3812\n",
      "82/224, train_loss: 0.1661, step time: 0.3987\n",
      "83/224, train_loss: 0.1935, step time: 0.4075\n",
      "84/224, train_loss: 0.2142, step time: 0.3755\n",
      "85/224, train_loss: 0.1605, step time: 0.3657\n",
      "86/224, train_loss: 0.1037, step time: 0.4013\n",
      "87/224, train_loss: 0.0964, step time: 0.3157\n",
      "88/224, train_loss: 0.1764, step time: 0.3772\n",
      "89/224, train_loss: 0.1501, step time: 0.3150\n",
      "90/224, train_loss: 0.1313, step time: 0.3831\n",
      "91/224, train_loss: 0.2057, step time: 0.3145\n",
      "92/224, train_loss: 0.1381, step time: 0.3946\n",
      "93/224, train_loss: 0.1019, step time: 0.3151\n",
      "94/224, train_loss: 0.3256, step time: 0.3146\n",
      "95/224, train_loss: 0.2739, step time: 0.3792\n",
      "96/224, train_loss: 0.0843, step time: 0.4023\n",
      "97/224, train_loss: 0.1495, step time: 0.3892\n",
      "98/224, train_loss: 0.1050, step time: 0.3175\n",
      "99/224, train_loss: 0.0713, step time: 0.3843\n",
      "100/224, train_loss: 0.0794, step time: 0.3142\n",
      "101/224, train_loss: 0.2118, step time: 0.3706\n",
      "102/224, train_loss: 0.1294, step time: 0.3142\n",
      "103/224, train_loss: 0.0983, step time: 0.3661\n",
      "104/224, train_loss: 0.2312, step time: 0.3897\n",
      "105/224, train_loss: 0.2133, step time: 0.3153\n",
      "106/224, train_loss: 0.1198, step time: 0.3149\n",
      "107/224, train_loss: 0.3263, step time: 0.3663\n",
      "108/224, train_loss: 0.1530, step time: 0.3133\n",
      "109/224, train_loss: 0.1439, step time: 0.3684\n",
      "110/224, train_loss: 0.1224, step time: 0.3881\n",
      "111/224, train_loss: 0.1086, step time: 0.3702\n",
      "112/224, train_loss: 0.1115, step time: 0.3143\n",
      "113/224, train_loss: 0.1365, step time: 0.3895\n",
      "114/224, train_loss: 0.3695, step time: 0.3794\n",
      "115/224, train_loss: 0.0912, step time: 0.3143\n",
      "116/224, train_loss: 0.1659, step time: 0.3122\n",
      "117/224, train_loss: 0.3006, step time: 0.3164\n",
      "118/224, train_loss: 0.0882, step time: 0.3167\n",
      "119/224, train_loss: 0.1190, step time: 0.3787\n",
      "120/224, train_loss: 0.0778, step time: 0.3157\n",
      "121/224, train_loss: 0.0877, step time: 0.3991\n",
      "122/224, train_loss: 0.2971, step time: 0.3861\n",
      "123/224, train_loss: 0.0877, step time: 0.3145\n",
      "124/224, train_loss: 0.1112, step time: 0.3146\n",
      "125/224, train_loss: 0.1631, step time: 0.3149\n",
      "126/224, train_loss: 0.0972, step time: 0.3152\n",
      "127/224, train_loss: 0.1424, step time: 0.3168\n",
      "128/224, train_loss: 0.3584, step time: 0.3150\n",
      "129/224, train_loss: 0.1181, step time: 0.3132\n",
      "130/224, train_loss: 0.1232, step time: 0.3983\n",
      "131/224, train_loss: 0.3768, step time: 0.3172\n",
      "132/224, train_loss: 0.1454, step time: 0.3731\n",
      "133/224, train_loss: 0.1156, step time: 0.3151\n",
      "134/224, train_loss: 0.1104, step time: 0.3155\n",
      "135/224, train_loss: 0.0964, step time: 0.3180\n",
      "136/224, train_loss: 0.2516, step time: 0.4004\n",
      "137/224, train_loss: 0.1297, step time: 0.3670\n",
      "138/224, train_loss: 0.0920, step time: 0.3770\n",
      "139/224, train_loss: 0.0903, step time: 0.4048\n",
      "140/224, train_loss: 0.0541, step time: 0.3158\n",
      "141/224, train_loss: 0.0811, step time: 0.3182\n",
      "142/224, train_loss: 0.1469, step time: 0.3150\n",
      "143/224, train_loss: 0.0875, step time: 0.3169\n",
      "144/224, train_loss: 0.1675, step time: 0.4129\n",
      "145/224, train_loss: 0.1620, step time: 0.3154\n",
      "146/224, train_loss: 0.1353, step time: 0.3178\n",
      "147/224, train_loss: 0.3603, step time: 0.3799\n",
      "148/224, train_loss: 0.1119, step time: 0.3152\n",
      "149/224, train_loss: 0.0683, step time: 0.3852\n",
      "150/224, train_loss: 0.3138, step time: 0.3766\n",
      "151/224, train_loss: 0.3212, step time: 0.4087\n",
      "152/224, train_loss: 0.2373, step time: 0.4040\n",
      "153/224, train_loss: 0.1244, step time: 0.3179\n",
      "154/224, train_loss: 0.1643, step time: 0.3177\n",
      "155/224, train_loss: 0.3601, step time: 0.4037\n",
      "156/224, train_loss: 0.0773, step time: 0.3144\n",
      "157/224, train_loss: 0.0730, step time: 0.3145\n",
      "158/224, train_loss: 0.1378, step time: 0.3147\n",
      "159/224, train_loss: 0.1094, step time: 0.3879\n",
      "160/224, train_loss: 0.1672, step time: 0.3762\n",
      "161/224, train_loss: 0.1241, step time: 0.3153\n",
      "162/224, train_loss: 0.0950, step time: 0.3135\n",
      "163/224, train_loss: 0.1187, step time: 0.3777\n",
      "164/224, train_loss: 0.1072, step time: 0.3156\n",
      "165/224, train_loss: 0.0609, step time: 0.3173\n",
      "166/224, train_loss: 0.2498, step time: 0.3760\n",
      "167/224, train_loss: 0.1169, step time: 0.3147\n",
      "168/224, train_loss: 0.1246, step time: 0.3169\n",
      "169/224, train_loss: 0.0740, step time: 0.3150\n",
      "170/224, train_loss: 0.0518, step time: 0.3156\n",
      "171/224, train_loss: 0.1236, step time: 0.3974\n",
      "172/224, train_loss: 0.1360, step time: 0.3150\n",
      "173/224, train_loss: 0.1458, step time: 0.3692\n",
      "174/224, train_loss: 0.1037, step time: 0.3668\n",
      "175/224, train_loss: 0.3266, step time: 0.4022\n",
      "176/224, train_loss: 0.3344, step time: 0.3964\n",
      "177/224, train_loss: 0.0674, step time: 0.3188\n",
      "178/224, train_loss: 0.1035, step time: 0.3155\n",
      "179/224, train_loss: 0.0705, step time: 0.3154\n",
      "180/224, train_loss: 0.0894, step time: 0.3155\n",
      "181/224, train_loss: 0.1535, step time: 0.3832\n",
      "182/224, train_loss: 0.1490, step time: 0.3895\n",
      "183/224, train_loss: 0.3049, step time: 0.4115\n",
      "184/224, train_loss: 0.1719, step time: 0.3127\n",
      "185/224, train_loss: 0.1569, step time: 0.3662\n",
      "186/224, train_loss: 0.0914, step time: 0.3122\n",
      "187/224, train_loss: 0.0939, step time: 0.3796\n",
      "188/224, train_loss: 0.3909, step time: 0.3907\n",
      "189/224, train_loss: 0.1410, step time: 0.3701\n",
      "190/224, train_loss: 0.2041, step time: 0.3801\n",
      "191/224, train_loss: 0.2646, step time: 0.3728\n",
      "192/224, train_loss: 0.2874, step time: 0.3798\n",
      "193/224, train_loss: 0.2809, step time: 0.3881\n",
      "194/224, train_loss: 0.2378, step time: 0.3834\n",
      "195/224, train_loss: 0.2672, step time: 0.3146\n",
      "196/224, train_loss: 0.1648, step time: 0.5385\n",
      "197/224, train_loss: 0.0825, step time: 0.3175\n",
      "198/224, train_loss: 0.3386, step time: 0.3643\n",
      "199/224, train_loss: 0.1515, step time: 0.3811\n",
      "200/224, train_loss: 0.2366, step time: 0.3969\n",
      "201/224, train_loss: 0.0817, step time: 0.3141\n",
      "202/224, train_loss: 0.3844, step time: 0.3968\n",
      "203/224, train_loss: 0.1545, step time: 0.3129\n",
      "204/224, train_loss: 0.2200, step time: 0.3983\n",
      "205/224, train_loss: 0.2952, step time: 0.3945\n",
      "206/224, train_loss: 0.2162, step time: 0.3772\n",
      "207/224, train_loss: 0.1221, step time: 0.3178\n",
      "208/224, train_loss: 0.2360, step time: 0.3785\n",
      "209/224, train_loss: 0.3849, step time: 0.4141\n",
      "210/224, train_loss: 0.1280, step time: 0.3158\n",
      "211/224, train_loss: 0.1358, step time: 0.3156\n",
      "212/224, train_loss: 0.2065, step time: 0.3165\n",
      "213/224, train_loss: 0.3138, step time: 0.3847\n",
      "214/224, train_loss: 0.1303, step time: 0.3957\n",
      "215/224, train_loss: 0.3607, step time: 0.3166\n",
      "216/224, train_loss: 0.2221, step time: 0.3801\n",
      "217/224, train_loss: 0.4083, step time: 0.3128\n",
      "218/224, train_loss: 0.3370, step time: 0.3659\n",
      "219/224, train_loss: 0.2246, step time: 0.3150\n",
      "220/224, train_loss: 0.1162, step time: 0.4022\n",
      "221/224, train_loss: 0.1515, step time: 0.3127\n",
      "222/224, train_loss: 0.3501, step time: 0.4068\n",
      "223/224, train_loss: 0.1595, step time: 0.4000\n",
      "224/224, train_loss: 0.1716, step time: 0.3976\n",
      "epoch 47 average loss: 0.1746\n",
      "current epoch: 47 current mean dice: 0.6963 class1: 0.9993 class2: 0.7151 class3: 0.3745\n",
      "best mean dice: 0.7031 at epoch: 45\n",
      "time consuming of epoch 47 is: 792.3126\n",
      "hello\n",
      "----------\n",
      "epoch 48/100\n",
      "1/224, train_loss: 0.1080, step time: 0.3792\n",
      "2/224, train_loss: 0.2529, step time: 0.3991\n",
      "3/224, train_loss: 0.2089, step time: 0.3153\n",
      "4/224, train_loss: 0.1520, step time: 0.3165\n",
      "5/224, train_loss: 0.1012, step time: 0.3905\n",
      "6/224, train_loss: 0.0827, step time: 0.3145\n",
      "7/224, train_loss: 0.1468, step time: 0.3159\n",
      "8/224, train_loss: 0.0892, step time: 0.3151\n",
      "9/224, train_loss: 0.0796, step time: 0.3980\n",
      "10/224, train_loss: 0.3125, step time: 0.3171\n",
      "11/224, train_loss: 0.2363, step time: 0.3800\n",
      "12/224, train_loss: 0.0998, step time: 0.3172\n",
      "13/224, train_loss: 0.1951, step time: 0.3133\n",
      "14/224, train_loss: 0.1473, step time: 0.3711\n",
      "15/224, train_loss: 0.2128, step time: 0.3128\n",
      "16/224, train_loss: 0.1509, step time: 0.3150\n",
      "17/224, train_loss: 0.1455, step time: 0.3153\n",
      "18/224, train_loss: 0.4108, step time: 0.3812\n",
      "19/224, train_loss: 0.1557, step time: 0.3981\n",
      "20/224, train_loss: 0.1239, step time: 0.3176\n",
      "21/224, train_loss: 0.1804, step time: 0.4002\n",
      "22/224, train_loss: 0.2990, step time: 0.3843\n",
      "23/224, train_loss: 0.2092, step time: 0.3936\n",
      "24/224, train_loss: 0.1383, step time: 0.3720\n",
      "25/224, train_loss: 0.3333, step time: 0.3979\n",
      "26/224, train_loss: 0.0696, step time: 0.3126\n",
      "27/224, train_loss: 0.1172, step time: 0.3834\n",
      "28/224, train_loss: 0.0816, step time: 0.3173\n",
      "29/224, train_loss: 0.1078, step time: 0.4099\n",
      "30/224, train_loss: 0.3058, step time: 0.3777\n",
      "31/224, train_loss: 0.0771, step time: 0.3157\n",
      "32/224, train_loss: 0.2342, step time: 0.3769\n",
      "33/224, train_loss: 0.1019, step time: 0.3941\n",
      "34/224, train_loss: 0.2412, step time: 0.3887\n",
      "35/224, train_loss: 0.3144, step time: 0.4049\n",
      "36/224, train_loss: 0.1449, step time: 0.3658\n",
      "37/224, train_loss: 0.1224, step time: 0.3687\n",
      "38/224, train_loss: 0.0941, step time: 0.3146\n",
      "39/224, train_loss: 0.1378, step time: 0.3145\n",
      "40/224, train_loss: 0.1696, step time: 0.3768\n",
      "41/224, train_loss: 0.2410, step time: 0.3730\n",
      "42/224, train_loss: 0.0783, step time: 0.3924\n",
      "43/224, train_loss: 0.0691, step time: 0.3161\n",
      "44/224, train_loss: 0.3553, step time: 0.3176\n",
      "45/224, train_loss: 0.2643, step time: 0.4095\n",
      "46/224, train_loss: 0.3314, step time: 0.3171\n",
      "47/224, train_loss: 0.1433, step time: 0.3908\n",
      "48/224, train_loss: 0.3832, step time: 0.3839\n",
      "49/224, train_loss: 0.0824, step time: 0.3153\n",
      "50/224, train_loss: 0.0980, step time: 0.3130\n",
      "51/224, train_loss: 0.0912, step time: 0.3175\n",
      "52/224, train_loss: 0.1100, step time: 0.3800\n",
      "53/224, train_loss: 0.0758, step time: 0.3145\n",
      "54/224, train_loss: 0.1131, step time: 0.3149\n",
      "55/224, train_loss: 0.2577, step time: 0.3665\n",
      "56/224, train_loss: 0.2530, step time: 0.4011\n",
      "57/224, train_loss: 0.0892, step time: 0.3148\n",
      "58/224, train_loss: 0.1849, step time: 0.3155\n",
      "59/224, train_loss: 0.2000, step time: 0.3845\n",
      "60/224, train_loss: 0.1035, step time: 0.3889\n",
      "61/224, train_loss: 0.3350, step time: 0.3655\n",
      "62/224, train_loss: 0.1937, step time: 0.3171\n",
      "63/224, train_loss: 0.0920, step time: 0.3152\n",
      "64/224, train_loss: 0.1637, step time: 0.3133\n",
      "65/224, train_loss: 0.0906, step time: 0.3856\n",
      "66/224, train_loss: 0.1842, step time: 0.3882\n",
      "67/224, train_loss: 0.1453, step time: 0.3162\n",
      "68/224, train_loss: 0.2128, step time: 0.3743\n",
      "69/224, train_loss: 0.0995, step time: 0.4008\n",
      "70/224, train_loss: 0.1573, step time: 0.3748\n",
      "71/224, train_loss: 0.1378, step time: 0.3961\n",
      "72/224, train_loss: 0.3140, step time: 0.3792\n",
      "73/224, train_loss: 0.3660, step time: 0.3172\n",
      "74/224, train_loss: 0.2323, step time: 0.3173\n",
      "75/224, train_loss: 0.2573, step time: 0.3169\n",
      "76/224, train_loss: 0.2697, step time: 0.3139\n",
      "77/224, train_loss: 0.1083, step time: 0.3144\n",
      "78/224, train_loss: 0.1061, step time: 0.4138\n",
      "79/224, train_loss: 0.1486, step time: 0.3168\n",
      "80/224, train_loss: 0.2150, step time: 0.3170\n",
      "81/224, train_loss: 0.1422, step time: 0.3833\n",
      "82/224, train_loss: 0.2030, step time: 0.4005\n",
      "83/224, train_loss: 0.2435, step time: 0.3800\n",
      "84/224, train_loss: 0.0819, step time: 0.3145\n",
      "85/224, train_loss: 0.1342, step time: 0.3141\n",
      "86/224, train_loss: 0.0847, step time: 0.3174\n",
      "87/224, train_loss: 0.1885, step time: 0.3881\n",
      "88/224, train_loss: 0.2306, step time: 0.3694\n",
      "89/224, train_loss: 0.1953, step time: 0.3895\n",
      "90/224, train_loss: 0.2700, step time: 0.3141\n",
      "91/224, train_loss: 0.1833, step time: 0.3974\n",
      "92/224, train_loss: 0.1444, step time: 0.3141\n",
      "93/224, train_loss: 0.1722, step time: 0.3697\n",
      "94/224, train_loss: 0.1826, step time: 0.3153\n",
      "95/224, train_loss: 0.0761, step time: 0.3135\n",
      "96/224, train_loss: 0.1304, step time: 0.3156\n",
      "97/224, train_loss: 0.0678, step time: 0.3145\n",
      "98/224, train_loss: 0.0854, step time: 0.3175\n",
      "99/224, train_loss: 0.1623, step time: 0.3146\n",
      "100/224, train_loss: 0.1555, step time: 0.3150\n",
      "101/224, train_loss: 0.1305, step time: 0.3150\n",
      "102/224, train_loss: 0.1537, step time: 0.3141\n",
      "103/224, train_loss: 0.2599, step time: 0.3172\n",
      "104/224, train_loss: 0.1260, step time: 0.3176\n",
      "105/224, train_loss: 0.3030, step time: 0.3786\n",
      "106/224, train_loss: 0.2481, step time: 0.3943\n",
      "107/224, train_loss: 0.2087, step time: 0.3863\n",
      "108/224, train_loss: 0.3419, step time: 0.3725\n",
      "109/224, train_loss: 0.3436, step time: 0.3936\n",
      "110/224, train_loss: 0.0631, step time: 0.3844\n",
      "111/224, train_loss: 0.0963, step time: 0.3775\n",
      "112/224, train_loss: 0.2669, step time: 0.3148\n",
      "113/224, train_loss: 0.4079, step time: 0.3907\n",
      "114/224, train_loss: 0.2241, step time: 0.3968\n",
      "115/224, train_loss: 0.1957, step time: 0.4101\n",
      "116/224, train_loss: 0.1604, step time: 0.3165\n",
      "117/224, train_loss: 0.1316, step time: 0.3143\n",
      "118/224, train_loss: 0.2078, step time: 0.3738\n",
      "119/224, train_loss: 0.1157, step time: 0.3128\n",
      "120/224, train_loss: 0.1462, step time: 0.3144\n",
      "121/224, train_loss: 0.2352, step time: 0.3146\n",
      "122/224, train_loss: 0.0801, step time: 0.3124\n",
      "123/224, train_loss: 0.4028, step time: 0.3140\n",
      "124/224, train_loss: 0.0808, step time: 0.3170\n",
      "125/224, train_loss: 0.0826, step time: 0.3148\n",
      "126/224, train_loss: 0.1766, step time: 0.4003\n",
      "127/224, train_loss: 0.1958, step time: 0.3727\n",
      "128/224, train_loss: 0.2211, step time: 0.3768\n",
      "129/224, train_loss: 0.1524, step time: 0.3925\n",
      "130/224, train_loss: 0.1384, step time: 0.3171\n",
      "131/224, train_loss: 0.3780, step time: 0.3749\n",
      "132/224, train_loss: 0.2199, step time: 0.3903\n",
      "133/224, train_loss: 0.1548, step time: 0.3147\n",
      "134/224, train_loss: 0.1780, step time: 0.3748\n",
      "135/224, train_loss: 0.1993, step time: 0.3736\n",
      "136/224, train_loss: 0.0787, step time: 0.3147\n",
      "137/224, train_loss: 0.1768, step time: 0.3803\n",
      "138/224, train_loss: 0.2071, step time: 0.4024\n",
      "139/224, train_loss: 0.0898, step time: 0.3176\n",
      "140/224, train_loss: 0.2581, step time: 0.3175\n",
      "141/224, train_loss: 0.1229, step time: 0.3178\n",
      "142/224, train_loss: 0.1270, step time: 0.3696\n",
      "143/224, train_loss: 0.1199, step time: 0.3149\n",
      "144/224, train_loss: 0.1601, step time: 0.4077\n",
      "145/224, train_loss: 0.1890, step time: 0.4138\n",
      "146/224, train_loss: 0.1790, step time: 0.3141\n",
      "147/224, train_loss: 0.3503, step time: 0.3130\n",
      "148/224, train_loss: 0.4257, step time: 0.3852\n",
      "149/224, train_loss: 0.1154, step time: 0.3147\n",
      "150/224, train_loss: 0.1509, step time: 0.3785\n",
      "151/224, train_loss: 0.2271, step time: 0.3918\n",
      "152/224, train_loss: 0.2029, step time: 0.3974\n",
      "153/224, train_loss: 0.1292, step time: 0.3126\n",
      "154/224, train_loss: 0.1642, step time: 0.3934\n",
      "155/224, train_loss: 0.1073, step time: 0.3132\n",
      "156/224, train_loss: 0.1408, step time: 0.3148\n",
      "157/224, train_loss: 0.3903, step time: 0.3911\n",
      "158/224, train_loss: 0.1184, step time: 0.3152\n",
      "159/224, train_loss: 0.1191, step time: 0.3899\n",
      "160/224, train_loss: 0.0630, step time: 0.3150\n",
      "161/224, train_loss: 0.2158, step time: 0.3985\n",
      "162/224, train_loss: 0.3347, step time: 0.3146\n",
      "163/224, train_loss: 0.2059, step time: 0.3696\n",
      "164/224, train_loss: 0.0686, step time: 0.3171\n",
      "165/224, train_loss: 0.3035, step time: 0.3154\n",
      "166/224, train_loss: 0.1572, step time: 0.3153\n",
      "167/224, train_loss: 0.1545, step time: 0.3764\n",
      "168/224, train_loss: 0.1497, step time: 0.4070\n",
      "169/224, train_loss: 0.2768, step time: 0.3775\n",
      "170/224, train_loss: 0.1467, step time: 0.3175\n",
      "171/224, train_loss: 0.3892, step time: 0.3909\n",
      "172/224, train_loss: 0.0719, step time: 0.3147\n",
      "173/224, train_loss: 0.0843, step time: 0.3934\n",
      "174/224, train_loss: 0.1609, step time: 0.3178\n",
      "175/224, train_loss: 0.1746, step time: 0.3992\n",
      "176/224, train_loss: 0.1872, step time: 0.3138\n",
      "177/224, train_loss: 0.1186, step time: 0.3159\n",
      "178/224, train_loss: 0.1735, step time: 0.3166\n",
      "179/224, train_loss: 0.1439, step time: 0.3159\n",
      "180/224, train_loss: 0.2102, step time: 0.3995\n",
      "181/224, train_loss: 0.0753, step time: 0.3849\n",
      "182/224, train_loss: 0.1046, step time: 0.3736\n",
      "183/224, train_loss: 0.0965, step time: 0.4124\n",
      "184/224, train_loss: 0.2142, step time: 0.4082\n",
      "185/224, train_loss: 0.0933, step time: 0.3193\n",
      "186/224, train_loss: 0.1181, step time: 0.3143\n",
      "187/224, train_loss: 0.1597, step time: 0.3738\n",
      "188/224, train_loss: 0.1084, step time: 0.3746\n",
      "189/224, train_loss: 0.1873, step time: 0.3962\n",
      "190/224, train_loss: 0.0881, step time: 0.3943\n",
      "191/224, train_loss: 0.1281, step time: 0.3718\n",
      "192/224, train_loss: 0.1582, step time: 0.3733\n",
      "193/224, train_loss: 0.1106, step time: 0.3165\n",
      "194/224, train_loss: 0.1851, step time: 0.3817\n",
      "195/224, train_loss: 0.0917, step time: 0.3166\n",
      "196/224, train_loss: 0.1665, step time: 0.3836\n",
      "197/224, train_loss: 0.0914, step time: 0.3923\n",
      "198/224, train_loss: 0.1673, step time: 0.3173\n",
      "199/224, train_loss: 0.1910, step time: 0.3171\n",
      "200/224, train_loss: 0.1502, step time: 0.3154\n",
      "201/224, train_loss: 0.3182, step time: 0.3180\n",
      "202/224, train_loss: 0.1934, step time: 0.3179\n",
      "203/224, train_loss: 0.2075, step time: 0.4020\n",
      "204/224, train_loss: 0.2790, step time: 0.3875\n",
      "205/224, train_loss: 0.1677, step time: 0.3928\n",
      "206/224, train_loss: 0.1415, step time: 0.3163\n",
      "207/224, train_loss: 0.1991, step time: 0.3140\n",
      "208/224, train_loss: 0.2371, step time: 0.3162\n",
      "209/224, train_loss: 0.1582, step time: 0.4116\n",
      "210/224, train_loss: 0.1217, step time: 0.4079\n",
      "211/224, train_loss: 0.1608, step time: 0.3169\n",
      "212/224, train_loss: 0.3844, step time: 0.3687\n",
      "213/224, train_loss: 0.2157, step time: 0.4093\n",
      "214/224, train_loss: 0.1333, step time: 0.3703\n",
      "215/224, train_loss: 0.0950, step time: 0.3148\n",
      "216/224, train_loss: 0.1203, step time: 0.3158\n",
      "217/224, train_loss: 0.1239, step time: 0.3815\n",
      "218/224, train_loss: 0.1756, step time: 0.3148\n",
      "219/224, train_loss: 0.0927, step time: 0.3190\n",
      "220/224, train_loss: 0.0814, step time: 0.3152\n",
      "221/224, train_loss: 0.2675, step time: 0.4009\n",
      "222/224, train_loss: 0.1221, step time: 0.3742\n",
      "223/224, train_loss: 0.4079, step time: 0.3148\n",
      "224/224, train_loss: 0.1367, step time: 0.3839\n",
      "epoch 48 average loss: 0.1776\n",
      "current epoch: 48 current mean dice: 0.6997 class1: 0.9993 class2: 0.7409 class3: 0.3590\n",
      "best mean dice: 0.7031 at epoch: 45\n",
      "time consuming of epoch 48 is: 755.4264\n",
      "hello\n",
      "----------\n",
      "epoch 49/100\n",
      "1/224, train_loss: 0.1253, step time: 0.3877\n",
      "2/224, train_loss: 0.3130, step time: 0.3149\n",
      "3/224, train_loss: 0.0681, step time: 0.3146\n",
      "4/224, train_loss: 0.1540, step time: 0.3791\n",
      "5/224, train_loss: 0.1245, step time: 0.3147\n",
      "6/224, train_loss: 0.2759, step time: 0.3148\n",
      "7/224, train_loss: 0.1274, step time: 0.4004\n",
      "8/224, train_loss: 0.3707, step time: 0.3816\n",
      "9/224, train_loss: 0.3563, step time: 0.3992\n",
      "10/224, train_loss: 0.1265, step time: 0.3149\n",
      "11/224, train_loss: 0.1923, step time: 0.4005\n",
      "12/224, train_loss: 0.1184, step time: 0.3128\n",
      "13/224, train_loss: 0.1484, step time: 0.3758\n",
      "14/224, train_loss: 0.1489, step time: 0.3144\n",
      "15/224, train_loss: 0.0980, step time: 0.3973\n",
      "16/224, train_loss: 0.2300, step time: 0.3867\n",
      "17/224, train_loss: 0.3797, step time: 0.3709\n",
      "18/224, train_loss: 0.2505, step time: 0.3889\n",
      "19/224, train_loss: 0.0782, step time: 0.3169\n",
      "20/224, train_loss: 0.2352, step time: 0.3661\n",
      "21/224, train_loss: 0.1288, step time: 0.3145\n",
      "22/224, train_loss: 0.3157, step time: 0.3951\n",
      "23/224, train_loss: 0.2373, step time: 0.3148\n",
      "24/224, train_loss: 0.1153, step time: 0.3148\n",
      "25/224, train_loss: 0.0934, step time: 0.3145\n",
      "26/224, train_loss: 0.1306, step time: 0.3145\n",
      "27/224, train_loss: 0.1182, step time: 0.3145\n",
      "28/224, train_loss: 0.1660, step time: 0.3175\n",
      "29/224, train_loss: 0.2265, step time: 0.3151\n",
      "30/224, train_loss: 0.1015, step time: 0.3166\n",
      "31/224, train_loss: 0.0865, step time: 0.3175\n",
      "32/224, train_loss: 0.0869, step time: 0.3160\n",
      "33/224, train_loss: 0.5458, step time: 0.3920\n",
      "34/224, train_loss: 0.3652, step time: 0.4122\n",
      "35/224, train_loss: 0.2999, step time: 0.3919\n",
      "36/224, train_loss: 0.1567, step time: 0.4077\n",
      "37/224, train_loss: 0.2803, step time: 0.3644\n",
      "38/224, train_loss: 0.0951, step time: 0.3148\n",
      "39/224, train_loss: 0.1119, step time: 0.3177\n",
      "40/224, train_loss: 0.1495, step time: 0.4047\n",
      "41/224, train_loss: 0.0810, step time: 0.3122\n",
      "42/224, train_loss: 0.1194, step time: 0.3178\n",
      "43/224, train_loss: 0.0982, step time: 0.3150\n",
      "44/224, train_loss: 0.1488, step time: 0.3146\n",
      "45/224, train_loss: 0.2820, step time: 0.3147\n",
      "46/224, train_loss: 0.1538, step time: 0.3131\n",
      "47/224, train_loss: 0.2938, step time: 0.3908\n",
      "48/224, train_loss: 0.0774, step time: 0.3156\n",
      "49/224, train_loss: 0.2894, step time: 0.4006\n",
      "50/224, train_loss: 0.1658, step time: 0.3147\n",
      "51/224, train_loss: 0.2237, step time: 0.3169\n",
      "52/224, train_loss: 0.1577, step time: 0.3174\n",
      "53/224, train_loss: 0.0874, step time: 0.3134\n",
      "54/224, train_loss: 0.1111, step time: 0.3178\n",
      "55/224, train_loss: 0.1230, step time: 0.3869\n",
      "56/224, train_loss: 0.1965, step time: 0.3178\n",
      "57/224, train_loss: 0.1562, step time: 0.3929\n",
      "58/224, train_loss: 0.1901, step time: 0.3782\n",
      "59/224, train_loss: 0.1222, step time: 0.3167\n",
      "60/224, train_loss: 0.0806, step time: 0.3720\n",
      "61/224, train_loss: 0.1463, step time: 0.3134\n",
      "62/224, train_loss: 0.1199, step time: 0.3179\n",
      "63/224, train_loss: 0.1887, step time: 0.3173\n",
      "64/224, train_loss: 0.0990, step time: 0.3144\n",
      "65/224, train_loss: 0.1041, step time: 0.3743\n",
      "66/224, train_loss: 0.1317, step time: 0.3756\n",
      "67/224, train_loss: 0.2507, step time: 0.3146\n",
      "68/224, train_loss: 0.1857, step time: 0.3978\n",
      "69/224, train_loss: 0.0988, step time: 0.3144\n",
      "70/224, train_loss: 0.1426, step time: 0.3143\n",
      "71/224, train_loss: 0.1582, step time: 0.3873\n",
      "72/224, train_loss: 0.0784, step time: 0.3806\n",
      "73/224, train_loss: 0.1022, step time: 0.3146\n",
      "74/224, train_loss: 0.0819, step time: 0.3670\n",
      "75/224, train_loss: 0.2025, step time: 0.4098\n",
      "76/224, train_loss: 0.3342, step time: 0.3879\n",
      "77/224, train_loss: 0.1116, step time: 0.3144\n",
      "78/224, train_loss: 0.0958, step time: 0.3999\n",
      "79/224, train_loss: 0.1213, step time: 0.3736\n",
      "80/224, train_loss: 0.1273, step time: 0.3778\n",
      "81/224, train_loss: 0.1457, step time: 0.3177\n",
      "82/224, train_loss: 0.1964, step time: 0.3152\n",
      "83/224, train_loss: 0.2528, step time: 0.3171\n",
      "84/224, train_loss: 0.0818, step time: 0.4061\n",
      "85/224, train_loss: 0.1235, step time: 0.3178\n",
      "86/224, train_loss: 0.1041, step time: 0.3669\n",
      "87/224, train_loss: 0.1765, step time: 0.3781\n",
      "88/224, train_loss: 0.0444, step time: 0.4100\n",
      "89/224, train_loss: 0.1324, step time: 0.3861\n",
      "90/224, train_loss: 0.1505, step time: 0.3132\n",
      "91/224, train_loss: 0.2685, step time: 0.3958\n",
      "92/224, train_loss: 0.1427, step time: 0.3944\n",
      "93/224, train_loss: 0.0772, step time: 0.3684\n",
      "94/224, train_loss: 0.0787, step time: 0.3142\n",
      "95/224, train_loss: 0.1608, step time: 0.4108\n",
      "96/224, train_loss: 0.3673, step time: 0.3950\n",
      "97/224, train_loss: 0.2320, step time: 0.4056\n",
      "98/224, train_loss: 0.0984, step time: 0.3176\n",
      "99/224, train_loss: 0.1937, step time: 0.4084\n",
      "100/224, train_loss: 0.2116, step time: 0.3854\n",
      "101/224, train_loss: 0.0505, step time: 0.3131\n",
      "102/224, train_loss: 0.1188, step time: 0.3176\n",
      "103/224, train_loss: 0.3172, step time: 0.3175\n",
      "104/224, train_loss: 0.0754, step time: 0.3158\n",
      "105/224, train_loss: 0.2540, step time: 0.4017\n",
      "106/224, train_loss: 0.1426, step time: 0.3155\n",
      "107/224, train_loss: 0.1087, step time: 0.3146\n",
      "108/224, train_loss: 0.1849, step time: 0.4106\n",
      "109/224, train_loss: 0.3343, step time: 0.4115\n",
      "110/224, train_loss: 0.1819, step time: 0.3137\n",
      "111/224, train_loss: 0.1088, step time: 0.4094\n",
      "112/224, train_loss: 0.1480, step time: 0.3151\n",
      "113/224, train_loss: 0.0759, step time: 0.3782\n",
      "114/224, train_loss: 0.1267, step time: 0.3176\n",
      "115/224, train_loss: 0.1024, step time: 0.3825\n",
      "116/224, train_loss: 0.1235, step time: 0.3163\n",
      "117/224, train_loss: 0.2427, step time: 0.3666\n",
      "118/224, train_loss: 0.0730, step time: 0.3147\n",
      "119/224, train_loss: 0.1682, step time: 0.3820\n",
      "120/224, train_loss: 0.1138, step time: 0.3147\n",
      "121/224, train_loss: 0.3276, step time: 0.4059\n",
      "122/224, train_loss: 0.1934, step time: 0.4062\n",
      "123/224, train_loss: 0.2043, step time: 0.3157\n",
      "124/224, train_loss: 0.2101, step time: 0.3131\n",
      "125/224, train_loss: 0.1790, step time: 0.3951\n",
      "126/224, train_loss: 0.1143, step time: 0.3125\n",
      "127/224, train_loss: 0.1769, step time: 0.3710\n",
      "128/224, train_loss: 0.2430, step time: 0.3829\n",
      "129/224, train_loss: 0.0896, step time: 0.3146\n",
      "130/224, train_loss: 0.3461, step time: 0.3992\n",
      "131/224, train_loss: 0.4006, step time: 0.3731\n",
      "132/224, train_loss: 0.1357, step time: 0.3991\n",
      "133/224, train_loss: 0.3742, step time: 0.3652\n",
      "134/224, train_loss: 0.1018, step time: 0.3868\n",
      "135/224, train_loss: 0.1879, step time: 0.3152\n",
      "136/224, train_loss: 0.1564, step time: 0.3144\n",
      "137/224, train_loss: 0.3810, step time: 0.3696\n",
      "138/224, train_loss: 0.1685, step time: 0.3693\n",
      "139/224, train_loss: 0.4332, step time: 0.4050\n",
      "140/224, train_loss: 0.0898, step time: 0.3146\n",
      "141/224, train_loss: 0.1815, step time: 0.3166\n",
      "142/224, train_loss: 0.1098, step time: 0.3166\n",
      "143/224, train_loss: 0.1323, step time: 0.4079\n",
      "144/224, train_loss: 0.2010, step time: 0.3145\n",
      "145/224, train_loss: 0.2166, step time: 0.3685\n",
      "146/224, train_loss: 0.0748, step time: 0.3148\n",
      "147/224, train_loss: 0.1860, step time: 0.3168\n",
      "148/224, train_loss: 0.2480, step time: 0.3750\n",
      "149/224, train_loss: 0.1934, step time: 0.3698\n",
      "150/224, train_loss: 0.0789, step time: 0.4035\n",
      "151/224, train_loss: 0.1219, step time: 0.3152\n",
      "152/224, train_loss: 0.1122, step time: 0.3148\n",
      "153/224, train_loss: 0.0921, step time: 0.3146\n",
      "154/224, train_loss: 0.2769, step time: 0.3126\n",
      "155/224, train_loss: 0.2331, step time: 0.3869\n",
      "156/224, train_loss: 0.1265, step time: 0.3149\n",
      "157/224, train_loss: 0.1363, step time: 0.3178\n",
      "158/224, train_loss: 0.3796, step time: 0.3717\n",
      "159/224, train_loss: 0.1017, step time: 0.4009\n",
      "160/224, train_loss: 0.2812, step time: 0.3834\n",
      "161/224, train_loss: 0.2432, step time: 0.3698\n",
      "162/224, train_loss: 0.1649, step time: 0.3141\n",
      "163/224, train_loss: 0.3695, step time: 0.3952\n",
      "164/224, train_loss: 0.0779, step time: 0.3184\n",
      "165/224, train_loss: 0.1190, step time: 0.3838\n",
      "166/224, train_loss: 0.0442, step time: 0.4117\n",
      "167/224, train_loss: 0.0922, step time: 0.3167\n",
      "168/224, train_loss: 0.1384, step time: 0.3148\n",
      "169/224, train_loss: 0.2063, step time: 0.3178\n",
      "170/224, train_loss: 0.1534, step time: 0.3830\n",
      "171/224, train_loss: 0.0847, step time: 0.3174\n",
      "172/224, train_loss: 0.1493, step time: 0.3174\n",
      "173/224, train_loss: 0.1191, step time: 0.4108\n",
      "174/224, train_loss: 0.0719, step time: 0.3176\n",
      "175/224, train_loss: 0.1199, step time: 0.3885\n",
      "176/224, train_loss: 0.3071, step time: 0.4092\n",
      "177/224, train_loss: 0.1035, step time: 0.3151\n",
      "178/224, train_loss: 0.2208, step time: 0.3127\n",
      "179/224, train_loss: 0.1038, step time: 0.3129\n",
      "180/224, train_loss: 0.3994, step time: 0.3831\n",
      "181/224, train_loss: 0.1686, step time: 0.3169\n",
      "182/224, train_loss: 0.1396, step time: 0.3395\n",
      "183/224, train_loss: 0.1154, step time: 0.3915\n",
      "184/224, train_loss: 0.1275, step time: 0.3157\n",
      "185/224, train_loss: 0.1364, step time: 0.3764\n",
      "186/224, train_loss: 0.4278, step time: 0.3866\n",
      "187/224, train_loss: 0.1045, step time: 0.3155\n",
      "188/224, train_loss: 0.1660, step time: 0.3862\n",
      "189/224, train_loss: 0.3795, step time: 0.4091\n",
      "190/224, train_loss: 0.1106, step time: 0.3665\n",
      "191/224, train_loss: 0.1786, step time: 0.3147\n",
      "192/224, train_loss: 0.1479, step time: 0.3147\n",
      "193/224, train_loss: 0.1457, step time: 0.3781\n",
      "194/224, train_loss: 0.1413, step time: 0.4040\n",
      "195/224, train_loss: 0.3765, step time: 0.3854\n",
      "196/224, train_loss: 0.1647, step time: 0.3153\n",
      "197/224, train_loss: 0.1280, step time: 0.3148\n",
      "198/224, train_loss: 0.1609, step time: 0.3169\n",
      "199/224, train_loss: 0.3691, step time: 0.3850\n",
      "200/224, train_loss: 0.0603, step time: 0.3145\n",
      "201/224, train_loss: 0.2641, step time: 0.3754\n",
      "202/224, train_loss: 0.1706, step time: 0.3795\n",
      "203/224, train_loss: 0.1024, step time: 0.3755\n",
      "204/224, train_loss: 0.1250, step time: 0.4097\n",
      "205/224, train_loss: 0.1834, step time: 0.3144\n",
      "206/224, train_loss: 0.1746, step time: 0.3976\n",
      "207/224, train_loss: 0.3713, step time: 0.3661\n",
      "208/224, train_loss: 0.3738, step time: 0.3157\n",
      "209/224, train_loss: 0.1250, step time: 0.3128\n",
      "210/224, train_loss: 0.2627, step time: 0.3146\n",
      "211/224, train_loss: 0.1812, step time: 0.3159\n",
      "212/224, train_loss: 0.1443, step time: 0.4041\n",
      "213/224, train_loss: 0.1282, step time: 0.3159\n",
      "214/224, train_loss: 0.1745, step time: 0.4104\n",
      "215/224, train_loss: 0.1287, step time: 0.3160\n",
      "216/224, train_loss: 0.1559, step time: 0.3985\n",
      "217/224, train_loss: 0.1993, step time: 0.3994\n",
      "218/224, train_loss: 0.0623, step time: 0.3175\n",
      "219/224, train_loss: 0.0753, step time: 0.3716\n",
      "220/224, train_loss: 0.1815, step time: 0.3173\n",
      "221/224, train_loss: 0.1595, step time: 0.3149\n",
      "222/224, train_loss: 0.1321, step time: 0.3725\n",
      "223/224, train_loss: 0.0811, step time: 0.3146\n",
      "224/224, train_loss: 0.2017, step time: 0.3147\n",
      "epoch 49 average loss: 0.1752\n",
      "current epoch: 49 current mean dice: 0.6721 class1: 0.9993 class2: 0.7339 class3: 0.2832\n",
      "best mean dice: 0.7031 at epoch: 45\n",
      "time consuming of epoch 49 is: 755.7466\n",
      "hello\n",
      "----------\n",
      "epoch 50/100\n",
      "1/224, train_loss: 0.1609, step time: 0.3982\n",
      "2/224, train_loss: 0.1031, step time: 0.3150\n",
      "3/224, train_loss: 0.3039, step time: 0.3985\n",
      "4/224, train_loss: 0.0791, step time: 0.3820\n",
      "5/224, train_loss: 0.0789, step time: 0.3146\n",
      "6/224, train_loss: 0.4089, step time: 0.3910\n",
      "7/224, train_loss: 0.1486, step time: 0.4019\n",
      "8/224, train_loss: 0.1463, step time: 0.3835\n",
      "9/224, train_loss: 0.1346, step time: 0.3969\n",
      "10/224, train_loss: 0.1062, step time: 0.3150\n",
      "11/224, train_loss: 0.1237, step time: 0.4038\n",
      "12/224, train_loss: 0.0956, step time: 0.3907\n",
      "13/224, train_loss: 0.3052, step time: 0.3144\n",
      "14/224, train_loss: 0.0947, step time: 0.3146\n",
      "15/224, train_loss: 0.1505, step time: 0.3966\n",
      "16/224, train_loss: 0.1182, step time: 0.3180\n",
      "17/224, train_loss: 0.1700, step time: 0.3134\n",
      "18/224, train_loss: 0.2650, step time: 0.3131\n",
      "19/224, train_loss: 0.1644, step time: 0.3171\n",
      "20/224, train_loss: 0.0929, step time: 0.3126\n",
      "21/224, train_loss: 0.2499, step time: 0.4078\n",
      "22/224, train_loss: 0.1267, step time: 0.3756\n",
      "23/224, train_loss: 0.0826, step time: 0.3154\n",
      "24/224, train_loss: 0.0929, step time: 0.3130\n",
      "25/224, train_loss: 0.1869, step time: 0.3129\n",
      "26/224, train_loss: 0.2071, step time: 0.3149\n",
      "27/224, train_loss: 0.2556, step time: 0.3877\n",
      "28/224, train_loss: 0.0778, step time: 0.3172\n",
      "29/224, train_loss: 0.1454, step time: 0.3175\n",
      "30/224, train_loss: 0.1534, step time: 0.3779\n",
      "31/224, train_loss: 0.1643, step time: 0.3841\n",
      "32/224, train_loss: 0.2674, step time: 0.3174\n",
      "33/224, train_loss: 0.1822, step time: 0.3785\n",
      "34/224, train_loss: 0.1217, step time: 0.3148\n",
      "35/224, train_loss: 0.3643, step time: 0.3729\n",
      "36/224, train_loss: 0.1340, step time: 0.3795\n",
      "37/224, train_loss: 0.3438, step time: 0.4099\n",
      "38/224, train_loss: 0.1644, step time: 0.3793\n",
      "39/224, train_loss: 0.1114, step time: 0.3157\n",
      "40/224, train_loss: 0.1541, step time: 0.3162\n",
      "41/224, train_loss: 0.1796, step time: 0.4053\n",
      "42/224, train_loss: 0.1094, step time: 0.3174\n",
      "43/224, train_loss: 0.1950, step time: 0.3825\n",
      "44/224, train_loss: 0.1051, step time: 0.3138\n",
      "45/224, train_loss: 0.2190, step time: 0.3171\n",
      "46/224, train_loss: 0.0668, step time: 0.3146\n",
      "47/224, train_loss: 0.4680, step time: 0.3985\n",
      "48/224, train_loss: 0.3192, step time: 0.3911\n",
      "49/224, train_loss: 0.0968, step time: 0.3151\n",
      "50/224, train_loss: 0.1778, step time: 0.3869\n",
      "51/224, train_loss: 0.0777, step time: 0.3167\n",
      "52/224, train_loss: 0.2253, step time: 0.3860\n",
      "53/224, train_loss: 0.1944, step time: 0.3700\n",
      "54/224, train_loss: 0.3695, step time: 0.3168\n",
      "55/224, train_loss: 0.2868, step time: 0.3147\n",
      "56/224, train_loss: 0.1134, step time: 0.3899\n",
      "57/224, train_loss: 0.0834, step time: 0.3153\n",
      "58/224, train_loss: 0.1018, step time: 0.3146\n",
      "59/224, train_loss: 0.0567, step time: 0.3121\n",
      "60/224, train_loss: 0.2625, step time: 0.3143\n",
      "61/224, train_loss: 0.1564, step time: 0.4123\n",
      "62/224, train_loss: 0.2060, step time: 0.3131\n",
      "63/224, train_loss: 0.0546, step time: 0.3747\n",
      "64/224, train_loss: 0.1723, step time: 0.3973\n",
      "65/224, train_loss: 0.2538, step time: 0.3180\n",
      "66/224, train_loss: 0.3467, step time: 0.3704\n",
      "67/224, train_loss: 0.0927, step time: 0.3885\n",
      "68/224, train_loss: 0.1463, step time: 0.3135\n",
      "69/224, train_loss: 0.1145, step time: 0.3701\n",
      "70/224, train_loss: 0.1863, step time: 0.4056\n",
      "71/224, train_loss: 0.1064, step time: 0.3149\n",
      "72/224, train_loss: 0.0585, step time: 0.3130\n",
      "73/224, train_loss: 0.0890, step time: 0.3148\n",
      "74/224, train_loss: 0.1779, step time: 0.3156\n",
      "75/224, train_loss: 0.0750, step time: 0.3151\n",
      "76/224, train_loss: 0.2477, step time: 0.3662\n",
      "77/224, train_loss: 0.3409, step time: 0.3664\n",
      "78/224, train_loss: 0.0888, step time: 0.3124\n",
      "79/224, train_loss: 0.1829, step time: 0.3797\n",
      "80/224, train_loss: 0.3533, step time: 0.3886\n",
      "81/224, train_loss: 0.0980, step time: 0.3148\n",
      "82/224, train_loss: 0.0980, step time: 0.3915\n",
      "83/224, train_loss: 0.1899, step time: 0.3170\n",
      "84/224, train_loss: 0.1071, step time: 0.3122\n",
      "85/224, train_loss: 0.1861, step time: 0.3123\n",
      "86/224, train_loss: 0.1684, step time: 0.3145\n",
      "87/224, train_loss: 0.2166, step time: 0.3835\n",
      "88/224, train_loss: 0.1428, step time: 0.3147\n",
      "89/224, train_loss: 0.2271, step time: 0.3147\n",
      "90/224, train_loss: 0.2547, step time: 0.4059\n",
      "91/224, train_loss: 0.1197, step time: 0.3862\n",
      "92/224, train_loss: 0.3853, step time: 0.4098\n",
      "93/224, train_loss: 0.1462, step time: 0.3166\n",
      "94/224, train_loss: 0.0802, step time: 0.3123\n",
      "95/224, train_loss: 0.2556, step time: 0.3123\n",
      "96/224, train_loss: 0.1395, step time: 0.3140\n",
      "97/224, train_loss: 0.0796, step time: 0.3141\n",
      "98/224, train_loss: 0.1572, step time: 0.3171\n",
      "99/224, train_loss: 0.0852, step time: 0.3174\n",
      "100/224, train_loss: 0.1531, step time: 0.3171\n",
      "101/224, train_loss: 0.2067, step time: 0.3889\n",
      "102/224, train_loss: 0.2297, step time: 0.3166\n",
      "103/224, train_loss: 0.1098, step time: 0.3122\n",
      "104/224, train_loss: 0.3800, step time: 0.3156\n",
      "105/224, train_loss: 0.2573, step time: 0.3709\n",
      "106/224, train_loss: 0.0786, step time: 0.3126\n",
      "107/224, train_loss: 0.1255, step time: 0.3146\n",
      "108/224, train_loss: 0.0994, step time: 0.3174\n",
      "109/224, train_loss: 0.1134, step time: 0.3151\n",
      "110/224, train_loss: 0.1489, step time: 0.3148\n",
      "111/224, train_loss: 0.1911, step time: 0.3861\n",
      "112/224, train_loss: 0.1000, step time: 0.3768\n",
      "113/224, train_loss: 0.1920, step time: 0.4104\n",
      "114/224, train_loss: 0.2334, step time: 0.3874\n",
      "115/224, train_loss: 0.3660, step time: 0.3761\n",
      "116/224, train_loss: 0.1323, step time: 0.3131\n",
      "117/224, train_loss: 0.0515, step time: 0.3923\n",
      "118/224, train_loss: 0.1196, step time: 0.4023\n",
      "119/224, train_loss: 0.2860, step time: 0.3905\n",
      "120/224, train_loss: 0.1247, step time: 0.3856\n",
      "121/224, train_loss: 0.3822, step time: 0.3927\n",
      "122/224, train_loss: 0.0838, step time: 0.3145\n",
      "123/224, train_loss: 0.0917, step time: 0.4112\n",
      "124/224, train_loss: 0.1820, step time: 0.4036\n",
      "125/224, train_loss: 0.1295, step time: 0.3693\n",
      "126/224, train_loss: 0.1752, step time: 0.3862\n",
      "127/224, train_loss: 0.1279, step time: 0.3181\n",
      "128/224, train_loss: 0.0908, step time: 0.3865\n",
      "129/224, train_loss: 0.1196, step time: 0.3736\n",
      "130/224, train_loss: 0.3965, step time: 0.3911\n",
      "131/224, train_loss: 0.0928, step time: 0.3148\n",
      "132/224, train_loss: 0.2171, step time: 0.3666\n",
      "133/224, train_loss: 0.3417, step time: 0.3813\n",
      "134/224, train_loss: 0.0792, step time: 0.3764\n",
      "135/224, train_loss: 0.2060, step time: 0.4011\n",
      "136/224, train_loss: 0.1057, step time: 0.3793\n",
      "137/224, train_loss: 0.1203, step time: 0.3737\n",
      "138/224, train_loss: 0.3727, step time: 0.3149\n",
      "139/224, train_loss: 0.0959, step time: 0.3903\n",
      "140/224, train_loss: 0.1268, step time: 0.3154\n",
      "141/224, train_loss: 0.1305, step time: 0.3155\n",
      "142/224, train_loss: 0.1484, step time: 0.4018\n",
      "143/224, train_loss: 0.3116, step time: 0.3926\n",
      "144/224, train_loss: 0.0963, step time: 0.3148\n",
      "145/224, train_loss: 0.1104, step time: 0.3146\n",
      "146/224, train_loss: 0.1682, step time: 0.3172\n",
      "147/224, train_loss: 0.0996, step time: 0.3654\n",
      "148/224, train_loss: 0.0679, step time: 0.3142\n",
      "149/224, train_loss: 0.1985, step time: 0.3808\n",
      "150/224, train_loss: 0.1560, step time: 0.3149\n",
      "151/224, train_loss: 0.2234, step time: 0.3154\n",
      "152/224, train_loss: 0.1146, step time: 0.3175\n",
      "153/224, train_loss: 0.1710, step time: 0.3172\n",
      "154/224, train_loss: 0.1093, step time: 0.3173\n",
      "155/224, train_loss: 0.1952, step time: 0.3781\n",
      "156/224, train_loss: 0.0493, step time: 0.3147\n",
      "157/224, train_loss: 0.1534, step time: 0.3131\n",
      "158/224, train_loss: 0.2906, step time: 0.3790\n",
      "159/224, train_loss: 0.3656, step time: 0.3960\n",
      "160/224, train_loss: 0.1393, step time: 0.3176\n",
      "161/224, train_loss: 0.0564, step time: 0.3177\n",
      "162/224, train_loss: 0.0857, step time: 0.3147\n",
      "163/224, train_loss: 0.1469, step time: 0.3649\n",
      "164/224, train_loss: 0.2152, step time: 0.3737\n",
      "165/224, train_loss: 0.1964, step time: 0.3836\n",
      "166/224, train_loss: 0.1337, step time: 0.3168\n",
      "167/224, train_loss: 0.3482, step time: 0.3996\n",
      "168/224, train_loss: 0.1400, step time: 0.3905\n",
      "169/224, train_loss: 0.3511, step time: 0.4092\n",
      "170/224, train_loss: 0.4399, step time: 0.3799\n",
      "171/224, train_loss: 0.1356, step time: 0.3920\n",
      "172/224, train_loss: 0.0777, step time: 0.3126\n",
      "173/224, train_loss: 0.1772, step time: 0.3146\n",
      "174/224, train_loss: 0.1265, step time: 0.3862\n",
      "175/224, train_loss: 0.1077, step time: 0.3172\n",
      "176/224, train_loss: 0.0635, step time: 0.3121\n",
      "177/224, train_loss: 0.1431, step time: 0.3144\n",
      "178/224, train_loss: 0.1411, step time: 0.3145\n",
      "179/224, train_loss: 0.1744, step time: 0.3996\n",
      "180/224, train_loss: 0.0847, step time: 0.3148\n",
      "181/224, train_loss: 0.1712, step time: 0.4094\n",
      "182/224, train_loss: 0.1355, step time: 0.3168\n",
      "183/224, train_loss: 0.4472, step time: 0.3661\n",
      "184/224, train_loss: 0.0967, step time: 0.3139\n",
      "185/224, train_loss: 0.2710, step time: 0.4023\n",
      "186/224, train_loss: 0.1958, step time: 0.3994\n",
      "187/224, train_loss: 0.0990, step time: 0.3173\n",
      "188/224, train_loss: 0.3734, step time: 0.3941\n",
      "189/224, train_loss: 0.0791, step time: 0.3149\n",
      "190/224, train_loss: 0.3344, step time: 0.3683\n",
      "191/224, train_loss: 0.1736, step time: 0.3124\n",
      "192/224, train_loss: 0.1174, step time: 0.4008\n",
      "193/224, train_loss: 0.1201, step time: 0.3170\n",
      "194/224, train_loss: 0.3469, step time: 0.3980\n",
      "195/224, train_loss: 0.3066, step time: 0.4113\n",
      "196/224, train_loss: 0.1461, step time: 0.3875\n",
      "197/224, train_loss: 0.1699, step time: 0.3976\n",
      "198/224, train_loss: 0.2170, step time: 0.3143\n",
      "199/224, train_loss: 0.1644, step time: 0.3143\n",
      "200/224, train_loss: 0.3399, step time: 0.3887\n",
      "201/224, train_loss: 0.1295, step time: 0.4025\n",
      "202/224, train_loss: 0.1910, step time: 0.3789\n",
      "203/224, train_loss: 0.1038, step time: 0.3157\n",
      "204/224, train_loss: 0.2012, step time: 0.3981\n",
      "205/224, train_loss: 0.1183, step time: 0.4007\n",
      "206/224, train_loss: 0.1857, step time: 0.3965\n",
      "207/224, train_loss: 0.1850, step time: 0.3716\n",
      "208/224, train_loss: 0.0791, step time: 0.3965\n",
      "209/224, train_loss: 0.1043, step time: 0.3147\n",
      "210/224, train_loss: 0.2334, step time: 0.4025\n",
      "211/224, train_loss: 0.0486, step time: 0.3158\n",
      "212/224, train_loss: 0.1412, step time: 0.4041\n",
      "213/224, train_loss: 0.2444, step time: 0.3729\n",
      "214/224, train_loss: 0.1889, step time: 0.3780\n",
      "215/224, train_loss: 0.0937, step time: 0.3171\n",
      "216/224, train_loss: 0.1373, step time: 0.3918\n",
      "217/224, train_loss: 0.1010, step time: 0.3953\n",
      "218/224, train_loss: 0.1218, step time: 0.3695\n",
      "219/224, train_loss: 0.2800, step time: 0.3125\n",
      "220/224, train_loss: 0.1415, step time: 0.3153\n",
      "221/224, train_loss: 0.1383, step time: 0.3888\n",
      "222/224, train_loss: 0.1052, step time: 0.3145\n",
      "223/224, train_loss: 0.2455, step time: 0.3173\n",
      "224/224, train_loss: 0.4626, step time: 0.3923\n",
      "epoch 50 average loss: 0.1754\n",
      "current epoch: 50 current mean dice: 0.7055 class1: 0.9993 class2: 0.7382 class3: 0.3791\n",
      "best mean dice: 0.7055 at epoch: 50\n",
      "time consuming of epoch 50 is: 766.6082\n",
      "hello\n",
      "----------\n",
      "epoch 51/100\n",
      "1/224, train_loss: 0.1715, step time: 0.3726\n",
      "2/224, train_loss: 0.3544, step time: 0.3887\n",
      "3/224, train_loss: 0.1860, step time: 0.3171\n",
      "4/224, train_loss: 0.1132, step time: 0.3178\n",
      "5/224, train_loss: 0.1026, step time: 0.3158\n",
      "6/224, train_loss: 0.5378, step time: 0.3738\n",
      "7/224, train_loss: 0.1786, step time: 0.3781\n",
      "8/224, train_loss: 0.1248, step time: 0.3155\n",
      "9/224, train_loss: 0.0972, step time: 0.3128\n",
      "10/224, train_loss: 0.0889, step time: 0.4122\n",
      "11/224, train_loss: 0.1584, step time: 0.3171\n",
      "12/224, train_loss: 0.0805, step time: 0.3808\n",
      "13/224, train_loss: 0.3202, step time: 0.3733\n",
      "14/224, train_loss: 0.1355, step time: 0.3683\n",
      "15/224, train_loss: 0.2703, step time: 0.3926\n",
      "16/224, train_loss: 0.1638, step time: 0.3965\n",
      "17/224, train_loss: 0.0883, step time: 0.3123\n",
      "18/224, train_loss: 0.1182, step time: 0.3707\n",
      "19/224, train_loss: 0.0941, step time: 0.3944\n",
      "20/224, train_loss: 0.3098, step time: 0.4111\n",
      "21/224, train_loss: 0.1181, step time: 0.3175\n",
      "22/224, train_loss: 0.2087, step time: 0.3767\n",
      "23/224, train_loss: 0.1288, step time: 0.3153\n",
      "24/224, train_loss: 0.1305, step time: 0.3158\n",
      "25/224, train_loss: 0.2618, step time: 0.3844\n",
      "26/224, train_loss: 0.2292, step time: 0.3154\n",
      "27/224, train_loss: 0.1197, step time: 0.3819\n",
      "28/224, train_loss: 0.1061, step time: 0.3182\n",
      "29/224, train_loss: 0.1459, step time: 0.3133\n",
      "30/224, train_loss: 0.0769, step time: 0.3167\n",
      "31/224, train_loss: 0.1279, step time: 0.3175\n",
      "32/224, train_loss: 0.1043, step time: 0.3820\n",
      "33/224, train_loss: 0.1594, step time: 0.3146\n",
      "34/224, train_loss: 0.0968, step time: 0.4114\n",
      "35/224, train_loss: 0.1833, step time: 0.3125\n",
      "36/224, train_loss: 0.2698, step time: 0.3122\n",
      "37/224, train_loss: 0.3410, step time: 0.3150\n",
      "38/224, train_loss: 0.1572, step time: 0.3940\n",
      "39/224, train_loss: 0.0836, step time: 0.3147\n",
      "40/224, train_loss: 0.1708, step time: 0.3928\n",
      "41/224, train_loss: 0.0728, step time: 0.3982\n",
      "42/224, train_loss: 0.2158, step time: 0.3174\n",
      "43/224, train_loss: 0.0691, step time: 0.3136\n",
      "44/224, train_loss: 0.1100, step time: 0.3151\n",
      "45/224, train_loss: 0.1895, step time: 0.4104\n",
      "46/224, train_loss: 0.1897, step time: 0.3770\n",
      "47/224, train_loss: 0.1458, step time: 0.3151\n",
      "48/224, train_loss: 0.0924, step time: 0.3794\n",
      "49/224, train_loss: 0.1189, step time: 0.3134\n",
      "50/224, train_loss: 0.2288, step time: 0.3716\n",
      "51/224, train_loss: 0.1085, step time: 0.3166\n",
      "52/224, train_loss: 0.2669, step time: 0.3152\n",
      "53/224, train_loss: 0.1110, step time: 0.3177\n",
      "54/224, train_loss: 0.2254, step time: 0.3176\n",
      "55/224, train_loss: 0.0841, step time: 0.3130\n",
      "56/224, train_loss: 0.1368, step time: 0.3168\n",
      "57/224, train_loss: 0.1887, step time: 0.3818\n",
      "58/224, train_loss: 0.1104, step time: 0.3826\n",
      "59/224, train_loss: 0.4163, step time: 0.3937\n",
      "60/224, train_loss: 0.1269, step time: 0.3159\n",
      "61/224, train_loss: 0.1632, step time: 0.3178\n",
      "62/224, train_loss: 0.1259, step time: 0.3172\n",
      "63/224, train_loss: 0.1310, step time: 0.3781\n",
      "64/224, train_loss: 0.1746, step time: 0.3160\n",
      "65/224, train_loss: 0.0514, step time: 0.3686\n",
      "66/224, train_loss: 0.2162, step time: 0.3128\n",
      "67/224, train_loss: 0.3974, step time: 0.3874\n",
      "68/224, train_loss: 0.2851, step time: 0.3756\n",
      "69/224, train_loss: 0.1750, step time: 0.3151\n",
      "70/224, train_loss: 0.1170, step time: 0.3131\n",
      "71/224, train_loss: 0.1336, step time: 0.3153\n",
      "72/224, train_loss: 0.1286, step time: 0.3745\n",
      "73/224, train_loss: 0.1326, step time: 0.3997\n",
      "74/224, train_loss: 0.1777, step time: 0.3146\n",
      "75/224, train_loss: 0.1512, step time: 0.3878\n",
      "76/224, train_loss: 0.2030, step time: 0.4040\n",
      "77/224, train_loss: 0.1128, step time: 0.3655\n",
      "78/224, train_loss: 0.2641, step time: 0.4023\n",
      "79/224, train_loss: 0.2144, step time: 0.3155\n",
      "80/224, train_loss: 0.1580, step time: 0.3812\n",
      "81/224, train_loss: 0.3544, step time: 0.3125\n",
      "82/224, train_loss: 0.1438, step time: 0.3147\n",
      "83/224, train_loss: 0.2035, step time: 0.3959\n",
      "84/224, train_loss: 0.1959, step time: 0.3168\n",
      "85/224, train_loss: 0.1027, step time: 0.3144\n",
      "86/224, train_loss: 0.2282, step time: 0.3641\n",
      "87/224, train_loss: 0.0497, step time: 0.3173\n",
      "88/224, train_loss: 0.0915, step time: 0.3144\n",
      "89/224, train_loss: 0.2102, step time: 0.3144\n",
      "90/224, train_loss: 0.3503, step time: 0.4058\n",
      "91/224, train_loss: 0.1549, step time: 0.3153\n",
      "92/224, train_loss: 0.0880, step time: 0.3928\n",
      "93/224, train_loss: 0.1224, step time: 0.3143\n",
      "94/224, train_loss: 0.2656, step time: 0.3983\n",
      "95/224, train_loss: 0.1400, step time: 0.3149\n",
      "96/224, train_loss: 0.1182, step time: 0.3169\n",
      "97/224, train_loss: 0.0912, step time: 0.3149\n",
      "98/224, train_loss: 0.0982, step time: 0.3143\n",
      "99/224, train_loss: 0.0763, step time: 0.3143\n",
      "100/224, train_loss: 0.0904, step time: 0.3124\n",
      "101/224, train_loss: 0.1579, step time: 0.3168\n",
      "102/224, train_loss: 0.1548, step time: 0.3166\n",
      "103/224, train_loss: 0.1275, step time: 0.3143\n",
      "104/224, train_loss: 0.1792, step time: 0.3174\n",
      "105/224, train_loss: 0.1946, step time: 0.4019\n",
      "106/224, train_loss: 0.3017, step time: 0.3695\n",
      "107/224, train_loss: 0.0914, step time: 0.3791\n",
      "108/224, train_loss: 0.1720, step time: 0.3132\n",
      "109/224, train_loss: 0.2089, step time: 0.3807\n",
      "110/224, train_loss: 0.1071, step time: 0.4048\n",
      "111/224, train_loss: 0.0680, step time: 0.3842\n",
      "112/224, train_loss: 0.1654, step time: 0.3804\n",
      "113/224, train_loss: 0.1156, step time: 0.3158\n",
      "114/224, train_loss: 0.1369, step time: 0.3691\n",
      "115/224, train_loss: 0.2314, step time: 0.4015\n",
      "116/224, train_loss: 0.1674, step time: 0.4004\n",
      "117/224, train_loss: 0.1429, step time: 0.3155\n",
      "118/224, train_loss: 0.0746, step time: 0.3858\n",
      "119/224, train_loss: 0.0928, step time: 0.3178\n",
      "120/224, train_loss: 0.0885, step time: 0.3810\n",
      "121/224, train_loss: 0.1082, step time: 0.3148\n",
      "122/224, train_loss: 0.1506, step time: 0.3152\n",
      "123/224, train_loss: 0.2887, step time: 0.3178\n",
      "124/224, train_loss: 0.1670, step time: 0.4120\n",
      "125/224, train_loss: 0.0655, step time: 0.3148\n",
      "126/224, train_loss: 0.1314, step time: 0.3917\n",
      "127/224, train_loss: 0.1291, step time: 0.3158\n",
      "128/224, train_loss: 0.1381, step time: 0.3150\n",
      "129/224, train_loss: 0.0769, step time: 0.4111\n",
      "130/224, train_loss: 0.1281, step time: 0.3138\n",
      "131/224, train_loss: 0.3416, step time: 0.3180\n",
      "132/224, train_loss: 0.0846, step time: 0.3128\n",
      "133/224, train_loss: 0.2351, step time: 0.3789\n",
      "134/224, train_loss: 0.3668, step time: 0.4034\n",
      "135/224, train_loss: 0.1086, step time: 0.3179\n",
      "136/224, train_loss: 0.0892, step time: 0.3155\n",
      "137/224, train_loss: 0.1288, step time: 0.3153\n",
      "138/224, train_loss: 0.1806, step time: 0.3829\n",
      "139/224, train_loss: 0.1511, step time: 0.3145\n",
      "140/224, train_loss: 0.1760, step time: 0.3869\n",
      "141/224, train_loss: 0.1285, step time: 0.4031\n",
      "142/224, train_loss: 0.2662, step time: 0.3993\n",
      "143/224, train_loss: 0.1305, step time: 0.4036\n",
      "144/224, train_loss: 0.1045, step time: 0.3785\n",
      "145/224, train_loss: 0.1121, step time: 0.4112\n",
      "146/224, train_loss: 0.1080, step time: 0.3156\n",
      "147/224, train_loss: 0.0889, step time: 0.3809\n",
      "148/224, train_loss: 0.1023, step time: 0.3173\n",
      "149/224, train_loss: 0.1583, step time: 0.3955\n",
      "150/224, train_loss: 0.1758, step time: 0.3148\n",
      "151/224, train_loss: 0.1071, step time: 0.3135\n",
      "152/224, train_loss: 0.3817, step time: 0.4059\n",
      "153/224, train_loss: 0.0805, step time: 0.3736\n",
      "154/224, train_loss: 0.0835, step time: 0.3777\n",
      "155/224, train_loss: 0.0839, step time: 0.3175\n",
      "156/224, train_loss: 0.2091, step time: 0.3168\n",
      "157/224, train_loss: 0.1591, step time: 0.3149\n",
      "158/224, train_loss: 0.3710, step time: 0.3175\n",
      "159/224, train_loss: 0.1587, step time: 0.3159\n",
      "160/224, train_loss: 0.3304, step time: 0.3695\n",
      "161/224, train_loss: 0.1782, step time: 0.3837\n",
      "162/224, train_loss: 0.1213, step time: 0.3996\n",
      "163/224, train_loss: 0.0833, step time: 0.3150\n",
      "164/224, train_loss: 0.1075, step time: 0.3816\n",
      "165/224, train_loss: 0.2371, step time: 0.3850\n",
      "166/224, train_loss: 0.2105, step time: 0.3167\n",
      "167/224, train_loss: 0.2058, step time: 0.4017\n",
      "168/224, train_loss: 0.1955, step time: 0.3934\n",
      "169/224, train_loss: 0.3451, step time: 0.3740\n",
      "170/224, train_loss: 0.1946, step time: 0.3841\n",
      "171/224, train_loss: 0.3305, step time: 0.3157\n",
      "172/224, train_loss: 0.0907, step time: 0.3146\n",
      "173/224, train_loss: 0.1209, step time: 0.3892\n",
      "174/224, train_loss: 0.0756, step time: 0.3162\n",
      "175/224, train_loss: 0.0982, step time: 0.3121\n",
      "176/224, train_loss: 0.1866, step time: 0.3721\n",
      "177/224, train_loss: 0.2705, step time: 0.3924\n",
      "178/224, train_loss: 0.1868, step time: 0.3881\n",
      "179/224, train_loss: 0.0781, step time: 0.3140\n",
      "180/224, train_loss: 0.1309, step time: 0.3141\n",
      "181/224, train_loss: 0.2320, step time: 0.3745\n",
      "182/224, train_loss: 0.1901, step time: 0.3969\n",
      "183/224, train_loss: 0.1748, step time: 0.3849\n",
      "184/224, train_loss: 0.1168, step time: 0.3141\n",
      "185/224, train_loss: 0.1080, step time: 0.3145\n",
      "186/224, train_loss: 0.0884, step time: 0.3148\n",
      "187/224, train_loss: 0.1129, step time: 0.3153\n",
      "188/224, train_loss: 0.1797, step time: 0.3132\n",
      "189/224, train_loss: 0.0961, step time: 0.4042\n",
      "190/224, train_loss: 0.1981, step time: 0.3965\n",
      "191/224, train_loss: 0.1341, step time: 0.4051\n",
      "192/224, train_loss: 0.3492, step time: 0.3982\n",
      "193/224, train_loss: 0.1472, step time: 0.3171\n",
      "194/224, train_loss: 0.0584, step time: 0.3176\n",
      "195/224, train_loss: 0.1484, step time: 0.3147\n",
      "196/224, train_loss: 0.1062, step time: 0.4011\n",
      "197/224, train_loss: 0.2580, step time: 0.3144\n",
      "198/224, train_loss: 0.2643, step time: 0.4028\n",
      "199/224, train_loss: 0.1592, step time: 0.3690\n",
      "200/224, train_loss: 0.0867, step time: 0.3155\n",
      "201/224, train_loss: 0.1599, step time: 0.3131\n",
      "202/224, train_loss: 0.2366, step time: 0.3732\n",
      "203/224, train_loss: 0.3791, step time: 0.3777\n",
      "204/224, train_loss: 0.1694, step time: 0.3922\n",
      "205/224, train_loss: 0.0941, step time: 0.3144\n",
      "206/224, train_loss: 0.1388, step time: 0.3707\n",
      "207/224, train_loss: 0.1798, step time: 0.3139\n",
      "208/224, train_loss: 0.3151, step time: 0.3921\n",
      "209/224, train_loss: 0.1852, step time: 0.3735\n",
      "210/224, train_loss: 0.3822, step time: 0.3989\n",
      "211/224, train_loss: 0.1288, step time: 0.3686\n",
      "212/224, train_loss: 0.3358, step time: 0.3831\n",
      "213/224, train_loss: 0.1447, step time: 0.4034\n",
      "214/224, train_loss: 0.4064, step time: 0.3909\n",
      "215/224, train_loss: 0.1356, step time: 0.3146\n",
      "216/224, train_loss: 0.1010, step time: 0.3147\n",
      "217/224, train_loss: 0.1186, step time: 0.3878\n",
      "218/224, train_loss: 0.1154, step time: 0.3849\n",
      "219/224, train_loss: 0.0664, step time: 0.3142\n",
      "220/224, train_loss: 0.1449, step time: 0.4036\n",
      "221/224, train_loss: 0.2635, step time: 0.3175\n",
      "222/224, train_loss: 0.2348, step time: 0.3808\n",
      "223/224, train_loss: 0.3847, step time: 0.3643\n",
      "224/224, train_loss: 0.2188, step time: 0.3993\n",
      "epoch 51 average loss: 0.1700\n",
      "current epoch: 51 current mean dice: 0.6830 class1: 0.9993 class2: 0.7139 class3: 0.3357\n",
      "best mean dice: 0.7055 at epoch: 50\n",
      "time consuming of epoch 51 is: 714.2934\n",
      "hello\n",
      "----------\n",
      "epoch 52/100\n",
      "1/224, train_loss: 0.1673, step time: 0.3151\n",
      "2/224, train_loss: 0.0889, step time: 0.3794\n",
      "3/224, train_loss: 0.1497, step time: 0.3800\n",
      "4/224, train_loss: 0.3857, step time: 0.3170\n",
      "5/224, train_loss: 0.0774, step time: 0.3125\n",
      "6/224, train_loss: 0.1146, step time: 0.3150\n",
      "7/224, train_loss: 0.2626, step time: 0.3154\n",
      "8/224, train_loss: 0.1424, step time: 0.3156\n",
      "9/224, train_loss: 0.1791, step time: 0.3152\n",
      "10/224, train_loss: 0.1733, step time: 0.3149\n",
      "11/224, train_loss: 0.1343, step time: 0.3161\n",
      "12/224, train_loss: 0.1222, step time: 0.3146\n",
      "13/224, train_loss: 0.1461, step time: 0.3861\n",
      "14/224, train_loss: 0.1390, step time: 0.3147\n",
      "15/224, train_loss: 0.2479, step time: 0.3823\n",
      "16/224, train_loss: 0.3809, step time: 0.3878\n",
      "17/224, train_loss: 0.1016, step time: 0.3710\n",
      "18/224, train_loss: 0.0941, step time: 0.3918\n",
      "19/224, train_loss: 0.0581, step time: 0.3144\n",
      "20/224, train_loss: 0.0738, step time: 0.3175\n",
      "21/224, train_loss: 0.1789, step time: 0.3788\n",
      "22/224, train_loss: 0.1454, step time: 0.3754\n",
      "23/224, train_loss: 0.1473, step time: 0.3873\n",
      "24/224, train_loss: 0.0840, step time: 0.3880\n",
      "25/224, train_loss: 0.1035, step time: 0.3166\n",
      "26/224, train_loss: 0.3729, step time: 0.3639\n",
      "27/224, train_loss: 0.0811, step time: 0.3149\n",
      "28/224, train_loss: 0.1278, step time: 0.3147\n",
      "29/224, train_loss: 0.1693, step time: 0.3730\n",
      "30/224, train_loss: 0.1653, step time: 0.3997\n",
      "31/224, train_loss: 0.1116, step time: 0.3167\n",
      "32/224, train_loss: 0.1400, step time: 0.3793\n",
      "33/224, train_loss: 0.0960, step time: 0.3147\n",
      "34/224, train_loss: 0.0822, step time: 0.3937\n",
      "35/224, train_loss: 0.2247, step time: 0.3751\n",
      "36/224, train_loss: 0.1321, step time: 0.3941\n",
      "37/224, train_loss: 0.1405, step time: 0.3169\n",
      "38/224, train_loss: 0.1605, step time: 0.3976\n",
      "39/224, train_loss: 0.2978, step time: 0.4057\n",
      "40/224, train_loss: 0.2271, step time: 0.3168\n",
      "41/224, train_loss: 0.0909, step time: 0.3142\n",
      "42/224, train_loss: 0.1057, step time: 0.3140\n",
      "43/224, train_loss: 0.1132, step time: 0.3143\n",
      "44/224, train_loss: 0.1028, step time: 0.3800\n",
      "45/224, train_loss: 0.3738, step time: 0.3148\n",
      "46/224, train_loss: 0.1285, step time: 0.3898\n",
      "47/224, train_loss: 0.1207, step time: 0.3821\n",
      "48/224, train_loss: 0.1509, step time: 0.3156\n",
      "49/224, train_loss: 0.0857, step time: 0.3158\n",
      "50/224, train_loss: 0.2810, step time: 0.3169\n",
      "51/224, train_loss: 0.3317, step time: 0.3127\n",
      "52/224, train_loss: 0.1765, step time: 0.3150\n",
      "53/224, train_loss: 0.0836, step time: 0.3746\n",
      "54/224, train_loss: 0.1083, step time: 0.3171\n",
      "55/224, train_loss: 0.0700, step time: 0.3144\n",
      "56/224, train_loss: 0.1025, step time: 0.3814\n",
      "57/224, train_loss: 0.1324, step time: 0.3148\n",
      "58/224, train_loss: 0.1112, step time: 0.3905\n",
      "59/224, train_loss: 0.3025, step time: 0.3152\n",
      "60/224, train_loss: 0.1656, step time: 0.3707\n",
      "61/224, train_loss: 0.1127, step time: 0.3167\n",
      "62/224, train_loss: 0.1530, step time: 0.3939\n",
      "63/224, train_loss: 0.2328, step time: 0.4040\n",
      "64/224, train_loss: 0.1426, step time: 0.3147\n",
      "65/224, train_loss: 0.0889, step time: 0.3871\n",
      "66/224, train_loss: 0.1146, step time: 0.3756\n",
      "67/224, train_loss: 0.0806, step time: 0.3121\n",
      "68/224, train_loss: 0.2311, step time: 0.4031\n",
      "69/224, train_loss: 0.1239, step time: 0.3652\n",
      "70/224, train_loss: 0.0941, step time: 0.3129\n",
      "71/224, train_loss: 0.1518, step time: 0.3149\n",
      "72/224, train_loss: 0.0497, step time: 0.3148\n",
      "73/224, train_loss: 0.1895, step time: 0.3733\n",
      "74/224, train_loss: 0.0884, step time: 0.3168\n",
      "75/224, train_loss: 0.2672, step time: 0.3926\n",
      "76/224, train_loss: 0.1139, step time: 0.3143\n",
      "77/224, train_loss: 0.1545, step time: 0.3990\n",
      "78/224, train_loss: 0.1438, step time: 0.4097\n",
      "79/224, train_loss: 0.1692, step time: 0.3880\n",
      "80/224, train_loss: 0.2186, step time: 0.3733\n",
      "81/224, train_loss: 0.2189, step time: 0.3985\n",
      "82/224, train_loss: 0.1973, step time: 0.3994\n",
      "83/224, train_loss: 0.5134, step time: 0.4088\n",
      "84/224, train_loss: 0.0727, step time: 0.3155\n",
      "85/224, train_loss: 0.2214, step time: 0.3150\n",
      "86/224, train_loss: 0.1000, step time: 0.3126\n",
      "87/224, train_loss: 0.1159, step time: 0.3142\n",
      "88/224, train_loss: 0.2667, step time: 0.3145\n",
      "89/224, train_loss: 0.0855, step time: 0.3826\n",
      "90/224, train_loss: 0.4871, step time: 0.3697\n",
      "91/224, train_loss: 0.0502, step time: 0.3143\n",
      "92/224, train_loss: 0.0552, step time: 0.4074\n",
      "93/224, train_loss: 0.3030, step time: 0.3790\n",
      "94/224, train_loss: 0.1458, step time: 0.3153\n",
      "95/224, train_loss: 0.1284, step time: 0.3993\n",
      "96/224, train_loss: 0.1025, step time: 0.3154\n",
      "97/224, train_loss: 0.1351, step time: 0.3172\n",
      "98/224, train_loss: 0.1503, step time: 0.3140\n",
      "99/224, train_loss: 0.1725, step time: 0.3714\n",
      "100/224, train_loss: 0.1727, step time: 0.4095\n",
      "101/224, train_loss: 0.0455, step time: 0.3725\n",
      "102/224, train_loss: 0.1863, step time: 0.4040\n",
      "103/224, train_loss: 0.0886, step time: 0.3827\n",
      "104/224, train_loss: 0.1202, step time: 0.3159\n",
      "105/224, train_loss: 0.1176, step time: 0.3638\n",
      "106/224, train_loss: 0.0969, step time: 0.3851\n",
      "107/224, train_loss: 0.1836, step time: 0.4078\n",
      "108/224, train_loss: 0.2055, step time: 0.3165\n",
      "109/224, train_loss: 0.2581, step time: 0.3888\n",
      "110/224, train_loss: 0.2677, step time: 0.4022\n",
      "111/224, train_loss: 0.0687, step time: 0.3865\n",
      "112/224, train_loss: 0.0924, step time: 0.3181\n",
      "113/224, train_loss: 0.1532, step time: 0.3154\n",
      "114/224, train_loss: 0.1191, step time: 0.3158\n",
      "115/224, train_loss: 0.0619, step time: 0.3137\n",
      "116/224, train_loss: 0.3409, step time: 0.3832\n",
      "117/224, train_loss: 0.1221, step time: 0.3158\n",
      "118/224, train_loss: 0.1697, step time: 0.3937\n",
      "119/224, train_loss: 0.1924, step time: 0.3789\n",
      "120/224, train_loss: 0.2027, step time: 0.4025\n",
      "121/224, train_loss: 0.0863, step time: 0.3962\n",
      "122/224, train_loss: 0.1232, step time: 0.3145\n",
      "123/224, train_loss: 0.1349, step time: 0.3123\n",
      "124/224, train_loss: 0.0817, step time: 0.3147\n",
      "125/224, train_loss: 0.3748, step time: 0.3150\n",
      "126/224, train_loss: 0.2151, step time: 0.3983\n",
      "127/224, train_loss: 0.3548, step time: 0.4049\n",
      "128/224, train_loss: 0.3667, step time: 0.3722\n",
      "129/224, train_loss: 0.1771, step time: 0.3782\n",
      "130/224, train_loss: 0.1607, step time: 0.3168\n",
      "131/224, train_loss: 0.1880, step time: 0.4092\n",
      "132/224, train_loss: 0.2753, step time: 0.3884\n",
      "133/224, train_loss: 0.1034, step time: 0.3154\n",
      "134/224, train_loss: 0.0940, step time: 0.3146\n",
      "135/224, train_loss: 0.1594, step time: 0.3789\n",
      "136/224, train_loss: 0.2074, step time: 0.3157\n",
      "137/224, train_loss: 0.1720, step time: 0.3168\n",
      "138/224, train_loss: 0.1421, step time: 0.3152\n",
      "139/224, train_loss: 0.1493, step time: 0.3148\n",
      "140/224, train_loss: 0.1214, step time: 0.3744\n",
      "141/224, train_loss: 0.3560, step time: 0.3177\n",
      "142/224, train_loss: 0.3972, step time: 0.4073\n",
      "143/224, train_loss: 0.2579, step time: 0.3171\n",
      "144/224, train_loss: 0.1071, step time: 0.3144\n",
      "145/224, train_loss: 0.0680, step time: 0.3141\n",
      "146/224, train_loss: 0.3057, step time: 0.4121\n",
      "147/224, train_loss: 0.2219, step time: 0.4006\n",
      "148/224, train_loss: 0.1106, step time: 0.3661\n",
      "149/224, train_loss: 0.1026, step time: 0.3124\n",
      "150/224, train_loss: 0.1997, step time: 0.3172\n",
      "151/224, train_loss: 0.2349, step time: 0.3158\n",
      "152/224, train_loss: 0.1681, step time: 0.3156\n",
      "153/224, train_loss: 0.1969, step time: 0.3807\n",
      "154/224, train_loss: 0.0788, step time: 0.3135\n",
      "155/224, train_loss: 0.1240, step time: 0.3168\n",
      "156/224, train_loss: 0.1625, step time: 0.3155\n",
      "157/224, train_loss: 0.0879, step time: 0.3174\n",
      "158/224, train_loss: 0.0780, step time: 0.3152\n",
      "159/224, train_loss: 0.3094, step time: 0.3688\n",
      "160/224, train_loss: 0.2316, step time: 0.4019\n",
      "161/224, train_loss: 0.0689, step time: 0.3146\n",
      "162/224, train_loss: 0.4528, step time: 0.3993\n",
      "163/224, train_loss: 0.0934, step time: 0.4139\n",
      "164/224, train_loss: 0.3335, step time: 0.3738\n",
      "165/224, train_loss: 0.1104, step time: 0.3189\n",
      "166/224, train_loss: 0.1248, step time: 0.3162\n",
      "167/224, train_loss: 0.1842, step time: 0.3999\n",
      "168/224, train_loss: 0.1404, step time: 0.3722\n",
      "169/224, train_loss: 0.1399, step time: 0.3134\n",
      "170/224, train_loss: 0.0994, step time: 0.3152\n",
      "171/224, train_loss: 0.3073, step time: 0.3956\n",
      "172/224, train_loss: 0.0883, step time: 0.3165\n",
      "173/224, train_loss: 0.1791, step time: 0.3144\n",
      "174/224, train_loss: 0.1080, step time: 0.3134\n",
      "175/224, train_loss: 0.0996, step time: 0.3183\n",
      "176/224, train_loss: 0.1939, step time: 0.3718\n",
      "177/224, train_loss: 0.2688, step time: 0.4014\n",
      "178/224, train_loss: 0.0786, step time: 0.3172\n",
      "179/224, train_loss: 0.0782, step time: 0.3980\n",
      "180/224, train_loss: 0.3085, step time: 0.4134\n",
      "181/224, train_loss: 0.3240, step time: 0.3168\n",
      "182/224, train_loss: 0.1282, step time: 0.3934\n",
      "183/224, train_loss: 0.1268, step time: 0.3149\n",
      "184/224, train_loss: 0.1048, step time: 0.3150\n",
      "185/224, train_loss: 0.1453, step time: 0.3179\n",
      "186/224, train_loss: 0.1182, step time: 0.4014\n",
      "187/224, train_loss: 0.2145, step time: 0.3171\n",
      "188/224, train_loss: 0.1056, step time: 0.3813\n",
      "189/224, train_loss: 0.1082, step time: 0.3175\n",
      "190/224, train_loss: 0.1533, step time: 0.3187\n",
      "191/224, train_loss: 0.0653, step time: 0.3665\n",
      "192/224, train_loss: 0.3104, step time: 0.3157\n",
      "193/224, train_loss: 0.1290, step time: 0.3155\n",
      "194/224, train_loss: 0.1941, step time: 0.3895\n",
      "195/224, train_loss: 0.3797, step time: 0.3888\n",
      "196/224, train_loss: 0.1556, step time: 0.3157\n",
      "197/224, train_loss: 0.1590, step time: 0.3152\n",
      "198/224, train_loss: 0.3061, step time: 0.3145\n",
      "199/224, train_loss: 0.1200, step time: 0.4051\n",
      "200/224, train_loss: 0.0715, step time: 0.4130\n",
      "201/224, train_loss: 0.1652, step time: 0.3779\n",
      "202/224, train_loss: 0.1787, step time: 0.3153\n",
      "203/224, train_loss: 0.3010, step time: 0.4075\n",
      "204/224, train_loss: 0.1670, step time: 0.3924\n",
      "205/224, train_loss: 0.0736, step time: 0.3138\n",
      "206/224, train_loss: 0.0739, step time: 0.3153\n",
      "207/224, train_loss: 0.1375, step time: 0.3176\n",
      "208/224, train_loss: 0.1253, step time: 0.4114\n",
      "209/224, train_loss: 0.1329, step time: 0.3121\n",
      "210/224, train_loss: 0.1640, step time: 0.3173\n",
      "211/224, train_loss: 0.3019, step time: 0.4039\n",
      "212/224, train_loss: 0.1410, step time: 0.3148\n",
      "213/224, train_loss: 0.0818, step time: 0.3142\n",
      "214/224, train_loss: 0.0762, step time: 0.3888\n",
      "215/224, train_loss: 0.1894, step time: 0.3710\n",
      "216/224, train_loss: 0.1245, step time: 0.3146\n",
      "217/224, train_loss: 0.0679, step time: 0.3144\n",
      "218/224, train_loss: 0.0928, step time: 0.3164\n",
      "219/224, train_loss: 0.1459, step time: 0.3774\n",
      "220/224, train_loss: 0.3693, step time: 0.3952\n",
      "221/224, train_loss: 0.3408, step time: 0.3805\n",
      "222/224, train_loss: 0.1316, step time: 0.3171\n",
      "223/224, train_loss: 0.1611, step time: 0.3657\n",
      "224/224, train_loss: 0.1155, step time: 0.3134\n",
      "epoch 52 average loss: 0.1674\n",
      "current epoch: 52 current mean dice: 0.6937 class1: 0.9993 class2: 0.7368 class3: 0.3451\n",
      "best mean dice: 0.7055 at epoch: 50\n",
      "time consuming of epoch 52 is: 683.0365\n",
      "hello\n",
      "----------\n",
      "epoch 53/100\n",
      "1/224, train_loss: 0.2229, step time: 0.3989\n",
      "2/224, train_loss: 0.1242, step time: 0.3149\n",
      "3/224, train_loss: 0.0873, step time: 0.3969\n",
      "4/224, train_loss: 0.1110, step time: 0.4086\n",
      "5/224, train_loss: 0.3435, step time: 0.4101\n",
      "6/224, train_loss: 0.0780, step time: 0.3160\n",
      "7/224, train_loss: 0.1697, step time: 0.3134\n",
      "8/224, train_loss: 0.1286, step time: 0.3172\n",
      "9/224, train_loss: 0.1178, step time: 0.3755\n",
      "10/224, train_loss: 0.1148, step time: 0.3803\n",
      "11/224, train_loss: 0.2707, step time: 0.3149\n",
      "12/224, train_loss: 0.1732, step time: 0.3149\n",
      "13/224, train_loss: 0.0984, step time: 0.3164\n",
      "14/224, train_loss: 0.1438, step time: 0.3140\n",
      "15/224, train_loss: 0.1094, step time: 0.3170\n",
      "16/224, train_loss: 0.3009, step time: 0.3738\n",
      "17/224, train_loss: 0.1095, step time: 0.3173\n",
      "18/224, train_loss: 0.1621, step time: 0.3995\n",
      "19/224, train_loss: 0.0729, step time: 0.3152\n",
      "20/224, train_loss: 0.2318, step time: 0.4078\n",
      "21/224, train_loss: 0.1024, step time: 0.3151\n",
      "22/224, train_loss: 0.4051, step time: 0.3874\n",
      "23/224, train_loss: 0.0900, step time: 0.3869\n",
      "24/224, train_loss: 0.1480, step time: 0.3149\n",
      "25/224, train_loss: 0.1824, step time: 0.3750\n",
      "26/224, train_loss: 0.2045, step time: 0.3124\n",
      "27/224, train_loss: 0.1241, step time: 0.3122\n",
      "28/224, train_loss: 0.1305, step time: 0.4006\n",
      "29/224, train_loss: 0.0794, step time: 0.3125\n",
      "30/224, train_loss: 0.1414, step time: 0.4072\n",
      "31/224, train_loss: 0.1696, step time: 0.4032\n",
      "32/224, train_loss: 0.1064, step time: 0.3156\n",
      "33/224, train_loss: 0.0909, step time: 0.3151\n",
      "34/224, train_loss: 0.1310, step time: 0.3973\n",
      "35/224, train_loss: 0.1737, step time: 0.3144\n",
      "36/224, train_loss: 0.1395, step time: 0.3791\n",
      "37/224, train_loss: 0.0910, step time: 0.3174\n",
      "38/224, train_loss: 0.0718, step time: 0.3170\n",
      "39/224, train_loss: 0.1237, step time: 0.3144\n",
      "40/224, train_loss: 0.1346, step time: 0.3172\n",
      "41/224, train_loss: 0.1892, step time: 0.3147\n",
      "42/224, train_loss: 0.0887, step time: 0.3143\n",
      "43/224, train_loss: 0.1598, step time: 0.3144\n",
      "44/224, train_loss: 0.1133, step time: 0.3764\n",
      "45/224, train_loss: 0.1058, step time: 0.4107\n",
      "46/224, train_loss: 0.1160, step time: 0.3130\n",
      "47/224, train_loss: 0.0688, step time: 0.3176\n",
      "48/224, train_loss: 0.0998, step time: 0.3823\n",
      "49/224, train_loss: 0.3561, step time: 0.3749\n",
      "50/224, train_loss: 0.0681, step time: 0.3147\n",
      "51/224, train_loss: 0.0824, step time: 0.3712\n",
      "52/224, train_loss: 0.0688, step time: 0.3821\n",
      "53/224, train_loss: 0.1206, step time: 0.3130\n",
      "54/224, train_loss: 0.1219, step time: 0.3838\n",
      "55/224, train_loss: 0.1021, step time: 0.3152\n",
      "56/224, train_loss: 0.0753, step time: 0.3770\n",
      "57/224, train_loss: 0.0677, step time: 0.3144\n",
      "58/224, train_loss: 0.1257, step time: 0.3144\n",
      "59/224, train_loss: 0.4199, step time: 0.5480\n",
      "60/224, train_loss: 0.0884, step time: 0.4019\n",
      "61/224, train_loss: 0.1534, step time: 0.3150\n",
      "62/224, train_loss: 0.2079, step time: 0.3134\n",
      "63/224, train_loss: 0.0484, step time: 0.3786\n",
      "64/224, train_loss: 0.0991, step time: 0.3653\n",
      "65/224, train_loss: 0.0819, step time: 0.3150\n",
      "66/224, train_loss: 0.0939, step time: 0.3155\n",
      "67/224, train_loss: 0.0962, step time: 0.3151\n",
      "68/224, train_loss: 0.1461, step time: 0.3165\n",
      "69/224, train_loss: 0.0814, step time: 0.3796\n",
      "70/224, train_loss: 0.3413, step time: 0.3951\n",
      "71/224, train_loss: 0.0925, step time: 0.3146\n",
      "72/224, train_loss: 0.1504, step time: 0.3149\n",
      "73/224, train_loss: 0.1367, step time: 0.3703\n",
      "74/224, train_loss: 0.0629, step time: 0.3704\n",
      "75/224, train_loss: 0.0719, step time: 0.3130\n",
      "76/224, train_loss: 0.3499, step time: 0.4004\n",
      "77/224, train_loss: 0.1747, step time: 0.3835\n",
      "78/224, train_loss: 0.1785, step time: 0.4062\n",
      "79/224, train_loss: 0.2380, step time: 0.3866\n",
      "80/224, train_loss: 0.1286, step time: 0.3160\n",
      "81/224, train_loss: 0.1384, step time: 0.3133\n",
      "82/224, train_loss: 0.3370, step time: 0.3766\n",
      "83/224, train_loss: 0.4787, step time: 0.3873\n",
      "84/224, train_loss: 0.1204, step time: 0.3132\n",
      "85/224, train_loss: 0.1017, step time: 0.3944\n",
      "86/224, train_loss: 0.1450, step time: 0.3140\n",
      "87/224, train_loss: 0.1744, step time: 0.4095\n",
      "88/224, train_loss: 0.0806, step time: 0.3176\n",
      "89/224, train_loss: 0.0880, step time: 0.3713\n",
      "90/224, train_loss: 0.1394, step time: 0.3801\n",
      "91/224, train_loss: 0.0862, step time: 0.3948\n",
      "92/224, train_loss: 0.2843, step time: 0.3156\n",
      "93/224, train_loss: 0.3219, step time: 0.4002\n",
      "94/224, train_loss: 0.1575, step time: 0.3850\n",
      "95/224, train_loss: 0.1095, step time: 0.3161\n",
      "96/224, train_loss: 0.1676, step time: 0.3174\n",
      "97/224, train_loss: 0.0946, step time: 0.3666\n",
      "98/224, train_loss: 0.1480, step time: 0.3708\n",
      "99/224, train_loss: 0.1543, step time: 0.3179\n",
      "100/224, train_loss: 0.1577, step time: 0.3181\n",
      "101/224, train_loss: 0.1101, step time: 0.3152\n",
      "102/224, train_loss: 0.0965, step time: 0.4098\n",
      "103/224, train_loss: 0.1562, step time: 0.3681\n",
      "104/224, train_loss: 0.1460, step time: 0.3844\n",
      "105/224, train_loss: 0.1518, step time: 0.3830\n",
      "106/224, train_loss: 0.1273, step time: 0.3156\n",
      "107/224, train_loss: 0.3510, step time: 0.3180\n",
      "108/224, train_loss: 0.1111, step time: 0.3179\n",
      "109/224, train_loss: 0.1369, step time: 0.4046\n",
      "110/224, train_loss: 0.2926, step time: 0.3848\n",
      "111/224, train_loss: 0.1081, step time: 0.3129\n",
      "112/224, train_loss: 0.1104, step time: 0.3169\n",
      "113/224, train_loss: 0.0955, step time: 0.3642\n",
      "114/224, train_loss: 0.2504, step time: 0.3822\n",
      "115/224, train_loss: 0.1332, step time: 0.3145\n",
      "116/224, train_loss: 0.2085, step time: 0.4083\n",
      "117/224, train_loss: 0.1597, step time: 0.3766\n",
      "118/224, train_loss: 0.2417, step time: 0.3937\n",
      "119/224, train_loss: 0.1596, step time: 0.3959\n",
      "120/224, train_loss: 0.1146, step time: 0.3158\n",
      "121/224, train_loss: 0.0876, step time: 0.3126\n",
      "122/224, train_loss: 0.3105, step time: 0.4033\n",
      "123/224, train_loss: 0.0858, step time: 0.3148\n",
      "124/224, train_loss: 0.1161, step time: 0.3147\n",
      "125/224, train_loss: 0.2320, step time: 0.3857\n",
      "126/224, train_loss: 0.2262, step time: 0.3874\n",
      "127/224, train_loss: 0.1358, step time: 0.3123\n",
      "128/224, train_loss: 0.0816, step time: 0.3125\n",
      "129/224, train_loss: 0.3167, step time: 0.3747\n",
      "130/224, train_loss: 0.0600, step time: 0.3147\n",
      "131/224, train_loss: 0.1350, step time: 0.3170\n",
      "132/224, train_loss: 0.1468, step time: 0.3126\n",
      "133/224, train_loss: 0.0930, step time: 0.3692\n",
      "134/224, train_loss: 0.2171, step time: 0.3144\n",
      "135/224, train_loss: 0.0782, step time: 0.3977\n",
      "136/224, train_loss: 0.3445, step time: 0.3745\n",
      "137/224, train_loss: 0.0972, step time: 0.3178\n",
      "138/224, train_loss: 0.1960, step time: 0.3719\n",
      "139/224, train_loss: 0.0953, step time: 0.3170\n",
      "140/224, train_loss: 0.0994, step time: 0.3652\n",
      "141/224, train_loss: 0.2167, step time: 0.3123\n",
      "142/224, train_loss: 0.1476, step time: 0.3937\n",
      "143/224, train_loss: 0.1110, step time: 0.3148\n",
      "144/224, train_loss: 0.2499, step time: 0.3816\n",
      "145/224, train_loss: 0.2647, step time: 0.4028\n",
      "146/224, train_loss: 0.1379, step time: 0.3944\n",
      "147/224, train_loss: 0.0756, step time: 0.3132\n",
      "148/224, train_loss: 0.0761, step time: 0.3733\n",
      "149/224, train_loss: 0.1198, step time: 0.3907\n",
      "150/224, train_loss: 0.1341, step time: 0.3869\n",
      "151/224, train_loss: 0.0799, step time: 0.3701\n",
      "152/224, train_loss: 0.1680, step time: 0.3625\n",
      "153/224, train_loss: 0.1139, step time: 0.3147\n",
      "154/224, train_loss: 0.0872, step time: 0.3145\n",
      "155/224, train_loss: 0.3084, step time: 0.3175\n",
      "156/224, train_loss: 0.1818, step time: 0.3675\n",
      "157/224, train_loss: 0.0934, step time: 0.3155\n",
      "158/224, train_loss: 0.2538, step time: 0.3178\n",
      "159/224, train_loss: 0.2747, step time: 0.3149\n",
      "160/224, train_loss: 0.1619, step time: 0.4083\n",
      "161/224, train_loss: 0.1492, step time: 0.3180\n",
      "162/224, train_loss: 0.2944, step time: 0.4042\n",
      "163/224, train_loss: 0.2907, step time: 0.3169\n",
      "164/224, train_loss: 0.2431, step time: 0.4062\n",
      "165/224, train_loss: 0.1229, step time: 0.3778\n",
      "166/224, train_loss: 0.1133, step time: 0.3151\n",
      "167/224, train_loss: 0.1349, step time: 0.3794\n",
      "168/224, train_loss: 0.3144, step time: 0.3830\n",
      "169/224, train_loss: 0.1970, step time: 0.3850\n",
      "170/224, train_loss: 0.1326, step time: 0.3155\n",
      "171/224, train_loss: 0.1096, step time: 0.3173\n",
      "172/224, train_loss: 0.2693, step time: 0.3148\n",
      "173/224, train_loss: 0.3542, step time: 0.3951\n",
      "174/224, train_loss: 0.1490, step time: 0.4028\n",
      "175/224, train_loss: 0.0809, step time: 0.3676\n",
      "176/224, train_loss: 0.0530, step time: 0.3132\n",
      "177/224, train_loss: 0.1406, step time: 0.3178\n",
      "178/224, train_loss: 0.1150, step time: 0.3180\n",
      "179/224, train_loss: 0.0910, step time: 0.3184\n",
      "180/224, train_loss: 0.0770, step time: 0.3991\n",
      "181/224, train_loss: 0.1072, step time: 0.3144\n",
      "182/224, train_loss: 0.1810, step time: 0.3817\n",
      "183/224, train_loss: 0.1669, step time: 0.3800\n",
      "184/224, train_loss: 0.1111, step time: 0.3895\n",
      "185/224, train_loss: 0.1923, step time: 0.3143\n",
      "186/224, train_loss: 0.1571, step time: 0.3966\n",
      "187/224, train_loss: 0.1938, step time: 0.4090\n",
      "188/224, train_loss: 0.0794, step time: 0.4013\n",
      "189/224, train_loss: 0.2425, step time: 0.3794\n",
      "190/224, train_loss: 0.1784, step time: 0.3759\n",
      "191/224, train_loss: 0.3582, step time: 0.3720\n",
      "192/224, train_loss: 0.1389, step time: 0.3173\n",
      "193/224, train_loss: 0.1657, step time: 0.3145\n",
      "194/224, train_loss: 0.0673, step time: 0.3140\n",
      "195/224, train_loss: 0.1273, step time: 0.3151\n",
      "196/224, train_loss: 0.1833, step time: 0.3741\n",
      "197/224, train_loss: 0.2660, step time: 0.3132\n",
      "198/224, train_loss: 0.3182, step time: 0.3767\n",
      "199/224, train_loss: 0.1070, step time: 0.3965\n",
      "200/224, train_loss: 0.1438, step time: 0.4047\n",
      "201/224, train_loss: 0.3851, step time: 0.3908\n",
      "202/224, train_loss: 0.0446, step time: 0.3151\n",
      "203/224, train_loss: 0.1558, step time: 0.3884\n",
      "204/224, train_loss: 0.2297, step time: 0.3847\n",
      "205/224, train_loss: 0.1109, step time: 0.4072\n",
      "206/224, train_loss: 0.1211, step time: 0.3147\n",
      "207/224, train_loss: 0.2022, step time: 0.3700\n",
      "208/224, train_loss: 0.2643, step time: 0.3157\n",
      "209/224, train_loss: 0.1572, step time: 0.4056\n",
      "210/224, train_loss: 0.1125, step time: 0.3123\n",
      "211/224, train_loss: 0.1357, step time: 0.4141\n",
      "212/224, train_loss: 0.1405, step time: 0.3173\n",
      "213/224, train_loss: 0.0671, step time: 0.3125\n",
      "214/224, train_loss: 0.0808, step time: 0.3127\n",
      "215/224, train_loss: 0.1068, step time: 0.3168\n",
      "216/224, train_loss: 0.1513, step time: 0.3671\n",
      "217/224, train_loss: 0.1456, step time: 0.3143\n",
      "218/224, train_loss: 0.1155, step time: 0.3169\n",
      "219/224, train_loss: 0.1868, step time: 0.4131\n",
      "220/224, train_loss: 0.0992, step time: 0.3866\n",
      "221/224, train_loss: 0.2352, step time: 0.3871\n",
      "222/224, train_loss: 0.0950, step time: 0.4087\n",
      "223/224, train_loss: 0.2563, step time: 0.3733\n",
      "224/224, train_loss: 0.1392, step time: 0.3167\n",
      "epoch 53 average loss: 0.1580\n",
      "current epoch: 53 current mean dice: 0.7136 class1: 0.9993 class2: 0.7294 class3: 0.4121\n",
      "best mean dice: 0.7136 at epoch: 53\n",
      "time consuming of epoch 53 is: 752.2731\n",
      "hello\n",
      "----------\n",
      "epoch 54/100\n",
      "1/224, train_loss: 0.1362, step time: 0.3179\n",
      "2/224, train_loss: 0.3607, step time: 0.3946\n",
      "3/224, train_loss: 0.2459, step time: 0.3768\n",
      "4/224, train_loss: 0.3690, step time: 0.4014\n",
      "5/224, train_loss: 0.1590, step time: 0.3851\n",
      "6/224, train_loss: 0.0637, step time: 0.4027\n",
      "7/224, train_loss: 0.1513, step time: 0.3728\n",
      "8/224, train_loss: 0.1082, step time: 0.3665\n",
      "9/224, train_loss: 0.2168, step time: 0.3146\n",
      "10/224, train_loss: 0.1939, step time: 0.3145\n",
      "11/224, train_loss: 0.1103, step time: 0.3126\n",
      "12/224, train_loss: 0.0751, step time: 0.3124\n",
      "13/224, train_loss: 0.1519, step time: 0.3175\n",
      "14/224, train_loss: 0.1391, step time: 0.4069\n",
      "15/224, train_loss: 0.1046, step time: 0.3996\n",
      "16/224, train_loss: 0.1094, step time: 0.3718\n",
      "17/224, train_loss: 0.2078, step time: 0.3984\n",
      "18/224, train_loss: 0.0792, step time: 0.3146\n",
      "19/224, train_loss: 0.0930, step time: 0.3147\n",
      "20/224, train_loss: 0.0909, step time: 0.3153\n",
      "21/224, train_loss: 0.1825, step time: 0.3879\n",
      "22/224, train_loss: 0.2093, step time: 0.4059\n",
      "23/224, train_loss: 0.1026, step time: 0.3678\n",
      "24/224, train_loss: 0.1180, step time: 0.3160\n",
      "25/224, train_loss: 0.0674, step time: 0.3165\n",
      "26/224, train_loss: 0.1900, step time: 0.4021\n",
      "27/224, train_loss: 0.1756, step time: 0.3160\n",
      "28/224, train_loss: 0.0441, step time: 0.3712\n",
      "29/224, train_loss: 0.2147, step time: 0.3919\n",
      "30/224, train_loss: 0.1753, step time: 0.3179\n",
      "31/224, train_loss: 0.1325, step time: 0.3154\n",
      "32/224, train_loss: 0.0960, step time: 0.3708\n",
      "33/224, train_loss: 0.1149, step time: 0.4022\n",
      "34/224, train_loss: 0.0905, step time: 0.3887\n",
      "35/224, train_loss: 0.3544, step time: 0.3755\n",
      "36/224, train_loss: 0.1783, step time: 0.3754\n",
      "37/224, train_loss: 0.1853, step time: 0.3890\n",
      "38/224, train_loss: 0.1019, step time: 0.3150\n",
      "39/224, train_loss: 0.1153, step time: 0.4002\n",
      "40/224, train_loss: 0.0699, step time: 0.3700\n",
      "41/224, train_loss: 0.1699, step time: 0.3909\n",
      "42/224, train_loss: 0.1155, step time: 0.3992\n",
      "43/224, train_loss: 0.0857, step time: 0.3133\n",
      "44/224, train_loss: 0.1093, step time: 0.3155\n",
      "45/224, train_loss: 0.2023, step time: 0.3675\n",
      "46/224, train_loss: 0.0726, step time: 0.3951\n",
      "47/224, train_loss: 0.1165, step time: 0.4092\n",
      "48/224, train_loss: 0.1202, step time: 0.3910\n",
      "49/224, train_loss: 0.1039, step time: 0.3819\n",
      "50/224, train_loss: 0.1318, step time: 0.3150\n",
      "51/224, train_loss: 0.2746, step time: 0.4118\n",
      "52/224, train_loss: 0.0952, step time: 0.3157\n",
      "53/224, train_loss: 0.1264, step time: 0.3148\n",
      "54/224, train_loss: 0.0742, step time: 0.4057\n",
      "55/224, train_loss: 0.2362, step time: 0.3146\n",
      "56/224, train_loss: 0.1359, step time: 0.3150\n",
      "57/224, train_loss: 0.1541, step time: 0.4107\n",
      "58/224, train_loss: 0.3992, step time: 0.3169\n",
      "59/224, train_loss: 0.0876, step time: 0.3732\n",
      "60/224, train_loss: 0.1100, step time: 0.3979\n",
      "61/224, train_loss: 0.2606, step time: 0.3127\n",
      "62/224, train_loss: 0.0903, step time: 0.3177\n",
      "63/224, train_loss: 0.0805, step time: 0.3889\n",
      "64/224, train_loss: 0.1265, step time: 0.3152\n",
      "65/224, train_loss: 0.1044, step time: 0.3699\n",
      "66/224, train_loss: 0.0682, step time: 0.3148\n",
      "67/224, train_loss: 0.3606, step time: 0.4103\n",
      "68/224, train_loss: 0.0756, step time: 0.3678\n",
      "69/224, train_loss: 0.3334, step time: 0.3683\n",
      "70/224, train_loss: 0.1424, step time: 0.3145\n",
      "71/224, train_loss: 0.1270, step time: 0.3748\n",
      "72/224, train_loss: 0.0993, step time: 0.3892\n",
      "73/224, train_loss: 0.0714, step time: 0.3174\n",
      "74/224, train_loss: 0.1688, step time: 0.3718\n",
      "75/224, train_loss: 0.1441, step time: 0.3849\n",
      "76/224, train_loss: 0.1698, step time: 0.3156\n",
      "77/224, train_loss: 0.0744, step time: 0.3172\n",
      "78/224, train_loss: 0.1097, step time: 0.3142\n",
      "79/224, train_loss: 0.1375, step time: 0.3887\n",
      "80/224, train_loss: 0.1154, step time: 0.4002\n",
      "81/224, train_loss: 0.0711, step time: 0.3151\n",
      "82/224, train_loss: 0.1188, step time: 0.4103\n",
      "83/224, train_loss: 0.1223, step time: 0.3147\n",
      "84/224, train_loss: 0.3016, step time: 0.3803\n",
      "85/224, train_loss: 0.1668, step time: 0.4025\n",
      "86/224, train_loss: 0.1145, step time: 0.3143\n",
      "87/224, train_loss: 0.0999, step time: 0.3151\n",
      "88/224, train_loss: 0.1153, step time: 0.3144\n",
      "89/224, train_loss: 0.1183, step time: 0.3865\n",
      "90/224, train_loss: 0.1694, step time: 0.4074\n",
      "91/224, train_loss: 0.1800, step time: 0.3807\n",
      "92/224, train_loss: 0.0873, step time: 0.3157\n",
      "93/224, train_loss: 0.1304, step time: 0.3698\n",
      "94/224, train_loss: 0.1040, step time: 0.3171\n",
      "95/224, train_loss: 0.1440, step time: 0.3737\n",
      "96/224, train_loss: 0.0966, step time: 0.3698\n",
      "97/224, train_loss: 0.0948, step time: 0.3181\n",
      "98/224, train_loss: 0.3628, step time: 0.3171\n",
      "99/224, train_loss: 0.1193, step time: 0.3141\n",
      "100/224, train_loss: 0.1407, step time: 0.3150\n",
      "101/224, train_loss: 0.4216, step time: 0.3800\n",
      "102/224, train_loss: 0.1206, step time: 0.3767\n",
      "103/224, train_loss: 0.1363, step time: 0.3945\n",
      "104/224, train_loss: 0.0917, step time: 0.3880\n",
      "105/224, train_loss: 0.1495, step time: 0.3175\n",
      "106/224, train_loss: 0.1641, step time: 0.3818\n",
      "107/224, train_loss: 0.0984, step time: 0.3151\n",
      "108/224, train_loss: 0.2140, step time: 0.3180\n",
      "109/224, train_loss: 0.1167, step time: 0.3781\n",
      "110/224, train_loss: 0.1081, step time: 0.3785\n",
      "111/224, train_loss: 0.3971, step time: 0.3149\n",
      "112/224, train_loss: 0.1561, step time: 0.4049\n",
      "113/224, train_loss: 0.0921, step time: 0.3751\n",
      "114/224, train_loss: 0.1211, step time: 0.3153\n",
      "115/224, train_loss: 0.1106, step time: 0.4036\n",
      "116/224, train_loss: 0.2101, step time: 0.3777\n",
      "117/224, train_loss: 0.1645, step time: 0.3999\n",
      "118/224, train_loss: 0.0910, step time: 0.3143\n",
      "119/224, train_loss: 0.1023, step time: 0.3144\n",
      "120/224, train_loss: 0.1520, step time: 0.3132\n",
      "121/224, train_loss: 0.1856, step time: 0.3700\n",
      "122/224, train_loss: 0.0931, step time: 0.3123\n",
      "123/224, train_loss: 0.1065, step time: 0.3999\n",
      "124/224, train_loss: 0.1034, step time: 0.3690\n",
      "125/224, train_loss: 0.2464, step time: 0.3170\n",
      "126/224, train_loss: 0.2732, step time: 0.3136\n",
      "127/224, train_loss: 0.1221, step time: 0.3910\n",
      "128/224, train_loss: 0.1492, step time: 0.3810\n",
      "129/224, train_loss: 0.0862, step time: 0.3130\n",
      "130/224, train_loss: 0.0867, step time: 0.3145\n",
      "131/224, train_loss: 0.1541, step time: 0.3973\n",
      "132/224, train_loss: 0.0905, step time: 0.3178\n",
      "133/224, train_loss: 0.1356, step time: 0.3714\n",
      "134/224, train_loss: 0.0923, step time: 0.3155\n",
      "135/224, train_loss: 0.2137, step time: 0.4038\n",
      "136/224, train_loss: 0.0711, step time: 0.3760\n",
      "137/224, train_loss: 0.1295, step time: 0.3766\n",
      "138/224, train_loss: 0.0745, step time: 0.3913\n",
      "139/224, train_loss: 0.1208, step time: 0.3179\n",
      "140/224, train_loss: 0.1646, step time: 0.3880\n",
      "141/224, train_loss: 0.2293, step time: 0.4083\n",
      "142/224, train_loss: 0.2202, step time: 0.3758\n",
      "143/224, train_loss: 0.2726, step time: 0.3830\n",
      "144/224, train_loss: 0.2214, step time: 0.3746\n",
      "145/224, train_loss: 0.0978, step time: 0.3143\n",
      "146/224, train_loss: 0.1340, step time: 0.3678\n",
      "147/224, train_loss: 0.0743, step time: 0.3152\n",
      "148/224, train_loss: 0.1649, step time: 0.3153\n",
      "149/224, train_loss: 0.1008, step time: 0.3645\n",
      "150/224, train_loss: 0.1477, step time: 0.3154\n",
      "151/224, train_loss: 0.1384, step time: 0.3150\n",
      "152/224, train_loss: 0.2221, step time: 0.3174\n",
      "153/224, train_loss: 0.0978, step time: 0.3736\n",
      "154/224, train_loss: 0.0758, step time: 0.3168\n",
      "155/224, train_loss: 0.1438, step time: 0.3931\n",
      "156/224, train_loss: 0.3552, step time: 0.3726\n",
      "157/224, train_loss: 0.0818, step time: 0.3153\n",
      "158/224, train_loss: 0.3408, step time: 0.3145\n",
      "159/224, train_loss: 0.1510, step time: 0.3145\n",
      "160/224, train_loss: 0.0520, step time: 0.3171\n",
      "161/224, train_loss: 0.2929, step time: 0.3146\n",
      "162/224, train_loss: 0.0804, step time: 0.3151\n",
      "163/224, train_loss: 0.2897, step time: 0.3148\n",
      "164/224, train_loss: 0.1508, step time: 0.4077\n",
      "165/224, train_loss: 0.1444, step time: 0.3172\n",
      "166/224, train_loss: 0.3466, step time: 0.3146\n",
      "167/224, train_loss: 0.3069, step time: 0.3143\n",
      "168/224, train_loss: 0.1850, step time: 0.3936\n",
      "169/224, train_loss: 0.1154, step time: 0.3172\n",
      "170/224, train_loss: 0.2417, step time: 0.3904\n",
      "171/224, train_loss: 0.0628, step time: 0.3145\n",
      "172/224, train_loss: 0.4125, step time: 0.3636\n",
      "173/224, train_loss: 0.1426, step time: 0.3171\n",
      "174/224, train_loss: 0.0903, step time: 0.3159\n",
      "175/224, train_loss: 0.2489, step time: 0.3720\n",
      "176/224, train_loss: 0.0951, step time: 0.3156\n",
      "177/224, train_loss: 0.3393, step time: 0.3179\n",
      "178/224, train_loss: 0.0728, step time: 0.3886\n",
      "179/224, train_loss: 0.1677, step time: 0.3154\n",
      "180/224, train_loss: 0.0547, step time: 0.3147\n",
      "181/224, train_loss: 0.0932, step time: 0.3177\n",
      "182/224, train_loss: 0.2297, step time: 0.4139\n",
      "183/224, train_loss: 0.1023, step time: 0.3849\n",
      "184/224, train_loss: 0.1441, step time: 0.3757\n",
      "185/224, train_loss: 0.0960, step time: 0.3968\n",
      "186/224, train_loss: 0.1571, step time: 0.3178\n",
      "187/224, train_loss: 0.0691, step time: 0.3130\n",
      "188/224, train_loss: 0.0945, step time: 0.3147\n",
      "189/224, train_loss: 0.0815, step time: 0.3148\n",
      "190/224, train_loss: 0.1256, step time: 0.4086\n",
      "191/224, train_loss: 0.2044, step time: 0.3176\n",
      "192/224, train_loss: 0.1227, step time: 0.3132\n",
      "193/224, train_loss: 0.0556, step time: 0.3148\n",
      "194/224, train_loss: 0.2569, step time: 0.3153\n",
      "195/224, train_loss: 0.1247, step time: 0.3178\n",
      "196/224, train_loss: 0.1676, step time: 0.4007\n",
      "197/224, train_loss: 0.1028, step time: 0.4082\n",
      "198/224, train_loss: 0.1728, step time: 0.3157\n",
      "199/224, train_loss: 0.1203, step time: 0.3182\n",
      "200/224, train_loss: 0.1965, step time: 0.4043\n",
      "201/224, train_loss: 0.1412, step time: 0.3959\n",
      "202/224, train_loss: 0.0798, step time: 0.4059\n",
      "203/224, train_loss: 0.0887, step time: 0.3131\n",
      "204/224, train_loss: 0.1699, step time: 0.3982\n",
      "205/224, train_loss: 0.1526, step time: 0.3162\n",
      "206/224, train_loss: 0.2850, step time: 0.3152\n",
      "207/224, train_loss: 0.1148, step time: 0.3172\n",
      "208/224, train_loss: 0.3009, step time: 0.3826\n",
      "209/224, train_loss: 0.1446, step time: 0.3740\n",
      "210/224, train_loss: 0.0836, step time: 0.3162\n",
      "211/224, train_loss: 0.0940, step time: 0.4099\n",
      "212/224, train_loss: 0.0863, step time: 0.3149\n",
      "213/224, train_loss: 0.1227, step time: 0.3173\n",
      "214/224, train_loss: 0.2991, step time: 0.4027\n",
      "215/224, train_loss: 0.0799, step time: 0.3939\n",
      "216/224, train_loss: 0.1467, step time: 0.3156\n",
      "217/224, train_loss: 0.2825, step time: 0.3126\n",
      "218/224, train_loss: 0.1398, step time: 0.3153\n",
      "219/224, train_loss: 0.3057, step time: 0.4072\n",
      "220/224, train_loss: 0.1920, step time: 0.3807\n",
      "221/224, train_loss: 0.1284, step time: 0.3153\n",
      "222/224, train_loss: 0.1202, step time: 0.3171\n",
      "223/224, train_loss: 0.1632, step time: 0.3668\n",
      "224/224, train_loss: 0.3260, step time: 0.3154\n",
      "epoch 54 average loss: 0.1543\n",
      "current epoch: 54 current mean dice: 0.6898 class1: 0.9992 class2: 0.7208 class3: 0.3494\n",
      "best mean dice: 0.7136 at epoch: 53\n",
      "time consuming of epoch 54 is: 725.8036\n",
      "hello\n",
      "----------\n",
      "epoch 55/100\n",
      "1/224, train_loss: 0.0904, step time: 0.3181\n",
      "2/224, train_loss: 0.0411, step time: 0.3171\n",
      "3/224, train_loss: 0.0893, step time: 0.3146\n",
      "4/224, train_loss: 0.0910, step time: 0.3180\n",
      "5/224, train_loss: 0.4579, step time: 0.3959\n",
      "6/224, train_loss: 0.1266, step time: 0.3914\n",
      "7/224, train_loss: 0.1481, step time: 0.3711\n",
      "8/224, train_loss: 0.1356, step time: 0.3170\n",
      "9/224, train_loss: 0.1447, step time: 0.3126\n",
      "10/224, train_loss: 0.1065, step time: 0.3845\n",
      "11/224, train_loss: 0.1165, step time: 0.3944\n",
      "12/224, train_loss: 0.1877, step time: 0.3934\n",
      "13/224, train_loss: 0.1052, step time: 0.3730\n",
      "14/224, train_loss: 0.1226, step time: 0.3169\n",
      "15/224, train_loss: 0.2401, step time: 0.3716\n",
      "16/224, train_loss: 0.1631, step time: 0.3976\n",
      "17/224, train_loss: 0.3801, step time: 0.3152\n",
      "18/224, train_loss: 0.3407, step time: 0.3862\n",
      "19/224, train_loss: 0.1548, step time: 0.4091\n",
      "20/224, train_loss: 0.1700, step time: 0.3800\n",
      "21/224, train_loss: 0.0973, step time: 0.3179\n",
      "22/224, train_loss: 0.1061, step time: 0.3156\n",
      "23/224, train_loss: 0.1663, step time: 0.4024\n",
      "24/224, train_loss: 0.1230, step time: 0.3153\n",
      "25/224, train_loss: 0.0930, step time: 0.3152\n",
      "26/224, train_loss: 0.3676, step time: 0.3921\n",
      "27/224, train_loss: 0.2874, step time: 0.4035\n",
      "28/224, train_loss: 0.2245, step time: 0.3984\n",
      "29/224, train_loss: 0.1509, step time: 0.3763\n",
      "30/224, train_loss: 0.3356, step time: 0.3929\n",
      "31/224, train_loss: 0.1216, step time: 0.3176\n",
      "32/224, train_loss: 0.1404, step time: 0.3905\n",
      "33/224, train_loss: 0.1616, step time: 0.3690\n",
      "34/224, train_loss: 0.1422, step time: 0.3991\n",
      "35/224, train_loss: 0.0886, step time: 0.3733\n",
      "36/224, train_loss: 0.2074, step time: 0.3957\n",
      "37/224, train_loss: 0.2311, step time: 0.3149\n",
      "38/224, train_loss: 0.1503, step time: 0.3157\n",
      "39/224, train_loss: 0.1223, step time: 0.3645\n",
      "40/224, train_loss: 0.1324, step time: 0.3958\n",
      "41/224, train_loss: 0.3158, step time: 0.3733\n",
      "42/224, train_loss: 0.1523, step time: 0.3152\n",
      "43/224, train_loss: 0.2616, step time: 0.3723\n",
      "44/224, train_loss: 0.1542, step time: 0.3148\n",
      "45/224, train_loss: 0.0653, step time: 0.3169\n",
      "46/224, train_loss: 0.1359, step time: 0.3794\n",
      "47/224, train_loss: 0.0749, step time: 0.3175\n",
      "48/224, train_loss: 0.1265, step time: 0.4053\n",
      "49/224, train_loss: 0.1567, step time: 0.3979\n",
      "50/224, train_loss: 0.1730, step time: 0.3663\n",
      "51/224, train_loss: 0.1196, step time: 0.3136\n",
      "52/224, train_loss: 0.1063, step time: 0.3173\n",
      "53/224, train_loss: 0.2128, step time: 0.3793\n",
      "54/224, train_loss: 0.1129, step time: 0.3146\n",
      "55/224, train_loss: 0.0758, step time: 0.3180\n",
      "56/224, train_loss: 0.1039, step time: 0.3156\n",
      "57/224, train_loss: 0.0833, step time: 0.3184\n",
      "58/224, train_loss: 0.1170, step time: 0.3177\n",
      "59/224, train_loss: 0.2863, step time: 0.3129\n",
      "60/224, train_loss: 0.1241, step time: 0.3148\n",
      "61/224, train_loss: 0.0839, step time: 0.3179\n",
      "62/224, train_loss: 0.2351, step time: 0.3709\n",
      "63/224, train_loss: 0.1028, step time: 0.4075\n",
      "64/224, train_loss: 0.1484, step time: 0.4109\n",
      "65/224, train_loss: 0.0985, step time: 0.3133\n",
      "66/224, train_loss: 0.1133, step time: 0.3177\n",
      "67/224, train_loss: 0.1261, step time: 0.3176\n",
      "68/224, train_loss: 0.1384, step time: 0.3882\n",
      "69/224, train_loss: 0.0878, step time: 0.3144\n",
      "70/224, train_loss: 0.2332, step time: 0.3164\n",
      "71/224, train_loss: 0.1242, step time: 0.3977\n",
      "72/224, train_loss: 0.2884, step time: 0.3788\n",
      "73/224, train_loss: 0.1745, step time: 0.3700\n",
      "74/224, train_loss: 0.2862, step time: 0.3186\n",
      "75/224, train_loss: 0.1010, step time: 0.3147\n",
      "76/224, train_loss: 0.0909, step time: 0.3147\n",
      "77/224, train_loss: 0.0705, step time: 0.3156\n",
      "78/224, train_loss: 0.1574, step time: 0.3162\n",
      "79/224, train_loss: 0.1337, step time: 0.3159\n",
      "80/224, train_loss: 0.1913, step time: 0.3786\n",
      "81/224, train_loss: 0.0975, step time: 0.3149\n",
      "82/224, train_loss: 0.0998, step time: 0.4000\n",
      "83/224, train_loss: 0.1176, step time: 0.3128\n",
      "84/224, train_loss: 0.1640, step time: 0.3948\n",
      "85/224, train_loss: 0.1331, step time: 0.3153\n",
      "86/224, train_loss: 0.0840, step time: 0.3153\n",
      "87/224, train_loss: 0.1682, step time: 0.3174\n",
      "88/224, train_loss: 0.2043, step time: 0.3134\n",
      "89/224, train_loss: 0.0620, step time: 0.3153\n",
      "90/224, train_loss: 0.0842, step time: 0.4071\n",
      "91/224, train_loss: 0.1489, step time: 0.3988\n",
      "92/224, train_loss: 0.2794, step time: 0.3987\n",
      "93/224, train_loss: 0.1511, step time: 0.3772\n",
      "94/224, train_loss: 0.1050, step time: 0.3148\n",
      "95/224, train_loss: 0.1144, step time: 0.3174\n",
      "96/224, train_loss: 0.1232, step time: 0.4034\n",
      "97/224, train_loss: 0.0963, step time: 0.3755\n",
      "98/224, train_loss: 0.2657, step time: 0.3909\n",
      "99/224, train_loss: 0.0936, step time: 0.3150\n",
      "100/224, train_loss: 0.3457, step time: 0.3156\n",
      "101/224, train_loss: 0.2380, step time: 0.3871\n",
      "102/224, train_loss: 0.3456, step time: 0.4074\n",
      "103/224, train_loss: 0.1416, step time: 0.3936\n",
      "104/224, train_loss: 0.0988, step time: 0.3161\n",
      "105/224, train_loss: 0.0936, step time: 0.3714\n",
      "106/224, train_loss: 0.1832, step time: 0.3662\n",
      "107/224, train_loss: 0.1757, step time: 0.3158\n",
      "108/224, train_loss: 0.2019, step time: 0.3923\n",
      "109/224, train_loss: 0.1573, step time: 0.3853\n",
      "110/224, train_loss: 0.0998, step time: 0.3179\n",
      "111/224, train_loss: 0.1152, step time: 0.3152\n",
      "112/224, train_loss: 0.2193, step time: 0.3146\n",
      "113/224, train_loss: 0.0746, step time: 0.3128\n",
      "114/224, train_loss: 0.1141, step time: 0.4035\n",
      "115/224, train_loss: 0.1189, step time: 0.3183\n",
      "116/224, train_loss: 0.1912, step time: 0.3135\n",
      "117/224, train_loss: 0.1573, step time: 0.3687\n",
      "118/224, train_loss: 0.1543, step time: 0.3156\n",
      "119/224, train_loss: 0.1356, step time: 0.3183\n",
      "120/224, train_loss: 0.1491, step time: 0.3153\n",
      "121/224, train_loss: 0.1012, step time: 0.3171\n",
      "122/224, train_loss: 0.1980, step time: 0.3855\n",
      "123/224, train_loss: 0.1317, step time: 0.3955\n",
      "124/224, train_loss: 0.1062, step time: 0.3183\n",
      "125/224, train_loss: 0.1209, step time: 0.3178\n",
      "126/224, train_loss: 0.1021, step time: 0.3149\n",
      "127/224, train_loss: 0.2504, step time: 0.3153\n",
      "128/224, train_loss: 0.1057, step time: 0.3137\n",
      "129/224, train_loss: 0.1716, step time: 0.4010\n",
      "130/224, train_loss: 0.0950, step time: 0.3161\n",
      "131/224, train_loss: 0.1361, step time: 0.4058\n",
      "132/224, train_loss: 0.1150, step time: 0.3659\n",
      "133/224, train_loss: 0.0728, step time: 0.3151\n",
      "134/224, train_loss: 0.1564, step time: 0.3147\n",
      "135/224, train_loss: 0.0779, step time: 0.3964\n",
      "136/224, train_loss: 0.1804, step time: 0.3777\n",
      "137/224, train_loss: 0.0772, step time: 0.3835\n",
      "138/224, train_loss: 0.1012, step time: 0.3177\n",
      "139/224, train_loss: 0.2530, step time: 0.4056\n",
      "140/224, train_loss: 0.1743, step time: 0.3171\n",
      "141/224, train_loss: 0.1315, step time: 0.3171\n",
      "142/224, train_loss: 0.1520, step time: 0.3147\n",
      "143/224, train_loss: 0.2410, step time: 0.4111\n",
      "144/224, train_loss: 0.1203, step time: 0.3177\n",
      "145/224, train_loss: 0.2328, step time: 0.3147\n",
      "146/224, train_loss: 0.1153, step time: 0.3624\n",
      "147/224, train_loss: 0.1607, step time: 0.3824\n",
      "148/224, train_loss: 0.2470, step time: 0.4053\n",
      "149/224, train_loss: 0.2122, step time: 0.3756\n",
      "150/224, train_loss: 0.2498, step time: 0.3831\n",
      "151/224, train_loss: 0.0652, step time: 0.3173\n",
      "152/224, train_loss: 0.1739, step time: 0.3764\n",
      "153/224, train_loss: 0.0912, step time: 0.3154\n",
      "154/224, train_loss: 0.1105, step time: 0.4049\n",
      "155/224, train_loss: 0.2459, step time: 0.3943\n",
      "156/224, train_loss: 0.2757, step time: 0.3173\n",
      "157/224, train_loss: 0.0897, step time: 0.3991\n",
      "158/224, train_loss: 0.0591, step time: 0.3853\n",
      "159/224, train_loss: 0.2145, step time: 0.3810\n",
      "160/224, train_loss: 0.4167, step time: 0.3684\n",
      "161/224, train_loss: 0.2098, step time: 0.4091\n",
      "162/224, train_loss: 0.2175, step time: 0.3156\n",
      "163/224, train_loss: 0.0999, step time: 0.3178\n",
      "164/224, train_loss: 0.2579, step time: 0.3743\n",
      "165/224, train_loss: 0.3478, step time: 0.3134\n",
      "166/224, train_loss: 0.1663, step time: 0.3184\n",
      "167/224, train_loss: 0.2356, step time: 0.3151\n",
      "168/224, train_loss: 0.3344, step time: 0.3171\n",
      "169/224, train_loss: 0.3770, step time: 0.3903\n",
      "170/224, train_loss: 0.2077, step time: 0.3156\n",
      "171/224, train_loss: 0.4124, step time: 0.4013\n",
      "172/224, train_loss: 0.1325, step time: 0.3181\n",
      "173/224, train_loss: 0.3701, step time: 0.4021\n",
      "174/224, train_loss: 0.1014, step time: 0.3127\n",
      "175/224, train_loss: 0.1479, step time: 0.3156\n",
      "176/224, train_loss: 0.0826, step time: 0.3915\n",
      "177/224, train_loss: 0.1696, step time: 0.4096\n",
      "178/224, train_loss: 0.0687, step time: 0.3177\n",
      "179/224, train_loss: 0.1318, step time: 0.4005\n",
      "180/224, train_loss: 0.1852, step time: 0.3806\n",
      "181/224, train_loss: 0.1174, step time: 0.3135\n",
      "182/224, train_loss: 0.1020, step time: 0.3148\n",
      "183/224, train_loss: 0.0964, step time: 0.4083\n",
      "184/224, train_loss: 0.2497, step time: 0.3679\n",
      "185/224, train_loss: 0.1602, step time: 0.3152\n",
      "186/224, train_loss: 0.3963, step time: 0.4015\n",
      "187/224, train_loss: 0.0525, step time: 0.3160\n",
      "188/224, train_loss: 0.1838, step time: 0.3136\n",
      "189/224, train_loss: 0.2869, step time: 0.3683\n",
      "190/224, train_loss: 0.0960, step time: 0.3160\n",
      "191/224, train_loss: 0.1567, step time: 0.3742\n",
      "192/224, train_loss: 0.1706, step time: 0.3182\n",
      "193/224, train_loss: 0.1114, step time: 0.3858\n",
      "194/224, train_loss: 0.2196, step time: 0.3136\n",
      "195/224, train_loss: 0.2668, step time: 0.3834\n",
      "196/224, train_loss: 0.3373, step time: 0.3824\n",
      "197/224, train_loss: 0.1617, step time: 0.3166\n",
      "198/224, train_loss: 0.0888, step time: 0.3136\n",
      "199/224, train_loss: 0.1272, step time: 0.3161\n",
      "200/224, train_loss: 0.1592, step time: 0.3142\n",
      "201/224, train_loss: 0.2738, step time: 0.3737\n",
      "202/224, train_loss: 0.1518, step time: 0.3158\n",
      "203/224, train_loss: 0.2548, step time: 0.4029\n",
      "204/224, train_loss: 0.1149, step time: 0.3156\n",
      "205/224, train_loss: 0.1831, step time: 0.3161\n",
      "206/224, train_loss: 0.3698, step time: 0.3162\n",
      "207/224, train_loss: 0.1449, step time: 0.3157\n",
      "208/224, train_loss: 0.3388, step time: 0.3179\n",
      "209/224, train_loss: 0.1061, step time: 0.3913\n",
      "210/224, train_loss: 0.0804, step time: 0.3153\n",
      "211/224, train_loss: 0.1571, step time: 0.3136\n",
      "212/224, train_loss: 0.2178, step time: 0.3858\n",
      "213/224, train_loss: 0.2174, step time: 0.3146\n",
      "214/224, train_loss: 0.0984, step time: 0.3161\n",
      "215/224, train_loss: 0.0832, step time: 0.3975\n",
      "216/224, train_loss: 0.0895, step time: 0.3135\n",
      "217/224, train_loss: 0.1128, step time: 0.3156\n",
      "218/224, train_loss: 0.2885, step time: 0.3160\n",
      "219/224, train_loss: 0.3064, step time: 0.3160\n",
      "220/224, train_loss: 0.3039, step time: 0.3160\n",
      "221/224, train_loss: 0.3834, step time: 0.3157\n",
      "222/224, train_loss: 0.2930, step time: 0.3952\n",
      "223/224, train_loss: 0.0714, step time: 0.3154\n",
      "224/224, train_loss: 0.1376, step time: 0.3130\n",
      "epoch 55 average loss: 0.1688\n",
      "current epoch: 55 current mean dice: 0.6964 class1: 0.9993 class2: 0.7454 class3: 0.3444\n",
      "best mean dice: 0.7136 at epoch: 53\n",
      "time consuming of epoch 55 is: 684.7011\n",
      "hello\n",
      "----------\n",
      "epoch 56/100\n",
      "1/224, train_loss: 0.0977, step time: 0.3139\n",
      "2/224, train_loss: 0.0870, step time: 0.3151\n",
      "3/224, train_loss: 0.1865, step time: 0.3748\n",
      "4/224, train_loss: 0.0619, step time: 0.4066\n",
      "5/224, train_loss: 0.1948, step time: 0.3728\n",
      "6/224, train_loss: 0.1485, step time: 0.3165\n",
      "7/224, train_loss: 0.1496, step time: 0.3144\n",
      "8/224, train_loss: 0.1681, step time: 0.3768\n",
      "9/224, train_loss: 0.0625, step time: 0.3157\n",
      "10/224, train_loss: 0.2161, step time: 0.3156\n",
      "11/224, train_loss: 0.0878, step time: 0.3175\n",
      "12/224, train_loss: 0.1022, step time: 0.4046\n",
      "13/224, train_loss: 0.2526, step time: 0.3161\n",
      "14/224, train_loss: 0.1196, step time: 0.3159\n",
      "15/224, train_loss: 0.1121, step time: 0.3182\n",
      "16/224, train_loss: 0.1938, step time: 0.3767\n",
      "17/224, train_loss: 0.2446, step time: 0.3801\n",
      "18/224, train_loss: 0.0518, step time: 0.3706\n",
      "19/224, train_loss: 0.0995, step time: 0.4072\n",
      "20/224, train_loss: 0.1806, step time: 0.3157\n",
      "21/224, train_loss: 0.2825, step time: 0.3962\n",
      "22/224, train_loss: 0.2667, step time: 0.4123\n",
      "23/224, train_loss: 0.0508, step time: 0.3164\n",
      "24/224, train_loss: 0.2516, step time: 0.3771\n",
      "25/224, train_loss: 0.0985, step time: 0.3129\n",
      "26/224, train_loss: 0.1047, step time: 0.3179\n",
      "27/224, train_loss: 0.0973, step time: 0.3163\n",
      "28/224, train_loss: 0.1184, step time: 0.3161\n",
      "29/224, train_loss: 0.1491, step time: 0.3721\n",
      "30/224, train_loss: 0.1304, step time: 0.3925\n",
      "31/224, train_loss: 0.1202, step time: 0.3769\n",
      "32/224, train_loss: 0.2011, step time: 0.3157\n",
      "33/224, train_loss: 0.1942, step time: 0.3162\n",
      "34/224, train_loss: 0.1399, step time: 0.3820\n",
      "35/224, train_loss: 0.1265, step time: 0.3176\n",
      "36/224, train_loss: 0.1540, step time: 0.3157\n",
      "37/224, train_loss: 0.3578, step time: 0.3706\n",
      "38/224, train_loss: 0.1089, step time: 0.4036\n",
      "39/224, train_loss: 0.0877, step time: 0.4051\n",
      "40/224, train_loss: 0.2481, step time: 0.3993\n",
      "41/224, train_loss: 0.3818, step time: 0.4094\n",
      "42/224, train_loss: 0.1278, step time: 0.3177\n",
      "43/224, train_loss: 0.1183, step time: 0.3184\n",
      "44/224, train_loss: 0.2001, step time: 0.4022\n",
      "45/224, train_loss: 0.3528, step time: 0.3133\n",
      "46/224, train_loss: 0.1722, step time: 0.3151\n",
      "47/224, train_loss: 0.0993, step time: 0.3140\n",
      "48/224, train_loss: 0.3255, step time: 0.3659\n",
      "49/224, train_loss: 0.0773, step time: 0.3147\n",
      "50/224, train_loss: 0.0948, step time: 0.3747\n",
      "51/224, train_loss: 0.0666, step time: 0.3882\n",
      "52/224, train_loss: 0.2522, step time: 0.3686\n",
      "53/224, train_loss: 0.0821, step time: 0.3129\n",
      "54/224, train_loss: 0.1955, step time: 0.3151\n",
      "55/224, train_loss: 0.3430, step time: 0.3936\n",
      "56/224, train_loss: 0.2833, step time: 0.3692\n",
      "57/224, train_loss: 0.1340, step time: 0.3180\n",
      "58/224, train_loss: 0.2795, step time: 0.3149\n",
      "59/224, train_loss: 0.2133, step time: 0.3936\n",
      "60/224, train_loss: 0.1257, step time: 0.3122\n",
      "61/224, train_loss: 0.0981, step time: 0.3163\n",
      "62/224, train_loss: 0.1141, step time: 0.4058\n",
      "63/224, train_loss: 0.0759, step time: 0.3152\n",
      "64/224, train_loss: 0.1446, step time: 0.3125\n",
      "65/224, train_loss: 0.1479, step time: 0.3151\n",
      "66/224, train_loss: 0.1532, step time: 0.3157\n",
      "67/224, train_loss: 0.0723, step time: 0.3154\n",
      "68/224, train_loss: 0.1029, step time: 0.3169\n",
      "69/224, train_loss: 0.0715, step time: 0.3144\n",
      "70/224, train_loss: 0.1068, step time: 0.3944\n",
      "71/224, train_loss: 0.0978, step time: 0.3145\n",
      "72/224, train_loss: 0.0740, step time: 0.3153\n",
      "73/224, train_loss: 0.0930, step time: 0.3160\n",
      "74/224, train_loss: 0.3675, step time: 0.3903\n",
      "75/224, train_loss: 0.0906, step time: 0.3664\n",
      "76/224, train_loss: 0.1033, step time: 0.3131\n",
      "77/224, train_loss: 0.1780, step time: 0.3746\n",
      "78/224, train_loss: 0.0652, step time: 0.3178\n",
      "79/224, train_loss: 0.0973, step time: 0.3991\n",
      "80/224, train_loss: 0.0801, step time: 0.3174\n",
      "81/224, train_loss: 0.1000, step time: 0.3152\n",
      "82/224, train_loss: 0.0954, step time: 0.4024\n",
      "83/224, train_loss: 0.1382, step time: 0.3146\n",
      "84/224, train_loss: 0.1248, step time: 0.3918\n",
      "85/224, train_loss: 0.1072, step time: 0.3179\n",
      "86/224, train_loss: 0.2799, step time: 0.3949\n",
      "87/224, train_loss: 0.0943, step time: 0.3159\n",
      "88/224, train_loss: 0.1346, step time: 0.3141\n",
      "89/224, train_loss: 0.2136, step time: 0.3150\n",
      "90/224, train_loss: 0.0493, step time: 0.3136\n",
      "91/224, train_loss: 0.0974, step time: 0.3866\n",
      "92/224, train_loss: 0.2095, step time: 0.3156\n",
      "93/224, train_loss: 0.3412, step time: 0.3751\n",
      "94/224, train_loss: 0.1043, step time: 0.3148\n",
      "95/224, train_loss: 0.3077, step time: 0.3964\n",
      "96/224, train_loss: 0.2498, step time: 0.3145\n",
      "97/224, train_loss: 0.0852, step time: 0.3122\n",
      "98/224, train_loss: 0.0768, step time: 0.3168\n",
      "99/224, train_loss: 0.0736, step time: 0.3149\n",
      "100/224, train_loss: 0.1996, step time: 0.3843\n",
      "101/224, train_loss: 0.1199, step time: 0.3147\n",
      "102/224, train_loss: 0.1756, step time: 0.3726\n",
      "103/224, train_loss: 0.2017, step time: 0.3959\n",
      "104/224, train_loss: 0.2762, step time: 0.3771\n",
      "105/224, train_loss: 0.2192, step time: 0.3157\n",
      "106/224, train_loss: 0.1936, step time: 0.3898\n",
      "107/224, train_loss: 0.0529, step time: 0.3147\n",
      "108/224, train_loss: 0.2371, step time: 0.3144\n",
      "109/224, train_loss: 0.1511, step time: 0.3121\n",
      "110/224, train_loss: 0.0870, step time: 0.4002\n",
      "111/224, train_loss: 0.2197, step time: 0.3951\n",
      "112/224, train_loss: 0.1801, step time: 0.3161\n",
      "113/224, train_loss: 0.1294, step time: 0.3164\n",
      "114/224, train_loss: 0.3880, step time: 0.3676\n",
      "115/224, train_loss: 0.3819, step time: 0.3148\n",
      "116/224, train_loss: 0.1011, step time: 0.3150\n",
      "117/224, train_loss: 0.1712, step time: 0.4008\n",
      "118/224, train_loss: 0.2322, step time: 0.3151\n",
      "119/224, train_loss: 0.1910, step time: 0.3695\n",
      "120/224, train_loss: 0.3774, step time: 0.4048\n",
      "121/224, train_loss: 0.2300, step time: 0.3854\n",
      "122/224, train_loss: 0.0842, step time: 0.3152\n",
      "123/224, train_loss: 0.1105, step time: 0.3757\n",
      "124/224, train_loss: 0.1866, step time: 0.3685\n",
      "125/224, train_loss: 0.1665, step time: 0.3175\n",
      "126/224, train_loss: 0.2374, step time: 0.3755\n",
      "127/224, train_loss: 0.1284, step time: 0.3151\n",
      "128/224, train_loss: 0.1547, step time: 0.3166\n",
      "129/224, train_loss: 0.1630, step time: 0.3830\n",
      "130/224, train_loss: 0.0646, step time: 0.3803\n",
      "131/224, train_loss: 0.1796, step time: 0.3154\n",
      "132/224, train_loss: 0.1112, step time: 0.3997\n",
      "133/224, train_loss: 0.1092, step time: 0.3175\n",
      "134/224, train_loss: 0.1283, step time: 0.3148\n",
      "135/224, train_loss: 0.1516, step time: 0.3895\n",
      "136/224, train_loss: 0.1101, step time: 0.3151\n",
      "137/224, train_loss: 0.2292, step time: 0.3793\n",
      "138/224, train_loss: 0.0669, step time: 0.3950\n",
      "139/224, train_loss: 0.1473, step time: 0.3133\n",
      "140/224, train_loss: 0.0916, step time: 0.3176\n",
      "141/224, train_loss: 0.1117, step time: 0.3161\n",
      "142/224, train_loss: 0.1241, step time: 0.3946\n",
      "143/224, train_loss: 0.3562, step time: 0.3950\n",
      "144/224, train_loss: 0.1188, step time: 0.3152\n",
      "145/224, train_loss: 0.3110, step time: 0.3697\n",
      "146/224, train_loss: 0.0974, step time: 0.3151\n",
      "147/224, train_loss: 0.1041, step time: 0.3179\n",
      "148/224, train_loss: 0.0940, step time: 0.3156\n",
      "149/224, train_loss: 0.1555, step time: 0.3751\n",
      "150/224, train_loss: 0.1144, step time: 0.3152\n",
      "151/224, train_loss: 0.1074, step time: 0.4013\n",
      "152/224, train_loss: 0.0737, step time: 0.3149\n",
      "153/224, train_loss: 0.1386, step time: 0.3859\n",
      "154/224, train_loss: 0.1475, step time: 0.3825\n",
      "155/224, train_loss: 0.1880, step time: 0.4103\n",
      "156/224, train_loss: 0.1370, step time: 0.3136\n",
      "157/224, train_loss: 0.1490, step time: 0.3866\n",
      "158/224, train_loss: 0.0887, step time: 0.3932\n",
      "159/224, train_loss: 0.1306, step time: 0.3153\n",
      "160/224, train_loss: 0.2872, step time: 0.3948\n",
      "161/224, train_loss: 0.2336, step time: 0.3914\n",
      "162/224, train_loss: 0.2437, step time: 0.4167\n",
      "163/224, train_loss: 0.0659, step time: 0.3759\n",
      "164/224, train_loss: 0.2868, step time: 0.3162\n",
      "165/224, train_loss: 0.0671, step time: 0.3156\n",
      "166/224, train_loss: 0.0994, step time: 0.3902\n",
      "167/224, train_loss: 0.1371, step time: 0.3916\n",
      "168/224, train_loss: 0.1938, step time: 0.3160\n",
      "169/224, train_loss: 0.1197, step time: 0.3887\n",
      "170/224, train_loss: 0.1139, step time: 0.4116\n",
      "171/224, train_loss: 0.0732, step time: 0.3154\n",
      "172/224, train_loss: 0.0772, step time: 0.3814\n",
      "173/224, train_loss: 0.3046, step time: 0.3175\n",
      "174/224, train_loss: 0.1054, step time: 0.3153\n",
      "175/224, train_loss: 0.0637, step time: 0.4115\n",
      "176/224, train_loss: 0.0812, step time: 0.3993\n",
      "177/224, train_loss: 0.0879, step time: 0.3155\n",
      "178/224, train_loss: 0.2940, step time: 0.3160\n",
      "179/224, train_loss: 0.1032, step time: 0.3159\n",
      "180/224, train_loss: 0.1810, step time: 0.3177\n",
      "181/224, train_loss: 0.3060, step time: 0.4013\n",
      "182/224, train_loss: 0.1054, step time: 0.3152\n",
      "183/224, train_loss: 0.0728, step time: 0.3151\n",
      "184/224, train_loss: 0.0850, step time: 0.3156\n",
      "185/224, train_loss: 0.0794, step time: 0.3177\n",
      "186/224, train_loss: 0.2463, step time: 0.3716\n",
      "187/224, train_loss: 0.1437, step time: 0.3154\n",
      "188/224, train_loss: 0.0530, step time: 0.3735\n",
      "189/224, train_loss: 0.2454, step time: 0.3180\n",
      "190/224, train_loss: 0.0891, step time: 0.3183\n",
      "191/224, train_loss: 0.1450, step time: 0.3140\n",
      "192/224, train_loss: 0.0889, step time: 0.3187\n",
      "193/224, train_loss: 0.1127, step time: 0.3150\n",
      "194/224, train_loss: 0.1465, step time: 0.3135\n",
      "195/224, train_loss: 0.1330, step time: 0.3840\n",
      "196/224, train_loss: 0.1258, step time: 0.3134\n",
      "197/224, train_loss: 0.1059, step time: 0.4012\n",
      "198/224, train_loss: 0.1337, step time: 0.3992\n",
      "199/224, train_loss: 0.1341, step time: 0.3172\n",
      "200/224, train_loss: 0.1605, step time: 0.3153\n",
      "201/224, train_loss: 0.3798, step time: 0.4092\n",
      "202/224, train_loss: 0.1406, step time: 0.3829\n",
      "203/224, train_loss: 0.2034, step time: 0.3139\n",
      "204/224, train_loss: 0.0814, step time: 0.3165\n",
      "205/224, train_loss: 0.1280, step time: 0.3160\n",
      "206/224, train_loss: 0.3133, step time: 0.3176\n",
      "207/224, train_loss: 0.3543, step time: 0.3154\n",
      "208/224, train_loss: 0.0730, step time: 0.3131\n",
      "209/224, train_loss: 0.2197, step time: 0.3955\n",
      "210/224, train_loss: 0.3748, step time: 0.4047\n",
      "211/224, train_loss: 0.1479, step time: 0.3150\n",
      "212/224, train_loss: 0.1611, step time: 0.3853\n",
      "213/224, train_loss: 0.0974, step time: 0.3723\n",
      "214/224, train_loss: 0.1060, step time: 0.3180\n",
      "215/224, train_loss: 0.1113, step time: 0.3152\n",
      "216/224, train_loss: 0.1832, step time: 0.3866\n",
      "217/224, train_loss: 0.3783, step time: 0.3920\n",
      "218/224, train_loss: 0.1324, step time: 0.3879\n",
      "219/224, train_loss: 0.1519, step time: 0.4047\n",
      "220/224, train_loss: 0.1213, step time: 0.3973\n",
      "221/224, train_loss: 0.3938, step time: 0.3831\n",
      "222/224, train_loss: 0.0684, step time: 0.4020\n",
      "223/224, train_loss: 0.1446, step time: 0.3164\n",
      "224/224, train_loss: 0.2117, step time: 0.3926\n",
      "epoch 56 average loss: 0.1596\n",
      "current epoch: 56 current mean dice: 0.7052 class1: 0.9993 class2: 0.7341 class3: 0.3822\n",
      "best mean dice: 0.7136 at epoch: 53\n",
      "time consuming of epoch 56 is: 691.5205\n",
      "hello\n",
      "----------\n",
      "epoch 57/100\n",
      "1/224, train_loss: 0.0599, step time: 0.3163\n",
      "2/224, train_loss: 0.1214, step time: 0.3190\n",
      "3/224, train_loss: 0.0839, step time: 0.3891\n",
      "4/224, train_loss: 0.1072, step time: 0.3173\n",
      "5/224, train_loss: 0.1313, step time: 0.3147\n",
      "6/224, train_loss: 0.1516, step time: 0.3852\n",
      "7/224, train_loss: 0.1461, step time: 0.3178\n",
      "8/224, train_loss: 0.0953, step time: 0.3174\n",
      "9/224, train_loss: 0.1384, step time: 0.3173\n",
      "10/224, train_loss: 0.1597, step time: 0.3146\n",
      "11/224, train_loss: 0.0643, step time: 0.3147\n",
      "12/224, train_loss: 0.1652, step time: 0.3987\n",
      "13/224, train_loss: 0.0966, step time: 0.4122\n",
      "14/224, train_loss: 0.1245, step time: 0.3133\n",
      "15/224, train_loss: 0.4290, step time: 0.3920\n",
      "16/224, train_loss: 0.2581, step time: 0.3856\n",
      "17/224, train_loss: 0.1568, step time: 0.3150\n",
      "18/224, train_loss: 0.1454, step time: 0.3757\n",
      "19/224, train_loss: 0.0742, step time: 0.3166\n",
      "20/224, train_loss: 0.1030, step time: 0.3956\n",
      "21/224, train_loss: 0.0779, step time: 0.3151\n",
      "22/224, train_loss: 0.1279, step time: 0.3160\n",
      "23/224, train_loss: 0.0971, step time: 0.3156\n",
      "24/224, train_loss: 0.0801, step time: 0.4026\n",
      "25/224, train_loss: 0.1133, step time: 0.3149\n",
      "26/224, train_loss: 0.0768, step time: 0.3129\n",
      "27/224, train_loss: 0.0752, step time: 0.3130\n",
      "28/224, train_loss: 0.0901, step time: 0.3129\n",
      "29/224, train_loss: 0.0887, step time: 0.3130\n",
      "30/224, train_loss: 0.1339, step time: 0.4017\n",
      "31/224, train_loss: 0.1417, step time: 0.3819\n",
      "32/224, train_loss: 0.0833, step time: 0.4020\n",
      "33/224, train_loss: 0.2413, step time: 0.3727\n",
      "34/224, train_loss: 0.3553, step time: 0.4001\n",
      "35/224, train_loss: 0.2329, step time: 0.3178\n",
      "36/224, train_loss: 0.1121, step time: 0.4068\n",
      "37/224, train_loss: 0.2203, step time: 0.3938\n",
      "38/224, train_loss: 0.0939, step time: 0.3168\n",
      "39/224, train_loss: 0.0829, step time: 0.3840\n",
      "40/224, train_loss: 0.0908, step time: 0.3146\n",
      "41/224, train_loss: 0.1740, step time: 0.3752\n",
      "42/224, train_loss: 0.0782, step time: 0.3148\n",
      "43/224, train_loss: 0.1022, step time: 0.3126\n",
      "44/224, train_loss: 0.1456, step time: 0.4087\n",
      "45/224, train_loss: 0.0607, step time: 0.3149\n",
      "46/224, train_loss: 0.1081, step time: 0.3167\n",
      "47/224, train_loss: 0.1134, step time: 0.3125\n",
      "48/224, train_loss: 0.1778, step time: 0.3124\n",
      "49/224, train_loss: 0.1930, step time: 0.3151\n",
      "50/224, train_loss: 0.1633, step time: 0.3737\n",
      "51/224, train_loss: 0.1424, step time: 0.3787\n",
      "52/224, train_loss: 0.0834, step time: 0.3748\n",
      "53/224, train_loss: 0.0759, step time: 0.3155\n",
      "54/224, train_loss: 0.1121, step time: 0.3146\n",
      "55/224, train_loss: 0.1027, step time: 0.3125\n",
      "56/224, train_loss: 0.1422, step time: 0.3782\n",
      "57/224, train_loss: 0.0533, step time: 0.4059\n",
      "58/224, train_loss: 0.0769, step time: 0.3147\n",
      "59/224, train_loss: 0.0966, step time: 0.3152\n",
      "60/224, train_loss: 0.1211, step time: 0.3993\n",
      "61/224, train_loss: 0.0791, step time: 0.3892\n",
      "62/224, train_loss: 0.0988, step time: 0.3152\n",
      "63/224, train_loss: 0.1180, step time: 0.3148\n",
      "64/224, train_loss: 0.0936, step time: 0.3166\n",
      "65/224, train_loss: 0.0708, step time: 0.3153\n",
      "66/224, train_loss: 0.0721, step time: 0.3155\n",
      "67/224, train_loss: 0.1197, step time: 0.3883\n",
      "68/224, train_loss: 0.2969, step time: 0.3174\n",
      "69/224, train_loss: 0.1495, step time: 0.3726\n",
      "70/224, train_loss: 0.0907, step time: 0.4074\n",
      "71/224, train_loss: 0.2145, step time: 0.3128\n",
      "72/224, train_loss: 0.0792, step time: 0.3909\n",
      "73/224, train_loss: 0.0632, step time: 0.3148\n",
      "74/224, train_loss: 0.0832, step time: 0.3175\n",
      "75/224, train_loss: 0.2959, step time: 0.3832\n",
      "76/224, train_loss: 0.1421, step time: 0.4084\n",
      "77/224, train_loss: 0.1274, step time: 0.3803\n",
      "78/224, train_loss: 0.1444, step time: 0.3760\n",
      "79/224, train_loss: 0.0799, step time: 0.3775\n",
      "80/224, train_loss: 0.1064, step time: 0.3152\n",
      "81/224, train_loss: 0.1335, step time: 0.3169\n",
      "82/224, train_loss: 0.4055, step time: 0.3726\n",
      "83/224, train_loss: 0.3583, step time: 0.3883\n",
      "84/224, train_loss: 0.0830, step time: 0.3146\n",
      "85/224, train_loss: 0.2561, step time: 0.4039\n",
      "86/224, train_loss: 0.1282, step time: 0.3922\n",
      "87/224, train_loss: 0.1587, step time: 0.3967\n",
      "88/224, train_loss: 0.1420, step time: 0.4002\n",
      "89/224, train_loss: 0.0732, step time: 0.3171\n",
      "90/224, train_loss: 0.0686, step time: 0.3145\n",
      "91/224, train_loss: 0.2186, step time: 0.3145\n",
      "92/224, train_loss: 0.1132, step time: 0.3123\n",
      "93/224, train_loss: 0.1082, step time: 0.3883\n",
      "94/224, train_loss: 0.2023, step time: 0.3656\n",
      "95/224, train_loss: 0.1058, step time: 0.3152\n",
      "96/224, train_loss: 0.1428, step time: 0.3152\n",
      "97/224, train_loss: 0.2827, step time: 0.3658\n",
      "98/224, train_loss: 0.4029, step time: 0.3878\n",
      "99/224, train_loss: 0.1072, step time: 0.3150\n",
      "100/224, train_loss: 0.0806, step time: 0.3162\n",
      "101/224, train_loss: 0.0663, step time: 0.3150\n",
      "102/224, train_loss: 0.3028, step time: 0.3134\n",
      "103/224, train_loss: 0.3789, step time: 0.3760\n",
      "104/224, train_loss: 0.1445, step time: 0.3155\n",
      "105/224, train_loss: 0.2261, step time: 0.3835\n",
      "106/224, train_loss: 0.1556, step time: 0.3153\n",
      "107/224, train_loss: 0.1498, step time: 0.3172\n",
      "108/224, train_loss: 0.1132, step time: 0.3153\n",
      "109/224, train_loss: 0.2007, step time: 0.3975\n",
      "110/224, train_loss: 0.1236, step time: 0.3152\n",
      "111/224, train_loss: 0.0857, step time: 0.3146\n",
      "112/224, train_loss: 0.1435, step time: 0.3717\n",
      "113/224, train_loss: 0.1251, step time: 0.3958\n",
      "114/224, train_loss: 0.1380, step time: 0.3144\n",
      "115/224, train_loss: 0.1670, step time: 0.3748\n",
      "116/224, train_loss: 0.0616, step time: 0.3144\n",
      "117/224, train_loss: 0.0829, step time: 0.3125\n",
      "118/224, train_loss: 0.3025, step time: 0.3883\n",
      "119/224, train_loss: 0.4076, step time: 0.3811\n",
      "120/224, train_loss: 0.0980, step time: 0.3177\n",
      "121/224, train_loss: 0.1997, step time: 0.3738\n",
      "122/224, train_loss: 0.1065, step time: 0.3696\n",
      "123/224, train_loss: 0.3202, step time: 0.3865\n",
      "124/224, train_loss: 0.3599, step time: 0.3707\n",
      "125/224, train_loss: 0.0787, step time: 0.3173\n",
      "126/224, train_loss: 0.1096, step time: 0.3991\n",
      "127/224, train_loss: 0.1340, step time: 0.3178\n",
      "128/224, train_loss: 0.3663, step time: 0.3727\n",
      "129/224, train_loss: 0.1204, step time: 0.3154\n",
      "130/224, train_loss: 0.1573, step time: 0.3804\n",
      "131/224, train_loss: 0.0858, step time: 0.3146\n",
      "132/224, train_loss: 0.1902, step time: 0.3168\n",
      "133/224, train_loss: 0.1801, step time: 0.3775\n",
      "134/224, train_loss: 0.3566, step time: 0.3798\n",
      "135/224, train_loss: 0.1424, step time: 0.3146\n",
      "136/224, train_loss: 0.1151, step time: 0.3146\n",
      "137/224, train_loss: 0.0847, step time: 0.3147\n",
      "138/224, train_loss: 0.2800, step time: 0.4099\n",
      "139/224, train_loss: 0.0831, step time: 0.3171\n",
      "140/224, train_loss: 0.0667, step time: 0.3165\n",
      "141/224, train_loss: 0.1961, step time: 0.3985\n",
      "142/224, train_loss: 0.2543, step time: 0.3156\n",
      "143/224, train_loss: 0.2791, step time: 0.3136\n",
      "144/224, train_loss: 0.3149, step time: 0.3897\n",
      "145/224, train_loss: 0.3150, step time: 0.3888\n",
      "146/224, train_loss: 0.2415, step time: 0.3803\n",
      "147/224, train_loss: 0.2066, step time: 0.3147\n",
      "148/224, train_loss: 0.1325, step time: 0.3146\n",
      "149/224, train_loss: 0.0984, step time: 0.3788\n",
      "150/224, train_loss: 0.0573, step time: 0.3902\n",
      "151/224, train_loss: 0.0575, step time: 0.3168\n",
      "152/224, train_loss: 0.1407, step time: 0.3155\n",
      "153/224, train_loss: 0.1066, step time: 0.3154\n",
      "154/224, train_loss: 0.2885, step time: 0.3898\n",
      "155/224, train_loss: 0.1520, step time: 0.4123\n",
      "156/224, train_loss: 0.1505, step time: 0.3167\n",
      "157/224, train_loss: 0.0971, step time: 0.3842\n",
      "158/224, train_loss: 0.0960, step time: 0.3715\n",
      "159/224, train_loss: 0.1371, step time: 0.3178\n",
      "160/224, train_loss: 0.2006, step time: 0.3135\n",
      "161/224, train_loss: 0.1331, step time: 0.3154\n",
      "162/224, train_loss: 0.0508, step time: 0.3166\n",
      "163/224, train_loss: 0.3743, step time: 0.3884\n",
      "164/224, train_loss: 0.0651, step time: 0.3126\n",
      "165/224, train_loss: 0.1587, step time: 0.3170\n",
      "166/224, train_loss: 0.1746, step time: 0.3855\n",
      "167/224, train_loss: 0.3021, step time: 0.3779\n",
      "168/224, train_loss: 0.1153, step time: 0.3842\n",
      "169/224, train_loss: 0.0926, step time: 0.3184\n",
      "170/224, train_loss: 0.0876, step time: 0.3168\n",
      "171/224, train_loss: 0.1449, step time: 0.3681\n",
      "172/224, train_loss: 0.1219, step time: 0.4077\n",
      "173/224, train_loss: 0.1644, step time: 0.3160\n",
      "174/224, train_loss: 0.1584, step time: 0.4095\n",
      "175/224, train_loss: 0.1720, step time: 0.3920\n",
      "176/224, train_loss: 0.0944, step time: 0.3898\n",
      "177/224, train_loss: 0.0815, step time: 0.3146\n",
      "178/224, train_loss: 0.0741, step time: 0.3144\n",
      "179/224, train_loss: 0.1180, step time: 0.3124\n",
      "180/224, train_loss: 0.1547, step time: 0.3148\n",
      "181/224, train_loss: 0.1066, step time: 0.3745\n",
      "182/224, train_loss: 0.1261, step time: 0.3832\n",
      "183/224, train_loss: 0.1086, step time: 0.3775\n",
      "184/224, train_loss: 0.1063, step time: 0.4000\n",
      "185/224, train_loss: 0.2487, step time: 0.3703\n",
      "186/224, train_loss: 0.0888, step time: 0.3148\n",
      "187/224, train_loss: 0.2433, step time: 0.3746\n",
      "188/224, train_loss: 0.3537, step time: 0.3165\n",
      "189/224, train_loss: 0.3743, step time: 0.3704\n",
      "190/224, train_loss: 0.2563, step time: 0.3182\n",
      "191/224, train_loss: 0.0849, step time: 0.3144\n",
      "192/224, train_loss: 0.3081, step time: 0.3148\n",
      "193/224, train_loss: 0.1505, step time: 0.3697\n",
      "194/224, train_loss: 0.2279, step time: 0.3159\n",
      "195/224, train_loss: 0.1964, step time: 0.3970\n",
      "196/224, train_loss: 0.1302, step time: 0.3146\n",
      "197/224, train_loss: 0.0678, step time: 0.3146\n",
      "198/224, train_loss: 0.0848, step time: 0.3910\n",
      "199/224, train_loss: 0.1454, step time: 0.3152\n",
      "200/224, train_loss: 0.1298, step time: 0.3793\n",
      "201/224, train_loss: 0.1545, step time: 0.3818\n",
      "202/224, train_loss: 0.1510, step time: 0.3988\n",
      "203/224, train_loss: 0.3042, step time: 0.3716\n",
      "204/224, train_loss: 0.1800, step time: 0.3141\n",
      "205/224, train_loss: 0.0902, step time: 0.3140\n",
      "206/224, train_loss: 0.1280, step time: 0.3964\n",
      "207/224, train_loss: 0.3139, step time: 0.4028\n",
      "208/224, train_loss: 0.2015, step time: 0.3779\n",
      "209/224, train_loss: 0.2672, step time: 0.3147\n",
      "210/224, train_loss: 0.4302, step time: 0.3904\n",
      "211/224, train_loss: 0.1626, step time: 0.3147\n",
      "212/224, train_loss: 0.2514, step time: 0.3671\n",
      "213/224, train_loss: 0.0770, step time: 0.3142\n",
      "214/224, train_loss: 0.1988, step time: 0.3144\n",
      "215/224, train_loss: 0.0864, step time: 0.3717\n",
      "216/224, train_loss: 0.4444, step time: 0.4041\n",
      "217/224, train_loss: 0.3588, step time: 0.3145\n",
      "218/224, train_loss: 0.1305, step time: 0.3164\n",
      "219/224, train_loss: 0.0628, step time: 0.3726\n",
      "220/224, train_loss: 0.2336, step time: 0.3171\n",
      "221/224, train_loss: 0.1114, step time: 0.3874\n",
      "222/224, train_loss: 0.3436, step time: 0.3153\n",
      "223/224, train_loss: 0.1519, step time: 0.4022\n",
      "224/224, train_loss: 0.1275, step time: 0.3124\n",
      "epoch 57 average loss: 0.1595\n",
      "current epoch: 57 current mean dice: 0.6884 class1: 0.9993 class2: 0.7148 class3: 0.3511\n",
      "best mean dice: 0.7136 at epoch: 53\n",
      "time consuming of epoch 57 is: 677.7567\n",
      "hello\n",
      "----------\n",
      "epoch 58/100\n",
      "1/224, train_loss: 0.1527, step time: 0.3864\n",
      "2/224, train_loss: 0.2184, step time: 0.3949\n",
      "3/224, train_loss: 0.3383, step time: 0.3146\n",
      "4/224, train_loss: 0.0896, step time: 0.4051\n",
      "5/224, train_loss: 0.1202, step time: 0.3148\n",
      "6/224, train_loss: 0.1880, step time: 0.3645\n",
      "7/224, train_loss: 0.1245, step time: 0.3733\n",
      "8/224, train_loss: 0.0886, step time: 0.3129\n",
      "9/224, train_loss: 0.1330, step time: 0.3999\n",
      "10/224, train_loss: 0.1625, step time: 0.3120\n",
      "11/224, train_loss: 0.2649, step time: 0.3645\n",
      "12/224, train_loss: 0.0647, step time: 0.3171\n",
      "13/224, train_loss: 0.1904, step time: 0.4009\n",
      "14/224, train_loss: 0.3682, step time: 0.3143\n",
      "15/224, train_loss: 0.1098, step time: 0.3142\n",
      "16/224, train_loss: 0.2655, step time: 0.3686\n",
      "17/224, train_loss: 0.1119, step time: 0.3163\n",
      "18/224, train_loss: 0.1540, step time: 0.4044\n",
      "19/224, train_loss: 0.1429, step time: 0.4037\n",
      "20/224, train_loss: 0.1008, step time: 0.3151\n",
      "21/224, train_loss: 0.1039, step time: 0.3167\n",
      "22/224, train_loss: 0.4336, step time: 0.4022\n",
      "23/224, train_loss: 0.1634, step time: 0.3141\n",
      "24/224, train_loss: 0.1345, step time: 0.3169\n",
      "25/224, train_loss: 0.0966, step time: 0.3141\n",
      "26/224, train_loss: 0.0751, step time: 0.3858\n",
      "27/224, train_loss: 0.0921, step time: 0.4005\n",
      "28/224, train_loss: 0.2129, step time: 0.3874\n",
      "29/224, train_loss: 0.0830, step time: 0.3116\n",
      "30/224, train_loss: 0.1338, step time: 0.3162\n",
      "31/224, train_loss: 0.1717, step time: 0.4085\n",
      "32/224, train_loss: 0.1060, step time: 0.3144\n",
      "33/224, train_loss: 0.0871, step time: 0.3148\n",
      "34/224, train_loss: 0.1239, step time: 0.3149\n",
      "35/224, train_loss: 0.2748, step time: 0.4005\n",
      "36/224, train_loss: 0.0845, step time: 0.3966\n",
      "37/224, train_loss: 0.0845, step time: 0.3139\n",
      "38/224, train_loss: 0.1034, step time: 0.3160\n",
      "39/224, train_loss: 0.3600, step time: 0.3951\n",
      "40/224, train_loss: 0.2618, step time: 0.4049\n",
      "41/224, train_loss: 0.1699, step time: 0.3138\n",
      "42/224, train_loss: 0.0991, step time: 0.3837\n",
      "43/224, train_loss: 0.1448, step time: 0.3890\n",
      "44/224, train_loss: 0.1282, step time: 0.3148\n",
      "45/224, train_loss: 0.1657, step time: 0.3141\n",
      "46/224, train_loss: 0.2193, step time: 0.3737\n",
      "47/224, train_loss: 0.2647, step time: 0.3144\n",
      "48/224, train_loss: 0.3888, step time: 0.3770\n",
      "49/224, train_loss: 0.1987, step time: 0.3150\n",
      "50/224, train_loss: 0.1243, step time: 0.3734\n",
      "51/224, train_loss: 0.1246, step time: 0.3825\n",
      "52/224, train_loss: 0.3573, step time: 0.3939\n",
      "53/224, train_loss: 0.1596, step time: 0.3906\n",
      "54/224, train_loss: 0.2036, step time: 0.3801\n",
      "55/224, train_loss: 0.0753, step time: 0.3145\n",
      "56/224, train_loss: 0.0820, step time: 0.3138\n",
      "57/224, train_loss: 0.1631, step time: 0.4123\n",
      "58/224, train_loss: 0.3423, step time: 0.3136\n",
      "59/224, train_loss: 0.1261, step time: 0.3139\n",
      "60/224, train_loss: 0.2027, step time: 0.3670\n",
      "61/224, train_loss: 0.2220, step time: 0.3848\n",
      "62/224, train_loss: 0.1507, step time: 0.3149\n",
      "63/224, train_loss: 0.1321, step time: 0.3169\n",
      "64/224, train_loss: 0.3025, step time: 0.3143\n",
      "65/224, train_loss: 0.3117, step time: 0.3166\n",
      "66/224, train_loss: 0.0581, step time: 0.3162\n",
      "67/224, train_loss: 0.1772, step time: 0.3160\n",
      "68/224, train_loss: 0.1790, step time: 0.3137\n",
      "69/224, train_loss: 0.1198, step time: 0.3144\n",
      "70/224, train_loss: 0.1371, step time: 0.3144\n",
      "71/224, train_loss: 0.3202, step time: 0.4103\n",
      "72/224, train_loss: 0.1259, step time: 0.3142\n",
      "73/224, train_loss: 0.2486, step time: 0.3732\n",
      "74/224, train_loss: 0.2450, step time: 0.3877\n",
      "75/224, train_loss: 0.1214, step time: 0.3121\n",
      "76/224, train_loss: 0.2384, step time: 0.3142\n",
      "77/224, train_loss: 0.1291, step time: 0.3155\n",
      "78/224, train_loss: 0.0851, step time: 0.3895\n",
      "79/224, train_loss: 0.1038, step time: 0.3153\n",
      "80/224, train_loss: 0.1372, step time: 0.3144\n",
      "81/224, train_loss: 0.0892, step time: 0.3120\n",
      "82/224, train_loss: 0.0870, step time: 0.3149\n",
      "83/224, train_loss: 0.2928, step time: 0.4101\n",
      "84/224, train_loss: 0.0729, step time: 0.3969\n",
      "85/224, train_loss: 0.0988, step time: 0.3167\n",
      "86/224, train_loss: 0.1482, step time: 0.3152\n",
      "87/224, train_loss: 0.0793, step time: 0.4014\n",
      "88/224, train_loss: 0.1262, step time: 0.4004\n",
      "89/224, train_loss: 0.1480, step time: 0.3989\n",
      "90/224, train_loss: 0.1425, step time: 0.4036\n",
      "91/224, train_loss: 0.0883, step time: 0.3173\n",
      "92/224, train_loss: 0.2205, step time: 0.3175\n",
      "93/224, train_loss: 0.1402, step time: 0.3899\n",
      "94/224, train_loss: 0.1755, step time: 0.3716\n",
      "95/224, train_loss: 0.1491, step time: 0.3915\n",
      "96/224, train_loss: 0.1707, step time: 0.3845\n",
      "97/224, train_loss: 0.1032, step time: 0.3149\n",
      "98/224, train_loss: 0.1359, step time: 0.3954\n",
      "99/224, train_loss: 0.0985, step time: 0.3722\n",
      "100/224, train_loss: 0.3914, step time: 0.3123\n",
      "101/224, train_loss: 0.1816, step time: 0.3872\n",
      "102/224, train_loss: 0.1377, step time: 0.3169\n",
      "103/224, train_loss: 0.2139, step time: 0.3920\n",
      "104/224, train_loss: 0.0866, step time: 0.3143\n",
      "105/224, train_loss: 0.0675, step time: 0.3170\n",
      "106/224, train_loss: 0.1845, step time: 0.3961\n",
      "107/224, train_loss: 0.0806, step time: 0.4004\n",
      "108/224, train_loss: 0.3565, step time: 0.3142\n",
      "109/224, train_loss: 0.4229, step time: 0.3976\n",
      "110/224, train_loss: 0.0788, step time: 0.3144\n",
      "111/224, train_loss: 0.1223, step time: 0.3123\n",
      "112/224, train_loss: 0.1632, step time: 0.3833\n",
      "113/224, train_loss: 0.3195, step time: 0.3144\n",
      "114/224, train_loss: 0.2065, step time: 0.3160\n",
      "115/224, train_loss: 0.1019, step time: 0.4005\n",
      "116/224, train_loss: 0.1307, step time: 0.4125\n",
      "117/224, train_loss: 0.1681, step time: 0.3888\n",
      "118/224, train_loss: 0.3218, step time: 0.3755\n",
      "119/224, train_loss: 0.1786, step time: 0.3142\n",
      "120/224, train_loss: 0.1321, step time: 0.3167\n",
      "121/224, train_loss: 0.1068, step time: 0.4002\n",
      "122/224, train_loss: 0.2504, step time: 0.3753\n",
      "123/224, train_loss: 0.1077, step time: 0.3923\n",
      "124/224, train_loss: 0.2061, step time: 0.3894\n",
      "125/224, train_loss: 0.1309, step time: 0.3166\n",
      "126/224, train_loss: 0.0950, step time: 0.3120\n",
      "127/224, train_loss: 0.1003, step time: 0.3734\n",
      "128/224, train_loss: 0.1117, step time: 0.3145\n",
      "129/224, train_loss: 0.0962, step time: 0.3996\n",
      "130/224, train_loss: 0.1503, step time: 0.3160\n",
      "131/224, train_loss: 0.0866, step time: 0.3749\n",
      "132/224, train_loss: 0.2476, step time: 0.3920\n",
      "133/224, train_loss: 0.1006, step time: 0.3117\n",
      "134/224, train_loss: 0.1156, step time: 0.3138\n",
      "135/224, train_loss: 0.0944, step time: 0.3141\n",
      "136/224, train_loss: 0.2672, step time: 0.3844\n",
      "137/224, train_loss: 0.0906, step time: 0.3141\n",
      "138/224, train_loss: 0.0912, step time: 0.3163\n",
      "139/224, train_loss: 0.1273, step time: 0.3148\n",
      "140/224, train_loss: 0.0616, step time: 0.3916\n",
      "141/224, train_loss: 0.0802, step time: 0.3955\n",
      "142/224, train_loss: 0.3446, step time: 0.4057\n",
      "143/224, train_loss: 0.1022, step time: 0.3677\n",
      "144/224, train_loss: 0.0984, step time: 0.3164\n",
      "145/224, train_loss: 0.2100, step time: 0.3172\n",
      "146/224, train_loss: 0.1422, step time: 0.4028\n",
      "147/224, train_loss: 0.1268, step time: 0.3918\n",
      "148/224, train_loss: 0.0862, step time: 0.3974\n",
      "149/224, train_loss: 0.0727, step time: 0.3969\n",
      "150/224, train_loss: 0.0991, step time: 0.3122\n",
      "151/224, train_loss: 0.1203, step time: 0.3144\n",
      "152/224, train_loss: 0.0878, step time: 0.3144\n",
      "153/224, train_loss: 0.0607, step time: 0.3147\n",
      "154/224, train_loss: 0.1063, step time: 0.3189\n",
      "155/224, train_loss: 0.0867, step time: 0.3177\n",
      "156/224, train_loss: 0.1121, step time: 0.4067\n",
      "157/224, train_loss: 0.2371, step time: 0.3141\n",
      "158/224, train_loss: 0.1041, step time: 0.3147\n",
      "159/224, train_loss: 0.1380, step time: 0.3929\n",
      "160/224, train_loss: 0.0715, step time: 0.4034\n",
      "161/224, train_loss: 0.0866, step time: 0.3837\n",
      "162/224, train_loss: 0.1056, step time: 0.3151\n",
      "163/224, train_loss: 0.0771, step time: 0.3149\n",
      "164/224, train_loss: 0.1144, step time: 0.3126\n",
      "165/224, train_loss: 0.0631, step time: 0.3145\n",
      "166/224, train_loss: 0.1377, step time: 0.3705\n",
      "167/224, train_loss: 0.0655, step time: 0.4017\n",
      "168/224, train_loss: 0.0739, step time: 0.3166\n",
      "169/224, train_loss: 0.2609, step time: 0.3881\n",
      "170/224, train_loss: 0.1281, step time: 0.3144\n",
      "171/224, train_loss: 0.0949, step time: 0.3877\n",
      "172/224, train_loss: 0.1209, step time: 0.3163\n",
      "173/224, train_loss: 0.0746, step time: 0.3169\n",
      "174/224, train_loss: 0.1038, step time: 0.3171\n",
      "175/224, train_loss: 0.1304, step time: 0.3844\n",
      "176/224, train_loss: 0.1409, step time: 0.3175\n",
      "177/224, train_loss: 0.1405, step time: 0.3178\n",
      "178/224, train_loss: 0.1189, step time: 0.3128\n",
      "179/224, train_loss: 0.0948, step time: 0.3726\n",
      "180/224, train_loss: 0.0868, step time: 0.3937\n",
      "181/224, train_loss: 0.0767, step time: 0.3124\n",
      "182/224, train_loss: 0.1473, step time: 0.3874\n",
      "183/224, train_loss: 0.3235, step time: 0.3817\n",
      "184/224, train_loss: 0.2677, step time: 0.3920\n",
      "185/224, train_loss: 0.1201, step time: 0.3999\n",
      "186/224, train_loss: 0.1786, step time: 0.3128\n",
      "187/224, train_loss: 0.0808, step time: 0.3157\n",
      "188/224, train_loss: 0.1246, step time: 0.3155\n",
      "189/224, train_loss: 0.1248, step time: 0.3132\n",
      "190/224, train_loss: 0.1337, step time: 0.3147\n",
      "191/224, train_loss: 0.1388, step time: 0.3818\n",
      "192/224, train_loss: 0.0570, step time: 0.4033\n",
      "193/224, train_loss: 0.1240, step time: 0.3174\n",
      "194/224, train_loss: 0.1404, step time: 0.3983\n",
      "195/224, train_loss: 0.1875, step time: 0.3776\n",
      "196/224, train_loss: 0.2879, step time: 0.3712\n",
      "197/224, train_loss: 0.1467, step time: 0.3710\n",
      "198/224, train_loss: 0.0718, step time: 0.3173\n",
      "199/224, train_loss: 0.1309, step time: 0.3127\n",
      "200/224, train_loss: 0.1040, step time: 0.3145\n",
      "201/224, train_loss: 0.1035, step time: 0.3126\n",
      "202/224, train_loss: 0.0893, step time: 0.3146\n",
      "203/224, train_loss: 0.1850, step time: 0.3667\n",
      "204/224, train_loss: 0.1050, step time: 0.3796\n",
      "205/224, train_loss: 0.2218, step time: 0.3728\n",
      "206/224, train_loss: 0.0880, step time: 0.3993\n",
      "207/224, train_loss: 0.3574, step time: 0.3969\n",
      "208/224, train_loss: 0.1045, step time: 0.3903\n",
      "209/224, train_loss: 0.1113, step time: 0.3914\n",
      "210/224, train_loss: 0.0767, step time: 0.3136\n",
      "211/224, train_loss: 0.1229, step time: 0.4027\n",
      "212/224, train_loss: 0.0988, step time: 0.3146\n",
      "213/224, train_loss: 0.0679, step time: 0.3175\n",
      "214/224, train_loss: 0.1064, step time: 0.3152\n",
      "215/224, train_loss: 0.1543, step time: 0.5436\n",
      "216/224, train_loss: 0.0649, step time: 0.3839\n",
      "217/224, train_loss: 0.2002, step time: 0.3862\n",
      "218/224, train_loss: 0.1211, step time: 0.3155\n",
      "219/224, train_loss: 0.1951, step time: 0.3976\n",
      "220/224, train_loss: 0.1358, step time: 0.3153\n",
      "221/224, train_loss: 0.1981, step time: 0.4063\n",
      "222/224, train_loss: 0.1767, step time: 0.3710\n",
      "223/224, train_loss: 0.1062, step time: 0.3828\n",
      "224/224, train_loss: 0.2055, step time: 0.3981\n",
      "epoch 58 average loss: 0.1526\n",
      "current epoch: 58 current mean dice: 0.6966 class1: 0.9993 class2: 0.7417 class3: 0.3488\n",
      "best mean dice: 0.7136 at epoch: 53\n",
      "time consuming of epoch 58 is: 698.9304\n",
      "hello\n",
      "----------\n",
      "epoch 59/100\n",
      "1/224, train_loss: 0.1181, step time: 0.3173\n",
      "2/224, train_loss: 0.1140, step time: 0.3901\n",
      "3/224, train_loss: 0.1576, step time: 0.3851\n",
      "4/224, train_loss: 0.2643, step time: 0.3146\n",
      "5/224, train_loss: 0.1046, step time: 0.3145\n",
      "6/224, train_loss: 0.1160, step time: 0.3165\n",
      "7/224, train_loss: 0.1167, step time: 0.3868\n",
      "8/224, train_loss: 0.1054, step time: 0.3799\n",
      "9/224, train_loss: 0.1251, step time: 0.3166\n",
      "10/224, train_loss: 0.2102, step time: 0.4028\n",
      "11/224, train_loss: 0.2130, step time: 0.3992\n",
      "12/224, train_loss: 0.0775, step time: 0.3152\n",
      "13/224, train_loss: 0.1440, step time: 0.4015\n",
      "14/224, train_loss: 0.3445, step time: 0.3813\n",
      "15/224, train_loss: 0.0944, step time: 0.3761\n",
      "16/224, train_loss: 0.1374, step time: 0.3743\n",
      "17/224, train_loss: 0.1065, step time: 0.3183\n",
      "18/224, train_loss: 0.1345, step time: 0.3153\n",
      "19/224, train_loss: 0.0609, step time: 0.3132\n",
      "20/224, train_loss: 0.0832, step time: 0.3904\n",
      "21/224, train_loss: 0.0938, step time: 0.3142\n",
      "22/224, train_loss: 0.0928, step time: 0.3729\n",
      "23/224, train_loss: 0.1936, step time: 0.3762\n",
      "24/224, train_loss: 0.1239, step time: 0.3670\n",
      "25/224, train_loss: 0.2107, step time: 0.3763\n",
      "26/224, train_loss: 0.2269, step time: 0.3974\n",
      "27/224, train_loss: 0.0950, step time: 0.3158\n",
      "28/224, train_loss: 0.1503, step time: 0.3176\n",
      "29/224, train_loss: 0.1864, step time: 0.3783\n",
      "30/224, train_loss: 0.1428, step time: 0.3711\n",
      "31/224, train_loss: 0.0711, step time: 0.3173\n",
      "32/224, train_loss: 0.0717, step time: 0.3173\n",
      "33/224, train_loss: 0.1136, step time: 0.3148\n",
      "34/224, train_loss: 0.1325, step time: 0.3144\n",
      "35/224, train_loss: 0.0578, step time: 0.3145\n",
      "36/224, train_loss: 0.2366, step time: 0.4041\n",
      "37/224, train_loss: 0.2544, step time: 0.3885\n",
      "38/224, train_loss: 0.1056, step time: 0.4054\n",
      "39/224, train_loss: 0.1177, step time: 0.3765\n",
      "40/224, train_loss: 0.0817, step time: 0.3122\n",
      "41/224, train_loss: 0.1003, step time: 0.3175\n",
      "42/224, train_loss: 0.2170, step time: 0.3861\n",
      "43/224, train_loss: 0.3476, step time: 0.3703\n",
      "44/224, train_loss: 0.1958, step time: 0.3880\n",
      "45/224, train_loss: 0.0943, step time: 0.3990\n",
      "46/224, train_loss: 0.0843, step time: 0.4046\n",
      "47/224, train_loss: 0.1694, step time: 0.3786\n",
      "48/224, train_loss: 0.3654, step time: 0.3912\n",
      "49/224, train_loss: 0.2876, step time: 0.3732\n",
      "50/224, train_loss: 0.1266, step time: 0.3185\n",
      "51/224, train_loss: 0.1312, step time: 0.4091\n",
      "52/224, train_loss: 0.2648, step time: 0.3791\n",
      "53/224, train_loss: 0.0866, step time: 0.3746\n",
      "54/224, train_loss: 0.1136, step time: 0.3164\n",
      "55/224, train_loss: 0.0698, step time: 0.3139\n",
      "56/224, train_loss: 0.2378, step time: 0.4138\n",
      "57/224, train_loss: 0.1272, step time: 0.3840\n",
      "58/224, train_loss: 0.0993, step time: 0.3164\n",
      "59/224, train_loss: 0.1334, step time: 0.3834\n",
      "60/224, train_loss: 0.2232, step time: 0.3719\n",
      "61/224, train_loss: 0.0636, step time: 0.3175\n",
      "62/224, train_loss: 0.1310, step time: 0.3174\n",
      "63/224, train_loss: 0.1627, step time: 0.3156\n",
      "64/224, train_loss: 0.0779, step time: 0.3912\n",
      "65/224, train_loss: 0.1228, step time: 0.3670\n",
      "66/224, train_loss: 0.1755, step time: 0.3158\n",
      "67/224, train_loss: 0.1733, step time: 0.3807\n",
      "68/224, train_loss: 0.0720, step time: 0.3926\n",
      "69/224, train_loss: 0.3868, step time: 0.4110\n",
      "70/224, train_loss: 0.1640, step time: 0.3909\n",
      "71/224, train_loss: 0.1018, step time: 0.3150\n",
      "72/224, train_loss: 0.1139, step time: 0.3877\n",
      "73/224, train_loss: 0.0880, step time: 0.3817\n",
      "74/224, train_loss: 0.0627, step time: 0.3159\n",
      "75/224, train_loss: 0.1250, step time: 0.3832\n",
      "76/224, train_loss: 0.3025, step time: 0.4095\n",
      "77/224, train_loss: 0.0452, step time: 0.3890\n",
      "78/224, train_loss: 0.2166, step time: 0.3932\n",
      "79/224, train_loss: 0.1563, step time: 0.3154\n",
      "80/224, train_loss: 0.1207, step time: 0.3961\n",
      "81/224, train_loss: 0.1599, step time: 0.3184\n",
      "82/224, train_loss: 0.1581, step time: 0.4014\n",
      "83/224, train_loss: 0.1123, step time: 0.3178\n",
      "84/224, train_loss: 0.0972, step time: 0.3697\n",
      "85/224, train_loss: 0.0716, step time: 0.3152\n",
      "86/224, train_loss: 0.0792, step time: 0.3130\n",
      "87/224, train_loss: 0.2076, step time: 0.3687\n",
      "88/224, train_loss: 0.0950, step time: 0.4037\n",
      "89/224, train_loss: 0.1156, step time: 0.4088\n",
      "90/224, train_loss: 0.1237, step time: 0.3158\n",
      "91/224, train_loss: 0.1335, step time: 0.3131\n",
      "92/224, train_loss: 0.3852, step time: 0.4108\n",
      "93/224, train_loss: 0.0728, step time: 0.3756\n",
      "94/224, train_loss: 0.2297, step time: 0.3654\n",
      "95/224, train_loss: 0.0864, step time: 0.4005\n",
      "96/224, train_loss: 0.1133, step time: 0.3865\n",
      "97/224, train_loss: 0.0693, step time: 0.3758\n",
      "98/224, train_loss: 0.1231, step time: 0.3692\n",
      "99/224, train_loss: 0.1703, step time: 0.3987\n",
      "100/224, train_loss: 0.0773, step time: 0.4022\n",
      "101/224, train_loss: 0.0907, step time: 0.3184\n",
      "102/224, train_loss: 0.0834, step time: 0.3983\n",
      "103/224, train_loss: 0.1933, step time: 0.4044\n",
      "104/224, train_loss: 0.2271, step time: 0.3856\n",
      "105/224, train_loss: 0.1941, step time: 0.3172\n",
      "106/224, train_loss: 0.1975, step time: 0.4098\n",
      "107/224, train_loss: 0.1127, step time: 0.3183\n",
      "108/224, train_loss: 0.1983, step time: 0.3161\n",
      "109/224, train_loss: 0.1692, step time: 0.3699\n",
      "110/224, train_loss: 0.0909, step time: 0.3725\n",
      "111/224, train_loss: 0.3514, step time: 0.4122\n",
      "112/224, train_loss: 0.1638, step time: 0.3155\n",
      "113/224, train_loss: 0.1460, step time: 0.3771\n",
      "114/224, train_loss: 0.1499, step time: 0.3178\n",
      "115/224, train_loss: 0.2436, step time: 0.3731\n",
      "116/224, train_loss: 0.2790, step time: 0.3879\n",
      "117/224, train_loss: 0.2479, step time: 0.4038\n",
      "118/224, train_loss: 0.3426, step time: 0.4083\n",
      "119/224, train_loss: 0.0689, step time: 0.3155\n",
      "120/224, train_loss: 0.1211, step time: 0.3826\n",
      "121/224, train_loss: 0.1493, step time: 0.3170\n",
      "122/224, train_loss: 0.1247, step time: 0.3138\n",
      "123/224, train_loss: 0.1030, step time: 0.3155\n",
      "124/224, train_loss: 0.1552, step time: 0.3828\n",
      "125/224, train_loss: 0.1646, step time: 0.4088\n",
      "126/224, train_loss: 0.1864, step time: 0.3908\n",
      "127/224, train_loss: 0.1449, step time: 0.3874\n",
      "128/224, train_loss: 0.1544, step time: 0.4008\n",
      "129/224, train_loss: 0.0749, step time: 0.3153\n",
      "130/224, train_loss: 0.2361, step time: 0.4012\n",
      "131/224, train_loss: 0.2418, step time: 0.4002\n",
      "132/224, train_loss: 0.1398, step time: 0.3151\n",
      "133/224, train_loss: 0.3137, step time: 0.3848\n",
      "134/224, train_loss: 0.2468, step time: 0.4029\n",
      "135/224, train_loss: 0.0961, step time: 0.3170\n",
      "136/224, train_loss: 0.0752, step time: 0.3149\n",
      "137/224, train_loss: 0.3771, step time: 0.3684\n",
      "138/224, train_loss: 0.0942, step time: 0.3153\n",
      "139/224, train_loss: 0.1611, step time: 0.4099\n",
      "140/224, train_loss: 0.1236, step time: 0.3151\n",
      "141/224, train_loss: 0.1877, step time: 0.3150\n",
      "142/224, train_loss: 0.1972, step time: 0.4001\n",
      "143/224, train_loss: 0.1192, step time: 0.3829\n",
      "144/224, train_loss: 0.0992, step time: 0.3682\n",
      "145/224, train_loss: 0.4466, step time: 0.3790\n",
      "146/224, train_loss: 0.0920, step time: 0.3175\n",
      "147/224, train_loss: 0.1104, step time: 0.3132\n",
      "148/224, train_loss: 0.1346, step time: 0.3845\n",
      "149/224, train_loss: 0.1605, step time: 0.3942\n",
      "150/224, train_loss: 0.1423, step time: 0.3148\n",
      "151/224, train_loss: 0.0753, step time: 0.3719\n",
      "152/224, train_loss: 0.0820, step time: 0.3173\n",
      "153/224, train_loss: 0.1023, step time: 0.3166\n",
      "154/224, train_loss: 0.0739, step time: 0.3143\n",
      "155/224, train_loss: 0.0758, step time: 0.3145\n",
      "156/224, train_loss: 0.1071, step time: 0.3169\n",
      "157/224, train_loss: 0.0777, step time: 0.3124\n",
      "158/224, train_loss: 0.0850, step time: 0.3143\n",
      "159/224, train_loss: 0.1334, step time: 0.3168\n",
      "160/224, train_loss: 0.3514, step time: 0.3737\n",
      "161/224, train_loss: 0.0914, step time: 0.3950\n",
      "162/224, train_loss: 0.0657, step time: 0.4023\n",
      "163/224, train_loss: 0.0809, step time: 0.3810\n",
      "164/224, train_loss: 0.2347, step time: 0.3763\n",
      "165/224, train_loss: 0.3540, step time: 0.3852\n",
      "166/224, train_loss: 0.1449, step time: 0.3146\n",
      "167/224, train_loss: 0.1099, step time: 0.3138\n",
      "168/224, train_loss: 0.1465, step time: 0.3757\n",
      "169/224, train_loss: 0.1063, step time: 0.3860\n",
      "170/224, train_loss: 0.1819, step time: 0.3164\n",
      "171/224, train_loss: 0.0771, step time: 0.3784\n",
      "172/224, train_loss: 0.1008, step time: 0.4090\n",
      "173/224, train_loss: 0.1000, step time: 0.3166\n",
      "174/224, train_loss: 0.1621, step time: 0.4064\n",
      "175/224, train_loss: 0.0693, step time: 0.3174\n",
      "176/224, train_loss: 0.3280, step time: 0.3146\n",
      "177/224, train_loss: 0.0661, step time: 0.3166\n",
      "178/224, train_loss: 0.1386, step time: 0.3162\n",
      "179/224, train_loss: 0.1439, step time: 0.4063\n",
      "180/224, train_loss: 0.4781, step time: 0.3784\n",
      "181/224, train_loss: 0.0963, step time: 0.3945\n",
      "182/224, train_loss: 0.1068, step time: 0.3896\n",
      "183/224, train_loss: 0.1415, step time: 0.3707\n",
      "184/224, train_loss: 0.1137, step time: 0.3166\n",
      "185/224, train_loss: 0.0914, step time: 0.4151\n",
      "186/224, train_loss: 0.1075, step time: 0.3986\n",
      "187/224, train_loss: 0.2210, step time: 0.3694\n",
      "188/224, train_loss: 0.1831, step time: 0.3990\n",
      "189/224, train_loss: 0.1568, step time: 0.3814\n",
      "190/224, train_loss: 0.2259, step time: 0.3170\n",
      "191/224, train_loss: 0.0783, step time: 0.3153\n",
      "192/224, train_loss: 0.1309, step time: 0.3150\n",
      "193/224, train_loss: 0.2404, step time: 0.3154\n",
      "194/224, train_loss: 0.1548, step time: 0.3155\n",
      "195/224, train_loss: 0.1039, step time: 0.3130\n",
      "196/224, train_loss: 0.1208, step time: 0.3887\n",
      "197/224, train_loss: 0.0937, step time: 0.3176\n",
      "198/224, train_loss: 0.0984, step time: 0.3991\n",
      "199/224, train_loss: 0.1424, step time: 0.3695\n",
      "200/224, train_loss: 0.2937, step time: 0.3138\n",
      "201/224, train_loss: 0.2776, step time: 0.3992\n",
      "202/224, train_loss: 0.1439, step time: 0.3157\n",
      "203/224, train_loss: 0.3115, step time: 0.3984\n",
      "204/224, train_loss: 0.0863, step time: 0.3156\n",
      "205/224, train_loss: 0.2655, step time: 0.3157\n",
      "206/224, train_loss: 0.1524, step time: 0.3883\n",
      "207/224, train_loss: 0.1221, step time: 0.4015\n",
      "208/224, train_loss: 0.1447, step time: 0.3998\n",
      "209/224, train_loss: 0.1738, step time: 0.3172\n",
      "210/224, train_loss: 0.1077, step time: 0.3143\n",
      "211/224, train_loss: 0.1518, step time: 0.3144\n",
      "212/224, train_loss: 0.1041, step time: 0.3146\n",
      "213/224, train_loss: 0.0719, step time: 0.4112\n",
      "214/224, train_loss: 0.1986, step time: 0.4063\n",
      "215/224, train_loss: 0.0622, step time: 0.3146\n",
      "216/224, train_loss: 0.0946, step time: 0.3171\n",
      "217/224, train_loss: 0.0713, step time: 0.3169\n",
      "218/224, train_loss: 0.0676, step time: 0.3142\n",
      "219/224, train_loss: 0.0791, step time: 0.3123\n",
      "220/224, train_loss: 0.2462, step time: 0.3148\n",
      "221/224, train_loss: 0.1614, step time: 0.3917\n",
      "222/224, train_loss: 0.1638, step time: 0.4091\n",
      "223/224, train_loss: 0.1550, step time: 0.3149\n",
      "224/224, train_loss: 0.1953, step time: 0.3689\n",
      "epoch 59 average loss: 0.1526\n",
      "current epoch: 59 current mean dice: 0.7022 class1: 0.9993 class2: 0.7418 class3: 0.3654\n",
      "best mean dice: 0.7136 at epoch: 53\n",
      "time consuming of epoch 59 is: 848.8564\n",
      "hello\n",
      "----------\n",
      "epoch 60/100\n",
      "1/224, train_loss: 0.1587, step time: 0.4053\n",
      "2/224, train_loss: 0.1448, step time: 0.3162\n",
      "3/224, train_loss: 0.0781, step time: 0.4019\n",
      "4/224, train_loss: 0.0906, step time: 0.4082\n",
      "5/224, train_loss: 0.0808, step time: 0.3137\n",
      "6/224, train_loss: 0.0775, step time: 0.3131\n",
      "7/224, train_loss: 0.1204, step time: 0.3170\n",
      "8/224, train_loss: 0.1969, step time: 0.3960\n",
      "9/224, train_loss: 0.0717, step time: 0.4019\n",
      "10/224, train_loss: 0.1148, step time: 0.3175\n",
      "11/224, train_loss: 0.2158, step time: 0.3130\n",
      "12/224, train_loss: 0.1128, step time: 0.3172\n",
      "13/224, train_loss: 0.2713, step time: 0.3975\n",
      "14/224, train_loss: 0.1573, step time: 0.3940\n",
      "15/224, train_loss: 0.1270, step time: 0.3930\n",
      "16/224, train_loss: 0.2906, step time: 0.4003\n",
      "17/224, train_loss: 0.1696, step time: 0.3945\n",
      "18/224, train_loss: 0.1835, step time: 0.4086\n",
      "19/224, train_loss: 0.1144, step time: 0.3830\n",
      "20/224, train_loss: 0.2840, step time: 0.3869\n",
      "21/224, train_loss: 0.1159, step time: 0.3163\n",
      "22/224, train_loss: 0.1166, step time: 0.3705\n",
      "23/224, train_loss: 0.1531, step time: 0.3820\n",
      "24/224, train_loss: 0.1135, step time: 0.3180\n",
      "25/224, train_loss: 0.1071, step time: 0.3176\n",
      "26/224, train_loss: 0.1324, step time: 0.3170\n",
      "27/224, train_loss: 0.1486, step time: 0.3145\n",
      "28/224, train_loss: 0.2864, step time: 0.3880\n",
      "29/224, train_loss: 0.1551, step time: 0.3801\n",
      "30/224, train_loss: 0.0951, step time: 0.3176\n",
      "31/224, train_loss: 0.0671, step time: 0.3146\n",
      "32/224, train_loss: 0.0891, step time: 0.3126\n",
      "33/224, train_loss: 0.1377, step time: 0.3707\n",
      "34/224, train_loss: 0.1659, step time: 0.3155\n",
      "35/224, train_loss: 0.1907, step time: 0.3677\n",
      "36/224, train_loss: 0.1097, step time: 0.3155\n",
      "37/224, train_loss: 0.1094, step time: 0.4085\n",
      "38/224, train_loss: 0.1432, step time: 0.3788\n",
      "39/224, train_loss: 0.0609, step time: 0.3156\n",
      "40/224, train_loss: 0.0490, step time: 0.3173\n",
      "41/224, train_loss: 0.1064, step time: 0.3174\n",
      "42/224, train_loss: 0.2843, step time: 0.3863\n",
      "43/224, train_loss: 0.0847, step time: 0.3182\n",
      "44/224, train_loss: 0.1138, step time: 0.3695\n",
      "45/224, train_loss: 0.0596, step time: 0.3157\n",
      "46/224, train_loss: 0.2810, step time: 0.3160\n",
      "47/224, train_loss: 0.0528, step time: 0.3155\n",
      "48/224, train_loss: 0.1854, step time: 0.4073\n",
      "49/224, train_loss: 0.1220, step time: 0.3170\n",
      "50/224, train_loss: 0.2669, step time: 0.3786\n",
      "51/224, train_loss: 0.1189, step time: 0.3940\n",
      "52/224, train_loss: 0.2832, step time: 0.3153\n",
      "53/224, train_loss: 0.1154, step time: 0.3923\n",
      "54/224, train_loss: 0.1171, step time: 0.3745\n",
      "55/224, train_loss: 0.0777, step time: 0.3158\n",
      "56/224, train_loss: 0.1390, step time: 0.3158\n",
      "57/224, train_loss: 0.1847, step time: 0.3710\n",
      "58/224, train_loss: 0.0629, step time: 0.4027\n",
      "59/224, train_loss: 0.0749, step time: 0.3178\n",
      "60/224, train_loss: 0.1698, step time: 0.3820\n",
      "61/224, train_loss: 0.0652, step time: 0.3151\n",
      "62/224, train_loss: 0.2391, step time: 0.4008\n",
      "63/224, train_loss: 0.1501, step time: 0.3151\n",
      "64/224, train_loss: 0.0756, step time: 0.3132\n",
      "65/224, train_loss: 0.1327, step time: 0.3186\n",
      "66/224, train_loss: 0.1166, step time: 0.3183\n",
      "67/224, train_loss: 0.2919, step time: 0.3816\n",
      "68/224, train_loss: 0.1885, step time: 0.3903\n",
      "69/224, train_loss: 0.1700, step time: 0.3153\n",
      "70/224, train_loss: 0.2841, step time: 0.3732\n",
      "71/224, train_loss: 0.2188, step time: 0.3126\n",
      "72/224, train_loss: 0.1010, step time: 0.3143\n",
      "73/224, train_loss: 0.0999, step time: 0.3172\n",
      "74/224, train_loss: 0.1790, step time: 0.3172\n",
      "75/224, train_loss: 0.1517, step time: 0.3796\n",
      "76/224, train_loss: 0.1141, step time: 0.3158\n",
      "77/224, train_loss: 0.2197, step time: 0.3993\n",
      "78/224, train_loss: 0.2833, step time: 0.3679\n",
      "79/224, train_loss: 0.0744, step time: 0.3169\n",
      "80/224, train_loss: 0.1318, step time: 0.3154\n",
      "81/224, train_loss: 0.0497, step time: 0.3959\n",
      "82/224, train_loss: 0.1668, step time: 0.3172\n",
      "83/224, train_loss: 0.1730, step time: 0.4085\n",
      "84/224, train_loss: 0.0998, step time: 0.3970\n",
      "85/224, train_loss: 0.0904, step time: 0.3729\n",
      "86/224, train_loss: 0.2398, step time: 0.4102\n",
      "87/224, train_loss: 0.1165, step time: 0.4041\n",
      "88/224, train_loss: 0.1047, step time: 0.3133\n",
      "89/224, train_loss: 0.0550, step time: 0.3125\n",
      "90/224, train_loss: 0.2813, step time: 0.3172\n",
      "91/224, train_loss: 0.0945, step time: 0.3730\n",
      "92/224, train_loss: 0.2438, step time: 0.3151\n",
      "93/224, train_loss: 0.1131, step time: 0.3150\n",
      "94/224, train_loss: 0.0912, step time: 0.3128\n",
      "95/224, train_loss: 0.1965, step time: 0.3153\n",
      "96/224, train_loss: 0.1455, step time: 0.3153\n",
      "97/224, train_loss: 0.1100, step time: 0.3173\n",
      "98/224, train_loss: 0.1024, step time: 0.4051\n",
      "99/224, train_loss: 0.1348, step time: 0.3149\n",
      "100/224, train_loss: 0.1006, step time: 0.3151\n",
      "101/224, train_loss: 0.1647, step time: 0.3890\n",
      "102/224, train_loss: 0.2310, step time: 0.3152\n",
      "103/224, train_loss: 0.1352, step time: 0.3150\n",
      "104/224, train_loss: 0.0928, step time: 0.4037\n",
      "105/224, train_loss: 0.1044, step time: 0.3152\n",
      "106/224, train_loss: 0.1063, step time: 0.3171\n",
      "107/224, train_loss: 0.1133, step time: 0.3814\n",
      "108/224, train_loss: 0.0811, step time: 0.3177\n",
      "109/224, train_loss: 0.0615, step time: 0.3810\n",
      "110/224, train_loss: 0.0867, step time: 0.3176\n",
      "111/224, train_loss: 0.0775, step time: 0.3840\n",
      "112/224, train_loss: 0.1421, step time: 0.3859\n",
      "113/224, train_loss: 0.1490, step time: 0.3159\n",
      "114/224, train_loss: 0.0695, step time: 0.4002\n",
      "115/224, train_loss: 0.1187, step time: 0.3124\n",
      "116/224, train_loss: 0.0719, step time: 0.3147\n",
      "117/224, train_loss: 0.1447, step time: 0.3840\n",
      "118/224, train_loss: 0.1251, step time: 0.3143\n",
      "119/224, train_loss: 0.1180, step time: 0.3146\n",
      "120/224, train_loss: 0.1145, step time: 0.3150\n",
      "121/224, train_loss: 0.0935, step time: 0.3178\n",
      "122/224, train_loss: 0.0941, step time: 0.3804\n",
      "123/224, train_loss: 0.1183, step time: 0.3169\n",
      "124/224, train_loss: 0.1550, step time: 0.3123\n",
      "125/224, train_loss: 0.2288, step time: 0.4013\n",
      "126/224, train_loss: 0.3595, step time: 0.3811\n",
      "127/224, train_loss: 0.1304, step time: 0.4068\n",
      "128/224, train_loss: 0.0776, step time: 0.3148\n",
      "129/224, train_loss: 0.2396, step time: 0.3146\n",
      "130/224, train_loss: 0.1427, step time: 0.3791\n",
      "131/224, train_loss: 0.1097, step time: 0.3171\n",
      "132/224, train_loss: 0.2331, step time: 0.3966\n",
      "133/224, train_loss: 0.1485, step time: 0.3144\n",
      "134/224, train_loss: 0.1390, step time: 0.3169\n",
      "135/224, train_loss: 0.0812, step time: 0.3126\n",
      "136/224, train_loss: 0.1527, step time: 0.3746\n",
      "137/224, train_loss: 0.1096, step time: 0.3754\n",
      "138/224, train_loss: 0.3726, step time: 0.3765\n",
      "139/224, train_loss: 0.1928, step time: 0.3972\n",
      "140/224, train_loss: 0.1372, step time: 0.3157\n",
      "141/224, train_loss: 0.2877, step time: 0.3792\n",
      "142/224, train_loss: 0.2132, step time: 0.3863\n",
      "143/224, train_loss: 0.1493, step time: 0.3847\n",
      "144/224, train_loss: 0.0885, step time: 0.3151\n",
      "145/224, train_loss: 0.1985, step time: 0.3171\n",
      "146/224, train_loss: 0.1761, step time: 0.3172\n",
      "147/224, train_loss: 0.1220, step time: 0.3167\n",
      "148/224, train_loss: 0.1107, step time: 0.3140\n",
      "149/224, train_loss: 0.1183, step time: 0.3973\n",
      "150/224, train_loss: 0.0749, step time: 0.3167\n",
      "151/224, train_loss: 0.1525, step time: 0.3175\n",
      "152/224, train_loss: 0.0757, step time: 0.3147\n",
      "153/224, train_loss: 0.0824, step time: 0.3140\n",
      "154/224, train_loss: 0.1310, step time: 0.3770\n",
      "155/224, train_loss: 0.1113, step time: 0.3141\n",
      "156/224, train_loss: 0.0856, step time: 0.3141\n",
      "157/224, train_loss: 0.2322, step time: 0.3145\n",
      "158/224, train_loss: 0.1374, step time: 0.4026\n",
      "159/224, train_loss: 0.4492, step time: 0.3859\n",
      "160/224, train_loss: 0.1755, step time: 0.4099\n",
      "161/224, train_loss: 0.0967, step time: 0.3152\n",
      "162/224, train_loss: 0.3785, step time: 0.3682\n",
      "163/224, train_loss: 0.1149, step time: 0.3179\n",
      "164/224, train_loss: 0.3758, step time: 0.3794\n",
      "165/224, train_loss: 0.1324, step time: 0.3754\n",
      "166/224, train_loss: 0.1156, step time: 0.3796\n",
      "167/224, train_loss: 0.0770, step time: 0.3151\n",
      "168/224, train_loss: 0.3712, step time: 0.3686\n",
      "169/224, train_loss: 0.2453, step time: 0.3925\n",
      "170/224, train_loss: 0.1069, step time: 0.3897\n",
      "171/224, train_loss: 0.1084, step time: 0.3146\n",
      "172/224, train_loss: 0.1147, step time: 0.3932\n",
      "173/224, train_loss: 0.1870, step time: 0.3956\n",
      "174/224, train_loss: 0.0725, step time: 0.3143\n",
      "175/224, train_loss: 0.1200, step time: 0.3143\n",
      "176/224, train_loss: 0.0754, step time: 0.3144\n",
      "177/224, train_loss: 0.3420, step time: 0.3993\n",
      "178/224, train_loss: 0.1026, step time: 0.3122\n",
      "179/224, train_loss: 0.0593, step time: 0.3120\n",
      "180/224, train_loss: 0.0733, step time: 0.3854\n",
      "181/224, train_loss: 0.3216, step time: 0.3759\n",
      "182/224, train_loss: 0.1609, step time: 0.3717\n",
      "183/224, train_loss: 0.2188, step time: 0.4131\n",
      "184/224, train_loss: 0.0751, step time: 0.3151\n",
      "185/224, train_loss: 0.0743, step time: 0.3123\n",
      "186/224, train_loss: 0.1286, step time: 0.3167\n",
      "187/224, train_loss: 0.0993, step time: 0.4069\n",
      "188/224, train_loss: 0.1132, step time: 0.3165\n",
      "189/224, train_loss: 0.2392, step time: 0.3731\n",
      "190/224, train_loss: 0.0958, step time: 0.3142\n",
      "191/224, train_loss: 0.1683, step time: 0.3145\n",
      "192/224, train_loss: 0.1723, step time: 0.3124\n",
      "193/224, train_loss: 0.1596, step time: 0.3148\n",
      "194/224, train_loss: 0.0850, step time: 0.3747\n",
      "195/224, train_loss: 0.1443, step time: 0.3153\n",
      "196/224, train_loss: 0.1482, step time: 0.3143\n",
      "197/224, train_loss: 0.3599, step time: 0.3657\n",
      "198/224, train_loss: 0.0541, step time: 0.3695\n",
      "199/224, train_loss: 0.1011, step time: 0.3169\n",
      "200/224, train_loss: 0.0951, step time: 0.3144\n",
      "201/224, train_loss: 0.0808, step time: 0.3144\n",
      "202/224, train_loss: 0.2961, step time: 0.4012\n",
      "203/224, train_loss: 0.1544, step time: 0.3967\n",
      "204/224, train_loss: 0.3366, step time: 0.3149\n",
      "205/224, train_loss: 0.2090, step time: 0.3798\n",
      "206/224, train_loss: 0.2128, step time: 0.3166\n",
      "207/224, train_loss: 0.0927, step time: 0.3120\n",
      "208/224, train_loss: 0.0944, step time: 0.3125\n",
      "209/224, train_loss: 0.0995, step time: 0.3827\n",
      "210/224, train_loss: 0.0875, step time: 0.3141\n",
      "211/224, train_loss: 0.0579, step time: 0.3655\n",
      "212/224, train_loss: 0.0980, step time: 0.3902\n",
      "213/224, train_loss: 0.1176, step time: 0.3654\n",
      "214/224, train_loss: 0.3474, step time: 0.3869\n",
      "215/224, train_loss: 0.3692, step time: 0.3169\n",
      "216/224, train_loss: 0.1052, step time: 0.3162\n",
      "217/224, train_loss: 0.0830, step time: 0.3723\n",
      "218/224, train_loss: 0.0890, step time: 0.3125\n",
      "219/224, train_loss: 0.0883, step time: 0.3795\n",
      "220/224, train_loss: 0.1117, step time: 0.3167\n",
      "221/224, train_loss: 0.1059, step time: 0.3847\n",
      "222/224, train_loss: 0.2350, step time: 0.3124\n",
      "223/224, train_loss: 0.1329, step time: 0.3145\n",
      "224/224, train_loss: 0.3801, step time: 0.3685\n",
      "epoch 60 average loss: 0.1499\n",
      "current epoch: 60 current mean dice: 0.7138 class1: 0.9993 class2: 0.7407 class3: 0.4014\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 60 is: 673.2662\n",
      "hello\n",
      "----------\n",
      "epoch 61/100\n",
      "1/224, train_loss: 0.1157, step time: 0.3825\n",
      "2/224, train_loss: 0.0852, step time: 0.3130\n",
      "3/224, train_loss: 0.2463, step time: 0.3898\n",
      "4/224, train_loss: 0.1375, step time: 0.4006\n",
      "5/224, train_loss: 0.0990, step time: 0.3682\n",
      "6/224, train_loss: 0.1010, step time: 0.3153\n",
      "7/224, train_loss: 0.1438, step time: 0.3644\n",
      "8/224, train_loss: 0.1513, step time: 0.3148\n",
      "9/224, train_loss: 0.0864, step time: 0.3166\n",
      "10/224, train_loss: 0.2211, step time: 0.3166\n",
      "11/224, train_loss: 0.0715, step time: 0.3126\n",
      "12/224, train_loss: 0.2510, step time: 0.3846\n",
      "13/224, train_loss: 0.2595, step time: 0.3905\n",
      "14/224, train_loss: 0.2355, step time: 0.3148\n",
      "15/224, train_loss: 0.0986, step time: 0.4084\n",
      "16/224, train_loss: 0.0413, step time: 0.3130\n",
      "17/224, train_loss: 0.1441, step time: 0.3156\n",
      "18/224, train_loss: 0.1980, step time: 0.3775\n",
      "19/224, train_loss: 0.0471, step time: 0.3153\n",
      "20/224, train_loss: 0.1879, step time: 0.4089\n",
      "21/224, train_loss: 0.3173, step time: 0.3940\n",
      "22/224, train_loss: 0.0794, step time: 0.3146\n",
      "23/224, train_loss: 0.1081, step time: 0.3148\n",
      "24/224, train_loss: 0.0883, step time: 0.3130\n",
      "25/224, train_loss: 0.3082, step time: 0.3153\n",
      "26/224, train_loss: 0.1868, step time: 0.3840\n",
      "27/224, train_loss: 0.0655, step time: 0.4035\n",
      "28/224, train_loss: 0.1007, step time: 0.3161\n",
      "29/224, train_loss: 0.0823, step time: 0.4086\n",
      "30/224, train_loss: 0.1639, step time: 0.3801\n",
      "31/224, train_loss: 0.0760, step time: 0.3148\n",
      "32/224, train_loss: 0.3719, step time: 0.3887\n",
      "33/224, train_loss: 0.1830, step time: 0.3706\n",
      "34/224, train_loss: 0.1260, step time: 0.3156\n",
      "35/224, train_loss: 0.2112, step time: 0.4077\n",
      "36/224, train_loss: 0.1060, step time: 0.3633\n",
      "37/224, train_loss: 0.1551, step time: 0.3963\n",
      "38/224, train_loss: 0.2839, step time: 0.4103\n",
      "39/224, train_loss: 0.1568, step time: 0.3140\n",
      "40/224, train_loss: 0.1579, step time: 0.3874\n",
      "41/224, train_loss: 0.2809, step time: 0.3816\n",
      "42/224, train_loss: 0.3106, step time: 0.4009\n",
      "43/224, train_loss: 0.0614, step time: 0.3175\n",
      "44/224, train_loss: 0.1248, step time: 0.3165\n",
      "45/224, train_loss: 0.1224, step time: 0.3183\n",
      "46/224, train_loss: 0.1198, step time: 0.3930\n",
      "47/224, train_loss: 0.0597, step time: 0.3151\n",
      "48/224, train_loss: 0.1399, step time: 0.3151\n",
      "49/224, train_loss: 0.0569, step time: 0.3854\n",
      "50/224, train_loss: 0.1702, step time: 0.3764\n",
      "51/224, train_loss: 0.0755, step time: 0.3140\n",
      "52/224, train_loss: 0.1424, step time: 0.3159\n",
      "53/224, train_loss: 0.1381, step time: 0.4023\n",
      "54/224, train_loss: 0.1078, step time: 0.3938\n",
      "55/224, train_loss: 0.1624, step time: 0.3947\n",
      "56/224, train_loss: 0.1136, step time: 0.3177\n",
      "57/224, train_loss: 0.1703, step time: 0.3891\n",
      "58/224, train_loss: 0.1385, step time: 0.3858\n",
      "59/224, train_loss: 0.1640, step time: 0.3152\n",
      "60/224, train_loss: 0.1558, step time: 0.3890\n",
      "61/224, train_loss: 0.1651, step time: 0.3793\n",
      "62/224, train_loss: 0.0720, step time: 0.3155\n",
      "63/224, train_loss: 0.0867, step time: 0.3158\n",
      "64/224, train_loss: 0.1457, step time: 0.3772\n",
      "65/224, train_loss: 0.1909, step time: 0.3926\n",
      "66/224, train_loss: 0.1397, step time: 0.3153\n",
      "67/224, train_loss: 0.1460, step time: 0.3181\n",
      "68/224, train_loss: 0.1793, step time: 0.4002\n",
      "69/224, train_loss: 0.1110, step time: 0.3763\n",
      "70/224, train_loss: 0.1377, step time: 0.3150\n",
      "71/224, train_loss: 0.0845, step time: 0.3153\n",
      "72/224, train_loss: 0.1092, step time: 0.3159\n",
      "73/224, train_loss: 0.1120, step time: 0.3163\n",
      "74/224, train_loss: 0.1384, step time: 0.3156\n",
      "75/224, train_loss: 0.1652, step time: 0.3785\n",
      "76/224, train_loss: 0.1306, step time: 0.3152\n",
      "77/224, train_loss: 0.1024, step time: 0.3179\n",
      "78/224, train_loss: 0.0840, step time: 0.3788\n",
      "79/224, train_loss: 0.0960, step time: 0.3788\n",
      "80/224, train_loss: 0.0798, step time: 0.3163\n",
      "81/224, train_loss: 0.0987, step time: 0.3161\n",
      "82/224, train_loss: 0.3355, step time: 0.4148\n",
      "83/224, train_loss: 0.1090, step time: 0.3158\n",
      "84/224, train_loss: 0.3494, step time: 0.3187\n",
      "85/224, train_loss: 0.1379, step time: 0.3826\n",
      "86/224, train_loss: 0.0822, step time: 0.3637\n",
      "87/224, train_loss: 0.1207, step time: 0.3179\n",
      "88/224, train_loss: 0.0982, step time: 0.3178\n",
      "89/224, train_loss: 0.1377, step time: 0.3904\n",
      "90/224, train_loss: 0.1027, step time: 0.3158\n",
      "91/224, train_loss: 0.1034, step time: 0.3157\n",
      "92/224, train_loss: 0.1352, step time: 0.3174\n",
      "93/224, train_loss: 0.2153, step time: 0.3155\n",
      "94/224, train_loss: 0.0710, step time: 0.3153\n",
      "95/224, train_loss: 0.1199, step time: 0.3153\n",
      "96/224, train_loss: 0.0511, step time: 0.3139\n",
      "97/224, train_loss: 0.0684, step time: 0.3162\n",
      "98/224, train_loss: 0.1140, step time: 0.3164\n",
      "99/224, train_loss: 0.0832, step time: 0.3183\n",
      "100/224, train_loss: 0.1067, step time: 0.3695\n",
      "101/224, train_loss: 0.0710, step time: 0.3156\n",
      "102/224, train_loss: 0.1269, step time: 0.3131\n",
      "103/224, train_loss: 0.1470, step time: 0.3175\n",
      "104/224, train_loss: 0.0883, step time: 0.3158\n",
      "105/224, train_loss: 0.1218, step time: 0.3164\n",
      "106/224, train_loss: 0.1250, step time: 0.3143\n",
      "107/224, train_loss: 0.1541, step time: 0.3144\n",
      "108/224, train_loss: 0.1394, step time: 0.3150\n",
      "109/224, train_loss: 0.1654, step time: 0.3690\n",
      "110/224, train_loss: 0.1092, step time: 0.4011\n",
      "111/224, train_loss: 0.0890, step time: 0.3142\n",
      "112/224, train_loss: 0.0926, step time: 0.3734\n",
      "113/224, train_loss: 0.1238, step time: 0.3158\n",
      "114/224, train_loss: 0.0931, step time: 0.3981\n",
      "115/224, train_loss: 0.2119, step time: 0.4000\n",
      "116/224, train_loss: 0.1222, step time: 0.3182\n",
      "117/224, train_loss: 0.2314, step time: 0.3184\n",
      "118/224, train_loss: 0.1568, step time: 0.3166\n",
      "119/224, train_loss: 0.0922, step time: 0.3698\n",
      "120/224, train_loss: 0.0540, step time: 0.3180\n",
      "121/224, train_loss: 0.2151, step time: 0.4084\n",
      "122/224, train_loss: 0.0841, step time: 0.3156\n",
      "123/224, train_loss: 0.1659, step time: 0.3670\n",
      "124/224, train_loss: 0.1196, step time: 0.3180\n",
      "125/224, train_loss: 0.1990, step time: 0.3154\n",
      "126/224, train_loss: 0.1773, step time: 0.3131\n",
      "127/224, train_loss: 0.1085, step time: 0.3759\n",
      "128/224, train_loss: 0.0828, step time: 0.3175\n",
      "129/224, train_loss: 0.0972, step time: 0.3838\n",
      "130/224, train_loss: 0.0799, step time: 0.4070\n",
      "131/224, train_loss: 0.1778, step time: 0.3662\n",
      "132/224, train_loss: 0.0766, step time: 0.3179\n",
      "133/224, train_loss: 0.0849, step time: 0.3176\n",
      "134/224, train_loss: 0.1208, step time: 0.3173\n",
      "135/224, train_loss: 0.2000, step time: 0.3151\n",
      "136/224, train_loss: 0.0739, step time: 0.3799\n",
      "137/224, train_loss: 0.1410, step time: 0.3982\n",
      "138/224, train_loss: 0.2133, step time: 0.4107\n",
      "139/224, train_loss: 0.3471, step time: 0.3141\n",
      "140/224, train_loss: 0.1105, step time: 0.3156\n",
      "141/224, train_loss: 0.0935, step time: 0.3883\n",
      "142/224, train_loss: 0.1436, step time: 0.4018\n",
      "143/224, train_loss: 0.1550, step time: 0.3996\n",
      "144/224, train_loss: 0.0817, step time: 0.3149\n",
      "145/224, train_loss: 0.2169, step time: 0.3963\n",
      "146/224, train_loss: 0.1428, step time: 0.3124\n",
      "147/224, train_loss: 0.0829, step time: 0.3141\n",
      "148/224, train_loss: 0.1301, step time: 0.3968\n",
      "149/224, train_loss: 0.1559, step time: 0.3786\n",
      "150/224, train_loss: 0.1197, step time: 0.3872\n",
      "151/224, train_loss: 0.1470, step time: 0.3826\n",
      "152/224, train_loss: 0.0782, step time: 0.3680\n",
      "153/224, train_loss: 0.1021, step time: 0.3128\n",
      "154/224, train_loss: 0.1506, step time: 0.3998\n",
      "155/224, train_loss: 0.1339, step time: 0.3142\n",
      "156/224, train_loss: 0.0679, step time: 0.3125\n",
      "157/224, train_loss: 0.0751, step time: 0.3147\n",
      "158/224, train_loss: 0.1517, step time: 0.3177\n",
      "159/224, train_loss: 0.2108, step time: 0.3132\n",
      "160/224, train_loss: 0.1812, step time: 0.3855\n",
      "161/224, train_loss: 0.1245, step time: 0.3152\n",
      "162/224, train_loss: 0.1376, step time: 0.3871\n",
      "163/224, train_loss: 0.0954, step time: 0.3150\n",
      "164/224, train_loss: 0.1017, step time: 0.4006\n",
      "165/224, train_loss: 0.0827, step time: 0.3157\n",
      "166/224, train_loss: 0.3537, step time: 0.3850\n",
      "167/224, train_loss: 0.1291, step time: 0.3124\n",
      "168/224, train_loss: 0.1858, step time: 0.3147\n",
      "169/224, train_loss: 0.1226, step time: 0.3149\n",
      "170/224, train_loss: 0.0600, step time: 0.3151\n",
      "171/224, train_loss: 0.1112, step time: 0.4105\n",
      "172/224, train_loss: 0.0856, step time: 0.3177\n",
      "173/224, train_loss: 0.0931, step time: 0.3171\n",
      "174/224, train_loss: 0.0859, step time: 0.3147\n",
      "175/224, train_loss: 0.1143, step time: 0.3169\n",
      "176/224, train_loss: 0.1491, step time: 0.4136\n",
      "177/224, train_loss: 0.0867, step time: 0.3159\n",
      "178/224, train_loss: 0.0636, step time: 0.3147\n",
      "179/224, train_loss: 0.2789, step time: 0.3917\n",
      "180/224, train_loss: 0.3681, step time: 0.3134\n",
      "181/224, train_loss: 0.1465, step time: 0.3999\n",
      "182/224, train_loss: 0.3560, step time: 0.3159\n",
      "183/224, train_loss: 0.0742, step time: 0.3132\n",
      "184/224, train_loss: 0.0906, step time: 0.3152\n",
      "185/224, train_loss: 0.1031, step time: 0.3757\n",
      "186/224, train_loss: 0.1033, step time: 0.3658\n",
      "187/224, train_loss: 0.0657, step time: 0.3173\n",
      "188/224, train_loss: 0.1345, step time: 0.3154\n",
      "189/224, train_loss: 0.1350, step time: 0.3843\n",
      "190/224, train_loss: 0.1810, step time: 0.3196\n",
      "191/224, train_loss: 0.0900, step time: 0.3156\n",
      "192/224, train_loss: 0.0743, step time: 0.3154\n",
      "193/224, train_loss: 0.1035, step time: 0.3178\n",
      "194/224, train_loss: 0.0733, step time: 0.3145\n",
      "195/224, train_loss: 0.1166, step time: 0.3146\n",
      "196/224, train_loss: 0.3545, step time: 0.3741\n",
      "197/224, train_loss: 0.1367, step time: 0.4023\n",
      "198/224, train_loss: 0.1515, step time: 0.4039\n",
      "199/224, train_loss: 0.0892, step time: 0.3172\n",
      "200/224, train_loss: 0.0927, step time: 0.3144\n",
      "201/224, train_loss: 0.3233, step time: 0.3992\n",
      "202/224, train_loss: 0.3101, step time: 0.3739\n",
      "203/224, train_loss: 0.0858, step time: 0.3157\n",
      "204/224, train_loss: 0.0426, step time: 0.3707\n",
      "205/224, train_loss: 0.0837, step time: 0.3157\n",
      "206/224, train_loss: 0.0905, step time: 0.3157\n",
      "207/224, train_loss: 0.1185, step time: 0.3160\n",
      "208/224, train_loss: 0.0723, step time: 0.3780\n",
      "209/224, train_loss: 0.0790, step time: 0.3127\n",
      "210/224, train_loss: 0.1257, step time: 0.3616\n",
      "211/224, train_loss: 0.2184, step time: 0.3731\n",
      "212/224, train_loss: 0.2093, step time: 0.3903\n",
      "213/224, train_loss: 0.1492, step time: 0.3963\n",
      "214/224, train_loss: 0.0516, step time: 0.3174\n",
      "215/224, train_loss: 0.1172, step time: 0.3155\n",
      "216/224, train_loss: 0.0900, step time: 0.3157\n",
      "217/224, train_loss: 0.1997, step time: 0.3804\n",
      "218/224, train_loss: 0.1265, step time: 0.3154\n",
      "219/224, train_loss: 0.1110, step time: 0.3170\n",
      "220/224, train_loss: 0.1567, step time: 0.4036\n",
      "221/224, train_loss: 0.1055, step time: 0.3850\n",
      "222/224, train_loss: 0.1459, step time: 0.3173\n",
      "223/224, train_loss: 0.1135, step time: 0.3826\n",
      "224/224, train_loss: 0.1752, step time: 0.3157\n",
      "epoch 61 average loss: 0.1384\n",
      "current epoch: 61 current mean dice: 0.6973 class1: 0.9994 class2: 0.7505 class3: 0.3421\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 61 is: 654.2067\n",
      "hello\n",
      "----------\n",
      "epoch 62/100\n",
      "1/224, train_loss: 0.1907, step time: 0.3884\n",
      "2/224, train_loss: 0.1258, step time: 0.3163\n",
      "3/224, train_loss: 0.1307, step time: 0.3955\n",
      "4/224, train_loss: 0.0732, step time: 0.3790\n",
      "5/224, train_loss: 0.0869, step time: 0.3161\n",
      "6/224, train_loss: 0.1483, step time: 0.3908\n",
      "7/224, train_loss: 0.1439, step time: 0.3171\n",
      "8/224, train_loss: 0.0757, step time: 0.3148\n",
      "9/224, train_loss: 0.2328, step time: 0.4069\n",
      "10/224, train_loss: 0.3100, step time: 0.3153\n",
      "11/224, train_loss: 0.1866, step time: 0.4028\n",
      "12/224, train_loss: 0.0639, step time: 0.3158\n",
      "13/224, train_loss: 0.3230, step time: 0.3695\n",
      "14/224, train_loss: 0.1349, step time: 0.4101\n",
      "15/224, train_loss: 0.1056, step time: 0.4037\n",
      "16/224, train_loss: 0.2949, step time: 0.3690\n",
      "17/224, train_loss: 0.0818, step time: 0.3798\n",
      "18/224, train_loss: 0.0690, step time: 0.3145\n",
      "19/224, train_loss: 0.2184, step time: 0.3774\n",
      "20/224, train_loss: 0.1055, step time: 0.3146\n",
      "21/224, train_loss: 0.1336, step time: 0.3756\n",
      "22/224, train_loss: 0.1301, step time: 0.3151\n",
      "23/224, train_loss: 0.2209, step time: 0.3666\n",
      "24/224, train_loss: 0.1421, step time: 0.3975\n",
      "25/224, train_loss: 0.0789, step time: 0.3148\n",
      "26/224, train_loss: 0.1122, step time: 0.3986\n",
      "27/224, train_loss: 0.2208, step time: 0.4072\n",
      "28/224, train_loss: 0.0812, step time: 0.3927\n",
      "29/224, train_loss: 0.0700, step time: 0.3135\n",
      "30/224, train_loss: 0.1025, step time: 0.3157\n",
      "31/224, train_loss: 0.2908, step time: 0.4048\n",
      "32/224, train_loss: 0.0883, step time: 0.3878\n",
      "33/224, train_loss: 0.1088, step time: 0.3888\n",
      "34/224, train_loss: 0.1352, step time: 0.3740\n",
      "35/224, train_loss: 0.1220, step time: 0.3146\n",
      "36/224, train_loss: 0.1308, step time: 0.3874\n",
      "37/224, train_loss: 0.1073, step time: 0.3169\n",
      "38/224, train_loss: 0.2456, step time: 0.3983\n",
      "39/224, train_loss: 0.2214, step time: 0.3171\n",
      "40/224, train_loss: 0.2510, step time: 0.3987\n",
      "41/224, train_loss: 0.1665, step time: 0.3721\n",
      "42/224, train_loss: 0.0786, step time: 0.3166\n",
      "43/224, train_loss: 0.0852, step time: 0.3148\n",
      "44/224, train_loss: 0.1137, step time: 0.3743\n",
      "45/224, train_loss: 0.0927, step time: 0.3147\n",
      "46/224, train_loss: 0.0778, step time: 0.4101\n",
      "47/224, train_loss: 0.1633, step time: 0.3812\n",
      "48/224, train_loss: 0.0979, step time: 0.3789\n",
      "49/224, train_loss: 0.0792, step time: 0.3737\n",
      "50/224, train_loss: 0.2469, step time: 0.3659\n",
      "51/224, train_loss: 0.1098, step time: 0.4071\n",
      "52/224, train_loss: 0.0713, step time: 0.3144\n",
      "53/224, train_loss: 0.1176, step time: 0.3149\n",
      "54/224, train_loss: 0.0802, step time: 0.3172\n",
      "55/224, train_loss: 0.1239, step time: 0.4050\n",
      "56/224, train_loss: 0.1079, step time: 0.3173\n",
      "57/224, train_loss: 0.2230, step time: 0.3841\n",
      "58/224, train_loss: 0.3219, step time: 0.3698\n",
      "59/224, train_loss: 0.0515, step time: 0.3701\n",
      "60/224, train_loss: 0.1748, step time: 0.3930\n",
      "61/224, train_loss: 0.1255, step time: 0.3668\n",
      "62/224, train_loss: 0.0936, step time: 0.3173\n",
      "63/224, train_loss: 0.2103, step time: 0.3169\n",
      "64/224, train_loss: 0.1467, step time: 0.3932\n",
      "65/224, train_loss: 0.1942, step time: 0.4122\n",
      "66/224, train_loss: 0.1943, step time: 0.3123\n",
      "67/224, train_loss: 0.1470, step time: 0.3806\n",
      "68/224, train_loss: 0.0986, step time: 0.3127\n",
      "69/224, train_loss: 0.1353, step time: 0.3176\n",
      "70/224, train_loss: 0.1605, step time: 0.3661\n",
      "71/224, train_loss: 0.0622, step time: 0.3152\n",
      "72/224, train_loss: 0.1177, step time: 0.3178\n",
      "73/224, train_loss: 0.1847, step time: 0.3130\n",
      "74/224, train_loss: 0.3357, step time: 0.3143\n",
      "75/224, train_loss: 0.0698, step time: 0.3142\n",
      "76/224, train_loss: 0.0786, step time: 0.3753\n",
      "77/224, train_loss: 0.0449, step time: 0.3145\n",
      "78/224, train_loss: 0.1385, step time: 0.3151\n",
      "79/224, train_loss: 0.0905, step time: 0.3918\n",
      "80/224, train_loss: 0.1340, step time: 0.4049\n",
      "81/224, train_loss: 0.2857, step time: 0.3774\n",
      "82/224, train_loss: 0.0632, step time: 0.3146\n",
      "83/224, train_loss: 0.1873, step time: 0.4017\n",
      "84/224, train_loss: 0.1271, step time: 0.3692\n",
      "85/224, train_loss: 0.1306, step time: 0.4013\n",
      "86/224, train_loss: 0.2190, step time: 0.3758\n",
      "87/224, train_loss: 0.2494, step time: 0.3193\n",
      "88/224, train_loss: 0.0739, step time: 0.3193\n",
      "89/224, train_loss: 0.0991, step time: 0.3165\n",
      "90/224, train_loss: 0.1551, step time: 0.3186\n",
      "91/224, train_loss: 0.1164, step time: 0.3154\n",
      "92/224, train_loss: 0.1185, step time: 0.3696\n",
      "93/224, train_loss: 0.0830, step time: 0.3877\n",
      "94/224, train_loss: 0.1280, step time: 0.3180\n",
      "95/224, train_loss: 0.2228, step time: 0.4094\n",
      "96/224, train_loss: 0.1314, step time: 0.3800\n",
      "97/224, train_loss: 0.1157, step time: 0.3187\n",
      "98/224, train_loss: 0.1170, step time: 0.3184\n",
      "99/224, train_loss: 0.0800, step time: 0.3142\n",
      "100/224, train_loss: 0.1944, step time: 0.3163\n",
      "101/224, train_loss: 0.0828, step time: 0.4034\n",
      "102/224, train_loss: 0.0833, step time: 0.3138\n",
      "103/224, train_loss: 0.2211, step time: 0.3943\n",
      "104/224, train_loss: 0.1327, step time: 0.3184\n",
      "105/224, train_loss: 0.1203, step time: 0.4018\n",
      "106/224, train_loss: 0.1704, step time: 0.3837\n",
      "107/224, train_loss: 0.0771, step time: 0.3161\n",
      "108/224, train_loss: 0.1435, step time: 0.3182\n",
      "109/224, train_loss: 0.1386, step time: 0.4008\n",
      "110/224, train_loss: 0.1327, step time: 0.3782\n",
      "111/224, train_loss: 0.0899, step time: 0.3150\n",
      "112/224, train_loss: 0.3767, step time: 0.3982\n",
      "113/224, train_loss: 0.0810, step time: 0.3155\n",
      "114/224, train_loss: 0.1061, step time: 0.3154\n",
      "115/224, train_loss: 0.0883, step time: 0.3154\n",
      "116/224, train_loss: 0.0808, step time: 0.3152\n",
      "117/224, train_loss: 0.2135, step time: 0.3140\n",
      "118/224, train_loss: 0.1391, step time: 0.3185\n",
      "119/224, train_loss: 0.1382, step time: 0.4062\n",
      "120/224, train_loss: 0.3341, step time: 0.3859\n",
      "121/224, train_loss: 0.0660, step time: 0.3169\n",
      "122/224, train_loss: 0.0794, step time: 0.3150\n",
      "123/224, train_loss: 0.0595, step time: 0.3124\n",
      "124/224, train_loss: 0.1433, step time: 0.3145\n",
      "125/224, train_loss: 0.1513, step time: 0.3791\n",
      "126/224, train_loss: 0.1286, step time: 0.3859\n",
      "127/224, train_loss: 0.1945, step time: 0.3167\n",
      "128/224, train_loss: 0.2328, step time: 0.3818\n",
      "129/224, train_loss: 0.0785, step time: 0.3150\n",
      "130/224, train_loss: 0.1958, step time: 0.4025\n",
      "131/224, train_loss: 0.1034, step time: 0.3150\n",
      "132/224, train_loss: 0.2082, step time: 0.3847\n",
      "133/224, train_loss: 0.0736, step time: 0.3156\n",
      "134/224, train_loss: 0.2453, step time: 0.3750\n",
      "135/224, train_loss: 0.1424, step time: 0.3965\n",
      "136/224, train_loss: 0.4403, step time: 0.4099\n",
      "137/224, train_loss: 0.0646, step time: 0.3147\n",
      "138/224, train_loss: 0.0990, step time: 0.3146\n",
      "139/224, train_loss: 0.1242, step time: 0.3172\n",
      "140/224, train_loss: 0.0943, step time: 0.3807\n",
      "141/224, train_loss: 0.0780, step time: 0.3174\n",
      "142/224, train_loss: 0.1871, step time: 0.3864\n",
      "143/224, train_loss: 0.1474, step time: 0.3153\n",
      "144/224, train_loss: 0.0923, step time: 0.3183\n",
      "145/224, train_loss: 0.1084, step time: 0.3173\n",
      "146/224, train_loss: 0.2000, step time: 0.3919\n",
      "147/224, train_loss: 0.3661, step time: 0.3151\n",
      "148/224, train_loss: 0.1950, step time: 0.4019\n",
      "149/224, train_loss: 0.0610, step time: 0.3147\n",
      "150/224, train_loss: 0.1530, step time: 0.3880\n",
      "151/224, train_loss: 0.1323, step time: 0.3706\n",
      "152/224, train_loss: 0.0602, step time: 0.3827\n",
      "153/224, train_loss: 0.3026, step time: 0.3830\n",
      "154/224, train_loss: 0.0911, step time: 0.3188\n",
      "155/224, train_loss: 0.1487, step time: 0.3822\n",
      "156/224, train_loss: 0.1472, step time: 0.3183\n",
      "157/224, train_loss: 0.0928, step time: 0.3193\n",
      "158/224, train_loss: 0.2390, step time: 0.3176\n",
      "159/224, train_loss: 0.1760, step time: 0.3196\n",
      "160/224, train_loss: 0.0440, step time: 0.3710\n",
      "161/224, train_loss: 0.1257, step time: 0.3163\n",
      "162/224, train_loss: 0.0910, step time: 0.3160\n",
      "163/224, train_loss: 0.1003, step time: 0.3164\n",
      "164/224, train_loss: 0.2152, step time: 0.3992\n",
      "165/224, train_loss: 0.0520, step time: 0.3173\n",
      "166/224, train_loss: 0.0930, step time: 0.3200\n",
      "167/224, train_loss: 0.1342, step time: 0.3794\n",
      "168/224, train_loss: 0.0764, step time: 0.3164\n",
      "169/224, train_loss: 0.0874, step time: 0.4123\n",
      "170/224, train_loss: 0.1696, step time: 0.3167\n",
      "171/224, train_loss: 0.2179, step time: 0.3731\n",
      "172/224, train_loss: 0.1365, step time: 0.4069\n",
      "173/224, train_loss: 0.0825, step time: 0.3201\n",
      "174/224, train_loss: 0.1895, step time: 0.3163\n",
      "175/224, train_loss: 0.1249, step time: 0.3171\n",
      "176/224, train_loss: 0.0767, step time: 0.3129\n",
      "177/224, train_loss: 0.1409, step time: 0.3891\n",
      "178/224, train_loss: 0.1039, step time: 0.3150\n",
      "179/224, train_loss: 0.0934, step time: 0.3153\n",
      "180/224, train_loss: 0.0968, step time: 0.3131\n",
      "181/224, train_loss: 0.1482, step time: 0.3151\n",
      "182/224, train_loss: 0.0924, step time: 0.3663\n",
      "183/224, train_loss: 0.1128, step time: 0.3152\n",
      "184/224, train_loss: 0.1036, step time: 0.3767\n",
      "185/224, train_loss: 0.2400, step time: 0.3940\n",
      "186/224, train_loss: 0.0998, step time: 0.3868\n",
      "187/224, train_loss: 0.1488, step time: 0.3184\n",
      "188/224, train_loss: 0.1388, step time: 0.3230\n",
      "189/224, train_loss: 0.0955, step time: 0.3191\n",
      "190/224, train_loss: 0.3452, step time: 0.3653\n",
      "191/224, train_loss: 0.1548, step time: 0.3177\n",
      "192/224, train_loss: 0.1402, step time: 0.3199\n",
      "193/224, train_loss: 0.0990, step time: 0.3824\n",
      "194/224, train_loss: 0.1055, step time: 0.3849\n",
      "195/224, train_loss: 0.1523, step time: 0.3765\n",
      "196/224, train_loss: 0.0886, step time: 0.3168\n",
      "197/224, train_loss: 0.0843, step time: 0.3716\n",
      "198/224, train_loss: 0.0949, step time: 0.3169\n",
      "199/224, train_loss: 0.2092, step time: 0.3869\n",
      "200/224, train_loss: 0.2909, step time: 0.3165\n",
      "201/224, train_loss: 0.4643, step time: 0.3780\n",
      "202/224, train_loss: 0.0860, step time: 0.3769\n",
      "203/224, train_loss: 0.0827, step time: 0.3146\n",
      "204/224, train_loss: 0.1249, step time: 0.3173\n",
      "205/224, train_loss: 0.0966, step time: 0.3175\n",
      "206/224, train_loss: 0.1087, step time: 0.3730\n",
      "207/224, train_loss: 0.1167, step time: 0.3185\n",
      "208/224, train_loss: 0.1000, step time: 0.3199\n",
      "209/224, train_loss: 0.1299, step time: 0.3193\n",
      "210/224, train_loss: 0.1044, step time: 0.3189\n",
      "211/224, train_loss: 0.2976, step time: 0.3893\n",
      "212/224, train_loss: 0.1084, step time: 0.3740\n",
      "213/224, train_loss: 0.2116, step time: 0.3203\n",
      "214/224, train_loss: 0.1555, step time: 0.4118\n",
      "215/224, train_loss: 0.0802, step time: 0.3187\n",
      "216/224, train_loss: 0.1015, step time: 0.3680\n",
      "217/224, train_loss: 0.2226, step time: 0.3692\n",
      "218/224, train_loss: 0.1097, step time: 0.3172\n",
      "219/224, train_loss: 0.1337, step time: 0.3180\n",
      "220/224, train_loss: 0.1124, step time: 0.3195\n",
      "221/224, train_loss: 0.3317, step time: 0.3820\n",
      "222/224, train_loss: 0.0748, step time: 0.3169\n",
      "223/224, train_loss: 0.0729, step time: 0.3718\n",
      "224/224, train_loss: 0.1004, step time: 0.3689\n",
      "epoch 62 average loss: 0.1434\n",
      "current epoch: 62 current mean dice: 0.7071 class1: 0.9993 class2: 0.7377 class3: 0.3843\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 62 is: 750.7295\n",
      "hello\n",
      "----------\n",
      "epoch 63/100\n",
      "1/224, train_loss: 0.0490, step time: 0.3170\n",
      "2/224, train_loss: 0.0904, step time: 0.3202\n",
      "3/224, train_loss: 0.3073, step time: 0.4044\n",
      "4/224, train_loss: 0.3104, step time: 0.3861\n",
      "5/224, train_loss: 0.0983, step time: 0.3809\n",
      "6/224, train_loss: 0.1195, step time: 0.3167\n",
      "7/224, train_loss: 0.1490, step time: 0.4000\n",
      "8/224, train_loss: 0.4121, step time: 0.3802\n",
      "9/224, train_loss: 0.0970, step time: 0.3142\n",
      "10/224, train_loss: 0.2658, step time: 0.4051\n",
      "11/224, train_loss: 0.1601, step time: 0.3189\n",
      "12/224, train_loss: 0.2247, step time: 0.3159\n",
      "13/224, train_loss: 0.1173, step time: 0.3162\n",
      "14/224, train_loss: 0.0824, step time: 0.3164\n",
      "15/224, train_loss: 0.0816, step time: 0.3684\n",
      "16/224, train_loss: 0.0933, step time: 0.3166\n",
      "17/224, train_loss: 0.1547, step time: 0.3952\n",
      "18/224, train_loss: 0.1746, step time: 0.3165\n",
      "19/224, train_loss: 0.2886, step time: 0.4116\n",
      "20/224, train_loss: 0.1272, step time: 0.4063\n",
      "21/224, train_loss: 0.0935, step time: 0.3162\n",
      "22/224, train_loss: 0.1320, step time: 0.3161\n",
      "23/224, train_loss: 0.0896, step time: 0.3188\n",
      "24/224, train_loss: 0.0847, step time: 0.3922\n",
      "25/224, train_loss: 0.2306, step time: 0.3946\n",
      "26/224, train_loss: 0.0771, step time: 0.3160\n",
      "27/224, train_loss: 0.1890, step time: 0.3890\n",
      "28/224, train_loss: 0.1322, step time: 0.3172\n",
      "29/224, train_loss: 0.0870, step time: 0.3144\n",
      "30/224, train_loss: 0.1058, step time: 0.3163\n",
      "31/224, train_loss: 0.0905, step time: 0.3197\n",
      "32/224, train_loss: 0.1047, step time: 0.3171\n",
      "33/224, train_loss: 0.0851, step time: 0.3688\n",
      "34/224, train_loss: 0.0649, step time: 0.4033\n",
      "35/224, train_loss: 0.0936, step time: 0.4051\n",
      "36/224, train_loss: 0.1323, step time: 0.3845\n",
      "37/224, train_loss: 0.1307, step time: 0.4098\n",
      "38/224, train_loss: 0.0738, step time: 0.3151\n",
      "39/224, train_loss: 0.1287, step time: 0.3710\n",
      "40/224, train_loss: 0.0808, step time: 0.3167\n",
      "41/224, train_loss: 0.0922, step time: 0.3141\n",
      "42/224, train_loss: 0.0633, step time: 0.3170\n",
      "43/224, train_loss: 0.2337, step time: 0.3197\n",
      "44/224, train_loss: 0.0768, step time: 0.4002\n",
      "45/224, train_loss: 0.1049, step time: 0.3856\n",
      "46/224, train_loss: 0.1678, step time: 0.4085\n",
      "47/224, train_loss: 0.1459, step time: 0.4062\n",
      "48/224, train_loss: 0.0859, step time: 0.3169\n",
      "49/224, train_loss: 0.0816, step time: 0.4042\n",
      "50/224, train_loss: 0.0682, step time: 0.3967\n",
      "51/224, train_loss: 0.1413, step time: 0.3709\n",
      "52/224, train_loss: 0.0822, step time: 0.3895\n",
      "53/224, train_loss: 0.3394, step time: 0.3969\n",
      "54/224, train_loss: 0.3591, step time: 0.4116\n",
      "55/224, train_loss: 0.0816, step time: 0.3163\n",
      "56/224, train_loss: 0.1231, step time: 0.3917\n",
      "57/224, train_loss: 0.0539, step time: 0.3140\n",
      "58/224, train_loss: 0.1344, step time: 0.4067\n",
      "59/224, train_loss: 0.2747, step time: 0.3887\n",
      "60/224, train_loss: 0.2372, step time: 0.3815\n",
      "61/224, train_loss: 0.2444, step time: 0.3892\n",
      "62/224, train_loss: 0.2604, step time: 0.3163\n",
      "63/224, train_loss: 0.1270, step time: 0.3768\n",
      "64/224, train_loss: 0.1957, step time: 0.3872\n",
      "65/224, train_loss: 0.0871, step time: 0.3194\n",
      "66/224, train_loss: 0.1478, step time: 0.3709\n",
      "67/224, train_loss: 0.1470, step time: 0.4041\n",
      "68/224, train_loss: 0.1586, step time: 0.3160\n",
      "69/224, train_loss: 0.0803, step time: 0.3158\n",
      "70/224, train_loss: 0.1638, step time: 0.3816\n",
      "71/224, train_loss: 0.1268, step time: 0.3163\n",
      "72/224, train_loss: 0.0868, step time: 0.3161\n",
      "73/224, train_loss: 0.2117, step time: 0.3758\n",
      "74/224, train_loss: 0.1229, step time: 0.3158\n",
      "75/224, train_loss: 0.2105, step time: 0.3961\n",
      "76/224, train_loss: 0.1089, step time: 0.3168\n",
      "77/224, train_loss: 0.2833, step time: 0.3921\n",
      "78/224, train_loss: 0.3569, step time: 0.3162\n",
      "79/224, train_loss: 0.3711, step time: 0.3812\n",
      "80/224, train_loss: 0.2099, step time: 0.4053\n",
      "81/224, train_loss: 0.1768, step time: 0.3187\n",
      "82/224, train_loss: 0.2313, step time: 0.4090\n",
      "83/224, train_loss: 0.0616, step time: 0.3183\n",
      "84/224, train_loss: 0.1226, step time: 0.4008\n",
      "85/224, train_loss: 0.1341, step time: 0.3700\n",
      "86/224, train_loss: 0.2061, step time: 0.3179\n",
      "87/224, train_loss: 0.3471, step time: 0.4003\n",
      "88/224, train_loss: 0.0585, step time: 0.3835\n",
      "89/224, train_loss: 0.0786, step time: 0.3168\n",
      "90/224, train_loss: 0.2226, step time: 0.3158\n",
      "91/224, train_loss: 0.2301, step time: 0.3207\n",
      "92/224, train_loss: 0.1086, step time: 0.4091\n",
      "93/224, train_loss: 0.0792, step time: 0.3972\n",
      "94/224, train_loss: 0.0643, step time: 0.3192\n",
      "95/224, train_loss: 0.1324, step time: 0.3996\n",
      "96/224, train_loss: 0.0835, step time: 0.3178\n",
      "97/224, train_loss: 0.0759, step time: 0.3182\n",
      "98/224, train_loss: 0.1346, step time: 0.3721\n",
      "99/224, train_loss: 0.0882, step time: 0.3998\n",
      "100/224, train_loss: 0.0860, step time: 0.3164\n",
      "101/224, train_loss: 0.0860, step time: 0.3188\n",
      "102/224, train_loss: 0.0895, step time: 0.3156\n",
      "103/224, train_loss: 0.0913, step time: 0.3789\n",
      "104/224, train_loss: 0.0754, step time: 0.3161\n",
      "105/224, train_loss: 0.1394, step time: 0.3955\n",
      "106/224, train_loss: 0.0685, step time: 0.3840\n",
      "107/224, train_loss: 0.3339, step time: 0.3980\n",
      "108/224, train_loss: 0.2912, step time: 0.4089\n",
      "109/224, train_loss: 0.1502, step time: 0.3151\n",
      "110/224, train_loss: 0.1535, step time: 0.3634\n",
      "111/224, train_loss: 0.2543, step time: 0.3693\n",
      "112/224, train_loss: 0.1019, step time: 0.3911\n",
      "113/224, train_loss: 0.2531, step time: 0.3725\n",
      "114/224, train_loss: 0.1536, step time: 0.3155\n",
      "115/224, train_loss: 0.0975, step time: 0.3157\n",
      "116/224, train_loss: 0.0961, step time: 0.3154\n",
      "117/224, train_loss: 0.0644, step time: 0.3153\n",
      "118/224, train_loss: 0.1584, step time: 0.3766\n",
      "119/224, train_loss: 0.1630, step time: 0.3977\n",
      "120/224, train_loss: 0.0889, step time: 0.3152\n",
      "121/224, train_loss: 0.0842, step time: 0.3694\n",
      "122/224, train_loss: 0.1574, step time: 0.3790\n",
      "123/224, train_loss: 0.0826, step time: 0.3762\n",
      "124/224, train_loss: 0.1286, step time: 0.3908\n",
      "125/224, train_loss: 0.0630, step time: 0.3150\n",
      "126/224, train_loss: 0.2413, step time: 0.3155\n",
      "127/224, train_loss: 0.1402, step time: 0.3153\n",
      "128/224, train_loss: 0.0799, step time: 0.3692\n",
      "129/224, train_loss: 0.1805, step time: 0.4032\n",
      "130/224, train_loss: 0.1989, step time: 0.3134\n",
      "131/224, train_loss: 0.0770, step time: 0.3715\n",
      "132/224, train_loss: 0.1208, step time: 0.3649\n",
      "133/224, train_loss: 0.2259, step time: 0.3651\n",
      "134/224, train_loss: 0.1002, step time: 0.3736\n",
      "135/224, train_loss: 0.0418, step time: 0.3209\n",
      "136/224, train_loss: 0.2663, step time: 0.4113\n",
      "137/224, train_loss: 0.1257, step time: 0.3979\n",
      "138/224, train_loss: 0.0825, step time: 0.3835\n",
      "139/224, train_loss: 0.0931, step time: 0.3892\n",
      "140/224, train_loss: 0.1066, step time: 0.3184\n",
      "141/224, train_loss: 0.0782, step time: 0.3725\n",
      "142/224, train_loss: 0.4143, step time: 0.3746\n",
      "143/224, train_loss: 0.0996, step time: 0.3192\n",
      "144/224, train_loss: 0.0847, step time: 0.3159\n",
      "145/224, train_loss: 0.0823, step time: 0.3205\n",
      "146/224, train_loss: 0.0952, step time: 0.3205\n",
      "147/224, train_loss: 0.1174, step time: 0.3183\n",
      "148/224, train_loss: 0.3210, step time: 0.3186\n",
      "149/224, train_loss: 0.1342, step time: 0.3178\n",
      "150/224, train_loss: 0.0796, step time: 0.3176\n",
      "151/224, train_loss: 0.0821, step time: 0.3182\n",
      "152/224, train_loss: 0.0538, step time: 0.3209\n",
      "153/224, train_loss: 0.2103, step time: 0.4018\n",
      "154/224, train_loss: 0.1738, step time: 0.4038\n",
      "155/224, train_loss: 0.1519, step time: 0.3923\n",
      "156/224, train_loss: 0.1687, step time: 0.3161\n",
      "157/224, train_loss: 0.0535, step time: 0.3146\n",
      "158/224, train_loss: 0.2796, step time: 0.3714\n",
      "159/224, train_loss: 0.1295, step time: 0.3127\n",
      "160/224, train_loss: 0.2148, step time: 0.3144\n",
      "161/224, train_loss: 0.0931, step time: 0.3662\n",
      "162/224, train_loss: 0.1364, step time: 0.3143\n",
      "163/224, train_loss: 0.1218, step time: 0.3126\n",
      "164/224, train_loss: 0.0608, step time: 0.3125\n",
      "165/224, train_loss: 0.0917, step time: 0.3778\n",
      "166/224, train_loss: 0.3502, step time: 0.3900\n",
      "167/224, train_loss: 0.2205, step time: 0.3128\n",
      "168/224, train_loss: 0.2192, step time: 0.4139\n",
      "169/224, train_loss: 0.1426, step time: 0.3191\n",
      "170/224, train_loss: 0.2298, step time: 0.3204\n",
      "171/224, train_loss: 0.0989, step time: 0.4088\n",
      "172/224, train_loss: 0.0976, step time: 0.4026\n",
      "173/224, train_loss: 0.0785, step time: 0.3155\n",
      "174/224, train_loss: 0.0932, step time: 0.4142\n",
      "175/224, train_loss: 0.0844, step time: 0.3166\n",
      "176/224, train_loss: 0.0838, step time: 0.3166\n",
      "177/224, train_loss: 0.0960, step time: 0.3195\n",
      "178/224, train_loss: 0.1243, step time: 0.3167\n",
      "179/224, train_loss: 0.1339, step time: 0.3142\n",
      "180/224, train_loss: 0.1531, step time: 0.3181\n",
      "181/224, train_loss: 0.1338, step time: 0.3182\n",
      "182/224, train_loss: 0.0797, step time: 0.3178\n",
      "183/224, train_loss: 0.1977, step time: 0.4000\n",
      "184/224, train_loss: 0.1401, step time: 0.3902\n",
      "185/224, train_loss: 0.1989, step time: 0.3791\n",
      "186/224, train_loss: 0.0849, step time: 0.3183\n",
      "187/224, train_loss: 0.1215, step time: 0.3904\n",
      "188/224, train_loss: 0.1085, step time: 0.3168\n",
      "189/224, train_loss: 0.1227, step time: 0.3687\n",
      "190/224, train_loss: 0.2852, step time: 0.3903\n",
      "191/224, train_loss: 0.0674, step time: 0.3171\n",
      "192/224, train_loss: 0.1164, step time: 0.3920\n",
      "193/224, train_loss: 0.1418, step time: 0.4101\n",
      "194/224, train_loss: 0.0807, step time: 0.3169\n",
      "195/224, train_loss: 0.1880, step time: 0.3872\n",
      "196/224, train_loss: 0.1044, step time: 0.3159\n",
      "197/224, train_loss: 0.2142, step time: 0.3744\n",
      "198/224, train_loss: 0.0734, step time: 0.4043\n",
      "199/224, train_loss: 0.0738, step time: 0.3160\n",
      "200/224, train_loss: 0.1128, step time: 0.3169\n",
      "201/224, train_loss: 0.0997, step time: 0.3165\n",
      "202/224, train_loss: 0.2659, step time: 0.3860\n",
      "203/224, train_loss: 0.3819, step time: 0.4110\n",
      "204/224, train_loss: 0.1103, step time: 0.3900\n",
      "205/224, train_loss: 0.1198, step time: 0.3184\n",
      "206/224, train_loss: 0.2087, step time: 0.3137\n",
      "207/224, train_loss: 0.1279, step time: 0.3834\n",
      "208/224, train_loss: 0.0615, step time: 0.4088\n",
      "209/224, train_loss: 0.0656, step time: 0.3162\n",
      "210/224, train_loss: 0.1083, step time: 0.3154\n",
      "211/224, train_loss: 0.3408, step time: 0.3960\n",
      "212/224, train_loss: 0.3217, step time: 0.3857\n",
      "213/224, train_loss: 0.0842, step time: 0.4082\n",
      "214/224, train_loss: 0.1776, step time: 0.3853\n",
      "215/224, train_loss: 0.0706, step time: 0.3162\n",
      "216/224, train_loss: 0.1599, step time: 0.3895\n",
      "217/224, train_loss: 0.1535, step time: 0.3881\n",
      "218/224, train_loss: 0.1232, step time: 0.3147\n",
      "219/224, train_loss: 0.0891, step time: 0.3168\n",
      "220/224, train_loss: 0.2239, step time: 0.4051\n",
      "221/224, train_loss: 0.0950, step time: 0.3987\n",
      "222/224, train_loss: 0.3310, step time: 0.4087\n",
      "223/224, train_loss: 0.0838, step time: 0.3155\n",
      "224/224, train_loss: 0.0812, step time: 0.3176\n",
      "epoch 63 average loss: 0.1462\n",
      "current epoch: 63 current mean dice: 0.7105 class1: 0.9993 class2: 0.7383 class3: 0.3938\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 63 is: 776.8209\n",
      "hello\n",
      "----------\n",
      "epoch 64/100\n",
      "1/224, train_loss: 0.1020, step time: 0.3159\n",
      "2/224, train_loss: 0.2583, step time: 0.3182\n",
      "3/224, train_loss: 0.1116, step time: 0.3132\n",
      "4/224, train_loss: 0.0611, step time: 0.3152\n",
      "5/224, train_loss: 0.1088, step time: 0.4107\n",
      "6/224, train_loss: 0.0716, step time: 0.3150\n",
      "7/224, train_loss: 0.0759, step time: 0.3174\n",
      "8/224, train_loss: 0.1233, step time: 0.3842\n",
      "9/224, train_loss: 0.0937, step time: 0.3654\n",
      "10/224, train_loss: 0.1217, step time: 0.3976\n",
      "11/224, train_loss: 0.3680, step time: 0.3987\n",
      "12/224, train_loss: 0.1453, step time: 0.4067\n",
      "13/224, train_loss: 0.3406, step time: 0.3176\n",
      "14/224, train_loss: 0.1067, step time: 0.3719\n",
      "15/224, train_loss: 0.1922, step time: 0.3792\n",
      "16/224, train_loss: 0.0901, step time: 0.3851\n",
      "17/224, train_loss: 0.1248, step time: 0.4064\n",
      "18/224, train_loss: 0.1103, step time: 0.3129\n",
      "19/224, train_loss: 0.1263, step time: 0.3139\n",
      "20/224, train_loss: 0.1089, step time: 0.4085\n",
      "21/224, train_loss: 0.1061, step time: 0.3171\n",
      "22/224, train_loss: 0.0963, step time: 0.3125\n",
      "23/224, train_loss: 0.0821, step time: 0.3151\n",
      "24/224, train_loss: 0.1028, step time: 0.3794\n",
      "25/224, train_loss: 0.2566, step time: 0.3662\n",
      "26/224, train_loss: 0.0942, step time: 0.3832\n",
      "27/224, train_loss: 0.1455, step time: 0.3879\n",
      "28/224, train_loss: 0.1306, step time: 0.4048\n",
      "29/224, train_loss: 0.2421, step time: 0.3852\n",
      "30/224, train_loss: 0.0684, step time: 0.3129\n",
      "31/224, train_loss: 0.1120, step time: 0.3151\n",
      "32/224, train_loss: 0.3151, step time: 0.4039\n",
      "33/224, train_loss: 0.0967, step time: 0.3161\n",
      "34/224, train_loss: 0.0665, step time: 0.3745\n",
      "35/224, train_loss: 0.1807, step time: 0.3157\n",
      "36/224, train_loss: 0.2228, step time: 0.3967\n",
      "37/224, train_loss: 0.2968, step time: 0.3663\n",
      "38/224, train_loss: 0.1562, step time: 0.3896\n",
      "39/224, train_loss: 0.1730, step time: 0.3806\n",
      "40/224, train_loss: 0.0433, step time: 0.3921\n",
      "41/224, train_loss: 0.1991, step time: 0.3154\n",
      "42/224, train_loss: 0.3515, step time: 0.3985\n",
      "43/224, train_loss: 0.1527, step time: 0.3155\n",
      "44/224, train_loss: 0.1713, step time: 0.3157\n",
      "45/224, train_loss: 0.2238, step time: 0.3802\n",
      "46/224, train_loss: 0.1356, step time: 0.3149\n",
      "47/224, train_loss: 0.2337, step time: 0.3780\n",
      "48/224, train_loss: 0.4075, step time: 0.3917\n",
      "49/224, train_loss: 0.2084, step time: 0.3124\n",
      "50/224, train_loss: 0.2414, step time: 0.3772\n",
      "51/224, train_loss: 0.0924, step time: 0.3962\n",
      "52/224, train_loss: 0.1216, step time: 0.3674\n",
      "53/224, train_loss: 0.2174, step time: 0.4064\n",
      "54/224, train_loss: 0.2111, step time: 0.3149\n",
      "55/224, train_loss: 0.3470, step time: 0.3982\n",
      "56/224, train_loss: 0.0947, step time: 0.3149\n",
      "57/224, train_loss: 0.0722, step time: 0.3149\n",
      "58/224, train_loss: 0.1210, step time: 0.3158\n",
      "59/224, train_loss: 0.1429, step time: 0.4087\n",
      "60/224, train_loss: 0.2020, step time: 0.3801\n",
      "61/224, train_loss: 0.1031, step time: 0.3165\n",
      "62/224, train_loss: 0.1258, step time: 0.3841\n",
      "63/224, train_loss: 0.1457, step time: 0.3731\n",
      "64/224, train_loss: 0.0771, step time: 0.3641\n",
      "65/224, train_loss: 0.0650, step time: 0.4128\n",
      "66/224, train_loss: 0.0719, step time: 0.3130\n",
      "67/224, train_loss: 0.1228, step time: 0.3171\n",
      "68/224, train_loss: 0.0899, step time: 0.3147\n",
      "69/224, train_loss: 0.0947, step time: 0.3153\n",
      "70/224, train_loss: 0.0969, step time: 0.3159\n",
      "71/224, train_loss: 0.0562, step time: 0.3176\n",
      "72/224, train_loss: 0.2392, step time: 0.3989\n",
      "73/224, train_loss: 0.0815, step time: 0.4113\n",
      "74/224, train_loss: 0.1366, step time: 0.3919\n",
      "75/224, train_loss: 0.2611, step time: 0.3795\n",
      "76/224, train_loss: 0.1026, step time: 0.3191\n",
      "77/224, train_loss: 0.1344, step time: 0.3153\n",
      "78/224, train_loss: 0.1003, step time: 0.5427\n",
      "79/224, train_loss: 0.1979, step time: 0.3986\n",
      "80/224, train_loss: 0.0467, step time: 0.3146\n",
      "81/224, train_loss: 0.1537, step time: 0.3176\n",
      "82/224, train_loss: 0.1565, step time: 0.3667\n",
      "83/224, train_loss: 0.2139, step time: 0.3154\n",
      "84/224, train_loss: 0.0722, step time: 0.4077\n",
      "85/224, train_loss: 0.1390, step time: 0.3731\n",
      "86/224, train_loss: 0.0918, step time: 0.3144\n",
      "87/224, train_loss: 0.1664, step time: 0.3150\n",
      "88/224, train_loss: 0.1458, step time: 0.3794\n",
      "89/224, train_loss: 0.0726, step time: 0.3712\n",
      "90/224, train_loss: 0.0821, step time: 0.3864\n",
      "91/224, train_loss: 0.1454, step time: 0.3787\n",
      "92/224, train_loss: 0.0920, step time: 0.3169\n",
      "93/224, train_loss: 0.0868, step time: 0.3151\n",
      "94/224, train_loss: 0.1208, step time: 0.3881\n",
      "95/224, train_loss: 0.3640, step time: 0.3916\n",
      "96/224, train_loss: 0.1027, step time: 0.3152\n",
      "97/224, train_loss: 0.1150, step time: 0.4130\n",
      "98/224, train_loss: 0.1342, step time: 0.3153\n",
      "99/224, train_loss: 0.3528, step time: 0.3698\n",
      "100/224, train_loss: 0.1702, step time: 0.3712\n",
      "101/224, train_loss: 0.1262, step time: 0.3968\n",
      "102/224, train_loss: 0.0995, step time: 0.3173\n",
      "103/224, train_loss: 0.1637, step time: 0.3994\n",
      "104/224, train_loss: 0.0862, step time: 0.3146\n",
      "105/224, train_loss: 0.1364, step time: 0.3651\n",
      "106/224, train_loss: 0.2915, step time: 0.3860\n",
      "107/224, train_loss: 0.0880, step time: 0.3148\n",
      "108/224, train_loss: 0.1603, step time: 0.3877\n",
      "109/224, train_loss: 0.1947, step time: 0.3171\n",
      "110/224, train_loss: 0.1210, step time: 0.3702\n",
      "111/224, train_loss: 0.1927, step time: 0.3696\n",
      "112/224, train_loss: 0.1385, step time: 0.3821\n",
      "113/224, train_loss: 0.0933, step time: 0.3170\n",
      "114/224, train_loss: 0.2993, step time: 0.3682\n",
      "115/224, train_loss: 0.0441, step time: 0.3150\n",
      "116/224, train_loss: 0.1258, step time: 0.3826\n",
      "117/224, train_loss: 0.1517, step time: 0.3805\n",
      "118/224, train_loss: 0.1755, step time: 0.3146\n",
      "119/224, train_loss: 0.0709, step time: 0.3144\n",
      "120/224, train_loss: 0.1571, step time: 0.3818\n",
      "121/224, train_loss: 0.1174, step time: 0.3152\n",
      "122/224, train_loss: 0.1882, step time: 0.3895\n",
      "123/224, train_loss: 0.1612, step time: 0.3132\n",
      "124/224, train_loss: 0.0792, step time: 0.3771\n",
      "125/224, train_loss: 0.3294, step time: 0.3839\n",
      "126/224, train_loss: 0.0776, step time: 0.3133\n",
      "127/224, train_loss: 0.0785, step time: 0.3785\n",
      "128/224, train_loss: 0.1355, step time: 0.3729\n",
      "129/224, train_loss: 0.1976, step time: 0.3887\n",
      "130/224, train_loss: 0.1738, step time: 0.3137\n",
      "131/224, train_loss: 0.1420, step time: 0.3805\n",
      "132/224, train_loss: 0.1168, step time: 0.3959\n",
      "133/224, train_loss: 0.1000, step time: 0.3941\n",
      "134/224, train_loss: 0.1680, step time: 0.4049\n",
      "135/224, train_loss: 0.0944, step time: 0.3796\n",
      "136/224, train_loss: 0.0720, step time: 0.3922\n",
      "137/224, train_loss: 0.1234, step time: 0.3937\n",
      "138/224, train_loss: 0.1298, step time: 0.3147\n",
      "139/224, train_loss: 0.0927, step time: 0.3738\n",
      "140/224, train_loss: 0.0690, step time: 0.3796\n",
      "141/224, train_loss: 0.3337, step time: 0.3766\n",
      "142/224, train_loss: 0.1927, step time: 0.3630\n",
      "143/224, train_loss: 0.1337, step time: 0.3176\n",
      "144/224, train_loss: 0.0922, step time: 0.3904\n",
      "145/224, train_loss: 0.0956, step time: 0.3148\n",
      "146/224, train_loss: 0.3649, step time: 0.3155\n",
      "147/224, train_loss: 0.1037, step time: 0.3742\n",
      "148/224, train_loss: 0.3001, step time: 0.3149\n",
      "149/224, train_loss: 0.0890, step time: 0.3153\n",
      "150/224, train_loss: 0.0743, step time: 0.3177\n",
      "151/224, train_loss: 0.0727, step time: 0.3176\n",
      "152/224, train_loss: 0.0784, step time: 0.3153\n",
      "153/224, train_loss: 0.1596, step time: 0.3182\n",
      "154/224, train_loss: 0.2109, step time: 0.4012\n",
      "155/224, train_loss: 0.1026, step time: 0.3129\n",
      "156/224, train_loss: 0.0830, step time: 0.3149\n",
      "157/224, train_loss: 0.1020, step time: 0.3801\n",
      "158/224, train_loss: 0.0830, step time: 0.4123\n",
      "159/224, train_loss: 0.1138, step time: 0.3128\n",
      "160/224, train_loss: 0.0735, step time: 0.3150\n",
      "161/224, train_loss: 0.1136, step time: 0.3125\n",
      "162/224, train_loss: 0.1065, step time: 0.3124\n",
      "163/224, train_loss: 0.0937, step time: 0.3741\n",
      "164/224, train_loss: 0.1292, step time: 0.3926\n",
      "165/224, train_loss: 0.1392, step time: 0.3153\n",
      "166/224, train_loss: 0.1877, step time: 0.3969\n",
      "167/224, train_loss: 0.1045, step time: 0.3170\n",
      "168/224, train_loss: 0.2126, step time: 0.4073\n",
      "169/224, train_loss: 0.1395, step time: 0.3151\n",
      "170/224, train_loss: 0.0815, step time: 0.3146\n",
      "171/224, train_loss: 0.1138, step time: 0.3739\n",
      "172/224, train_loss: 0.1278, step time: 0.3800\n",
      "173/224, train_loss: 0.0940, step time: 0.3157\n",
      "174/224, train_loss: 0.1451, step time: 0.3132\n",
      "175/224, train_loss: 0.1457, step time: 0.3148\n",
      "176/224, train_loss: 0.1055, step time: 0.3154\n",
      "177/224, train_loss: 0.1401, step time: 0.3152\n",
      "178/224, train_loss: 0.1055, step time: 0.3150\n",
      "179/224, train_loss: 0.0761, step time: 0.3742\n",
      "180/224, train_loss: 0.0897, step time: 0.3807\n",
      "181/224, train_loss: 0.1578, step time: 0.3772\n",
      "182/224, train_loss: 0.0790, step time: 0.3731\n",
      "183/224, train_loss: 0.0794, step time: 0.3167\n",
      "184/224, train_loss: 0.1545, step time: 0.3852\n",
      "185/224, train_loss: 0.2169, step time: 0.3763\n",
      "186/224, train_loss: 0.1656, step time: 0.3176\n",
      "187/224, train_loss: 0.0495, step time: 0.3130\n",
      "188/224, train_loss: 0.1118, step time: 0.3896\n",
      "189/224, train_loss: 0.0923, step time: 0.3144\n",
      "190/224, train_loss: 0.1341, step time: 0.3148\n",
      "191/224, train_loss: 0.1174, step time: 0.3179\n",
      "192/224, train_loss: 0.1424, step time: 0.4092\n",
      "193/224, train_loss: 0.1523, step time: 0.3147\n",
      "194/224, train_loss: 0.1652, step time: 0.3175\n",
      "195/224, train_loss: 0.1212, step time: 0.3180\n",
      "196/224, train_loss: 0.1464, step time: 0.4025\n",
      "197/224, train_loss: 0.0989, step time: 0.3173\n",
      "198/224, train_loss: 0.1389, step time: 0.3178\n",
      "199/224, train_loss: 0.0680, step time: 0.3152\n",
      "200/224, train_loss: 0.1019, step time: 0.3955\n",
      "201/224, train_loss: 0.0971, step time: 0.3935\n",
      "202/224, train_loss: 0.0687, step time: 0.3145\n",
      "203/224, train_loss: 0.1351, step time: 0.3204\n",
      "204/224, train_loss: 0.1017, step time: 0.3778\n",
      "205/224, train_loss: 0.1262, step time: 0.3903\n",
      "206/224, train_loss: 0.0999, step time: 0.3196\n",
      "207/224, train_loss: 0.1855, step time: 0.3971\n",
      "208/224, train_loss: 0.0793, step time: 0.3177\n",
      "209/224, train_loss: 0.3284, step time: 0.3982\n",
      "210/224, train_loss: 0.1027, step time: 0.3708\n",
      "211/224, train_loss: 0.1421, step time: 0.3982\n",
      "212/224, train_loss: 0.2647, step time: 0.4018\n",
      "213/224, train_loss: 0.1429, step time: 0.4118\n",
      "214/224, train_loss: 0.1561, step time: 0.3727\n",
      "215/224, train_loss: 0.1372, step time: 0.3160\n",
      "216/224, train_loss: 0.1500, step time: 0.3180\n",
      "217/224, train_loss: 0.0801, step time: 0.3177\n",
      "218/224, train_loss: 0.0885, step time: 0.3931\n",
      "219/224, train_loss: 0.2156, step time: 0.4007\n",
      "220/224, train_loss: 0.1165, step time: 0.3184\n",
      "221/224, train_loss: 0.1314, step time: 0.3167\n",
      "222/224, train_loss: 0.1396, step time: 0.3155\n",
      "223/224, train_loss: 0.0784, step time: 0.3151\n",
      "224/224, train_loss: 0.0762, step time: 0.3785\n",
      "epoch 64 average loss: 0.1416\n",
      "current epoch: 64 current mean dice: 0.7093 class1: 0.9993 class2: 0.7442 class3: 0.3843\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 64 is: 762.9517\n",
      "hello\n",
      "----------\n",
      "epoch 65/100\n",
      "1/224, train_loss: 0.1262, step time: 0.3935\n",
      "2/224, train_loss: 0.0633, step time: 0.4113\n",
      "3/224, train_loss: 0.1036, step time: 0.3144\n",
      "4/224, train_loss: 0.1047, step time: 0.3156\n",
      "5/224, train_loss: 0.0951, step time: 0.4115\n",
      "6/224, train_loss: 0.3050, step time: 0.4114\n",
      "7/224, train_loss: 0.1467, step time: 0.3155\n",
      "8/224, train_loss: 0.1804, step time: 0.3859\n",
      "9/224, train_loss: 0.0926, step time: 0.3157\n",
      "10/224, train_loss: 0.1541, step time: 0.3945\n",
      "11/224, train_loss: 0.0655, step time: 0.3156\n",
      "12/224, train_loss: 0.0991, step time: 0.3138\n",
      "13/224, train_loss: 0.1269, step time: 0.3704\n",
      "14/224, train_loss: 0.1513, step time: 0.4077\n",
      "15/224, train_loss: 0.0742, step time: 0.3154\n",
      "16/224, train_loss: 0.1096, step time: 0.3153\n",
      "17/224, train_loss: 0.0666, step time: 0.3174\n",
      "18/224, train_loss: 0.1162, step time: 0.4034\n",
      "19/224, train_loss: 0.1242, step time: 0.4057\n",
      "20/224, train_loss: 0.0860, step time: 0.3144\n",
      "21/224, train_loss: 0.1740, step time: 0.3175\n",
      "22/224, train_loss: 0.1736, step time: 0.3130\n",
      "23/224, train_loss: 0.0614, step time: 0.3773\n",
      "24/224, train_loss: 0.0998, step time: 0.3858\n",
      "25/224, train_loss: 0.2453, step time: 0.3147\n",
      "26/224, train_loss: 0.1146, step time: 0.3868\n",
      "27/224, train_loss: 0.1482, step time: 0.3154\n",
      "28/224, train_loss: 0.1131, step time: 0.3178\n",
      "29/224, train_loss: 0.0959, step time: 0.3811\n",
      "30/224, train_loss: 0.1411, step time: 0.3984\n",
      "31/224, train_loss: 0.2575, step time: 0.3845\n",
      "32/224, train_loss: 0.0816, step time: 0.3177\n",
      "33/224, train_loss: 0.0906, step time: 0.3130\n",
      "34/224, train_loss: 0.3529, step time: 0.3632\n",
      "35/224, train_loss: 0.1334, step time: 0.3132\n",
      "36/224, train_loss: 0.2467, step time: 0.3651\n",
      "37/224, train_loss: 0.0996, step time: 0.3783\n",
      "38/224, train_loss: 0.0724, step time: 0.4028\n",
      "39/224, train_loss: 0.1405, step time: 0.4116\n",
      "40/224, train_loss: 0.3205, step time: 0.3978\n",
      "41/224, train_loss: 0.1387, step time: 0.3149\n",
      "42/224, train_loss: 0.0646, step time: 0.3144\n",
      "43/224, train_loss: 0.1068, step time: 0.3144\n",
      "44/224, train_loss: 0.1281, step time: 0.3154\n",
      "45/224, train_loss: 0.0691, step time: 0.3149\n",
      "46/224, train_loss: 0.1483, step time: 0.3971\n",
      "47/224, train_loss: 0.1355, step time: 0.3165\n",
      "48/224, train_loss: 0.1734, step time: 0.3140\n",
      "49/224, train_loss: 0.1917, step time: 0.4011\n",
      "50/224, train_loss: 0.0669, step time: 0.3783\n",
      "51/224, train_loss: 0.2208, step time: 0.3894\n",
      "52/224, train_loss: 0.1510, step time: 0.3775\n",
      "53/224, train_loss: 0.3489, step time: 0.3736\n",
      "54/224, train_loss: 0.1801, step time: 0.3778\n",
      "55/224, train_loss: 0.1199, step time: 0.3150\n",
      "56/224, train_loss: 0.3110, step time: 0.3754\n",
      "57/224, train_loss: 0.0979, step time: 0.3169\n",
      "58/224, train_loss: 0.0790, step time: 0.3782\n",
      "59/224, train_loss: 0.1430, step time: 0.3151\n",
      "60/224, train_loss: 0.3124, step time: 0.4002\n",
      "61/224, train_loss: 0.0949, step time: 0.3144\n",
      "62/224, train_loss: 0.1310, step time: 0.3940\n",
      "63/224, train_loss: 0.1059, step time: 0.3147\n",
      "64/224, train_loss: 0.1407, step time: 0.3992\n",
      "65/224, train_loss: 0.0902, step time: 0.3174\n",
      "66/224, train_loss: 0.0802, step time: 0.4099\n",
      "67/224, train_loss: 0.0955, step time: 0.3177\n",
      "68/224, train_loss: 0.0695, step time: 0.3683\n",
      "69/224, train_loss: 0.1123, step time: 0.3126\n",
      "70/224, train_loss: 0.0863, step time: 0.3167\n",
      "71/224, train_loss: 0.0922, step time: 0.3145\n",
      "72/224, train_loss: 0.1368, step time: 0.3122\n",
      "73/224, train_loss: 0.2696, step time: 0.3123\n",
      "74/224, train_loss: 0.1050, step time: 0.3144\n",
      "75/224, train_loss: 0.0708, step time: 0.3884\n",
      "76/224, train_loss: 0.4028, step time: 0.4047\n",
      "77/224, train_loss: 0.1313, step time: 0.3775\n",
      "78/224, train_loss: 0.2171, step time: 0.3155\n",
      "79/224, train_loss: 0.0868, step time: 0.3126\n",
      "80/224, train_loss: 0.2348, step time: 0.3870\n",
      "81/224, train_loss: 0.1108, step time: 0.3153\n",
      "82/224, train_loss: 0.3671, step time: 0.3692\n",
      "83/224, train_loss: 0.0834, step time: 0.3797\n",
      "84/224, train_loss: 0.1016, step time: 0.3727\n",
      "85/224, train_loss: 0.1077, step time: 0.3123\n",
      "86/224, train_loss: 0.3672, step time: 0.3900\n",
      "87/224, train_loss: 0.0789, step time: 0.3170\n",
      "88/224, train_loss: 0.2028, step time: 0.3826\n",
      "89/224, train_loss: 0.0720, step time: 0.3922\n",
      "90/224, train_loss: 0.1391, step time: 0.3959\n",
      "91/224, train_loss: 0.1088, step time: 0.3153\n",
      "92/224, train_loss: 0.1261, step time: 0.3158\n",
      "93/224, train_loss: 0.1284, step time: 0.3774\n",
      "94/224, train_loss: 0.0623, step time: 0.3146\n",
      "95/224, train_loss: 0.2557, step time: 0.3740\n",
      "96/224, train_loss: 0.2352, step time: 0.3155\n",
      "97/224, train_loss: 0.3098, step time: 0.3146\n",
      "98/224, train_loss: 0.0671, step time: 0.3997\n",
      "99/224, train_loss: 0.1347, step time: 0.3129\n",
      "100/224, train_loss: 0.1319, step time: 0.3175\n",
      "101/224, train_loss: 0.1615, step time: 0.4096\n",
      "102/224, train_loss: 0.0993, step time: 0.3142\n",
      "103/224, train_loss: 0.1826, step time: 0.3849\n",
      "104/224, train_loss: 0.0578, step time: 0.3130\n",
      "105/224, train_loss: 0.1334, step time: 0.3147\n",
      "106/224, train_loss: 0.0919, step time: 0.3148\n",
      "107/224, train_loss: 0.2062, step time: 0.4018\n",
      "108/224, train_loss: 0.1115, step time: 0.3152\n",
      "109/224, train_loss: 0.1979, step time: 0.3952\n",
      "110/224, train_loss: 0.1133, step time: 0.3137\n",
      "111/224, train_loss: 0.3745, step time: 0.3800\n",
      "112/224, train_loss: 0.2900, step time: 0.3150\n",
      "113/224, train_loss: 0.1179, step time: 0.3125\n",
      "114/224, train_loss: 0.0866, step time: 0.3125\n",
      "115/224, train_loss: 0.1503, step time: 0.3699\n",
      "116/224, train_loss: 0.1052, step time: 0.3655\n",
      "117/224, train_loss: 0.1281, step time: 0.3788\n",
      "118/224, train_loss: 0.0825, step time: 0.3164\n",
      "119/224, train_loss: 0.1055, step time: 0.4025\n",
      "120/224, train_loss: 0.3072, step time: 0.3800\n",
      "121/224, train_loss: 0.0578, step time: 0.3136\n",
      "122/224, train_loss: 0.0939, step time: 0.3141\n",
      "123/224, train_loss: 0.1256, step time: 0.4005\n",
      "124/224, train_loss: 0.1247, step time: 0.3125\n",
      "125/224, train_loss: 0.0598, step time: 0.3911\n",
      "126/224, train_loss: 0.0962, step time: 0.3173\n",
      "127/224, train_loss: 0.1170, step time: 0.3154\n",
      "128/224, train_loss: 0.0818, step time: 0.3135\n",
      "129/224, train_loss: 0.1225, step time: 0.3794\n",
      "130/224, train_loss: 0.2477, step time: 0.3166\n",
      "131/224, train_loss: 0.1334, step time: 0.4053\n",
      "132/224, train_loss: 0.2555, step time: 0.3919\n",
      "133/224, train_loss: 0.1869, step time: 0.3827\n",
      "134/224, train_loss: 0.1339, step time: 0.3139\n",
      "135/224, train_loss: 0.1252, step time: 0.3156\n",
      "136/224, train_loss: 0.2113, step time: 0.4068\n",
      "137/224, train_loss: 0.1472, step time: 0.3153\n",
      "138/224, train_loss: 0.3006, step time: 0.4067\n",
      "139/224, train_loss: 0.1007, step time: 0.3188\n",
      "140/224, train_loss: 0.2174, step time: 0.3740\n",
      "141/224, train_loss: 0.2062, step time: 0.3153\n",
      "142/224, train_loss: 0.2463, step time: 0.3735\n",
      "143/224, train_loss: 0.0914, step time: 0.3164\n",
      "144/224, train_loss: 0.0464, step time: 0.3731\n",
      "145/224, train_loss: 0.1802, step time: 0.3154\n",
      "146/224, train_loss: 0.0687, step time: 0.3162\n",
      "147/224, train_loss: 0.1322, step time: 0.4043\n",
      "148/224, train_loss: 0.1134, step time: 0.3151\n",
      "149/224, train_loss: 0.0593, step time: 0.3990\n",
      "150/224, train_loss: 0.0866, step time: 0.3923\n",
      "151/224, train_loss: 0.2111, step time: 0.3885\n",
      "152/224, train_loss: 0.1436, step time: 0.3155\n",
      "153/224, train_loss: 0.1280, step time: 0.3177\n",
      "154/224, train_loss: 0.1082, step time: 0.3182\n",
      "155/224, train_loss: 0.1165, step time: 0.3945\n",
      "156/224, train_loss: 0.1597, step time: 0.3808\n",
      "157/224, train_loss: 0.1999, step time: 0.3194\n",
      "158/224, train_loss: 0.1404, step time: 0.3139\n",
      "159/224, train_loss: 0.1504, step time: 0.3135\n",
      "160/224, train_loss: 0.0982, step time: 0.3150\n",
      "161/224, train_loss: 0.3531, step time: 0.3959\n",
      "162/224, train_loss: 0.0751, step time: 0.3176\n",
      "163/224, train_loss: 0.0748, step time: 0.3175\n",
      "164/224, train_loss: 0.0805, step time: 0.3150\n",
      "165/224, train_loss: 0.0913, step time: 0.3146\n",
      "166/224, train_loss: 0.1930, step time: 0.3685\n",
      "167/224, train_loss: 0.3361, step time: 0.3692\n",
      "168/224, train_loss: 0.1140, step time: 0.3970\n",
      "169/224, train_loss: 0.1119, step time: 0.3997\n",
      "170/224, train_loss: 0.1291, step time: 0.3156\n",
      "171/224, train_loss: 0.1362, step time: 0.3824\n",
      "172/224, train_loss: 0.0950, step time: 0.3142\n",
      "173/224, train_loss: 0.0770, step time: 0.3162\n",
      "174/224, train_loss: 0.1323, step time: 0.3782\n",
      "175/224, train_loss: 0.1862, step time: 0.4048\n",
      "176/224, train_loss: 0.0966, step time: 0.3949\n",
      "177/224, train_loss: 0.1393, step time: 0.3174\n",
      "178/224, train_loss: 0.1303, step time: 0.3898\n",
      "179/224, train_loss: 0.1260, step time: 0.4143\n",
      "180/224, train_loss: 0.1178, step time: 0.3986\n",
      "181/224, train_loss: 0.0689, step time: 0.3174\n",
      "182/224, train_loss: 0.1236, step time: 0.3139\n",
      "183/224, train_loss: 0.2099, step time: 0.3742\n",
      "184/224, train_loss: 0.4549, step time: 0.3792\n",
      "185/224, train_loss: 0.1869, step time: 0.3910\n",
      "186/224, train_loss: 0.1511, step time: 0.3157\n",
      "187/224, train_loss: 0.1159, step time: 0.3133\n",
      "188/224, train_loss: 0.1042, step time: 0.4036\n",
      "189/224, train_loss: 0.0959, step time: 0.3156\n",
      "190/224, train_loss: 0.2078, step time: 0.3942\n",
      "191/224, train_loss: 0.1326, step time: 0.3731\n",
      "192/224, train_loss: 0.2440, step time: 0.3150\n",
      "193/224, train_loss: 0.0928, step time: 0.3821\n",
      "194/224, train_loss: 0.0996, step time: 0.3154\n",
      "195/224, train_loss: 0.1506, step time: 0.3815\n",
      "196/224, train_loss: 0.0794, step time: 0.3852\n",
      "197/224, train_loss: 0.3061, step time: 0.3154\n",
      "198/224, train_loss: 0.2304, step time: 0.3877\n",
      "199/224, train_loss: 0.0895, step time: 0.3996\n",
      "200/224, train_loss: 0.1086, step time: 0.3154\n",
      "201/224, train_loss: 0.1692, step time: 0.3971\n",
      "202/224, train_loss: 0.4315, step time: 0.4049\n",
      "203/224, train_loss: 0.2989, step time: 0.3169\n",
      "204/224, train_loss: 0.2815, step time: 0.3145\n",
      "205/224, train_loss: 0.1840, step time: 0.3890\n",
      "206/224, train_loss: 0.1368, step time: 0.3981\n",
      "207/224, train_loss: 0.1266, step time: 0.4040\n",
      "208/224, train_loss: 0.1140, step time: 0.3687\n",
      "209/224, train_loss: 0.0755, step time: 0.3131\n",
      "210/224, train_loss: 0.0864, step time: 0.3153\n",
      "211/224, train_loss: 0.1240, step time: 0.3743\n",
      "212/224, train_loss: 0.1197, step time: 0.3176\n",
      "213/224, train_loss: 0.1310, step time: 0.3149\n",
      "214/224, train_loss: 0.3208, step time: 0.3906\n",
      "215/224, train_loss: 0.0717, step time: 0.3752\n",
      "216/224, train_loss: 0.1074, step time: 0.3675\n",
      "217/224, train_loss: 0.1017, step time: 0.4095\n",
      "218/224, train_loss: 0.0894, step time: 0.3158\n",
      "219/224, train_loss: 0.1613, step time: 0.3131\n",
      "220/224, train_loss: 0.0956, step time: 0.3174\n",
      "221/224, train_loss: 0.0804, step time: 0.3953\n",
      "222/224, train_loss: 0.1378, step time: 0.3820\n",
      "223/224, train_loss: 0.0907, step time: 0.3655\n",
      "224/224, train_loss: 0.0869, step time: 0.3924\n",
      "epoch 65 average loss: 0.1477\n",
      "current epoch: 65 current mean dice: 0.6893 class1: 0.9993 class2: 0.6849 class3: 0.3838\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 65 is: 746.1881\n",
      "hello\n",
      "----------\n",
      "epoch 66/100\n",
      "1/224, train_loss: 0.2584, step time: 0.3129\n",
      "2/224, train_loss: 0.1293, step time: 0.3129\n",
      "3/224, train_loss: 0.0678, step time: 0.4087\n",
      "4/224, train_loss: 0.0875, step time: 0.3132\n",
      "5/224, train_loss: 0.1375, step time: 0.3175\n",
      "6/224, train_loss: 0.0984, step time: 0.3176\n",
      "7/224, train_loss: 0.4279, step time: 0.3673\n",
      "8/224, train_loss: 0.1277, step time: 0.3665\n",
      "9/224, train_loss: 0.1217, step time: 0.3170\n",
      "10/224, train_loss: 0.2586, step time: 0.3148\n",
      "11/224, train_loss: 0.1025, step time: 0.3147\n",
      "12/224, train_loss: 0.1446, step time: 0.3172\n",
      "13/224, train_loss: 0.0705, step time: 0.3151\n",
      "14/224, train_loss: 0.0878, step time: 0.3177\n",
      "15/224, train_loss: 0.0960, step time: 0.3998\n",
      "16/224, train_loss: 0.1265, step time: 0.3168\n",
      "17/224, train_loss: 0.2476, step time: 0.3769\n",
      "18/224, train_loss: 0.1899, step time: 0.3967\n",
      "19/224, train_loss: 0.0626, step time: 0.3138\n",
      "20/224, train_loss: 0.0959, step time: 0.3994\n",
      "21/224, train_loss: 0.1336, step time: 0.3154\n",
      "22/224, train_loss: 0.2512, step time: 0.3172\n",
      "23/224, train_loss: 0.0689, step time: 0.3731\n",
      "24/224, train_loss: 0.0762, step time: 0.3879\n",
      "25/224, train_loss: 0.0618, step time: 0.3148\n",
      "26/224, train_loss: 0.1203, step time: 0.3173\n",
      "27/224, train_loss: 0.0974, step time: 0.3153\n",
      "28/224, train_loss: 0.1382, step time: 0.4003\n",
      "29/224, train_loss: 0.1274, step time: 0.3159\n",
      "30/224, train_loss: 0.0960, step time: 0.3734\n",
      "31/224, train_loss: 0.0647, step time: 0.3135\n",
      "32/224, train_loss: 0.1172, step time: 0.4083\n",
      "33/224, train_loss: 0.1880, step time: 0.3863\n",
      "34/224, train_loss: 0.2338, step time: 0.3129\n",
      "35/224, train_loss: 0.0574, step time: 0.3177\n",
      "36/224, train_loss: 0.3471, step time: 0.4010\n",
      "37/224, train_loss: 0.1347, step time: 0.3696\n",
      "38/224, train_loss: 0.1485, step time: 0.3125\n",
      "39/224, train_loss: 0.1220, step time: 0.3936\n",
      "40/224, train_loss: 0.1325, step time: 0.3172\n",
      "41/224, train_loss: 0.3384, step time: 0.3990\n",
      "42/224, train_loss: 0.0920, step time: 0.3651\n",
      "43/224, train_loss: 0.1762, step time: 0.3864\n",
      "44/224, train_loss: 0.0833, step time: 0.3686\n",
      "45/224, train_loss: 0.0910, step time: 0.4017\n",
      "46/224, train_loss: 0.1148, step time: 0.3146\n",
      "47/224, train_loss: 0.2749, step time: 0.3771\n",
      "48/224, train_loss: 0.1509, step time: 0.3690\n",
      "49/224, train_loss: 0.1896, step time: 0.3912\n",
      "50/224, train_loss: 0.0988, step time: 0.4122\n",
      "51/224, train_loss: 0.0868, step time: 0.3125\n",
      "52/224, train_loss: 0.0893, step time: 0.3804\n",
      "53/224, train_loss: 0.0810, step time: 0.3145\n",
      "54/224, train_loss: 0.1259, step time: 0.3148\n",
      "55/224, train_loss: 0.0955, step time: 0.3158\n",
      "56/224, train_loss: 0.1238, step time: 0.4109\n",
      "57/224, train_loss: 0.1224, step time: 0.3699\n",
      "58/224, train_loss: 0.2493, step time: 0.4065\n",
      "59/224, train_loss: 0.1165, step time: 0.3815\n",
      "60/224, train_loss: 0.0754, step time: 0.3147\n",
      "61/224, train_loss: 0.1075, step time: 0.3146\n",
      "62/224, train_loss: 0.0881, step time: 0.3167\n",
      "63/224, train_loss: 0.0886, step time: 0.3166\n",
      "64/224, train_loss: 0.0618, step time: 0.3147\n",
      "65/224, train_loss: 0.0956, step time: 0.3145\n",
      "66/224, train_loss: 0.0843, step time: 0.3124\n",
      "67/224, train_loss: 0.1206, step time: 0.3717\n",
      "68/224, train_loss: 0.1171, step time: 0.3132\n",
      "69/224, train_loss: 0.0834, step time: 0.3151\n",
      "70/224, train_loss: 0.1019, step time: 0.3886\n",
      "71/224, train_loss: 0.1229, step time: 0.3150\n",
      "72/224, train_loss: 0.2321, step time: 0.3148\n",
      "73/224, train_loss: 0.1062, step time: 0.3146\n",
      "74/224, train_loss: 0.1227, step time: 0.3177\n",
      "75/224, train_loss: 0.1521, step time: 0.3178\n",
      "76/224, train_loss: 0.1327, step time: 0.3130\n",
      "77/224, train_loss: 0.0434, step time: 0.3142\n",
      "78/224, train_loss: 0.1483, step time: 0.3805\n",
      "79/224, train_loss: 0.0576, step time: 0.3722\n",
      "80/224, train_loss: 0.0761, step time: 0.3799\n",
      "81/224, train_loss: 0.1845, step time: 0.3154\n",
      "82/224, train_loss: 0.0658, step time: 0.3172\n",
      "83/224, train_loss: 0.2564, step time: 0.3969\n",
      "84/224, train_loss: 0.0782, step time: 0.3151\n",
      "85/224, train_loss: 0.3069, step time: 0.3144\n",
      "86/224, train_loss: 0.1110, step time: 0.3834\n",
      "87/224, train_loss: 0.1191, step time: 0.3135\n",
      "88/224, train_loss: 0.1645, step time: 0.3157\n",
      "89/224, train_loss: 0.0902, step time: 0.3155\n",
      "90/224, train_loss: 0.0916, step time: 0.3177\n",
      "91/224, train_loss: 0.1201, step time: 0.3159\n",
      "92/224, train_loss: 0.2846, step time: 0.3996\n",
      "93/224, train_loss: 0.1057, step time: 0.3158\n",
      "94/224, train_loss: 0.1270, step time: 0.3162\n",
      "95/224, train_loss: 0.1859, step time: 0.3888\n",
      "96/224, train_loss: 0.0841, step time: 0.3740\n",
      "97/224, train_loss: 0.0721, step time: 0.3134\n",
      "98/224, train_loss: 0.1090, step time: 0.3151\n",
      "99/224, train_loss: 0.1332, step time: 0.3816\n",
      "100/224, train_loss: 0.1354, step time: 0.4039\n",
      "101/224, train_loss: 0.0784, step time: 0.3157\n",
      "102/224, train_loss: 0.1077, step time: 0.3171\n",
      "103/224, train_loss: 0.1972, step time: 0.3896\n",
      "104/224, train_loss: 0.2326, step time: 0.3900\n",
      "105/224, train_loss: 0.0852, step time: 0.3153\n",
      "106/224, train_loss: 0.0538, step time: 0.3130\n",
      "107/224, train_loss: 0.1499, step time: 0.3803\n",
      "108/224, train_loss: 0.2094, step time: 0.3949\n",
      "109/224, train_loss: 0.1806, step time: 0.3788\n",
      "110/224, train_loss: 0.0887, step time: 0.3127\n",
      "111/224, train_loss: 0.1278, step time: 0.3961\n",
      "112/224, train_loss: 0.1221, step time: 0.3157\n",
      "113/224, train_loss: 0.0829, step time: 0.4109\n",
      "114/224, train_loss: 0.1401, step time: 0.3149\n",
      "115/224, train_loss: 0.0880, step time: 0.4012\n",
      "116/224, train_loss: 0.1221, step time: 0.3177\n",
      "117/224, train_loss: 0.4150, step time: 0.3983\n",
      "118/224, train_loss: 0.0924, step time: 0.3177\n",
      "119/224, train_loss: 0.0995, step time: 0.3765\n",
      "120/224, train_loss: 0.1878, step time: 0.3150\n",
      "121/224, train_loss: 0.1072, step time: 0.3129\n",
      "122/224, train_loss: 0.1743, step time: 0.3177\n",
      "123/224, train_loss: 0.1391, step time: 0.3972\n",
      "124/224, train_loss: 0.3498, step time: 0.3994\n",
      "125/224, train_loss: 0.1886, step time: 0.3690\n",
      "126/224, train_loss: 0.2003, step time: 0.4106\n",
      "127/224, train_loss: 0.2451, step time: 0.3665\n",
      "128/224, train_loss: 0.0704, step time: 0.3149\n",
      "129/224, train_loss: 0.1652, step time: 0.3746\n",
      "130/224, train_loss: 0.1282, step time: 0.3831\n",
      "131/224, train_loss: 0.1455, step time: 0.3892\n",
      "132/224, train_loss: 0.0551, step time: 0.3750\n",
      "133/224, train_loss: 0.0732, step time: 0.3134\n",
      "134/224, train_loss: 0.0874, step time: 0.3159\n",
      "135/224, train_loss: 0.0631, step time: 0.3171\n",
      "136/224, train_loss: 0.0733, step time: 0.3144\n",
      "137/224, train_loss: 0.1125, step time: 0.3147\n",
      "138/224, train_loss: 0.0767, step time: 0.3175\n",
      "139/224, train_loss: 0.3436, step time: 0.3721\n",
      "140/224, train_loss: 0.2062, step time: 0.3908\n",
      "141/224, train_loss: 0.1401, step time: 0.3129\n",
      "142/224, train_loss: 0.3180, step time: 0.3756\n",
      "143/224, train_loss: 0.1241, step time: 0.3148\n",
      "144/224, train_loss: 0.3441, step time: 0.4043\n",
      "145/224, train_loss: 0.0846, step time: 0.3732\n",
      "146/224, train_loss: 0.1726, step time: 0.3717\n",
      "147/224, train_loss: 0.0841, step time: 0.3867\n",
      "148/224, train_loss: 0.1257, step time: 0.3665\n",
      "149/224, train_loss: 0.3620, step time: 0.3858\n",
      "150/224, train_loss: 0.1199, step time: 0.3136\n",
      "151/224, train_loss: 0.3164, step time: 0.3917\n",
      "152/224, train_loss: 0.1329, step time: 0.3876\n",
      "153/224, train_loss: 0.1107, step time: 0.3186\n",
      "154/224, train_loss: 0.1574, step time: 0.3860\n",
      "155/224, train_loss: 0.1042, step time: 0.3138\n",
      "156/224, train_loss: 0.1632, step time: 0.3886\n",
      "157/224, train_loss: 0.1461, step time: 0.3159\n",
      "158/224, train_loss: 0.1456, step time: 0.3794\n",
      "159/224, train_loss: 0.2373, step time: 0.3798\n",
      "160/224, train_loss: 0.1846, step time: 0.3140\n",
      "161/224, train_loss: 0.2595, step time: 0.4123\n",
      "162/224, train_loss: 0.2438, step time: 0.3987\n",
      "163/224, train_loss: 0.1980, step time: 0.3166\n",
      "164/224, train_loss: 0.0620, step time: 0.3180\n",
      "165/224, train_loss: 0.1290, step time: 0.3156\n",
      "166/224, train_loss: 0.1689, step time: 0.3690\n",
      "167/224, train_loss: 0.1003, step time: 0.3183\n",
      "168/224, train_loss: 0.0898, step time: 0.3178\n",
      "169/224, train_loss: 0.0529, step time: 0.3184\n",
      "170/224, train_loss: 0.0875, step time: 0.3188\n",
      "171/224, train_loss: 0.0833, step time: 0.3819\n",
      "172/224, train_loss: 0.1665, step time: 0.4078\n",
      "173/224, train_loss: 0.1591, step time: 0.4032\n",
      "174/224, train_loss: 0.1048, step time: 0.3706\n",
      "175/224, train_loss: 0.0886, step time: 0.3157\n",
      "176/224, train_loss: 0.1227, step time: 0.3137\n",
      "177/224, train_loss: 0.0690, step time: 0.3186\n",
      "178/224, train_loss: 0.1308, step time: 0.3694\n",
      "179/224, train_loss: 0.0818, step time: 0.3166\n",
      "180/224, train_loss: 0.2131, step time: 0.4108\n",
      "181/224, train_loss: 0.0970, step time: 0.3981\n",
      "182/224, train_loss: 0.1306, step time: 0.3763\n",
      "183/224, train_loss: 0.0865, step time: 0.3162\n",
      "184/224, train_loss: 0.1303, step time: 0.3157\n",
      "185/224, train_loss: 0.0687, step time: 0.3180\n",
      "186/224, train_loss: 0.2103, step time: 0.3903\n",
      "187/224, train_loss: 0.1950, step time: 0.3827\n",
      "188/224, train_loss: 0.0725, step time: 0.3187\n",
      "189/224, train_loss: 0.1344, step time: 0.3823\n",
      "190/224, train_loss: 0.0926, step time: 0.3163\n",
      "191/224, train_loss: 0.0957, step time: 0.3157\n",
      "192/224, train_loss: 0.0793, step time: 0.3134\n",
      "193/224, train_loss: 0.0804, step time: 0.4030\n",
      "194/224, train_loss: 0.1378, step time: 0.3187\n",
      "195/224, train_loss: 0.2730, step time: 0.3691\n",
      "196/224, train_loss: 0.2318, step time: 0.3704\n",
      "197/224, train_loss: 0.0772, step time: 0.3188\n",
      "198/224, train_loss: 0.0926, step time: 0.3160\n",
      "199/224, train_loss: 0.1278, step time: 0.3164\n",
      "200/224, train_loss: 0.1694, step time: 0.3183\n",
      "201/224, train_loss: 0.3189, step time: 0.3723\n",
      "202/224, train_loss: 0.1531, step time: 0.3160\n",
      "203/224, train_loss: 0.1095, step time: 0.3156\n",
      "204/224, train_loss: 0.1490, step time: 0.3739\n",
      "205/224, train_loss: 0.1091, step time: 0.3916\n",
      "206/224, train_loss: 0.1095, step time: 0.3791\n",
      "207/224, train_loss: 0.2658, step time: 0.3732\n",
      "208/224, train_loss: 0.1246, step time: 0.3183\n",
      "209/224, train_loss: 0.1141, step time: 0.3157\n",
      "210/224, train_loss: 0.0887, step time: 0.3974\n",
      "211/224, train_loss: 0.1712, step time: 0.3820\n",
      "212/224, train_loss: 0.1807, step time: 0.3947\n",
      "213/224, train_loss: 0.2153, step time: 0.4016\n",
      "214/224, train_loss: 0.1447, step time: 0.3162\n",
      "215/224, train_loss: 0.0920, step time: 0.4082\n",
      "216/224, train_loss: 0.1008, step time: 0.3136\n",
      "217/224, train_loss: 0.0767, step time: 0.3770\n",
      "218/224, train_loss: 0.0693, step time: 0.4009\n",
      "219/224, train_loss: 0.1907, step time: 0.3153\n",
      "220/224, train_loss: 0.1387, step time: 0.3151\n",
      "221/224, train_loss: 0.0961, step time: 0.3829\n",
      "222/224, train_loss: 0.1293, step time: 0.3837\n",
      "223/224, train_loss: 0.0910, step time: 0.3152\n",
      "224/224, train_loss: 0.0861, step time: 0.3152\n",
      "epoch 66 average loss: 0.1400\n",
      "current epoch: 66 current mean dice: 0.6848 class1: 0.9993 class2: 0.7450 class3: 0.3100\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 66 is: 690.4863\n",
      "hello\n",
      "----------\n",
      "epoch 67/100\n",
      "1/224, train_loss: 0.1825, step time: 0.3740\n",
      "2/224, train_loss: 0.1400, step time: 0.3162\n",
      "3/224, train_loss: 0.1133, step time: 0.3154\n",
      "4/224, train_loss: 0.0924, step time: 0.3137\n",
      "5/224, train_loss: 0.1968, step time: 0.3993\n",
      "6/224, train_loss: 0.0695, step time: 0.3129\n",
      "7/224, train_loss: 0.0954, step time: 0.4106\n",
      "8/224, train_loss: 0.1734, step time: 0.3737\n",
      "9/224, train_loss: 0.2258, step time: 0.3730\n",
      "10/224, train_loss: 0.1089, step time: 0.3152\n",
      "11/224, train_loss: 0.1082, step time: 0.3154\n",
      "12/224, train_loss: 0.0868, step time: 0.3710\n",
      "13/224, train_loss: 0.2040, step time: 0.4062\n",
      "14/224, train_loss: 0.1703, step time: 0.4041\n",
      "15/224, train_loss: 0.1220, step time: 0.3924\n",
      "16/224, train_loss: 0.1378, step time: 0.3160\n",
      "17/224, train_loss: 0.0833, step time: 0.3179\n",
      "18/224, train_loss: 0.0717, step time: 0.3133\n",
      "19/224, train_loss: 0.0919, step time: 0.3161\n",
      "20/224, train_loss: 0.1229, step time: 0.3979\n",
      "21/224, train_loss: 0.0803, step time: 0.3167\n",
      "22/224, train_loss: 0.0930, step time: 0.3140\n",
      "23/224, train_loss: 0.1276, step time: 0.3809\n",
      "24/224, train_loss: 0.1876, step time: 0.3156\n",
      "25/224, train_loss: 0.1043, step time: 0.3177\n",
      "26/224, train_loss: 0.1077, step time: 0.3890\n",
      "27/224, train_loss: 0.0823, step time: 0.3659\n",
      "28/224, train_loss: 0.0956, step time: 0.3943\n",
      "29/224, train_loss: 0.0912, step time: 0.3183\n",
      "30/224, train_loss: 0.1182, step time: 0.3153\n",
      "31/224, train_loss: 0.0614, step time: 0.3174\n",
      "32/224, train_loss: 0.1976, step time: 0.3137\n",
      "33/224, train_loss: 0.0751, step time: 0.3182\n",
      "34/224, train_loss: 0.1818, step time: 0.3905\n",
      "35/224, train_loss: 0.1334, step time: 0.3180\n",
      "36/224, train_loss: 0.1420, step time: 0.3833\n",
      "37/224, train_loss: 0.1529, step time: 0.3129\n",
      "38/224, train_loss: 0.3364, step time: 0.3768\n",
      "39/224, train_loss: 0.0719, step time: 0.3166\n",
      "40/224, train_loss: 0.1083, step time: 0.3142\n",
      "41/224, train_loss: 0.0490, step time: 0.3965\n",
      "42/224, train_loss: 0.0980, step time: 0.3182\n",
      "43/224, train_loss: 0.0878, step time: 0.4071\n",
      "44/224, train_loss: 0.1927, step time: 0.3966\n",
      "45/224, train_loss: 0.0601, step time: 0.3154\n",
      "46/224, train_loss: 0.1477, step time: 0.3988\n",
      "47/224, train_loss: 0.0816, step time: 0.3176\n",
      "48/224, train_loss: 0.3405, step time: 0.3741\n",
      "49/224, train_loss: 0.1289, step time: 0.3175\n",
      "50/224, train_loss: 0.2945, step time: 0.3714\n",
      "51/224, train_loss: 0.2796, step time: 0.3141\n",
      "52/224, train_loss: 0.3431, step time: 0.3184\n",
      "53/224, train_loss: 0.1668, step time: 0.3944\n",
      "54/224, train_loss: 0.1652, step time: 0.3157\n",
      "55/224, train_loss: 0.1608, step time: 0.3918\n",
      "56/224, train_loss: 0.1308, step time: 0.3155\n",
      "57/224, train_loss: 0.2267, step time: 0.3978\n",
      "58/224, train_loss: 0.0874, step time: 0.3887\n",
      "59/224, train_loss: 0.0934, step time: 0.3160\n",
      "60/224, train_loss: 0.2073, step time: 0.3175\n",
      "61/224, train_loss: 0.0972, step time: 0.4013\n",
      "62/224, train_loss: 0.1163, step time: 0.3731\n",
      "63/224, train_loss: 0.1056, step time: 0.3150\n",
      "64/224, train_loss: 0.1305, step time: 0.3831\n",
      "65/224, train_loss: 0.0655, step time: 0.3133\n",
      "66/224, train_loss: 0.2377, step time: 0.3673\n",
      "67/224, train_loss: 0.3584, step time: 0.3912\n",
      "68/224, train_loss: 0.1069, step time: 0.4045\n",
      "69/224, train_loss: 0.1496, step time: 0.3691\n",
      "70/224, train_loss: 0.1055, step time: 0.3145\n",
      "71/224, train_loss: 0.1348, step time: 0.3186\n",
      "72/224, train_loss: 0.2933, step time: 0.4063\n",
      "73/224, train_loss: 0.3037, step time: 0.3914\n",
      "74/224, train_loss: 0.1329, step time: 0.3179\n",
      "75/224, train_loss: 0.1410, step time: 0.3190\n",
      "76/224, train_loss: 0.0970, step time: 0.3195\n",
      "77/224, train_loss: 0.1506, step time: 0.3958\n",
      "78/224, train_loss: 0.2561, step time: 0.3700\n",
      "79/224, train_loss: 0.1727, step time: 0.3806\n",
      "80/224, train_loss: 0.0858, step time: 0.3181\n",
      "81/224, train_loss: 0.1056, step time: 0.3748\n",
      "82/224, train_loss: 0.3101, step time: 0.3704\n",
      "83/224, train_loss: 0.1359, step time: 0.3193\n",
      "84/224, train_loss: 0.1079, step time: 0.4016\n",
      "85/224, train_loss: 0.0604, step time: 0.3163\n",
      "86/224, train_loss: 0.1153, step time: 0.3167\n",
      "87/224, train_loss: 0.1140, step time: 0.3190\n",
      "88/224, train_loss: 0.1389, step time: 0.3153\n",
      "89/224, train_loss: 0.0947, step time: 0.3145\n",
      "90/224, train_loss: 0.1150, step time: 0.3985\n",
      "91/224, train_loss: 0.0894, step time: 0.3166\n",
      "92/224, train_loss: 0.0937, step time: 0.3723\n",
      "93/224, train_loss: 0.1144, step time: 0.3165\n",
      "94/224, train_loss: 0.1827, step time: 0.3160\n",
      "95/224, train_loss: 0.1170, step time: 0.4110\n",
      "96/224, train_loss: 0.1381, step time: 0.3776\n",
      "97/224, train_loss: 0.0716, step time: 0.4009\n",
      "98/224, train_loss: 0.1366, step time: 0.4150\n",
      "99/224, train_loss: 0.0936, step time: 0.3171\n",
      "100/224, train_loss: 0.0725, step time: 0.3723\n",
      "101/224, train_loss: 0.1584, step time: 0.4070\n",
      "102/224, train_loss: 0.0767, step time: 0.3179\n",
      "103/224, train_loss: 0.0886, step time: 0.3200\n",
      "104/224, train_loss: 0.1080, step time: 0.3177\n",
      "105/224, train_loss: 0.0506, step time: 0.3178\n",
      "106/224, train_loss: 0.0772, step time: 0.4080\n",
      "107/224, train_loss: 0.3784, step time: 0.3721\n",
      "108/224, train_loss: 0.1145, step time: 0.3693\n",
      "109/224, train_loss: 0.0711, step time: 0.3819\n",
      "110/224, train_loss: 0.0915, step time: 0.4051\n",
      "111/224, train_loss: 0.2168, step time: 0.3699\n",
      "112/224, train_loss: 0.2405, step time: 0.3708\n",
      "113/224, train_loss: 0.0567, step time: 0.3181\n",
      "114/224, train_loss: 0.0725, step time: 0.4056\n",
      "115/224, train_loss: 0.1240, step time: 0.3174\n",
      "116/224, train_loss: 0.0951, step time: 0.3172\n",
      "117/224, train_loss: 0.1478, step time: 0.3664\n",
      "118/224, train_loss: 0.2407, step time: 0.3786\n",
      "119/224, train_loss: 0.0766, step time: 0.4031\n",
      "120/224, train_loss: 0.2054, step time: 0.3146\n",
      "121/224, train_loss: 0.1593, step time: 0.3191\n",
      "122/224, train_loss: 0.0609, step time: 0.3169\n",
      "123/224, train_loss: 0.1264, step time: 0.3191\n",
      "124/224, train_loss: 0.1147, step time: 0.3177\n",
      "125/224, train_loss: 0.2097, step time: 0.3732\n",
      "126/224, train_loss: 0.2372, step time: 0.3785\n",
      "127/224, train_loss: 0.0899, step time: 0.3199\n",
      "128/224, train_loss: 0.1071, step time: 0.3172\n",
      "129/224, train_loss: 0.0539, step time: 0.3170\n",
      "130/224, train_loss: 0.0893, step time: 0.3176\n",
      "131/224, train_loss: 0.0402, step time: 0.3172\n",
      "132/224, train_loss: 0.1574, step time: 0.3840\n",
      "133/224, train_loss: 0.0914, step time: 0.3152\n",
      "134/224, train_loss: 0.1218, step time: 0.3171\n",
      "135/224, train_loss: 0.0733, step time: 0.3181\n",
      "136/224, train_loss: 0.1488, step time: 0.3177\n",
      "137/224, train_loss: 0.1173, step time: 0.3784\n",
      "138/224, train_loss: 0.0643, step time: 0.3194\n",
      "139/224, train_loss: 0.1031, step time: 0.3891\n",
      "140/224, train_loss: 0.1521, step time: 0.4124\n",
      "141/224, train_loss: 0.2423, step time: 0.4032\n",
      "142/224, train_loss: 0.1579, step time: 0.3703\n",
      "143/224, train_loss: 0.1093, step time: 0.3191\n",
      "144/224, train_loss: 0.3885, step time: 0.3968\n",
      "145/224, train_loss: 0.0977, step time: 0.3192\n",
      "146/224, train_loss: 0.1138, step time: 0.3771\n",
      "147/224, train_loss: 0.0772, step time: 0.3169\n",
      "148/224, train_loss: 0.1783, step time: 0.3964\n",
      "149/224, train_loss: 0.1387, step time: 0.3173\n",
      "150/224, train_loss: 0.1669, step time: 0.3799\n",
      "151/224, train_loss: 0.1023, step time: 0.4074\n",
      "152/224, train_loss: 0.1201, step time: 0.3168\n",
      "153/224, train_loss: 0.0489, step time: 0.3188\n",
      "154/224, train_loss: 0.1392, step time: 0.3162\n",
      "155/224, train_loss: 0.1926, step time: 0.3915\n",
      "156/224, train_loss: 0.0840, step time: 0.3173\n",
      "157/224, train_loss: 0.0974, step time: 0.3192\n",
      "158/224, train_loss: 0.0642, step time: 0.3202\n",
      "159/224, train_loss: 0.1593, step time: 0.3177\n",
      "160/224, train_loss: 0.1863, step time: 0.3199\n",
      "161/224, train_loss: 0.0740, step time: 0.3952\n",
      "162/224, train_loss: 0.1187, step time: 0.3171\n",
      "163/224, train_loss: 0.2412, step time: 0.3901\n",
      "164/224, train_loss: 0.0899, step time: 0.3170\n",
      "165/224, train_loss: 0.1206, step time: 0.3148\n",
      "166/224, train_loss: 0.2831, step time: 0.3800\n",
      "167/224, train_loss: 0.1545, step time: 0.3202\n",
      "168/224, train_loss: 0.1156, step time: 0.4066\n",
      "169/224, train_loss: 0.0938, step time: 0.3191\n",
      "170/224, train_loss: 0.1039, step time: 0.3147\n",
      "171/224, train_loss: 0.1630, step time: 0.3186\n",
      "172/224, train_loss: 0.1454, step time: 0.3142\n",
      "173/224, train_loss: 0.0729, step time: 0.3167\n",
      "174/224, train_loss: 0.1939, step time: 0.3161\n",
      "175/224, train_loss: 0.1234, step time: 0.3831\n",
      "176/224, train_loss: 0.0461, step time: 0.3738\n",
      "177/224, train_loss: 0.1749, step time: 0.3885\n",
      "178/224, train_loss: 0.0880, step time: 0.4116\n",
      "179/224, train_loss: 0.0666, step time: 0.3207\n",
      "180/224, train_loss: 0.1276, step time: 0.3160\n",
      "181/224, train_loss: 0.0936, step time: 0.3177\n",
      "182/224, train_loss: 0.0954, step time: 0.3179\n",
      "183/224, train_loss: 0.1061, step time: 0.3875\n",
      "184/224, train_loss: 0.1436, step time: 0.3169\n",
      "185/224, train_loss: 0.1195, step time: 0.3812\n",
      "186/224, train_loss: 0.1216, step time: 0.3982\n",
      "187/224, train_loss: 0.0689, step time: 0.3201\n",
      "188/224, train_loss: 0.1775, step time: 0.3829\n",
      "189/224, train_loss: 0.1216, step time: 0.4123\n",
      "190/224, train_loss: 0.0759, step time: 0.3207\n",
      "191/224, train_loss: 0.0982, step time: 0.3775\n",
      "192/224, train_loss: 0.2973, step time: 0.3176\n",
      "193/224, train_loss: 0.0858, step time: 0.4062\n",
      "194/224, train_loss: 0.1153, step time: 0.3177\n",
      "195/224, train_loss: 0.3852, step time: 0.3819\n",
      "196/224, train_loss: 0.3837, step time: 0.3197\n",
      "197/224, train_loss: 0.1237, step time: 0.3903\n",
      "198/224, train_loss: 0.1730, step time: 0.3175\n",
      "199/224, train_loss: 0.1037, step time: 0.3197\n",
      "200/224, train_loss: 0.0571, step time: 0.3171\n",
      "201/224, train_loss: 0.1455, step time: 0.3172\n",
      "202/224, train_loss: 0.0870, step time: 0.3670\n",
      "203/224, train_loss: 0.1587, step time: 0.3998\n",
      "204/224, train_loss: 0.3453, step time: 0.3699\n",
      "205/224, train_loss: 0.1139, step time: 0.3189\n",
      "206/224, train_loss: 0.0605, step time: 0.3167\n",
      "207/224, train_loss: 0.0841, step time: 0.3164\n",
      "208/224, train_loss: 0.1003, step time: 0.3170\n",
      "209/224, train_loss: 0.1624, step time: 0.3731\n",
      "210/224, train_loss: 0.0886, step time: 0.3740\n",
      "211/224, train_loss: 0.1054, step time: 0.3755\n",
      "212/224, train_loss: 0.0939, step time: 0.3918\n",
      "213/224, train_loss: 0.1583, step time: 0.3778\n",
      "214/224, train_loss: 0.1112, step time: 0.4128\n",
      "215/224, train_loss: 0.0646, step time: 0.3166\n",
      "216/224, train_loss: 0.1167, step time: 0.3144\n",
      "217/224, train_loss: 0.2014, step time: 0.3948\n",
      "218/224, train_loss: 0.1446, step time: 0.3158\n",
      "219/224, train_loss: 0.2257, step time: 0.3883\n",
      "220/224, train_loss: 0.1141, step time: 0.4088\n",
      "221/224, train_loss: 0.1879, step time: 0.3176\n",
      "222/224, train_loss: 0.1295, step time: 0.3746\n",
      "223/224, train_loss: 0.3194, step time: 0.3787\n",
      "224/224, train_loss: 0.2628, step time: 0.3809\n",
      "epoch 67 average loss: 0.1390\n",
      "current epoch: 67 current mean dice: 0.7001 class1: 0.9993 class2: 0.7285 class3: 0.3725\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 67 is: 711.5639\n",
      "hello\n",
      "----------\n",
      "epoch 68/100\n",
      "1/224, train_loss: 0.1986, step time: 0.3161\n",
      "2/224, train_loss: 0.0610, step time: 0.3175\n",
      "3/224, train_loss: 0.0576, step time: 0.3197\n",
      "4/224, train_loss: 0.0931, step time: 0.3894\n",
      "5/224, train_loss: 0.2059, step time: 0.3842\n",
      "6/224, train_loss: 0.1938, step time: 0.3774\n",
      "7/224, train_loss: 0.0869, step time: 0.3149\n",
      "8/224, train_loss: 0.1260, step time: 0.3130\n",
      "9/224, train_loss: 0.0511, step time: 0.3150\n",
      "10/224, train_loss: 0.0755, step time: 0.3161\n",
      "11/224, train_loss: 0.0754, step time: 0.3156\n",
      "12/224, train_loss: 0.2766, step time: 0.3176\n",
      "13/224, train_loss: 0.1112, step time: 0.3159\n",
      "14/224, train_loss: 0.1854, step time: 0.3168\n",
      "15/224, train_loss: 0.2998, step time: 0.3192\n",
      "16/224, train_loss: 0.1207, step time: 0.3175\n",
      "17/224, train_loss: 0.2231, step time: 0.4094\n",
      "18/224, train_loss: 0.1096, step time: 0.3156\n",
      "19/224, train_loss: 0.2081, step time: 0.3175\n",
      "20/224, train_loss: 0.1237, step time: 0.3960\n",
      "21/224, train_loss: 0.1410, step time: 0.3946\n",
      "22/224, train_loss: 0.1348, step time: 0.3744\n",
      "23/224, train_loss: 0.0858, step time: 0.3139\n",
      "24/224, train_loss: 0.1501, step time: 0.3647\n",
      "25/224, train_loss: 0.2346, step time: 0.3994\n",
      "26/224, train_loss: 0.0907, step time: 0.3163\n",
      "27/224, train_loss: 0.1224, step time: 0.3883\n",
      "28/224, train_loss: 0.0887, step time: 0.3777\n",
      "29/224, train_loss: 0.0959, step time: 0.3994\n",
      "30/224, train_loss: 0.1181, step time: 0.3777\n",
      "31/224, train_loss: 0.0982, step time: 0.3178\n",
      "32/224, train_loss: 0.1369, step time: 0.3902\n",
      "33/224, train_loss: 0.0961, step time: 0.4064\n",
      "34/224, train_loss: 0.0751, step time: 0.3184\n",
      "35/224, train_loss: 0.1372, step time: 0.4092\n",
      "36/224, train_loss: 0.1470, step time: 0.4040\n",
      "37/224, train_loss: 0.2420, step time: 0.4125\n",
      "38/224, train_loss: 0.2022, step time: 0.3804\n",
      "39/224, train_loss: 0.0925, step time: 0.3190\n",
      "40/224, train_loss: 0.1351, step time: 0.3931\n",
      "41/224, train_loss: 0.2425, step time: 0.3187\n",
      "42/224, train_loss: 0.0787, step time: 0.3158\n",
      "43/224, train_loss: 0.0605, step time: 0.3145\n",
      "44/224, train_loss: 0.0921, step time: 0.3166\n",
      "45/224, train_loss: 0.1266, step time: 0.3702\n",
      "46/224, train_loss: 0.1233, step time: 0.3975\n",
      "47/224, train_loss: 0.0904, step time: 0.3137\n",
      "48/224, train_loss: 0.1204, step time: 0.3164\n",
      "49/224, train_loss: 0.1056, step time: 0.3164\n",
      "50/224, train_loss: 0.0662, step time: 0.3856\n",
      "51/224, train_loss: 0.0897, step time: 0.3162\n",
      "52/224, train_loss: 0.0961, step time: 0.3928\n",
      "53/224, train_loss: 0.2023, step time: 0.3185\n",
      "54/224, train_loss: 0.1013, step time: 0.3983\n",
      "55/224, train_loss: 0.0957, step time: 0.4021\n",
      "56/224, train_loss: 0.0999, step time: 0.3164\n",
      "57/224, train_loss: 0.0928, step time: 0.3160\n",
      "58/224, train_loss: 0.1200, step time: 0.3827\n",
      "59/224, train_loss: 0.1293, step time: 0.4066\n",
      "60/224, train_loss: 0.1110, step time: 0.3145\n",
      "61/224, train_loss: 0.2561, step time: 0.3840\n",
      "62/224, train_loss: 0.1408, step time: 0.4047\n",
      "63/224, train_loss: 0.0833, step time: 0.3855\n",
      "64/224, train_loss: 0.1334, step time: 0.3156\n",
      "65/224, train_loss: 0.0886, step time: 0.3818\n",
      "66/224, train_loss: 0.0841, step time: 0.3160\n",
      "67/224, train_loss: 0.0961, step time: 0.3869\n",
      "68/224, train_loss: 0.1605, step time: 0.3191\n",
      "69/224, train_loss: 0.1292, step time: 0.3184\n",
      "70/224, train_loss: 0.0690, step time: 0.3155\n",
      "71/224, train_loss: 0.1127, step time: 0.3187\n",
      "72/224, train_loss: 0.1877, step time: 0.3694\n",
      "73/224, train_loss: 0.0835, step time: 0.3156\n",
      "74/224, train_loss: 0.1164, step time: 0.3161\n",
      "75/224, train_loss: 0.0836, step time: 0.3910\n",
      "76/224, train_loss: 0.1633, step time: 0.3159\n",
      "77/224, train_loss: 0.0637, step time: 0.3131\n",
      "78/224, train_loss: 0.2613, step time: 0.3975\n",
      "79/224, train_loss: 0.1128, step time: 0.3135\n",
      "80/224, train_loss: 0.1578, step time: 0.3677\n",
      "81/224, train_loss: 0.0783, step time: 0.4101\n",
      "82/224, train_loss: 0.1299, step time: 0.4015\n",
      "83/224, train_loss: 0.1575, step time: 0.3162\n",
      "84/224, train_loss: 0.1264, step time: 0.3140\n",
      "85/224, train_loss: 0.0746, step time: 0.3818\n",
      "86/224, train_loss: 0.1497, step time: 0.4009\n",
      "87/224, train_loss: 0.0843, step time: 0.3161\n",
      "88/224, train_loss: 0.0747, step time: 0.3161\n",
      "89/224, train_loss: 0.1639, step time: 0.3155\n",
      "90/224, train_loss: 0.0812, step time: 0.3153\n",
      "91/224, train_loss: 0.1366, step time: 0.4036\n",
      "92/224, train_loss: 0.2088, step time: 0.4075\n",
      "93/224, train_loss: 0.1530, step time: 0.3737\n",
      "94/224, train_loss: 0.1167, step time: 0.3153\n",
      "95/224, train_loss: 0.1504, step time: 0.3156\n",
      "96/224, train_loss: 0.3364, step time: 0.3976\n",
      "97/224, train_loss: 0.0622, step time: 0.3155\n",
      "98/224, train_loss: 0.1747, step time: 0.3177\n",
      "99/224, train_loss: 0.0998, step time: 0.3722\n",
      "100/224, train_loss: 0.1497, step time: 0.3150\n",
      "101/224, train_loss: 0.3470, step time: 0.3174\n",
      "102/224, train_loss: 0.1998, step time: 0.3171\n",
      "103/224, train_loss: 0.0565, step time: 0.3149\n",
      "104/224, train_loss: 0.1678, step time: 0.3140\n",
      "105/224, train_loss: 0.1034, step time: 0.3161\n",
      "106/224, train_loss: 0.0603, step time: 0.3173\n",
      "107/224, train_loss: 0.0981, step time: 0.3151\n",
      "108/224, train_loss: 0.0969, step time: 0.3151\n",
      "109/224, train_loss: 0.1630, step time: 0.3156\n",
      "110/224, train_loss: 0.1305, step time: 0.3152\n",
      "111/224, train_loss: 0.1166, step time: 0.3978\n",
      "112/224, train_loss: 0.1138, step time: 0.3154\n",
      "113/224, train_loss: 0.0698, step time: 0.3158\n",
      "114/224, train_loss: 0.0931, step time: 0.3158\n",
      "115/224, train_loss: 0.0606, step time: 0.3176\n",
      "116/224, train_loss: 0.1290, step time: 0.3865\n",
      "117/224, train_loss: 0.0858, step time: 0.3156\n",
      "118/224, train_loss: 0.2323, step time: 0.4091\n",
      "119/224, train_loss: 0.1494, step time: 0.3728\n",
      "120/224, train_loss: 0.3039, step time: 0.3156\n",
      "121/224, train_loss: 0.2497, step time: 0.4024\n",
      "122/224, train_loss: 0.0736, step time: 0.3162\n",
      "123/224, train_loss: 0.0776, step time: 0.3180\n",
      "124/224, train_loss: 0.1588, step time: 0.3790\n",
      "125/224, train_loss: 0.0639, step time: 0.3723\n",
      "126/224, train_loss: 0.0985, step time: 0.3165\n",
      "127/224, train_loss: 0.1817, step time: 0.3868\n",
      "128/224, train_loss: 0.0687, step time: 0.3175\n",
      "129/224, train_loss: 0.0490, step time: 0.3157\n",
      "130/224, train_loss: 0.0929, step time: 0.4026\n",
      "131/224, train_loss: 0.0851, step time: 0.3159\n",
      "132/224, train_loss: 0.1067, step time: 0.3842\n",
      "133/224, train_loss: 0.0852, step time: 0.3167\n",
      "134/224, train_loss: 0.0884, step time: 0.3712\n",
      "135/224, train_loss: 0.0976, step time: 0.3909\n",
      "136/224, train_loss: 0.0874, step time: 0.4081\n",
      "137/224, train_loss: 0.0658, step time: 0.3123\n",
      "138/224, train_loss: 0.1244, step time: 0.3144\n",
      "139/224, train_loss: 0.0553, step time: 0.3175\n",
      "140/224, train_loss: 0.0911, step time: 0.3174\n",
      "141/224, train_loss: 0.1025, step time: 0.3129\n",
      "142/224, train_loss: 0.1313, step time: 0.3655\n",
      "143/224, train_loss: 0.3745, step time: 0.3842\n",
      "144/224, train_loss: 0.0913, step time: 0.3854\n",
      "145/224, train_loss: 0.0756, step time: 0.3144\n",
      "146/224, train_loss: 0.1027, step time: 0.4033\n",
      "147/224, train_loss: 0.0766, step time: 0.3124\n",
      "148/224, train_loss: 0.1061, step time: 0.3122\n",
      "149/224, train_loss: 0.1554, step time: 0.3174\n",
      "150/224, train_loss: 0.2560, step time: 0.3153\n",
      "151/224, train_loss: 0.0950, step time: 0.3694\n",
      "152/224, train_loss: 0.2104, step time: 0.4038\n",
      "153/224, train_loss: 0.1568, step time: 0.3847\n",
      "154/224, train_loss: 0.1496, step time: 0.3878\n",
      "155/224, train_loss: 0.1555, step time: 0.3147\n",
      "156/224, train_loss: 0.1138, step time: 0.3991\n",
      "157/224, train_loss: 0.1227, step time: 0.3770\n",
      "158/224, train_loss: 0.1128, step time: 0.3874\n",
      "159/224, train_loss: 0.1958, step time: 0.3888\n",
      "160/224, train_loss: 0.0987, step time: 0.3141\n",
      "161/224, train_loss: 0.0792, step time: 0.3736\n",
      "162/224, train_loss: 0.2057, step time: 0.3948\n",
      "163/224, train_loss: 0.1364, step time: 0.4031\n",
      "164/224, train_loss: 0.0883, step time: 0.3163\n",
      "165/224, train_loss: 0.3570, step time: 0.3169\n",
      "166/224, train_loss: 0.0961, step time: 0.3968\n",
      "167/224, train_loss: 0.0656, step time: 0.3141\n",
      "168/224, train_loss: 0.1285, step time: 0.3142\n",
      "169/224, train_loss: 0.3152, step time: 0.3164\n",
      "170/224, train_loss: 0.2211, step time: 0.3867\n",
      "171/224, train_loss: 0.0971, step time: 0.3142\n",
      "172/224, train_loss: 0.1054, step time: 0.3142\n",
      "173/224, train_loss: 0.0889, step time: 0.3120\n",
      "174/224, train_loss: 0.1188, step time: 0.3144\n",
      "175/224, train_loss: 0.1477, step time: 0.3746\n",
      "176/224, train_loss: 0.1201, step time: 0.3148\n",
      "177/224, train_loss: 0.0967, step time: 0.3147\n",
      "178/224, train_loss: 0.0613, step time: 0.3142\n",
      "179/224, train_loss: 0.1222, step time: 0.3144\n",
      "180/224, train_loss: 0.1397, step time: 0.3140\n",
      "181/224, train_loss: 0.0707, step time: 0.3129\n",
      "182/224, train_loss: 0.1473, step time: 0.3174\n",
      "183/224, train_loss: 0.1083, step time: 0.3149\n",
      "184/224, train_loss: 0.1102, step time: 0.3766\n",
      "185/224, train_loss: 0.0863, step time: 0.3870\n",
      "186/224, train_loss: 0.0819, step time: 0.3885\n",
      "187/224, train_loss: 0.0888, step time: 0.3917\n",
      "188/224, train_loss: 0.0500, step time: 0.3704\n",
      "189/224, train_loss: 0.2143, step time: 0.3686\n",
      "190/224, train_loss: 0.1153, step time: 0.3153\n",
      "191/224, train_loss: 0.0953, step time: 0.3152\n",
      "192/224, train_loss: 0.0363, step time: 0.3981\n",
      "193/224, train_loss: 0.0688, step time: 0.3157\n",
      "194/224, train_loss: 0.1292, step time: 0.3696\n",
      "195/224, train_loss: 0.2705, step time: 0.3682\n",
      "196/224, train_loss: 0.2066, step time: 0.3133\n",
      "197/224, train_loss: 0.1398, step time: 0.3862\n",
      "198/224, train_loss: 0.1011, step time: 0.3120\n",
      "199/224, train_loss: 0.1256, step time: 0.3140\n",
      "200/224, train_loss: 0.1089, step time: 0.3142\n",
      "201/224, train_loss: 0.1121, step time: 0.3121\n",
      "202/224, train_loss: 0.1168, step time: 0.3145\n",
      "203/224, train_loss: 0.1416, step time: 0.4080\n",
      "204/224, train_loss: 0.3217, step time: 0.3144\n",
      "205/224, train_loss: 0.0657, step time: 0.3142\n",
      "206/224, train_loss: 0.1885, step time: 0.3866\n",
      "207/224, train_loss: 0.1680, step time: 0.3169\n",
      "208/224, train_loss: 0.0486, step time: 0.3143\n",
      "209/224, train_loss: 0.0558, step time: 0.3126\n",
      "210/224, train_loss: 0.1298, step time: 0.3841\n",
      "211/224, train_loss: 0.0827, step time: 0.3147\n",
      "212/224, train_loss: 0.1834, step time: 0.3697\n",
      "213/224, train_loss: 0.0852, step time: 0.3175\n",
      "214/224, train_loss: 0.4663, step time: 0.3816\n",
      "215/224, train_loss: 0.1041, step time: 0.3177\n",
      "216/224, train_loss: 0.1419, step time: 0.3942\n",
      "217/224, train_loss: 0.0975, step time: 0.3148\n",
      "218/224, train_loss: 0.2619, step time: 0.3674\n",
      "219/224, train_loss: 0.1530, step time: 0.3727\n",
      "220/224, train_loss: 0.1202, step time: 0.3171\n",
      "221/224, train_loss: 0.1777, step time: 0.3757\n",
      "222/224, train_loss: 0.1183, step time: 0.3784\n",
      "223/224, train_loss: 0.1215, step time: 0.3931\n",
      "224/224, train_loss: 0.1631, step time: 0.4071\n",
      "epoch 68 average loss: 0.1316\n",
      "current epoch: 68 current mean dice: 0.6981 class1: 0.9993 class2: 0.7188 class3: 0.3763\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 68 is: 652.7391\n",
      "hello\n",
      "----------\n",
      "epoch 69/100\n",
      "1/224, train_loss: 0.1636, step time: 0.3637\n",
      "2/224, train_loss: 0.2348, step time: 0.3789\n",
      "3/224, train_loss: 0.0989, step time: 0.3625\n",
      "4/224, train_loss: 0.2949, step time: 0.3725\n",
      "5/224, train_loss: 0.1368, step time: 0.3147\n",
      "6/224, train_loss: 0.1407, step time: 0.3659\n",
      "7/224, train_loss: 0.1638, step time: 0.3867\n",
      "8/224, train_loss: 0.1223, step time: 0.3151\n",
      "9/224, train_loss: 0.1317, step time: 0.3152\n",
      "10/224, train_loss: 0.0920, step time: 0.3151\n",
      "11/224, train_loss: 0.0800, step time: 0.3718\n",
      "12/224, train_loss: 0.1355, step time: 0.3174\n",
      "13/224, train_loss: 0.1618, step time: 0.3148\n",
      "14/224, train_loss: 0.1369, step time: 0.3894\n",
      "15/224, train_loss: 0.0946, step time: 0.3153\n",
      "16/224, train_loss: 0.0774, step time: 0.3144\n",
      "17/224, train_loss: 0.1250, step time: 0.3150\n",
      "18/224, train_loss: 0.1338, step time: 0.3171\n",
      "19/224, train_loss: 0.0664, step time: 0.3166\n",
      "20/224, train_loss: 0.1445, step time: 0.4003\n",
      "21/224, train_loss: 0.0893, step time: 0.4006\n",
      "22/224, train_loss: 0.1006, step time: 0.4030\n",
      "23/224, train_loss: 0.1766, step time: 0.3991\n",
      "24/224, train_loss: 0.2485, step time: 0.3170\n",
      "25/224, train_loss: 0.0987, step time: 0.3147\n",
      "26/224, train_loss: 0.1607, step time: 0.3744\n",
      "27/224, train_loss: 0.4028, step time: 0.4074\n",
      "28/224, train_loss: 0.1346, step time: 0.3142\n",
      "29/224, train_loss: 0.1142, step time: 0.3143\n",
      "30/224, train_loss: 0.2783, step time: 0.3142\n",
      "31/224, train_loss: 0.3251, step time: 0.3728\n",
      "32/224, train_loss: 0.0910, step time: 0.4082\n",
      "33/224, train_loss: 0.2468, step time: 0.3771\n",
      "34/224, train_loss: 0.0754, step time: 0.3146\n",
      "35/224, train_loss: 0.0758, step time: 0.3747\n",
      "36/224, train_loss: 0.2284, step time: 0.3701\n",
      "37/224, train_loss: 0.1005, step time: 0.3167\n",
      "38/224, train_loss: 0.0835, step time: 0.4069\n",
      "39/224, train_loss: 0.1227, step time: 0.3149\n",
      "40/224, train_loss: 0.1588, step time: 0.3906\n",
      "41/224, train_loss: 0.1267, step time: 0.3858\n",
      "42/224, train_loss: 0.2364, step time: 0.4039\n",
      "43/224, train_loss: 0.1293, step time: 0.3933\n",
      "44/224, train_loss: 0.0747, step time: 0.4001\n",
      "45/224, train_loss: 0.1066, step time: 0.3138\n",
      "46/224, train_loss: 0.1437, step time: 0.3157\n",
      "47/224, train_loss: 0.1957, step time: 0.3156\n",
      "48/224, train_loss: 0.3035, step time: 0.3154\n",
      "49/224, train_loss: 0.1291, step time: 0.3147\n",
      "50/224, train_loss: 0.1066, step time: 0.3152\n",
      "51/224, train_loss: 0.1291, step time: 0.3156\n",
      "52/224, train_loss: 0.1078, step time: 0.3152\n",
      "53/224, train_loss: 0.2500, step time: 0.4017\n",
      "54/224, train_loss: 0.2300, step time: 0.3177\n",
      "55/224, train_loss: 0.1476, step time: 0.3766\n",
      "56/224, train_loss: 0.1530, step time: 0.4109\n",
      "57/224, train_loss: 0.1528, step time: 0.3742\n",
      "58/224, train_loss: 0.0641, step time: 0.3170\n",
      "59/224, train_loss: 0.1260, step time: 0.4085\n",
      "60/224, train_loss: 0.3536, step time: 0.3145\n",
      "61/224, train_loss: 0.1400, step time: 0.3151\n",
      "62/224, train_loss: 0.1134, step time: 0.3954\n",
      "63/224, train_loss: 0.1041, step time: 0.3168\n",
      "64/224, train_loss: 0.0944, step time: 0.3810\n",
      "65/224, train_loss: 0.2330, step time: 0.3691\n",
      "66/224, train_loss: 0.1104, step time: 0.3173\n",
      "67/224, train_loss: 0.1198, step time: 0.3167\n",
      "68/224, train_loss: 0.1042, step time: 0.3160\n",
      "69/224, train_loss: 0.0853, step time: 0.3126\n",
      "70/224, train_loss: 0.0830, step time: 0.3151\n",
      "71/224, train_loss: 0.1235, step time: 0.3150\n",
      "72/224, train_loss: 0.1297, step time: 0.4082\n",
      "73/224, train_loss: 0.1013, step time: 0.4009\n",
      "74/224, train_loss: 0.0788, step time: 0.3147\n",
      "75/224, train_loss: 0.1225, step time: 0.3840\n",
      "76/224, train_loss: 0.2682, step time: 0.3176\n",
      "77/224, train_loss: 0.0790, step time: 0.3151\n",
      "78/224, train_loss: 0.0581, step time: 0.3173\n",
      "79/224, train_loss: 0.1232, step time: 0.3156\n",
      "80/224, train_loss: 0.1188, step time: 0.3805\n",
      "81/224, train_loss: 0.0993, step time: 0.3174\n",
      "82/224, train_loss: 0.1452, step time: 0.4001\n",
      "83/224, train_loss: 0.1228, step time: 0.3150\n",
      "84/224, train_loss: 0.1965, step time: 0.3900\n",
      "85/224, train_loss: 0.0845, step time: 0.3935\n",
      "86/224, train_loss: 0.0820, step time: 0.3766\n",
      "87/224, train_loss: 0.1269, step time: 0.3175\n",
      "88/224, train_loss: 0.0463, step time: 0.3170\n",
      "89/224, train_loss: 0.1524, step time: 0.3154\n",
      "90/224, train_loss: 0.0817, step time: 0.3986\n",
      "91/224, train_loss: 0.1165, step time: 0.4012\n",
      "92/224, train_loss: 0.0912, step time: 0.3178\n",
      "93/224, train_loss: 0.1034, step time: 0.3127\n",
      "94/224, train_loss: 0.1146, step time: 0.4100\n",
      "95/224, train_loss: 0.1185, step time: 0.3958\n",
      "96/224, train_loss: 0.0946, step time: 0.3127\n",
      "97/224, train_loss: 0.1448, step time: 0.3172\n",
      "98/224, train_loss: 0.1051, step time: 0.3750\n",
      "99/224, train_loss: 0.1047, step time: 0.3151\n",
      "100/224, train_loss: 0.0875, step time: 0.3177\n",
      "101/224, train_loss: 0.0973, step time: 0.3156\n",
      "102/224, train_loss: 0.1120, step time: 0.3158\n",
      "103/224, train_loss: 0.1060, step time: 0.3758\n",
      "104/224, train_loss: 0.0680, step time: 0.3181\n",
      "105/224, train_loss: 0.0759, step time: 0.3932\n",
      "106/224, train_loss: 0.1259, step time: 0.3712\n",
      "107/224, train_loss: 0.1564, step time: 0.3926\n",
      "108/224, train_loss: 0.1024, step time: 0.3960\n",
      "109/224, train_loss: 0.1348, step time: 0.4077\n",
      "110/224, train_loss: 0.1647, step time: 0.3837\n",
      "111/224, train_loss: 0.1172, step time: 0.3182\n",
      "112/224, train_loss: 0.1133, step time: 0.3153\n",
      "113/224, train_loss: 0.1653, step time: 0.3153\n",
      "114/224, train_loss: 0.0719, step time: 0.3134\n",
      "115/224, train_loss: 0.1894, step time: 0.4047\n",
      "116/224, train_loss: 0.0470, step time: 0.3187\n",
      "117/224, train_loss: 0.1211, step time: 0.3162\n",
      "118/224, train_loss: 0.0594, step time: 0.3136\n",
      "119/224, train_loss: 0.0513, step time: 0.3987\n",
      "120/224, train_loss: 0.1321, step time: 0.3688\n",
      "121/224, train_loss: 0.0635, step time: 0.3180\n",
      "122/224, train_loss: 0.0898, step time: 0.3916\n",
      "123/224, train_loss: 0.0775, step time: 0.3159\n",
      "124/224, train_loss: 0.0903, step time: 0.3155\n",
      "125/224, train_loss: 0.2281, step time: 0.3130\n",
      "126/224, train_loss: 0.0709, step time: 0.3175\n",
      "127/224, train_loss: 0.2132, step time: 0.4058\n",
      "128/224, train_loss: 0.0753, step time: 0.3156\n",
      "129/224, train_loss: 0.0981, step time: 0.3722\n",
      "130/224, train_loss: 0.0673, step time: 0.4079\n",
      "131/224, train_loss: 0.1496, step time: 0.3160\n",
      "132/224, train_loss: 0.1266, step time: 0.3834\n",
      "133/224, train_loss: 0.0942, step time: 0.3162\n",
      "134/224, train_loss: 0.0706, step time: 0.3947\n",
      "135/224, train_loss: 0.1194, step time: 0.3185\n",
      "136/224, train_loss: 0.3447, step time: 0.4031\n",
      "137/224, train_loss: 0.1610, step time: 0.3186\n",
      "138/224, train_loss: 0.2448, step time: 0.3137\n",
      "139/224, train_loss: 0.1675, step time: 0.3176\n",
      "140/224, train_loss: 0.1307, step time: 0.3152\n",
      "141/224, train_loss: 0.1237, step time: 0.3151\n",
      "142/224, train_loss: 0.0993, step time: 0.3157\n",
      "143/224, train_loss: 0.1636, step time: 0.3721\n",
      "144/224, train_loss: 0.0860, step time: 0.3836\n",
      "145/224, train_loss: 0.1825, step time: 0.3939\n",
      "146/224, train_loss: 0.1009, step time: 0.3157\n",
      "147/224, train_loss: 0.1338, step time: 0.3957\n",
      "148/224, train_loss: 0.0999, step time: 0.3810\n",
      "149/224, train_loss: 0.1654, step time: 0.4011\n",
      "150/224, train_loss: 0.0975, step time: 0.3203\n",
      "151/224, train_loss: 0.1745, step time: 0.3164\n",
      "152/224, train_loss: 0.1465, step time: 0.3161\n",
      "153/224, train_loss: 0.1021, step time: 0.3176\n",
      "154/224, train_loss: 0.0912, step time: 0.4099\n",
      "155/224, train_loss: 0.0726, step time: 0.3143\n",
      "156/224, train_loss: 0.1131, step time: 0.3155\n",
      "157/224, train_loss: 0.2493, step time: 0.3766\n",
      "158/224, train_loss: 0.0611, step time: 0.4036\n",
      "159/224, train_loss: 0.3388, step time: 0.3177\n",
      "160/224, train_loss: 0.2586, step time: 0.3132\n",
      "161/224, train_loss: 0.2723, step time: 0.3787\n",
      "162/224, train_loss: 0.0782, step time: 0.3184\n",
      "163/224, train_loss: 0.1845, step time: 0.4134\n",
      "164/224, train_loss: 0.2207, step time: 0.3174\n",
      "165/224, train_loss: 0.0777, step time: 0.3152\n",
      "166/224, train_loss: 0.0966, step time: 0.3734\n",
      "167/224, train_loss: 0.3296, step time: 0.3151\n",
      "168/224, train_loss: 0.0695, step time: 0.3151\n",
      "169/224, train_loss: 0.1617, step time: 0.3158\n",
      "170/224, train_loss: 0.1917, step time: 0.3738\n",
      "171/224, train_loss: 0.1135, step time: 0.3156\n",
      "172/224, train_loss: 0.1521, step time: 0.3132\n",
      "173/224, train_loss: 0.1069, step time: 0.3129\n",
      "174/224, train_loss: 0.1257, step time: 0.3130\n",
      "175/224, train_loss: 0.0726, step time: 0.3179\n",
      "176/224, train_loss: 0.0722, step time: 0.3137\n",
      "177/224, train_loss: 0.2310, step time: 0.3182\n",
      "178/224, train_loss: 0.1317, step time: 0.3161\n",
      "179/224, train_loss: 0.1067, step time: 0.3177\n",
      "180/224, train_loss: 0.1144, step time: 0.3738\n",
      "181/224, train_loss: 0.2496, step time: 0.3182\n",
      "182/224, train_loss: 0.0944, step time: 0.3152\n",
      "183/224, train_loss: 0.1218, step time: 0.3152\n",
      "184/224, train_loss: 0.0792, step time: 0.3152\n",
      "185/224, train_loss: 0.0603, step time: 0.3135\n",
      "186/224, train_loss: 0.0779, step time: 0.3175\n",
      "187/224, train_loss: 0.0902, step time: 0.3150\n",
      "188/224, train_loss: 0.0683, step time: 0.3150\n",
      "189/224, train_loss: 0.1156, step time: 0.3980\n",
      "190/224, train_loss: 0.0978, step time: 0.3160\n",
      "191/224, train_loss: 0.1423, step time: 0.3181\n",
      "192/224, train_loss: 0.0867, step time: 0.3154\n",
      "193/224, train_loss: 0.1527, step time: 0.3130\n",
      "194/224, train_loss: 0.0758, step time: 0.3147\n",
      "195/224, train_loss: 0.0765, step time: 0.4011\n",
      "196/224, train_loss: 0.0747, step time: 0.3161\n",
      "197/224, train_loss: 0.1247, step time: 0.3156\n",
      "198/224, train_loss: 0.2544, step time: 0.4077\n",
      "199/224, train_loss: 0.0901, step time: 0.4116\n",
      "200/224, train_loss: 0.1215, step time: 0.3156\n",
      "201/224, train_loss: 0.1086, step time: 0.4026\n",
      "202/224, train_loss: 0.1764, step time: 0.3747\n",
      "203/224, train_loss: 0.1053, step time: 0.3709\n",
      "204/224, train_loss: 0.0720, step time: 0.3882\n",
      "205/224, train_loss: 0.1027, step time: 0.3161\n",
      "206/224, train_loss: 0.0795, step time: 0.3856\n",
      "207/224, train_loss: 0.1410, step time: 0.3760\n",
      "208/224, train_loss: 0.1559, step time: 0.3943\n",
      "209/224, train_loss: 0.0514, step time: 0.3177\n",
      "210/224, train_loss: 0.1133, step time: 0.3136\n",
      "211/224, train_loss: 0.0715, step time: 0.3155\n",
      "212/224, train_loss: 0.2352, step time: 0.4041\n",
      "213/224, train_loss: 0.0836, step time: 0.3151\n",
      "214/224, train_loss: 0.1436, step time: 0.3969\n",
      "215/224, train_loss: 0.1129, step time: 0.3138\n",
      "216/224, train_loss: 0.0954, step time: 0.3921\n",
      "217/224, train_loss: 0.1154, step time: 0.3156\n",
      "218/224, train_loss: 0.1184, step time: 0.4064\n",
      "219/224, train_loss: 0.2327, step time: 0.3698\n",
      "220/224, train_loss: 0.0790, step time: 0.3155\n",
      "221/224, train_loss: 0.1167, step time: 0.3153\n",
      "222/224, train_loss: 0.1216, step time: 0.3757\n",
      "223/224, train_loss: 0.0830, step time: 0.3994\n",
      "224/224, train_loss: 0.0926, step time: 0.3970\n",
      "epoch 69 average loss: 0.1324\n",
      "current epoch: 69 current mean dice: 0.6910 class1: 0.9994 class2: 0.7555 class3: 0.3182\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 69 is: 639.6018\n",
      "hello\n",
      "----------\n",
      "epoch 70/100\n",
      "1/224, train_loss: 0.1911, step time: 0.3815\n",
      "2/224, train_loss: 0.0926, step time: 0.4107\n",
      "3/224, train_loss: 0.2804, step time: 0.4068\n",
      "4/224, train_loss: 0.0904, step time: 0.3941\n",
      "5/224, train_loss: 0.0889, step time: 0.3158\n",
      "6/224, train_loss: 0.2078, step time: 0.3737\n",
      "7/224, train_loss: 0.0794, step time: 0.3156\n",
      "8/224, train_loss: 0.2475, step time: 0.3153\n",
      "9/224, train_loss: 0.1834, step time: 0.3151\n",
      "10/224, train_loss: 0.1152, step time: 0.4037\n",
      "11/224, train_loss: 0.0834, step time: 0.3151\n",
      "12/224, train_loss: 0.1898, step time: 0.4064\n",
      "13/224, train_loss: 0.1186, step time: 0.3158\n",
      "14/224, train_loss: 0.0945, step time: 0.3182\n",
      "15/224, train_loss: 0.3888, step time: 0.3861\n",
      "16/224, train_loss: 0.0908, step time: 0.3143\n",
      "17/224, train_loss: 0.1749, step time: 0.3177\n",
      "18/224, train_loss: 0.1438, step time: 0.4005\n",
      "19/224, train_loss: 0.0675, step time: 0.3996\n",
      "20/224, train_loss: 0.0879, step time: 0.3178\n",
      "21/224, train_loss: 0.1447, step time: 0.3152\n",
      "22/224, train_loss: 0.1141, step time: 0.3777\n",
      "23/224, train_loss: 0.1786, step time: 0.3827\n",
      "24/224, train_loss: 0.0543, step time: 0.3178\n",
      "25/224, train_loss: 0.1632, step time: 0.3962\n",
      "26/224, train_loss: 0.1305, step time: 0.4047\n",
      "27/224, train_loss: 0.0983, step time: 0.4116\n",
      "28/224, train_loss: 0.0969, step time: 0.3916\n",
      "29/224, train_loss: 0.1892, step time: 0.3854\n",
      "30/224, train_loss: 0.2357, step time: 0.3963\n",
      "31/224, train_loss: 0.2507, step time: 0.3838\n",
      "32/224, train_loss: 0.1399, step time: 0.3846\n",
      "33/224, train_loss: 0.0552, step time: 0.3173\n",
      "34/224, train_loss: 0.0706, step time: 0.3972\n",
      "35/224, train_loss: 0.0886, step time: 0.4066\n",
      "36/224, train_loss: 0.1324, step time: 0.3155\n",
      "37/224, train_loss: 0.1842, step time: 0.3153\n",
      "38/224, train_loss: 0.1748, step time: 0.3176\n",
      "39/224, train_loss: 0.2959, step time: 0.3867\n",
      "40/224, train_loss: 0.0913, step time: 0.3779\n",
      "41/224, train_loss: 0.1054, step time: 0.3894\n",
      "42/224, train_loss: 0.0530, step time: 0.3158\n",
      "43/224, train_loss: 0.1271, step time: 0.3158\n",
      "44/224, train_loss: 0.1834, step time: 0.3166\n",
      "45/224, train_loss: 0.2147, step time: 0.3822\n",
      "46/224, train_loss: 0.1531, step time: 0.3675\n",
      "47/224, train_loss: 0.1600, step time: 0.3902\n",
      "48/224, train_loss: 0.0569, step time: 0.3186\n",
      "49/224, train_loss: 0.0720, step time: 0.3756\n",
      "50/224, train_loss: 0.0649, step time: 0.3137\n",
      "51/224, train_loss: 0.1049, step time: 0.3155\n",
      "52/224, train_loss: 0.0598, step time: 0.3178\n",
      "53/224, train_loss: 0.0615, step time: 0.3160\n",
      "54/224, train_loss: 0.0514, step time: 0.3158\n",
      "55/224, train_loss: 0.1063, step time: 0.3848\n",
      "56/224, train_loss: 0.3405, step time: 0.4018\n",
      "57/224, train_loss: 0.2585, step time: 0.3794\n",
      "58/224, train_loss: 0.1259, step time: 0.3759\n",
      "59/224, train_loss: 0.3426, step time: 0.3877\n",
      "60/224, train_loss: 0.0707, step time: 0.3952\n",
      "61/224, train_loss: 0.0776, step time: 0.3181\n",
      "62/224, train_loss: 0.1417, step time: 0.3143\n",
      "63/224, train_loss: 0.1051, step time: 0.3783\n",
      "64/224, train_loss: 0.0972, step time: 0.3164\n",
      "65/224, train_loss: 0.1322, step time: 0.4098\n",
      "66/224, train_loss: 0.1108, step time: 0.3176\n",
      "67/224, train_loss: 0.2693, step time: 0.3875\n",
      "68/224, train_loss: 0.1089, step time: 0.3719\n",
      "69/224, train_loss: 0.1836, step time: 0.3673\n",
      "70/224, train_loss: 0.2987, step time: 0.3939\n",
      "71/224, train_loss: 0.0808, step time: 0.3130\n",
      "72/224, train_loss: 0.0560, step time: 0.3179\n",
      "73/224, train_loss: 0.1050, step time: 0.3723\n",
      "74/224, train_loss: 0.0958, step time: 0.3152\n",
      "75/224, train_loss: 0.3574, step time: 0.3975\n",
      "76/224, train_loss: 0.1810, step time: 0.3776\n",
      "77/224, train_loss: 0.1100, step time: 0.3162\n",
      "78/224, train_loss: 0.1531, step time: 0.3157\n",
      "79/224, train_loss: 0.3492, step time: 0.3790\n",
      "80/224, train_loss: 0.1232, step time: 0.3832\n",
      "81/224, train_loss: 0.1386, step time: 0.3737\n",
      "82/224, train_loss: 0.1027, step time: 0.3154\n",
      "83/224, train_loss: 0.1586, step time: 0.4054\n",
      "84/224, train_loss: 0.0708, step time: 0.3142\n",
      "85/224, train_loss: 0.0947, step time: 0.4013\n",
      "86/224, train_loss: 0.2317, step time: 0.3659\n",
      "87/224, train_loss: 0.1308, step time: 0.3162\n",
      "88/224, train_loss: 0.0923, step time: 0.3152\n",
      "89/224, train_loss: 0.0658, step time: 0.3173\n",
      "90/224, train_loss: 0.1001, step time: 0.3155\n",
      "91/224, train_loss: 0.1197, step time: 0.3156\n",
      "92/224, train_loss: 0.1197, step time: 0.3835\n",
      "93/224, train_loss: 0.1312, step time: 0.3757\n",
      "94/224, train_loss: 0.0853, step time: 0.3178\n",
      "95/224, train_loss: 0.0823, step time: 0.3741\n",
      "96/224, train_loss: 0.1906, step time: 0.3177\n",
      "97/224, train_loss: 0.1015, step time: 0.3161\n",
      "98/224, train_loss: 0.1977, step time: 0.3988\n",
      "99/224, train_loss: 0.3219, step time: 0.3798\n",
      "100/224, train_loss: 0.1090, step time: 0.3150\n",
      "101/224, train_loss: 0.1155, step time: 0.3675\n",
      "102/224, train_loss: 0.2540, step time: 0.3744\n",
      "103/224, train_loss: 0.1445, step time: 0.3875\n",
      "104/224, train_loss: 0.0695, step time: 0.3961\n",
      "105/224, train_loss: 0.1136, step time: 0.3148\n",
      "106/224, train_loss: 0.1491, step time: 0.3145\n",
      "107/224, train_loss: 0.1435, step time: 0.3167\n",
      "108/224, train_loss: 0.0829, step time: 0.3144\n",
      "109/224, train_loss: 0.1409, step time: 0.3178\n",
      "110/224, train_loss: 0.1256, step time: 0.3878\n",
      "111/224, train_loss: 0.1679, step time: 0.4028\n",
      "112/224, train_loss: 0.0655, step time: 0.3152\n",
      "113/224, train_loss: 0.0631, step time: 0.3174\n",
      "114/224, train_loss: 0.0725, step time: 0.3660\n",
      "115/224, train_loss: 0.0753, step time: 0.3128\n",
      "116/224, train_loss: 0.1014, step time: 0.3781\n",
      "117/224, train_loss: 0.3446, step time: 0.3904\n",
      "118/224, train_loss: 0.1116, step time: 0.3910\n",
      "119/224, train_loss: 0.1366, step time: 0.4088\n",
      "120/224, train_loss: 0.1349, step time: 0.4101\n",
      "121/224, train_loss: 0.3327, step time: 0.3715\n",
      "122/224, train_loss: 0.0931, step time: 0.3183\n",
      "123/224, train_loss: 0.2064, step time: 0.3793\n",
      "124/224, train_loss: 0.1239, step time: 0.4130\n",
      "125/224, train_loss: 0.0981, step time: 0.3178\n",
      "126/224, train_loss: 0.1152, step time: 0.4056\n",
      "127/224, train_loss: 0.2448, step time: 0.4119\n",
      "128/224, train_loss: 0.1955, step time: 0.4100\n",
      "129/224, train_loss: 0.0892, step time: 0.3784\n",
      "130/224, train_loss: 0.0743, step time: 0.3181\n",
      "131/224, train_loss: 0.0799, step time: 0.3197\n",
      "132/224, train_loss: 0.1552, step time: 0.3945\n",
      "133/224, train_loss: 0.0745, step time: 0.3832\n",
      "134/224, train_loss: 0.2129, step time: 0.3862\n",
      "135/224, train_loss: 0.1682, step time: 0.4002\n",
      "136/224, train_loss: 0.1233, step time: 0.3175\n",
      "137/224, train_loss: 0.1463, step time: 0.3202\n",
      "138/224, train_loss: 0.2533, step time: 0.3745\n",
      "139/224, train_loss: 0.1112, step time: 0.3163\n",
      "140/224, train_loss: 0.2010, step time: 0.3797\n",
      "141/224, train_loss: 0.0777, step time: 0.3206\n",
      "142/224, train_loss: 0.3309, step time: 0.3870\n",
      "143/224, train_loss: 0.1107, step time: 0.3145\n",
      "144/224, train_loss: 0.1185, step time: 0.3703\n",
      "145/224, train_loss: 0.3079, step time: 0.3752\n",
      "146/224, train_loss: 0.1797, step time: 0.3855\n",
      "147/224, train_loss: 0.0855, step time: 0.4064\n",
      "148/224, train_loss: 0.0496, step time: 0.4142\n",
      "149/224, train_loss: 0.0721, step time: 0.3202\n",
      "150/224, train_loss: 0.1360, step time: 0.3175\n",
      "151/224, train_loss: 0.1465, step time: 0.3167\n",
      "152/224, train_loss: 0.1369, step time: 0.4049\n",
      "153/224, train_loss: 0.0740, step time: 0.3200\n",
      "154/224, train_loss: 0.0856, step time: 0.3857\n",
      "155/224, train_loss: 0.1078, step time: 0.3190\n",
      "156/224, train_loss: 0.2154, step time: 0.4120\n",
      "157/224, train_loss: 0.1023, step time: 0.3164\n",
      "158/224, train_loss: 0.3611, step time: 0.4080\n",
      "159/224, train_loss: 0.1787, step time: 0.3151\n",
      "160/224, train_loss: 0.0709, step time: 0.3167\n",
      "161/224, train_loss: 0.0822, step time: 0.3174\n",
      "162/224, train_loss: 0.2509, step time: 0.3178\n",
      "163/224, train_loss: 0.1823, step time: 0.3798\n",
      "164/224, train_loss: 0.3539, step time: 0.3174\n",
      "165/224, train_loss: 0.1353, step time: 0.4138\n",
      "166/224, train_loss: 0.1998, step time: 0.3167\n",
      "167/224, train_loss: 0.0640, step time: 0.3989\n",
      "168/224, train_loss: 0.1261, step time: 0.4045\n",
      "169/224, train_loss: 0.1666, step time: 0.4145\n",
      "170/224, train_loss: 0.0939, step time: 0.3834\n",
      "171/224, train_loss: 0.0767, step time: 0.3195\n",
      "172/224, train_loss: 0.0762, step time: 0.3884\n",
      "173/224, train_loss: 0.1182, step time: 0.3191\n",
      "174/224, train_loss: 0.0960, step time: 0.3192\n",
      "175/224, train_loss: 0.1591, step time: 0.3724\n",
      "176/224, train_loss: 0.1277, step time: 0.4008\n",
      "177/224, train_loss: 0.2193, step time: 0.3933\n",
      "178/224, train_loss: 0.1079, step time: 0.4180\n",
      "179/224, train_loss: 0.1429, step time: 0.3818\n",
      "180/224, train_loss: 0.0950, step time: 0.3752\n",
      "181/224, train_loss: 0.1081, step time: 0.3937\n",
      "182/224, train_loss: 0.1876, step time: 0.3186\n",
      "183/224, train_loss: 0.1495, step time: 0.3165\n",
      "184/224, train_loss: 0.1690, step time: 0.4127\n",
      "185/224, train_loss: 0.0847, step time: 0.3183\n",
      "186/224, train_loss: 0.3344, step time: 0.3762\n",
      "187/224, train_loss: 0.0921, step time: 0.4016\n",
      "188/224, train_loss: 0.1035, step time: 0.3171\n",
      "189/224, train_loss: 0.1999, step time: 0.3719\n",
      "190/224, train_loss: 0.1279, step time: 0.4057\n",
      "191/224, train_loss: 0.0757, step time: 0.3192\n",
      "192/224, train_loss: 0.0780, step time: 0.3734\n",
      "193/224, train_loss: 0.1754, step time: 0.3186\n",
      "194/224, train_loss: 0.0951, step time: 0.3142\n",
      "195/224, train_loss: 0.0999, step time: 0.3157\n",
      "196/224, train_loss: 0.0784, step time: 0.3167\n",
      "197/224, train_loss: 0.0743, step time: 0.3826\n",
      "198/224, train_loss: 0.0816, step time: 0.3194\n",
      "199/224, train_loss: 0.0888, step time: 0.3147\n",
      "200/224, train_loss: 0.1316, step time: 0.3817\n",
      "201/224, train_loss: 0.1181, step time: 0.3754\n",
      "202/224, train_loss: 0.1117, step time: 0.3209\n",
      "203/224, train_loss: 0.0994, step time: 0.3158\n",
      "204/224, train_loss: 0.1416, step time: 0.3830\n",
      "205/224, train_loss: 0.1417, step time: 0.4050\n",
      "206/224, train_loss: 0.1207, step time: 0.4108\n",
      "207/224, train_loss: 0.0679, step time: 0.3140\n",
      "208/224, train_loss: 0.0433, step time: 0.3182\n",
      "209/224, train_loss: 0.0734, step time: 0.3987\n",
      "210/224, train_loss: 0.2857, step time: 0.3173\n",
      "211/224, train_loss: 0.0813, step time: 0.3132\n",
      "212/224, train_loss: 0.1197, step time: 0.3974\n",
      "213/224, train_loss: 0.0888, step time: 0.3206\n",
      "214/224, train_loss: 0.1177, step time: 0.3164\n",
      "215/224, train_loss: 0.0935, step time: 0.3197\n",
      "216/224, train_loss: 0.0795, step time: 0.3152\n",
      "217/224, train_loss: 0.0918, step time: 0.3163\n",
      "218/224, train_loss: 0.1087, step time: 0.4068\n",
      "219/224, train_loss: 0.1173, step time: 0.3199\n",
      "220/224, train_loss: 0.0887, step time: 0.3174\n",
      "221/224, train_loss: 0.1423, step time: 0.3988\n",
      "222/224, train_loss: 0.0919, step time: 0.3154\n",
      "223/224, train_loss: 0.1281, step time: 0.3155\n",
      "224/224, train_loss: 0.0720, step time: 0.3202\n",
      "epoch 70 average loss: 0.1388\n",
      "current epoch: 70 current mean dice: 0.7058 class1: 0.9994 class2: 0.7462 class3: 0.3719\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 70 is: 824.0274\n",
      "hello\n",
      "----------\n",
      "epoch 71/100\n",
      "1/224, train_loss: 0.2428, step time: 0.3192\n",
      "2/224, train_loss: 0.0890, step time: 0.3182\n",
      "3/224, train_loss: 0.0659, step time: 0.3194\n",
      "4/224, train_loss: 0.0601, step time: 0.3173\n",
      "5/224, train_loss: 0.0806, step time: 0.3990\n",
      "6/224, train_loss: 0.0692, step time: 0.3169\n",
      "7/224, train_loss: 0.1166, step time: 0.3990\n",
      "8/224, train_loss: 0.2199, step time: 0.4145\n",
      "9/224, train_loss: 0.1273, step time: 0.3929\n",
      "10/224, train_loss: 0.0876, step time: 0.3865\n",
      "11/224, train_loss: 0.1236, step time: 0.3984\n",
      "12/224, train_loss: 0.0954, step time: 0.3158\n",
      "13/224, train_loss: 0.1027, step time: 0.3153\n",
      "14/224, train_loss: 0.0870, step time: 0.3839\n",
      "15/224, train_loss: 0.2315, step time: 0.3185\n",
      "16/224, train_loss: 0.0779, step time: 0.3189\n",
      "17/224, train_loss: 0.1562, step time: 0.3777\n",
      "18/224, train_loss: 0.3997, step time: 0.3910\n",
      "19/224, train_loss: 0.0709, step time: 0.3138\n",
      "20/224, train_loss: 0.0665, step time: 0.3164\n",
      "21/224, train_loss: 0.0777, step time: 0.3760\n",
      "22/224, train_loss: 0.0633, step time: 0.3139\n",
      "23/224, train_loss: 0.0817, step time: 0.3184\n",
      "24/224, train_loss: 0.3621, step time: 0.4068\n",
      "25/224, train_loss: 0.0831, step time: 0.3157\n",
      "26/224, train_loss: 0.0978, step time: 0.3167\n",
      "27/224, train_loss: 0.0802, step time: 0.3911\n",
      "28/224, train_loss: 0.2309, step time: 0.4102\n",
      "29/224, train_loss: 0.0968, step time: 0.3182\n",
      "30/224, train_loss: 0.1534, step time: 0.3754\n",
      "31/224, train_loss: 0.2510, step time: 0.3156\n",
      "32/224, train_loss: 0.1293, step time: 0.3135\n",
      "33/224, train_loss: 0.0781, step time: 0.3158\n",
      "34/224, train_loss: 0.3688, step time: 0.3931\n",
      "35/224, train_loss: 0.0781, step time: 0.3717\n",
      "36/224, train_loss: 0.0840, step time: 0.3155\n",
      "37/224, train_loss: 0.1476, step time: 0.3819\n",
      "38/224, train_loss: 0.0910, step time: 0.3155\n",
      "39/224, train_loss: 0.1725, step time: 0.3147\n",
      "40/224, train_loss: 0.3043, step time: 0.3148\n",
      "41/224, train_loss: 0.1478, step time: 0.3879\n",
      "42/224, train_loss: 0.1286, step time: 0.3157\n",
      "43/224, train_loss: 0.1179, step time: 0.3140\n",
      "44/224, train_loss: 0.0852, step time: 0.3838\n",
      "45/224, train_loss: 0.3111, step time: 0.3734\n",
      "46/224, train_loss: 0.1168, step time: 0.3135\n",
      "47/224, train_loss: 0.0989, step time: 0.3178\n",
      "48/224, train_loss: 0.3994, step time: 0.3173\n",
      "49/224, train_loss: 0.1072, step time: 0.3133\n",
      "50/224, train_loss: 0.0522, step time: 0.3847\n",
      "51/224, train_loss: 0.1458, step time: 0.3174\n",
      "52/224, train_loss: 0.1172, step time: 0.3176\n",
      "53/224, train_loss: 0.2756, step time: 0.3964\n",
      "54/224, train_loss: 0.4630, step time: 0.3672\n",
      "55/224, train_loss: 0.0905, step time: 0.3846\n",
      "56/224, train_loss: 0.1606, step time: 0.3180\n",
      "57/224, train_loss: 0.1447, step time: 0.3152\n",
      "58/224, train_loss: 0.2556, step time: 0.3182\n",
      "59/224, train_loss: 0.0880, step time: 0.3626\n",
      "60/224, train_loss: 0.3423, step time: 0.4011\n",
      "61/224, train_loss: 0.2732, step time: 0.3836\n",
      "62/224, train_loss: 0.3555, step time: 0.3998\n",
      "63/224, train_loss: 0.1221, step time: 0.3150\n",
      "64/224, train_loss: 0.0799, step time: 0.3175\n",
      "65/224, train_loss: 0.1227, step time: 0.3151\n",
      "66/224, train_loss: 0.0770, step time: 0.3834\n",
      "67/224, train_loss: 0.0845, step time: 0.4003\n",
      "68/224, train_loss: 0.3803, step time: 0.3935\n",
      "69/224, train_loss: 0.1743, step time: 0.3160\n",
      "70/224, train_loss: 0.1661, step time: 0.3935\n",
      "71/224, train_loss: 0.2686, step time: 0.4066\n",
      "72/224, train_loss: 0.0876, step time: 0.3155\n",
      "73/224, train_loss: 0.2791, step time: 0.3152\n",
      "74/224, train_loss: 0.1895, step time: 0.3708\n",
      "75/224, train_loss: 0.1148, step time: 0.3139\n",
      "76/224, train_loss: 0.1514, step time: 0.3839\n",
      "77/224, train_loss: 0.1696, step time: 0.3778\n",
      "78/224, train_loss: 0.2206, step time: 0.3813\n",
      "79/224, train_loss: 0.1190, step time: 0.3947\n",
      "80/224, train_loss: 0.1076, step time: 0.3151\n",
      "81/224, train_loss: 0.2703, step time: 0.4025\n",
      "82/224, train_loss: 0.0981, step time: 0.3989\n",
      "83/224, train_loss: 0.1485, step time: 0.3175\n",
      "84/224, train_loss: 0.1625, step time: 0.3156\n",
      "85/224, train_loss: 0.1307, step time: 0.3154\n",
      "86/224, train_loss: 0.3989, step time: 0.4103\n",
      "87/224, train_loss: 0.1190, step time: 0.3165\n",
      "88/224, train_loss: 0.0816, step time: 0.3156\n",
      "89/224, train_loss: 0.2621, step time: 0.4110\n",
      "90/224, train_loss: 0.3524, step time: 0.4009\n",
      "91/224, train_loss: 0.1249, step time: 0.3138\n",
      "92/224, train_loss: 0.1061, step time: 0.3174\n",
      "93/224, train_loss: 0.2019, step time: 0.3998\n",
      "94/224, train_loss: 0.0924, step time: 0.3824\n",
      "95/224, train_loss: 0.3178, step time: 0.3184\n",
      "96/224, train_loss: 0.0968, step time: 0.3157\n",
      "97/224, train_loss: 0.1310, step time: 0.3190\n",
      "98/224, train_loss: 0.4243, step time: 0.3860\n",
      "99/224, train_loss: 0.1349, step time: 0.3915\n",
      "100/224, train_loss: 0.0712, step time: 0.3162\n",
      "101/224, train_loss: 0.0658, step time: 0.3161\n",
      "102/224, train_loss: 0.0974, step time: 0.3184\n",
      "103/224, train_loss: 0.3780, step time: 0.3865\n",
      "104/224, train_loss: 0.2638, step time: 0.3819\n",
      "105/224, train_loss: 0.1068, step time: 0.3160\n",
      "106/224, train_loss: 0.1023, step time: 0.3154\n",
      "107/224, train_loss: 0.1430, step time: 0.4042\n",
      "108/224, train_loss: 0.1840, step time: 0.3916\n",
      "109/224, train_loss: 0.1042, step time: 0.3182\n",
      "110/224, train_loss: 0.1103, step time: 0.3870\n",
      "111/224, train_loss: 0.1042, step time: 0.4107\n",
      "112/224, train_loss: 0.0747, step time: 0.4046\n",
      "113/224, train_loss: 0.1567, step time: 0.3148\n",
      "114/224, train_loss: 0.3108, step time: 0.3153\n",
      "115/224, train_loss: 0.3570, step time: 0.3936\n",
      "116/224, train_loss: 0.1160, step time: 0.3961\n",
      "117/224, train_loss: 0.0941, step time: 0.3148\n",
      "118/224, train_loss: 0.1402, step time: 0.4153\n",
      "119/224, train_loss: 0.0554, step time: 0.3157\n",
      "120/224, train_loss: 0.1236, step time: 0.4066\n",
      "121/224, train_loss: 0.0834, step time: 0.3184\n",
      "122/224, train_loss: 0.2692, step time: 0.4002\n",
      "123/224, train_loss: 0.0815, step time: 0.3159\n",
      "124/224, train_loss: 0.1051, step time: 0.3739\n",
      "125/224, train_loss: 0.1699, step time: 0.4004\n",
      "126/224, train_loss: 0.1635, step time: 0.3660\n",
      "127/224, train_loss: 0.1041, step time: 0.3164\n",
      "128/224, train_loss: 0.0871, step time: 0.3183\n",
      "129/224, train_loss: 0.1854, step time: 0.3838\n",
      "130/224, train_loss: 0.1401, step time: 0.3905\n",
      "131/224, train_loss: 0.0997, step time: 0.3854\n",
      "132/224, train_loss: 0.0962, step time: 0.3156\n",
      "133/224, train_loss: 0.1239, step time: 0.3136\n",
      "134/224, train_loss: 0.1038, step time: 0.3184\n",
      "135/224, train_loss: 0.0920, step time: 0.3161\n",
      "136/224, train_loss: 0.1205, step time: 0.3156\n",
      "137/224, train_loss: 0.1742, step time: 0.3892\n",
      "138/224, train_loss: 0.2924, step time: 0.3893\n",
      "139/224, train_loss: 0.0617, step time: 0.3159\n",
      "140/224, train_loss: 0.1285, step time: 0.3155\n",
      "141/224, train_loss: 0.1845, step time: 0.3961\n",
      "142/224, train_loss: 0.1816, step time: 0.4101\n",
      "143/224, train_loss: 0.0976, step time: 0.3660\n",
      "144/224, train_loss: 0.0736, step time: 0.3131\n",
      "145/224, train_loss: 0.0576, step time: 0.3154\n",
      "146/224, train_loss: 0.0709, step time: 0.3154\n",
      "147/224, train_loss: 0.1132, step time: 0.3134\n",
      "148/224, train_loss: 0.2502, step time: 0.4058\n",
      "149/224, train_loss: 0.0972, step time: 0.3854\n",
      "150/224, train_loss: 0.1052, step time: 0.3941\n",
      "151/224, train_loss: 0.1179, step time: 0.3133\n",
      "152/224, train_loss: 0.0501, step time: 0.3860\n",
      "153/224, train_loss: 0.1345, step time: 0.4086\n",
      "154/224, train_loss: 0.1230, step time: 0.3186\n",
      "155/224, train_loss: 0.3456, step time: 0.3862\n",
      "156/224, train_loss: 0.3693, step time: 0.3979\n",
      "157/224, train_loss: 0.1860, step time: 0.3153\n",
      "158/224, train_loss: 0.0810, step time: 0.3154\n",
      "159/224, train_loss: 0.1164, step time: 0.3157\n",
      "160/224, train_loss: 0.1657, step time: 0.3986\n",
      "161/224, train_loss: 0.0816, step time: 0.3169\n",
      "162/224, train_loss: 0.1137, step time: 0.3940\n",
      "163/224, train_loss: 0.0956, step time: 0.3660\n",
      "164/224, train_loss: 0.2344, step time: 0.3174\n",
      "165/224, train_loss: 0.1562, step time: 0.3859\n",
      "166/224, train_loss: 0.1387, step time: 0.3141\n",
      "167/224, train_loss: 0.0784, step time: 0.3161\n",
      "168/224, train_loss: 0.1844, step time: 0.4098\n",
      "169/224, train_loss: 0.0733, step time: 0.3150\n",
      "170/224, train_loss: 0.3011, step time: 0.3128\n",
      "171/224, train_loss: 0.0842, step time: 0.3158\n",
      "172/224, train_loss: 0.0540, step time: 0.3158\n",
      "173/224, train_loss: 0.0987, step time: 0.3744\n",
      "174/224, train_loss: 0.0796, step time: 0.3162\n",
      "175/224, train_loss: 0.1355, step time: 0.4020\n",
      "176/224, train_loss: 0.0842, step time: 0.3132\n",
      "177/224, train_loss: 0.0956, step time: 0.3134\n",
      "178/224, train_loss: 0.2827, step time: 0.3831\n",
      "179/224, train_loss: 0.1044, step time: 0.3181\n",
      "180/224, train_loss: 0.1839, step time: 0.4118\n",
      "181/224, train_loss: 0.1589, step time: 0.3975\n",
      "182/224, train_loss: 0.1952, step time: 0.3712\n",
      "183/224, train_loss: 0.2897, step time: 0.3823\n",
      "184/224, train_loss: 0.3476, step time: 0.3890\n",
      "185/224, train_loss: 0.1183, step time: 0.3659\n",
      "186/224, train_loss: 0.1476, step time: 0.3133\n",
      "187/224, train_loss: 0.0845, step time: 0.3152\n",
      "188/224, train_loss: 0.0976, step time: 0.3157\n",
      "189/224, train_loss: 0.1011, step time: 0.3156\n",
      "190/224, train_loss: 0.0555, step time: 0.3156\n",
      "191/224, train_loss: 0.1296, step time: 0.3807\n",
      "192/224, train_loss: 0.1125, step time: 0.3177\n",
      "193/224, train_loss: 0.1014, step time: 0.3178\n",
      "194/224, train_loss: 0.2313, step time: 0.3994\n",
      "195/224, train_loss: 0.1094, step time: 0.3158\n",
      "196/224, train_loss: 0.1799, step time: 0.3183\n",
      "197/224, train_loss: 0.1177, step time: 0.3155\n",
      "198/224, train_loss: 0.1369, step time: 0.3716\n",
      "199/224, train_loss: 0.1799, step time: 0.3905\n",
      "200/224, train_loss: 0.1029, step time: 0.3173\n",
      "201/224, train_loss: 0.0853, step time: 0.3181\n",
      "202/224, train_loss: 0.0987, step time: 0.3153\n",
      "203/224, train_loss: 0.0887, step time: 0.3136\n",
      "204/224, train_loss: 0.2833, step time: 0.3181\n",
      "205/224, train_loss: 0.3941, step time: 0.3931\n",
      "206/224, train_loss: 0.1330, step time: 0.3829\n",
      "207/224, train_loss: 0.0936, step time: 0.3906\n",
      "208/224, train_loss: 0.1220, step time: 0.3709\n",
      "209/224, train_loss: 0.1002, step time: 0.4025\n",
      "210/224, train_loss: 0.0985, step time: 0.3940\n",
      "211/224, train_loss: 0.2291, step time: 0.3824\n",
      "212/224, train_loss: 0.1821, step time: 0.4146\n",
      "213/224, train_loss: 0.1222, step time: 0.3977\n",
      "214/224, train_loss: 0.0598, step time: 0.3181\n",
      "215/224, train_loss: 0.1271, step time: 0.3134\n",
      "216/224, train_loss: 0.1626, step time: 0.3860\n",
      "217/224, train_loss: 0.2493, step time: 0.3860\n",
      "218/224, train_loss: 0.2758, step time: 0.3823\n",
      "219/224, train_loss: 0.0738, step time: 0.3828\n",
      "220/224, train_loss: 0.1031, step time: 0.3865\n",
      "221/224, train_loss: 0.1704, step time: 0.3987\n",
      "222/224, train_loss: 0.1959, step time: 0.3154\n",
      "223/224, train_loss: 0.1179, step time: 0.3829\n",
      "224/224, train_loss: 0.1766, step time: 0.3182\n",
      "epoch 71 average loss: 0.1545\n",
      "current epoch: 71 current mean dice: 0.6868 class1: 0.9993 class2: 0.6982 class3: 0.3628\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 71 is: 722.3042\n",
      "hello\n",
      "----------\n",
      "epoch 72/100\n",
      "1/224, train_loss: 0.0813, step time: 0.3169\n",
      "2/224, train_loss: 0.0748, step time: 0.3185\n",
      "3/224, train_loss: 0.1141, step time: 0.3189\n",
      "4/224, train_loss: 0.0873, step time: 0.3186\n",
      "5/224, train_loss: 0.1247, step time: 0.4088\n",
      "6/224, train_loss: 0.0627, step time: 0.3153\n",
      "7/224, train_loss: 0.0904, step time: 0.4103\n",
      "8/224, train_loss: 0.0669, step time: 0.3155\n",
      "9/224, train_loss: 0.2148, step time: 0.3808\n",
      "10/224, train_loss: 0.1936, step time: 0.4108\n",
      "11/224, train_loss: 0.1363, step time: 0.3152\n",
      "12/224, train_loss: 0.1461, step time: 0.3183\n",
      "13/224, train_loss: 0.3652, step time: 0.3730\n",
      "14/224, train_loss: 0.1013, step time: 0.3825\n",
      "15/224, train_loss: 0.1156, step time: 0.3165\n",
      "16/224, train_loss: 0.1234, step time: 0.4108\n",
      "17/224, train_loss: 0.0717, step time: 0.3170\n",
      "18/224, train_loss: 0.0919, step time: 0.3152\n",
      "19/224, train_loss: 0.1535, step time: 0.3872\n",
      "20/224, train_loss: 0.1044, step time: 0.4066\n",
      "21/224, train_loss: 0.3555, step time: 0.3741\n",
      "22/224, train_loss: 0.1342, step time: 0.3798\n",
      "23/224, train_loss: 0.2194, step time: 0.3711\n",
      "24/224, train_loss: 0.1043, step time: 0.3715\n",
      "25/224, train_loss: 0.1058, step time: 0.3174\n",
      "26/224, train_loss: 0.0682, step time: 0.3158\n",
      "27/224, train_loss: 0.2939, step time: 0.3187\n",
      "28/224, train_loss: 0.2526, step time: 0.3688\n",
      "29/224, train_loss: 0.0629, step time: 0.3686\n",
      "30/224, train_loss: 0.0625, step time: 0.3176\n",
      "31/224, train_loss: 0.0674, step time: 0.3155\n",
      "32/224, train_loss: 0.3111, step time: 0.4000\n",
      "33/224, train_loss: 0.2070, step time: 0.3150\n",
      "34/224, train_loss: 0.0527, step time: 0.3135\n",
      "35/224, train_loss: 0.1806, step time: 0.3795\n",
      "36/224, train_loss: 0.1747, step time: 0.3157\n",
      "37/224, train_loss: 0.2541, step time: 0.3986\n",
      "38/224, train_loss: 0.1894, step time: 0.3183\n",
      "39/224, train_loss: 0.0677, step time: 0.3160\n",
      "40/224, train_loss: 0.1765, step time: 0.3667\n",
      "41/224, train_loss: 0.1446, step time: 0.4144\n",
      "42/224, train_loss: 0.1518, step time: 0.4060\n",
      "43/224, train_loss: 0.1155, step time: 0.3157\n",
      "44/224, train_loss: 0.0791, step time: 0.3166\n",
      "45/224, train_loss: 0.0687, step time: 0.3178\n",
      "46/224, train_loss: 0.3863, step time: 0.3947\n",
      "47/224, train_loss: 0.0903, step time: 0.3155\n",
      "48/224, train_loss: 0.1859, step time: 0.3172\n",
      "49/224, train_loss: 0.1472, step time: 0.3704\n",
      "50/224, train_loss: 0.1251, step time: 0.3170\n",
      "51/224, train_loss: 0.1210, step time: 0.3134\n",
      "52/224, train_loss: 0.0651, step time: 0.3821\n",
      "53/224, train_loss: 0.1324, step time: 0.3740\n",
      "54/224, train_loss: 0.0829, step time: 0.3861\n",
      "55/224, train_loss: 0.0955, step time: 0.3951\n",
      "56/224, train_loss: 0.0751, step time: 0.3162\n",
      "57/224, train_loss: 0.2139, step time: 0.4105\n",
      "58/224, train_loss: 0.1030, step time: 0.3157\n",
      "59/224, train_loss: 0.2473, step time: 0.3986\n",
      "60/224, train_loss: 0.1086, step time: 0.3130\n",
      "61/224, train_loss: 0.1238, step time: 0.4090\n",
      "62/224, train_loss: 0.3053, step time: 0.4032\n",
      "63/224, train_loss: 0.0891, step time: 0.3130\n",
      "64/224, train_loss: 0.0623, step time: 0.3159\n",
      "65/224, train_loss: 0.0620, step time: 0.3180\n",
      "66/224, train_loss: 0.0873, step time: 0.4003\n",
      "67/224, train_loss: 0.2009, step time: 0.3864\n",
      "68/224, train_loss: 0.1193, step time: 0.3156\n",
      "69/224, train_loss: 0.0988, step time: 0.3181\n",
      "70/224, train_loss: 0.1589, step time: 0.3857\n",
      "71/224, train_loss: 0.0870, step time: 0.3679\n",
      "72/224, train_loss: 0.1173, step time: 0.3155\n",
      "73/224, train_loss: 0.1198, step time: 0.3138\n",
      "74/224, train_loss: 0.1198, step time: 0.3188\n",
      "75/224, train_loss: 0.0933, step time: 0.3166\n",
      "76/224, train_loss: 0.1667, step time: 0.4030\n",
      "77/224, train_loss: 0.1306, step time: 0.4025\n",
      "78/224, train_loss: 0.0866, step time: 0.3159\n",
      "79/224, train_loss: 0.3223, step time: 0.3158\n",
      "80/224, train_loss: 0.0871, step time: 0.3138\n",
      "81/224, train_loss: 0.0842, step time: 0.3740\n",
      "82/224, train_loss: 0.1263, step time: 0.3151\n",
      "83/224, train_loss: 0.1671, step time: 0.3954\n",
      "84/224, train_loss: 0.1075, step time: 0.3793\n",
      "85/224, train_loss: 0.3630, step time: 0.3876\n",
      "86/224, train_loss: 0.1886, step time: 0.3155\n",
      "87/224, train_loss: 0.2236, step time: 0.3748\n",
      "88/224, train_loss: 0.1013, step time: 0.3792\n",
      "89/224, train_loss: 0.3247, step time: 0.4017\n",
      "90/224, train_loss: 0.0752, step time: 0.3755\n",
      "91/224, train_loss: 0.0647, step time: 0.3149\n",
      "92/224, train_loss: 0.1134, step time: 0.3768\n",
      "93/224, train_loss: 0.1916, step time: 0.3153\n",
      "94/224, train_loss: 0.2600, step time: 0.3793\n",
      "95/224, train_loss: 0.1278, step time: 0.3874\n",
      "96/224, train_loss: 0.0688, step time: 0.3175\n",
      "97/224, train_loss: 0.1030, step time: 0.4170\n",
      "98/224, train_loss: 0.3642, step time: 0.3848\n",
      "99/224, train_loss: 0.1279, step time: 0.4019\n",
      "100/224, train_loss: 0.0719, step time: 0.3153\n",
      "101/224, train_loss: 0.1983, step time: 0.3826\n",
      "102/224, train_loss: 0.1185, step time: 0.3765\n",
      "103/224, train_loss: 0.0977, step time: 0.3130\n",
      "104/224, train_loss: 0.1664, step time: 0.3153\n",
      "105/224, train_loss: 0.1181, step time: 0.3152\n",
      "106/224, train_loss: 0.1116, step time: 0.3875\n",
      "107/224, train_loss: 0.1793, step time: 0.3819\n",
      "108/224, train_loss: 0.0569, step time: 0.3157\n",
      "109/224, train_loss: 0.1061, step time: 0.3165\n",
      "110/224, train_loss: 0.0914, step time: 0.3162\n",
      "111/224, train_loss: 0.1098, step time: 0.3174\n",
      "112/224, train_loss: 0.1071, step time: 0.4113\n",
      "113/224, train_loss: 0.1006, step time: 0.3155\n",
      "114/224, train_loss: 0.1400, step time: 0.3189\n",
      "115/224, train_loss: 0.1905, step time: 0.4029\n",
      "116/224, train_loss: 0.1369, step time: 0.3985\n",
      "117/224, train_loss: 0.1210, step time: 0.3149\n",
      "118/224, train_loss: 0.1396, step time: 0.3188\n",
      "119/224, train_loss: 0.1320, step time: 0.3191\n",
      "120/224, train_loss: 0.0582, step time: 0.3181\n",
      "121/224, train_loss: 0.1630, step time: 0.3785\n",
      "122/224, train_loss: 0.1627, step time: 0.3174\n",
      "123/224, train_loss: 0.0794, step time: 0.3134\n",
      "124/224, train_loss: 0.1292, step time: 0.3164\n",
      "125/224, train_loss: 0.0924, step time: 0.3136\n",
      "126/224, train_loss: 0.2296, step time: 0.3653\n",
      "127/224, train_loss: 0.1314, step time: 0.3660\n",
      "128/224, train_loss: 0.0741, step time: 0.3157\n",
      "129/224, train_loss: 0.0714, step time: 0.3158\n",
      "130/224, train_loss: 0.1336, step time: 0.3709\n",
      "131/224, train_loss: 0.1770, step time: 0.3897\n",
      "132/224, train_loss: 0.0555, step time: 0.4137\n",
      "133/224, train_loss: 0.0789, step time: 0.3186\n",
      "134/224, train_loss: 0.1276, step time: 0.3167\n",
      "135/224, train_loss: 0.2307, step time: 0.3186\n",
      "136/224, train_loss: 0.2223, step time: 0.3942\n",
      "137/224, train_loss: 0.1016, step time: 0.3970\n",
      "138/224, train_loss: 0.3375, step time: 0.3882\n",
      "139/224, train_loss: 0.1223, step time: 0.3757\n",
      "140/224, train_loss: 0.0836, step time: 0.3687\n",
      "141/224, train_loss: 0.1615, step time: 0.3160\n",
      "142/224, train_loss: 0.0787, step time: 0.3158\n",
      "143/224, train_loss: 0.0876, step time: 0.3157\n",
      "144/224, train_loss: 0.1358, step time: 0.3906\n",
      "145/224, train_loss: 0.2785, step time: 0.4021\n",
      "146/224, train_loss: 0.0788, step time: 0.3146\n",
      "147/224, train_loss: 0.0985, step time: 0.3809\n",
      "148/224, train_loss: 0.1210, step time: 0.4089\n",
      "149/224, train_loss: 0.1976, step time: 0.4069\n",
      "150/224, train_loss: 0.0949, step time: 0.3173\n",
      "151/224, train_loss: 0.2689, step time: 0.3819\n",
      "152/224, train_loss: 0.0939, step time: 0.3142\n",
      "153/224, train_loss: 0.1059, step time: 0.3124\n",
      "154/224, train_loss: 0.1412, step time: 0.3137\n",
      "155/224, train_loss: 0.1026, step time: 0.3850\n",
      "156/224, train_loss: 0.0801, step time: 0.3724\n",
      "157/224, train_loss: 0.1084, step time: 0.3174\n",
      "158/224, train_loss: 0.1975, step time: 0.3177\n",
      "159/224, train_loss: 0.1417, step time: 0.3844\n",
      "160/224, train_loss: 0.0892, step time: 0.3142\n",
      "161/224, train_loss: 0.1797, step time: 0.3151\n",
      "162/224, train_loss: 0.1264, step time: 0.3145\n",
      "163/224, train_loss: 0.1871, step time: 0.3784\n",
      "164/224, train_loss: 0.0714, step time: 0.3695\n",
      "165/224, train_loss: 0.1983, step time: 0.4091\n",
      "166/224, train_loss: 0.0764, step time: 0.3163\n",
      "167/224, train_loss: 0.0671, step time: 0.3171\n",
      "168/224, train_loss: 0.1615, step time: 0.3983\n",
      "169/224, train_loss: 0.1069, step time: 0.3733\n",
      "170/224, train_loss: 0.1145, step time: 0.3149\n",
      "171/224, train_loss: 0.0603, step time: 0.3174\n",
      "172/224, train_loss: 0.1002, step time: 0.3146\n",
      "173/224, train_loss: 0.1739, step time: 0.3124\n",
      "174/224, train_loss: 0.1283, step time: 0.3171\n",
      "175/224, train_loss: 0.1235, step time: 0.3130\n",
      "176/224, train_loss: 0.1521, step time: 0.4002\n",
      "177/224, train_loss: 0.1282, step time: 0.3781\n",
      "178/224, train_loss: 0.1341, step time: 0.3929\n",
      "179/224, train_loss: 0.0822, step time: 0.3859\n",
      "180/224, train_loss: 0.1685, step time: 0.3984\n",
      "181/224, train_loss: 0.0494, step time: 0.3129\n",
      "182/224, train_loss: 0.0750, step time: 0.3145\n",
      "183/224, train_loss: 0.1144, step time: 0.4001\n",
      "184/224, train_loss: 0.1818, step time: 0.3133\n",
      "185/224, train_loss: 0.0996, step time: 0.4067\n",
      "186/224, train_loss: 0.1694, step time: 0.3147\n",
      "187/224, train_loss: 0.1359, step time: 0.3891\n",
      "188/224, train_loss: 0.0915, step time: 0.3156\n",
      "189/224, train_loss: 0.0765, step time: 0.3725\n",
      "190/224, train_loss: 0.0750, step time: 0.3170\n",
      "191/224, train_loss: 0.1444, step time: 0.3951\n",
      "192/224, train_loss: 0.2525, step time: 0.4040\n",
      "193/224, train_loss: 0.0663, step time: 0.3174\n",
      "194/224, train_loss: 0.0737, step time: 0.3153\n",
      "195/224, train_loss: 0.1487, step time: 0.3973\n",
      "196/224, train_loss: 0.1021, step time: 0.3139\n",
      "197/224, train_loss: 0.0994, step time: 0.3164\n",
      "198/224, train_loss: 0.0691, step time: 0.3138\n",
      "199/224, train_loss: 0.1299, step time: 0.3169\n",
      "200/224, train_loss: 0.0699, step time: 0.3740\n",
      "201/224, train_loss: 0.1116, step time: 0.3148\n",
      "202/224, train_loss: 0.0967, step time: 0.3167\n",
      "203/224, train_loss: 0.2217, step time: 0.3163\n",
      "204/224, train_loss: 0.0785, step time: 0.3144\n",
      "205/224, train_loss: 0.0936, step time: 0.3149\n",
      "206/224, train_loss: 0.1289, step time: 0.3173\n",
      "207/224, train_loss: 0.1108, step time: 0.3178\n",
      "208/224, train_loss: 0.0442, step time: 0.3149\n",
      "209/224, train_loss: 0.2603, step time: 0.3774\n",
      "210/224, train_loss: 0.3446, step time: 0.4047\n",
      "211/224, train_loss: 0.3029, step time: 0.3718\n",
      "212/224, train_loss: 0.1058, step time: 0.4014\n",
      "213/224, train_loss: 0.0812, step time: 0.3146\n",
      "214/224, train_loss: 0.0873, step time: 0.3175\n",
      "215/224, train_loss: 0.1344, step time: 0.3159\n",
      "216/224, train_loss: 0.1271, step time: 0.3813\n",
      "217/224, train_loss: 0.0998, step time: 0.4062\n",
      "218/224, train_loss: 0.1116, step time: 0.3806\n",
      "219/224, train_loss: 0.2372, step time: 0.3171\n",
      "220/224, train_loss: 0.1017, step time: 0.3806\n",
      "221/224, train_loss: 0.0843, step time: 0.3171\n",
      "222/224, train_loss: 0.1486, step time: 0.4064\n",
      "223/224, train_loss: 0.0825, step time: 0.3175\n",
      "224/224, train_loss: 0.2089, step time: 0.3147\n",
      "epoch 72 average loss: 0.1366\n",
      "current epoch: 72 current mean dice: 0.7116 class1: 0.9994 class2: 0.7306 class3: 0.4048\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 72 is: 717.0836\n",
      "hello\n",
      "----------\n",
      "epoch 73/100\n",
      "1/224, train_loss: 0.0773, step time: 0.3987\n",
      "2/224, train_loss: 0.0991, step time: 0.3134\n",
      "3/224, train_loss: 0.2616, step time: 0.3874\n",
      "4/224, train_loss: 0.1231, step time: 0.3148\n",
      "5/224, train_loss: 0.1211, step time: 0.3148\n",
      "6/224, train_loss: 0.0653, step time: 0.3143\n",
      "7/224, train_loss: 0.1839, step time: 0.4096\n",
      "8/224, train_loss: 0.1357, step time: 0.3880\n",
      "9/224, train_loss: 0.1035, step time: 0.3143\n",
      "10/224, train_loss: 0.1990, step time: 0.4043\n",
      "11/224, train_loss: 0.3107, step time: 0.3686\n",
      "12/224, train_loss: 0.1235, step time: 0.3143\n",
      "13/224, train_loss: 0.1656, step time: 0.3128\n",
      "14/224, train_loss: 0.1232, step time: 0.3847\n",
      "15/224, train_loss: 0.1359, step time: 0.3146\n",
      "16/224, train_loss: 0.1225, step time: 0.3787\n",
      "17/224, train_loss: 0.0790, step time: 0.3664\n",
      "18/224, train_loss: 0.0972, step time: 0.3156\n",
      "19/224, train_loss: 0.1047, step time: 0.3155\n",
      "20/224, train_loss: 0.1765, step time: 0.3772\n",
      "21/224, train_loss: 0.3900, step time: 0.4098\n",
      "22/224, train_loss: 0.1726, step time: 0.3914\n",
      "23/224, train_loss: 0.0905, step time: 0.3629\n",
      "24/224, train_loss: 0.2515, step time: 0.3921\n",
      "25/224, train_loss: 0.1261, step time: 0.4019\n",
      "26/224, train_loss: 0.1677, step time: 0.4029\n",
      "27/224, train_loss: 0.0835, step time: 0.4099\n",
      "28/224, train_loss: 0.1925, step time: 0.3847\n",
      "29/224, train_loss: 0.1061, step time: 0.3696\n",
      "30/224, train_loss: 0.0932, step time: 0.3912\n",
      "31/224, train_loss: 0.1022, step time: 0.3131\n",
      "32/224, train_loss: 0.2087, step time: 0.3181\n",
      "33/224, train_loss: 0.0574, step time: 0.3158\n",
      "34/224, train_loss: 0.1990, step time: 0.3951\n",
      "35/224, train_loss: 0.1198, step time: 0.4129\n",
      "36/224, train_loss: 0.1418, step time: 0.3981\n",
      "37/224, train_loss: 0.1577, step time: 0.3120\n",
      "38/224, train_loss: 0.0905, step time: 0.3965\n",
      "39/224, train_loss: 0.0975, step time: 0.3174\n",
      "40/224, train_loss: 0.0811, step time: 0.3168\n",
      "41/224, train_loss: 0.1902, step time: 0.3682\n",
      "42/224, train_loss: 0.1453, step time: 0.3942\n",
      "43/224, train_loss: 0.0759, step time: 0.3165\n",
      "44/224, train_loss: 0.0935, step time: 0.3149\n",
      "45/224, train_loss: 0.0437, step time: 0.3149\n",
      "46/224, train_loss: 0.1260, step time: 0.3968\n",
      "47/224, train_loss: 0.1756, step time: 0.3169\n",
      "48/224, train_loss: 0.1203, step time: 0.4088\n",
      "49/224, train_loss: 0.1405, step time: 0.3155\n",
      "50/224, train_loss: 0.3081, step time: 0.3983\n",
      "51/224, train_loss: 0.1062, step time: 0.3125\n",
      "52/224, train_loss: 0.1210, step time: 0.3861\n",
      "53/224, train_loss: 0.0537, step time: 0.3983\n",
      "54/224, train_loss: 0.0986, step time: 0.3868\n",
      "55/224, train_loss: 0.2863, step time: 0.3904\n",
      "56/224, train_loss: 0.0891, step time: 0.3140\n",
      "57/224, train_loss: 0.2376, step time: 0.3835\n",
      "58/224, train_loss: 0.1293, step time: 0.4036\n",
      "59/224, train_loss: 0.0603, step time: 0.3772\n",
      "60/224, train_loss: 0.1914, step time: 0.3120\n",
      "61/224, train_loss: 0.1434, step time: 0.3807\n",
      "62/224, train_loss: 0.1152, step time: 0.3169\n",
      "63/224, train_loss: 0.1642, step time: 0.3693\n",
      "64/224, train_loss: 0.1044, step time: 0.3149\n",
      "65/224, train_loss: 0.1013, step time: 0.3144\n",
      "66/224, train_loss: 0.1141, step time: 0.3143\n",
      "67/224, train_loss: 0.1277, step time: 0.3148\n",
      "68/224, train_loss: 0.1440, step time: 0.3150\n",
      "69/224, train_loss: 0.0934, step time: 0.3990\n",
      "70/224, train_loss: 0.1803, step time: 0.4019\n",
      "71/224, train_loss: 0.1340, step time: 0.3150\n",
      "72/224, train_loss: 0.3544, step time: 0.3145\n",
      "73/224, train_loss: 0.0926, step time: 0.3764\n",
      "74/224, train_loss: 0.0839, step time: 0.3144\n",
      "75/224, train_loss: 0.1280, step time: 0.4097\n",
      "76/224, train_loss: 0.0833, step time: 0.4097\n",
      "77/224, train_loss: 0.0659, step time: 0.3145\n",
      "78/224, train_loss: 0.0922, step time: 0.3165\n",
      "79/224, train_loss: 0.0729, step time: 0.3148\n",
      "80/224, train_loss: 0.1261, step time: 0.3170\n",
      "81/224, train_loss: 0.1281, step time: 0.3143\n",
      "82/224, train_loss: 0.1279, step time: 0.3126\n",
      "83/224, train_loss: 0.0991, step time: 0.3143\n",
      "84/224, train_loss: 0.1739, step time: 0.3171\n",
      "85/224, train_loss: 0.0765, step time: 0.3766\n",
      "86/224, train_loss: 0.1967, step time: 0.3885\n",
      "87/224, train_loss: 0.0720, step time: 0.3173\n",
      "88/224, train_loss: 0.1742, step time: 0.3149\n",
      "89/224, train_loss: 0.0802, step time: 0.4085\n",
      "90/224, train_loss: 0.0746, step time: 0.4089\n",
      "91/224, train_loss: 0.0911, step time: 0.3142\n",
      "92/224, train_loss: 0.1145, step time: 0.4084\n",
      "93/224, train_loss: 0.1239, step time: 0.3731\n",
      "94/224, train_loss: 0.0997, step time: 0.3143\n",
      "95/224, train_loss: 0.1074, step time: 0.3966\n",
      "96/224, train_loss: 0.0669, step time: 0.4004\n",
      "97/224, train_loss: 0.0851, step time: 0.3186\n",
      "98/224, train_loss: 0.0443, step time: 0.3150\n",
      "99/224, train_loss: 0.2535, step time: 0.3786\n",
      "100/224, train_loss: 0.0934, step time: 0.3893\n",
      "101/224, train_loss: 0.2551, step time: 0.3750\n",
      "102/224, train_loss: 0.1318, step time: 0.4012\n",
      "103/224, train_loss: 0.0712, step time: 0.3149\n",
      "104/224, train_loss: 0.1342, step time: 0.3144\n",
      "105/224, train_loss: 0.0801, step time: 0.3141\n",
      "106/224, train_loss: 0.0764, step time: 0.3949\n",
      "107/224, train_loss: 0.0715, step time: 0.3150\n",
      "108/224, train_loss: 0.0593, step time: 0.3860\n",
      "109/224, train_loss: 0.1572, step time: 0.3754\n",
      "110/224, train_loss: 0.0729, step time: 0.3156\n",
      "111/224, train_loss: 0.0605, step time: 0.3716\n",
      "112/224, train_loss: 0.1000, step time: 0.3671\n",
      "113/224, train_loss: 0.1249, step time: 0.3924\n",
      "114/224, train_loss: 0.0863, step time: 0.3142\n",
      "115/224, train_loss: 0.1064, step time: 0.3144\n",
      "116/224, train_loss: 0.3513, step time: 0.3771\n",
      "117/224, train_loss: 0.0977, step time: 0.3694\n",
      "118/224, train_loss: 0.0730, step time: 0.3151\n",
      "119/224, train_loss: 0.1924, step time: 0.3797\n",
      "120/224, train_loss: 0.1328, step time: 0.3128\n",
      "121/224, train_loss: 0.1642, step time: 0.3860\n",
      "122/224, train_loss: 0.0453, step time: 0.4022\n",
      "123/224, train_loss: 0.1082, step time: 0.3980\n",
      "124/224, train_loss: 0.0697, step time: 0.3128\n",
      "125/224, train_loss: 0.1003, step time: 0.3884\n",
      "126/224, train_loss: 0.1499, step time: 0.3729\n",
      "127/224, train_loss: 0.1157, step time: 0.3176\n",
      "128/224, train_loss: 0.1043, step time: 0.3152\n",
      "129/224, train_loss: 0.0922, step time: 0.3148\n",
      "130/224, train_loss: 0.0622, step time: 0.3125\n",
      "131/224, train_loss: 0.1347, step time: 0.3859\n",
      "132/224, train_loss: 0.4382, step time: 0.3967\n",
      "133/224, train_loss: 0.1236, step time: 0.3161\n",
      "134/224, train_loss: 0.0689, step time: 0.4017\n",
      "135/224, train_loss: 0.0703, step time: 0.4138\n",
      "136/224, train_loss: 0.0760, step time: 0.3152\n",
      "137/224, train_loss: 0.1626, step time: 0.3182\n",
      "138/224, train_loss: 0.2684, step time: 0.3160\n",
      "139/224, train_loss: 0.0980, step time: 0.3159\n",
      "140/224, train_loss: 0.1403, step time: 0.3138\n",
      "141/224, train_loss: 0.0631, step time: 0.3154\n",
      "142/224, train_loss: 0.3396, step time: 0.4086\n",
      "143/224, train_loss: 0.1289, step time: 0.3774\n",
      "144/224, train_loss: 0.1179, step time: 0.3152\n",
      "145/224, train_loss: 0.2624, step time: 0.3973\n",
      "146/224, train_loss: 0.1003, step time: 0.3179\n",
      "147/224, train_loss: 0.1423, step time: 0.3897\n",
      "148/224, train_loss: 0.0740, step time: 0.4112\n",
      "149/224, train_loss: 0.0611, step time: 0.3173\n",
      "150/224, train_loss: 0.0692, step time: 0.3138\n",
      "151/224, train_loss: 0.1831, step time: 0.3687\n",
      "152/224, train_loss: 0.1017, step time: 0.3958\n",
      "153/224, train_loss: 0.0929, step time: 0.3172\n",
      "154/224, train_loss: 0.0971, step time: 0.3849\n",
      "155/224, train_loss: 0.4088, step time: 0.3826\n",
      "156/224, train_loss: 0.0851, step time: 0.4058\n",
      "157/224, train_loss: 0.2190, step time: 0.3998\n",
      "158/224, train_loss: 0.0640, step time: 0.3759\n",
      "159/224, train_loss: 0.1304, step time: 0.3152\n",
      "160/224, train_loss: 0.1350, step time: 0.3809\n",
      "161/224, train_loss: 0.2410, step time: 0.3652\n",
      "162/224, train_loss: 0.2056, step time: 0.4040\n",
      "163/224, train_loss: 0.1078, step time: 0.3145\n",
      "164/224, train_loss: 0.0909, step time: 0.3172\n",
      "165/224, train_loss: 0.1151, step time: 0.3149\n",
      "166/224, train_loss: 0.0975, step time: 0.3122\n",
      "167/224, train_loss: 0.0595, step time: 0.3129\n",
      "168/224, train_loss: 0.1555, step time: 0.3863\n",
      "169/224, train_loss: 0.2102, step time: 0.3819\n",
      "170/224, train_loss: 0.2455, step time: 0.3994\n",
      "171/224, train_loss: 0.1850, step time: 0.3140\n",
      "172/224, train_loss: 0.1161, step time: 0.3726\n",
      "173/224, train_loss: 0.1874, step time: 0.3171\n",
      "174/224, train_loss: 0.1577, step time: 0.3835\n",
      "175/224, train_loss: 0.3768, step time: 0.3824\n",
      "176/224, train_loss: 0.2078, step time: 0.4076\n",
      "177/224, train_loss: 0.0524, step time: 0.3152\n",
      "178/224, train_loss: 0.1149, step time: 0.3144\n",
      "179/224, train_loss: 0.0917, step time: 0.3149\n",
      "180/224, train_loss: 0.2346, step time: 0.3829\n",
      "181/224, train_loss: 0.1291, step time: 0.3859\n",
      "182/224, train_loss: 0.1097, step time: 0.3123\n",
      "183/224, train_loss: 0.1703, step time: 0.3933\n",
      "184/224, train_loss: 0.0779, step time: 0.3147\n",
      "185/224, train_loss: 0.0976, step time: 0.3144\n",
      "186/224, train_loss: 0.0813, step time: 0.3151\n",
      "187/224, train_loss: 0.0921, step time: 0.3146\n",
      "188/224, train_loss: 0.1514, step time: 0.3681\n",
      "189/224, train_loss: 0.0631, step time: 0.3927\n",
      "190/224, train_loss: 0.0980, step time: 0.3147\n",
      "191/224, train_loss: 0.0836, step time: 0.3147\n",
      "192/224, train_loss: 0.1350, step time: 0.3129\n",
      "193/224, train_loss: 0.0984, step time: 0.3146\n",
      "194/224, train_loss: 0.2229, step time: 0.3155\n",
      "195/224, train_loss: 0.2803, step time: 0.3923\n",
      "196/224, train_loss: 0.2454, step time: 0.4083\n",
      "197/224, train_loss: 0.2076, step time: 0.3905\n",
      "198/224, train_loss: 0.0673, step time: 0.3148\n",
      "199/224, train_loss: 0.1351, step time: 0.3799\n",
      "200/224, train_loss: 0.0482, step time: 0.3155\n",
      "201/224, train_loss: 0.1181, step time: 0.3709\n",
      "202/224, train_loss: 0.1975, step time: 0.3967\n",
      "203/224, train_loss: 0.0836, step time: 0.3167\n",
      "204/224, train_loss: 0.0926, step time: 0.3122\n",
      "205/224, train_loss: 0.2481, step time: 0.3175\n",
      "206/224, train_loss: 0.0822, step time: 0.3136\n",
      "207/224, train_loss: 0.0427, step time: 0.3147\n",
      "208/224, train_loss: 0.0929, step time: 0.3143\n",
      "209/224, train_loss: 0.1152, step time: 0.3177\n",
      "210/224, train_loss: 0.1415, step time: 0.3181\n",
      "211/224, train_loss: 0.2486, step time: 0.4096\n",
      "212/224, train_loss: 0.0656, step time: 0.3157\n",
      "213/224, train_loss: 0.1083, step time: 0.4087\n",
      "214/224, train_loss: 0.0697, step time: 0.3972\n",
      "215/224, train_loss: 0.0975, step time: 0.3169\n",
      "216/224, train_loss: 0.1558, step time: 0.3712\n",
      "217/224, train_loss: 0.0981, step time: 0.3945\n",
      "218/224, train_loss: 0.1007, step time: 0.3146\n",
      "219/224, train_loss: 0.0933, step time: 0.3704\n",
      "220/224, train_loss: 0.0684, step time: 0.3148\n",
      "221/224, train_loss: 0.0650, step time: 0.3149\n",
      "222/224, train_loss: 0.1721, step time: 0.3167\n",
      "223/224, train_loss: 0.1088, step time: 0.3120\n",
      "224/224, train_loss: 0.0974, step time: 0.3144\n",
      "epoch 73 average loss: 0.1333\n",
      "current epoch: 73 current mean dice: 0.7125 class1: 0.9993 class2: 0.7280 class3: 0.4102\n",
      "best mean dice: 0.7138 at epoch: 60\n",
      "time consuming of epoch 73 is: 687.1694\n",
      "hello\n",
      "----------\n",
      "epoch 74/100\n",
      "1/224, train_loss: 0.0582, step time: 0.3144\n",
      "2/224, train_loss: 0.1153, step time: 0.3769\n",
      "3/224, train_loss: 0.0834, step time: 0.3721\n",
      "4/224, train_loss: 0.0723, step time: 0.3154\n",
      "5/224, train_loss: 0.1180, step time: 0.4120\n",
      "6/224, train_loss: 0.1022, step time: 0.4019\n",
      "7/224, train_loss: 0.0769, step time: 0.3155\n",
      "8/224, train_loss: 0.0652, step time: 0.3149\n",
      "9/224, train_loss: 0.1966, step time: 0.3904\n",
      "10/224, train_loss: 0.0808, step time: 0.3969\n",
      "11/224, train_loss: 0.2653, step time: 0.3127\n",
      "12/224, train_loss: 0.1214, step time: 0.3146\n",
      "13/224, train_loss: 0.1052, step time: 0.3533\n",
      "14/224, train_loss: 0.0687, step time: 0.3695\n",
      "15/224, train_loss: 0.0814, step time: 0.3181\n",
      "16/224, train_loss: 0.3254, step time: 0.3151\n",
      "17/224, train_loss: 0.0751, step time: 0.3159\n",
      "18/224, train_loss: 0.0601, step time: 0.3138\n",
      "19/224, train_loss: 0.1362, step time: 0.3156\n",
      "20/224, train_loss: 0.3191, step time: 0.3661\n",
      "21/224, train_loss: 0.0914, step time: 0.3129\n",
      "22/224, train_loss: 0.1309, step time: 0.3175\n",
      "23/224, train_loss: 0.0809, step time: 0.3152\n",
      "24/224, train_loss: 0.1468, step time: 0.3187\n",
      "25/224, train_loss: 0.1942, step time: 0.3813\n",
      "26/224, train_loss: 0.1800, step time: 0.3949\n",
      "27/224, train_loss: 0.0717, step time: 0.3139\n",
      "28/224, train_loss: 0.1003, step time: 0.3136\n",
      "29/224, train_loss: 0.1651, step time: 0.4114\n",
      "30/224, train_loss: 0.0651, step time: 0.3159\n",
      "31/224, train_loss: 0.1116, step time: 0.3156\n",
      "32/224, train_loss: 0.1237, step time: 0.3182\n",
      "33/224, train_loss: 0.1008, step time: 0.3162\n",
      "34/224, train_loss: 0.1520, step time: 0.3144\n",
      "35/224, train_loss: 0.2755, step time: 0.3166\n",
      "36/224, train_loss: 0.3281, step time: 0.4046\n",
      "37/224, train_loss: 0.1889, step time: 0.3160\n",
      "38/224, train_loss: 0.2371, step time: 0.3159\n",
      "39/224, train_loss: 0.1505, step time: 0.3187\n",
      "40/224, train_loss: 0.1580, step time: 0.3758\n",
      "41/224, train_loss: 0.1455, step time: 0.3182\n",
      "42/224, train_loss: 0.0709, step time: 0.3190\n",
      "43/224, train_loss: 0.2780, step time: 0.3184\n",
      "44/224, train_loss: 0.0807, step time: 0.3154\n",
      "45/224, train_loss: 0.0639, step time: 0.4036\n",
      "46/224, train_loss: 0.1337, step time: 0.3994\n",
      "47/224, train_loss: 0.0722, step time: 0.3719\n",
      "48/224, train_loss: 0.1255, step time: 0.3991\n",
      "49/224, train_loss: 0.2332, step time: 0.4131\n",
      "50/224, train_loss: 0.0933, step time: 0.3164\n",
      "51/224, train_loss: 0.1354, step time: 0.3736\n",
      "52/224, train_loss: 0.1145, step time: 0.3154\n",
      "53/224, train_loss: 0.1025, step time: 0.3157\n",
      "54/224, train_loss: 0.0684, step time: 0.3164\n",
      "55/224, train_loss: 0.1084, step time: 0.3187\n",
      "56/224, train_loss: 0.1828, step time: 0.3144\n",
      "57/224, train_loss: 0.0846, step time: 0.3798\n",
      "58/224, train_loss: 0.0755, step time: 0.3165\n",
      "59/224, train_loss: 0.1924, step time: 0.3882\n",
      "60/224, train_loss: 0.0435, step time: 0.3155\n",
      "61/224, train_loss: 0.1383, step time: 0.3938\n",
      "62/224, train_loss: 0.1336, step time: 0.3172\n",
      "63/224, train_loss: 0.1862, step time: 0.3860\n",
      "64/224, train_loss: 0.0728, step time: 0.3164\n",
      "65/224, train_loss: 0.0771, step time: 0.3145\n",
      "66/224, train_loss: 0.0930, step time: 0.3167\n",
      "67/224, train_loss: 0.1523, step time: 0.3694\n",
      "68/224, train_loss: 0.1449, step time: 0.3164\n",
      "69/224, train_loss: 0.1148, step time: 0.4069\n",
      "70/224, train_loss: 0.0401, step time: 0.3182\n",
      "71/224, train_loss: 0.1065, step time: 0.3184\n",
      "72/224, train_loss: 0.1032, step time: 0.3159\n",
      "73/224, train_loss: 0.1483, step time: 0.3176\n",
      "74/224, train_loss: 0.0860, step time: 0.4084\n",
      "75/224, train_loss: 0.2451, step time: 0.4068\n",
      "76/224, train_loss: 0.0831, step time: 0.3164\n",
      "77/224, train_loss: 0.0902, step time: 0.4078\n",
      "78/224, train_loss: 0.1059, step time: 0.3843\n",
      "79/224, train_loss: 0.0722, step time: 0.3761\n",
      "80/224, train_loss: 0.1225, step time: 0.3699\n",
      "81/224, train_loss: 0.1356, step time: 0.3139\n",
      "82/224, train_loss: 0.0993, step time: 0.3978\n",
      "83/224, train_loss: 0.0732, step time: 0.3138\n",
      "84/224, train_loss: 0.0969, step time: 0.3142\n",
      "85/224, train_loss: 0.1878, step time: 0.3171\n",
      "86/224, train_loss: 0.1475, step time: 0.3195\n",
      "87/224, train_loss: 0.2430, step time: 0.3140\n",
      "88/224, train_loss: 0.0862, step time: 0.3179\n",
      "89/224, train_loss: 0.1180, step time: 0.3979\n",
      "90/224, train_loss: 0.1053, step time: 0.3163\n",
      "91/224, train_loss: 0.1315, step time: 0.3784\n",
      "92/224, train_loss: 0.0654, step time: 0.3157\n",
      "93/224, train_loss: 0.1015, step time: 0.3158\n",
      "94/224, train_loss: 0.1162, step time: 0.3155\n",
      "95/224, train_loss: 0.1873, step time: 0.3179\n",
      "96/224, train_loss: 0.1405, step time: 0.3723\n",
      "97/224, train_loss: 0.2238, step time: 0.4002\n",
      "98/224, train_loss: 0.1627, step time: 0.4123\n",
      "99/224, train_loss: 0.1189, step time: 0.4005\n",
      "100/224, train_loss: 0.0687, step time: 0.3183\n",
      "101/224, train_loss: 0.1083, step time: 0.3741\n",
      "102/224, train_loss: 0.2131, step time: 0.4128\n",
      "103/224, train_loss: 0.1086, step time: 0.3169\n",
      "104/224, train_loss: 0.1180, step time: 0.3187\n",
      "105/224, train_loss: 0.1030, step time: 0.3157\n",
      "106/224, train_loss: 0.0906, step time: 0.3160\n",
      "107/224, train_loss: 0.2516, step time: 0.3742\n",
      "108/224, train_loss: 0.1128, step time: 0.3765\n",
      "109/224, train_loss: 0.0995, step time: 0.3182\n",
      "110/224, train_loss: 0.1793, step time: 0.4109\n",
      "111/224, train_loss: 0.1103, step time: 0.4109\n",
      "112/224, train_loss: 0.1265, step time: 0.3182\n",
      "113/224, train_loss: 0.1492, step time: 0.3160\n",
      "114/224, train_loss: 0.1206, step time: 0.4019\n",
      "115/224, train_loss: 0.0684, step time: 0.4111\n",
      "116/224, train_loss: 0.1084, step time: 0.3166\n",
      "117/224, train_loss: 0.0714, step time: 0.3168\n",
      "118/224, train_loss: 0.1418, step time: 0.4179\n",
      "119/224, train_loss: 0.1059, step time: 0.4021\n",
      "120/224, train_loss: 0.0858, step time: 0.3160\n",
      "121/224, train_loss: 0.0864, step time: 0.4007\n",
      "122/224, train_loss: 0.2883, step time: 0.3935\n",
      "123/224, train_loss: 0.1445, step time: 0.3136\n",
      "124/224, train_loss: 0.0561, step time: 0.3154\n",
      "125/224, train_loss: 0.0768, step time: 0.3159\n",
      "126/224, train_loss: 0.1112, step time: 0.4011\n",
      "127/224, train_loss: 0.0652, step time: 0.3143\n",
      "128/224, train_loss: 0.0902, step time: 0.3168\n",
      "129/224, train_loss: 0.1433, step time: 0.3778\n",
      "130/224, train_loss: 0.1435, step time: 0.4088\n",
      "131/224, train_loss: 0.1874, step time: 0.3712\n",
      "132/224, train_loss: 0.1807, step time: 0.3167\n",
      "133/224, train_loss: 0.0686, step time: 0.3164\n",
      "134/224, train_loss: 0.1039, step time: 0.3799\n",
      "135/224, train_loss: 0.1553, step time: 0.3155\n",
      "136/224, train_loss: 0.1927, step time: 0.4041\n",
      "137/224, train_loss: 0.1378, step time: 0.3905\n",
      "138/224, train_loss: 0.2376, step time: 0.4092\n",
      "139/224, train_loss: 0.2601, step time: 0.4113\n",
      "140/224, train_loss: 0.1510, step time: 0.4105\n",
      "141/224, train_loss: 0.0573, step time: 0.3155\n",
      "142/224, train_loss: 0.0707, step time: 0.3182\n",
      "143/224, train_loss: 0.0935, step time: 0.3192\n",
      "144/224, train_loss: 0.1317, step time: 0.3165\n",
      "145/224, train_loss: 0.1583, step time: 0.3710\n",
      "146/224, train_loss: 0.1114, step time: 0.4002\n",
      "147/224, train_loss: 0.3193, step time: 0.4132\n",
      "148/224, train_loss: 0.1337, step time: 0.4109\n",
      "149/224, train_loss: 0.0432, step time: 0.3153\n",
      "150/224, train_loss: 0.1230, step time: 0.3158\n",
      "151/224, train_loss: 0.1113, step time: 0.3176\n",
      "152/224, train_loss: 0.1255, step time: 0.3824\n",
      "153/224, train_loss: 0.1680, step time: 0.3875\n",
      "154/224, train_loss: 0.0702, step time: 0.4133\n",
      "155/224, train_loss: 0.1063, step time: 0.3154\n",
      "156/224, train_loss: 0.1313, step time: 0.3179\n",
      "157/224, train_loss: 0.1051, step time: 0.3177\n",
      "158/224, train_loss: 0.1781, step time: 0.3806\n",
      "159/224, train_loss: 0.0660, step time: 0.3164\n",
      "160/224, train_loss: 0.1146, step time: 0.4050\n",
      "161/224, train_loss: 0.1392, step time: 0.3158\n",
      "162/224, train_loss: 0.0861, step time: 0.3158\n",
      "163/224, train_loss: 0.2038, step time: 0.3816\n",
      "164/224, train_loss: 0.0644, step time: 0.3172\n",
      "165/224, train_loss: 0.0995, step time: 0.3166\n",
      "166/224, train_loss: 0.0883, step time: 0.3160\n",
      "167/224, train_loss: 0.0981, step time: 0.3153\n",
      "168/224, train_loss: 0.1989, step time: 0.3893\n",
      "169/224, train_loss: 0.1057, step time: 0.3154\n",
      "170/224, train_loss: 0.0963, step time: 0.4070\n",
      "171/224, train_loss: 0.1415, step time: 0.3930\n",
      "172/224, train_loss: 0.1269, step time: 0.3164\n",
      "173/224, train_loss: 0.1309, step time: 0.4140\n",
      "174/224, train_loss: 0.0992, step time: 0.3914\n",
      "175/224, train_loss: 0.1077, step time: 0.3756\n",
      "176/224, train_loss: 0.1594, step time: 0.3766\n",
      "177/224, train_loss: 0.0656, step time: 0.3157\n",
      "178/224, train_loss: 0.1066, step time: 0.3146\n",
      "179/224, train_loss: 0.1225, step time: 0.4000\n",
      "180/224, train_loss: 0.0861, step time: 0.3191\n",
      "181/224, train_loss: 0.1765, step time: 0.3990\n",
      "182/224, train_loss: 0.1555, step time: 0.3962\n",
      "183/224, train_loss: 0.1373, step time: 0.4123\n",
      "184/224, train_loss: 0.0334, step time: 0.3791\n",
      "185/224, train_loss: 0.1861, step time: 0.3715\n",
      "186/224, train_loss: 0.5045, step time: 0.3994\n",
      "187/224, train_loss: 0.1189, step time: 0.3136\n",
      "188/224, train_loss: 0.1909, step time: 0.3152\n",
      "189/224, train_loss: 0.0715, step time: 0.3148\n",
      "190/224, train_loss: 0.1291, step time: 0.3147\n",
      "191/224, train_loss: 0.4400, step time: 0.3929\n",
      "192/224, train_loss: 0.1138, step time: 0.3149\n",
      "193/224, train_loss: 0.1828, step time: 0.4126\n",
      "194/224, train_loss: 0.3547, step time: 0.3905\n",
      "195/224, train_loss: 0.0847, step time: 0.3179\n",
      "196/224, train_loss: 0.2057, step time: 0.3979\n",
      "197/224, train_loss: 0.1324, step time: 0.3153\n",
      "198/224, train_loss: 0.1196, step time: 0.3750\n",
      "199/224, train_loss: 0.1446, step time: 0.3172\n",
      "200/224, train_loss: 0.0699, step time: 0.4171\n",
      "201/224, train_loss: 0.1405, step time: 0.3138\n",
      "202/224, train_loss: 0.0977, step time: 0.3896\n",
      "203/224, train_loss: 0.1070, step time: 0.3731\n",
      "204/224, train_loss: 0.1027, step time: 0.3156\n",
      "205/224, train_loss: 0.0539, step time: 0.3162\n",
      "206/224, train_loss: 0.0832, step time: 0.4051\n",
      "207/224, train_loss: 0.1604, step time: 0.3185\n",
      "208/224, train_loss: 0.1411, step time: 0.3164\n",
      "209/224, train_loss: 0.0835, step time: 0.3663\n",
      "210/224, train_loss: 0.1095, step time: 0.3179\n",
      "211/224, train_loss: 0.1139, step time: 0.3185\n",
      "212/224, train_loss: 0.1006, step time: 0.3160\n",
      "213/224, train_loss: 0.0803, step time: 0.4089\n",
      "214/224, train_loss: 0.0815, step time: 0.4028\n",
      "215/224, train_loss: 0.0725, step time: 0.3182\n",
      "216/224, train_loss: 0.2126, step time: 0.4012\n",
      "217/224, train_loss: 0.1913, step time: 0.4067\n",
      "218/224, train_loss: 0.0566, step time: 0.3133\n",
      "219/224, train_loss: 0.0686, step time: 0.3149\n",
      "220/224, train_loss: 0.0727, step time: 0.3146\n",
      "221/224, train_loss: 0.0859, step time: 0.3129\n",
      "222/224, train_loss: 0.0809, step time: 0.3916\n",
      "223/224, train_loss: 0.0724, step time: 0.3140\n",
      "224/224, train_loss: 0.1102, step time: 0.3156\n",
      "epoch 74 average loss: 0.1296\n",
      "current epoch: 74 current mean dice: 0.7156 class1: 0.9993 class2: 0.7383 class3: 0.4091\n",
      "best mean dice: 0.7156 at epoch: 74\n",
      "time consuming of epoch 74 is: 653.7605\n",
      "hello\n",
      "----------\n",
      "epoch 75/100\n",
      "1/224, train_loss: 0.0901, step time: 0.3178\n",
      "2/224, train_loss: 0.1529, step time: 0.3675\n",
      "3/224, train_loss: 0.1393, step time: 0.3146\n",
      "4/224, train_loss: 0.1684, step time: 0.3732\n",
      "5/224, train_loss: 0.0838, step time: 0.3147\n",
      "6/224, train_loss: 0.0591, step time: 0.3126\n",
      "7/224, train_loss: 0.1153, step time: 0.3169\n",
      "8/224, train_loss: 0.0539, step time: 0.3125\n",
      "9/224, train_loss: 0.1425, step time: 0.4035\n",
      "10/224, train_loss: 0.0883, step time: 0.3986\n",
      "11/224, train_loss: 0.1427, step time: 0.3135\n",
      "12/224, train_loss: 0.0509, step time: 0.3855\n",
      "13/224, train_loss: 0.1139, step time: 0.3689\n",
      "14/224, train_loss: 0.1795, step time: 0.3179\n",
      "15/224, train_loss: 0.2886, step time: 0.3892\n",
      "16/224, train_loss: 0.0961, step time: 0.4001\n",
      "17/224, train_loss: 0.0662, step time: 0.3829\n",
      "18/224, train_loss: 0.2231, step time: 0.3776\n",
      "19/224, train_loss: 0.0735, step time: 0.4044\n",
      "20/224, train_loss: 0.1027, step time: 0.3150\n",
      "21/224, train_loss: 0.0566, step time: 0.4140\n",
      "22/224, train_loss: 0.0918, step time: 0.3159\n",
      "23/224, train_loss: 0.2395, step time: 0.3171\n",
      "24/224, train_loss: 0.1842, step time: 0.3749\n",
      "25/224, train_loss: 0.0637, step time: 0.3934\n",
      "26/224, train_loss: 0.1616, step time: 0.4017\n",
      "27/224, train_loss: 0.1553, step time: 0.3153\n",
      "28/224, train_loss: 0.0622, step time: 0.3145\n",
      "29/224, train_loss: 0.1134, step time: 0.3127\n",
      "30/224, train_loss: 0.1557, step time: 0.3149\n",
      "31/224, train_loss: 0.1003, step time: 0.4097\n",
      "32/224, train_loss: 0.0418, step time: 0.3174\n",
      "33/224, train_loss: 0.1403, step time: 0.3135\n",
      "34/224, train_loss: 0.1046, step time: 0.3949\n",
      "35/224, train_loss: 0.0740, step time: 0.3152\n",
      "36/224, train_loss: 0.0992, step time: 0.4057\n",
      "37/224, train_loss: 0.1239, step time: 0.3933\n",
      "38/224, train_loss: 0.0933, step time: 0.3145\n",
      "39/224, train_loss: 0.1547, step time: 0.3896\n",
      "40/224, train_loss: 0.2375, step time: 0.3847\n",
      "41/224, train_loss: 0.2652, step time: 0.4082\n",
      "42/224, train_loss: 0.0604, step time: 0.3152\n",
      "43/224, train_loss: 0.1887, step time: 0.3804\n",
      "44/224, train_loss: 0.0933, step time: 0.3133\n",
      "45/224, train_loss: 0.0592, step time: 0.3154\n",
      "46/224, train_loss: 0.1531, step time: 0.3810\n",
      "47/224, train_loss: 0.1592, step time: 0.4034\n",
      "48/224, train_loss: 0.3507, step time: 0.3784\n",
      "49/224, train_loss: 0.0948, step time: 0.3147\n",
      "50/224, train_loss: 0.0858, step time: 0.3153\n",
      "51/224, train_loss: 0.1921, step time: 0.3783\n",
      "52/224, train_loss: 0.1771, step time: 0.3872\n",
      "53/224, train_loss: 0.1677, step time: 0.3733\n",
      "54/224, train_loss: 0.0673, step time: 0.3155\n",
      "55/224, train_loss: 0.0804, step time: 0.4014\n",
      "56/224, train_loss: 0.1388, step time: 0.3902\n",
      "57/224, train_loss: 0.0766, step time: 0.3169\n",
      "58/224, train_loss: 0.1083, step time: 0.3147\n",
      "59/224, train_loss: 0.1629, step time: 0.3679\n",
      "60/224, train_loss: 0.1879, step time: 0.3797\n",
      "61/224, train_loss: 0.1045, step time: 0.3144\n",
      "62/224, train_loss: 0.1026, step time: 0.3720\n",
      "63/224, train_loss: 0.1350, step time: 0.4106\n",
      "64/224, train_loss: 0.0654, step time: 0.3898\n",
      "65/224, train_loss: 0.1033, step time: 0.4094\n",
      "66/224, train_loss: 0.1148, step time: 0.3795\n",
      "67/224, train_loss: 0.0707, step time: 0.3156\n",
      "68/224, train_loss: 0.0661, step time: 0.4100\n",
      "69/224, train_loss: 0.2118, step time: 0.4030\n",
      "70/224, train_loss: 0.0578, step time: 0.3168\n",
      "71/224, train_loss: 0.3070, step time: 0.3750\n",
      "72/224, train_loss: 0.0945, step time: 0.3146\n",
      "73/224, train_loss: 0.0862, step time: 0.3904\n",
      "74/224, train_loss: 0.0925, step time: 0.3127\n",
      "75/224, train_loss: 0.1433, step time: 0.4097\n",
      "76/224, train_loss: 0.1228, step time: 0.3152\n",
      "77/224, train_loss: 0.0733, step time: 0.3868\n",
      "78/224, train_loss: 0.2709, step time: 0.3672\n",
      "79/224, train_loss: 0.0885, step time: 0.3127\n",
      "80/224, train_loss: 0.3201, step time: 0.3139\n",
      "81/224, train_loss: 0.0636, step time: 0.3173\n",
      "82/224, train_loss: 0.1031, step time: 0.3171\n",
      "83/224, train_loss: 0.0861, step time: 0.3832\n",
      "84/224, train_loss: 0.0440, step time: 0.3174\n",
      "85/224, train_loss: 0.1347, step time: 0.3159\n",
      "86/224, train_loss: 0.1766, step time: 0.3912\n",
      "87/224, train_loss: 0.2755, step time: 0.3982\n",
      "88/224, train_loss: 0.0762, step time: 0.3152\n",
      "89/224, train_loss: 0.1521, step time: 0.3860\n",
      "90/224, train_loss: 0.0951, step time: 0.3162\n",
      "91/224, train_loss: 0.3401, step time: 0.3949\n",
      "92/224, train_loss: 0.0757, step time: 0.3170\n",
      "93/224, train_loss: 0.1422, step time: 0.3886\n",
      "94/224, train_loss: 0.0923, step time: 0.4021\n",
      "95/224, train_loss: 0.3209, step time: 0.3921\n",
      "96/224, train_loss: 0.0934, step time: 0.3137\n",
      "97/224, train_loss: 0.0671, step time: 0.3153\n",
      "98/224, train_loss: 0.1974, step time: 0.3149\n",
      "99/224, train_loss: 0.1380, step time: 0.3795\n",
      "100/224, train_loss: 0.2124, step time: 0.3797\n",
      "101/224, train_loss: 0.1191, step time: 0.4066\n",
      "102/224, train_loss: 0.0805, step time: 0.3156\n",
      "103/224, train_loss: 0.0665, step time: 0.3156\n",
      "104/224, train_loss: 0.3497, step time: 0.3786\n",
      "105/224, train_loss: 0.1432, step time: 0.3148\n",
      "106/224, train_loss: 0.0999, step time: 0.3123\n",
      "107/224, train_loss: 0.0871, step time: 0.3146\n",
      "108/224, train_loss: 0.1208, step time: 0.3147\n",
      "109/224, train_loss: 0.0619, step time: 0.4734\n",
      "110/224, train_loss: 0.0928, step time: 0.3784\n",
      "111/224, train_loss: 0.0768, step time: 0.4027\n",
      "112/224, train_loss: 0.1667, step time: 0.3903\n",
      "113/224, train_loss: 0.0645, step time: 0.3130\n",
      "114/224, train_loss: 0.2005, step time: 0.3984\n",
      "115/224, train_loss: 0.1316, step time: 0.3844\n",
      "116/224, train_loss: 0.0967, step time: 0.3667\n",
      "117/224, train_loss: 0.2415, step time: 0.3149\n",
      "118/224, train_loss: 0.1103, step time: 0.3125\n",
      "119/224, train_loss: 0.0738, step time: 0.3154\n",
      "120/224, train_loss: 0.1336, step time: 0.3152\n",
      "121/224, train_loss: 0.1136, step time: 0.4073\n",
      "122/224, train_loss: 0.1396, step time: 0.3144\n",
      "123/224, train_loss: 0.0613, step time: 0.3152\n",
      "124/224, train_loss: 0.3934, step time: 0.3913\n",
      "125/224, train_loss: 0.0796, step time: 0.3148\n",
      "126/224, train_loss: 0.3144, step time: 0.4033\n",
      "127/224, train_loss: 0.0563, step time: 0.3173\n",
      "128/224, train_loss: 0.0988, step time: 0.3927\n",
      "129/224, train_loss: 0.1061, step time: 0.4050\n",
      "130/224, train_loss: 0.1534, step time: 0.3146\n",
      "131/224, train_loss: 0.1721, step time: 0.3781\n",
      "132/224, train_loss: 0.1116, step time: 0.3148\n",
      "133/224, train_loss: 0.1438, step time: 0.3769\n",
      "134/224, train_loss: 0.1244, step time: 0.4094\n",
      "135/224, train_loss: 0.0946, step time: 0.3919\n",
      "136/224, train_loss: 0.0722, step time: 0.3148\n",
      "137/224, train_loss: 0.0899, step time: 0.3169\n",
      "138/224, train_loss: 0.1451, step time: 0.3743\n",
      "139/224, train_loss: 0.1469, step time: 0.4013\n",
      "140/224, train_loss: 0.1060, step time: 0.3989\n",
      "141/224, train_loss: 0.0824, step time: 0.3161\n",
      "142/224, train_loss: 0.1173, step time: 0.3733\n",
      "143/224, train_loss: 0.0643, step time: 0.4063\n",
      "144/224, train_loss: 0.0609, step time: 0.3670\n",
      "145/224, train_loss: 0.1034, step time: 0.4012\n",
      "146/224, train_loss: 0.0619, step time: 0.3754\n",
      "147/224, train_loss: 0.0798, step time: 0.3178\n",
      "148/224, train_loss: 0.0714, step time: 0.3989\n",
      "149/224, train_loss: 0.0776, step time: 0.4037\n",
      "150/224, train_loss: 0.1128, step time: 0.3978\n",
      "151/224, train_loss: 0.0858, step time: 0.4002\n",
      "152/224, train_loss: 0.1253, step time: 0.3156\n",
      "153/224, train_loss: 0.1165, step time: 0.3158\n",
      "154/224, train_loss: 0.1604, step time: 0.3831\n",
      "155/224, train_loss: 0.0673, step time: 0.3179\n",
      "156/224, train_loss: 0.1447, step time: 0.3958\n",
      "157/224, train_loss: 0.0719, step time: 0.3151\n",
      "158/224, train_loss: 0.0926, step time: 0.3149\n",
      "159/224, train_loss: 0.0556, step time: 0.3737\n",
      "160/224, train_loss: 0.0955, step time: 0.3130\n",
      "161/224, train_loss: 0.0648, step time: 0.3939\n",
      "162/224, train_loss: 0.2695, step time: 0.3974\n",
      "163/224, train_loss: 0.0826, step time: 0.3148\n",
      "164/224, train_loss: 0.3491, step time: 0.3742\n",
      "165/224, train_loss: 0.1383, step time: 0.4024\n",
      "166/224, train_loss: 0.0869, step time: 0.4092\n",
      "167/224, train_loss: 0.3290, step time: 0.3906\n",
      "168/224, train_loss: 0.0755, step time: 0.3178\n",
      "169/224, train_loss: 0.1717, step time: 0.3898\n",
      "170/224, train_loss: 0.0535, step time: 0.3172\n",
      "171/224, train_loss: 0.1307, step time: 0.4007\n",
      "172/224, train_loss: 0.1344, step time: 0.4007\n",
      "173/224, train_loss: 0.1454, step time: 0.3830\n",
      "174/224, train_loss: 0.0880, step time: 0.3176\n",
      "175/224, train_loss: 0.0408, step time: 0.3847\n",
      "176/224, train_loss: 0.1344, step time: 0.3147\n",
      "177/224, train_loss: 0.1212, step time: 0.3151\n",
      "178/224, train_loss: 0.0921, step time: 0.3173\n",
      "179/224, train_loss: 0.0853, step time: 0.3152\n",
      "180/224, train_loss: 0.0852, step time: 0.3145\n",
      "181/224, train_loss: 0.1518, step time: 0.3986\n",
      "182/224, train_loss: 0.1299, step time: 0.3905\n",
      "183/224, train_loss: 0.1077, step time: 0.3169\n",
      "184/224, train_loss: 0.1470, step time: 0.3937\n",
      "185/224, train_loss: 0.0922, step time: 0.3127\n",
      "186/224, train_loss: 0.2066, step time: 0.3889\n",
      "187/224, train_loss: 0.2519, step time: 0.3675\n",
      "188/224, train_loss: 0.2213, step time: 0.3690\n",
      "189/224, train_loss: 0.1018, step time: 0.4096\n",
      "190/224, train_loss: 0.1451, step time: 0.4011\n",
      "191/224, train_loss: 0.1532, step time: 0.3675\n",
      "192/224, train_loss: 0.2472, step time: 0.3918\n",
      "193/224, train_loss: 0.0888, step time: 0.3180\n",
      "194/224, train_loss: 0.1266, step time: 0.3155\n",
      "195/224, train_loss: 0.1275, step time: 0.4071\n",
      "196/224, train_loss: 0.0729, step time: 0.3133\n",
      "197/224, train_loss: 0.0989, step time: 0.4046\n",
      "198/224, train_loss: 0.1245, step time: 0.3173\n",
      "199/224, train_loss: 0.1146, step time: 0.3702\n",
      "200/224, train_loss: 0.1074, step time: 0.3175\n",
      "201/224, train_loss: 0.3962, step time: 0.4094\n",
      "202/224, train_loss: 0.3466, step time: 0.3942\n",
      "203/224, train_loss: 0.1851, step time: 0.3147\n",
      "204/224, train_loss: 0.0679, step time: 0.3148\n",
      "205/224, train_loss: 0.1413, step time: 0.3870\n",
      "206/224, train_loss: 0.1023, step time: 0.3160\n",
      "207/224, train_loss: 0.0940, step time: 0.3160\n",
      "208/224, train_loss: 0.0733, step time: 0.4012\n",
      "209/224, train_loss: 0.0747, step time: 0.3178\n",
      "210/224, train_loss: 0.1063, step time: 0.3153\n",
      "211/224, train_loss: 0.1794, step time: 0.3998\n",
      "212/224, train_loss: 0.0715, step time: 0.3128\n",
      "213/224, train_loss: 0.2151, step time: 0.3687\n",
      "214/224, train_loss: 0.0986, step time: 0.4110\n",
      "215/224, train_loss: 0.1176, step time: 0.3125\n",
      "216/224, train_loss: 0.1178, step time: 0.3934\n",
      "217/224, train_loss: 0.1181, step time: 0.4119\n",
      "218/224, train_loss: 0.1637, step time: 0.3972\n",
      "219/224, train_loss: 0.1091, step time: 0.3149\n",
      "220/224, train_loss: 0.1960, step time: 0.3147\n",
      "221/224, train_loss: 0.1228, step time: 0.3125\n",
      "222/224, train_loss: 0.0640, step time: 0.3148\n",
      "223/224, train_loss: 0.0735, step time: 0.3173\n",
      "224/224, train_loss: 0.1189, step time: 0.4050\n",
      "epoch 75 average loss: 0.1304\n",
      "current epoch: 75 current mean dice: 0.6870 class1: 0.9993 class2: 0.7395 class3: 0.3221\n",
      "best mean dice: 0.7156 at epoch: 74\n",
      "time consuming of epoch 75 is: 783.6225\n",
      "hello\n",
      "----------\n",
      "epoch 76/100\n",
      "1/224, train_loss: 0.1864, step time: 0.3171\n",
      "2/224, train_loss: 0.0787, step time: 0.3149\n",
      "3/224, train_loss: 0.1838, step time: 0.4063\n",
      "4/224, train_loss: 0.1141, step time: 0.3711\n",
      "5/224, train_loss: 0.1076, step time: 0.3159\n",
      "6/224, train_loss: 0.3199, step time: 0.4013\n",
      "7/224, train_loss: 0.0816, step time: 0.3148\n",
      "8/224, train_loss: 0.0874, step time: 0.3942\n",
      "9/224, train_loss: 0.0593, step time: 0.3143\n",
      "10/224, train_loss: 0.0908, step time: 0.3127\n",
      "11/224, train_loss: 0.0936, step time: 0.3168\n",
      "12/224, train_loss: 0.1184, step time: 0.4063\n",
      "13/224, train_loss: 0.1685, step time: 0.3176\n",
      "14/224, train_loss: 0.2009, step time: 0.3836\n",
      "15/224, train_loss: 0.0696, step time: 0.4079\n",
      "16/224, train_loss: 0.1033, step time: 0.4053\n",
      "17/224, train_loss: 0.1340, step time: 0.3957\n",
      "18/224, train_loss: 0.1217, step time: 0.3135\n",
      "19/224, train_loss: 0.0854, step time: 0.3158\n",
      "20/224, train_loss: 0.0871, step time: 0.4065\n",
      "21/224, train_loss: 0.1097, step time: 0.3738\n",
      "22/224, train_loss: 0.0953, step time: 0.3157\n",
      "23/224, train_loss: 0.0783, step time: 0.3740\n",
      "24/224, train_loss: 0.2893, step time: 0.4036\n",
      "25/224, train_loss: 0.2404, step time: 0.3925\n",
      "26/224, train_loss: 0.2153, step time: 0.3812\n",
      "27/224, train_loss: 0.0894, step time: 0.3129\n",
      "28/224, train_loss: 0.2192, step time: 0.3176\n",
      "29/224, train_loss: 0.3460, step time: 0.3851\n",
      "30/224, train_loss: 0.0828, step time: 0.3151\n",
      "31/224, train_loss: 0.0511, step time: 0.3125\n",
      "32/224, train_loss: 0.1271, step time: 0.4064\n",
      "33/224, train_loss: 0.3153, step time: 0.4052\n",
      "34/224, train_loss: 0.0981, step time: 0.3181\n",
      "35/224, train_loss: 0.0985, step time: 0.3147\n",
      "36/224, train_loss: 0.0930, step time: 0.3154\n",
      "37/224, train_loss: 0.0497, step time: 0.3147\n",
      "38/224, train_loss: 0.3546, step time: 0.3721\n",
      "39/224, train_loss: 0.0638, step time: 0.3801\n",
      "40/224, train_loss: 0.0931, step time: 0.3173\n",
      "41/224, train_loss: 0.2662, step time: 0.3143\n",
      "42/224, train_loss: 0.2421, step time: 0.3989\n",
      "43/224, train_loss: 0.1658, step time: 0.3169\n",
      "44/224, train_loss: 0.0739, step time: 0.4084\n",
      "45/224, train_loss: 0.0893, step time: 0.3145\n",
      "46/224, train_loss: 0.2591, step time: 0.3912\n",
      "47/224, train_loss: 0.0914, step time: 0.3147\n",
      "48/224, train_loss: 0.1084, step time: 0.3950\n",
      "49/224, train_loss: 0.0986, step time: 0.3875\n",
      "50/224, train_loss: 0.1050, step time: 0.3147\n",
      "51/224, train_loss: 0.0879, step time: 0.3794\n",
      "52/224, train_loss: 0.2206, step time: 0.4063\n",
      "53/224, train_loss: 0.1188, step time: 0.3176\n",
      "54/224, train_loss: 0.0859, step time: 0.3153\n",
      "55/224, train_loss: 0.1241, step time: 0.3152\n",
      "56/224, train_loss: 0.0707, step time: 0.3158\n",
      "57/224, train_loss: 0.0947, step time: 0.3750\n",
      "58/224, train_loss: 0.0983, step time: 0.4000\n",
      "59/224, train_loss: 0.0744, step time: 0.3143\n",
      "60/224, train_loss: 0.0449, step time: 0.3152\n",
      "61/224, train_loss: 0.0814, step time: 0.3163\n",
      "62/224, train_loss: 0.0768, step time: 0.3139\n",
      "63/224, train_loss: 0.0630, step time: 0.3715\n",
      "64/224, train_loss: 0.1853, step time: 0.3776\n",
      "65/224, train_loss: 0.0857, step time: 0.3745\n",
      "66/224, train_loss: 0.0871, step time: 0.3170\n",
      "67/224, train_loss: 0.1222, step time: 0.3827\n",
      "68/224, train_loss: 0.2312, step time: 0.3819\n",
      "69/224, train_loss: 0.1351, step time: 0.3136\n",
      "70/224, train_loss: 0.1205, step time: 0.3129\n",
      "71/224, train_loss: 0.1220, step time: 0.3982\n",
      "72/224, train_loss: 0.0982, step time: 0.3174\n",
      "73/224, train_loss: 0.3289, step time: 0.3632\n",
      "74/224, train_loss: 0.3018, step time: 0.3852\n",
      "75/224, train_loss: 0.0615, step time: 0.3149\n",
      "76/224, train_loss: 0.1421, step time: 0.3155\n",
      "77/224, train_loss: 0.0826, step time: 0.3695\n",
      "78/224, train_loss: 0.3228, step time: 0.4041\n",
      "79/224, train_loss: 0.1110, step time: 0.3767\n",
      "80/224, train_loss: 0.1583, step time: 0.3814\n",
      "81/224, train_loss: 0.0763, step time: 0.3123\n",
      "82/224, train_loss: 0.0648, step time: 0.3757\n",
      "83/224, train_loss: 0.0717, step time: 0.3146\n",
      "84/224, train_loss: 0.1115, step time: 0.3724\n",
      "85/224, train_loss: 0.0991, step time: 0.3734\n",
      "86/224, train_loss: 0.0969, step time: 0.3155\n",
      "87/224, train_loss: 0.3574, step time: 0.4017\n",
      "88/224, train_loss: 0.0966, step time: 0.3921\n",
      "89/224, train_loss: 0.1887, step time: 0.3720\n",
      "90/224, train_loss: 0.0751, step time: 0.3147\n",
      "91/224, train_loss: 0.0758, step time: 0.3169\n",
      "92/224, train_loss: 0.1207, step time: 0.3989\n",
      "93/224, train_loss: 0.2182, step time: 0.3645\n",
      "94/224, train_loss: 0.0908, step time: 0.3952\n",
      "95/224, train_loss: 0.1196, step time: 0.3730\n",
      "96/224, train_loss: 0.1282, step time: 0.3793\n",
      "97/224, train_loss: 0.1284, step time: 0.3148\n",
      "98/224, train_loss: 0.1204, step time: 0.3145\n",
      "99/224, train_loss: 0.0635, step time: 0.4012\n",
      "100/224, train_loss: 0.2222, step time: 0.3149\n",
      "101/224, train_loss: 0.1026, step time: 0.3150\n",
      "102/224, train_loss: 0.0671, step time: 0.3150\n",
      "103/224, train_loss: 0.2410, step time: 0.3904\n",
      "104/224, train_loss: 0.1597, step time: 0.3142\n",
      "105/224, train_loss: 0.0885, step time: 0.3924\n",
      "106/224, train_loss: 0.3315, step time: 0.3947\n",
      "107/224, train_loss: 0.0969, step time: 0.3952\n",
      "108/224, train_loss: 0.0782, step time: 0.3143\n",
      "109/224, train_loss: 0.1089, step time: 0.3119\n",
      "110/224, train_loss: 0.2206, step time: 0.4050\n",
      "111/224, train_loss: 0.0723, step time: 0.3120\n",
      "112/224, train_loss: 0.1131, step time: 0.3144\n",
      "113/224, train_loss: 0.1447, step time: 0.3890\n",
      "114/224, train_loss: 0.0832, step time: 0.3143\n",
      "115/224, train_loss: 0.1785, step time: 0.3802\n",
      "116/224, train_loss: 0.2454, step time: 0.3168\n",
      "117/224, train_loss: 0.1287, step time: 0.3120\n",
      "118/224, train_loss: 0.1587, step time: 0.3121\n",
      "119/224, train_loss: 0.2063, step time: 0.3842\n",
      "120/224, train_loss: 0.1171, step time: 0.3166\n",
      "121/224, train_loss: 0.3813, step time: 0.3145\n",
      "122/224, train_loss: 0.1080, step time: 0.3899\n",
      "123/224, train_loss: 0.1424, step time: 0.4013\n",
      "124/224, train_loss: 0.0849, step time: 0.3174\n",
      "125/224, train_loss: 0.0965, step time: 0.3167\n",
      "126/224, train_loss: 0.1367, step time: 0.3717\n",
      "127/224, train_loss: 0.0834, step time: 0.3164\n",
      "128/224, train_loss: 0.0885, step time: 0.3150\n",
      "129/224, train_loss: 0.1322, step time: 0.3934\n",
      "130/224, train_loss: 0.1607, step time: 0.3695\n",
      "131/224, train_loss: 0.1020, step time: 0.3150\n",
      "132/224, train_loss: 0.1450, step time: 0.3691\n",
      "133/224, train_loss: 0.0706, step time: 0.3145\n",
      "134/224, train_loss: 0.1336, step time: 0.3812\n",
      "135/224, train_loss: 0.1954, step time: 0.3721\n",
      "136/224, train_loss: 0.0843, step time: 0.3768\n",
      "137/224, train_loss: 0.0694, step time: 0.3151\n",
      "138/224, train_loss: 0.0749, step time: 0.3723\n",
      "139/224, train_loss: 0.0579, step time: 0.3144\n",
      "140/224, train_loss: 0.1015, step time: 0.4060\n",
      "141/224, train_loss: 0.1432, step time: 0.3922\n",
      "142/224, train_loss: 0.0623, step time: 0.3130\n",
      "143/224, train_loss: 0.0833, step time: 0.3150\n",
      "144/224, train_loss: 0.1932, step time: 0.3737\n",
      "145/224, train_loss: 0.2344, step time: 0.4073\n",
      "146/224, train_loss: 0.0796, step time: 0.3169\n",
      "147/224, train_loss: 0.0711, step time: 0.3162\n",
      "148/224, train_loss: 0.0896, step time: 0.3162\n",
      "149/224, train_loss: 0.2202, step time: 0.3160\n",
      "150/224, train_loss: 0.0750, step time: 0.3146\n",
      "151/224, train_loss: 0.1446, step time: 0.3881\n",
      "152/224, train_loss: 0.3110, step time: 0.3889\n",
      "153/224, train_loss: 0.0851, step time: 0.4032\n",
      "154/224, train_loss: 0.2298, step time: 0.4076\n",
      "155/224, train_loss: 0.2204, step time: 0.3675\n",
      "156/224, train_loss: 0.1616, step time: 0.3806\n",
      "157/224, train_loss: 0.0798, step time: 0.3675\n",
      "158/224, train_loss: 0.1330, step time: 0.3784\n",
      "159/224, train_loss: 0.0883, step time: 0.3181\n",
      "160/224, train_loss: 0.2939, step time: 0.3725\n",
      "161/224, train_loss: 0.0767, step time: 0.3177\n",
      "162/224, train_loss: 0.0809, step time: 0.3141\n",
      "163/224, train_loss: 0.3810, step time: 0.3717\n",
      "164/224, train_loss: 0.1635, step time: 0.4036\n",
      "165/224, train_loss: 0.0670, step time: 0.3879\n",
      "166/224, train_loss: 0.0880, step time: 0.3129\n",
      "167/224, train_loss: 0.1124, step time: 0.3147\n",
      "168/224, train_loss: 0.0985, step time: 0.3149\n",
      "169/224, train_loss: 0.0997, step time: 0.3138\n",
      "170/224, train_loss: 0.0803, step time: 0.3691\n",
      "171/224, train_loss: 0.0898, step time: 0.3149\n",
      "172/224, train_loss: 0.0965, step time: 0.3148\n",
      "173/224, train_loss: 0.0452, step time: 0.3149\n",
      "174/224, train_loss: 0.0943, step time: 0.3153\n",
      "175/224, train_loss: 0.1255, step time: 0.3174\n",
      "176/224, train_loss: 0.1001, step time: 0.3147\n",
      "177/224, train_loss: 0.3586, step time: 0.3661\n",
      "178/224, train_loss: 0.0691, step time: 0.4120\n",
      "179/224, train_loss: 0.1309, step time: 0.4079\n",
      "180/224, train_loss: 0.1754, step time: 0.3916\n",
      "181/224, train_loss: 0.0714, step time: 0.3672\n",
      "182/224, train_loss: 0.0676, step time: 0.3152\n",
      "183/224, train_loss: 0.1277, step time: 0.3157\n",
      "184/224, train_loss: 0.0935, step time: 0.3996\n",
      "185/224, train_loss: 0.2632, step time: 0.4106\n",
      "186/224, train_loss: 0.1220, step time: 0.3159\n",
      "187/224, train_loss: 0.0662, step time: 0.3150\n",
      "188/224, train_loss: 0.0758, step time: 0.3147\n",
      "189/224, train_loss: 0.1508, step time: 0.3818\n",
      "190/224, train_loss: 0.1147, step time: 0.3171\n",
      "191/224, train_loss: 0.1542, step time: 0.3936\n",
      "192/224, train_loss: 0.0940, step time: 0.3730\n",
      "193/224, train_loss: 0.1119, step time: 0.3151\n",
      "194/224, train_loss: 0.1670, step time: 0.4009\n",
      "195/224, train_loss: 0.0929, step time: 0.3151\n",
      "196/224, train_loss: 0.0784, step time: 0.3126\n",
      "197/224, train_loss: 0.1750, step time: 0.3708\n",
      "198/224, train_loss: 0.0690, step time: 0.3171\n",
      "199/224, train_loss: 0.0965, step time: 0.3156\n",
      "200/224, train_loss: 0.1443, step time: 0.4056\n",
      "201/224, train_loss: 0.1467, step time: 0.3150\n",
      "202/224, train_loss: 0.0761, step time: 0.3148\n",
      "203/224, train_loss: 0.0854, step time: 0.3171\n",
      "204/224, train_loss: 0.1262, step time: 0.4045\n",
      "205/224, train_loss: 0.2933, step time: 0.3766\n",
      "206/224, train_loss: 0.1091, step time: 0.3161\n",
      "207/224, train_loss: 0.0612, step time: 0.3655\n",
      "208/224, train_loss: 0.1323, step time: 0.3128\n",
      "209/224, train_loss: 0.1427, step time: 0.3155\n",
      "210/224, train_loss: 0.3082, step time: 0.3146\n",
      "211/224, train_loss: 0.0689, step time: 0.3158\n",
      "212/224, train_loss: 0.1184, step time: 0.3179\n",
      "213/224, train_loss: 0.0744, step time: 0.3172\n",
      "214/224, train_loss: 0.1120, step time: 0.4056\n",
      "215/224, train_loss: 0.0748, step time: 0.3158\n",
      "216/224, train_loss: 0.1009, step time: 0.3151\n",
      "217/224, train_loss: 0.0874, step time: 0.3131\n",
      "218/224, train_loss: 0.3543, step time: 0.3946\n",
      "219/224, train_loss: 0.2759, step time: 0.3803\n",
      "220/224, train_loss: 0.1143, step time: 0.3158\n",
      "221/224, train_loss: 0.0928, step time: 0.3149\n",
      "222/224, train_loss: 0.0935, step time: 0.4079\n",
      "223/224, train_loss: 0.2518, step time: 0.4041\n",
      "224/224, train_loss: 0.1295, step time: 0.3878\n",
      "epoch 76 average loss: 0.1351\n",
      "current epoch: 76 current mean dice: 0.7145 class1: 0.9993 class2: 0.7400 class3: 0.4043\n",
      "best mean dice: 0.7156 at epoch: 74\n",
      "time consuming of epoch 76 is: 747.4363\n",
      "hello\n",
      "----------\n",
      "epoch 77/100\n",
      "1/224, train_loss: 0.1190, step time: 0.3999\n",
      "2/224, train_loss: 0.1171, step time: 0.3163\n",
      "3/224, train_loss: 0.0786, step time: 0.3157\n",
      "4/224, train_loss: 0.1057, step time: 0.3172\n",
      "5/224, train_loss: 0.1390, step time: 0.3148\n",
      "6/224, train_loss: 0.0985, step time: 0.3182\n",
      "7/224, train_loss: 0.0552, step time: 0.3131\n",
      "8/224, train_loss: 0.1948, step time: 0.3680\n",
      "9/224, train_loss: 0.1059, step time: 0.3150\n",
      "10/224, train_loss: 0.0669, step time: 0.3170\n",
      "11/224, train_loss: 0.0950, step time: 0.3146\n",
      "12/224, train_loss: 0.0824, step time: 0.3168\n",
      "13/224, train_loss: 0.0763, step time: 0.3234\n",
      "14/224, train_loss: 0.1024, step time: 0.3773\n",
      "15/224, train_loss: 0.1120, step time: 0.3881\n",
      "16/224, train_loss: 0.0882, step time: 0.4000\n",
      "17/224, train_loss: 0.1209, step time: 0.3150\n",
      "18/224, train_loss: 0.1566, step time: 0.3926\n",
      "19/224, train_loss: 0.0589, step time: 0.3142\n",
      "20/224, train_loss: 0.1350, step time: 0.3847\n",
      "21/224, train_loss: 0.1472, step time: 0.3931\n",
      "22/224, train_loss: 0.0858, step time: 0.3167\n",
      "23/224, train_loss: 0.1137, step time: 0.3151\n",
      "24/224, train_loss: 0.1069, step time: 0.3176\n",
      "25/224, train_loss: 0.0872, step time: 0.3156\n",
      "26/224, train_loss: 0.2376, step time: 0.3845\n",
      "27/224, train_loss: 0.0641, step time: 0.3832\n",
      "28/224, train_loss: 0.0957, step time: 0.3126\n",
      "29/224, train_loss: 0.1518, step time: 0.3172\n",
      "30/224, train_loss: 0.3811, step time: 0.3944\n",
      "31/224, train_loss: 0.1333, step time: 0.3763\n",
      "32/224, train_loss: 0.1598, step time: 0.3858\n",
      "33/224, train_loss: 0.2388, step time: 0.3702\n",
      "34/224, train_loss: 0.1471, step time: 0.3140\n",
      "35/224, train_loss: 0.0818, step time: 0.3166\n",
      "36/224, train_loss: 0.0803, step time: 0.3147\n",
      "37/224, train_loss: 0.0646, step time: 0.3146\n",
      "38/224, train_loss: 0.0996, step time: 0.3120\n",
      "39/224, train_loss: 0.2564, step time: 0.4015\n",
      "40/224, train_loss: 0.1131, step time: 0.3149\n",
      "41/224, train_loss: 0.1839, step time: 0.4098\n",
      "42/224, train_loss: 0.0811, step time: 0.3150\n",
      "43/224, train_loss: 0.1205, step time: 0.3133\n",
      "44/224, train_loss: 0.1169, step time: 0.3159\n",
      "45/224, train_loss: 0.1110, step time: 0.3687\n",
      "46/224, train_loss: 0.1643, step time: 0.3907\n",
      "47/224, train_loss: 0.3412, step time: 0.3152\n",
      "48/224, train_loss: 0.2127, step time: 0.3710\n",
      "49/224, train_loss: 0.0979, step time: 0.3151\n",
      "50/224, train_loss: 0.0996, step time: 0.4099\n",
      "51/224, train_loss: 0.1507, step time: 0.3932\n",
      "52/224, train_loss: 0.2092, step time: 0.3767\n",
      "53/224, train_loss: 0.0875, step time: 0.3149\n",
      "54/224, train_loss: 0.1329, step time: 0.3129\n",
      "55/224, train_loss: 0.0536, step time: 0.3153\n",
      "56/224, train_loss: 0.1012, step time: 0.4097\n",
      "57/224, train_loss: 0.0620, step time: 0.3146\n",
      "58/224, train_loss: 0.0860, step time: 0.3152\n",
      "59/224, train_loss: 0.1199, step time: 0.3905\n",
      "60/224, train_loss: 0.0999, step time: 0.3146\n",
      "61/224, train_loss: 0.2425, step time: 0.3980\n",
      "62/224, train_loss: 0.1201, step time: 0.3928\n",
      "63/224, train_loss: 0.0781, step time: 0.3744\n",
      "64/224, train_loss: 0.1385, step time: 0.3927\n",
      "65/224, train_loss: 0.0986, step time: 0.3902\n",
      "66/224, train_loss: 0.0780, step time: 0.3140\n",
      "67/224, train_loss: 0.1924, step time: 0.3767\n",
      "68/224, train_loss: 0.3695, step time: 0.3167\n",
      "69/224, train_loss: 0.0937, step time: 0.3135\n",
      "70/224, train_loss: 0.0753, step time: 0.3169\n",
      "71/224, train_loss: 0.0838, step time: 0.3166\n",
      "72/224, train_loss: 0.0859, step time: 0.3905\n",
      "73/224, train_loss: 0.0745, step time: 0.3165\n",
      "74/224, train_loss: 0.1104, step time: 0.3644\n",
      "75/224, train_loss: 0.1006, step time: 0.3143\n",
      "76/224, train_loss: 0.0625, step time: 0.4105\n",
      "77/224, train_loss: 0.0920, step time: 0.4026\n",
      "78/224, train_loss: 0.1174, step time: 0.3721\n",
      "79/224, train_loss: 0.0683, step time: 0.3121\n",
      "80/224, train_loss: 0.0812, step time: 0.3720\n",
      "81/224, train_loss: 0.1724, step time: 0.3733\n",
      "82/224, train_loss: 0.1180, step time: 0.3739\n",
      "83/224, train_loss: 0.0711, step time: 0.3151\n",
      "84/224, train_loss: 0.0817, step time: 0.3151\n",
      "85/224, train_loss: 0.0797, step time: 0.3170\n",
      "86/224, train_loss: 0.1291, step time: 0.3149\n",
      "87/224, train_loss: 0.0667, step time: 0.3172\n",
      "88/224, train_loss: 0.0605, step time: 0.3142\n",
      "89/224, train_loss: 0.0810, step time: 0.3167\n",
      "90/224, train_loss: 0.0778, step time: 0.3124\n",
      "91/224, train_loss: 0.0527, step time: 0.3146\n",
      "92/224, train_loss: 0.2526, step time: 0.3697\n",
      "93/224, train_loss: 0.1735, step time: 0.3142\n",
      "94/224, train_loss: 0.0944, step time: 0.3749\n",
      "95/224, train_loss: 0.1697, step time: 0.3979\n",
      "96/224, train_loss: 0.0730, step time: 0.3157\n",
      "97/224, train_loss: 0.1131, step time: 0.3154\n",
      "98/224, train_loss: 0.2146, step time: 0.3808\n",
      "99/224, train_loss: 0.1016, step time: 0.3927\n",
      "100/224, train_loss: 0.0561, step time: 0.3156\n",
      "101/224, train_loss: 0.0922, step time: 0.3145\n",
      "102/224, train_loss: 0.1312, step time: 0.3164\n",
      "103/224, train_loss: 0.1078, step time: 0.3766\n",
      "104/224, train_loss: 0.0661, step time: 0.3157\n",
      "105/224, train_loss: 0.0566, step time: 0.3149\n",
      "106/224, train_loss: 0.0816, step time: 0.4001\n",
      "107/224, train_loss: 0.1216, step time: 0.3154\n",
      "108/224, train_loss: 0.2604, step time: 0.3774\n",
      "109/224, train_loss: 0.0485, step time: 0.3148\n",
      "110/224, train_loss: 0.1103, step time: 0.3153\n",
      "111/224, train_loss: 0.2161, step time: 0.3182\n",
      "112/224, train_loss: 0.2488, step time: 0.3694\n",
      "113/224, train_loss: 0.1766, step time: 0.3882\n",
      "114/224, train_loss: 0.0714, step time: 0.3208\n",
      "115/224, train_loss: 0.1509, step time: 0.3190\n",
      "116/224, train_loss: 0.1637, step time: 0.3202\n",
      "117/224, train_loss: 0.1187, step time: 0.3748\n",
      "118/224, train_loss: 0.0843, step time: 0.4071\n",
      "119/224, train_loss: 0.0872, step time: 0.3731\n",
      "120/224, train_loss: 0.0660, step time: 0.3173\n",
      "121/224, train_loss: 0.1532, step time: 0.3904\n",
      "122/224, train_loss: 0.2045, step time: 0.3190\n",
      "123/224, train_loss: 0.0724, step time: 0.3161\n",
      "124/224, train_loss: 0.0795, step time: 0.3791\n",
      "125/224, train_loss: 0.0706, step time: 0.3720\n",
      "126/224, train_loss: 0.2612, step time: 0.3715\n",
      "127/224, train_loss: 0.0915, step time: 0.3692\n",
      "128/224, train_loss: 0.1049, step time: 0.3151\n",
      "129/224, train_loss: 0.0585, step time: 0.3172\n",
      "130/224, train_loss: 0.0932, step time: 0.3177\n",
      "131/224, train_loss: 0.1005, step time: 0.3745\n",
      "132/224, train_loss: 0.2621, step time: 0.3249\n",
      "133/224, train_loss: 0.0957, step time: 0.3864\n",
      "134/224, train_loss: 0.0893, step time: 0.3873\n",
      "135/224, train_loss: 0.1313, step time: 0.3977\n",
      "136/224, train_loss: 0.0620, step time: 0.3171\n",
      "137/224, train_loss: 0.1331, step time: 0.3175\n",
      "138/224, train_loss: 0.0973, step time: 0.3989\n",
      "139/224, train_loss: 0.0919, step time: 0.3698\n",
      "140/224, train_loss: 0.1063, step time: 0.3167\n",
      "141/224, train_loss: 0.1318, step time: 0.3144\n",
      "142/224, train_loss: 0.1299, step time: 0.3142\n",
      "143/224, train_loss: 0.1622, step time: 0.4059\n",
      "144/224, train_loss: 0.1314, step time: 0.3899\n",
      "145/224, train_loss: 0.1327, step time: 0.3692\n",
      "146/224, train_loss: 0.0898, step time: 0.3208\n",
      "147/224, train_loss: 0.0620, step time: 0.4015\n",
      "148/224, train_loss: 0.2207, step time: 0.3948\n",
      "149/224, train_loss: 0.0842, step time: 0.4048\n",
      "150/224, train_loss: 0.1885, step time: 0.3918\n",
      "151/224, train_loss: 0.1478, step time: 0.3898\n",
      "152/224, train_loss: 0.1714, step time: 0.4150\n",
      "153/224, train_loss: 0.1206, step time: 0.3771\n",
      "154/224, train_loss: 0.2882, step time: 0.3786\n",
      "155/224, train_loss: 0.1323, step time: 0.3198\n",
      "156/224, train_loss: 0.0966, step time: 0.3814\n",
      "157/224, train_loss: 0.0814, step time: 0.3164\n",
      "158/224, train_loss: 0.4510, step time: 0.3856\n",
      "159/224, train_loss: 0.1047, step time: 0.3775\n",
      "160/224, train_loss: 0.1169, step time: 0.3702\n",
      "161/224, train_loss: 0.1178, step time: 0.3897\n",
      "162/224, train_loss: 0.0836, step time: 0.3203\n",
      "163/224, train_loss: 0.1588, step time: 0.3912\n",
      "164/224, train_loss: 0.1568, step time: 0.3844\n",
      "165/224, train_loss: 0.0888, step time: 0.3152\n",
      "166/224, train_loss: 0.2444, step time: 0.4130\n",
      "167/224, train_loss: 0.1220, step time: 0.3820\n",
      "168/224, train_loss: 0.0754, step time: 0.3956\n",
      "169/224, train_loss: 0.0714, step time: 0.3144\n",
      "170/224, train_loss: 0.0854, step time: 0.3140\n",
      "171/224, train_loss: 0.1395, step time: 0.3162\n",
      "172/224, train_loss: 0.0803, step time: 0.3816\n",
      "173/224, train_loss: 0.0890, step time: 0.3172\n",
      "174/224, train_loss: 0.0577, step time: 0.3150\n",
      "175/224, train_loss: 0.0583, step time: 0.3165\n",
      "176/224, train_loss: 0.1339, step time: 0.4017\n",
      "177/224, train_loss: 0.1107, step time: 0.3935\n",
      "178/224, train_loss: 0.1182, step time: 0.3937\n",
      "179/224, train_loss: 0.1230, step time: 0.3158\n",
      "180/224, train_loss: 0.0742, step time: 0.3143\n",
      "181/224, train_loss: 0.2097, step time: 0.3146\n",
      "182/224, train_loss: 0.1009, step time: 0.3192\n",
      "183/224, train_loss: 0.1163, step time: 0.3894\n",
      "184/224, train_loss: 0.0804, step time: 0.3172\n",
      "185/224, train_loss: 0.0911, step time: 0.3210\n",
      "186/224, train_loss: 0.2414, step time: 0.3723\n",
      "187/224, train_loss: 0.0870, step time: 0.3158\n",
      "188/224, train_loss: 0.0893, step time: 0.3176\n",
      "189/224, train_loss: 0.1058, step time: 0.3895\n",
      "190/224, train_loss: 0.0855, step time: 0.3154\n",
      "191/224, train_loss: 0.1199, step time: 0.3157\n",
      "192/224, train_loss: 0.0554, step time: 0.3900\n",
      "193/224, train_loss: 0.1399, step time: 0.3989\n",
      "194/224, train_loss: 0.0837, step time: 0.4043\n",
      "195/224, train_loss: 0.0804, step time: 0.3180\n",
      "196/224, train_loss: 0.2585, step time: 0.3179\n",
      "197/224, train_loss: 0.1409, step time: 0.4125\n",
      "198/224, train_loss: 0.0533, step time: 0.4064\n",
      "199/224, train_loss: 0.2459, step time: 0.3687\n",
      "200/224, train_loss: 0.1265, step time: 0.3920\n",
      "201/224, train_loss: 0.0598, step time: 0.3187\n",
      "202/224, train_loss: 0.0811, step time: 0.4144\n",
      "203/224, train_loss: 0.1299, step time: 0.3196\n",
      "204/224, train_loss: 0.1199, step time: 0.3197\n",
      "205/224, train_loss: 0.1020, step time: 0.3172\n",
      "206/224, train_loss: 0.3030, step time: 0.3716\n",
      "207/224, train_loss: 0.1232, step time: 0.3156\n",
      "208/224, train_loss: 0.2608, step time: 0.3723\n",
      "209/224, train_loss: 0.1323, step time: 0.3172\n",
      "210/224, train_loss: 0.1615, step time: 0.3756\n",
      "211/224, train_loss: 0.1084, step time: 0.3948\n",
      "212/224, train_loss: 0.1050, step time: 0.3798\n",
      "213/224, train_loss: 0.0840, step time: 0.3190\n",
      "214/224, train_loss: 0.2329, step time: 0.3194\n",
      "215/224, train_loss: 0.0853, step time: 0.3199\n",
      "216/224, train_loss: 0.0839, step time: 0.4068\n",
      "217/224, train_loss: 0.0860, step time: 0.4048\n",
      "218/224, train_loss: 0.0848, step time: 0.3181\n",
      "219/224, train_loss: 0.0713, step time: 0.3138\n",
      "220/224, train_loss: 0.3414, step time: 0.3917\n",
      "221/224, train_loss: 0.0548, step time: 0.3793\n",
      "222/224, train_loss: 0.0947, step time: 0.3171\n",
      "223/224, train_loss: 0.0825, step time: 0.4154\n",
      "224/224, train_loss: 0.1184, step time: 0.3763\n",
      "epoch 77 average loss: 0.1244\n",
      "current epoch: 77 current mean dice: 0.6854 class1: 0.9994 class2: 0.7291 class3: 0.3276\n",
      "best mean dice: 0.7156 at epoch: 74\n",
      "time consuming of epoch 77 is: 724.5901\n",
      "hello\n",
      "----------\n",
      "epoch 78/100\n",
      "1/224, train_loss: 0.0685, step time: 0.3947\n",
      "2/224, train_loss: 0.1026, step time: 0.3993\n",
      "3/224, train_loss: 0.0444, step time: 0.3165\n",
      "4/224, train_loss: 0.0893, step time: 0.3193\n",
      "5/224, train_loss: 0.0816, step time: 0.3197\n",
      "6/224, train_loss: 0.0977, step time: 0.3190\n",
      "7/224, train_loss: 0.1240, step time: 0.3186\n",
      "8/224, train_loss: 0.0652, step time: 0.3172\n",
      "9/224, train_loss: 0.0796, step time: 0.4076\n",
      "10/224, train_loss: 0.3414, step time: 0.3703\n",
      "11/224, train_loss: 0.1407, step time: 0.3190\n",
      "12/224, train_loss: 0.1892, step time: 0.3166\n",
      "13/224, train_loss: 0.1253, step time: 0.3898\n",
      "14/224, train_loss: 0.0912, step time: 0.4079\n",
      "15/224, train_loss: 0.2136, step time: 0.3933\n",
      "16/224, train_loss: 0.1627, step time: 0.3186\n",
      "17/224, train_loss: 0.0698, step time: 0.3163\n",
      "18/224, train_loss: 0.1390, step time: 0.3162\n",
      "19/224, train_loss: 0.1794, step time: 0.3164\n",
      "20/224, train_loss: 0.0667, step time: 0.3170\n",
      "21/224, train_loss: 0.1031, step time: 0.3162\n",
      "22/224, train_loss: 0.1014, step time: 0.3163\n",
      "23/224, train_loss: 0.2271, step time: 0.3190\n",
      "24/224, train_loss: 0.2604, step time: 0.4044\n",
      "25/224, train_loss: 0.2278, step time: 0.3802\n",
      "26/224, train_loss: 0.1161, step time: 0.3750\n",
      "27/224, train_loss: 0.0398, step time: 0.3161\n",
      "28/224, train_loss: 0.3797, step time: 0.4053\n",
      "29/224, train_loss: 0.1120, step time: 0.4059\n",
      "30/224, train_loss: 0.1170, step time: 0.3921\n",
      "31/224, train_loss: 0.0890, step time: 0.4091\n",
      "32/224, train_loss: 0.1343, step time: 0.4129\n",
      "33/224, train_loss: 0.0766, step time: 0.3877\n",
      "34/224, train_loss: 0.0572, step time: 0.3147\n",
      "35/224, train_loss: 0.1035, step time: 0.3192\n",
      "36/224, train_loss: 0.0819, step time: 0.3162\n",
      "37/224, train_loss: 0.1119, step time: 0.3163\n",
      "38/224, train_loss: 0.0780, step time: 0.4022\n",
      "39/224, train_loss: 0.1509, step time: 0.4137\n",
      "40/224, train_loss: 0.1513, step time: 0.3157\n",
      "41/224, train_loss: 0.2113, step time: 0.3684\n",
      "42/224, train_loss: 0.1207, step time: 0.3146\n",
      "43/224, train_loss: 0.2605, step time: 0.3952\n",
      "44/224, train_loss: 0.0473, step time: 0.3177\n",
      "45/224, train_loss: 0.0980, step time: 0.3155\n",
      "46/224, train_loss: 0.0882, step time: 0.3155\n",
      "47/224, train_loss: 0.1111, step time: 0.3693\n",
      "48/224, train_loss: 0.0854, step time: 0.3179\n",
      "49/224, train_loss: 0.0784, step time: 0.3181\n",
      "50/224, train_loss: 0.1025, step time: 0.4029\n",
      "51/224, train_loss: 0.0389, step time: 0.3141\n",
      "52/224, train_loss: 0.0674, step time: 0.4074\n",
      "53/224, train_loss: 0.0528, step time: 0.3909\n",
      "54/224, train_loss: 0.0968, step time: 0.4016\n",
      "55/224, train_loss: 0.0764, step time: 0.3146\n",
      "56/224, train_loss: 0.0785, step time: 0.4070\n",
      "57/224, train_loss: 0.0952, step time: 0.3158\n",
      "58/224, train_loss: 0.0995, step time: 0.3192\n",
      "59/224, train_loss: 0.0996, step time: 0.3168\n",
      "60/224, train_loss: 0.0789, step time: 0.3946\n",
      "61/224, train_loss: 0.1314, step time: 0.3159\n",
      "62/224, train_loss: 0.1672, step time: 0.3895\n",
      "63/224, train_loss: 0.1463, step time: 0.3918\n",
      "64/224, train_loss: 0.1046, step time: 0.3192\n",
      "65/224, train_loss: 0.1040, step time: 0.3169\n",
      "66/224, train_loss: 0.0908, step time: 0.3188\n",
      "67/224, train_loss: 0.0728, step time: 0.3187\n",
      "68/224, train_loss: 0.0880, step time: 0.3701\n",
      "69/224, train_loss: 0.0742, step time: 0.3692\n",
      "70/224, train_loss: 0.0747, step time: 0.3165\n",
      "71/224, train_loss: 0.2302, step time: 0.3167\n",
      "72/224, train_loss: 0.0714, step time: 0.3160\n",
      "73/224, train_loss: 0.0873, step time: 0.3161\n",
      "74/224, train_loss: 0.1501, step time: 0.3739\n",
      "75/224, train_loss: 0.0925, step time: 0.3782\n",
      "76/224, train_loss: 0.0735, step time: 0.4052\n",
      "77/224, train_loss: 0.1488, step time: 0.3875\n",
      "78/224, train_loss: 0.2117, step time: 0.4106\n",
      "79/224, train_loss: 0.0509, step time: 0.3759\n",
      "80/224, train_loss: 0.1044, step time: 0.3191\n",
      "81/224, train_loss: 0.0847, step time: 0.3177\n",
      "82/224, train_loss: 0.0902, step time: 0.3202\n",
      "83/224, train_loss: 0.0701, step time: 0.3197\n",
      "84/224, train_loss: 0.1840, step time: 0.4021\n",
      "85/224, train_loss: 0.0729, step time: 0.3153\n",
      "86/224, train_loss: 0.0983, step time: 0.3727\n",
      "87/224, train_loss: 0.2666, step time: 0.3184\n",
      "88/224, train_loss: 0.0972, step time: 0.3203\n",
      "89/224, train_loss: 0.3368, step time: 0.4085\n",
      "90/224, train_loss: 0.1692, step time: 0.3161\n",
      "91/224, train_loss: 0.0894, step time: 0.3161\n",
      "92/224, train_loss: 0.2502, step time: 0.4165\n",
      "93/224, train_loss: 0.0778, step time: 0.4029\n",
      "94/224, train_loss: 0.1328, step time: 0.3145\n",
      "95/224, train_loss: 0.1244, step time: 0.3191\n",
      "96/224, train_loss: 0.0836, step time: 0.3169\n",
      "97/224, train_loss: 0.0624, step time: 0.3771\n",
      "98/224, train_loss: 0.0557, step time: 0.4023\n",
      "99/224, train_loss: 0.0553, step time: 0.3140\n",
      "100/224, train_loss: 0.1011, step time: 0.4003\n",
      "101/224, train_loss: 0.1645, step time: 0.3713\n",
      "102/224, train_loss: 0.1481, step time: 0.3753\n",
      "103/224, train_loss: 0.2078, step time: 0.3795\n",
      "104/224, train_loss: 0.1275, step time: 0.3180\n",
      "105/224, train_loss: 0.1092, step time: 0.3191\n",
      "106/224, train_loss: 0.1102, step time: 0.4066\n",
      "107/224, train_loss: 0.0987, step time: 0.3155\n",
      "108/224, train_loss: 0.0770, step time: 0.3182\n",
      "109/224, train_loss: 0.1476, step time: 0.3881\n",
      "110/224, train_loss: 0.1508, step time: 0.4024\n",
      "111/224, train_loss: 0.0888, step time: 0.4035\n",
      "112/224, train_loss: 0.1683, step time: 0.4037\n",
      "113/224, train_loss: 0.0901, step time: 0.3184\n",
      "114/224, train_loss: 0.0772, step time: 0.3155\n",
      "115/224, train_loss: 0.0747, step time: 0.3157\n",
      "116/224, train_loss: 0.0469, step time: 0.3157\n",
      "117/224, train_loss: 0.0979, step time: 0.3179\n",
      "118/224, train_loss: 0.0654, step time: 0.3156\n",
      "119/224, train_loss: 0.0682, step time: 0.3901\n",
      "120/224, train_loss: 0.1055, step time: 0.3813\n",
      "121/224, train_loss: 0.1063, step time: 0.3165\n",
      "122/224, train_loss: 0.1172, step time: 0.3722\n",
      "123/224, train_loss: 0.2655, step time: 0.3799\n",
      "124/224, train_loss: 0.0961, step time: 0.3186\n",
      "125/224, train_loss: 0.0621, step time: 0.3167\n",
      "126/224, train_loss: 0.0524, step time: 0.4068\n",
      "127/224, train_loss: 0.0885, step time: 0.3907\n",
      "128/224, train_loss: 0.0708, step time: 0.3151\n",
      "129/224, train_loss: 0.1028, step time: 0.3936\n",
      "130/224, train_loss: 0.2964, step time: 0.4075\n",
      "131/224, train_loss: 0.0832, step time: 0.3198\n",
      "132/224, train_loss: 0.1431, step time: 0.3943\n",
      "133/224, train_loss: 0.1235, step time: 0.3907\n",
      "134/224, train_loss: 0.0627, step time: 0.3187\n",
      "135/224, train_loss: 0.0636, step time: 0.3172\n",
      "136/224, train_loss: 0.1075, step time: 0.3147\n",
      "137/224, train_loss: 0.0713, step time: 0.3870\n",
      "138/224, train_loss: 0.1984, step time: 0.4011\n",
      "139/224, train_loss: 0.0759, step time: 0.4016\n",
      "140/224, train_loss: 0.1263, step time: 0.4105\n",
      "141/224, train_loss: 0.0850, step time: 0.3190\n",
      "142/224, train_loss: 0.3436, step time: 0.3968\n",
      "143/224, train_loss: 0.0799, step time: 0.3190\n",
      "144/224, train_loss: 0.1826, step time: 0.3936\n",
      "145/224, train_loss: 0.3020, step time: 0.4059\n",
      "146/224, train_loss: 0.0896, step time: 0.3970\n",
      "147/224, train_loss: 0.1656, step time: 0.3723\n",
      "148/224, train_loss: 0.0699, step time: 0.3935\n",
      "149/224, train_loss: 0.3447, step time: 0.3766\n",
      "150/224, train_loss: 0.0469, step time: 0.3160\n",
      "151/224, train_loss: 0.1067, step time: 0.3798\n",
      "152/224, train_loss: 0.1395, step time: 0.3959\n",
      "153/224, train_loss: 0.0811, step time: 0.3158\n",
      "154/224, train_loss: 0.0542, step time: 0.3797\n",
      "155/224, train_loss: 0.1861, step time: 0.3843\n",
      "156/224, train_loss: 0.1290, step time: 0.3682\n",
      "157/224, train_loss: 0.0938, step time: 0.3153\n",
      "158/224, train_loss: 0.0730, step time: 0.3149\n",
      "159/224, train_loss: 0.2840, step time: 0.4046\n",
      "160/224, train_loss: 0.0711, step time: 0.4047\n",
      "161/224, train_loss: 0.1112, step time: 0.3175\n",
      "162/224, train_loss: 0.0977, step time: 0.3144\n",
      "163/224, train_loss: 0.0769, step time: 0.3145\n",
      "164/224, train_loss: 0.2157, step time: 0.3775\n",
      "165/224, train_loss: 0.2858, step time: 0.3151\n",
      "166/224, train_loss: 0.0857, step time: 0.3148\n",
      "167/224, train_loss: 0.1525, step time: 0.3151\n",
      "168/224, train_loss: 0.3709, step time: 0.3833\n",
      "169/224, train_loss: 0.2285, step time: 0.3807\n",
      "170/224, train_loss: 0.1003, step time: 0.3856\n",
      "171/224, train_loss: 0.0484, step time: 0.3136\n",
      "172/224, train_loss: 0.3407, step time: 0.4172\n",
      "173/224, train_loss: 0.0543, step time: 0.3141\n",
      "174/224, train_loss: 0.0807, step time: 0.3162\n",
      "175/224, train_loss: 0.1637, step time: 0.4077\n",
      "176/224, train_loss: 0.2811, step time: 0.3777\n",
      "177/224, train_loss: 0.1089, step time: 0.3908\n",
      "178/224, train_loss: 0.1342, step time: 0.3831\n",
      "179/224, train_loss: 0.0606, step time: 0.3153\n",
      "180/224, train_loss: 0.1037, step time: 0.3965\n",
      "181/224, train_loss: 0.0986, step time: 0.3874\n",
      "182/224, train_loss: 0.1634, step time: 0.3889\n",
      "183/224, train_loss: 0.0896, step time: 0.3954\n",
      "184/224, train_loss: 0.1827, step time: 0.3734\n",
      "185/224, train_loss: 0.0973, step time: 0.4048\n",
      "186/224, train_loss: 0.1516, step time: 0.3996\n",
      "187/224, train_loss: 0.1025, step time: 0.3172\n",
      "188/224, train_loss: 0.0866, step time: 0.3167\n",
      "189/224, train_loss: 0.1001, step time: 0.3686\n",
      "190/224, train_loss: 0.0920, step time: 0.3171\n",
      "191/224, train_loss: 0.0797, step time: 0.3122\n",
      "192/224, train_loss: 0.1017, step time: 0.3707\n",
      "193/224, train_loss: 0.3001, step time: 0.3172\n",
      "194/224, train_loss: 0.1379, step time: 0.3997\n",
      "195/224, train_loss: 0.0843, step time: 0.3161\n",
      "196/224, train_loss: 0.0975, step time: 0.3151\n",
      "197/224, train_loss: 0.1101, step time: 0.3738\n",
      "198/224, train_loss: 0.0795, step time: 0.3748\n",
      "199/224, train_loss: 0.0645, step time: 0.3172\n",
      "200/224, train_loss: 0.0714, step time: 0.3143\n",
      "201/224, train_loss: 0.1712, step time: 0.3977\n",
      "202/224, train_loss: 0.1556, step time: 0.3149\n",
      "203/224, train_loss: 0.1357, step time: 0.3738\n",
      "204/224, train_loss: 0.1667, step time: 0.4095\n",
      "205/224, train_loss: 0.0868, step time: 0.3141\n",
      "206/224, train_loss: 0.0969, step time: 0.3953\n",
      "207/224, train_loss: 0.1329, step time: 0.3718\n",
      "208/224, train_loss: 0.1008, step time: 0.3948\n",
      "209/224, train_loss: 0.2650, step time: 0.3793\n",
      "210/224, train_loss: 0.0933, step time: 0.3172\n",
      "211/224, train_loss: 0.0820, step time: 0.3143\n",
      "212/224, train_loss: 0.0726, step time: 0.3897\n",
      "213/224, train_loss: 0.1105, step time: 0.4041\n",
      "214/224, train_loss: 0.0692, step time: 0.3156\n",
      "215/224, train_loss: 0.0910, step time: 0.3149\n",
      "216/224, train_loss: 0.0835, step time: 0.3152\n",
      "217/224, train_loss: 0.1428, step time: 0.3983\n",
      "218/224, train_loss: 0.0693, step time: 0.3743\n",
      "219/224, train_loss: 0.0855, step time: 0.3868\n",
      "220/224, train_loss: 0.0969, step time: 0.3131\n",
      "221/224, train_loss: 0.0804, step time: 0.3176\n",
      "222/224, train_loss: 0.1084, step time: 0.3978\n",
      "223/224, train_loss: 0.3355, step time: 0.3710\n",
      "224/224, train_loss: 0.1079, step time: 0.3171\n",
      "epoch 78 average loss: 0.1239\n",
      "current epoch: 78 current mean dice: 0.7188 class1: 0.9993 class2: 0.7420 class3: 0.4151\n",
      "best mean dice: 0.7188 at epoch: 78\n",
      "time consuming of epoch 78 is: 759.0203\n",
      "hello\n",
      "----------\n",
      "epoch 79/100\n",
      "1/224, train_loss: 0.1138, step time: 0.3720\n",
      "2/224, train_loss: 0.1041, step time: 0.3705\n",
      "3/224, train_loss: 0.0771, step time: 0.3153\n",
      "4/224, train_loss: 0.1385, step time: 0.4072\n",
      "5/224, train_loss: 0.2176, step time: 0.3771\n",
      "6/224, train_loss: 0.0711, step time: 0.3718\n",
      "7/224, train_loss: 0.1058, step time: 0.3750\n",
      "8/224, train_loss: 0.0994, step time: 0.3147\n",
      "9/224, train_loss: 0.0631, step time: 0.3846\n",
      "10/224, train_loss: 0.1056, step time: 0.3662\n",
      "11/224, train_loss: 0.0675, step time: 0.3153\n",
      "12/224, train_loss: 0.0612, step time: 0.3126\n",
      "13/224, train_loss: 0.0839, step time: 0.3176\n",
      "14/224, train_loss: 0.0931, step time: 0.3829\n",
      "15/224, train_loss: 0.1030, step time: 0.3148\n",
      "16/224, train_loss: 0.0665, step time: 0.3143\n",
      "17/224, train_loss: 0.2977, step time: 0.3705\n",
      "18/224, train_loss: 0.0679, step time: 0.3125\n",
      "19/224, train_loss: 0.0584, step time: 0.3688\n",
      "20/224, train_loss: 0.0813, step time: 0.3678\n",
      "21/224, train_loss: 0.1103, step time: 0.3759\n",
      "22/224, train_loss: 0.1215, step time: 0.3879\n",
      "23/224, train_loss: 0.1002, step time: 0.4005\n",
      "24/224, train_loss: 0.2233, step time: 0.3874\n",
      "25/224, train_loss: 0.1293, step time: 0.3748\n",
      "26/224, train_loss: 0.0948, step time: 0.3144\n",
      "27/224, train_loss: 0.1765, step time: 0.3790\n",
      "28/224, train_loss: 0.1033, step time: 0.3825\n",
      "29/224, train_loss: 0.0633, step time: 0.3143\n",
      "30/224, train_loss: 0.1669, step time: 0.4019\n",
      "31/224, train_loss: 0.0735, step time: 0.3989\n",
      "32/224, train_loss: 0.3350, step time: 0.3951\n",
      "33/224, train_loss: 0.1550, step time: 0.3820\n",
      "34/224, train_loss: 0.1110, step time: 0.3146\n",
      "35/224, train_loss: 0.1665, step time: 0.3124\n",
      "36/224, train_loss: 0.0530, step time: 0.3167\n",
      "37/224, train_loss: 0.0737, step time: 0.3948\n",
      "38/224, train_loss: 0.1424, step time: 0.3815\n",
      "39/224, train_loss: 0.1492, step time: 0.3937\n",
      "40/224, train_loss: 0.0819, step time: 0.3764\n",
      "41/224, train_loss: 0.0529, step time: 0.3170\n",
      "42/224, train_loss: 0.0903, step time: 0.3931\n",
      "43/224, train_loss: 0.0664, step time: 0.3140\n",
      "44/224, train_loss: 0.1323, step time: 0.3812\n",
      "45/224, train_loss: 0.2318, step time: 0.3877\n",
      "46/224, train_loss: 0.2152, step time: 0.3886\n",
      "47/224, train_loss: 0.1667, step time: 0.4053\n",
      "48/224, train_loss: 0.0921, step time: 0.3126\n",
      "49/224, train_loss: 0.1670, step time: 0.3791\n",
      "50/224, train_loss: 0.0607, step time: 0.3169\n",
      "51/224, train_loss: 0.2690, step time: 0.3649\n",
      "52/224, train_loss: 0.2179, step time: 0.3140\n",
      "53/224, train_loss: 0.0874, step time: 0.3144\n",
      "54/224, train_loss: 0.1155, step time: 0.3140\n",
      "55/224, train_loss: 0.1076, step time: 0.3140\n",
      "56/224, train_loss: 0.1679, step time: 0.3844\n",
      "57/224, train_loss: 0.0831, step time: 0.3174\n",
      "58/224, train_loss: 0.1019, step time: 0.3153\n",
      "59/224, train_loss: 0.0787, step time: 0.3174\n",
      "60/224, train_loss: 0.1273, step time: 0.3168\n",
      "61/224, train_loss: 0.2794, step time: 0.3870\n",
      "62/224, train_loss: 0.1579, step time: 0.3862\n",
      "63/224, train_loss: 0.1059, step time: 0.3142\n",
      "64/224, train_loss: 0.0978, step time: 0.4008\n",
      "65/224, train_loss: 0.1372, step time: 0.3871\n",
      "66/224, train_loss: 0.1133, step time: 0.3887\n",
      "67/224, train_loss: 0.0841, step time: 0.3171\n",
      "68/224, train_loss: 0.0876, step time: 0.3143\n",
      "69/224, train_loss: 0.0486, step time: 0.3165\n",
      "70/224, train_loss: 0.3208, step time: 0.3714\n",
      "71/224, train_loss: 0.1807, step time: 0.4093\n",
      "72/224, train_loss: 0.2684, step time: 0.4070\n",
      "73/224, train_loss: 0.0628, step time: 0.3144\n",
      "74/224, train_loss: 0.0949, step time: 0.3144\n",
      "75/224, train_loss: 0.0876, step time: 0.4080\n",
      "76/224, train_loss: 0.1209, step time: 0.3148\n",
      "77/224, train_loss: 0.3796, step time: 0.3826\n",
      "78/224, train_loss: 0.1319, step time: 0.3146\n",
      "79/224, train_loss: 0.0628, step time: 0.3145\n",
      "80/224, train_loss: 0.1500, step time: 0.3864\n",
      "81/224, train_loss: 0.0790, step time: 0.3143\n",
      "82/224, train_loss: 0.0929, step time: 0.3168\n",
      "83/224, train_loss: 0.1390, step time: 0.3167\n",
      "84/224, train_loss: 0.0762, step time: 0.3122\n",
      "85/224, train_loss: 0.1997, step time: 0.3939\n",
      "86/224, train_loss: 0.0791, step time: 0.3178\n",
      "87/224, train_loss: 0.1551, step time: 0.3731\n",
      "88/224, train_loss: 0.1288, step time: 0.3928\n",
      "89/224, train_loss: 0.1553, step time: 0.3843\n",
      "90/224, train_loss: 0.1388, step time: 0.3148\n",
      "91/224, train_loss: 0.1071, step time: 0.4100\n",
      "92/224, train_loss: 0.2001, step time: 0.3880\n",
      "93/224, train_loss: 0.0663, step time: 0.3144\n",
      "94/224, train_loss: 0.1112, step time: 0.3171\n",
      "95/224, train_loss: 0.1838, step time: 0.3713\n",
      "96/224, train_loss: 0.0916, step time: 0.4021\n",
      "97/224, train_loss: 0.0846, step time: 0.3812\n",
      "98/224, train_loss: 0.2378, step time: 0.3133\n",
      "99/224, train_loss: 0.2298, step time: 0.3810\n",
      "100/224, train_loss: 0.0741, step time: 0.3149\n",
      "101/224, train_loss: 0.1973, step time: 0.3972\n",
      "102/224, train_loss: 0.1016, step time: 0.3171\n",
      "103/224, train_loss: 0.3592, step time: 0.3826\n",
      "104/224, train_loss: 0.2092, step time: 0.3173\n",
      "105/224, train_loss: 0.0919, step time: 0.3175\n",
      "106/224, train_loss: 0.0778, step time: 0.3171\n",
      "107/224, train_loss: 0.1809, step time: 0.3173\n",
      "108/224, train_loss: 0.0866, step time: 0.3146\n",
      "109/224, train_loss: 0.0982, step time: 0.3150\n",
      "110/224, train_loss: 0.0553, step time: 0.3146\n",
      "111/224, train_loss: 0.1497, step time: 0.4098\n",
      "112/224, train_loss: 0.0802, step time: 0.3149\n",
      "113/224, train_loss: 0.1378, step time: 0.4023\n",
      "114/224, train_loss: 0.0972, step time: 0.3842\n",
      "115/224, train_loss: 0.1403, step time: 0.3683\n",
      "116/224, train_loss: 0.1967, step time: 0.3831\n",
      "117/224, train_loss: 0.2482, step time: 0.3924\n",
      "118/224, train_loss: 0.2406, step time: 0.3158\n",
      "119/224, train_loss: 0.2081, step time: 0.3134\n",
      "120/224, train_loss: 0.1115, step time: 0.3143\n",
      "121/224, train_loss: 0.2732, step time: 0.3171\n",
      "122/224, train_loss: 0.1151, step time: 0.3148\n",
      "123/224, train_loss: 0.0975, step time: 0.3144\n",
      "124/224, train_loss: 0.2338, step time: 0.3669\n",
      "125/224, train_loss: 0.1223, step time: 0.3146\n",
      "126/224, train_loss: 0.0911, step time: 0.4008\n",
      "127/224, train_loss: 0.1271, step time: 0.3765\n",
      "128/224, train_loss: 0.0745, step time: 0.3119\n",
      "129/224, train_loss: 0.0741, step time: 0.3146\n",
      "130/224, train_loss: 0.1243, step time: 0.3165\n",
      "131/224, train_loss: 0.1078, step time: 0.4044\n",
      "132/224, train_loss: 0.0665, step time: 0.3653\n",
      "133/224, train_loss: 0.1651, step time: 0.3173\n",
      "134/224, train_loss: 0.1673, step time: 0.3878\n",
      "135/224, train_loss: 0.2004, step time: 0.3743\n",
      "136/224, train_loss: 0.0859, step time: 0.3168\n",
      "137/224, train_loss: 0.0673, step time: 0.3143\n",
      "138/224, train_loss: 0.3478, step time: 0.4029\n",
      "139/224, train_loss: 0.0719, step time: 0.3691\n",
      "140/224, train_loss: 0.1063, step time: 0.3153\n",
      "141/224, train_loss: 0.1535, step time: 0.4070\n",
      "142/224, train_loss: 0.1470, step time: 0.3150\n",
      "143/224, train_loss: 0.0809, step time: 0.3953\n",
      "144/224, train_loss: 0.1772, step time: 0.3779\n",
      "145/224, train_loss: 0.1365, step time: 0.3841\n",
      "146/224, train_loss: 0.1172, step time: 0.3149\n",
      "147/224, train_loss: 0.3179, step time: 0.4014\n",
      "148/224, train_loss: 0.1039, step time: 0.3173\n",
      "149/224, train_loss: 0.0994, step time: 0.3727\n",
      "150/224, train_loss: 0.1099, step time: 0.3148\n",
      "151/224, train_loss: 0.1862, step time: 0.3811\n",
      "152/224, train_loss: 0.1534, step time: 0.3132\n",
      "153/224, train_loss: 0.2122, step time: 0.4011\n",
      "154/224, train_loss: 0.1085, step time: 0.3810\n",
      "155/224, train_loss: 0.2716, step time: 0.3783\n",
      "156/224, train_loss: 0.1187, step time: 0.3692\n",
      "157/224, train_loss: 0.0815, step time: 0.3982\n",
      "158/224, train_loss: 0.1155, step time: 0.4078\n",
      "159/224, train_loss: 0.0598, step time: 0.3675\n",
      "160/224, train_loss: 0.3295, step time: 0.3672\n",
      "161/224, train_loss: 0.0551, step time: 0.3140\n",
      "162/224, train_loss: 0.1084, step time: 0.3980\n",
      "163/224, train_loss: 0.1545, step time: 0.3854\n",
      "164/224, train_loss: 0.1525, step time: 0.3152\n",
      "165/224, train_loss: 0.0939, step time: 0.3151\n",
      "166/224, train_loss: 0.1857, step time: 0.3124\n",
      "167/224, train_loss: 0.1120, step time: 0.3140\n",
      "168/224, train_loss: 0.1604, step time: 0.3164\n",
      "169/224, train_loss: 0.0831, step time: 0.3167\n",
      "170/224, train_loss: 0.0811, step time: 0.4037\n",
      "171/224, train_loss: 0.0768, step time: 0.3860\n",
      "172/224, train_loss: 0.1512, step time: 0.3180\n",
      "173/224, train_loss: 0.0795, step time: 0.3152\n",
      "174/224, train_loss: 0.0415, step time: 0.3119\n",
      "175/224, train_loss: 0.1429, step time: 0.3140\n",
      "176/224, train_loss: 0.1570, step time: 0.3140\n",
      "177/224, train_loss: 0.0976, step time: 0.3148\n",
      "178/224, train_loss: 0.1526, step time: 0.3859\n",
      "179/224, train_loss: 0.3851, step time: 0.3706\n",
      "180/224, train_loss: 0.0666, step time: 0.3929\n",
      "181/224, train_loss: 0.1390, step time: 0.3142\n",
      "182/224, train_loss: 0.1094, step time: 0.3141\n",
      "183/224, train_loss: 0.3769, step time: 0.3788\n",
      "184/224, train_loss: 0.1480, step time: 0.4019\n",
      "185/224, train_loss: 0.1119, step time: 0.4033\n",
      "186/224, train_loss: 0.1439, step time: 0.3146\n",
      "187/224, train_loss: 0.2348, step time: 0.3671\n",
      "188/224, train_loss: 0.0918, step time: 0.3140\n",
      "189/224, train_loss: 0.1251, step time: 0.4042\n",
      "190/224, train_loss: 0.0902, step time: 0.4071\n",
      "191/224, train_loss: 0.0732, step time: 0.3807\n",
      "192/224, train_loss: 0.0881, step time: 0.3150\n",
      "193/224, train_loss: 0.1093, step time: 0.3145\n",
      "194/224, train_loss: 0.1152, step time: 0.3154\n",
      "195/224, train_loss: 0.0600, step time: 0.3683\n",
      "196/224, train_loss: 0.2717, step time: 0.3143\n",
      "197/224, train_loss: 0.1645, step time: 0.3953\n",
      "198/224, train_loss: 0.1366, step time: 0.3174\n",
      "199/224, train_loss: 0.0927, step time: 0.3151\n",
      "200/224, train_loss: 0.0734, step time: 0.3147\n",
      "201/224, train_loss: 0.2616, step time: 0.3977\n",
      "202/224, train_loss: 0.0568, step time: 0.3767\n",
      "203/224, train_loss: 0.0877, step time: 0.3172\n",
      "204/224, train_loss: 0.1050, step time: 0.3146\n",
      "205/224, train_loss: 0.0699, step time: 0.3800\n",
      "206/224, train_loss: 0.1577, step time: 0.3164\n",
      "207/224, train_loss: 0.1482, step time: 0.3142\n",
      "208/224, train_loss: 0.1844, step time: 0.3946\n",
      "209/224, train_loss: 0.1069, step time: 0.3165\n",
      "210/224, train_loss: 0.2658, step time: 0.4092\n",
      "211/224, train_loss: 0.0697, step time: 0.3167\n",
      "212/224, train_loss: 0.0933, step time: 0.3164\n",
      "213/224, train_loss: 0.1551, step time: 0.3717\n",
      "214/224, train_loss: 0.1241, step time: 0.3151\n",
      "215/224, train_loss: 0.2650, step time: 0.3847\n",
      "216/224, train_loss: 0.2084, step time: 0.3861\n",
      "217/224, train_loss: 0.0913, step time: 0.3145\n",
      "218/224, train_loss: 0.3710, step time: 0.4054\n",
      "219/224, train_loss: 0.1018, step time: 0.3154\n",
      "220/224, train_loss: 0.0823, step time: 0.3147\n",
      "221/224, train_loss: 0.1520, step time: 0.3166\n",
      "222/224, train_loss: 0.1185, step time: 0.3839\n",
      "223/224, train_loss: 0.2845, step time: 0.4003\n",
      "224/224, train_loss: 0.3211, step time: 0.3762\n",
      "epoch 79 average loss: 0.1383\n",
      "current epoch: 79 current mean dice: 0.7184 class1: 0.9993 class2: 0.7389 class3: 0.4170\n",
      "best mean dice: 0.7188 at epoch: 78\n",
      "time consuming of epoch 79 is: 777.9838\n",
      "hello\n",
      "----------\n",
      "epoch 80/100\n",
      "1/224, train_loss: 0.1276, step time: 0.3151\n",
      "2/224, train_loss: 0.0983, step time: 0.3171\n",
      "3/224, train_loss: 0.1482, step time: 0.4054\n",
      "4/224, train_loss: 0.1250, step time: 0.3124\n",
      "5/224, train_loss: 0.0722, step time: 0.3149\n",
      "6/224, train_loss: 0.1471, step time: 0.3724\n",
      "7/224, train_loss: 0.1220, step time: 0.3714\n",
      "8/224, train_loss: 0.0776, step time: 0.3151\n",
      "9/224, train_loss: 0.0784, step time: 0.3143\n",
      "10/224, train_loss: 0.3073, step time: 0.3843\n",
      "11/224, train_loss: 0.1518, step time: 0.3144\n",
      "12/224, train_loss: 0.1725, step time: 0.3999\n",
      "13/224, train_loss: 0.1623, step time: 0.4029\n",
      "14/224, train_loss: 0.0558, step time: 0.3142\n",
      "15/224, train_loss: 0.1056, step time: 0.3146\n",
      "16/224, train_loss: 0.1472, step time: 0.3716\n",
      "17/224, train_loss: 0.0935, step time: 0.4119\n",
      "18/224, train_loss: 0.1137, step time: 0.3142\n",
      "19/224, train_loss: 0.0713, step time: 0.3141\n",
      "20/224, train_loss: 0.0951, step time: 0.3907\n",
      "21/224, train_loss: 0.1277, step time: 0.4086\n",
      "22/224, train_loss: 0.1380, step time: 0.3818\n",
      "23/224, train_loss: 0.0763, step time: 0.3150\n",
      "24/224, train_loss: 0.1329, step time: 0.4049\n",
      "25/224, train_loss: 0.3491, step time: 0.3145\n",
      "26/224, train_loss: 0.1750, step time: 0.3935\n",
      "27/224, train_loss: 0.2377, step time: 0.3678\n",
      "28/224, train_loss: 0.0905, step time: 0.4126\n",
      "29/224, train_loss: 0.2018, step time: 0.3672\n",
      "30/224, train_loss: 0.2326, step time: 0.3982\n",
      "31/224, train_loss: 0.2027, step time: 0.3119\n",
      "32/224, train_loss: 0.0634, step time: 0.3161\n",
      "33/224, train_loss: 0.2908, step time: 0.3147\n",
      "34/224, train_loss: 0.1686, step time: 0.3766\n",
      "35/224, train_loss: 0.2803, step time: 0.4026\n",
      "36/224, train_loss: 0.0796, step time: 0.3141\n",
      "37/224, train_loss: 0.3209, step time: 0.3751\n",
      "38/224, train_loss: 0.1032, step time: 0.3170\n",
      "39/224, train_loss: 0.2300, step time: 0.3147\n",
      "40/224, train_loss: 0.1045, step time: 0.3171\n",
      "41/224, train_loss: 0.0983, step time: 0.3959\n",
      "42/224, train_loss: 0.0588, step time: 0.3144\n",
      "43/224, train_loss: 0.0794, step time: 0.4017\n",
      "44/224, train_loss: 0.0747, step time: 0.3147\n",
      "45/224, train_loss: 0.0980, step time: 0.3163\n",
      "46/224, train_loss: 0.0790, step time: 0.3863\n",
      "47/224, train_loss: 0.0676, step time: 0.3123\n",
      "48/224, train_loss: 0.0791, step time: 0.3171\n",
      "49/224, train_loss: 0.2678, step time: 0.3796\n",
      "50/224, train_loss: 0.1366, step time: 0.3163\n",
      "51/224, train_loss: 0.0820, step time: 0.3128\n",
      "52/224, train_loss: 0.2897, step time: 0.3149\n",
      "53/224, train_loss: 0.0494, step time: 0.3905\n",
      "54/224, train_loss: 0.1470, step time: 0.3796\n",
      "55/224, train_loss: 0.0765, step time: 0.3706\n",
      "56/224, train_loss: 0.1195, step time: 0.3741\n",
      "57/224, train_loss: 0.0849, step time: 0.3161\n",
      "58/224, train_loss: 0.0969, step time: 0.3164\n",
      "59/224, train_loss: 0.1434, step time: 0.3856\n",
      "60/224, train_loss: 0.2641, step time: 0.4029\n",
      "61/224, train_loss: 0.0569, step time: 0.3724\n",
      "62/224, train_loss: 0.1146, step time: 0.3883\n",
      "63/224, train_loss: 0.0830, step time: 0.3852\n",
      "64/224, train_loss: 0.0865, step time: 0.3865\n",
      "65/224, train_loss: 0.1024, step time: 0.3765\n",
      "66/224, train_loss: 0.0767, step time: 0.3175\n",
      "67/224, train_loss: 0.0825, step time: 0.3124\n",
      "68/224, train_loss: 0.1270, step time: 0.3692\n",
      "69/224, train_loss: 0.0942, step time: 0.3723\n",
      "70/224, train_loss: 0.0634, step time: 0.3162\n",
      "71/224, train_loss: 0.0611, step time: 0.3934\n",
      "72/224, train_loss: 0.1017, step time: 0.3154\n",
      "73/224, train_loss: 0.1628, step time: 0.3145\n",
      "74/224, train_loss: 0.0880, step time: 0.3167\n",
      "75/224, train_loss: 0.1019, step time: 0.3140\n",
      "76/224, train_loss: 0.1353, step time: 0.3735\n",
      "77/224, train_loss: 0.1289, step time: 0.3147\n",
      "78/224, train_loss: 0.1411, step time: 0.3143\n",
      "79/224, train_loss: 0.1075, step time: 0.3968\n",
      "80/224, train_loss: 0.0908, step time: 0.3131\n",
      "81/224, train_loss: 0.1370, step time: 0.4063\n",
      "82/224, train_loss: 0.0634, step time: 0.3172\n",
      "83/224, train_loss: 0.0968, step time: 0.3152\n",
      "84/224, train_loss: 0.1187, step time: 0.3149\n",
      "85/224, train_loss: 0.1284, step time: 0.3802\n",
      "86/224, train_loss: 0.0894, step time: 0.3939\n",
      "87/224, train_loss: 0.0821, step time: 0.4066\n",
      "88/224, train_loss: 0.0595, step time: 0.3838\n",
      "89/224, train_loss: 0.0672, step time: 0.3124\n",
      "90/224, train_loss: 0.0619, step time: 0.3173\n",
      "91/224, train_loss: 0.1951, step time: 0.3682\n",
      "92/224, train_loss: 0.0994, step time: 0.3152\n",
      "93/224, train_loss: 0.1138, step time: 0.3147\n",
      "94/224, train_loss: 0.0783, step time: 0.3121\n",
      "95/224, train_loss: 0.2078, step time: 0.3825\n",
      "96/224, train_loss: 0.0557, step time: 0.3124\n",
      "97/224, train_loss: 0.0941, step time: 0.3125\n",
      "98/224, train_loss: 0.1174, step time: 0.3882\n",
      "99/224, train_loss: 0.2074, step time: 0.3148\n",
      "100/224, train_loss: 0.1030, step time: 0.3760\n",
      "101/224, train_loss: 0.1043, step time: 0.3157\n",
      "102/224, train_loss: 0.1303, step time: 0.3142\n",
      "103/224, train_loss: 0.0956, step time: 0.3167\n",
      "104/224, train_loss: 0.0771, step time: 0.3144\n",
      "105/224, train_loss: 0.0676, step time: 0.3141\n",
      "106/224, train_loss: 0.0885, step time: 0.3124\n",
      "107/224, train_loss: 0.0736, step time: 0.3702\n",
      "108/224, train_loss: 0.1347, step time: 0.3747\n",
      "109/224, train_loss: 0.3825, step time: 0.4048\n",
      "110/224, train_loss: 0.1336, step time: 0.3944\n",
      "111/224, train_loss: 0.1196, step time: 0.3799\n",
      "112/224, train_loss: 0.0741, step time: 0.3168\n",
      "113/224, train_loss: 0.0959, step time: 0.3151\n",
      "114/224, train_loss: 0.0757, step time: 0.3883\n",
      "115/224, train_loss: 0.1034, step time: 0.4069\n",
      "116/224, train_loss: 0.1124, step time: 0.3146\n",
      "117/224, train_loss: 0.0865, step time: 0.3139\n",
      "118/224, train_loss: 0.0481, step time: 0.3144\n",
      "119/224, train_loss: 0.0601, step time: 0.3759\n",
      "120/224, train_loss: 0.1194, step time: 0.4068\n",
      "121/224, train_loss: 0.2834, step time: 0.4114\n",
      "122/224, train_loss: 0.2938, step time: 0.3989\n",
      "123/224, train_loss: 0.1703, step time: 0.3683\n",
      "124/224, train_loss: 0.1301, step time: 0.3153\n",
      "125/224, train_loss: 0.1415, step time: 0.4091\n",
      "126/224, train_loss: 0.0992, step time: 0.3157\n",
      "127/224, train_loss: 0.1155, step time: 0.4000\n",
      "128/224, train_loss: 0.0673, step time: 0.3958\n",
      "129/224, train_loss: 0.1150, step time: 0.3172\n",
      "130/224, train_loss: 0.0614, step time: 0.3172\n",
      "131/224, train_loss: 0.0970, step time: 0.3144\n",
      "132/224, train_loss: 0.1858, step time: 0.3151\n",
      "133/224, train_loss: 0.2157, step time: 0.3712\n",
      "134/224, train_loss: 0.1595, step time: 0.3965\n",
      "135/224, train_loss: 0.1766, step time: 0.3151\n",
      "136/224, train_loss: 0.0695, step time: 0.3837\n",
      "137/224, train_loss: 0.2415, step time: 0.4129\n",
      "138/224, train_loss: 0.1683, step time: 0.3995\n",
      "139/224, train_loss: 0.0787, step time: 0.3144\n",
      "140/224, train_loss: 0.0940, step time: 0.3143\n",
      "141/224, train_loss: 0.1895, step time: 0.3757\n",
      "142/224, train_loss: 0.0460, step time: 0.3847\n",
      "143/224, train_loss: 0.1097, step time: 0.4053\n",
      "144/224, train_loss: 0.0574, step time: 0.3126\n",
      "145/224, train_loss: 0.1049, step time: 0.4086\n",
      "146/224, train_loss: 0.0969, step time: 0.3123\n",
      "147/224, train_loss: 0.1348, step time: 0.4112\n",
      "148/224, train_loss: 0.1351, step time: 0.3154\n",
      "149/224, train_loss: 0.1610, step time: 0.3713\n",
      "150/224, train_loss: 0.0647, step time: 0.3167\n",
      "151/224, train_loss: 0.0827, step time: 0.3934\n",
      "152/224, train_loss: 0.1032, step time: 0.3954\n",
      "153/224, train_loss: 0.2026, step time: 0.3839\n",
      "154/224, train_loss: 0.1008, step time: 0.4046\n",
      "155/224, train_loss: 0.1063, step time: 0.3828\n",
      "156/224, train_loss: 0.0753, step time: 0.3150\n",
      "157/224, train_loss: 0.0751, step time: 0.3144\n",
      "158/224, train_loss: 0.0814, step time: 0.3143\n",
      "159/224, train_loss: 0.1510, step time: 0.3989\n",
      "160/224, train_loss: 0.1131, step time: 0.3799\n",
      "161/224, train_loss: 0.1068, step time: 0.3128\n",
      "162/224, train_loss: 0.2174, step time: 0.3912\n",
      "163/224, train_loss: 0.1146, step time: 0.3974\n",
      "164/224, train_loss: 0.1010, step time: 0.3171\n",
      "165/224, train_loss: 0.1313, step time: 0.3188\n",
      "166/224, train_loss: 0.0794, step time: 0.3176\n",
      "167/224, train_loss: 0.2643, step time: 0.3929\n",
      "168/224, train_loss: 0.0615, step time: 0.3146\n",
      "169/224, train_loss: 0.1520, step time: 0.4005\n",
      "170/224, train_loss: 0.0898, step time: 0.3145\n",
      "171/224, train_loss: 0.0787, step time: 0.3850\n",
      "172/224, train_loss: 0.1004, step time: 0.3152\n",
      "173/224, train_loss: 0.0737, step time: 0.3143\n",
      "174/224, train_loss: 0.2325, step time: 0.3131\n",
      "175/224, train_loss: 0.1299, step time: 0.3131\n",
      "176/224, train_loss: 0.0818, step time: 0.3896\n",
      "177/224, train_loss: 0.1195, step time: 0.3952\n",
      "178/224, train_loss: 0.0752, step time: 0.3158\n",
      "179/224, train_loss: 0.2156, step time: 0.3958\n",
      "180/224, train_loss: 0.1168, step time: 0.3983\n",
      "181/224, train_loss: 0.1123, step time: 0.3173\n",
      "182/224, train_loss: 0.2798, step time: 0.4099\n",
      "183/224, train_loss: 0.1026, step time: 0.3156\n",
      "184/224, train_loss: 0.1018, step time: 0.3146\n",
      "185/224, train_loss: 0.0703, step time: 0.3146\n",
      "186/224, train_loss: 0.2762, step time: 0.3909\n",
      "187/224, train_loss: 0.0749, step time: 0.3846\n",
      "188/224, train_loss: 0.0922, step time: 0.4103\n",
      "189/224, train_loss: 0.1321, step time: 0.3147\n",
      "190/224, train_loss: 0.1793, step time: 0.3704\n",
      "191/224, train_loss: 0.1444, step time: 0.3128\n",
      "192/224, train_loss: 0.0989, step time: 0.3169\n",
      "193/224, train_loss: 0.1095, step time: 0.4089\n",
      "194/224, train_loss: 0.0662, step time: 0.3173\n",
      "195/224, train_loss: 0.1035, step time: 0.3166\n",
      "196/224, train_loss: 0.2678, step time: 0.4016\n",
      "197/224, train_loss: 0.0539, step time: 0.3129\n",
      "198/224, train_loss: 0.0830, step time: 0.3134\n",
      "199/224, train_loss: 0.4558, step time: 0.4061\n",
      "200/224, train_loss: 0.1971, step time: 0.4034\n",
      "201/224, train_loss: 0.1959, step time: 0.3690\n",
      "202/224, train_loss: 0.0616, step time: 0.3697\n",
      "203/224, train_loss: 0.1720, step time: 0.3754\n",
      "204/224, train_loss: 0.0873, step time: 0.4060\n",
      "205/224, train_loss: 0.1122, step time: 0.3150\n",
      "206/224, train_loss: 0.0762, step time: 0.3145\n",
      "207/224, train_loss: 0.1023, step time: 0.3977\n",
      "208/224, train_loss: 0.0939, step time: 0.3716\n",
      "209/224, train_loss: 0.1048, step time: 0.3838\n",
      "210/224, train_loss: 0.2551, step time: 0.3831\n",
      "211/224, train_loss: 0.0863, step time: 0.4015\n",
      "212/224, train_loss: 0.2284, step time: 0.3906\n",
      "213/224, train_loss: 0.1205, step time: 0.3778\n",
      "214/224, train_loss: 0.0743, step time: 0.3147\n",
      "215/224, train_loss: 0.1297, step time: 0.3757\n",
      "216/224, train_loss: 0.1102, step time: 0.3124\n",
      "217/224, train_loss: 0.0793, step time: 0.3164\n",
      "218/224, train_loss: 0.1120, step time: 0.3745\n",
      "219/224, train_loss: 0.1028, step time: 0.3756\n",
      "220/224, train_loss: 0.0873, step time: 0.3151\n",
      "221/224, train_loss: 0.0656, step time: 0.3147\n",
      "222/224, train_loss: 0.1116, step time: 0.3647\n",
      "223/224, train_loss: 0.0614, step time: 0.3177\n",
      "224/224, train_loss: 0.0588, step time: 0.3822\n",
      "epoch 80 average loss: 0.1260\n",
      "current epoch: 80 current mean dice: 0.6787 class1: 0.9993 class2: 0.7413 class3: 0.2955\n",
      "best mean dice: 0.7188 at epoch: 78\n",
      "time consuming of epoch 80 is: 760.0925\n",
      "hello\n",
      "----------\n",
      "epoch 81/100\n",
      "1/224, train_loss: 0.1457, step time: 0.3986\n",
      "2/224, train_loss: 0.0744, step time: 0.3178\n",
      "3/224, train_loss: 0.0667, step time: 0.3132\n",
      "4/224, train_loss: 0.0817, step time: 0.3149\n",
      "5/224, train_loss: 0.0736, step time: 0.3711\n",
      "6/224, train_loss: 0.1283, step time: 0.4114\n",
      "7/224, train_loss: 0.0709, step time: 0.3179\n",
      "8/224, train_loss: 0.1102, step time: 0.3153\n",
      "9/224, train_loss: 0.1853, step time: 0.3897\n",
      "10/224, train_loss: 0.1622, step time: 0.3153\n",
      "11/224, train_loss: 0.1564, step time: 0.3154\n",
      "12/224, train_loss: 0.1794, step time: 0.3988\n",
      "13/224, train_loss: 0.0671, step time: 0.3142\n",
      "14/224, train_loss: 0.0826, step time: 0.3146\n",
      "15/224, train_loss: 0.1122, step time: 0.3123\n",
      "16/224, train_loss: 0.1718, step time: 0.3718\n",
      "17/224, train_loss: 0.2085, step time: 0.3929\n",
      "18/224, train_loss: 0.0651, step time: 0.3152\n",
      "19/224, train_loss: 0.1137, step time: 0.3155\n",
      "20/224, train_loss: 0.1033, step time: 0.3150\n",
      "21/224, train_loss: 0.1472, step time: 0.3759\n",
      "22/224, train_loss: 0.0973, step time: 0.3123\n",
      "23/224, train_loss: 0.0731, step time: 0.3141\n",
      "24/224, train_loss: 0.1278, step time: 0.3697\n",
      "25/224, train_loss: 0.0943, step time: 0.3704\n",
      "26/224, train_loss: 0.1440, step time: 0.4017\n",
      "27/224, train_loss: 0.0777, step time: 0.3760\n",
      "28/224, train_loss: 0.2747, step time: 0.3767\n",
      "29/224, train_loss: 0.0829, step time: 0.3176\n",
      "30/224, train_loss: 0.0716, step time: 0.4004\n",
      "31/224, train_loss: 0.1603, step time: 0.4014\n",
      "32/224, train_loss: 0.0947, step time: 0.3141\n",
      "33/224, train_loss: 0.1293, step time: 0.3121\n",
      "34/224, train_loss: 0.2189, step time: 0.3117\n",
      "35/224, train_loss: 0.1443, step time: 0.3165\n",
      "36/224, train_loss: 0.1624, step time: 0.3712\n",
      "37/224, train_loss: 0.2312, step time: 0.3863\n",
      "38/224, train_loss: 0.0881, step time: 0.3153\n",
      "39/224, train_loss: 0.0663, step time: 0.3146\n",
      "40/224, train_loss: 0.1714, step time: 0.3819\n",
      "41/224, train_loss: 0.0527, step time: 0.3683\n",
      "42/224, train_loss: 0.0771, step time: 0.3783\n",
      "43/224, train_loss: 0.1027, step time: 0.3761\n",
      "44/224, train_loss: 0.2607, step time: 0.3158\n",
      "45/224, train_loss: 0.1368, step time: 0.3170\n",
      "46/224, train_loss: 0.0920, step time: 0.3953\n",
      "47/224, train_loss: 0.0668, step time: 0.3141\n",
      "48/224, train_loss: 0.0625, step time: 0.3139\n",
      "49/224, train_loss: 0.1209, step time: 0.3778\n",
      "50/224, train_loss: 0.1564, step time: 0.4091\n",
      "51/224, train_loss: 0.0724, step time: 0.3915\n",
      "52/224, train_loss: 0.0922, step time: 0.3128\n",
      "53/224, train_loss: 0.0717, step time: 0.3164\n",
      "54/224, train_loss: 0.2391, step time: 0.3981\n",
      "55/224, train_loss: 0.1194, step time: 0.3873\n",
      "56/224, train_loss: 0.1447, step time: 0.3999\n",
      "57/224, train_loss: 0.0744, step time: 0.3686\n",
      "58/224, train_loss: 0.0870, step time: 0.3742\n",
      "59/224, train_loss: 0.0693, step time: 0.3126\n",
      "60/224, train_loss: 0.1034, step time: 0.3745\n",
      "61/224, train_loss: 0.0885, step time: 0.3149\n",
      "62/224, train_loss: 0.0848, step time: 0.3776\n",
      "63/224, train_loss: 0.1188, step time: 0.3698\n",
      "64/224, train_loss: 0.1159, step time: 0.3876\n",
      "65/224, train_loss: 0.0811, step time: 0.3127\n",
      "66/224, train_loss: 0.1311, step time: 0.3150\n",
      "67/224, train_loss: 0.0903, step time: 0.3125\n",
      "68/224, train_loss: 0.1363, step time: 0.3936\n",
      "69/224, train_loss: 0.1626, step time: 0.3146\n",
      "70/224, train_loss: 0.0585, step time: 0.3972\n",
      "71/224, train_loss: 0.1062, step time: 0.3149\n",
      "72/224, train_loss: 0.0620, step time: 0.3166\n",
      "73/224, train_loss: 0.0977, step time: 0.3634\n",
      "74/224, train_loss: 0.0842, step time: 0.3156\n",
      "75/224, train_loss: 0.1386, step time: 0.4059\n",
      "76/224, train_loss: 0.2328, step time: 0.3730\n",
      "77/224, train_loss: 0.0886, step time: 0.3148\n",
      "78/224, train_loss: 0.1294, step time: 0.3935\n",
      "79/224, train_loss: 0.1984, step time: 0.3155\n",
      "80/224, train_loss: 0.3091, step time: 0.3156\n",
      "81/224, train_loss: 0.0805, step time: 0.3133\n",
      "82/224, train_loss: 0.2728, step time: 0.3890\n",
      "83/224, train_loss: 0.1796, step time: 0.3146\n",
      "84/224, train_loss: 0.1401, step time: 0.4006\n",
      "85/224, train_loss: 0.3077, step time: 0.3143\n",
      "86/224, train_loss: 0.1077, step time: 0.3920\n",
      "87/224, train_loss: 0.0977, step time: 0.4029\n",
      "88/224, train_loss: 0.1300, step time: 0.3946\n",
      "89/224, train_loss: 0.0772, step time: 0.3763\n",
      "90/224, train_loss: 0.0551, step time: 0.3177\n",
      "91/224, train_loss: 0.1990, step time: 0.3692\n",
      "92/224, train_loss: 0.0651, step time: 0.3157\n",
      "93/224, train_loss: 0.1494, step time: 0.3921\n",
      "94/224, train_loss: 0.0799, step time: 0.3153\n",
      "95/224, train_loss: 0.0820, step time: 0.3807\n",
      "96/224, train_loss: 0.1426, step time: 0.3178\n",
      "97/224, train_loss: 0.2162, step time: 0.3991\n",
      "98/224, train_loss: 0.0738, step time: 0.3162\n",
      "99/224, train_loss: 0.1555, step time: 0.4131\n",
      "100/224, train_loss: 0.2345, step time: 0.3789\n",
      "101/224, train_loss: 0.1587, step time: 0.3184\n",
      "102/224, train_loss: 0.0879, step time: 0.3842\n",
      "103/224, train_loss: 0.1544, step time: 0.4087\n",
      "104/224, train_loss: 0.1114, step time: 0.3188\n",
      "105/224, train_loss: 0.1379, step time: 0.3905\n",
      "106/224, train_loss: 0.0846, step time: 0.3130\n",
      "107/224, train_loss: 0.1103, step time: 0.3133\n",
      "108/224, train_loss: 0.0815, step time: 0.3161\n",
      "109/224, train_loss: 0.2137, step time: 0.3182\n",
      "110/224, train_loss: 0.1554, step time: 0.3782\n",
      "111/224, train_loss: 0.3627, step time: 0.4023\n",
      "112/224, train_loss: 0.0930, step time: 0.3181\n",
      "113/224, train_loss: 0.1134, step time: 0.3138\n",
      "114/224, train_loss: 0.3209, step time: 0.3756\n",
      "115/224, train_loss: 0.0490, step time: 0.3144\n",
      "116/224, train_loss: 0.0760, step time: 0.4085\n",
      "117/224, train_loss: 0.0741, step time: 0.3162\n",
      "118/224, train_loss: 0.0942, step time: 0.3157\n",
      "119/224, train_loss: 0.1899, step time: 0.3680\n",
      "120/224, train_loss: 0.0893, step time: 0.3160\n",
      "121/224, train_loss: 0.2669, step time: 0.3650\n",
      "122/224, train_loss: 0.1203, step time: 0.3788\n",
      "123/224, train_loss: 0.1332, step time: 0.3692\n",
      "124/224, train_loss: 0.3242, step time: 0.3893\n",
      "125/224, train_loss: 0.0951, step time: 0.4036\n",
      "126/224, train_loss: 0.0911, step time: 0.3153\n",
      "127/224, train_loss: 0.0747, step time: 0.3154\n",
      "128/224, train_loss: 0.0794, step time: 0.4068\n",
      "129/224, train_loss: 0.1063, step time: 0.3143\n",
      "130/224, train_loss: 0.0808, step time: 0.3174\n",
      "131/224, train_loss: 0.0985, step time: 0.3152\n",
      "132/224, train_loss: 0.1445, step time: 0.3997\n",
      "133/224, train_loss: 0.0650, step time: 0.3137\n",
      "134/224, train_loss: 0.1512, step time: 0.3164\n",
      "135/224, train_loss: 0.1706, step time: 0.3809\n",
      "136/224, train_loss: 0.0839, step time: 0.3785\n",
      "137/224, train_loss: 0.1231, step time: 0.4131\n",
      "138/224, train_loss: 0.1271, step time: 0.3914\n",
      "139/224, train_loss: 0.0374, step time: 0.3837\n",
      "140/224, train_loss: 0.1823, step time: 0.3743\n",
      "141/224, train_loss: 0.1771, step time: 0.3152\n",
      "142/224, train_loss: 0.1579, step time: 0.3989\n",
      "143/224, train_loss: 0.1328, step time: 0.3980\n",
      "144/224, train_loss: 0.2336, step time: 0.4121\n",
      "145/224, train_loss: 0.1400, step time: 0.4146\n",
      "146/224, train_loss: 0.1193, step time: 0.3693\n",
      "147/224, train_loss: 0.0728, step time: 0.3165\n",
      "148/224, train_loss: 0.2727, step time: 0.3889\n",
      "149/224, train_loss: 0.1069, step time: 0.3159\n",
      "150/224, train_loss: 0.1304, step time: 0.3661\n",
      "151/224, train_loss: 0.1503, step time: 0.3928\n",
      "152/224, train_loss: 0.0849, step time: 0.3155\n",
      "153/224, train_loss: 0.0754, step time: 0.3173\n",
      "154/224, train_loss: 0.1159, step time: 0.3150\n",
      "155/224, train_loss: 0.0663, step time: 0.3128\n",
      "156/224, train_loss: 0.1189, step time: 0.3866\n",
      "157/224, train_loss: 0.1404, step time: 0.4130\n",
      "158/224, train_loss: 0.0555, step time: 0.3689\n",
      "159/224, train_loss: 0.0783, step time: 0.3157\n",
      "160/224, train_loss: 0.0964, step time: 0.3179\n",
      "161/224, train_loss: 0.0857, step time: 0.3159\n",
      "162/224, train_loss: 0.0415, step time: 0.3151\n",
      "163/224, train_loss: 0.1099, step time: 0.3171\n",
      "164/224, train_loss: 0.0875, step time: 0.3171\n",
      "165/224, train_loss: 0.0762, step time: 0.3151\n",
      "166/224, train_loss: 0.0952, step time: 0.3130\n",
      "167/224, train_loss: 0.0702, step time: 0.3158\n",
      "168/224, train_loss: 0.0620, step time: 0.3158\n",
      "169/224, train_loss: 0.1035, step time: 0.4042\n",
      "170/224, train_loss: 0.1178, step time: 0.3793\n",
      "171/224, train_loss: 0.0927, step time: 0.3684\n",
      "172/224, train_loss: 0.0751, step time: 0.3154\n",
      "173/224, train_loss: 0.1258, step time: 0.3976\n",
      "174/224, train_loss: 0.0859, step time: 0.3163\n",
      "175/224, train_loss: 0.0747, step time: 0.3176\n",
      "176/224, train_loss: 0.1053, step time: 0.3139\n",
      "177/224, train_loss: 0.0625, step time: 0.3179\n",
      "178/224, train_loss: 0.0632, step time: 0.3151\n",
      "179/224, train_loss: 0.2241, step time: 0.3668\n",
      "180/224, train_loss: 0.0859, step time: 0.3151\n",
      "181/224, train_loss: 0.0931, step time: 0.4041\n",
      "182/224, train_loss: 0.0826, step time: 0.3157\n",
      "183/224, train_loss: 0.1787, step time: 0.4019\n",
      "184/224, train_loss: 0.0804, step time: 0.3153\n",
      "185/224, train_loss: 0.0677, step time: 0.3148\n",
      "186/224, train_loss: 0.0817, step time: 0.3177\n",
      "187/224, train_loss: 0.0883, step time: 0.3655\n",
      "188/224, train_loss: 0.0931, step time: 0.4064\n",
      "189/224, train_loss: 0.0798, step time: 0.3675\n",
      "190/224, train_loss: 0.0709, step time: 0.3136\n",
      "191/224, train_loss: 0.0956, step time: 0.3824\n",
      "192/224, train_loss: 0.1640, step time: 0.4090\n",
      "193/224, train_loss: 0.1068, step time: 0.4011\n",
      "194/224, train_loss: 0.0813, step time: 0.3152\n",
      "195/224, train_loss: 0.1523, step time: 0.3790\n",
      "196/224, train_loss: 0.0701, step time: 0.3158\n",
      "197/224, train_loss: 0.1435, step time: 0.4048\n",
      "198/224, train_loss: 0.1033, step time: 0.3152\n",
      "199/224, train_loss: 0.1100, step time: 0.3164\n",
      "200/224, train_loss: 0.1302, step time: 0.3750\n",
      "201/224, train_loss: 0.1285, step time: 0.3979\n",
      "202/224, train_loss: 0.2328, step time: 0.3155\n",
      "203/224, train_loss: 0.0848, step time: 0.3150\n",
      "204/224, train_loss: 0.1584, step time: 0.3850\n",
      "205/224, train_loss: 0.0894, step time: 0.3187\n",
      "206/224, train_loss: 0.0926, step time: 0.3178\n",
      "207/224, train_loss: 0.3429, step time: 0.3879\n",
      "208/224, train_loss: 0.0921, step time: 0.3793\n",
      "209/224, train_loss: 0.1085, step time: 0.3159\n",
      "210/224, train_loss: 0.0809, step time: 0.3809\n",
      "211/224, train_loss: 0.1490, step time: 0.3734\n",
      "212/224, train_loss: 0.0765, step time: 0.3159\n",
      "213/224, train_loss: 0.1392, step time: 0.3911\n",
      "214/224, train_loss: 0.1308, step time: 0.3183\n",
      "215/224, train_loss: 0.2375, step time: 0.3159\n",
      "216/224, train_loss: 0.1069, step time: 0.3159\n",
      "217/224, train_loss: 0.1803, step time: 0.3175\n",
      "218/224, train_loss: 0.1091, step time: 0.3968\n",
      "219/224, train_loss: 0.0756, step time: 0.4031\n",
      "220/224, train_loss: 0.2586, step time: 0.4087\n",
      "221/224, train_loss: 0.0661, step time: 0.3178\n",
      "222/224, train_loss: 0.0786, step time: 0.3183\n",
      "223/224, train_loss: 0.1215, step time: 0.3822\n",
      "224/224, train_loss: 0.1671, step time: 0.3163\n",
      "epoch 81 average loss: 0.1234\n",
      "current epoch: 81 current mean dice: 0.7297 class1: 0.9994 class2: 0.7402 class3: 0.4496\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 81 is: 739.2163\n",
      "hello\n",
      "----------\n",
      "epoch 82/100\n",
      "1/224, train_loss: 0.2640, step time: 0.3784\n",
      "2/224, train_loss: 0.0872, step time: 0.3780\n",
      "3/224, train_loss: 0.0617, step time: 0.3167\n",
      "4/224, train_loss: 0.1846, step time: 0.3164\n",
      "5/224, train_loss: 0.0847, step time: 0.3782\n",
      "6/224, train_loss: 0.0691, step time: 0.3144\n",
      "7/224, train_loss: 0.2949, step time: 0.4089\n",
      "8/224, train_loss: 0.1492, step time: 0.4102\n",
      "9/224, train_loss: 0.0998, step time: 0.3154\n",
      "10/224, train_loss: 0.1158, step time: 0.3930\n",
      "11/224, train_loss: 0.0667, step time: 0.3133\n",
      "12/224, train_loss: 0.1267, step time: 0.3174\n",
      "13/224, train_loss: 0.1472, step time: 0.3706\n",
      "14/224, train_loss: 0.1165, step time: 0.3949\n",
      "15/224, train_loss: 0.0532, step time: 0.3665\n",
      "16/224, train_loss: 0.0816, step time: 0.4130\n",
      "17/224, train_loss: 0.1498, step time: 0.3144\n",
      "18/224, train_loss: 0.3014, step time: 0.3987\n",
      "19/224, train_loss: 0.0680, step time: 0.3157\n",
      "20/224, train_loss: 0.1286, step time: 0.4043\n",
      "21/224, train_loss: 0.0894, step time: 0.3152\n",
      "22/224, train_loss: 0.1066, step time: 0.3827\n",
      "23/224, train_loss: 0.2247, step time: 0.3802\n",
      "24/224, train_loss: 0.1097, step time: 0.3179\n",
      "25/224, train_loss: 0.1170, step time: 0.3821\n",
      "26/224, train_loss: 0.0651, step time: 0.3146\n",
      "27/224, train_loss: 0.1237, step time: 0.3146\n",
      "28/224, train_loss: 0.1085, step time: 0.3709\n",
      "29/224, train_loss: 0.1143, step time: 0.3639\n",
      "30/224, train_loss: 0.1002, step time: 0.3146\n",
      "31/224, train_loss: 0.0653, step time: 0.3150\n",
      "32/224, train_loss: 0.0977, step time: 0.3156\n",
      "33/224, train_loss: 0.0997, step time: 0.3155\n",
      "34/224, train_loss: 0.0764, step time: 0.4119\n",
      "35/224, train_loss: 0.0678, step time: 0.3726\n",
      "36/224, train_loss: 0.0988, step time: 0.3171\n",
      "37/224, train_loss: 0.0773, step time: 0.3829\n",
      "38/224, train_loss: 0.0667, step time: 0.3128\n",
      "39/224, train_loss: 0.0890, step time: 0.3144\n",
      "40/224, train_loss: 0.0761, step time: 0.3142\n",
      "41/224, train_loss: 0.0777, step time: 0.4058\n",
      "42/224, train_loss: 0.0694, step time: 0.4000\n",
      "43/224, train_loss: 0.1234, step time: 0.3159\n",
      "44/224, train_loss: 0.1423, step time: 0.3977\n",
      "45/224, train_loss: 0.2664, step time: 0.4060\n",
      "46/224, train_loss: 0.0648, step time: 0.3134\n",
      "47/224, train_loss: 0.1191, step time: 0.3689\n",
      "48/224, train_loss: 0.1269, step time: 0.3682\n",
      "49/224, train_loss: 0.2175, step time: 0.3841\n",
      "50/224, train_loss: 0.0712, step time: 0.3147\n",
      "51/224, train_loss: 0.1583, step time: 0.4081\n",
      "52/224, train_loss: 0.1666, step time: 0.3698\n",
      "53/224, train_loss: 0.2969, step time: 0.3836\n",
      "54/224, train_loss: 0.1357, step time: 0.3149\n",
      "55/224, train_loss: 0.1722, step time: 0.3909\n",
      "56/224, train_loss: 0.0760, step time: 0.3152\n",
      "57/224, train_loss: 0.0815, step time: 0.3147\n",
      "58/224, train_loss: 0.0882, step time: 0.3149\n",
      "59/224, train_loss: 0.1208, step time: 0.3669\n",
      "60/224, train_loss: 0.1999, step time: 0.3969\n",
      "61/224, train_loss: 0.0790, step time: 0.4079\n",
      "62/224, train_loss: 0.0555, step time: 0.4076\n",
      "63/224, train_loss: 0.1260, step time: 0.3906\n",
      "64/224, train_loss: 0.2050, step time: 0.4017\n",
      "65/224, train_loss: 0.0941, step time: 0.3134\n",
      "66/224, train_loss: 0.0939, step time: 0.3129\n",
      "67/224, train_loss: 0.1316, step time: 0.3125\n",
      "68/224, train_loss: 0.0633, step time: 0.3175\n",
      "69/224, train_loss: 0.0925, step time: 0.3675\n",
      "70/224, train_loss: 0.0608, step time: 0.3150\n",
      "71/224, train_loss: 0.0969, step time: 0.3146\n",
      "72/224, train_loss: 0.0896, step time: 0.3148\n",
      "73/224, train_loss: 0.2547, step time: 0.4107\n",
      "74/224, train_loss: 0.0485, step time: 0.3145\n",
      "75/224, train_loss: 0.1371, step time: 0.4000\n",
      "76/224, train_loss: 0.0474, step time: 0.3173\n",
      "77/224, train_loss: 0.0847, step time: 0.3168\n",
      "78/224, train_loss: 0.0699, step time: 0.3150\n",
      "79/224, train_loss: 0.0639, step time: 0.3675\n",
      "80/224, train_loss: 0.0676, step time: 0.3181\n",
      "81/224, train_loss: 0.0719, step time: 0.3761\n",
      "82/224, train_loss: 0.0970, step time: 0.3169\n",
      "83/224, train_loss: 0.1124, step time: 0.3185\n",
      "84/224, train_loss: 0.0914, step time: 0.3155\n",
      "85/224, train_loss: 0.1419, step time: 0.3974\n",
      "86/224, train_loss: 0.1269, step time: 0.3125\n",
      "87/224, train_loss: 0.0814, step time: 0.3145\n",
      "88/224, train_loss: 0.1812, step time: 0.3845\n",
      "89/224, train_loss: 0.1056, step time: 0.3179\n",
      "90/224, train_loss: 0.0740, step time: 0.3981\n",
      "91/224, train_loss: 0.1162, step time: 0.3907\n",
      "92/224, train_loss: 0.2092, step time: 0.3157\n",
      "93/224, train_loss: 0.1044, step time: 0.3160\n",
      "94/224, train_loss: 0.0633, step time: 0.3157\n",
      "95/224, train_loss: 0.0757, step time: 0.3160\n",
      "96/224, train_loss: 0.0861, step time: 0.3128\n",
      "97/224, train_loss: 0.1064, step time: 0.3146\n",
      "98/224, train_loss: 0.0851, step time: 0.3147\n",
      "99/224, train_loss: 0.0663, step time: 0.3172\n",
      "100/224, train_loss: 0.1002, step time: 0.3169\n",
      "101/224, train_loss: 0.0728, step time: 0.3693\n",
      "102/224, train_loss: 0.0979, step time: 0.3173\n",
      "103/224, train_loss: 0.0671, step time: 0.3149\n",
      "104/224, train_loss: 0.0655, step time: 0.3124\n",
      "105/224, train_loss: 0.1058, step time: 0.3172\n",
      "106/224, train_loss: 0.0647, step time: 0.3145\n",
      "107/224, train_loss: 0.0873, step time: 0.3934\n",
      "108/224, train_loss: 0.1168, step time: 0.3925\n",
      "109/224, train_loss: 0.0535, step time: 0.4024\n",
      "110/224, train_loss: 0.1039, step time: 0.3169\n",
      "111/224, train_loss: 0.0806, step time: 0.3147\n",
      "112/224, train_loss: 0.1143, step time: 0.3172\n",
      "113/224, train_loss: 0.1322, step time: 0.3724\n",
      "114/224, train_loss: 0.0967, step time: 0.3921\n",
      "115/224, train_loss: 0.0774, step time: 0.3161\n",
      "116/224, train_loss: 0.0702, step time: 0.3957\n",
      "117/224, train_loss: 0.0555, step time: 0.3179\n",
      "118/224, train_loss: 0.2275, step time: 0.3704\n",
      "119/224, train_loss: 0.0888, step time: 0.3168\n",
      "120/224, train_loss: 0.0567, step time: 0.3155\n",
      "121/224, train_loss: 0.2324, step time: 0.3737\n",
      "122/224, train_loss: 0.0590, step time: 0.3153\n",
      "123/224, train_loss: 0.1125, step time: 0.3148\n",
      "124/224, train_loss: 0.0781, step time: 0.3167\n",
      "125/224, train_loss: 0.1194, step time: 0.3126\n",
      "126/224, train_loss: 0.0543, step time: 0.3170\n",
      "127/224, train_loss: 0.2250, step time: 0.4001\n",
      "128/224, train_loss: 0.2287, step time: 0.3925\n",
      "129/224, train_loss: 0.1342, step time: 0.3736\n",
      "130/224, train_loss: 0.1176, step time: 0.3770\n",
      "131/224, train_loss: 0.0863, step time: 0.3822\n",
      "132/224, train_loss: 0.1547, step time: 0.3901\n",
      "133/224, train_loss: 0.0958, step time: 0.3991\n",
      "134/224, train_loss: 0.1349, step time: 0.3839\n",
      "135/224, train_loss: 0.1370, step time: 0.3741\n",
      "136/224, train_loss: 0.1085, step time: 0.3897\n",
      "137/224, train_loss: 0.0994, step time: 0.3908\n",
      "138/224, train_loss: 0.0750, step time: 0.3182\n",
      "139/224, train_loss: 0.1732, step time: 0.4117\n",
      "140/224, train_loss: 0.0995, step time: 0.4056\n",
      "141/224, train_loss: 0.0805, step time: 0.3168\n",
      "142/224, train_loss: 0.0798, step time: 0.3941\n",
      "143/224, train_loss: 0.2841, step time: 0.4018\n",
      "144/224, train_loss: 0.0847, step time: 0.3147\n",
      "145/224, train_loss: 0.0751, step time: 0.3176\n",
      "146/224, train_loss: 0.2472, step time: 0.4040\n",
      "147/224, train_loss: 0.0789, step time: 0.3914\n",
      "148/224, train_loss: 0.1284, step time: 0.3652\n",
      "149/224, train_loss: 0.1285, step time: 0.4084\n",
      "150/224, train_loss: 0.3059, step time: 0.3835\n",
      "151/224, train_loss: 0.0803, step time: 0.3147\n",
      "152/224, train_loss: 0.1497, step time: 0.3937\n",
      "153/224, train_loss: 0.0763, step time: 0.3161\n",
      "154/224, train_loss: 0.0972, step time: 0.3911\n",
      "155/224, train_loss: 0.1182, step time: 0.3940\n",
      "156/224, train_loss: 0.0945, step time: 0.3841\n",
      "157/224, train_loss: 0.0662, step time: 0.3146\n",
      "158/224, train_loss: 0.0819, step time: 0.3832\n",
      "159/224, train_loss: 0.2261, step time: 0.3170\n",
      "160/224, train_loss: 0.1869, step time: 0.3716\n",
      "161/224, train_loss: 0.1872, step time: 0.3996\n",
      "162/224, train_loss: 0.0886, step time: 0.3937\n",
      "163/224, train_loss: 0.0578, step time: 0.3154\n",
      "164/224, train_loss: 0.1223, step time: 0.4063\n",
      "165/224, train_loss: 0.1039, step time: 0.3154\n",
      "166/224, train_loss: 0.0651, step time: 0.3800\n",
      "167/224, train_loss: 0.0780, step time: 0.3147\n",
      "168/224, train_loss: 0.0480, step time: 0.3794\n",
      "169/224, train_loss: 0.2626, step time: 0.3942\n",
      "170/224, train_loss: 0.1315, step time: 0.3152\n",
      "171/224, train_loss: 0.3719, step time: 0.3773\n",
      "172/224, train_loss: 0.0933, step time: 0.4056\n",
      "173/224, train_loss: 0.1005, step time: 0.3783\n",
      "174/224, train_loss: 0.1358, step time: 0.3973\n",
      "175/224, train_loss: 0.1504, step time: 0.3167\n",
      "176/224, train_loss: 0.1105, step time: 0.3871\n",
      "177/224, train_loss: 0.1072, step time: 0.3793\n",
      "178/224, train_loss: 0.0852, step time: 0.3157\n",
      "179/224, train_loss: 0.0949, step time: 0.3180\n",
      "180/224, train_loss: 0.0695, step time: 0.3155\n",
      "181/224, train_loss: 0.0896, step time: 0.3148\n",
      "182/224, train_loss: 0.0723, step time: 0.3167\n",
      "183/224, train_loss: 0.0842, step time: 0.3165\n",
      "184/224, train_loss: 0.0690, step time: 0.3142\n",
      "185/224, train_loss: 0.0874, step time: 0.3165\n",
      "186/224, train_loss: 0.0515, step time: 0.3175\n",
      "187/224, train_loss: 0.1110, step time: 0.3835\n",
      "188/224, train_loss: 0.1243, step time: 0.3145\n",
      "189/224, train_loss: 0.4054, step time: 0.3758\n",
      "190/224, train_loss: 0.0880, step time: 0.3149\n",
      "191/224, train_loss: 0.1147, step time: 0.3655\n",
      "192/224, train_loss: 0.1148, step time: 0.3983\n",
      "193/224, train_loss: 0.1721, step time: 0.3127\n",
      "194/224, train_loss: 0.1295, step time: 0.4046\n",
      "195/224, train_loss: 0.1003, step time: 0.3883\n",
      "196/224, train_loss: 0.0741, step time: 0.3123\n",
      "197/224, train_loss: 0.0938, step time: 0.3164\n",
      "198/224, train_loss: 0.0991, step time: 0.3929\n",
      "199/224, train_loss: 0.1190, step time: 0.3148\n",
      "200/224, train_loss: 0.2207, step time: 0.4082\n",
      "201/224, train_loss: 0.0668, step time: 0.3156\n",
      "202/224, train_loss: 0.0821, step time: 0.3176\n",
      "203/224, train_loss: 0.1252, step time: 0.3822\n",
      "204/224, train_loss: 0.2146, step time: 0.3147\n",
      "205/224, train_loss: 0.1408, step time: 0.3802\n",
      "206/224, train_loss: 0.0769, step time: 0.3672\n",
      "207/224, train_loss: 0.0913, step time: 0.3994\n",
      "208/224, train_loss: 0.0821, step time: 0.3143\n",
      "209/224, train_loss: 0.1012, step time: 0.3171\n",
      "210/224, train_loss: 0.1605, step time: 0.3630\n",
      "211/224, train_loss: 0.1313, step time: 0.3796\n",
      "212/224, train_loss: 0.1118, step time: 0.3901\n",
      "213/224, train_loss: 0.0695, step time: 0.3128\n",
      "214/224, train_loss: 0.3919, step time: 0.3835\n",
      "215/224, train_loss: 0.0657, step time: 0.3142\n",
      "216/224, train_loss: 0.1268, step time: 0.3972\n",
      "217/224, train_loss: 0.3312, step time: 0.3123\n",
      "218/224, train_loss: 0.1964, step time: 0.3150\n",
      "219/224, train_loss: 0.0945, step time: 0.3149\n",
      "220/224, train_loss: 0.1223, step time: 0.3738\n",
      "221/224, train_loss: 0.0603, step time: 0.3155\n",
      "222/224, train_loss: 0.1290, step time: 0.4035\n",
      "223/224, train_loss: 0.0865, step time: 0.3650\n",
      "224/224, train_loss: 0.1546, step time: 0.3896\n",
      "epoch 82 average loss: 0.1187\n",
      "current epoch: 82 current mean dice: 0.7141 class1: 0.9993 class2: 0.7332 class3: 0.4097\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 82 is: 750.9781\n",
      "hello\n",
      "----------\n",
      "epoch 83/100\n",
      "1/224, train_loss: 0.1138, step time: 0.3202\n",
      "2/224, train_loss: 0.2059, step time: 0.3837\n",
      "3/224, train_loss: 0.0540, step time: 0.3860\n",
      "4/224, train_loss: 0.0759, step time: 0.4085\n",
      "5/224, train_loss: 0.1001, step time: 0.3135\n",
      "6/224, train_loss: 0.1183, step time: 0.3730\n",
      "7/224, train_loss: 0.0540, step time: 0.3184\n",
      "8/224, train_loss: 0.1342, step time: 0.3685\n",
      "9/224, train_loss: 0.1077, step time: 0.3164\n",
      "10/224, train_loss: 0.0939, step time: 0.3800\n",
      "11/224, train_loss: 0.1126, step time: 0.3787\n",
      "12/224, train_loss: 0.0632, step time: 0.3696\n",
      "13/224, train_loss: 0.0611, step time: 0.3150\n",
      "14/224, train_loss: 0.0561, step time: 0.3165\n",
      "15/224, train_loss: 0.1564, step time: 0.3886\n",
      "16/224, train_loss: 0.1763, step time: 0.3741\n",
      "17/224, train_loss: 0.1845, step time: 0.3898\n",
      "18/224, train_loss: 0.0896, step time: 0.3180\n",
      "19/224, train_loss: 0.1620, step time: 0.3655\n",
      "20/224, train_loss: 0.0916, step time: 0.3787\n",
      "21/224, train_loss: 0.0890, step time: 0.3149\n",
      "22/224, train_loss: 0.1114, step time: 0.3151\n",
      "23/224, train_loss: 0.1153, step time: 0.3167\n",
      "24/224, train_loss: 0.0843, step time: 0.3976\n",
      "25/224, train_loss: 0.0714, step time: 0.3173\n",
      "26/224, train_loss: 0.0785, step time: 0.3186\n",
      "27/224, train_loss: 0.1357, step time: 0.3150\n",
      "28/224, train_loss: 0.1262, step time: 0.3997\n",
      "29/224, train_loss: 0.1272, step time: 0.3647\n",
      "30/224, train_loss: 0.0484, step time: 0.3945\n",
      "31/224, train_loss: 0.1313, step time: 0.3945\n",
      "32/224, train_loss: 0.1017, step time: 0.3719\n",
      "33/224, train_loss: 0.0690, step time: 0.3913\n",
      "34/224, train_loss: 0.0700, step time: 0.3150\n",
      "35/224, train_loss: 0.2477, step time: 0.3757\n",
      "36/224, train_loss: 0.1097, step time: 0.3838\n",
      "37/224, train_loss: 0.0645, step time: 0.3156\n",
      "38/224, train_loss: 0.3243, step time: 0.4074\n",
      "39/224, train_loss: 0.3115, step time: 0.3860\n",
      "40/224, train_loss: 0.3694, step time: 0.4151\n",
      "41/224, train_loss: 0.1233, step time: 0.3151\n",
      "42/224, train_loss: 0.1256, step time: 0.4083\n",
      "43/224, train_loss: 0.0954, step time: 0.3715\n",
      "44/224, train_loss: 0.0903, step time: 0.3947\n",
      "45/224, train_loss: 0.2083, step time: 0.3180\n",
      "46/224, train_loss: 0.0544, step time: 0.3130\n",
      "47/224, train_loss: 0.1134, step time: 0.3963\n",
      "48/224, train_loss: 0.1388, step time: 0.3682\n",
      "49/224, train_loss: 0.1107, step time: 0.3935\n",
      "50/224, train_loss: 0.2082, step time: 0.3176\n",
      "51/224, train_loss: 0.0691, step time: 0.3807\n",
      "52/224, train_loss: 0.0977, step time: 0.4085\n",
      "53/224, train_loss: 0.0882, step time: 0.3176\n",
      "54/224, train_loss: 0.1110, step time: 0.3935\n",
      "55/224, train_loss: 0.0738, step time: 0.3185\n",
      "56/224, train_loss: 0.0941, step time: 0.3960\n",
      "57/224, train_loss: 0.0871, step time: 0.3164\n",
      "58/224, train_loss: 0.1060, step time: 0.3882\n",
      "59/224, train_loss: 0.1298, step time: 0.3155\n",
      "60/224, train_loss: 0.3197, step time: 0.3903\n",
      "61/224, train_loss: 0.0760, step time: 0.3163\n",
      "62/224, train_loss: 0.1838, step time: 0.4017\n",
      "63/224, train_loss: 0.0910, step time: 0.4085\n",
      "64/224, train_loss: 0.0662, step time: 0.3178\n",
      "65/224, train_loss: 0.1485, step time: 0.3671\n",
      "66/224, train_loss: 0.0675, step time: 0.3150\n",
      "67/224, train_loss: 0.3171, step time: 0.3719\n",
      "68/224, train_loss: 0.0935, step time: 0.3153\n",
      "69/224, train_loss: 0.1686, step time: 0.3821\n",
      "70/224, train_loss: 0.2137, step time: 0.3137\n",
      "71/224, train_loss: 0.1122, step time: 0.3148\n",
      "72/224, train_loss: 0.1007, step time: 0.3731\n",
      "73/224, train_loss: 0.0604, step time: 0.3159\n",
      "74/224, train_loss: 0.0822, step time: 0.3133\n",
      "75/224, train_loss: 0.0907, step time: 0.3127\n",
      "76/224, train_loss: 0.1466, step time: 0.3907\n",
      "77/224, train_loss: 0.2616, step time: 0.3823\n",
      "78/224, train_loss: 0.0933, step time: 0.4131\n",
      "79/224, train_loss: 0.2016, step time: 0.3894\n",
      "80/224, train_loss: 0.0513, step time: 0.3176\n",
      "81/224, train_loss: 0.1278, step time: 0.3182\n",
      "82/224, train_loss: 0.0816, step time: 0.3156\n",
      "83/224, train_loss: 0.0745, step time: 0.3147\n",
      "84/224, train_loss: 0.0893, step time: 0.3161\n",
      "85/224, train_loss: 0.0547, step time: 0.3144\n",
      "86/224, train_loss: 0.1198, step time: 0.3168\n",
      "87/224, train_loss: 0.0898, step time: 0.3182\n",
      "88/224, train_loss: 0.0838, step time: 0.3179\n",
      "89/224, train_loss: 0.0618, step time: 0.3957\n",
      "90/224, train_loss: 0.1264, step time: 0.4070\n",
      "91/224, train_loss: 0.1114, step time: 0.3149\n",
      "92/224, train_loss: 0.0736, step time: 0.3147\n",
      "93/224, train_loss: 0.0897, step time: 0.3149\n",
      "94/224, train_loss: 0.0978, step time: 0.3145\n",
      "95/224, train_loss: 0.1412, step time: 0.4136\n",
      "96/224, train_loss: 0.1411, step time: 0.3747\n",
      "97/224, train_loss: 0.0715, step time: 0.4083\n",
      "98/224, train_loss: 0.0903, step time: 0.3154\n",
      "99/224, train_loss: 0.1093, step time: 0.3775\n",
      "100/224, train_loss: 0.0852, step time: 0.4072\n",
      "101/224, train_loss: 0.1123, step time: 0.3153\n",
      "102/224, train_loss: 0.1233, step time: 0.3134\n",
      "103/224, train_loss: 0.1275, step time: 0.3908\n",
      "104/224, train_loss: 0.0702, step time: 0.3150\n",
      "105/224, train_loss: 0.0551, step time: 0.3794\n",
      "106/224, train_loss: 0.0901, step time: 0.3843\n",
      "107/224, train_loss: 0.0732, step time: 0.3157\n",
      "108/224, train_loss: 0.1537, step time: 0.3772\n",
      "109/224, train_loss: 0.0829, step time: 0.3169\n",
      "110/224, train_loss: 0.0861, step time: 0.3172\n",
      "111/224, train_loss: 0.2998, step time: 0.3867\n",
      "112/224, train_loss: 0.0618, step time: 0.3903\n",
      "113/224, train_loss: 0.1423, step time: 0.3924\n",
      "114/224, train_loss: 0.0626, step time: 0.3175\n",
      "115/224, train_loss: 0.0366, step time: 0.3166\n",
      "116/224, train_loss: 0.3878, step time: 0.4098\n",
      "117/224, train_loss: 0.0843, step time: 0.3852\n",
      "118/224, train_loss: 0.0969, step time: 0.3915\n",
      "119/224, train_loss: 0.0884, step time: 0.3156\n",
      "120/224, train_loss: 0.1341, step time: 0.3731\n",
      "121/224, train_loss: 0.0759, step time: 0.3151\n",
      "122/224, train_loss: 0.1636, step time: 0.3696\n",
      "123/224, train_loss: 0.0647, step time: 0.3173\n",
      "124/224, train_loss: 0.0783, step time: 0.3154\n",
      "125/224, train_loss: 0.1110, step time: 0.3147\n",
      "126/224, train_loss: 0.1540, step time: 0.3835\n",
      "127/224, train_loss: 0.1218, step time: 0.4138\n",
      "128/224, train_loss: 0.0923, step time: 0.4007\n",
      "129/224, train_loss: 0.0711, step time: 0.3142\n",
      "130/224, train_loss: 0.1080, step time: 0.4091\n",
      "131/224, train_loss: 0.1096, step time: 0.3937\n",
      "132/224, train_loss: 0.0524, step time: 0.3169\n",
      "133/224, train_loss: 0.0905, step time: 0.3631\n",
      "134/224, train_loss: 0.0439, step time: 0.3150\n",
      "135/224, train_loss: 0.0784, step time: 0.3129\n",
      "136/224, train_loss: 0.1066, step time: 0.3699\n",
      "137/224, train_loss: 0.0710, step time: 0.3164\n",
      "138/224, train_loss: 0.1221, step time: 0.3737\n",
      "139/224, train_loss: 0.1015, step time: 0.3168\n",
      "140/224, train_loss: 0.1485, step time: 0.4046\n",
      "141/224, train_loss: 0.0731, step time: 0.3147\n",
      "142/224, train_loss: 0.1148, step time: 0.4063\n",
      "143/224, train_loss: 0.1021, step time: 0.3785\n",
      "144/224, train_loss: 0.0782, step time: 0.3150\n",
      "145/224, train_loss: 0.1800, step time: 0.4138\n",
      "146/224, train_loss: 0.0822, step time: 0.3801\n",
      "147/224, train_loss: 0.0810, step time: 0.3711\n",
      "148/224, train_loss: 0.1307, step time: 0.3142\n",
      "149/224, train_loss: 0.1251, step time: 0.3119\n",
      "150/224, train_loss: 0.0751, step time: 0.3142\n",
      "151/224, train_loss: 0.0673, step time: 0.3140\n",
      "152/224, train_loss: 0.0628, step time: 0.3864\n",
      "153/224, train_loss: 0.0688, step time: 0.3175\n",
      "154/224, train_loss: 0.0664, step time: 0.3148\n",
      "155/224, train_loss: 0.1596, step time: 0.3694\n",
      "156/224, train_loss: 0.2750, step time: 0.4036\n",
      "157/224, train_loss: 0.1441, step time: 0.3945\n",
      "158/224, train_loss: 0.0718, step time: 0.3173\n",
      "159/224, train_loss: 0.0749, step time: 0.3153\n",
      "160/224, train_loss: 0.0606, step time: 0.3168\n",
      "161/224, train_loss: 0.0794, step time: 0.3172\n",
      "162/224, train_loss: 0.0734, step time: 0.3150\n",
      "163/224, train_loss: 0.1429, step time: 0.3144\n",
      "164/224, train_loss: 0.0742, step time: 0.3762\n",
      "165/224, train_loss: 0.0844, step time: 0.3173\n",
      "166/224, train_loss: 0.3576, step time: 0.3149\n",
      "167/224, train_loss: 0.1700, step time: 0.3144\n",
      "168/224, train_loss: 0.3455, step time: 0.3855\n",
      "169/224, train_loss: 0.2506, step time: 0.3855\n",
      "170/224, train_loss: 0.1023, step time: 0.3167\n",
      "171/224, train_loss: 0.1271, step time: 0.3169\n",
      "172/224, train_loss: 0.1646, step time: 0.3989\n",
      "173/224, train_loss: 0.0749, step time: 0.3149\n",
      "174/224, train_loss: 0.1300, step time: 0.3951\n",
      "175/224, train_loss: 0.0774, step time: 0.3926\n",
      "176/224, train_loss: 0.1530, step time: 0.3799\n",
      "177/224, train_loss: 0.1075, step time: 0.3145\n",
      "178/224, train_loss: 0.2895, step time: 0.3747\n",
      "179/224, train_loss: 0.2823, step time: 0.3138\n",
      "180/224, train_loss: 0.0558, step time: 0.3161\n",
      "181/224, train_loss: 0.1511, step time: 0.3162\n",
      "182/224, train_loss: 0.1959, step time: 0.4097\n",
      "183/224, train_loss: 0.0794, step time: 0.3162\n",
      "184/224, train_loss: 0.1695, step time: 0.3125\n",
      "185/224, train_loss: 0.2066, step time: 0.3143\n",
      "186/224, train_loss: 0.1327, step time: 0.3165\n",
      "187/224, train_loss: 0.1570, step time: 0.3172\n",
      "188/224, train_loss: 0.3254, step time: 0.3736\n",
      "189/224, train_loss: 0.1183, step time: 0.3147\n",
      "190/224, train_loss: 0.1050, step time: 0.3881\n",
      "191/224, train_loss: 0.1683, step time: 0.4007\n",
      "192/224, train_loss: 0.1150, step time: 0.3148\n",
      "193/224, train_loss: 0.0760, step time: 0.3857\n",
      "194/224, train_loss: 0.1186, step time: 0.3906\n",
      "195/224, train_loss: 0.1741, step time: 0.3805\n",
      "196/224, train_loss: 0.1354, step time: 0.3735\n",
      "197/224, train_loss: 0.1704, step time: 0.3774\n",
      "198/224, train_loss: 0.2111, step time: 0.4091\n",
      "199/224, train_loss: 0.0999, step time: 0.3155\n",
      "200/224, train_loss: 0.1001, step time: 0.3131\n",
      "201/224, train_loss: 0.2204, step time: 0.3829\n",
      "202/224, train_loss: 0.0968, step time: 0.3142\n",
      "203/224, train_loss: 0.0739, step time: 0.3723\n",
      "204/224, train_loss: 0.1087, step time: 0.3169\n",
      "205/224, train_loss: 0.0878, step time: 0.3143\n",
      "206/224, train_loss: 0.1383, step time: 0.3168\n",
      "207/224, train_loss: 0.1605, step time: 0.4141\n",
      "208/224, train_loss: 0.1093, step time: 0.3166\n",
      "209/224, train_loss: 0.3350, step time: 0.3894\n",
      "210/224, train_loss: 0.0603, step time: 0.3139\n",
      "211/224, train_loss: 0.1326, step time: 0.3120\n",
      "212/224, train_loss: 0.1392, step time: 0.4077\n",
      "213/224, train_loss: 0.1653, step time: 0.3144\n",
      "214/224, train_loss: 0.1581, step time: 0.3878\n",
      "215/224, train_loss: 0.3338, step time: 0.4017\n",
      "216/224, train_loss: 0.2072, step time: 0.3960\n",
      "217/224, train_loss: 0.1059, step time: 0.3782\n",
      "218/224, train_loss: 0.0774, step time: 0.3175\n",
      "219/224, train_loss: 0.0907, step time: 0.3168\n",
      "220/224, train_loss: 0.0778, step time: 0.3163\n",
      "221/224, train_loss: 0.1016, step time: 0.3712\n",
      "222/224, train_loss: 0.0994, step time: 0.3793\n",
      "223/224, train_loss: 0.0627, step time: 0.3169\n",
      "224/224, train_loss: 0.0837, step time: 0.3141\n",
      "epoch 83 average loss: 0.1241\n",
      "current epoch: 83 current mean dice: 0.7173 class1: 0.9993 class2: 0.7411 class3: 0.4114\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 83 is: 732.3786\n",
      "hello\n",
      "----------\n",
      "epoch 84/100\n",
      "1/224, train_loss: 0.0713, step time: 0.3130\n",
      "2/224, train_loss: 0.0884, step time: 0.3143\n",
      "3/224, train_loss: 0.1066, step time: 0.3148\n",
      "4/224, train_loss: 0.1625, step time: 0.3819\n",
      "5/224, train_loss: 0.0941, step time: 0.3171\n",
      "6/224, train_loss: 0.2564, step time: 0.3806\n",
      "7/224, train_loss: 0.0585, step time: 0.3677\n",
      "8/224, train_loss: 0.1554, step time: 0.4142\n",
      "9/224, train_loss: 0.1766, step time: 0.3153\n",
      "10/224, train_loss: 0.0927, step time: 0.3805\n",
      "11/224, train_loss: 0.1441, step time: 0.4051\n",
      "12/224, train_loss: 0.0899, step time: 0.3165\n",
      "13/224, train_loss: 0.2120, step time: 0.3897\n",
      "14/224, train_loss: 0.0866, step time: 0.3140\n",
      "15/224, train_loss: 0.1157, step time: 0.3140\n",
      "16/224, train_loss: 0.1182, step time: 0.3867\n",
      "17/224, train_loss: 0.1442, step time: 0.3804\n",
      "18/224, train_loss: 0.0763, step time: 0.3126\n",
      "19/224, train_loss: 0.1026, step time: 0.3152\n",
      "20/224, train_loss: 0.0699, step time: 0.3148\n",
      "21/224, train_loss: 0.2812, step time: 0.3840\n",
      "22/224, train_loss: 0.0888, step time: 0.3126\n",
      "23/224, train_loss: 0.2543, step time: 0.4071\n",
      "24/224, train_loss: 0.0816, step time: 0.3973\n",
      "25/224, train_loss: 0.1344, step time: 0.3169\n",
      "26/224, train_loss: 0.1113, step time: 0.3675\n",
      "27/224, train_loss: 0.0844, step time: 0.3164\n",
      "28/224, train_loss: 0.0884, step time: 0.4122\n",
      "29/224, train_loss: 0.2557, step time: 0.4077\n",
      "30/224, train_loss: 0.0889, step time: 0.3162\n",
      "31/224, train_loss: 0.1585, step time: 0.3165\n",
      "32/224, train_loss: 0.1051, step time: 0.3162\n",
      "33/224, train_loss: 0.1271, step time: 0.4086\n",
      "34/224, train_loss: 0.0645, step time: 0.3151\n",
      "35/224, train_loss: 0.0630, step time: 0.3166\n",
      "36/224, train_loss: 0.0698, step time: 0.3142\n",
      "37/224, train_loss: 0.1707, step time: 0.3706\n",
      "38/224, train_loss: 0.0500, step time: 0.3127\n",
      "39/224, train_loss: 0.1236, step time: 0.3167\n",
      "40/224, train_loss: 0.1032, step time: 0.3120\n",
      "41/224, train_loss: 0.0779, step time: 0.3166\n",
      "42/224, train_loss: 0.0928, step time: 0.3831\n",
      "43/224, train_loss: 0.1213, step time: 0.3724\n",
      "44/224, train_loss: 0.0663, step time: 0.3143\n",
      "45/224, train_loss: 0.3465, step time: 0.3823\n",
      "46/224, train_loss: 0.1652, step time: 0.3121\n",
      "47/224, train_loss: 0.1399, step time: 0.4066\n",
      "48/224, train_loss: 0.2468, step time: 0.3821\n",
      "49/224, train_loss: 0.1259, step time: 0.3776\n",
      "50/224, train_loss: 0.1813, step time: 0.3938\n",
      "51/224, train_loss: 0.1268, step time: 0.3894\n",
      "52/224, train_loss: 0.2251, step time: 0.3142\n",
      "53/224, train_loss: 0.1060, step time: 0.4083\n",
      "54/224, train_loss: 0.0872, step time: 0.3736\n",
      "55/224, train_loss: 0.0728, step time: 0.3152\n",
      "56/224, train_loss: 0.0847, step time: 0.3146\n",
      "57/224, train_loss: 0.1445, step time: 0.3782\n",
      "58/224, train_loss: 0.2022, step time: 0.3749\n",
      "59/224, train_loss: 0.1250, step time: 0.3776\n",
      "60/224, train_loss: 0.1415, step time: 0.3834\n",
      "61/224, train_loss: 0.0861, step time: 0.3149\n",
      "62/224, train_loss: 0.2233, step time: 0.3940\n",
      "63/224, train_loss: 0.1319, step time: 0.3141\n",
      "64/224, train_loss: 0.1003, step time: 0.4050\n",
      "65/224, train_loss: 0.0780, step time: 0.3896\n",
      "66/224, train_loss: 0.0895, step time: 0.3159\n",
      "67/224, train_loss: 0.2910, step time: 0.3996\n",
      "68/224, train_loss: 0.1243, step time: 0.3134\n",
      "69/224, train_loss: 0.0746, step time: 0.3159\n",
      "70/224, train_loss: 0.1075, step time: 0.3167\n",
      "71/224, train_loss: 0.0689, step time: 0.3181\n",
      "72/224, train_loss: 0.0730, step time: 0.3800\n",
      "73/224, train_loss: 0.0538, step time: 0.3850\n",
      "74/224, train_loss: 0.0688, step time: 0.3141\n",
      "75/224, train_loss: 0.1013, step time: 0.4022\n",
      "76/224, train_loss: 0.1017, step time: 0.3686\n",
      "77/224, train_loss: 0.1220, step time: 0.3943\n",
      "78/224, train_loss: 0.1291, step time: 0.3984\n",
      "79/224, train_loss: 0.0489, step time: 0.3152\n",
      "80/224, train_loss: 0.0892, step time: 0.4107\n",
      "81/224, train_loss: 0.1234, step time: 0.3135\n",
      "82/224, train_loss: 0.1028, step time: 0.3151\n",
      "83/224, train_loss: 0.0811, step time: 0.3882\n",
      "84/224, train_loss: 0.1170, step time: 0.3149\n",
      "85/224, train_loss: 0.0968, step time: 0.3671\n",
      "86/224, train_loss: 0.0670, step time: 0.3151\n",
      "87/224, train_loss: 0.0974, step time: 0.3895\n",
      "88/224, train_loss: 0.1358, step time: 0.3967\n",
      "89/224, train_loss: 0.1284, step time: 0.3740\n",
      "90/224, train_loss: 0.1016, step time: 0.3696\n",
      "91/224, train_loss: 0.0777, step time: 0.3123\n",
      "92/224, train_loss: 0.0587, step time: 0.3878\n",
      "93/224, train_loss: 0.0582, step time: 0.3173\n",
      "94/224, train_loss: 0.0772, step time: 0.3146\n",
      "95/224, train_loss: 0.1030, step time: 0.3129\n",
      "96/224, train_loss: 0.0690, step time: 0.3179\n",
      "97/224, train_loss: 0.0861, step time: 0.3889\n",
      "98/224, train_loss: 0.1831, step time: 0.4087\n",
      "99/224, train_loss: 0.1015, step time: 0.3135\n",
      "100/224, train_loss: 0.1961, step time: 0.3814\n",
      "101/224, train_loss: 0.0871, step time: 0.4011\n",
      "102/224, train_loss: 0.0937, step time: 0.3147\n",
      "103/224, train_loss: 0.0761, step time: 0.3150\n",
      "104/224, train_loss: 0.0548, step time: 0.3781\n",
      "105/224, train_loss: 0.0688, step time: 0.3157\n",
      "106/224, train_loss: 0.2828, step time: 0.4023\n",
      "107/224, train_loss: 0.0664, step time: 0.3722\n",
      "108/224, train_loss: 0.1286, step time: 0.3969\n",
      "109/224, train_loss: 0.1075, step time: 0.3953\n",
      "110/224, train_loss: 0.0893, step time: 0.4054\n",
      "111/224, train_loss: 0.1209, step time: 0.3679\n",
      "112/224, train_loss: 0.1355, step time: 0.3146\n",
      "113/224, train_loss: 0.0400, step time: 0.3148\n",
      "114/224, train_loss: 0.1168, step time: 0.3154\n",
      "115/224, train_loss: 0.0567, step time: 0.3134\n",
      "116/224, train_loss: 0.2651, step time: 0.3968\n",
      "117/224, train_loss: 0.1010, step time: 0.3176\n",
      "118/224, train_loss: 0.0696, step time: 0.3183\n",
      "119/224, train_loss: 0.0635, step time: 0.3176\n",
      "120/224, train_loss: 0.1269, step time: 0.3752\n",
      "121/224, train_loss: 0.0744, step time: 0.3181\n",
      "122/224, train_loss: 0.0824, step time: 0.3151\n",
      "123/224, train_loss: 0.4842, step time: 0.3987\n",
      "124/224, train_loss: 0.0812, step time: 0.3123\n",
      "125/224, train_loss: 0.0662, step time: 0.3151\n",
      "126/224, train_loss: 0.1804, step time: 0.3146\n",
      "127/224, train_loss: 0.0802, step time: 0.3156\n",
      "128/224, train_loss: 0.1164, step time: 0.3177\n",
      "129/224, train_loss: 0.1484, step time: 0.4099\n",
      "130/224, train_loss: 0.0718, step time: 0.3152\n",
      "131/224, train_loss: 0.0950, step time: 0.3846\n",
      "132/224, train_loss: 0.1003, step time: 0.3180\n",
      "133/224, train_loss: 0.0642, step time: 0.3157\n",
      "134/224, train_loss: 0.1015, step time: 0.3151\n",
      "135/224, train_loss: 0.1662, step time: 0.3858\n",
      "136/224, train_loss: 0.2562, step time: 0.4020\n",
      "137/224, train_loss: 0.0953, step time: 0.3155\n",
      "138/224, train_loss: 0.1009, step time: 0.3181\n",
      "139/224, train_loss: 0.3519, step time: 0.4051\n",
      "140/224, train_loss: 0.0821, step time: 0.3148\n",
      "141/224, train_loss: 0.0732, step time: 0.4060\n",
      "142/224, train_loss: 0.1334, step time: 0.3167\n",
      "143/224, train_loss: 0.2747, step time: 0.3749\n",
      "144/224, train_loss: 0.0862, step time: 0.3173\n",
      "145/224, train_loss: 0.1423, step time: 0.4086\n",
      "146/224, train_loss: 0.0737, step time: 0.4055\n",
      "147/224, train_loss: 0.1105, step time: 0.3156\n",
      "148/224, train_loss: 0.1603, step time: 0.4102\n",
      "149/224, train_loss: 0.1275, step time: 0.3966\n",
      "150/224, train_loss: 0.0570, step time: 0.3145\n",
      "151/224, train_loss: 0.2070, step time: 0.3937\n",
      "152/224, train_loss: 0.0473, step time: 0.3906\n",
      "153/224, train_loss: 0.2030, step time: 0.3981\n",
      "154/224, train_loss: 0.1068, step time: 0.4090\n",
      "155/224, train_loss: 0.0775, step time: 0.3153\n",
      "156/224, train_loss: 0.0750, step time: 0.3172\n",
      "157/224, train_loss: 0.1143, step time: 0.3170\n",
      "158/224, train_loss: 0.0742, step time: 0.3168\n",
      "159/224, train_loss: 0.1034, step time: 0.3166\n",
      "160/224, train_loss: 0.1165, step time: 0.3151\n",
      "161/224, train_loss: 0.1233, step time: 0.3146\n",
      "162/224, train_loss: 0.0616, step time: 0.3151\n",
      "163/224, train_loss: 0.1389, step time: 0.3669\n",
      "164/224, train_loss: 0.1686, step time: 0.3961\n",
      "165/224, train_loss: 0.0850, step time: 0.3125\n",
      "166/224, train_loss: 0.1192, step time: 0.4124\n",
      "167/224, train_loss: 0.3213, step time: 0.3148\n",
      "168/224, train_loss: 0.1242, step time: 0.4042\n",
      "169/224, train_loss: 0.0948, step time: 0.3174\n",
      "170/224, train_loss: 0.1031, step time: 0.3124\n",
      "171/224, train_loss: 0.1174, step time: 0.3125\n",
      "172/224, train_loss: 0.1204, step time: 0.3649\n",
      "173/224, train_loss: 0.0986, step time: 0.3146\n",
      "174/224, train_loss: 0.1069, step time: 0.3123\n",
      "175/224, train_loss: 0.1108, step time: 0.3896\n",
      "176/224, train_loss: 0.2668, step time: 0.4076\n",
      "177/224, train_loss: 0.1774, step time: 0.3933\n",
      "178/224, train_loss: 0.1137, step time: 0.3125\n",
      "179/224, train_loss: 0.1197, step time: 0.3154\n",
      "180/224, train_loss: 0.0907, step time: 0.3825\n",
      "181/224, train_loss: 0.1619, step time: 0.3702\n",
      "182/224, train_loss: 0.2637, step time: 0.3825\n",
      "183/224, train_loss: 0.0746, step time: 0.3904\n",
      "184/224, train_loss: 0.0952, step time: 0.3768\n",
      "185/224, train_loss: 0.1137, step time: 0.3851\n",
      "186/224, train_loss: 0.2140, step time: 0.3148\n",
      "187/224, train_loss: 0.0594, step time: 0.3144\n",
      "188/224, train_loss: 0.1024, step time: 0.3963\n",
      "189/224, train_loss: 0.2447, step time: 0.4137\n",
      "190/224, train_loss: 0.1351, step time: 0.4039\n",
      "191/224, train_loss: 0.0770, step time: 0.3127\n",
      "192/224, train_loss: 0.0870, step time: 0.3123\n",
      "193/224, train_loss: 0.0700, step time: 0.3145\n",
      "194/224, train_loss: 0.0997, step time: 0.3151\n",
      "195/224, train_loss: 0.2833, step time: 0.3173\n",
      "196/224, train_loss: 0.0799, step time: 0.3124\n",
      "197/224, train_loss: 0.0882, step time: 0.3168\n",
      "198/224, train_loss: 0.0857, step time: 0.3839\n",
      "199/224, train_loss: 0.0729, step time: 0.3131\n",
      "200/224, train_loss: 0.0995, step time: 0.3663\n",
      "201/224, train_loss: 0.0982, step time: 0.3937\n",
      "202/224, train_loss: 0.0781, step time: 0.3945\n",
      "203/224, train_loss: 0.1204, step time: 0.3806\n",
      "204/224, train_loss: 0.1141, step time: 0.3177\n",
      "205/224, train_loss: 0.0759, step time: 0.4014\n",
      "206/224, train_loss: 0.1308, step time: 0.3986\n",
      "207/224, train_loss: 0.1184, step time: 0.3810\n",
      "208/224, train_loss: 0.1180, step time: 0.3159\n",
      "209/224, train_loss: 0.0553, step time: 0.3164\n",
      "210/224, train_loss: 0.2140, step time: 0.3824\n",
      "211/224, train_loss: 0.0732, step time: 0.3158\n",
      "212/224, train_loss: 0.0834, step time: 0.3984\n",
      "213/224, train_loss: 0.1378, step time: 0.3960\n",
      "214/224, train_loss: 0.0767, step time: 0.3740\n",
      "215/224, train_loss: 0.1889, step time: 0.3161\n",
      "216/224, train_loss: 0.2093, step time: 0.3702\n",
      "217/224, train_loss: 0.0794, step time: 0.3894\n",
      "218/224, train_loss: 0.0881, step time: 0.4070\n",
      "219/224, train_loss: 0.1332, step time: 0.3139\n",
      "220/224, train_loss: 0.0904, step time: 0.3175\n",
      "221/224, train_loss: 0.1750, step time: 0.3925\n",
      "222/224, train_loss: 0.1570, step time: 0.3863\n",
      "223/224, train_loss: 0.1069, step time: 0.3155\n",
      "224/224, train_loss: 0.1501, step time: 0.3959\n",
      "epoch 84 average loss: 0.1223\n",
      "current epoch: 84 current mean dice: 0.7042 class1: 0.9994 class2: 0.7487 class3: 0.3645\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 84 is: 739.4266\n",
      "hello\n",
      "----------\n",
      "epoch 85/100\n",
      "1/224, train_loss: 0.0630, step time: 0.3139\n",
      "2/224, train_loss: 0.1011, step time: 0.3971\n",
      "3/224, train_loss: 0.0798, step time: 0.3174\n",
      "4/224, train_loss: 0.0426, step time: 0.3915\n",
      "5/224, train_loss: 0.2636, step time: 0.3852\n",
      "6/224, train_loss: 0.0639, step time: 0.3841\n",
      "7/224, train_loss: 0.1003, step time: 0.3818\n",
      "8/224, train_loss: 0.1220, step time: 0.3180\n",
      "9/224, train_loss: 0.1284, step time: 0.3793\n",
      "10/224, train_loss: 0.0969, step time: 0.3794\n",
      "11/224, train_loss: 0.0897, step time: 0.3131\n",
      "12/224, train_loss: 0.0942, step time: 0.3137\n",
      "13/224, train_loss: 0.2620, step time: 0.3171\n",
      "14/224, train_loss: 0.0920, step time: 0.3703\n",
      "15/224, train_loss: 0.1055, step time: 0.3174\n",
      "16/224, train_loss: 0.1548, step time: 0.3779\n",
      "17/224, train_loss: 0.0778, step time: 0.3168\n",
      "18/224, train_loss: 0.0660, step time: 0.3179\n",
      "19/224, train_loss: 0.1891, step time: 0.4045\n",
      "20/224, train_loss: 0.2956, step time: 0.4091\n",
      "21/224, train_loss: 0.1621, step time: 0.3175\n",
      "22/224, train_loss: 0.0749, step time: 0.3157\n",
      "23/224, train_loss: 0.0758, step time: 0.3786\n",
      "24/224, train_loss: 0.3087, step time: 0.3761\n",
      "25/224, train_loss: 0.1849, step time: 0.4015\n",
      "26/224, train_loss: 0.1015, step time: 0.3901\n",
      "27/224, train_loss: 0.0641, step time: 0.3909\n",
      "28/224, train_loss: 0.0875, step time: 0.3151\n",
      "29/224, train_loss: 0.2111, step time: 0.3883\n",
      "30/224, train_loss: 0.3620, step time: 0.3968\n",
      "31/224, train_loss: 0.0817, step time: 0.3137\n",
      "32/224, train_loss: 0.1154, step time: 0.3147\n",
      "33/224, train_loss: 0.0623, step time: 0.3852\n",
      "34/224, train_loss: 0.0742, step time: 0.3151\n",
      "35/224, train_loss: 0.1238, step time: 0.4097\n",
      "36/224, train_loss: 0.1141, step time: 0.3134\n",
      "37/224, train_loss: 0.1171, step time: 0.4019\n",
      "38/224, train_loss: 0.0594, step time: 0.3159\n",
      "39/224, train_loss: 0.1163, step time: 0.4041\n",
      "40/224, train_loss: 0.1580, step time: 0.4102\n",
      "41/224, train_loss: 0.0800, step time: 0.3161\n",
      "42/224, train_loss: 0.1925, step time: 0.3799\n",
      "43/224, train_loss: 0.1361, step time: 0.3114\n",
      "44/224, train_loss: 0.1970, step time: 0.3784\n",
      "45/224, train_loss: 0.0347, step time: 0.3176\n",
      "46/224, train_loss: 0.1135, step time: 0.3184\n",
      "47/224, train_loss: 0.3177, step time: 0.3781\n",
      "48/224, train_loss: 0.1283, step time: 0.3845\n",
      "49/224, train_loss: 0.1564, step time: 0.3176\n",
      "50/224, train_loss: 0.1907, step time: 0.4024\n",
      "51/224, train_loss: 0.1584, step time: 0.3896\n",
      "52/224, train_loss: 0.1275, step time: 0.3832\n",
      "53/224, train_loss: 0.2321, step time: 0.4052\n",
      "54/224, train_loss: 0.1074, step time: 0.3150\n",
      "55/224, train_loss: 0.0638, step time: 0.3166\n",
      "56/224, train_loss: 0.0870, step time: 0.3125\n",
      "57/224, train_loss: 0.1215, step time: 0.3867\n",
      "58/224, train_loss: 0.0768, step time: 0.3152\n",
      "59/224, train_loss: 0.1702, step time: 0.3745\n",
      "60/224, train_loss: 0.1591, step time: 0.3149\n",
      "61/224, train_loss: 0.3733, step time: 0.3978\n",
      "62/224, train_loss: 0.0987, step time: 0.4027\n",
      "63/224, train_loss: 0.1595, step time: 0.4018\n",
      "64/224, train_loss: 0.1453, step time: 0.4033\n",
      "65/224, train_loss: 0.1089, step time: 0.3172\n",
      "66/224, train_loss: 0.0935, step time: 0.3926\n",
      "67/224, train_loss: 0.2181, step time: 0.4120\n",
      "68/224, train_loss: 0.1477, step time: 0.3950\n",
      "69/224, train_loss: 0.1050, step time: 0.4087\n",
      "70/224, train_loss: 0.0714, step time: 0.3956\n",
      "71/224, train_loss: 0.1455, step time: 0.3145\n",
      "72/224, train_loss: 0.0832, step time: 0.3175\n",
      "73/224, train_loss: 0.0608, step time: 0.3801\n",
      "74/224, train_loss: 0.1412, step time: 0.3135\n",
      "75/224, train_loss: 0.0851, step time: 0.3148\n",
      "76/224, train_loss: 0.2539, step time: 0.4119\n",
      "77/224, train_loss: 0.2278, step time: 0.3143\n",
      "78/224, train_loss: 0.0713, step time: 0.3170\n",
      "79/224, train_loss: 0.0603, step time: 0.3153\n",
      "80/224, train_loss: 0.0750, step time: 0.3156\n",
      "81/224, train_loss: 0.0820, step time: 0.3146\n",
      "82/224, train_loss: 0.1113, step time: 0.3142\n",
      "83/224, train_loss: 0.0893, step time: 0.3142\n",
      "84/224, train_loss: 0.0524, step time: 0.3167\n",
      "85/224, train_loss: 0.0595, step time: 0.4032\n",
      "86/224, train_loss: 0.3250, step time: 0.3707\n",
      "87/224, train_loss: 0.1197, step time: 0.3142\n",
      "88/224, train_loss: 0.1177, step time: 0.3147\n",
      "89/224, train_loss: 0.1253, step time: 0.4132\n",
      "90/224, train_loss: 0.0974, step time: 0.3168\n",
      "91/224, train_loss: 0.0510, step time: 0.3126\n",
      "92/224, train_loss: 0.0880, step time: 0.3173\n",
      "93/224, train_loss: 0.1427, step time: 0.3174\n",
      "94/224, train_loss: 0.0696, step time: 0.3145\n",
      "95/224, train_loss: 0.1067, step time: 0.3143\n",
      "96/224, train_loss: 0.1218, step time: 0.3988\n",
      "97/224, train_loss: 0.2466, step time: 0.3762\n",
      "98/224, train_loss: 0.0901, step time: 0.3890\n",
      "99/224, train_loss: 0.0990, step time: 0.3746\n",
      "100/224, train_loss: 0.1033, step time: 0.4119\n",
      "101/224, train_loss: 0.1316, step time: 0.3704\n",
      "102/224, train_loss: 0.0889, step time: 0.3153\n",
      "103/224, train_loss: 0.0796, step time: 0.4112\n",
      "104/224, train_loss: 0.1019, step time: 0.3169\n",
      "105/224, train_loss: 0.0920, step time: 0.4029\n",
      "106/224, train_loss: 0.1532, step time: 0.3835\n",
      "107/224, train_loss: 0.0848, step time: 0.3145\n",
      "108/224, train_loss: 0.0781, step time: 0.4050\n",
      "109/224, train_loss: 0.0689, step time: 0.3177\n",
      "110/224, train_loss: 0.1217, step time: 0.3130\n",
      "111/224, train_loss: 0.0532, step time: 0.3146\n",
      "112/224, train_loss: 0.1362, step time: 0.3950\n",
      "113/224, train_loss: 0.0820, step time: 0.4006\n",
      "114/224, train_loss: 0.0916, step time: 0.3180\n",
      "115/224, train_loss: 0.0413, step time: 0.3180\n",
      "116/224, train_loss: 0.0836, step time: 0.3138\n",
      "117/224, train_loss: 0.0812, step time: 0.4005\n",
      "118/224, train_loss: 0.1478, step time: 0.3795\n",
      "119/224, train_loss: 0.1538, step time: 0.3152\n",
      "120/224, train_loss: 0.1194, step time: 0.3162\n",
      "121/224, train_loss: 0.1136, step time: 0.3183\n",
      "122/224, train_loss: 0.1522, step time: 0.4135\n",
      "123/224, train_loss: 0.1923, step time: 0.4036\n",
      "124/224, train_loss: 0.1025, step time: 0.3156\n",
      "125/224, train_loss: 0.1069, step time: 0.3144\n",
      "126/224, train_loss: 0.0898, step time: 0.3726\n",
      "127/224, train_loss: 0.0917, step time: 0.3916\n",
      "128/224, train_loss: 0.1122, step time: 0.3854\n",
      "129/224, train_loss: 0.1642, step time: 0.3745\n",
      "130/224, train_loss: 0.1211, step time: 0.3695\n",
      "131/224, train_loss: 0.0911, step time: 0.3789\n",
      "132/224, train_loss: 0.1308, step time: 0.4052\n",
      "133/224, train_loss: 0.0391, step time: 0.3211\n",
      "134/224, train_loss: 0.1056, step time: 0.3195\n",
      "135/224, train_loss: 0.0770, step time: 0.3191\n",
      "136/224, train_loss: 0.1943, step time: 0.3162\n",
      "137/224, train_loss: 0.1683, step time: 0.4048\n",
      "138/224, train_loss: 0.0862, step time: 0.3171\n",
      "139/224, train_loss: 0.0816, step time: 0.3866\n",
      "140/224, train_loss: 0.3144, step time: 0.4014\n",
      "141/224, train_loss: 0.0898, step time: 0.3777\n",
      "142/224, train_loss: 0.0561, step time: 0.3162\n",
      "143/224, train_loss: 0.0770, step time: 0.3183\n",
      "144/224, train_loss: 0.1142, step time: 0.3152\n",
      "145/224, train_loss: 0.1172, step time: 0.3879\n",
      "146/224, train_loss: 0.0796, step time: 0.3762\n",
      "147/224, train_loss: 0.3774, step time: 0.3769\n",
      "148/224, train_loss: 0.0603, step time: 0.3937\n",
      "149/224, train_loss: 0.1613, step time: 0.4056\n",
      "150/224, train_loss: 0.0634, step time: 0.3153\n",
      "151/224, train_loss: 0.0859, step time: 0.3180\n",
      "152/224, train_loss: 0.0965, step time: 0.3153\n",
      "153/224, train_loss: 0.0751, step time: 0.4056\n",
      "154/224, train_loss: 0.0750, step time: 0.3163\n",
      "155/224, train_loss: 0.0740, step time: 0.3152\n",
      "156/224, train_loss: 0.0964, step time: 0.3153\n",
      "157/224, train_loss: 0.1797, step time: 0.4165\n",
      "158/224, train_loss: 0.1187, step time: 0.3143\n",
      "159/224, train_loss: 0.0794, step time: 0.3178\n",
      "160/224, train_loss: 0.0640, step time: 0.3160\n",
      "161/224, train_loss: 0.0691, step time: 0.3900\n",
      "162/224, train_loss: 0.1277, step time: 0.3164\n",
      "163/224, train_loss: 0.1170, step time: 0.3172\n",
      "164/224, train_loss: 0.0585, step time: 0.3149\n",
      "165/224, train_loss: 0.0809, step time: 0.3920\n",
      "166/224, train_loss: 0.1118, step time: 0.3125\n",
      "167/224, train_loss: 0.0785, step time: 0.3170\n",
      "168/224, train_loss: 0.0563, step time: 0.3921\n",
      "169/224, train_loss: 0.1489, step time: 0.4099\n",
      "170/224, train_loss: 0.0689, step time: 0.3175\n",
      "171/224, train_loss: 0.0928, step time: 0.3131\n",
      "172/224, train_loss: 0.1172, step time: 0.3157\n",
      "173/224, train_loss: 0.1418, step time: 0.3860\n",
      "174/224, train_loss: 0.0907, step time: 0.3858\n",
      "175/224, train_loss: 0.1856, step time: 0.3981\n",
      "176/224, train_loss: 0.0573, step time: 0.3751\n",
      "177/224, train_loss: 0.0748, step time: 0.3172\n",
      "178/224, train_loss: 0.0930, step time: 0.3790\n",
      "179/224, train_loss: 0.2205, step time: 0.3174\n",
      "180/224, train_loss: 0.1158, step time: 0.4074\n",
      "181/224, train_loss: 0.0575, step time: 0.3130\n",
      "182/224, train_loss: 0.0758, step time: 0.3722\n",
      "183/224, train_loss: 0.0889, step time: 0.3142\n",
      "184/224, train_loss: 0.1530, step time: 0.3161\n",
      "185/224, train_loss: 0.0645, step time: 0.3141\n",
      "186/224, train_loss: 0.0772, step time: 0.3165\n",
      "187/224, train_loss: 0.1668, step time: 0.3831\n",
      "188/224, train_loss: 0.3347, step time: 0.3128\n",
      "189/224, train_loss: 0.1468, step time: 0.3837\n",
      "190/224, train_loss: 0.0935, step time: 0.3166\n",
      "191/224, train_loss: 0.0647, step time: 0.3168\n",
      "192/224, train_loss: 0.1190, step time: 0.4043\n",
      "193/224, train_loss: 0.1987, step time: 0.3833\n",
      "194/224, train_loss: 0.1240, step time: 0.3148\n",
      "195/224, train_loss: 0.1172, step time: 0.3175\n",
      "196/224, train_loss: 0.1068, step time: 0.3145\n",
      "197/224, train_loss: 0.0647, step time: 0.3146\n",
      "198/224, train_loss: 0.2183, step time: 0.3805\n",
      "199/224, train_loss: 0.1151, step time: 0.3786\n",
      "200/224, train_loss: 0.0973, step time: 0.3136\n",
      "201/224, train_loss: 0.0526, step time: 0.3148\n",
      "202/224, train_loss: 0.1123, step time: 0.3167\n",
      "203/224, train_loss: 0.0675, step time: 0.3146\n",
      "204/224, train_loss: 0.0935, step time: 0.3166\n",
      "205/224, train_loss: 0.0983, step time: 0.3966\n",
      "206/224, train_loss: 0.2982, step time: 0.3759\n",
      "207/224, train_loss: 0.1900, step time: 0.3180\n",
      "208/224, train_loss: 0.0731, step time: 0.3156\n",
      "209/224, train_loss: 0.0994, step time: 0.3822\n",
      "210/224, train_loss: 0.1031, step time: 0.3734\n",
      "211/224, train_loss: 0.0409, step time: 0.3714\n",
      "212/224, train_loss: 0.1050, step time: 0.3878\n",
      "213/224, train_loss: 0.0525, step time: 0.3160\n",
      "214/224, train_loss: 0.1659, step time: 0.3842\n",
      "215/224, train_loss: 0.0675, step time: 0.3151\n",
      "216/224, train_loss: 0.3158, step time: 0.3846\n",
      "217/224, train_loss: 0.0650, step time: 0.3142\n",
      "218/224, train_loss: 0.1324, step time: 0.3124\n",
      "219/224, train_loss: 0.1529, step time: 0.3918\n",
      "220/224, train_loss: 0.0843, step time: 0.3126\n",
      "221/224, train_loss: 0.0793, step time: 0.4092\n",
      "222/224, train_loss: 0.1090, step time: 0.4104\n",
      "223/224, train_loss: 0.1569, step time: 0.3959\n",
      "224/224, train_loss: 0.1192, step time: 0.4097\n",
      "epoch 85 average loss: 0.1210\n",
      "current epoch: 85 current mean dice: 0.7055 class1: 0.9993 class2: 0.7377 class3: 0.3795\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 85 is: 746.4835\n",
      "hello\n",
      "----------\n",
      "epoch 86/100\n",
      "1/224, train_loss: 0.0907, step time: 0.3140\n",
      "2/224, train_loss: 0.1635, step time: 0.3790\n",
      "3/224, train_loss: 0.1065, step time: 0.3705\n",
      "4/224, train_loss: 0.0841, step time: 0.3761\n",
      "5/224, train_loss: 0.1031, step time: 0.3146\n",
      "6/224, train_loss: 0.1291, step time: 0.3805\n",
      "7/224, train_loss: 0.1869, step time: 0.3880\n",
      "8/224, train_loss: 0.0672, step time: 0.3775\n",
      "9/224, train_loss: 0.1532, step time: 0.4085\n",
      "10/224, train_loss: 0.1070, step time: 0.3154\n",
      "11/224, train_loss: 0.1507, step time: 0.3838\n",
      "12/224, train_loss: 0.0928, step time: 0.3155\n",
      "13/224, train_loss: 0.1106, step time: 0.3174\n",
      "14/224, train_loss: 0.0618, step time: 0.3166\n",
      "15/224, train_loss: 0.0708, step time: 0.3150\n",
      "16/224, train_loss: 0.0754, step time: 0.3130\n",
      "17/224, train_loss: 0.1304, step time: 0.3913\n",
      "18/224, train_loss: 0.0645, step time: 0.3129\n",
      "19/224, train_loss: 0.0922, step time: 0.4031\n",
      "20/224, train_loss: 0.1076, step time: 0.3979\n",
      "21/224, train_loss: 0.0838, step time: 0.3146\n",
      "22/224, train_loss: 0.0927, step time: 0.3693\n",
      "23/224, train_loss: 0.0645, step time: 0.3795\n",
      "24/224, train_loss: 0.1319, step time: 0.4130\n",
      "25/224, train_loss: 0.0948, step time: 0.3160\n",
      "26/224, train_loss: 0.0779, step time: 0.3121\n",
      "27/224, train_loss: 0.0774, step time: 0.3162\n",
      "28/224, train_loss: 0.0507, step time: 0.3153\n",
      "29/224, train_loss: 0.1385, step time: 0.3803\n",
      "30/224, train_loss: 0.1226, step time: 0.3942\n",
      "31/224, train_loss: 0.0366, step time: 0.3872\n",
      "32/224, train_loss: 0.0681, step time: 0.3876\n",
      "33/224, train_loss: 0.0734, step time: 0.3963\n",
      "34/224, train_loss: 0.0848, step time: 0.3148\n",
      "35/224, train_loss: 0.1284, step time: 0.3151\n",
      "36/224, train_loss: 0.1252, step time: 0.3954\n",
      "37/224, train_loss: 0.0546, step time: 0.4031\n",
      "38/224, train_loss: 0.1341, step time: 0.4004\n",
      "39/224, train_loss: 0.0970, step time: 0.3130\n",
      "40/224, train_loss: 0.0962, step time: 0.3150\n",
      "41/224, train_loss: 0.1638, step time: 0.3148\n",
      "42/224, train_loss: 0.0907, step time: 0.3815\n",
      "43/224, train_loss: 0.0940, step time: 0.3166\n",
      "44/224, train_loss: 0.0565, step time: 0.3148\n",
      "45/224, train_loss: 0.1350, step time: 0.3155\n",
      "46/224, train_loss: 0.1075, step time: 0.4080\n",
      "47/224, train_loss: 0.0777, step time: 0.3821\n",
      "48/224, train_loss: 0.0971, step time: 0.3146\n",
      "49/224, train_loss: 0.0528, step time: 0.4032\n",
      "50/224, train_loss: 0.2192, step time: 0.3845\n",
      "51/224, train_loss: 0.0838, step time: 0.3139\n",
      "52/224, train_loss: 0.0754, step time: 0.3140\n",
      "53/224, train_loss: 0.0754, step time: 0.4114\n",
      "54/224, train_loss: 0.1112, step time: 0.3948\n",
      "55/224, train_loss: 0.0702, step time: 0.3153\n",
      "56/224, train_loss: 0.1079, step time: 0.3781\n",
      "57/224, train_loss: 0.1890, step time: 0.3948\n",
      "58/224, train_loss: 0.0573, step time: 0.3789\n",
      "59/224, train_loss: 0.0659, step time: 0.3148\n",
      "60/224, train_loss: 0.0680, step time: 0.3124\n",
      "61/224, train_loss: 0.1314, step time: 0.3693\n",
      "62/224, train_loss: 0.0653, step time: 0.3147\n",
      "63/224, train_loss: 0.0742, step time: 0.3152\n",
      "64/224, train_loss: 0.1313, step time: 0.3151\n",
      "65/224, train_loss: 0.0639, step time: 0.3142\n",
      "66/224, train_loss: 0.1218, step time: 0.3789\n",
      "67/224, train_loss: 0.1506, step time: 0.3119\n",
      "68/224, train_loss: 0.0791, step time: 0.3674\n",
      "69/224, train_loss: 0.0875, step time: 0.3171\n",
      "70/224, train_loss: 0.0979, step time: 0.3164\n",
      "71/224, train_loss: 0.1797, step time: 0.3171\n",
      "72/224, train_loss: 0.1106, step time: 0.3172\n",
      "73/224, train_loss: 0.1448, step time: 0.3769\n",
      "74/224, train_loss: 0.0607, step time: 0.3973\n",
      "75/224, train_loss: 0.0923, step time: 0.3165\n",
      "76/224, train_loss: 0.1771, step time: 0.3976\n",
      "77/224, train_loss: 0.0883, step time: 0.3715\n",
      "78/224, train_loss: 0.2336, step time: 0.3934\n",
      "79/224, train_loss: 0.0849, step time: 0.3133\n",
      "80/224, train_loss: 0.1003, step time: 0.3151\n",
      "81/224, train_loss: 0.2361, step time: 0.3792\n",
      "82/224, train_loss: 0.1434, step time: 0.4026\n",
      "83/224, train_loss: 0.0522, step time: 0.3171\n",
      "84/224, train_loss: 0.2862, step time: 0.3874\n",
      "85/224, train_loss: 0.0550, step time: 0.3147\n",
      "86/224, train_loss: 0.1506, step time: 0.4054\n",
      "87/224, train_loss: 0.0647, step time: 0.3182\n",
      "88/224, train_loss: 0.0863, step time: 0.3845\n",
      "89/224, train_loss: 0.2019, step time: 0.3810\n",
      "90/224, train_loss: 0.0756, step time: 0.3157\n",
      "91/224, train_loss: 0.0737, step time: 0.3863\n",
      "92/224, train_loss: 0.0808, step time: 0.3180\n",
      "93/224, train_loss: 0.3589, step time: 0.4021\n",
      "94/224, train_loss: 0.2141, step time: 0.3853\n",
      "95/224, train_loss: 0.1069, step time: 0.3176\n",
      "96/224, train_loss: 0.1641, step time: 0.4052\n",
      "97/224, train_loss: 0.3598, step time: 0.3841\n",
      "98/224, train_loss: 0.1084, step time: 0.3165\n",
      "99/224, train_loss: 0.0726, step time: 0.3160\n",
      "100/224, train_loss: 0.0880, step time: 0.3171\n",
      "101/224, train_loss: 0.0877, step time: 0.3928\n",
      "102/224, train_loss: 0.0838, step time: 0.3168\n",
      "103/224, train_loss: 0.1103, step time: 0.3166\n",
      "104/224, train_loss: 0.0742, step time: 0.4033\n",
      "105/224, train_loss: 0.0803, step time: 0.3694\n",
      "106/224, train_loss: 0.0878, step time: 0.4161\n",
      "107/224, train_loss: 0.0602, step time: 0.3140\n",
      "108/224, train_loss: 0.0840, step time: 0.3726\n",
      "109/224, train_loss: 0.0784, step time: 0.3727\n",
      "110/224, train_loss: 0.0890, step time: 0.3161\n",
      "111/224, train_loss: 0.0602, step time: 0.3747\n",
      "112/224, train_loss: 0.2992, step time: 0.4060\n",
      "113/224, train_loss: 0.0787, step time: 0.3153\n",
      "114/224, train_loss: 0.1035, step time: 0.3156\n",
      "115/224, train_loss: 0.2275, step time: 0.3162\n",
      "116/224, train_loss: 0.0831, step time: 0.3158\n",
      "117/224, train_loss: 0.0715, step time: 0.3143\n",
      "118/224, train_loss: 0.0835, step time: 0.3181\n",
      "119/224, train_loss: 0.0681, step time: 0.3185\n",
      "120/224, train_loss: 0.0735, step time: 0.3161\n",
      "121/224, train_loss: 0.0760, step time: 0.3157\n",
      "122/224, train_loss: 0.1261, step time: 0.3142\n",
      "123/224, train_loss: 0.1049, step time: 0.3955\n",
      "124/224, train_loss: 0.0743, step time: 0.3984\n",
      "125/224, train_loss: 0.1191, step time: 0.3163\n",
      "126/224, train_loss: 0.2252, step time: 0.4134\n",
      "127/224, train_loss: 0.0832, step time: 0.3715\n",
      "128/224, train_loss: 0.1416, step time: 0.3732\n",
      "129/224, train_loss: 0.1026, step time: 0.3182\n",
      "130/224, train_loss: 0.1377, step time: 0.3158\n",
      "131/224, train_loss: 0.0887, step time: 0.3674\n",
      "132/224, train_loss: 0.0753, step time: 0.3153\n",
      "133/224, train_loss: 0.1296, step time: 0.3152\n",
      "134/224, train_loss: 0.0936, step time: 0.3179\n",
      "135/224, train_loss: 0.0676, step time: 0.3183\n",
      "136/224, train_loss: 0.1306, step time: 0.3759\n",
      "137/224, train_loss: 0.1039, step time: 0.3150\n",
      "138/224, train_loss: 0.0744, step time: 0.3132\n",
      "139/224, train_loss: 0.1376, step time: 0.3157\n",
      "140/224, train_loss: 0.1007, step time: 0.4779\n",
      "141/224, train_loss: 0.1187, step time: 0.3162\n",
      "142/224, train_loss: 0.1318, step time: 0.3158\n",
      "143/224, train_loss: 0.0611, step time: 0.3160\n",
      "144/224, train_loss: 0.2046, step time: 0.3174\n",
      "145/224, train_loss: 0.0801, step time: 0.3155\n",
      "146/224, train_loss: 0.0937, step time: 0.3735\n",
      "147/224, train_loss: 0.2852, step time: 0.4082\n",
      "148/224, train_loss: 0.1192, step time: 0.3855\n",
      "149/224, train_loss: 0.1019, step time: 0.3160\n",
      "150/224, train_loss: 0.2625, step time: 0.3967\n",
      "151/224, train_loss: 0.1285, step time: 0.3158\n",
      "152/224, train_loss: 0.1112, step time: 0.3147\n",
      "153/224, train_loss: 0.2025, step time: 0.3990\n",
      "154/224, train_loss: 0.0578, step time: 0.3706\n",
      "155/224, train_loss: 0.0949, step time: 0.3175\n",
      "156/224, train_loss: 0.1287, step time: 0.4112\n",
      "157/224, train_loss: 0.2503, step time: 0.4019\n",
      "158/224, train_loss: 0.1104, step time: 0.4051\n",
      "159/224, train_loss: 0.1773, step time: 0.3979\n",
      "160/224, train_loss: 0.1483, step time: 0.3770\n",
      "161/224, train_loss: 0.0587, step time: 0.3165\n",
      "162/224, train_loss: 0.1323, step time: 0.3697\n",
      "163/224, train_loss: 0.0674, step time: 0.3174\n",
      "164/224, train_loss: 0.1654, step time: 0.3151\n",
      "165/224, train_loss: 0.0801, step time: 0.3176\n",
      "166/224, train_loss: 0.0880, step time: 0.3133\n",
      "167/224, train_loss: 0.0833, step time: 0.3171\n",
      "168/224, train_loss: 0.1058, step time: 0.3738\n",
      "169/224, train_loss: 0.1133, step time: 0.3874\n",
      "170/224, train_loss: 0.1230, step time: 0.3154\n",
      "171/224, train_loss: 0.2978, step time: 0.3783\n",
      "172/224, train_loss: 0.0993, step time: 0.3162\n",
      "173/224, train_loss: 0.0705, step time: 0.3131\n",
      "174/224, train_loss: 0.0544, step time: 0.3775\n",
      "175/224, train_loss: 0.0698, step time: 0.3152\n",
      "176/224, train_loss: 0.0988, step time: 0.3755\n",
      "177/224, train_loss: 0.0862, step time: 0.4099\n",
      "178/224, train_loss: 0.0748, step time: 0.3142\n",
      "179/224, train_loss: 0.1036, step time: 0.4098\n",
      "180/224, train_loss: 0.0858, step time: 0.3835\n",
      "181/224, train_loss: 0.0908, step time: 0.3909\n",
      "182/224, train_loss: 0.1010, step time: 0.3157\n",
      "183/224, train_loss: 0.1166, step time: 0.3145\n",
      "184/224, train_loss: 0.2130, step time: 0.4050\n",
      "185/224, train_loss: 0.1599, step time: 0.3765\n",
      "186/224, train_loss: 0.1265, step time: 0.3872\n",
      "187/224, train_loss: 0.1146, step time: 0.3150\n",
      "188/224, train_loss: 0.1400, step time: 0.3173\n",
      "189/224, train_loss: 0.1005, step time: 0.3720\n",
      "190/224, train_loss: 0.0589, step time: 0.3726\n",
      "191/224, train_loss: 0.0751, step time: 0.3801\n",
      "192/224, train_loss: 0.0858, step time: 0.3791\n",
      "193/224, train_loss: 0.1130, step time: 0.3883\n",
      "194/224, train_loss: 0.2899, step time: 0.3814\n",
      "195/224, train_loss: 0.1581, step time: 0.3731\n",
      "196/224, train_loss: 0.0934, step time: 0.4081\n",
      "197/224, train_loss: 0.0627, step time: 0.3131\n",
      "198/224, train_loss: 0.2983, step time: 0.4007\n",
      "199/224, train_loss: 0.1301, step time: 0.3999\n",
      "200/224, train_loss: 0.1369, step time: 0.4111\n",
      "201/224, train_loss: 0.1132, step time: 0.3150\n",
      "202/224, train_loss: 0.0701, step time: 0.3171\n",
      "203/224, train_loss: 0.0946, step time: 0.3132\n",
      "204/224, train_loss: 0.0712, step time: 0.3144\n",
      "205/224, train_loss: 0.0575, step time: 0.3120\n",
      "206/224, train_loss: 0.1030, step time: 0.3139\n",
      "207/224, train_loss: 0.0878, step time: 0.4002\n",
      "208/224, train_loss: 0.0953, step time: 0.3145\n",
      "209/224, train_loss: 0.2027, step time: 0.3895\n",
      "210/224, train_loss: 0.1108, step time: 0.3150\n",
      "211/224, train_loss: 0.0684, step time: 0.3155\n",
      "212/224, train_loss: 0.0772, step time: 0.4117\n",
      "213/224, train_loss: 0.1236, step time: 0.3174\n",
      "214/224, train_loss: 0.0638, step time: 0.3168\n",
      "215/224, train_loss: 0.0887, step time: 0.3141\n",
      "216/224, train_loss: 0.0432, step time: 0.3179\n",
      "217/224, train_loss: 0.1021, step time: 0.3175\n",
      "218/224, train_loss: 0.1215, step time: 0.3171\n",
      "219/224, train_loss: 0.0602, step time: 0.3122\n",
      "220/224, train_loss: 0.0647, step time: 0.3833\n",
      "221/224, train_loss: 0.0685, step time: 0.3148\n",
      "222/224, train_loss: 0.3384, step time: 0.4101\n",
      "223/224, train_loss: 0.1047, step time: 0.4011\n",
      "224/224, train_loss: 0.0530, step time: 0.3774\n",
      "epoch 86 average loss: 0.1133\n",
      "current epoch: 86 current mean dice: 0.7073 class1: 0.9993 class2: 0.7369 class3: 0.3857\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 86 is: 704.5746\n",
      "hello\n",
      "----------\n",
      "epoch 87/100\n",
      "1/224, train_loss: 0.0713, step time: 0.3174\n",
      "2/224, train_loss: 0.0619, step time: 0.3925\n",
      "3/224, train_loss: 0.1818, step time: 0.3142\n",
      "4/224, train_loss: 0.0895, step time: 0.3849\n",
      "5/224, train_loss: 0.1028, step time: 0.3126\n",
      "6/224, train_loss: 0.0922, step time: 0.3167\n",
      "7/224, train_loss: 0.0877, step time: 0.3855\n",
      "8/224, train_loss: 0.0873, step time: 0.3173\n",
      "9/224, train_loss: 0.0968, step time: 0.3123\n",
      "10/224, train_loss: 0.0603, step time: 0.3142\n",
      "11/224, train_loss: 0.0763, step time: 0.3751\n",
      "12/224, train_loss: 0.1161, step time: 0.3134\n",
      "13/224, train_loss: 0.1270, step time: 0.3131\n",
      "14/224, train_loss: 0.0707, step time: 0.3167\n",
      "15/224, train_loss: 0.0724, step time: 0.3147\n",
      "16/224, train_loss: 0.0740, step time: 0.3173\n",
      "17/224, train_loss: 0.0736, step time: 0.3176\n",
      "18/224, train_loss: 0.1218, step time: 0.3769\n",
      "19/224, train_loss: 0.0599, step time: 0.3993\n",
      "20/224, train_loss: 0.2126, step time: 0.4055\n",
      "21/224, train_loss: 0.1120, step time: 0.4114\n",
      "22/224, train_loss: 0.0512, step time: 0.3144\n",
      "23/224, train_loss: 0.3296, step time: 0.3641\n",
      "24/224, train_loss: 0.2136, step time: 0.3675\n",
      "25/224, train_loss: 0.0429, step time: 0.3144\n",
      "26/224, train_loss: 0.1848, step time: 0.4106\n",
      "27/224, train_loss: 0.3133, step time: 0.3760\n",
      "28/224, train_loss: 0.1286, step time: 0.3693\n",
      "29/224, train_loss: 0.0469, step time: 0.3143\n",
      "30/224, train_loss: 0.1125, step time: 0.4012\n",
      "31/224, train_loss: 0.3806, step time: 0.3969\n",
      "32/224, train_loss: 0.1123, step time: 0.3145\n",
      "33/224, train_loss: 0.0577, step time: 0.3987\n",
      "34/224, train_loss: 0.0924, step time: 0.3147\n",
      "35/224, train_loss: 0.0438, step time: 0.3123\n",
      "36/224, train_loss: 0.0841, step time: 0.3123\n",
      "37/224, train_loss: 0.1181, step time: 0.3809\n",
      "38/224, train_loss: 0.0933, step time: 0.4067\n",
      "39/224, train_loss: 0.1238, step time: 0.3862\n",
      "40/224, train_loss: 0.1047, step time: 0.3130\n",
      "41/224, train_loss: 0.0995, step time: 0.3981\n",
      "42/224, train_loss: 0.0977, step time: 0.3141\n",
      "43/224, train_loss: 0.3265, step time: 0.3857\n",
      "44/224, train_loss: 0.0777, step time: 0.3722\n",
      "45/224, train_loss: 0.0617, step time: 0.3147\n",
      "46/224, train_loss: 0.0722, step time: 0.3141\n",
      "47/224, train_loss: 0.1024, step time: 0.3147\n",
      "48/224, train_loss: 0.0956, step time: 0.3174\n",
      "49/224, train_loss: 0.1554, step time: 0.3147\n",
      "50/224, train_loss: 0.0836, step time: 0.4034\n",
      "51/224, train_loss: 0.1843, step time: 0.3766\n",
      "52/224, train_loss: 0.0772, step time: 0.3128\n",
      "53/224, train_loss: 0.0666, step time: 0.3175\n",
      "54/224, train_loss: 0.1227, step time: 0.3164\n",
      "55/224, train_loss: 0.0916, step time: 0.3167\n",
      "56/224, train_loss: 0.1199, step time: 0.3981\n",
      "57/224, train_loss: 0.0739, step time: 0.3144\n",
      "58/224, train_loss: 0.1583, step time: 0.3956\n",
      "59/224, train_loss: 0.0799, step time: 0.3170\n",
      "60/224, train_loss: 0.0813, step time: 0.3829\n",
      "61/224, train_loss: 0.1765, step time: 0.3924\n",
      "62/224, train_loss: 0.0877, step time: 0.4000\n",
      "63/224, train_loss: 0.0889, step time: 0.3931\n",
      "64/224, train_loss: 0.1057, step time: 0.3149\n",
      "65/224, train_loss: 0.1042, step time: 0.3144\n",
      "66/224, train_loss: 0.2352, step time: 0.4033\n",
      "67/224, train_loss: 0.0767, step time: 0.3862\n",
      "68/224, train_loss: 0.0974, step time: 0.3862\n",
      "69/224, train_loss: 0.3217, step time: 0.3975\n",
      "70/224, train_loss: 0.0612, step time: 0.3695\n",
      "71/224, train_loss: 0.1255, step time: 0.3929\n",
      "72/224, train_loss: 0.0578, step time: 0.3785\n",
      "73/224, train_loss: 0.0414, step time: 0.3145\n",
      "74/224, train_loss: 0.1793, step time: 0.3949\n",
      "75/224, train_loss: 0.0604, step time: 0.3177\n",
      "76/224, train_loss: 0.2181, step time: 0.3674\n",
      "77/224, train_loss: 0.0904, step time: 0.3660\n",
      "78/224, train_loss: 0.0993, step time: 0.3176\n",
      "79/224, train_loss: 0.0949, step time: 0.3158\n",
      "80/224, train_loss: 0.0864, step time: 0.3173\n",
      "81/224, train_loss: 0.0674, step time: 0.3158\n",
      "82/224, train_loss: 0.2291, step time: 0.3931\n",
      "83/224, train_loss: 0.0649, step time: 0.3144\n",
      "84/224, train_loss: 0.0697, step time: 0.3750\n",
      "85/224, train_loss: 0.0544, step time: 0.3124\n",
      "86/224, train_loss: 0.1660, step time: 0.3707\n",
      "87/224, train_loss: 0.0958, step time: 0.3155\n",
      "88/224, train_loss: 0.0567, step time: 0.3150\n",
      "89/224, train_loss: 0.1219, step time: 0.3667\n",
      "90/224, train_loss: 0.0841, step time: 0.3124\n",
      "91/224, train_loss: 0.0951, step time: 0.3688\n",
      "92/224, train_loss: 0.0665, step time: 0.3758\n",
      "93/224, train_loss: 0.1361, step time: 0.3905\n",
      "94/224, train_loss: 0.0445, step time: 0.3155\n",
      "95/224, train_loss: 0.1212, step time: 0.3143\n",
      "96/224, train_loss: 0.0877, step time: 0.3144\n",
      "97/224, train_loss: 0.1159, step time: 0.3128\n",
      "98/224, train_loss: 0.0761, step time: 0.3153\n",
      "99/224, train_loss: 0.0917, step time: 0.3123\n",
      "100/224, train_loss: 0.1800, step time: 0.3713\n",
      "101/224, train_loss: 0.2308, step time: 0.3874\n",
      "102/224, train_loss: 0.0759, step time: 0.3815\n",
      "103/224, train_loss: 0.0444, step time: 0.3141\n",
      "104/224, train_loss: 0.1058, step time: 0.4011\n",
      "105/224, train_loss: 0.0829, step time: 0.3127\n",
      "106/224, train_loss: 0.0723, step time: 0.3144\n",
      "107/224, train_loss: 0.1164, step time: 0.3727\n",
      "108/224, train_loss: 0.0846, step time: 0.3145\n",
      "109/224, train_loss: 0.2510, step time: 0.3791\n",
      "110/224, train_loss: 0.1109, step time: 0.3148\n",
      "111/224, train_loss: 0.0611, step time: 0.3141\n",
      "112/224, train_loss: 0.0525, step time: 0.3142\n",
      "113/224, train_loss: 0.1000, step time: 0.3124\n",
      "114/224, train_loss: 0.1069, step time: 0.3174\n",
      "115/224, train_loss: 0.1839, step time: 0.3960\n",
      "116/224, train_loss: 0.1078, step time: 0.3171\n",
      "117/224, train_loss: 0.1852, step time: 0.3764\n",
      "118/224, train_loss: 0.0742, step time: 0.3729\n",
      "119/224, train_loss: 0.0945, step time: 0.3168\n",
      "120/224, train_loss: 0.1114, step time: 0.3143\n",
      "121/224, train_loss: 0.0847, step time: 0.4019\n",
      "122/224, train_loss: 0.0936, step time: 0.3144\n",
      "123/224, train_loss: 0.1379, step time: 0.3166\n",
      "124/224, train_loss: 0.2040, step time: 0.4122\n",
      "125/224, train_loss: 0.1016, step time: 0.3657\n",
      "126/224, train_loss: 0.1194, step time: 0.3147\n",
      "127/224, train_loss: 0.0544, step time: 0.3850\n",
      "128/224, train_loss: 0.0969, step time: 0.3157\n",
      "129/224, train_loss: 0.3359, step time: 0.4001\n",
      "130/224, train_loss: 0.0546, step time: 0.4084\n",
      "131/224, train_loss: 0.1701, step time: 0.3967\n",
      "132/224, train_loss: 0.1219, step time: 0.3150\n",
      "133/224, train_loss: 0.0582, step time: 0.3146\n",
      "134/224, train_loss: 0.0709, step time: 0.3144\n",
      "135/224, train_loss: 0.1023, step time: 0.3143\n",
      "136/224, train_loss: 0.2872, step time: 0.3760\n",
      "137/224, train_loss: 0.0789, step time: 0.3143\n",
      "138/224, train_loss: 0.1739, step time: 0.3755\n",
      "139/224, train_loss: 0.3360, step time: 0.3722\n",
      "140/224, train_loss: 0.1555, step time: 0.3178\n",
      "141/224, train_loss: 0.0816, step time: 0.3145\n",
      "142/224, train_loss: 0.0700, step time: 0.3140\n",
      "143/224, train_loss: 0.1072, step time: 0.3140\n",
      "144/224, train_loss: 0.0729, step time: 0.3148\n",
      "145/224, train_loss: 0.0666, step time: 0.3154\n",
      "146/224, train_loss: 0.0783, step time: 0.3148\n",
      "147/224, train_loss: 0.0857, step time: 0.3781\n",
      "148/224, train_loss: 0.0992, step time: 0.3140\n",
      "149/224, train_loss: 0.0799, step time: 0.3126\n",
      "150/224, train_loss: 0.0840, step time: 0.3165\n",
      "151/224, train_loss: 0.1019, step time: 0.3142\n",
      "152/224, train_loss: 0.1247, step time: 0.3169\n",
      "153/224, train_loss: 0.0892, step time: 0.3135\n",
      "154/224, train_loss: 0.0635, step time: 0.3146\n",
      "155/224, train_loss: 0.0667, step time: 0.3166\n",
      "156/224, train_loss: 0.0765, step time: 0.3140\n",
      "157/224, train_loss: 0.0652, step time: 0.3139\n",
      "158/224, train_loss: 0.0659, step time: 0.3138\n",
      "159/224, train_loss: 0.1522, step time: 0.4026\n",
      "160/224, train_loss: 0.0935, step time: 0.3119\n",
      "161/224, train_loss: 0.1317, step time: 0.3703\n",
      "162/224, train_loss: 0.0839, step time: 0.3130\n",
      "163/224, train_loss: 0.0956, step time: 0.3753\n",
      "164/224, train_loss: 0.1303, step time: 0.3881\n",
      "165/224, train_loss: 0.1416, step time: 0.3142\n",
      "166/224, train_loss: 0.0985, step time: 0.3165\n",
      "167/224, train_loss: 0.2016, step time: 0.3140\n",
      "168/224, train_loss: 0.0737, step time: 0.4077\n",
      "169/224, train_loss: 0.1453, step time: 0.3895\n",
      "170/224, train_loss: 0.1200, step time: 0.3724\n",
      "171/224, train_loss: 0.3511, step time: 0.3818\n",
      "172/224, train_loss: 0.1198, step time: 0.3151\n",
      "173/224, train_loss: 0.0723, step time: 0.3153\n",
      "174/224, train_loss: 0.0942, step time: 0.3150\n",
      "175/224, train_loss: 0.1334, step time: 0.4012\n",
      "176/224, train_loss: 0.4185, step time: 0.3700\n",
      "177/224, train_loss: 0.2444, step time: 0.3928\n",
      "178/224, train_loss: 0.1225, step time: 0.4057\n",
      "179/224, train_loss: 0.1307, step time: 0.4004\n",
      "180/224, train_loss: 0.1940, step time: 0.3789\n",
      "181/224, train_loss: 0.1050, step time: 0.3147\n",
      "182/224, train_loss: 0.2500, step time: 0.4126\n",
      "183/224, train_loss: 0.2073, step time: 0.3881\n",
      "184/224, train_loss: 0.1017, step time: 0.3132\n",
      "185/224, train_loss: 0.1141, step time: 0.3158\n",
      "186/224, train_loss: 0.0999, step time: 0.3135\n",
      "187/224, train_loss: 0.0898, step time: 0.3148\n",
      "188/224, train_loss: 0.1012, step time: 0.3142\n",
      "189/224, train_loss: 0.0923, step time: 0.3953\n",
      "190/224, train_loss: 0.0754, step time: 0.3132\n",
      "191/224, train_loss: 0.1074, step time: 0.4105\n",
      "192/224, train_loss: 0.0672, step time: 0.3171\n",
      "193/224, train_loss: 0.0672, step time: 0.3173\n",
      "194/224, train_loss: 0.1897, step time: 0.3679\n",
      "195/224, train_loss: 0.0699, step time: 0.4106\n",
      "196/224, train_loss: 0.1243, step time: 0.3147\n",
      "197/224, train_loss: 0.0989, step time: 0.3143\n",
      "198/224, train_loss: 0.1077, step time: 0.3845\n",
      "199/224, train_loss: 0.2182, step time: 0.3835\n",
      "200/224, train_loss: 0.1204, step time: 0.3816\n",
      "201/224, train_loss: 0.0667, step time: 0.3157\n",
      "202/224, train_loss: 0.0706, step time: 0.3170\n",
      "203/224, train_loss: 0.0745, step time: 0.3146\n",
      "204/224, train_loss: 0.0646, step time: 0.3124\n",
      "205/224, train_loss: 0.0804, step time: 0.3171\n",
      "206/224, train_loss: 0.3016, step time: 0.3796\n",
      "207/224, train_loss: 0.0502, step time: 0.3173\n",
      "208/224, train_loss: 0.1188, step time: 0.3172\n",
      "209/224, train_loss: 0.0739, step time: 0.3153\n",
      "210/224, train_loss: 0.1405, step time: 0.3185\n",
      "211/224, train_loss: 0.1184, step time: 0.4007\n",
      "212/224, train_loss: 0.1159, step time: 0.3158\n",
      "213/224, train_loss: 0.0843, step time: 0.3731\n",
      "214/224, train_loss: 0.1013, step time: 0.3175\n",
      "215/224, train_loss: 0.1082, step time: 0.3153\n",
      "216/224, train_loss: 0.1754, step time: 0.3799\n",
      "217/224, train_loss: 0.0719, step time: 0.3151\n",
      "218/224, train_loss: 0.0924, step time: 0.3133\n",
      "219/224, train_loss: 0.0385, step time: 0.3173\n",
      "220/224, train_loss: 0.0712, step time: 0.3143\n",
      "221/224, train_loss: 0.1852, step time: 0.3791\n",
      "222/224, train_loss: 0.1177, step time: 0.3880\n",
      "223/224, train_loss: 0.1079, step time: 0.3125\n",
      "224/224, train_loss: 0.1678, step time: 0.4069\n",
      "epoch 87 average loss: 0.1173\n",
      "current epoch: 87 current mean dice: 0.7021 class1: 0.9993 class2: 0.7043 class3: 0.4027\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 87 is: 645.3898\n",
      "hello\n",
      "----------\n",
      "epoch 88/100\n",
      "1/224, train_loss: 0.0762, step time: 0.4024\n",
      "2/224, train_loss: 0.1136, step time: 0.3741\n",
      "3/224, train_loss: 0.0924, step time: 0.3143\n",
      "4/224, train_loss: 0.0868, step time: 0.3175\n",
      "5/224, train_loss: 0.1215, step time: 0.3131\n",
      "6/224, train_loss: 0.1079, step time: 0.3126\n",
      "7/224, train_loss: 0.0876, step time: 0.3166\n",
      "8/224, train_loss: 0.1700, step time: 0.4099\n",
      "9/224, train_loss: 0.1239, step time: 0.3873\n",
      "10/224, train_loss: 0.0759, step time: 0.3126\n",
      "11/224, train_loss: 0.0607, step time: 0.3152\n",
      "12/224, train_loss: 0.0918, step time: 0.3736\n",
      "13/224, train_loss: 0.0970, step time: 0.4083\n",
      "14/224, train_loss: 0.1176, step time: 0.3901\n",
      "15/224, train_loss: 0.0768, step time: 0.3150\n",
      "16/224, train_loss: 0.0903, step time: 0.3154\n",
      "17/224, train_loss: 0.0911, step time: 0.3129\n",
      "18/224, train_loss: 0.1716, step time: 0.4104\n",
      "19/224, train_loss: 0.0681, step time: 0.3179\n",
      "20/224, train_loss: 0.2107, step time: 0.3181\n",
      "21/224, train_loss: 0.1161, step time: 0.4003\n",
      "22/224, train_loss: 0.1725, step time: 0.3828\n",
      "23/224, train_loss: 0.2276, step time: 0.4009\n",
      "24/224, train_loss: 0.0572, step time: 0.4003\n",
      "25/224, train_loss: 0.0944, step time: 0.3166\n",
      "26/224, train_loss: 0.0513, step time: 0.3991\n",
      "27/224, train_loss: 0.1043, step time: 0.3168\n",
      "28/224, train_loss: 0.0602, step time: 0.3812\n",
      "29/224, train_loss: 0.1099, step time: 0.3926\n",
      "30/224, train_loss: 0.1502, step time: 0.3184\n",
      "31/224, train_loss: 0.1220, step time: 0.3886\n",
      "32/224, train_loss: 0.1750, step time: 0.4093\n",
      "33/224, train_loss: 0.1644, step time: 0.3766\n",
      "34/224, train_loss: 0.2166, step time: 0.3851\n",
      "35/224, train_loss: 0.1151, step time: 0.3123\n",
      "36/224, train_loss: 0.0789, step time: 0.3145\n",
      "37/224, train_loss: 0.0921, step time: 0.3694\n",
      "38/224, train_loss: 0.1054, step time: 0.3717\n",
      "39/224, train_loss: 0.0951, step time: 0.3150\n",
      "40/224, train_loss: 0.1865, step time: 0.3125\n",
      "41/224, train_loss: 0.1061, step time: 0.4087\n",
      "42/224, train_loss: 0.1412, step time: 0.3699\n",
      "43/224, train_loss: 0.2946, step time: 0.3913\n",
      "44/224, train_loss: 0.1239, step time: 0.3153\n",
      "45/224, train_loss: 0.1095, step time: 0.3177\n",
      "46/224, train_loss: 0.0994, step time: 0.4024\n",
      "47/224, train_loss: 0.0836, step time: 0.3144\n",
      "48/224, train_loss: 0.1685, step time: 0.3971\n",
      "49/224, train_loss: 0.2940, step time: 0.3796\n",
      "50/224, train_loss: 0.0828, step time: 0.3981\n",
      "51/224, train_loss: 0.0988, step time: 0.3145\n",
      "52/224, train_loss: 0.0940, step time: 0.3930\n",
      "53/224, train_loss: 0.2237, step time: 0.3652\n",
      "54/224, train_loss: 0.0926, step time: 0.3151\n",
      "55/224, train_loss: 0.0743, step time: 0.3176\n",
      "56/224, train_loss: 0.1140, step time: 0.3142\n",
      "57/224, train_loss: 0.1661, step time: 0.3769\n",
      "58/224, train_loss: 0.2598, step time: 0.3952\n",
      "59/224, train_loss: 0.1661, step time: 0.3975\n",
      "60/224, train_loss: 0.0858, step time: 0.3988\n",
      "61/224, train_loss: 0.0502, step time: 0.3840\n",
      "62/224, train_loss: 0.0451, step time: 0.3748\n",
      "63/224, train_loss: 0.1199, step time: 0.3681\n",
      "64/224, train_loss: 0.1502, step time: 0.3947\n",
      "65/224, train_loss: 0.0836, step time: 0.3125\n",
      "66/224, train_loss: 0.1349, step time: 0.3715\n",
      "67/224, train_loss: 0.0708, step time: 0.3152\n",
      "68/224, train_loss: 0.1117, step time: 0.3910\n",
      "69/224, train_loss: 0.0641, step time: 0.3154\n",
      "70/224, train_loss: 0.3940, step time: 0.3179\n",
      "71/224, train_loss: 0.0934, step time: 0.3171\n",
      "72/224, train_loss: 0.0760, step time: 0.3142\n",
      "73/224, train_loss: 0.2046, step time: 0.3942\n",
      "74/224, train_loss: 0.0952, step time: 0.3813\n",
      "75/224, train_loss: 0.0639, step time: 0.3888\n",
      "76/224, train_loss: 0.0832, step time: 0.3962\n",
      "77/224, train_loss: 0.3795, step time: 0.3667\n",
      "78/224, train_loss: 0.0745, step time: 0.3128\n",
      "79/224, train_loss: 0.0722, step time: 0.3964\n",
      "80/224, train_loss: 0.1059, step time: 0.3876\n",
      "81/224, train_loss: 0.2521, step time: 0.3791\n",
      "82/224, train_loss: 0.3260, step time: 0.3981\n",
      "83/224, train_loss: 0.1646, step time: 0.3709\n",
      "84/224, train_loss: 0.0986, step time: 0.3706\n",
      "85/224, train_loss: 0.1002, step time: 0.3888\n",
      "86/224, train_loss: 0.2047, step time: 0.3827\n",
      "87/224, train_loss: 0.0477, step time: 0.3147\n",
      "88/224, train_loss: 0.0922, step time: 0.3176\n",
      "89/224, train_loss: 0.0814, step time: 0.3150\n",
      "90/224, train_loss: 0.2138, step time: 0.3864\n",
      "91/224, train_loss: 0.1546, step time: 0.3768\n",
      "92/224, train_loss: 0.1181, step time: 0.3911\n",
      "93/224, train_loss: 0.1597, step time: 0.3179\n",
      "94/224, train_loss: 0.2346, step time: 0.3980\n",
      "95/224, train_loss: 0.0536, step time: 0.3883\n",
      "96/224, train_loss: 0.0726, step time: 0.3149\n",
      "97/224, train_loss: 0.1395, step time: 0.3765\n",
      "98/224, train_loss: 0.0877, step time: 0.3149\n",
      "99/224, train_loss: 0.0743, step time: 0.4097\n",
      "100/224, train_loss: 0.1238, step time: 0.3699\n",
      "101/224, train_loss: 0.0777, step time: 0.3941\n",
      "102/224, train_loss: 0.1059, step time: 0.3122\n",
      "103/224, train_loss: 0.0585, step time: 0.3168\n",
      "104/224, train_loss: 0.1876, step time: 0.3688\n",
      "105/224, train_loss: 0.2145, step time: 0.3177\n",
      "106/224, train_loss: 0.1488, step time: 0.3686\n",
      "107/224, train_loss: 0.0946, step time: 0.3147\n",
      "108/224, train_loss: 0.0848, step time: 0.3174\n",
      "109/224, train_loss: 0.0781, step time: 0.3174\n",
      "110/224, train_loss: 0.3787, step time: 0.3982\n",
      "111/224, train_loss: 0.0545, step time: 0.3173\n",
      "112/224, train_loss: 0.1042, step time: 0.4071\n",
      "113/224, train_loss: 0.0746, step time: 0.3159\n",
      "114/224, train_loss: 0.1263, step time: 0.4088\n",
      "115/224, train_loss: 0.0863, step time: 0.3171\n",
      "116/224, train_loss: 0.1988, step time: 0.3815\n",
      "117/224, train_loss: 0.0963, step time: 0.3152\n",
      "118/224, train_loss: 0.0451, step time: 0.3147\n",
      "119/224, train_loss: 0.0569, step time: 0.3799\n",
      "120/224, train_loss: 0.1921, step time: 0.3909\n",
      "121/224, train_loss: 0.0906, step time: 0.3802\n",
      "122/224, train_loss: 0.0671, step time: 0.3192\n",
      "123/224, train_loss: 0.0741, step time: 0.3187\n",
      "124/224, train_loss: 0.2492, step time: 0.4142\n",
      "125/224, train_loss: 0.0895, step time: 0.3184\n",
      "126/224, train_loss: 0.0907, step time: 0.3173\n",
      "127/224, train_loss: 0.1021, step time: 0.3745\n",
      "128/224, train_loss: 0.1116, step time: 0.4089\n",
      "129/224, train_loss: 0.0722, step time: 0.3175\n",
      "130/224, train_loss: 0.2277, step time: 0.3675\n",
      "131/224, train_loss: 0.4158, step time: 0.3745\n",
      "132/224, train_loss: 0.1333, step time: 0.3657\n",
      "133/224, train_loss: 0.2650, step time: 0.4073\n",
      "134/224, train_loss: 0.2476, step time: 0.3144\n",
      "135/224, train_loss: 0.1668, step time: 0.3904\n",
      "136/224, train_loss: 0.0552, step time: 0.3156\n",
      "137/224, train_loss: 0.1480, step time: 0.3755\n",
      "138/224, train_loss: 0.0830, step time: 0.4104\n",
      "139/224, train_loss: 0.1063, step time: 0.3157\n",
      "140/224, train_loss: 0.0719, step time: 0.3171\n",
      "141/224, train_loss: 0.1168, step time: 0.3873\n",
      "142/224, train_loss: 0.0992, step time: 0.3171\n",
      "143/224, train_loss: 0.0471, step time: 0.3757\n",
      "144/224, train_loss: 0.1462, step time: 0.3908\n",
      "145/224, train_loss: 0.0933, step time: 0.3152\n",
      "146/224, train_loss: 0.0894, step time: 0.3980\n",
      "147/224, train_loss: 0.0975, step time: 0.3132\n",
      "148/224, train_loss: 0.0871, step time: 0.3148\n",
      "149/224, train_loss: 0.1077, step time: 0.3127\n",
      "150/224, train_loss: 0.1371, step time: 0.3936\n",
      "151/224, train_loss: 0.1132, step time: 0.3200\n",
      "152/224, train_loss: 0.0648, step time: 0.3939\n",
      "153/224, train_loss: 0.0572, step time: 0.3154\n",
      "154/224, train_loss: 0.0684, step time: 0.3149\n",
      "155/224, train_loss: 0.1341, step time: 0.3757\n",
      "156/224, train_loss: 0.0567, step time: 0.3998\n",
      "157/224, train_loss: 0.0666, step time: 0.3156\n",
      "158/224, train_loss: 0.0808, step time: 0.3130\n",
      "159/224, train_loss: 0.2210, step time: 0.3171\n",
      "160/224, train_loss: 0.0832, step time: 0.3130\n",
      "161/224, train_loss: 0.0613, step time: 0.3129\n",
      "162/224, train_loss: 0.1251, step time: 0.3151\n",
      "163/224, train_loss: 0.0851, step time: 0.4111\n",
      "164/224, train_loss: 0.1138, step time: 0.4103\n",
      "165/224, train_loss: 0.0658, step time: 0.4036\n",
      "166/224, train_loss: 0.0743, step time: 0.3158\n",
      "167/224, train_loss: 0.0650, step time: 0.3721\n",
      "168/224, train_loss: 0.2674, step time: 0.3749\n",
      "169/224, train_loss: 0.1098, step time: 0.3777\n",
      "170/224, train_loss: 0.1382, step time: 0.3855\n",
      "171/224, train_loss: 0.1235, step time: 0.4055\n",
      "172/224, train_loss: 0.0621, step time: 0.3144\n",
      "173/224, train_loss: 0.0968, step time: 0.3153\n",
      "174/224, train_loss: 0.0835, step time: 0.3172\n",
      "175/224, train_loss: 0.2696, step time: 0.3806\n",
      "176/224, train_loss: 0.3432, step time: 0.3149\n",
      "177/224, train_loss: 0.1006, step time: 0.3144\n",
      "178/224, train_loss: 0.1119, step time: 0.4077\n",
      "179/224, train_loss: 0.0664, step time: 0.3132\n",
      "180/224, train_loss: 0.0870, step time: 0.3125\n",
      "181/224, train_loss: 0.0900, step time: 0.3168\n",
      "182/224, train_loss: 0.0607, step time: 0.3800\n",
      "183/224, train_loss: 0.1638, step time: 0.3942\n",
      "184/224, train_loss: 0.0823, step time: 0.3186\n",
      "185/224, train_loss: 0.0985, step time: 0.4031\n",
      "186/224, train_loss: 0.1801, step time: 0.3786\n",
      "187/224, train_loss: 0.0855, step time: 0.3716\n",
      "188/224, train_loss: 0.1018, step time: 0.4080\n",
      "189/224, train_loss: 0.0954, step time: 0.4079\n",
      "190/224, train_loss: 0.1246, step time: 0.3779\n",
      "191/224, train_loss: 0.1790, step time: 0.4033\n",
      "192/224, train_loss: 0.1309, step time: 0.3809\n",
      "193/224, train_loss: 0.0951, step time: 0.3140\n",
      "194/224, train_loss: 0.0501, step time: 0.3135\n",
      "195/224, train_loss: 0.2658, step time: 0.3159\n",
      "196/224, train_loss: 0.3247, step time: 0.3827\n",
      "197/224, train_loss: 0.1179, step time: 0.3882\n",
      "198/224, train_loss: 0.0992, step time: 0.3729\n",
      "199/224, train_loss: 0.1029, step time: 0.3190\n",
      "200/224, train_loss: 0.0834, step time: 0.3696\n",
      "201/224, train_loss: 0.0558, step time: 0.3161\n",
      "202/224, train_loss: 0.2012, step time: 0.3766\n",
      "203/224, train_loss: 0.1086, step time: 0.3190\n",
      "204/224, train_loss: 0.1329, step time: 0.3162\n",
      "205/224, train_loss: 0.0805, step time: 0.3140\n",
      "206/224, train_loss: 0.0992, step time: 0.4092\n",
      "207/224, train_loss: 0.2751, step time: 0.4087\n",
      "208/224, train_loss: 0.0810, step time: 0.3186\n",
      "209/224, train_loss: 0.0821, step time: 0.3159\n",
      "210/224, train_loss: 0.0910, step time: 0.3160\n",
      "211/224, train_loss: 0.1666, step time: 0.3747\n",
      "212/224, train_loss: 0.0870, step time: 0.3745\n",
      "213/224, train_loss: 0.1465, step time: 0.3187\n",
      "214/224, train_loss: 0.1267, step time: 0.3682\n",
      "215/224, train_loss: 0.2721, step time: 0.3741\n",
      "216/224, train_loss: 0.1345, step time: 0.4114\n",
      "217/224, train_loss: 0.1253, step time: 0.3791\n",
      "218/224, train_loss: 0.2742, step time: 0.3851\n",
      "219/224, train_loss: 0.1370, step time: 0.3188\n",
      "220/224, train_loss: 0.1083, step time: 0.4148\n",
      "221/224, train_loss: 0.0594, step time: 0.3168\n",
      "222/224, train_loss: 0.0942, step time: 0.3171\n",
      "223/224, train_loss: 0.0763, step time: 0.3193\n",
      "224/224, train_loss: 0.0901, step time: 0.3747\n",
      "epoch 88 average loss: 0.1257\n",
      "current epoch: 88 current mean dice: 0.7068 class1: 0.9994 class2: 0.7385 class3: 0.3825\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 88 is: 819.5695\n",
      "hello\n",
      "----------\n",
      "epoch 89/100\n",
      "1/224, train_loss: 0.0634, step time: 0.3162\n",
      "2/224, train_loss: 0.0957, step time: 0.3184\n",
      "3/224, train_loss: 0.1536, step time: 0.3784\n",
      "4/224, train_loss: 0.0525, step time: 0.3778\n",
      "5/224, train_loss: 0.1062, step time: 0.3679\n",
      "6/224, train_loss: 0.0962, step time: 0.3846\n",
      "7/224, train_loss: 0.1039, step time: 0.3676\n",
      "8/224, train_loss: 0.0889, step time: 0.3817\n",
      "9/224, train_loss: 0.0686, step time: 0.3161\n",
      "10/224, train_loss: 0.0955, step time: 0.3927\n",
      "11/224, train_loss: 0.0831, step time: 0.3183\n",
      "12/224, train_loss: 0.0711, step time: 0.3728\n",
      "13/224, train_loss: 0.0728, step time: 0.3168\n",
      "14/224, train_loss: 0.1575, step time: 0.3173\n",
      "15/224, train_loss: 0.0956, step time: 0.3165\n",
      "16/224, train_loss: 0.1338, step time: 0.3717\n",
      "17/224, train_loss: 0.0763, step time: 0.3144\n",
      "18/224, train_loss: 0.1375, step time: 0.3183\n",
      "19/224, train_loss: 0.0666, step time: 0.3162\n",
      "20/224, train_loss: 0.0745, step time: 0.3199\n",
      "21/224, train_loss: 0.1414, step time: 0.3897\n",
      "22/224, train_loss: 0.1397, step time: 0.3169\n",
      "23/224, train_loss: 0.0980, step time: 0.4056\n",
      "24/224, train_loss: 0.0978, step time: 0.3160\n",
      "25/224, train_loss: 0.1639, step time: 0.3925\n",
      "26/224, train_loss: 0.1559, step time: 0.3827\n",
      "27/224, train_loss: 0.1724, step time: 0.3937\n",
      "28/224, train_loss: 0.0731, step time: 0.3694\n",
      "29/224, train_loss: 0.0785, step time: 0.3164\n",
      "30/224, train_loss: 0.3087, step time: 0.3758\n",
      "31/224, train_loss: 0.1084, step time: 0.3184\n",
      "32/224, train_loss: 0.0451, step time: 0.3149\n",
      "33/224, train_loss: 0.1533, step time: 0.3905\n",
      "34/224, train_loss: 0.0471, step time: 0.3163\n",
      "35/224, train_loss: 0.0758, step time: 0.3799\n",
      "36/224, train_loss: 0.0564, step time: 0.3143\n",
      "37/224, train_loss: 0.3101, step time: 0.3830\n",
      "38/224, train_loss: 0.1137, step time: 0.3167\n",
      "39/224, train_loss: 0.1861, step time: 0.3799\n",
      "40/224, train_loss: 0.0743, step time: 0.4116\n",
      "41/224, train_loss: 0.1557, step time: 0.4029\n",
      "42/224, train_loss: 0.0930, step time: 0.3663\n",
      "43/224, train_loss: 0.1042, step time: 0.3160\n",
      "44/224, train_loss: 0.1031, step time: 0.3172\n",
      "45/224, train_loss: 0.0575, step time: 0.4124\n",
      "46/224, train_loss: 0.1334, step time: 0.4079\n",
      "47/224, train_loss: 0.0992, step time: 0.3930\n",
      "48/224, train_loss: 0.0981, step time: 0.3796\n",
      "49/224, train_loss: 0.1833, step time: 0.4108\n",
      "50/224, train_loss: 0.0549, step time: 0.3651\n",
      "51/224, train_loss: 0.1011, step time: 0.3191\n",
      "52/224, train_loss: 0.0969, step time: 0.3184\n",
      "53/224, train_loss: 0.1307, step time: 0.4092\n",
      "54/224, train_loss: 0.1011, step time: 0.3967\n",
      "55/224, train_loss: 0.0610, step time: 0.3161\n",
      "56/224, train_loss: 0.1093, step time: 0.3189\n",
      "57/224, train_loss: 0.0802, step time: 0.3189\n",
      "58/224, train_loss: 0.0806, step time: 0.3163\n",
      "59/224, train_loss: 0.0898, step time: 0.3150\n",
      "60/224, train_loss: 0.1862, step time: 0.3726\n",
      "61/224, train_loss: 0.0969, step time: 0.3164\n",
      "62/224, train_loss: 0.0539, step time: 0.3955\n",
      "63/224, train_loss: 0.0856, step time: 0.3173\n",
      "64/224, train_loss: 0.1849, step time: 0.3876\n",
      "65/224, train_loss: 0.0683, step time: 0.3146\n",
      "66/224, train_loss: 0.2612, step time: 0.3900\n",
      "67/224, train_loss: 0.0826, step time: 0.3190\n",
      "68/224, train_loss: 0.0931, step time: 0.3185\n",
      "69/224, train_loss: 0.0765, step time: 0.3954\n",
      "70/224, train_loss: 0.1350, step time: 0.3197\n",
      "71/224, train_loss: 0.1369, step time: 0.3731\n",
      "72/224, train_loss: 0.0792, step time: 0.4084\n",
      "73/224, train_loss: 0.1547, step time: 0.3777\n",
      "74/224, train_loss: 0.0593, step time: 0.3167\n",
      "75/224, train_loss: 0.0737, step time: 0.3191\n",
      "76/224, train_loss: 0.0942, step time: 0.3865\n",
      "77/224, train_loss: 0.0946, step time: 0.3196\n",
      "78/224, train_loss: 0.0692, step time: 0.3154\n",
      "79/224, train_loss: 0.0951, step time: 0.3727\n",
      "80/224, train_loss: 0.1487, step time: 0.3743\n",
      "81/224, train_loss: 0.2959, step time: 0.3685\n",
      "82/224, train_loss: 0.0604, step time: 0.3910\n",
      "83/224, train_loss: 0.0893, step time: 0.4054\n",
      "84/224, train_loss: 0.0980, step time: 0.3917\n",
      "85/224, train_loss: 0.0779, step time: 0.4144\n",
      "86/224, train_loss: 0.0999, step time: 0.3202\n",
      "87/224, train_loss: 0.0943, step time: 0.3201\n",
      "88/224, train_loss: 0.0514, step time: 0.3207\n",
      "89/224, train_loss: 0.1051, step time: 0.3203\n",
      "90/224, train_loss: 0.2108, step time: 0.3197\n",
      "91/224, train_loss: 0.0911, step time: 0.3154\n",
      "92/224, train_loss: 0.1047, step time: 0.3798\n",
      "93/224, train_loss: 0.0675, step time: 0.3921\n",
      "94/224, train_loss: 0.1773, step time: 0.3206\n",
      "95/224, train_loss: 0.0966, step time: 0.3180\n",
      "96/224, train_loss: 0.0592, step time: 0.3660\n",
      "97/224, train_loss: 0.0594, step time: 0.3847\n",
      "98/224, train_loss: 0.1376, step time: 0.3695\n",
      "99/224, train_loss: 0.0694, step time: 0.4113\n",
      "100/224, train_loss: 0.0789, step time: 0.3710\n",
      "101/224, train_loss: 0.0787, step time: 0.3181\n",
      "102/224, train_loss: 0.1300, step time: 0.4110\n",
      "103/224, train_loss: 0.0916, step time: 0.4016\n",
      "104/224, train_loss: 0.0500, step time: 0.4005\n",
      "105/224, train_loss: 0.0721, step time: 0.3152\n",
      "106/224, train_loss: 0.0378, step time: 0.3919\n",
      "107/224, train_loss: 0.2025, step time: 0.3766\n",
      "108/224, train_loss: 0.1169, step time: 0.3975\n",
      "109/224, train_loss: 0.0526, step time: 0.3187\n",
      "110/224, train_loss: 0.0793, step time: 0.3139\n",
      "111/224, train_loss: 0.0811, step time: 0.3799\n",
      "112/224, train_loss: 0.0747, step time: 0.4045\n",
      "113/224, train_loss: 0.1051, step time: 0.4116\n",
      "114/224, train_loss: 0.0881, step time: 0.4076\n",
      "115/224, train_loss: 0.0742, step time: 0.3159\n",
      "116/224, train_loss: 0.1210, step time: 0.3194\n",
      "117/224, train_loss: 0.0922, step time: 0.3153\n",
      "118/224, train_loss: 0.2483, step time: 0.3673\n",
      "119/224, train_loss: 0.0806, step time: 0.3158\n",
      "120/224, train_loss: 0.1591, step time: 0.3175\n",
      "121/224, train_loss: 0.1270, step time: 0.3805\n",
      "122/224, train_loss: 0.1712, step time: 0.3179\n",
      "123/224, train_loss: 0.0899, step time: 0.3131\n",
      "124/224, train_loss: 0.0531, step time: 0.3134\n",
      "125/224, train_loss: 0.1575, step time: 0.3961\n",
      "126/224, train_loss: 0.1476, step time: 0.3817\n",
      "127/224, train_loss: 0.1245, step time: 0.3906\n",
      "128/224, train_loss: 0.2455, step time: 0.4050\n",
      "129/224, train_loss: 0.1322, step time: 0.3975\n",
      "130/224, train_loss: 0.0905, step time: 0.3175\n",
      "131/224, train_loss: 0.2522, step time: 0.3840\n",
      "132/224, train_loss: 0.0702, step time: 0.4076\n",
      "133/224, train_loss: 0.0781, step time: 0.3167\n",
      "134/224, train_loss: 0.2418, step time: 0.3981\n",
      "135/224, train_loss: 0.1055, step time: 0.3175\n",
      "136/224, train_loss: 0.0582, step time: 0.3135\n",
      "137/224, train_loss: 0.0865, step time: 0.3973\n",
      "138/224, train_loss: 0.0881, step time: 0.3877\n",
      "139/224, train_loss: 0.1031, step time: 0.3682\n",
      "140/224, train_loss: 0.1174, step time: 0.3178\n",
      "141/224, train_loss: 0.0939, step time: 0.3150\n",
      "142/224, train_loss: 0.0926, step time: 0.3134\n",
      "143/224, train_loss: 0.0649, step time: 0.3157\n",
      "144/224, train_loss: 0.2184, step time: 0.4049\n",
      "145/224, train_loss: 0.2367, step time: 0.3703\n",
      "146/224, train_loss: 0.1120, step time: 0.3697\n",
      "147/224, train_loss: 0.1041, step time: 0.3140\n",
      "148/224, train_loss: 0.2307, step time: 0.4112\n",
      "149/224, train_loss: 0.0345, step time: 0.3177\n",
      "150/224, train_loss: 0.0902, step time: 0.3171\n",
      "151/224, train_loss: 0.0846, step time: 0.4021\n",
      "152/224, train_loss: 0.1582, step time: 0.3150\n",
      "153/224, train_loss: 0.1926, step time: 0.3175\n",
      "154/224, train_loss: 0.1225, step time: 0.3799\n",
      "155/224, train_loss: 0.1297, step time: 0.4071\n",
      "156/224, train_loss: 0.0689, step time: 0.3182\n",
      "157/224, train_loss: 0.1196, step time: 0.4107\n",
      "158/224, train_loss: 0.0853, step time: 0.3150\n",
      "159/224, train_loss: 0.2742, step time: 0.3784\n",
      "160/224, train_loss: 0.2496, step time: 0.3848\n",
      "161/224, train_loss: 0.2072, step time: 0.3963\n",
      "162/224, train_loss: 0.0882, step time: 0.3170\n",
      "163/224, train_loss: 0.0896, step time: 0.3940\n",
      "164/224, train_loss: 0.0715, step time: 0.3175\n",
      "165/224, train_loss: 0.1106, step time: 0.3175\n",
      "166/224, train_loss: 0.0913, step time: 0.3170\n",
      "167/224, train_loss: 0.1736, step time: 0.3691\n",
      "168/224, train_loss: 0.0699, step time: 0.3124\n",
      "169/224, train_loss: 0.1387, step time: 0.3168\n",
      "170/224, train_loss: 0.0708, step time: 0.3694\n",
      "171/224, train_loss: 0.1297, step time: 0.3151\n",
      "172/224, train_loss: 0.1549, step time: 0.3904\n",
      "173/224, train_loss: 0.0816, step time: 0.3717\n",
      "174/224, train_loss: 0.0899, step time: 0.4091\n",
      "175/224, train_loss: 0.0683, step time: 0.3989\n",
      "176/224, train_loss: 0.0891, step time: 0.4011\n",
      "177/224, train_loss: 0.0718, step time: 0.3939\n",
      "178/224, train_loss: 0.2335, step time: 0.4069\n",
      "179/224, train_loss: 0.0808, step time: 0.3760\n",
      "180/224, train_loss: 0.1407, step time: 0.3789\n",
      "181/224, train_loss: 0.2071, step time: 0.3182\n",
      "182/224, train_loss: 0.1246, step time: 0.4098\n",
      "183/224, train_loss: 0.1059, step time: 0.3156\n",
      "184/224, train_loss: 0.0843, step time: 0.3173\n",
      "185/224, train_loss: 0.0828, step time: 0.3151\n",
      "186/224, train_loss: 0.0747, step time: 0.3148\n",
      "187/224, train_loss: 0.0994, step time: 0.3178\n",
      "188/224, train_loss: 0.0759, step time: 0.3154\n",
      "189/224, train_loss: 0.0483, step time: 0.3688\n",
      "190/224, train_loss: 0.1032, step time: 0.4088\n",
      "191/224, train_loss: 0.0794, step time: 0.3685\n",
      "192/224, train_loss: 0.1055, step time: 0.3178\n",
      "193/224, train_loss: 0.0961, step time: 0.3735\n",
      "194/224, train_loss: 0.0578, step time: 0.3191\n",
      "195/224, train_loss: 0.1793, step time: 0.3690\n",
      "196/224, train_loss: 0.1456, step time: 0.4068\n",
      "197/224, train_loss: 0.0990, step time: 0.3160\n",
      "198/224, train_loss: 0.1927, step time: 0.3151\n",
      "199/224, train_loss: 0.0942, step time: 0.3161\n",
      "200/224, train_loss: 0.0789, step time: 0.4101\n",
      "201/224, train_loss: 0.0913, step time: 0.4009\n",
      "202/224, train_loss: 0.0438, step time: 0.3157\n",
      "203/224, train_loss: 0.0710, step time: 0.3151\n",
      "204/224, train_loss: 0.1926, step time: 0.3180\n",
      "205/224, train_loss: 0.1441, step time: 0.3850\n",
      "206/224, train_loss: 0.0970, step time: 0.3172\n",
      "207/224, train_loss: 0.1089, step time: 0.3178\n",
      "208/224, train_loss: 0.0585, step time: 0.3175\n",
      "209/224, train_loss: 0.1075, step time: 0.3682\n",
      "210/224, train_loss: 0.1396, step time: 0.4065\n",
      "211/224, train_loss: 0.1179, step time: 0.4084\n",
      "212/224, train_loss: 0.1812, step time: 0.4040\n",
      "213/224, train_loss: 0.0701, step time: 0.3177\n",
      "214/224, train_loss: 0.1448, step time: 0.3150\n",
      "215/224, train_loss: 0.0803, step time: 0.3179\n",
      "216/224, train_loss: 0.1621, step time: 0.3974\n",
      "217/224, train_loss: 0.0573, step time: 0.3153\n",
      "218/224, train_loss: 0.0660, step time: 0.3160\n",
      "219/224, train_loss: 0.1429, step time: 0.3992\n",
      "220/224, train_loss: 0.0790, step time: 0.3156\n",
      "221/224, train_loss: 0.0992, step time: 0.3162\n",
      "222/224, train_loss: 0.1126, step time: 0.3135\n",
      "223/224, train_loss: 0.2060, step time: 0.3907\n",
      "224/224, train_loss: 0.0941, step time: 0.3921\n",
      "epoch 89 average loss: 0.1128\n",
      "current epoch: 89 current mean dice: 0.7123 class1: 0.9994 class2: 0.7539 class3: 0.3836\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 89 is: 766.3812\n",
      "hello\n",
      "----------\n",
      "epoch 90/100\n",
      "1/224, train_loss: 0.1136, step time: 0.3943\n",
      "2/224, train_loss: 0.1036, step time: 0.4058\n",
      "3/224, train_loss: 0.0691, step time: 0.3192\n",
      "4/224, train_loss: 0.0526, step time: 0.3160\n",
      "5/224, train_loss: 0.0565, step time: 0.3154\n",
      "6/224, train_loss: 0.0803, step time: 0.4017\n",
      "7/224, train_loss: 0.0445, step time: 0.3157\n",
      "8/224, train_loss: 0.1338, step time: 0.3177\n",
      "9/224, train_loss: 0.1379, step time: 0.3184\n",
      "10/224, train_loss: 0.0995, step time: 0.3161\n",
      "11/224, train_loss: 0.0969, step time: 0.3906\n",
      "12/224, train_loss: 0.0640, step time: 0.3140\n",
      "13/224, train_loss: 0.0995, step time: 0.4115\n",
      "14/224, train_loss: 0.0662, step time: 0.3166\n",
      "15/224, train_loss: 0.0814, step time: 0.3996\n",
      "16/224, train_loss: 0.1454, step time: 0.3770\n",
      "17/224, train_loss: 0.0769, step time: 0.3774\n",
      "18/224, train_loss: 0.0734, step time: 0.3955\n",
      "19/224, train_loss: 0.1218, step time: 0.3824\n",
      "20/224, train_loss: 0.1132, step time: 0.3154\n",
      "21/224, train_loss: 0.1087, step time: 0.3178\n",
      "22/224, train_loss: 0.0727, step time: 0.3162\n",
      "23/224, train_loss: 0.1151, step time: 0.3187\n",
      "24/224, train_loss: 0.0964, step time: 0.3181\n",
      "25/224, train_loss: 0.0742, step time: 0.3155\n",
      "26/224, train_loss: 0.1049, step time: 0.3158\n",
      "27/224, train_loss: 0.0839, step time: 0.3135\n",
      "28/224, train_loss: 0.2459, step time: 0.3980\n",
      "29/224, train_loss: 0.1070, step time: 0.4019\n",
      "30/224, train_loss: 0.1406, step time: 0.3811\n",
      "31/224, train_loss: 0.3812, step time: 0.3867\n",
      "32/224, train_loss: 0.1471, step time: 0.3978\n",
      "33/224, train_loss: 0.0903, step time: 0.3931\n",
      "34/224, train_loss: 0.0628, step time: 0.3160\n",
      "35/224, train_loss: 0.1028, step time: 0.3904\n",
      "36/224, train_loss: 0.0820, step time: 0.3160\n",
      "37/224, train_loss: 0.1742, step time: 0.3753\n",
      "38/224, train_loss: 0.0698, step time: 0.3160\n",
      "39/224, train_loss: 0.0850, step time: 0.4141\n",
      "40/224, train_loss: 0.1126, step time: 0.3157\n",
      "41/224, train_loss: 0.1677, step time: 0.3742\n",
      "42/224, train_loss: 0.1570, step time: 0.3726\n",
      "43/224, train_loss: 0.1325, step time: 0.4120\n",
      "44/224, train_loss: 0.0806, step time: 0.3178\n",
      "45/224, train_loss: 0.0832, step time: 0.3154\n",
      "46/224, train_loss: 0.1680, step time: 0.4102\n",
      "47/224, train_loss: 0.0453, step time: 0.3177\n",
      "48/224, train_loss: 0.0982, step time: 0.3150\n",
      "49/224, train_loss: 0.5182, step time: 0.3908\n",
      "50/224, train_loss: 0.0814, step time: 0.3829\n",
      "51/224, train_loss: 0.0985, step time: 0.3163\n",
      "52/224, train_loss: 0.1281, step time: 0.3144\n",
      "53/224, train_loss: 0.0571, step time: 0.3970\n",
      "54/224, train_loss: 0.1158, step time: 0.3820\n",
      "55/224, train_loss: 0.0954, step time: 0.3731\n",
      "56/224, train_loss: 0.0621, step time: 0.3676\n",
      "57/224, train_loss: 0.0879, step time: 0.3176\n",
      "58/224, train_loss: 0.1120, step time: 0.3156\n",
      "59/224, train_loss: 0.0471, step time: 0.3825\n",
      "60/224, train_loss: 0.0645, step time: 0.3900\n",
      "61/224, train_loss: 0.0699, step time: 0.3155\n",
      "62/224, train_loss: 0.0869, step time: 0.3130\n",
      "63/224, train_loss: 0.0766, step time: 0.3152\n",
      "64/224, train_loss: 0.0973, step time: 0.3154\n",
      "65/224, train_loss: 0.0443, step time: 0.3131\n",
      "66/224, train_loss: 0.0470, step time: 0.3728\n",
      "67/224, train_loss: 0.0841, step time: 0.3889\n",
      "68/224, train_loss: 0.0652, step time: 0.3174\n",
      "69/224, train_loss: 0.1785, step time: 0.3897\n",
      "70/224, train_loss: 0.2463, step time: 0.3996\n",
      "71/224, train_loss: 0.1063, step time: 0.3685\n",
      "72/224, train_loss: 0.0889, step time: 0.3152\n",
      "73/224, train_loss: 0.1315, step time: 0.3897\n",
      "74/224, train_loss: 0.1046, step time: 0.4016\n",
      "75/224, train_loss: 0.0565, step time: 0.3150\n",
      "76/224, train_loss: 0.0792, step time: 0.3776\n",
      "77/224, train_loss: 0.1183, step time: 0.4036\n",
      "78/224, train_loss: 0.0589, step time: 0.3979\n",
      "79/224, train_loss: 0.0954, step time: 0.3147\n",
      "80/224, train_loss: 0.1214, step time: 0.4064\n",
      "81/224, train_loss: 0.0647, step time: 0.3923\n",
      "82/224, train_loss: 0.0732, step time: 0.3120\n",
      "83/224, train_loss: 0.0659, step time: 0.3144\n",
      "84/224, train_loss: 0.0988, step time: 0.3917\n",
      "85/224, train_loss: 0.1100, step time: 0.3942\n",
      "86/224, train_loss: 0.0398, step time: 0.3143\n",
      "87/224, train_loss: 0.0889, step time: 0.3833\n",
      "88/224, train_loss: 0.2955, step time: 0.3663\n",
      "89/224, train_loss: 0.0773, step time: 0.3731\n",
      "90/224, train_loss: 0.0775, step time: 0.3171\n",
      "91/224, train_loss: 0.3201, step time: 0.3712\n",
      "92/224, train_loss: 0.1331, step time: 0.3782\n",
      "93/224, train_loss: 0.0754, step time: 0.3927\n",
      "94/224, train_loss: 0.0652, step time: 0.3144\n",
      "95/224, train_loss: 0.1278, step time: 0.3862\n",
      "96/224, train_loss: 0.0556, step time: 0.3166\n",
      "97/224, train_loss: 0.1869, step time: 0.3146\n",
      "98/224, train_loss: 0.0885, step time: 0.3818\n",
      "99/224, train_loss: 0.0964, step time: 0.3165\n",
      "100/224, train_loss: 0.0799, step time: 0.3170\n",
      "101/224, train_loss: 0.0745, step time: 0.3914\n",
      "102/224, train_loss: 0.1059, step time: 0.3872\n",
      "103/224, train_loss: 0.1197, step time: 0.3869\n",
      "104/224, train_loss: 0.1261, step time: 0.3143\n",
      "105/224, train_loss: 0.1004, step time: 0.3119\n",
      "106/224, train_loss: 0.0817, step time: 0.3140\n",
      "107/224, train_loss: 0.3903, step time: 0.4075\n",
      "108/224, train_loss: 0.0702, step time: 0.3150\n",
      "109/224, train_loss: 0.0665, step time: 0.3160\n",
      "110/224, train_loss: 0.1212, step time: 0.3153\n",
      "111/224, train_loss: 0.0853, step time: 0.4094\n",
      "112/224, train_loss: 0.0979, step time: 0.3165\n",
      "113/224, train_loss: 0.1713, step time: 0.3939\n",
      "114/224, train_loss: 0.1341, step time: 0.3143\n",
      "115/224, train_loss: 0.0852, step time: 0.3118\n",
      "116/224, train_loss: 0.0763, step time: 0.3125\n",
      "117/224, train_loss: 0.0942, step time: 0.3148\n",
      "118/224, train_loss: 0.0685, step time: 0.3686\n",
      "119/224, train_loss: 0.2320, step time: 0.4000\n",
      "120/224, train_loss: 0.0497, step time: 0.3145\n",
      "121/224, train_loss: 0.0615, step time: 0.4013\n",
      "122/224, train_loss: 0.1764, step time: 0.3135\n",
      "123/224, train_loss: 0.0688, step time: 0.3171\n",
      "124/224, train_loss: 0.2097, step time: 0.3754\n",
      "125/224, train_loss: 0.0768, step time: 0.3148\n",
      "126/224, train_loss: 0.1325, step time: 0.3170\n",
      "127/224, train_loss: 0.0739, step time: 0.3783\n",
      "128/224, train_loss: 0.0623, step time: 0.3123\n",
      "129/224, train_loss: 0.0627, step time: 0.4039\n",
      "130/224, train_loss: 0.0608, step time: 0.3654\n",
      "131/224, train_loss: 0.0991, step time: 0.3178\n",
      "132/224, train_loss: 0.1783, step time: 0.4057\n",
      "133/224, train_loss: 0.0523, step time: 0.3146\n",
      "134/224, train_loss: 0.0545, step time: 0.3150\n",
      "135/224, train_loss: 0.0855, step time: 0.3151\n",
      "136/224, train_loss: 0.0982, step time: 0.3168\n",
      "137/224, train_loss: 0.0898, step time: 0.3170\n",
      "138/224, train_loss: 0.0471, step time: 0.3174\n",
      "139/224, train_loss: 0.4250, step time: 0.3782\n",
      "140/224, train_loss: 0.1633, step time: 0.3175\n",
      "141/224, train_loss: 0.0719, step time: 0.3149\n",
      "142/224, train_loss: 0.1736, step time: 0.4028\n",
      "143/224, train_loss: 0.2183, step time: 0.4007\n",
      "144/224, train_loss: 0.0633, step time: 0.3158\n",
      "145/224, train_loss: 0.0888, step time: 0.3180\n",
      "146/224, train_loss: 0.1245, step time: 0.3763\n",
      "147/224, train_loss: 0.1151, step time: 0.3854\n",
      "148/224, train_loss: 0.2009, step time: 0.3724\n",
      "149/224, train_loss: 0.1153, step time: 0.3177\n",
      "150/224, train_loss: 0.1820, step time: 0.4012\n",
      "151/224, train_loss: 0.1500, step time: 0.3769\n",
      "152/224, train_loss: 0.1287, step time: 0.3942\n",
      "153/224, train_loss: 0.1738, step time: 0.3939\n",
      "154/224, train_loss: 0.1074, step time: 0.3149\n",
      "155/224, train_loss: 0.0769, step time: 0.3826\n",
      "156/224, train_loss: 0.1568, step time: 0.4006\n",
      "157/224, train_loss: 0.1314, step time: 0.3174\n",
      "158/224, train_loss: 0.1306, step time: 0.3704\n",
      "159/224, train_loss: 0.1569, step time: 0.3977\n",
      "160/224, train_loss: 0.0755, step time: 0.3170\n",
      "161/224, train_loss: 0.0624, step time: 0.3151\n",
      "162/224, train_loss: 0.0656, step time: 0.3781\n",
      "163/224, train_loss: 0.1175, step time: 0.3148\n",
      "164/224, train_loss: 0.0666, step time: 0.3861\n",
      "165/224, train_loss: 0.1298, step time: 0.3842\n",
      "166/224, train_loss: 0.0996, step time: 0.3127\n",
      "167/224, train_loss: 0.1228, step time: 0.3151\n",
      "168/224, train_loss: 0.1089, step time: 0.3810\n",
      "169/224, train_loss: 0.1292, step time: 0.3910\n",
      "170/224, train_loss: 0.1514, step time: 0.3152\n",
      "171/224, train_loss: 0.0901, step time: 0.3925\n",
      "172/224, train_loss: 0.1725, step time: 0.3744\n",
      "173/224, train_loss: 0.1160, step time: 0.4028\n",
      "174/224, train_loss: 0.0388, step time: 0.3150\n",
      "175/224, train_loss: 0.2150, step time: 0.3833\n",
      "176/224, train_loss: 0.2502, step time: 0.4047\n",
      "177/224, train_loss: 0.1208, step time: 0.3838\n",
      "178/224, train_loss: 0.1295, step time: 0.3150\n",
      "179/224, train_loss: 0.0802, step time: 0.3914\n",
      "180/224, train_loss: 0.2094, step time: 0.3865\n",
      "181/224, train_loss: 0.1458, step time: 0.3152\n",
      "182/224, train_loss: 0.1076, step time: 0.3675\n",
      "183/224, train_loss: 0.0972, step time: 0.3951\n",
      "184/224, train_loss: 0.0564, step time: 0.3149\n",
      "185/224, train_loss: 0.1846, step time: 0.3783\n",
      "186/224, train_loss: 0.0897, step time: 0.3174\n",
      "187/224, train_loss: 0.0724, step time: 0.3150\n",
      "188/224, train_loss: 0.0550, step time: 0.3126\n",
      "189/224, train_loss: 0.0827, step time: 0.3829\n",
      "190/224, train_loss: 0.1255, step time: 0.3154\n",
      "191/224, train_loss: 0.1179, step time: 0.3155\n",
      "192/224, train_loss: 0.1588, step time: 0.3989\n",
      "193/224, train_loss: 0.1285, step time: 0.3734\n",
      "194/224, train_loss: 0.0788, step time: 0.3152\n",
      "195/224, train_loss: 0.1275, step time: 0.3170\n",
      "196/224, train_loss: 0.1071, step time: 0.3707\n",
      "197/224, train_loss: 0.1220, step time: 0.3149\n",
      "198/224, train_loss: 0.3212, step time: 0.3962\n",
      "199/224, train_loss: 0.0621, step time: 0.3171\n",
      "200/224, train_loss: 0.1143, step time: 0.3142\n",
      "201/224, train_loss: 0.0773, step time: 0.3891\n",
      "202/224, train_loss: 0.1383, step time: 0.4055\n",
      "203/224, train_loss: 0.1872, step time: 0.4037\n",
      "204/224, train_loss: 0.1080, step time: 0.3167\n",
      "205/224, train_loss: 0.0795, step time: 0.3129\n",
      "206/224, train_loss: 0.0824, step time: 0.3150\n",
      "207/224, train_loss: 0.1481, step time: 0.3684\n",
      "208/224, train_loss: 0.0899, step time: 0.3168\n",
      "209/224, train_loss: 0.1850, step time: 0.3773\n",
      "210/224, train_loss: 0.0502, step time: 0.3171\n",
      "211/224, train_loss: 0.2693, step time: 0.3651\n",
      "212/224, train_loss: 0.1010, step time: 0.3859\n",
      "213/224, train_loss: 0.0705, step time: 0.3147\n",
      "214/224, train_loss: 0.2626, step time: 0.3868\n",
      "215/224, train_loss: 0.0908, step time: 0.3168\n",
      "216/224, train_loss: 0.0516, step time: 0.3151\n",
      "217/224, train_loss: 0.0716, step time: 0.3156\n",
      "218/224, train_loss: 0.1304, step time: 0.3174\n",
      "219/224, train_loss: 0.0803, step time: 0.3146\n",
      "220/224, train_loss: 0.1332, step time: 0.4050\n",
      "221/224, train_loss: 0.1535, step time: 0.3940\n",
      "222/224, train_loss: 0.0585, step time: 0.3131\n",
      "223/224, train_loss: 0.1014, step time: 0.3151\n",
      "224/224, train_loss: 0.1640, step time: 0.3662\n",
      "epoch 90 average loss: 0.1154\n",
      "current epoch: 90 current mean dice: 0.6879 class1: 0.9993 class2: 0.7355 class3: 0.3289\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 90 is: 732.1318\n",
      "hello\n",
      "----------\n",
      "epoch 91/100\n",
      "1/224, train_loss: 0.1271, step time: 0.3147\n",
      "2/224, train_loss: 0.3003, step time: 0.3817\n",
      "3/224, train_loss: 0.0731, step time: 0.3138\n",
      "4/224, train_loss: 0.1524, step time: 0.3755\n",
      "5/224, train_loss: 0.0925, step time: 0.3179\n",
      "6/224, train_loss: 0.1015, step time: 0.3670\n",
      "7/224, train_loss: 0.0804, step time: 0.3149\n",
      "8/224, train_loss: 0.2457, step time: 0.3146\n",
      "9/224, train_loss: 0.0769, step time: 0.3769\n",
      "10/224, train_loss: 0.0719, step time: 0.3178\n",
      "11/224, train_loss: 0.1021, step time: 0.3175\n",
      "12/224, train_loss: 0.3106, step time: 0.3775\n",
      "13/224, train_loss: 0.1463, step time: 0.3781\n",
      "14/224, train_loss: 0.0652, step time: 0.3128\n",
      "15/224, train_loss: 0.0491, step time: 0.3152\n",
      "16/224, train_loss: 0.0945, step time: 0.3158\n",
      "17/224, train_loss: 0.3383, step time: 0.3909\n",
      "18/224, train_loss: 0.1011, step time: 0.3133\n",
      "19/224, train_loss: 0.3603, step time: 0.3768\n",
      "20/224, train_loss: 0.1005, step time: 0.3894\n",
      "21/224, train_loss: 0.1153, step time: 0.4019\n",
      "22/224, train_loss: 0.1278, step time: 0.3661\n",
      "23/224, train_loss: 0.2147, step time: 0.4026\n",
      "24/224, train_loss: 0.1419, step time: 0.3152\n",
      "25/224, train_loss: 0.0885, step time: 0.3131\n",
      "26/224, train_loss: 0.1380, step time: 0.3757\n",
      "27/224, train_loss: 0.0622, step time: 0.3729\n",
      "28/224, train_loss: 0.1542, step time: 0.3926\n",
      "29/224, train_loss: 0.1704, step time: 0.3861\n",
      "30/224, train_loss: 0.1051, step time: 0.3154\n",
      "31/224, train_loss: 0.1344, step time: 0.3156\n",
      "32/224, train_loss: 0.1346, step time: 0.3725\n",
      "33/224, train_loss: 0.0794, step time: 0.3882\n",
      "34/224, train_loss: 0.0960, step time: 0.3777\n",
      "35/224, train_loss: 0.1657, step time: 0.3150\n",
      "36/224, train_loss: 0.4373, step time: 0.3654\n",
      "37/224, train_loss: 0.2461, step time: 0.3984\n",
      "38/224, train_loss: 0.1368, step time: 0.3182\n",
      "39/224, train_loss: 0.0951, step time: 0.3806\n",
      "40/224, train_loss: 0.0856, step time: 0.3176\n",
      "41/224, train_loss: 0.1951, step time: 0.3711\n",
      "42/224, train_loss: 0.0662, step time: 0.3159\n",
      "43/224, train_loss: 0.1265, step time: 0.3177\n",
      "44/224, train_loss: 0.1541, step time: 0.4104\n",
      "45/224, train_loss: 0.0699, step time: 0.3151\n",
      "46/224, train_loss: 0.0924, step time: 0.3153\n",
      "47/224, train_loss: 0.0896, step time: 0.3898\n",
      "48/224, train_loss: 0.0624, step time: 0.3693\n",
      "49/224, train_loss: 0.0997, step time: 0.3180\n",
      "50/224, train_loss: 0.1089, step time: 0.3181\n",
      "51/224, train_loss: 0.0733, step time: 0.3178\n",
      "52/224, train_loss: 0.1196, step time: 0.4008\n",
      "53/224, train_loss: 0.0950, step time: 0.4010\n",
      "54/224, train_loss: 0.1073, step time: 0.3199\n",
      "55/224, train_loss: 0.0999, step time: 0.3177\n",
      "56/224, train_loss: 0.0960, step time: 0.3677\n",
      "57/224, train_loss: 0.0785, step time: 0.3151\n",
      "58/224, train_loss: 0.1356, step time: 0.3916\n",
      "59/224, train_loss: 0.1444, step time: 0.4064\n",
      "60/224, train_loss: 0.0511, step time: 0.3788\n",
      "61/224, train_loss: 0.1043, step time: 0.3150\n",
      "62/224, train_loss: 0.0876, step time: 0.3150\n",
      "63/224, train_loss: 0.0430, step time: 0.3170\n",
      "64/224, train_loss: 0.0463, step time: 0.3154\n",
      "65/224, train_loss: 0.0919, step time: 0.3882\n",
      "66/224, train_loss: 0.0941, step time: 0.4056\n",
      "67/224, train_loss: 0.0815, step time: 0.3131\n",
      "68/224, train_loss: 0.0852, step time: 0.3145\n",
      "69/224, train_loss: 0.3878, step time: 0.4087\n",
      "70/224, train_loss: 0.0831, step time: 0.3149\n",
      "71/224, train_loss: 0.0822, step time: 0.3146\n",
      "72/224, train_loss: 0.0699, step time: 0.3714\n",
      "73/224, train_loss: 0.0628, step time: 0.3131\n",
      "74/224, train_loss: 0.0559, step time: 0.3136\n",
      "75/224, train_loss: 0.0794, step time: 0.3175\n",
      "76/224, train_loss: 0.1479, step time: 0.4011\n",
      "77/224, train_loss: 0.0942, step time: 0.3153\n",
      "78/224, train_loss: 0.2318, step time: 0.3946\n",
      "79/224, train_loss: 0.1094, step time: 0.3686\n",
      "80/224, train_loss: 0.0756, step time: 0.3166\n",
      "81/224, train_loss: 0.2524, step time: 0.3845\n",
      "82/224, train_loss: 0.0926, step time: 0.3144\n",
      "83/224, train_loss: 0.1227, step time: 0.3935\n",
      "84/224, train_loss: 0.0610, step time: 0.3153\n",
      "85/224, train_loss: 0.1046, step time: 0.4120\n",
      "86/224, train_loss: 0.1363, step time: 0.3655\n",
      "87/224, train_loss: 0.1654, step time: 0.3168\n",
      "88/224, train_loss: 0.2088, step time: 0.3146\n",
      "89/224, train_loss: 0.1881, step time: 0.3730\n",
      "90/224, train_loss: 0.1213, step time: 0.3173\n",
      "91/224, train_loss: 0.1263, step time: 0.3150\n",
      "92/224, train_loss: 0.1483, step time: 0.4096\n",
      "93/224, train_loss: 0.0799, step time: 0.3686\n",
      "94/224, train_loss: 0.1206, step time: 0.3898\n",
      "95/224, train_loss: 0.0974, step time: 0.3878\n",
      "96/224, train_loss: 0.0712, step time: 0.3139\n",
      "97/224, train_loss: 0.0846, step time: 0.3143\n",
      "98/224, train_loss: 0.2041, step time: 0.3167\n",
      "99/224, train_loss: 0.2430, step time: 0.3816\n",
      "100/224, train_loss: 0.0577, step time: 0.3886\n",
      "101/224, train_loss: 0.1145, step time: 0.3145\n",
      "102/224, train_loss: 0.1320, step time: 0.3856\n",
      "103/224, train_loss: 0.3794, step time: 0.3880\n",
      "104/224, train_loss: 0.0795, step time: 0.3151\n",
      "105/224, train_loss: 0.1123, step time: 0.3769\n",
      "106/224, train_loss: 0.1911, step time: 0.3769\n",
      "107/224, train_loss: 0.2333, step time: 0.3783\n",
      "108/224, train_loss: 0.0953, step time: 0.3631\n",
      "109/224, train_loss: 0.1384, step time: 0.4014\n",
      "110/224, train_loss: 0.1054, step time: 0.3144\n",
      "111/224, train_loss: 0.1697, step time: 0.3929\n",
      "112/224, train_loss: 0.1344, step time: 0.3755\n",
      "113/224, train_loss: 0.1239, step time: 0.3768\n",
      "114/224, train_loss: 0.1307, step time: 0.3702\n",
      "115/224, train_loss: 0.0721, step time: 0.3847\n",
      "116/224, train_loss: 0.0810, step time: 0.3152\n",
      "117/224, train_loss: 0.1901, step time: 0.3705\n",
      "118/224, train_loss: 0.1905, step time: 0.3970\n",
      "119/224, train_loss: 0.0634, step time: 0.3146\n",
      "120/224, train_loss: 0.1797, step time: 0.3666\n",
      "121/224, train_loss: 0.1566, step time: 0.3147\n",
      "122/224, train_loss: 0.1192, step time: 0.3172\n",
      "123/224, train_loss: 0.2235, step time: 0.3982\n",
      "124/224, train_loss: 0.0679, step time: 0.3938\n",
      "125/224, train_loss: 0.0768, step time: 0.3900\n",
      "126/224, train_loss: 0.1064, step time: 0.3176\n",
      "127/224, train_loss: 0.1329, step time: 0.4079\n",
      "128/224, train_loss: 0.1061, step time: 0.3153\n",
      "129/224, train_loss: 0.0898, step time: 0.3167\n",
      "130/224, train_loss: 0.1218, step time: 0.3127\n",
      "131/224, train_loss: 0.1060, step time: 0.3147\n",
      "132/224, train_loss: 0.0875, step time: 0.4002\n",
      "133/224, train_loss: 0.1827, step time: 0.3845\n",
      "134/224, train_loss: 0.0639, step time: 0.3145\n",
      "135/224, train_loss: 0.0795, step time: 0.3168\n",
      "136/224, train_loss: 0.1003, step time: 0.3142\n",
      "137/224, train_loss: 0.0689, step time: 0.3881\n",
      "138/224, train_loss: 0.0869, step time: 0.3877\n",
      "139/224, train_loss: 0.1369, step time: 0.3817\n",
      "140/224, train_loss: 0.3503, step time: 0.3933\n",
      "141/224, train_loss: 0.1148, step time: 0.3137\n",
      "142/224, train_loss: 0.1049, step time: 0.3818\n",
      "143/224, train_loss: 0.1700, step time: 0.4077\n",
      "144/224, train_loss: 0.0810, step time: 0.3778\n",
      "145/224, train_loss: 0.1957, step time: 0.3176\n",
      "146/224, train_loss: 0.1525, step time: 0.3815\n",
      "147/224, train_loss: 0.0395, step time: 0.3923\n",
      "148/224, train_loss: 0.1628, step time: 0.3714\n",
      "149/224, train_loss: 0.0986, step time: 0.4058\n",
      "150/224, train_loss: 0.1151, step time: 0.3803\n",
      "151/224, train_loss: 0.2810, step time: 0.3943\n",
      "152/224, train_loss: 0.0810, step time: 0.3155\n",
      "153/224, train_loss: 0.1013, step time: 0.3137\n",
      "154/224, train_loss: 0.1310, step time: 0.4105\n",
      "155/224, train_loss: 0.1363, step time: 0.3138\n",
      "156/224, train_loss: 0.0774, step time: 0.3165\n",
      "157/224, train_loss: 0.1540, step time: 0.3152\n",
      "158/224, train_loss: 0.1242, step time: 0.3157\n",
      "159/224, train_loss: 0.1475, step time: 0.4014\n",
      "160/224, train_loss: 0.1193, step time: 0.3158\n",
      "161/224, train_loss: 0.0827, step time: 0.3842\n",
      "162/224, train_loss: 0.3329, step time: 0.3774\n",
      "163/224, train_loss: 0.0754, step time: 0.3178\n",
      "164/224, train_loss: 0.0604, step time: 0.3177\n",
      "165/224, train_loss: 0.2252, step time: 0.3182\n",
      "166/224, train_loss: 0.0716, step time: 0.3183\n",
      "167/224, train_loss: 0.1849, step time: 0.3878\n",
      "168/224, train_loss: 0.1242, step time: 0.3151\n",
      "169/224, train_loss: 0.0483, step time: 0.3151\n",
      "170/224, train_loss: 0.0659, step time: 0.3179\n",
      "171/224, train_loss: 0.0601, step time: 0.3736\n",
      "172/224, train_loss: 0.1043, step time: 0.4077\n",
      "173/224, train_loss: 0.1116, step time: 0.3797\n",
      "174/224, train_loss: 0.1125, step time: 0.3908\n",
      "175/224, train_loss: 0.1443, step time: 0.3180\n",
      "176/224, train_loss: 0.2420, step time: 0.3820\n",
      "177/224, train_loss: 0.1366, step time: 0.3661\n",
      "178/224, train_loss: 0.0802, step time: 0.3162\n",
      "179/224, train_loss: 0.0678, step time: 0.3164\n",
      "180/224, train_loss: 0.0969, step time: 0.3678\n",
      "181/224, train_loss: 0.0393, step time: 0.3175\n",
      "182/224, train_loss: 0.0687, step time: 0.3155\n",
      "183/224, train_loss: 0.1008, step time: 0.3183\n",
      "184/224, train_loss: 0.0710, step time: 0.3182\n",
      "185/224, train_loss: 0.1271, step time: 0.3936\n",
      "186/224, train_loss: 0.0601, step time: 0.3153\n",
      "187/224, train_loss: 0.0956, step time: 0.3177\n",
      "188/224, train_loss: 0.2115, step time: 0.3719\n",
      "189/224, train_loss: 0.2033, step time: 0.3740\n",
      "190/224, train_loss: 0.0662, step time: 0.3129\n",
      "191/224, train_loss: 0.1223, step time: 0.3838\n",
      "192/224, train_loss: 0.1086, step time: 0.3997\n",
      "193/224, train_loss: 0.1095, step time: 0.3178\n",
      "194/224, train_loss: 0.0782, step time: 0.3157\n",
      "195/224, train_loss: 0.0816, step time: 0.3652\n",
      "196/224, train_loss: 0.1269, step time: 0.4051\n",
      "197/224, train_loss: 0.3705, step time: 0.4001\n",
      "198/224, train_loss: 0.0745, step time: 0.3173\n",
      "199/224, train_loss: 0.1429, step time: 0.3707\n",
      "200/224, train_loss: 0.0805, step time: 0.3154\n",
      "201/224, train_loss: 0.1990, step time: 0.4038\n",
      "202/224, train_loss: 0.0603, step time: 0.3187\n",
      "203/224, train_loss: 0.0777, step time: 0.3948\n",
      "204/224, train_loss: 0.0743, step time: 0.3658\n",
      "205/224, train_loss: 0.2217, step time: 0.4090\n",
      "206/224, train_loss: 0.0713, step time: 0.3128\n",
      "207/224, train_loss: 0.0612, step time: 0.3146\n",
      "208/224, train_loss: 0.0607, step time: 0.3145\n",
      "209/224, train_loss: 0.1551, step time: 0.3154\n",
      "210/224, train_loss: 0.1062, step time: 0.4052\n",
      "211/224, train_loss: 0.0625, step time: 0.4105\n",
      "212/224, train_loss: 0.0537, step time: 0.3144\n",
      "213/224, train_loss: 0.2147, step time: 0.3968\n",
      "214/224, train_loss: 0.1645, step time: 0.3666\n",
      "215/224, train_loss: 0.0937, step time: 0.3147\n",
      "216/224, train_loss: 0.0697, step time: 0.3156\n",
      "217/224, train_loss: 0.3172, step time: 0.3152\n",
      "218/224, train_loss: 0.0877, step time: 0.3151\n",
      "219/224, train_loss: 0.1173, step time: 0.4033\n",
      "220/224, train_loss: 0.2312, step time: 0.3815\n",
      "221/224, train_loss: 0.2173, step time: 0.3878\n",
      "222/224, train_loss: 0.1035, step time: 0.3148\n",
      "223/224, train_loss: 0.1005, step time: 0.4001\n",
      "224/224, train_loss: 0.0629, step time: 0.3176\n",
      "epoch 91 average loss: 0.1273\n",
      "current epoch: 91 current mean dice: 0.7105 class1: 0.9994 class2: 0.7472 class3: 0.3849\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 91 is: 765.3014\n",
      "hello\n",
      "----------\n",
      "epoch 92/100\n",
      "1/224, train_loss: 0.0594, step time: 0.3751\n",
      "2/224, train_loss: 0.0908, step time: 0.3129\n",
      "3/224, train_loss: 0.0790, step time: 0.4753\n",
      "4/224, train_loss: 0.3625, step time: 0.3144\n",
      "5/224, train_loss: 0.1324, step time: 0.3171\n",
      "6/224, train_loss: 0.0963, step time: 0.3151\n",
      "7/224, train_loss: 0.1440, step time: 0.3149\n",
      "8/224, train_loss: 0.0946, step time: 0.3168\n",
      "9/224, train_loss: 0.4482, step time: 0.3818\n",
      "10/224, train_loss: 0.1084, step time: 0.3125\n",
      "11/224, train_loss: 0.1423, step time: 0.3692\n",
      "12/224, train_loss: 0.1279, step time: 0.3695\n",
      "13/224, train_loss: 0.0642, step time: 0.3168\n",
      "14/224, train_loss: 0.0839, step time: 0.3144\n",
      "15/224, train_loss: 0.0515, step time: 0.3173\n",
      "16/224, train_loss: 0.1258, step time: 0.3161\n",
      "17/224, train_loss: 0.0978, step time: 0.3736\n",
      "18/224, train_loss: 0.1102, step time: 0.3750\n",
      "19/224, train_loss: 0.0696, step time: 0.3706\n",
      "20/224, train_loss: 0.2807, step time: 0.3918\n",
      "21/224, train_loss: 0.1973, step time: 0.3696\n",
      "22/224, train_loss: 0.0718, step time: 0.3153\n",
      "23/224, train_loss: 0.0646, step time: 0.4006\n",
      "24/224, train_loss: 0.0952, step time: 0.3941\n",
      "25/224, train_loss: 0.1140, step time: 0.3181\n",
      "26/224, train_loss: 0.2533, step time: 0.4033\n",
      "27/224, train_loss: 0.2630, step time: 0.3942\n",
      "28/224, train_loss: 0.0793, step time: 0.3145\n",
      "29/224, train_loss: 0.0861, step time: 0.3175\n",
      "30/224, train_loss: 0.0765, step time: 0.3174\n",
      "31/224, train_loss: 0.1074, step time: 0.3147\n",
      "32/224, train_loss: 0.0801, step time: 0.3145\n",
      "33/224, train_loss: 0.2547, step time: 0.4006\n",
      "34/224, train_loss: 0.0966, step time: 0.3158\n",
      "35/224, train_loss: 0.1157, step time: 0.3134\n",
      "36/224, train_loss: 0.0784, step time: 0.3171\n",
      "37/224, train_loss: 0.2063, step time: 0.3882\n",
      "38/224, train_loss: 0.1645, step time: 0.3152\n",
      "39/224, train_loss: 0.1295, step time: 0.4065\n",
      "40/224, train_loss: 0.0684, step time: 0.4083\n",
      "41/224, train_loss: 0.1251, step time: 0.3818\n",
      "42/224, train_loss: 0.0711, step time: 0.3155\n",
      "43/224, train_loss: 0.1130, step time: 0.3189\n",
      "44/224, train_loss: 0.0714, step time: 0.4098\n",
      "45/224, train_loss: 0.0673, step time: 0.3166\n",
      "46/224, train_loss: 0.2609, step time: 0.3728\n",
      "47/224, train_loss: 0.1086, step time: 0.3169\n",
      "48/224, train_loss: 0.1971, step time: 0.3916\n",
      "49/224, train_loss: 0.0942, step time: 0.3793\n",
      "50/224, train_loss: 0.0686, step time: 0.3148\n",
      "51/224, train_loss: 0.0626, step time: 0.3175\n",
      "52/224, train_loss: 0.1383, step time: 0.4096\n",
      "53/224, train_loss: 0.0872, step time: 0.3956\n",
      "54/224, train_loss: 0.1071, step time: 0.3144\n",
      "55/224, train_loss: 0.0820, step time: 0.3143\n",
      "56/224, train_loss: 0.0649, step time: 0.3142\n",
      "57/224, train_loss: 0.1068, step time: 0.3120\n",
      "58/224, train_loss: 0.1001, step time: 0.3821\n",
      "59/224, train_loss: 0.0588, step time: 0.3126\n",
      "60/224, train_loss: 0.1530, step time: 0.3787\n",
      "61/224, train_loss: 0.0804, step time: 0.3708\n",
      "62/224, train_loss: 0.0555, step time: 0.3131\n",
      "63/224, train_loss: 0.1090, step time: 0.3144\n",
      "64/224, train_loss: 0.1131, step time: 0.3854\n",
      "65/224, train_loss: 0.0959, step time: 0.3133\n",
      "66/224, train_loss: 0.1232, step time: 0.3170\n",
      "67/224, train_loss: 0.1376, step time: 0.4004\n",
      "68/224, train_loss: 0.0863, step time: 0.4014\n",
      "69/224, train_loss: 0.1088, step time: 0.3165\n",
      "70/224, train_loss: 0.0921, step time: 0.3166\n",
      "71/224, train_loss: 0.1212, step time: 0.3992\n",
      "72/224, train_loss: 0.0787, step time: 0.3151\n",
      "73/224, train_loss: 0.0768, step time: 0.3180\n",
      "74/224, train_loss: 0.2745, step time: 0.3873\n",
      "75/224, train_loss: 0.1030, step time: 0.3172\n",
      "76/224, train_loss: 0.1575, step time: 0.3949\n",
      "77/224, train_loss: 0.0840, step time: 0.4010\n",
      "78/224, train_loss: 0.0612, step time: 0.3168\n",
      "79/224, train_loss: 0.0820, step time: 0.3151\n",
      "80/224, train_loss: 0.1211, step time: 0.3925\n",
      "81/224, train_loss: 0.1329, step time: 0.3146\n",
      "82/224, train_loss: 0.1143, step time: 0.3957\n",
      "83/224, train_loss: 0.1046, step time: 0.3864\n",
      "84/224, train_loss: 0.2932, step time: 0.3775\n",
      "85/224, train_loss: 0.1516, step time: 0.4019\n",
      "86/224, train_loss: 0.0898, step time: 0.3960\n",
      "87/224, train_loss: 0.2602, step time: 0.3926\n",
      "88/224, train_loss: 0.0486, step time: 0.3168\n",
      "89/224, train_loss: 0.2678, step time: 0.4004\n",
      "90/224, train_loss: 0.0716, step time: 0.3171\n",
      "91/224, train_loss: 0.1027, step time: 0.3146\n",
      "92/224, train_loss: 0.1276, step time: 0.3829\n",
      "93/224, train_loss: 0.1452, step time: 0.3902\n",
      "94/224, train_loss: 0.0549, step time: 0.3151\n",
      "95/224, train_loss: 0.0846, step time: 0.3150\n",
      "96/224, train_loss: 0.1741, step time: 0.4104\n",
      "97/224, train_loss: 0.0932, step time: 0.3152\n",
      "98/224, train_loss: 0.0876, step time: 0.3971\n",
      "99/224, train_loss: 0.2798, step time: 0.4040\n",
      "100/224, train_loss: 0.1129, step time: 0.3147\n",
      "101/224, train_loss: 0.1396, step time: 0.3912\n",
      "102/224, train_loss: 0.0775, step time: 0.3167\n",
      "103/224, train_loss: 0.1255, step time: 0.3126\n",
      "104/224, train_loss: 0.1985, step time: 0.3130\n",
      "105/224, train_loss: 0.0726, step time: 0.4005\n",
      "106/224, train_loss: 0.0572, step time: 0.3153\n",
      "107/224, train_loss: 0.0607, step time: 0.3151\n",
      "108/224, train_loss: 0.1197, step time: 0.3148\n",
      "109/224, train_loss: 0.0938, step time: 0.3820\n",
      "110/224, train_loss: 0.1201, step time: 0.3983\n",
      "111/224, train_loss: 0.0660, step time: 0.3836\n",
      "112/224, train_loss: 0.1051, step time: 0.3840\n",
      "113/224, train_loss: 0.0712, step time: 0.3153\n",
      "114/224, train_loss: 0.1461, step time: 0.3716\n",
      "115/224, train_loss: 0.0680, step time: 0.3869\n",
      "116/224, train_loss: 0.0601, step time: 0.3902\n",
      "117/224, train_loss: 0.0869, step time: 0.3916\n",
      "118/224, train_loss: 0.1510, step time: 0.3791\n",
      "119/224, train_loss: 0.0607, step time: 0.3888\n",
      "120/224, train_loss: 0.1767, step time: 0.3919\n",
      "121/224, train_loss: 0.0561, step time: 0.3145\n",
      "122/224, train_loss: 0.0932, step time: 0.4010\n",
      "123/224, train_loss: 0.0875, step time: 0.3178\n",
      "124/224, train_loss: 0.0836, step time: 0.3789\n",
      "125/224, train_loss: 0.0771, step time: 0.3147\n",
      "126/224, train_loss: 0.1482, step time: 0.3652\n",
      "127/224, train_loss: 0.0575, step time: 0.4055\n",
      "128/224, train_loss: 0.0710, step time: 0.3170\n",
      "129/224, train_loss: 0.1491, step time: 0.3823\n",
      "130/224, train_loss: 0.1119, step time: 0.3783\n",
      "131/224, train_loss: 0.1136, step time: 0.3146\n",
      "132/224, train_loss: 0.1561, step time: 0.3760\n",
      "133/224, train_loss: 0.1047, step time: 0.3149\n",
      "134/224, train_loss: 0.0667, step time: 0.3793\n",
      "135/224, train_loss: 0.1382, step time: 0.3778\n",
      "136/224, train_loss: 0.1424, step time: 0.3177\n",
      "137/224, train_loss: 0.0996, step time: 0.3137\n",
      "138/224, train_loss: 0.1023, step time: 0.3136\n",
      "139/224, train_loss: 0.1543, step time: 0.3735\n",
      "140/224, train_loss: 0.2947, step time: 0.3154\n",
      "141/224, train_loss: 0.0752, step time: 0.3141\n",
      "142/224, train_loss: 0.1272, step time: 0.3671\n",
      "143/224, train_loss: 0.0673, step time: 0.3145\n",
      "144/224, train_loss: 0.1428, step time: 0.3188\n",
      "145/224, train_loss: 0.1015, step time: 0.3137\n",
      "146/224, train_loss: 0.1057, step time: 0.4060\n",
      "147/224, train_loss: 0.0823, step time: 0.3163\n",
      "148/224, train_loss: 0.0950, step time: 0.4047\n",
      "149/224, train_loss: 0.0955, step time: 0.3184\n",
      "150/224, train_loss: 0.1766, step time: 0.3164\n",
      "151/224, train_loss: 0.0518, step time: 0.3160\n",
      "152/224, train_loss: 0.0598, step time: 0.3995\n",
      "153/224, train_loss: 0.0750, step time: 0.3154\n",
      "154/224, train_loss: 0.0626, step time: 0.3158\n",
      "155/224, train_loss: 0.2725, step time: 0.4076\n",
      "156/224, train_loss: 0.0518, step time: 0.3160\n",
      "157/224, train_loss: 0.0592, step time: 0.3700\n",
      "158/224, train_loss: 0.0712, step time: 0.3156\n",
      "159/224, train_loss: 0.1156, step time: 0.3672\n",
      "160/224, train_loss: 0.4004, step time: 0.3757\n",
      "161/224, train_loss: 0.1034, step time: 0.3186\n",
      "162/224, train_loss: 0.0726, step time: 0.3798\n",
      "163/224, train_loss: 0.0522, step time: 0.3158\n",
      "164/224, train_loss: 0.0900, step time: 0.3982\n",
      "165/224, train_loss: 0.1938, step time: 0.3158\n",
      "166/224, train_loss: 0.0810, step time: 0.3175\n",
      "167/224, train_loss: 0.0692, step time: 0.3938\n",
      "168/224, train_loss: 0.1032, step time: 0.3133\n",
      "169/224, train_loss: 0.0610, step time: 0.3884\n",
      "170/224, train_loss: 0.1184, step time: 0.3159\n",
      "171/224, train_loss: 0.0935, step time: 0.4063\n",
      "172/224, train_loss: 0.0533, step time: 0.3166\n",
      "173/224, train_loss: 0.0730, step time: 0.3158\n",
      "174/224, train_loss: 0.1124, step time: 0.3977\n",
      "175/224, train_loss: 0.1407, step time: 0.4044\n",
      "176/224, train_loss: 0.1189, step time: 0.3169\n",
      "177/224, train_loss: 0.0769, step time: 0.3803\n",
      "178/224, train_loss: 0.0926, step time: 0.3670\n",
      "179/224, train_loss: 0.0754, step time: 0.3185\n",
      "180/224, train_loss: 0.1797, step time: 0.4038\n",
      "181/224, train_loss: 0.1100, step time: 0.3832\n",
      "182/224, train_loss: 0.0859, step time: 0.3183\n",
      "183/224, train_loss: 0.1017, step time: 0.3760\n",
      "184/224, train_loss: 0.0754, step time: 0.3139\n",
      "185/224, train_loss: 0.0834, step time: 0.3836\n",
      "186/224, train_loss: 0.0974, step time: 0.3785\n",
      "187/224, train_loss: 0.0605, step time: 0.3159\n",
      "188/224, train_loss: 0.2437, step time: 0.4141\n",
      "189/224, train_loss: 0.0871, step time: 0.3769\n",
      "190/224, train_loss: 0.1049, step time: 0.3694\n",
      "191/224, train_loss: 0.0782, step time: 0.3191\n",
      "192/224, train_loss: 0.0679, step time: 0.3192\n",
      "193/224, train_loss: 0.1854, step time: 0.3822\n",
      "194/224, train_loss: 0.0877, step time: 0.3717\n",
      "195/224, train_loss: 0.2972, step time: 0.4130\n",
      "196/224, train_loss: 0.0795, step time: 0.3172\n",
      "197/224, train_loss: 0.0805, step time: 0.4074\n",
      "198/224, train_loss: 0.1085, step time: 0.3230\n",
      "199/224, train_loss: 0.1236, step time: 0.3182\n",
      "200/224, train_loss: 0.1443, step time: 0.3957\n",
      "201/224, train_loss: 0.1152, step time: 0.3167\n",
      "202/224, train_loss: 0.0405, step time: 0.4062\n",
      "203/224, train_loss: 0.0959, step time: 0.3685\n",
      "204/224, train_loss: 0.0724, step time: 0.3185\n",
      "205/224, train_loss: 0.0585, step time: 0.3179\n",
      "206/224, train_loss: 0.1156, step time: 0.3666\n",
      "207/224, train_loss: 0.0533, step time: 0.3137\n",
      "208/224, train_loss: 0.1126, step time: 0.3813\n",
      "209/224, train_loss: 0.0970, step time: 0.3916\n",
      "210/224, train_loss: 0.0645, step time: 0.3137\n",
      "211/224, train_loss: 0.0936, step time: 0.3169\n",
      "212/224, train_loss: 0.1019, step time: 0.3153\n",
      "213/224, train_loss: 0.0790, step time: 0.3980\n",
      "214/224, train_loss: 0.1013, step time: 0.4104\n",
      "215/224, train_loss: 0.0969, step time: 0.4042\n",
      "216/224, train_loss: 0.0830, step time: 0.3899\n",
      "217/224, train_loss: 0.0523, step time: 0.3153\n",
      "218/224, train_loss: 0.0801, step time: 0.3938\n",
      "219/224, train_loss: 0.0641, step time: 0.3144\n",
      "220/224, train_loss: 0.0648, step time: 0.3141\n",
      "221/224, train_loss: 0.0930, step time: 0.3157\n",
      "222/224, train_loss: 0.1444, step time: 0.3783\n",
      "223/224, train_loss: 0.2961, step time: 0.3969\n",
      "224/224, train_loss: 0.0935, step time: 0.4025\n",
      "epoch 92 average loss: 0.1145\n",
      "current epoch: 92 current mean dice: 0.7055 class1: 0.9993 class2: 0.7386 class3: 0.3785\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 92 is: 733.3463\n",
      "hello\n",
      "----------\n",
      "epoch 93/100\n",
      "1/224, train_loss: 0.0619, step time: 0.3209\n",
      "2/224, train_loss: 0.0892, step time: 0.3893\n",
      "3/224, train_loss: 0.0651, step time: 0.3143\n",
      "4/224, train_loss: 0.0640, step time: 0.3142\n",
      "5/224, train_loss: 0.0604, step time: 0.3151\n",
      "6/224, train_loss: 0.1870, step time: 0.3706\n",
      "7/224, train_loss: 0.0605, step time: 0.3175\n",
      "8/224, train_loss: 0.0759, step time: 0.4088\n",
      "9/224, train_loss: 0.0803, step time: 0.4041\n",
      "10/224, train_loss: 0.0613, step time: 0.3126\n",
      "11/224, train_loss: 0.0718, step time: 0.3177\n",
      "12/224, train_loss: 0.1063, step time: 0.3178\n",
      "13/224, train_loss: 0.1201, step time: 0.3175\n",
      "14/224, train_loss: 0.0995, step time: 0.3151\n",
      "15/224, train_loss: 0.1736, step time: 0.3172\n",
      "16/224, train_loss: 0.1958, step time: 0.3747\n",
      "17/224, train_loss: 0.0885, step time: 0.3825\n",
      "18/224, train_loss: 0.0948, step time: 0.3707\n",
      "19/224, train_loss: 0.1208, step time: 0.3655\n",
      "20/224, train_loss: 0.1078, step time: 0.4068\n",
      "21/224, train_loss: 0.0735, step time: 0.3146\n",
      "22/224, train_loss: 0.1354, step time: 0.4021\n",
      "23/224, train_loss: 0.1059, step time: 0.3719\n",
      "24/224, train_loss: 0.1005, step time: 0.3958\n",
      "25/224, train_loss: 0.0769, step time: 0.3949\n",
      "26/224, train_loss: 0.3365, step time: 0.3754\n",
      "27/224, train_loss: 0.0675, step time: 0.3146\n",
      "28/224, train_loss: 0.1650, step time: 0.3813\n",
      "29/224, train_loss: 0.1295, step time: 0.3902\n",
      "30/224, train_loss: 0.0788, step time: 0.4080\n",
      "31/224, train_loss: 0.1414, step time: 0.3894\n",
      "32/224, train_loss: 0.1785, step time: 0.3761\n",
      "33/224, train_loss: 0.1179, step time: 0.3171\n",
      "34/224, train_loss: 0.0659, step time: 0.3174\n",
      "35/224, train_loss: 0.0693, step time: 0.3915\n",
      "36/224, train_loss: 0.0418, step time: 0.3149\n",
      "37/224, train_loss: 0.0922, step time: 0.3168\n",
      "38/224, train_loss: 0.1219, step time: 0.4041\n",
      "39/224, train_loss: 0.0611, step time: 0.3128\n",
      "40/224, train_loss: 0.1702, step time: 0.3773\n",
      "41/224, train_loss: 0.1108, step time: 0.3638\n",
      "42/224, train_loss: 0.0884, step time: 0.3141\n",
      "43/224, train_loss: 0.1297, step time: 0.3981\n",
      "44/224, train_loss: 0.1508, step time: 0.4019\n",
      "45/224, train_loss: 0.2729, step time: 0.3147\n",
      "46/224, train_loss: 0.1164, step time: 0.3793\n",
      "47/224, train_loss: 0.1186, step time: 0.3925\n",
      "48/224, train_loss: 0.1238, step time: 0.3693\n",
      "49/224, train_loss: 0.0435, step time: 0.4068\n",
      "50/224, train_loss: 0.0959, step time: 0.3148\n",
      "51/224, train_loss: 0.0875, step time: 0.3171\n",
      "52/224, train_loss: 0.0827, step time: 0.3150\n",
      "53/224, train_loss: 0.0753, step time: 0.3143\n",
      "54/224, train_loss: 0.3168, step time: 0.3816\n",
      "55/224, train_loss: 0.0495, step time: 0.3152\n",
      "56/224, train_loss: 0.0555, step time: 0.3154\n",
      "57/224, train_loss: 0.0877, step time: 0.3129\n",
      "58/224, train_loss: 0.0704, step time: 0.3171\n",
      "59/224, train_loss: 0.0736, step time: 0.3143\n",
      "60/224, train_loss: 0.1464, step time: 0.3937\n",
      "61/224, train_loss: 0.1220, step time: 0.3145\n",
      "62/224, train_loss: 0.0916, step time: 0.3144\n",
      "63/224, train_loss: 0.0825, step time: 0.4006\n",
      "64/224, train_loss: 0.0458, step time: 0.3912\n",
      "65/224, train_loss: 0.1838, step time: 0.3842\n",
      "66/224, train_loss: 0.2764, step time: 0.3990\n",
      "67/224, train_loss: 0.0578, step time: 0.3145\n",
      "68/224, train_loss: 0.1053, step time: 0.3872\n",
      "69/224, train_loss: 0.0950, step time: 0.3153\n",
      "70/224, train_loss: 0.0545, step time: 0.3129\n",
      "71/224, train_loss: 0.1346, step time: 0.3931\n",
      "72/224, train_loss: 0.1737, step time: 0.3706\n",
      "73/224, train_loss: 0.1386, step time: 0.3133\n",
      "74/224, train_loss: 0.1100, step time: 0.3789\n",
      "75/224, train_loss: 0.1256, step time: 0.3152\n",
      "76/224, train_loss: 0.1326, step time: 0.3708\n",
      "77/224, train_loss: 0.1153, step time: 0.3150\n",
      "78/224, train_loss: 0.1546, step time: 0.3173\n",
      "79/224, train_loss: 0.0901, step time: 0.3141\n",
      "80/224, train_loss: 0.0692, step time: 0.3155\n",
      "81/224, train_loss: 0.2315, step time: 0.3634\n",
      "82/224, train_loss: 0.0610, step time: 0.3152\n",
      "83/224, train_loss: 0.2864, step time: 0.3977\n",
      "84/224, train_loss: 0.0765, step time: 0.3124\n",
      "85/224, train_loss: 0.3013, step time: 0.4031\n",
      "86/224, train_loss: 0.0739, step time: 0.3151\n",
      "87/224, train_loss: 0.0878, step time: 0.3154\n",
      "88/224, train_loss: 0.0906, step time: 0.3150\n",
      "89/224, train_loss: 0.1083, step time: 0.3800\n",
      "90/224, train_loss: 0.0579, step time: 0.3172\n",
      "91/224, train_loss: 0.0831, step time: 0.3153\n",
      "92/224, train_loss: 0.1123, step time: 0.3175\n",
      "93/224, train_loss: 0.0947, step time: 0.3677\n",
      "94/224, train_loss: 0.1014, step time: 0.3694\n",
      "95/224, train_loss: 0.1100, step time: 0.3176\n",
      "96/224, train_loss: 0.1025, step time: 0.3150\n",
      "97/224, train_loss: 0.1369, step time: 0.3175\n",
      "98/224, train_loss: 0.0972, step time: 0.3882\n",
      "99/224, train_loss: 0.1375, step time: 0.4065\n",
      "100/224, train_loss: 0.2201, step time: 0.3872\n",
      "101/224, train_loss: 0.1243, step time: 0.3154\n",
      "102/224, train_loss: 0.0741, step time: 0.3154\n",
      "103/224, train_loss: 0.0920, step time: 0.3739\n",
      "104/224, train_loss: 0.0558, step time: 0.3754\n",
      "105/224, train_loss: 0.1361, step time: 0.3872\n",
      "106/224, train_loss: 0.1773, step time: 0.3983\n",
      "107/224, train_loss: 0.1169, step time: 0.3151\n",
      "108/224, train_loss: 0.0786, step time: 0.3177\n",
      "109/224, train_loss: 0.1793, step time: 0.3834\n",
      "110/224, train_loss: 0.0672, step time: 0.3147\n",
      "111/224, train_loss: 0.1527, step time: 0.3818\n",
      "112/224, train_loss: 0.0360, step time: 0.3177\n",
      "113/224, train_loss: 0.1004, step time: 0.3758\n",
      "114/224, train_loss: 0.0835, step time: 0.4061\n",
      "115/224, train_loss: 0.0931, step time: 0.3766\n",
      "116/224, train_loss: 0.1376, step time: 0.3728\n",
      "117/224, train_loss: 0.1385, step time: 0.3826\n",
      "118/224, train_loss: 0.1758, step time: 0.3148\n",
      "119/224, train_loss: 0.0858, step time: 0.3167\n",
      "120/224, train_loss: 0.0888, step time: 0.3145\n",
      "121/224, train_loss: 0.0733, step time: 0.3146\n",
      "122/224, train_loss: 0.1944, step time: 0.3749\n",
      "123/224, train_loss: 0.1153, step time: 0.3148\n",
      "124/224, train_loss: 0.0905, step time: 0.3144\n",
      "125/224, train_loss: 0.1009, step time: 0.3144\n",
      "126/224, train_loss: 0.0422, step time: 0.3148\n",
      "127/224, train_loss: 0.0803, step time: 0.3128\n",
      "128/224, train_loss: 0.2686, step time: 0.3129\n",
      "129/224, train_loss: 0.1788, step time: 0.3174\n",
      "130/224, train_loss: 0.0731, step time: 0.3152\n",
      "131/224, train_loss: 0.1291, step time: 0.3823\n",
      "132/224, train_loss: 0.1097, step time: 0.3931\n",
      "133/224, train_loss: 0.0901, step time: 0.3146\n",
      "134/224, train_loss: 0.3176, step time: 0.3154\n",
      "135/224, train_loss: 0.2392, step time: 0.4104\n",
      "136/224, train_loss: 0.1670, step time: 0.3992\n",
      "137/224, train_loss: 0.0711, step time: 0.3899\n",
      "138/224, train_loss: 0.0856, step time: 0.3147\n",
      "139/224, train_loss: 0.0868, step time: 0.3173\n",
      "140/224, train_loss: 0.1177, step time: 0.3743\n",
      "141/224, train_loss: 0.1171, step time: 0.3678\n",
      "142/224, train_loss: 0.0846, step time: 0.3134\n",
      "143/224, train_loss: 0.1088, step time: 0.4077\n",
      "144/224, train_loss: 0.1189, step time: 0.3839\n",
      "145/224, train_loss: 0.0677, step time: 0.3190\n",
      "146/224, train_loss: 0.1326, step time: 0.3194\n",
      "147/224, train_loss: 0.0739, step time: 0.3184\n",
      "148/224, train_loss: 0.1215, step time: 0.3945\n",
      "149/224, train_loss: 0.1395, step time: 0.4148\n",
      "150/224, train_loss: 0.2951, step time: 0.4002\n",
      "151/224, train_loss: 0.0797, step time: 0.3186\n",
      "152/224, train_loss: 0.0938, step time: 0.3184\n",
      "153/224, train_loss: 0.2058, step time: 0.3682\n",
      "154/224, train_loss: 0.0695, step time: 0.4031\n",
      "155/224, train_loss: 0.0729, step time: 0.3141\n",
      "156/224, train_loss: 0.0847, step time: 0.3158\n",
      "157/224, train_loss: 0.0728, step time: 0.3158\n",
      "158/224, train_loss: 0.1244, step time: 0.3886\n",
      "159/224, train_loss: 0.1385, step time: 0.3652\n",
      "160/224, train_loss: 0.0899, step time: 0.3905\n",
      "161/224, train_loss: 0.0811, step time: 0.3151\n",
      "162/224, train_loss: 0.1133, step time: 0.3885\n",
      "163/224, train_loss: 0.0860, step time: 0.3147\n",
      "164/224, train_loss: 0.0826, step time: 0.3688\n",
      "165/224, train_loss: 0.1422, step time: 0.3958\n",
      "166/224, train_loss: 0.0730, step time: 0.3173\n",
      "167/224, train_loss: 0.0652, step time: 0.3147\n",
      "168/224, train_loss: 0.0809, step time: 0.3151\n",
      "169/224, train_loss: 0.1120, step time: 0.3704\n",
      "170/224, train_loss: 0.1175, step time: 0.4021\n",
      "171/224, train_loss: 0.1467, step time: 0.4127\n",
      "172/224, train_loss: 0.0632, step time: 0.3716\n",
      "173/224, train_loss: 0.1340, step time: 0.3141\n",
      "174/224, train_loss: 0.1853, step time: 0.3892\n",
      "175/224, train_loss: 0.2350, step time: 0.3701\n",
      "176/224, train_loss: 0.1053, step time: 0.3730\n",
      "177/224, train_loss: 0.0783, step time: 0.4002\n",
      "178/224, train_loss: 0.0927, step time: 0.3150\n",
      "179/224, train_loss: 0.1286, step time: 0.3793\n",
      "180/224, train_loss: 0.4087, step time: 0.3700\n",
      "181/224, train_loss: 0.1023, step time: 0.3930\n",
      "182/224, train_loss: 0.0917, step time: 0.3154\n",
      "183/224, train_loss: 0.0561, step time: 0.3172\n",
      "184/224, train_loss: 0.1126, step time: 0.3145\n",
      "185/224, train_loss: 0.0850, step time: 0.3708\n",
      "186/224, train_loss: 0.3779, step time: 0.3736\n",
      "187/224, train_loss: 0.1074, step time: 0.3711\n",
      "188/224, train_loss: 0.0651, step time: 0.3174\n",
      "189/224, train_loss: 0.0809, step time: 0.3168\n",
      "190/224, train_loss: 0.1062, step time: 0.4034\n",
      "191/224, train_loss: 0.1128, step time: 0.3818\n",
      "192/224, train_loss: 0.2708, step time: 0.3733\n",
      "193/224, train_loss: 0.1498, step time: 0.3936\n",
      "194/224, train_loss: 0.0531, step time: 0.3144\n",
      "195/224, train_loss: 0.0886, step time: 0.3145\n",
      "196/224, train_loss: 0.0913, step time: 0.3173\n",
      "197/224, train_loss: 0.0990, step time: 0.3152\n",
      "198/224, train_loss: 0.0435, step time: 0.3131\n",
      "199/224, train_loss: 0.0963, step time: 0.3171\n",
      "200/224, train_loss: 0.0775, step time: 0.3122\n",
      "201/224, train_loss: 0.0672, step time: 0.3886\n",
      "202/224, train_loss: 0.0855, step time: 0.3859\n",
      "203/224, train_loss: 0.0716, step time: 0.3156\n",
      "204/224, train_loss: 0.0457, step time: 0.4105\n",
      "205/224, train_loss: 0.1033, step time: 0.3160\n",
      "206/224, train_loss: 0.0956, step time: 0.3668\n",
      "207/224, train_loss: 0.0625, step time: 0.3971\n",
      "208/224, train_loss: 0.0800, step time: 0.3148\n",
      "209/224, train_loss: 0.1056, step time: 0.4074\n",
      "210/224, train_loss: 0.0561, step time: 0.3124\n",
      "211/224, train_loss: 0.1474, step time: 0.3169\n",
      "212/224, train_loss: 0.0667, step time: 0.3124\n",
      "213/224, train_loss: 0.0573, step time: 0.3141\n",
      "214/224, train_loss: 0.1110, step time: 0.3732\n",
      "215/224, train_loss: 0.0735, step time: 0.4001\n",
      "216/224, train_loss: 0.0750, step time: 0.3131\n",
      "217/224, train_loss: 0.0631, step time: 0.3675\n",
      "218/224, train_loss: 0.0715, step time: 0.4064\n",
      "219/224, train_loss: 0.2390, step time: 0.3988\n",
      "220/224, train_loss: 0.1091, step time: 0.3146\n",
      "221/224, train_loss: 0.0900, step time: 0.3978\n",
      "222/224, train_loss: 0.1205, step time: 0.3702\n",
      "223/224, train_loss: 0.0718, step time: 0.4055\n",
      "224/224, train_loss: 0.1306, step time: 0.4055\n",
      "epoch 93 average loss: 0.1145\n",
      "current epoch: 93 current mean dice: 0.7203 class1: 0.9994 class2: 0.7444 class3: 0.4170\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 93 is: 787.6530\n",
      "hello\n",
      "----------\n",
      "epoch 94/100\n",
      "1/224, train_loss: 0.2067, step time: 0.4005\n",
      "2/224, train_loss: 0.1044, step time: 0.3152\n",
      "3/224, train_loss: 0.0840, step time: 0.3158\n",
      "4/224, train_loss: 0.1701, step time: 0.3179\n",
      "5/224, train_loss: 0.1061, step time: 0.3776\n",
      "6/224, train_loss: 0.2656, step time: 0.3703\n",
      "7/224, train_loss: 0.0834, step time: 0.3667\n",
      "8/224, train_loss: 0.1820, step time: 0.3919\n",
      "9/224, train_loss: 0.0652, step time: 0.3180\n",
      "10/224, train_loss: 0.0874, step time: 0.3802\n",
      "11/224, train_loss: 0.1033, step time: 0.3175\n",
      "12/224, train_loss: 0.1740, step time: 0.4159\n",
      "13/224, train_loss: 0.1505, step time: 0.3160\n",
      "14/224, train_loss: 0.0945, step time: 0.3784\n",
      "15/224, train_loss: 0.1612, step time: 0.4120\n",
      "16/224, train_loss: 0.1616, step time: 0.4102\n",
      "17/224, train_loss: 0.1284, step time: 0.3991\n",
      "18/224, train_loss: 0.0947, step time: 0.3830\n",
      "19/224, train_loss: 0.0837, step time: 0.4107\n",
      "20/224, train_loss: 0.0649, step time: 0.3156\n",
      "21/224, train_loss: 0.1801, step time: 0.3771\n",
      "22/224, train_loss: 0.0715, step time: 0.3162\n",
      "23/224, train_loss: 0.0682, step time: 0.3175\n",
      "24/224, train_loss: 0.1042, step time: 0.3902\n",
      "25/224, train_loss: 0.0402, step time: 0.3875\n",
      "26/224, train_loss: 0.1132, step time: 0.3176\n",
      "27/224, train_loss: 0.1457, step time: 0.3717\n",
      "28/224, train_loss: 0.2786, step time: 0.3852\n",
      "29/224, train_loss: 0.2250, step time: 0.3843\n",
      "30/224, train_loss: 0.0443, step time: 0.3149\n",
      "31/224, train_loss: 0.0898, step time: 0.3159\n",
      "32/224, train_loss: 0.1988, step time: 0.4061\n",
      "33/224, train_loss: 0.0923, step time: 0.3754\n",
      "34/224, train_loss: 0.0788, step time: 0.3133\n",
      "35/224, train_loss: 0.0861, step time: 0.3146\n",
      "36/224, train_loss: 0.0857, step time: 0.3169\n",
      "37/224, train_loss: 0.0897, step time: 0.3147\n",
      "38/224, train_loss: 0.0495, step time: 0.3154\n",
      "39/224, train_loss: 0.0926, step time: 0.3149\n",
      "40/224, train_loss: 0.0721, step time: 0.3182\n",
      "41/224, train_loss: 0.0675, step time: 0.3175\n",
      "42/224, train_loss: 0.0690, step time: 0.3149\n",
      "43/224, train_loss: 0.1418, step time: 0.3859\n",
      "44/224, train_loss: 0.1228, step time: 0.3758\n",
      "45/224, train_loss: 0.0806, step time: 0.3139\n",
      "46/224, train_loss: 0.0986, step time: 0.3846\n",
      "47/224, train_loss: 0.2729, step time: 0.3180\n",
      "48/224, train_loss: 0.0663, step time: 0.3987\n",
      "49/224, train_loss: 0.0603, step time: 0.3145\n",
      "50/224, train_loss: 0.0749, step time: 0.3172\n",
      "51/224, train_loss: 0.0893, step time: 0.3146\n",
      "52/224, train_loss: 0.1010, step time: 0.3867\n",
      "53/224, train_loss: 0.1593, step time: 0.4039\n",
      "54/224, train_loss: 0.0796, step time: 0.3179\n",
      "55/224, train_loss: 0.2670, step time: 0.3148\n",
      "56/224, train_loss: 0.0504, step time: 0.3153\n",
      "57/224, train_loss: 0.0686, step time: 0.3159\n",
      "58/224, train_loss: 0.0710, step time: 0.3748\n",
      "59/224, train_loss: 0.0740, step time: 0.3185\n",
      "60/224, train_loss: 0.0747, step time: 0.3179\n",
      "61/224, train_loss: 0.1448, step time: 0.3895\n",
      "62/224, train_loss: 0.0910, step time: 0.3148\n",
      "63/224, train_loss: 0.0945, step time: 0.3178\n",
      "64/224, train_loss: 0.1274, step time: 0.3156\n",
      "65/224, train_loss: 0.0903, step time: 0.3134\n",
      "66/224, train_loss: 0.0786, step time: 0.4046\n",
      "67/224, train_loss: 0.1077, step time: 0.3177\n",
      "68/224, train_loss: 0.0766, step time: 0.3149\n",
      "69/224, train_loss: 0.1030, step time: 0.4063\n",
      "70/224, train_loss: 0.0743, step time: 0.3154\n",
      "71/224, train_loss: 0.2811, step time: 0.3149\n",
      "72/224, train_loss: 0.0890, step time: 0.3178\n",
      "73/224, train_loss: 0.0913, step time: 0.3881\n",
      "74/224, train_loss: 0.0886, step time: 0.3177\n",
      "75/224, train_loss: 0.1923, step time: 0.3972\n",
      "76/224, train_loss: 0.1221, step time: 0.3711\n",
      "77/224, train_loss: 0.0798, step time: 0.3157\n",
      "78/224, train_loss: 0.0822, step time: 0.3152\n",
      "79/224, train_loss: 0.1079, step time: 0.3176\n",
      "80/224, train_loss: 0.1756, step time: 0.3182\n",
      "81/224, train_loss: 0.0742, step time: 0.3160\n",
      "82/224, train_loss: 0.1673, step time: 0.3720\n",
      "83/224, train_loss: 0.1087, step time: 0.3158\n",
      "84/224, train_loss: 0.1640, step time: 0.3947\n",
      "85/224, train_loss: 0.0888, step time: 0.4021\n",
      "86/224, train_loss: 0.1274, step time: 0.3990\n",
      "87/224, train_loss: 0.0935, step time: 0.3149\n",
      "88/224, train_loss: 0.0887, step time: 0.3176\n",
      "89/224, train_loss: 0.0936, step time: 0.3878\n",
      "90/224, train_loss: 0.1136, step time: 0.3913\n",
      "91/224, train_loss: 0.0542, step time: 0.4125\n",
      "92/224, train_loss: 0.0849, step time: 0.3172\n",
      "93/224, train_loss: 0.0650, step time: 0.3127\n",
      "94/224, train_loss: 0.1089, step time: 0.3147\n",
      "95/224, train_loss: 0.1036, step time: 0.3159\n",
      "96/224, train_loss: 0.2040, step time: 0.3972\n",
      "97/224, train_loss: 0.0655, step time: 0.3148\n",
      "98/224, train_loss: 0.0823, step time: 0.3788\n",
      "99/224, train_loss: 0.1097, step time: 0.3172\n",
      "100/224, train_loss: 0.0649, step time: 0.3873\n",
      "101/224, train_loss: 0.3075, step time: 0.3826\n",
      "102/224, train_loss: 0.2929, step time: 0.3922\n",
      "103/224, train_loss: 0.1016, step time: 0.3694\n",
      "104/224, train_loss: 0.0590, step time: 0.3153\n",
      "105/224, train_loss: 0.0523, step time: 0.3125\n",
      "106/224, train_loss: 0.3192, step time: 0.4084\n",
      "107/224, train_loss: 0.0389, step time: 0.3754\n",
      "108/224, train_loss: 0.0446, step time: 0.3171\n",
      "109/224, train_loss: 0.1029, step time: 0.3174\n",
      "110/224, train_loss: 0.1102, step time: 0.3133\n",
      "111/224, train_loss: 0.0618, step time: 0.3158\n",
      "112/224, train_loss: 0.1643, step time: 0.4042\n",
      "113/224, train_loss: 0.0771, step time: 0.3180\n",
      "114/224, train_loss: 0.0826, step time: 0.3177\n",
      "115/224, train_loss: 0.1558, step time: 0.3991\n",
      "116/224, train_loss: 0.1067, step time: 0.3125\n",
      "117/224, train_loss: 0.1296, step time: 0.3745\n",
      "118/224, train_loss: 0.1736, step time: 0.4046\n",
      "119/224, train_loss: 0.0967, step time: 0.3158\n",
      "120/224, train_loss: 0.1112, step time: 0.3130\n",
      "121/224, train_loss: 0.2378, step time: 0.4118\n",
      "122/224, train_loss: 0.1329, step time: 0.3821\n",
      "123/224, train_loss: 0.1102, step time: 0.3151\n",
      "124/224, train_loss: 0.1874, step time: 0.3938\n",
      "125/224, train_loss: 0.2646, step time: 0.3153\n",
      "126/224, train_loss: 0.1033, step time: 0.3135\n",
      "127/224, train_loss: 0.1042, step time: 0.3160\n",
      "128/224, train_loss: 0.2474, step time: 0.3812\n",
      "129/224, train_loss: 0.0597, step time: 0.3143\n",
      "130/224, train_loss: 0.1075, step time: 0.4048\n",
      "131/224, train_loss: 0.0991, step time: 0.3146\n",
      "132/224, train_loss: 0.1770, step time: 0.3809\n",
      "133/224, train_loss: 0.0745, step time: 0.3707\n",
      "134/224, train_loss: 0.0559, step time: 0.3161\n",
      "135/224, train_loss: 0.2674, step time: 0.4011\n",
      "136/224, train_loss: 0.2955, step time: 0.3921\n",
      "137/224, train_loss: 0.0548, step time: 0.3171\n",
      "138/224, train_loss: 0.2407, step time: 0.3696\n",
      "139/224, train_loss: 0.0665, step time: 0.3164\n",
      "140/224, train_loss: 0.0714, step time: 0.3718\n",
      "141/224, train_loss: 0.0525, step time: 0.3148\n",
      "142/224, train_loss: 0.0768, step time: 0.3133\n",
      "143/224, train_loss: 0.2610, step time: 0.3770\n",
      "144/224, train_loss: 0.1017, step time: 0.3983\n",
      "145/224, train_loss: 0.1149, step time: 0.3145\n",
      "146/224, train_loss: 0.0765, step time: 0.3123\n",
      "147/224, train_loss: 0.0493, step time: 0.4068\n",
      "148/224, train_loss: 0.0867, step time: 0.3154\n",
      "149/224, train_loss: 0.0430, step time: 0.3148\n",
      "150/224, train_loss: 0.0909, step time: 0.3166\n",
      "151/224, train_loss: 0.1179, step time: 0.3143\n",
      "152/224, train_loss: 0.0706, step time: 0.3166\n",
      "153/224, train_loss: 0.0729, step time: 0.4096\n",
      "154/224, train_loss: 0.1472, step time: 0.3971\n",
      "155/224, train_loss: 0.1107, step time: 0.3153\n",
      "156/224, train_loss: 0.1255, step time: 0.3148\n",
      "157/224, train_loss: 0.0568, step time: 0.3905\n",
      "158/224, train_loss: 0.1489, step time: 0.4027\n",
      "159/224, train_loss: 0.1403, step time: 0.3966\n",
      "160/224, train_loss: 0.0787, step time: 0.3148\n",
      "161/224, train_loss: 0.0710, step time: 0.3154\n",
      "162/224, train_loss: 0.0723, step time: 0.3166\n",
      "163/224, train_loss: 0.0756, step time: 0.3134\n",
      "164/224, train_loss: 0.0770, step time: 0.3169\n",
      "165/224, train_loss: 0.0874, step time: 0.3143\n",
      "166/224, train_loss: 0.0652, step time: 0.3121\n",
      "167/224, train_loss: 0.1069, step time: 0.3140\n",
      "168/224, train_loss: 0.0899, step time: 0.3141\n",
      "169/224, train_loss: 0.1992, step time: 0.3697\n",
      "170/224, train_loss: 0.1168, step time: 0.3976\n",
      "171/224, train_loss: 0.0785, step time: 0.3123\n",
      "172/224, train_loss: 0.0570, step time: 0.3740\n",
      "173/224, train_loss: 0.1678, step time: 0.3680\n",
      "174/224, train_loss: 0.1294, step time: 0.3714\n",
      "175/224, train_loss: 0.0751, step time: 0.3128\n",
      "176/224, train_loss: 0.0932, step time: 0.3922\n",
      "177/224, train_loss: 0.1032, step time: 0.3131\n",
      "178/224, train_loss: 0.1165, step time: 0.3145\n",
      "179/224, train_loss: 0.0670, step time: 0.3141\n",
      "180/224, train_loss: 0.1048, step time: 0.3141\n",
      "181/224, train_loss: 0.0662, step time: 0.3925\n",
      "182/224, train_loss: 0.0573, step time: 0.3143\n",
      "183/224, train_loss: 0.0999, step time: 0.3141\n",
      "184/224, train_loss: 0.1294, step time: 0.3167\n",
      "185/224, train_loss: 0.1061, step time: 0.3142\n",
      "186/224, train_loss: 0.1702, step time: 0.4068\n",
      "187/224, train_loss: 0.1185, step time: 0.3155\n",
      "188/224, train_loss: 0.2042, step time: 0.3828\n",
      "189/224, train_loss: 0.0434, step time: 0.4012\n",
      "190/224, train_loss: 0.0637, step time: 0.3144\n",
      "191/224, train_loss: 0.0766, step time: 0.3142\n",
      "192/224, train_loss: 0.0915, step time: 0.3163\n",
      "193/224, train_loss: 0.0797, step time: 0.3171\n",
      "194/224, train_loss: 0.0734, step time: 0.3155\n",
      "195/224, train_loss: 0.0657, step time: 0.3176\n",
      "196/224, train_loss: 0.1284, step time: 0.3996\n",
      "197/224, train_loss: 0.3016, step time: 0.3723\n",
      "198/224, train_loss: 0.1141, step time: 0.3670\n",
      "199/224, train_loss: 0.0621, step time: 0.3134\n",
      "200/224, train_loss: 0.1255, step time: 0.3750\n",
      "201/224, train_loss: 0.0826, step time: 0.3783\n",
      "202/224, train_loss: 0.0863, step time: 0.3171\n",
      "203/224, train_loss: 0.0964, step time: 0.3168\n",
      "204/224, train_loss: 0.0396, step time: 0.3163\n",
      "205/224, train_loss: 0.0833, step time: 0.3140\n",
      "206/224, train_loss: 0.0654, step time: 0.3986\n",
      "207/224, train_loss: 0.1011, step time: 0.3145\n",
      "208/224, train_loss: 0.1932, step time: 0.4089\n",
      "209/224, train_loss: 0.0732, step time: 0.3170\n",
      "210/224, train_loss: 0.1368, step time: 0.3716\n",
      "211/224, train_loss: 0.1021, step time: 0.3672\n",
      "212/224, train_loss: 0.0865, step time: 0.3956\n",
      "213/224, train_loss: 0.1455, step time: 0.4036\n",
      "214/224, train_loss: 0.0922, step time: 0.3152\n",
      "215/224, train_loss: 0.0678, step time: 0.3871\n",
      "216/224, train_loss: 0.1200, step time: 0.3787\n",
      "217/224, train_loss: 0.1467, step time: 0.4120\n",
      "218/224, train_loss: 0.0813, step time: 0.3829\n",
      "219/224, train_loss: 0.1215, step time: 0.3810\n",
      "220/224, train_loss: 0.0958, step time: 0.3173\n",
      "221/224, train_loss: 0.1005, step time: 0.4003\n",
      "222/224, train_loss: 0.0852, step time: 0.3648\n",
      "223/224, train_loss: 0.1029, step time: 0.3142\n",
      "224/224, train_loss: 0.0776, step time: 0.3142\n",
      "epoch 94 average loss: 0.1130\n",
      "current epoch: 94 current mean dice: 0.7189 class1: 0.9994 class2: 0.7484 class3: 0.4091\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 94 is: 666.4877\n",
      "hello\n",
      "----------\n",
      "epoch 95/100\n",
      "1/224, train_loss: 0.0726, step time: 0.3145\n",
      "2/224, train_loss: 0.0745, step time: 0.3146\n",
      "3/224, train_loss: 0.0595, step time: 0.3804\n",
      "4/224, train_loss: 0.1405, step time: 0.3895\n",
      "5/224, train_loss: 0.0625, step time: 0.3930\n",
      "6/224, train_loss: 0.0702, step time: 0.3169\n",
      "7/224, train_loss: 0.1041, step time: 0.3980\n",
      "8/224, train_loss: 0.2136, step time: 0.3666\n",
      "9/224, train_loss: 0.0588, step time: 0.3153\n",
      "10/224, train_loss: 0.0886, step time: 0.3122\n",
      "11/224, train_loss: 0.0646, step time: 0.3169\n",
      "12/224, train_loss: 0.1110, step time: 0.3181\n",
      "13/224, train_loss: 0.1809, step time: 0.3145\n",
      "14/224, train_loss: 0.0577, step time: 0.3125\n",
      "15/224, train_loss: 0.1549, step time: 0.4032\n",
      "16/224, train_loss: 0.1064, step time: 0.3120\n",
      "17/224, train_loss: 0.1095, step time: 0.3646\n",
      "18/224, train_loss: 0.2839, step time: 0.3166\n",
      "19/224, train_loss: 0.0950, step time: 0.3145\n",
      "20/224, train_loss: 0.1359, step time: 0.4062\n",
      "21/224, train_loss: 0.0599, step time: 0.3123\n",
      "22/224, train_loss: 0.1779, step time: 0.4011\n",
      "23/224, train_loss: 0.1237, step time: 0.3177\n",
      "24/224, train_loss: 0.0822, step time: 0.4043\n",
      "25/224, train_loss: 0.0879, step time: 0.3142\n",
      "26/224, train_loss: 0.0811, step time: 0.3144\n",
      "27/224, train_loss: 0.0749, step time: 0.4015\n",
      "28/224, train_loss: 0.0861, step time: 0.3142\n",
      "29/224, train_loss: 0.1086, step time: 0.3150\n",
      "30/224, train_loss: 0.1189, step time: 0.4125\n",
      "31/224, train_loss: 0.1057, step time: 0.3698\n",
      "32/224, train_loss: 0.1025, step time: 0.3173\n",
      "33/224, train_loss: 0.0474, step time: 0.3170\n",
      "34/224, train_loss: 0.0721, step time: 0.3141\n",
      "35/224, train_loss: 0.0725, step time: 0.3141\n",
      "36/224, train_loss: 0.0603, step time: 0.3121\n",
      "37/224, train_loss: 0.0770, step time: 0.3126\n",
      "38/224, train_loss: 0.0982, step time: 0.3654\n",
      "39/224, train_loss: 0.1379, step time: 0.3937\n",
      "40/224, train_loss: 0.1840, step time: 0.3853\n",
      "41/224, train_loss: 0.1328, step time: 0.3777\n",
      "42/224, train_loss: 0.0495, step time: 0.3764\n",
      "43/224, train_loss: 0.0405, step time: 0.3899\n",
      "44/224, train_loss: 0.0596, step time: 0.3130\n",
      "45/224, train_loss: 0.1178, step time: 0.3123\n",
      "46/224, train_loss: 0.2607, step time: 0.3173\n",
      "47/224, train_loss: 0.1490, step time: 0.3142\n",
      "48/224, train_loss: 0.1341, step time: 0.3149\n",
      "49/224, train_loss: 0.0510, step time: 0.3148\n",
      "50/224, train_loss: 0.0611, step time: 0.3166\n",
      "51/224, train_loss: 0.0615, step time: 0.3784\n",
      "52/224, train_loss: 0.0929, step time: 0.3949\n",
      "53/224, train_loss: 0.0813, step time: 0.3777\n",
      "54/224, train_loss: 0.0519, step time: 0.3123\n",
      "55/224, train_loss: 0.0720, step time: 0.3166\n",
      "56/224, train_loss: 0.0945, step time: 0.3147\n",
      "57/224, train_loss: 0.1069, step time: 0.3139\n",
      "58/224, train_loss: 0.0635, step time: 0.3713\n",
      "59/224, train_loss: 0.1338, step time: 0.4020\n",
      "60/224, train_loss: 0.1017, step time: 0.3133\n",
      "61/224, train_loss: 0.0828, step time: 0.3871\n",
      "62/224, train_loss: 0.0842, step time: 0.3967\n",
      "63/224, train_loss: 0.0792, step time: 0.3147\n",
      "64/224, train_loss: 0.0609, step time: 0.3674\n",
      "65/224, train_loss: 0.1279, step time: 0.3151\n",
      "66/224, train_loss: 0.0530, step time: 0.3840\n",
      "67/224, train_loss: 0.1781, step time: 0.3974\n",
      "68/224, train_loss: 0.1010, step time: 0.3150\n",
      "69/224, train_loss: 0.0512, step time: 0.3149\n",
      "70/224, train_loss: 0.0825, step time: 0.3152\n",
      "71/224, train_loss: 0.1596, step time: 0.3935\n",
      "72/224, train_loss: 0.0937, step time: 0.3883\n",
      "73/224, train_loss: 0.0394, step time: 0.3979\n",
      "74/224, train_loss: 0.0902, step time: 0.3125\n",
      "75/224, train_loss: 0.1171, step time: 0.3947\n",
      "76/224, train_loss: 0.1672, step time: 0.3707\n",
      "77/224, train_loss: 0.0740, step time: 0.3959\n",
      "78/224, train_loss: 0.0746, step time: 0.3151\n",
      "79/224, train_loss: 0.1026, step time: 0.3704\n",
      "80/224, train_loss: 0.0817, step time: 0.3144\n",
      "81/224, train_loss: 0.1705, step time: 0.3820\n",
      "82/224, train_loss: 0.0756, step time: 0.3122\n",
      "83/224, train_loss: 0.0735, step time: 0.3142\n",
      "84/224, train_loss: 0.0846, step time: 0.3694\n",
      "85/224, train_loss: 0.1365, step time: 0.3687\n",
      "86/224, train_loss: 0.1825, step time: 0.3718\n",
      "87/224, train_loss: 0.0868, step time: 0.3178\n",
      "88/224, train_loss: 0.0798, step time: 0.4070\n",
      "89/224, train_loss: 0.1330, step time: 0.3915\n",
      "90/224, train_loss: 0.0863, step time: 0.4080\n",
      "91/224, train_loss: 0.0835, step time: 0.3169\n",
      "92/224, train_loss: 0.0890, step time: 0.3174\n",
      "93/224, train_loss: 0.0803, step time: 0.4028\n",
      "94/224, train_loss: 0.1597, step time: 0.3147\n",
      "95/224, train_loss: 0.1321, step time: 0.3148\n",
      "96/224, train_loss: 0.1035, step time: 0.3156\n",
      "97/224, train_loss: 0.1650, step time: 0.4022\n",
      "98/224, train_loss: 0.1405, step time: 0.3995\n",
      "99/224, train_loss: 0.0727, step time: 0.3176\n",
      "100/224, train_loss: 0.0724, step time: 0.3151\n",
      "101/224, train_loss: 0.0903, step time: 0.3703\n",
      "102/224, train_loss: 0.2923, step time: 0.3916\n",
      "103/224, train_loss: 0.0835, step time: 0.3170\n",
      "104/224, train_loss: 0.0619, step time: 0.3948\n",
      "105/224, train_loss: 0.1039, step time: 0.3707\n",
      "106/224, train_loss: 0.0825, step time: 0.3148\n",
      "107/224, train_loss: 0.0552, step time: 0.3127\n",
      "108/224, train_loss: 0.1113, step time: 0.3124\n",
      "109/224, train_loss: 0.0809, step time: 0.3148\n",
      "110/224, train_loss: 0.1232, step time: 0.3964\n",
      "111/224, train_loss: 0.0708, step time: 0.3147\n",
      "112/224, train_loss: 0.0568, step time: 0.3149\n",
      "113/224, train_loss: 0.0756, step time: 0.3170\n",
      "114/224, train_loss: 0.1721, step time: 0.3129\n",
      "115/224, train_loss: 0.0832, step time: 0.3144\n",
      "116/224, train_loss: 0.0650, step time: 0.3171\n",
      "117/224, train_loss: 0.1403, step time: 0.3690\n",
      "118/224, train_loss: 0.0801, step time: 0.4012\n",
      "119/224, train_loss: 0.0751, step time: 0.3793\n",
      "120/224, train_loss: 0.0977, step time: 0.3997\n",
      "121/224, train_loss: 0.0998, step time: 0.3914\n",
      "122/224, train_loss: 0.1373, step time: 0.3703\n",
      "123/224, train_loss: 0.1889, step time: 0.3136\n",
      "124/224, train_loss: 0.0802, step time: 0.3149\n",
      "125/224, train_loss: 0.1576, step time: 0.4014\n",
      "126/224, train_loss: 0.0988, step time: 0.3709\n",
      "127/224, train_loss: 0.0836, step time: 0.3153\n",
      "128/224, train_loss: 0.0666, step time: 0.3874\n",
      "129/224, train_loss: 0.0903, step time: 0.3127\n",
      "130/224, train_loss: 0.0696, step time: 0.4081\n",
      "131/224, train_loss: 0.1050, step time: 0.3152\n",
      "132/224, train_loss: 0.0653, step time: 0.3792\n",
      "133/224, train_loss: 0.0603, step time: 0.4085\n",
      "134/224, train_loss: 0.0614, step time: 0.3119\n",
      "135/224, train_loss: 0.0628, step time: 0.3141\n",
      "136/224, train_loss: 0.0732, step time: 0.3142\n",
      "137/224, train_loss: 0.0587, step time: 0.3148\n",
      "138/224, train_loss: 0.1140, step time: 0.3749\n",
      "139/224, train_loss: 0.0569, step time: 0.3727\n",
      "140/224, train_loss: 0.0839, step time: 0.3736\n",
      "141/224, train_loss: 0.1473, step time: 0.4091\n",
      "142/224, train_loss: 0.0550, step time: 0.4009\n",
      "143/224, train_loss: 0.0618, step time: 0.3960\n",
      "144/224, train_loss: 0.1299, step time: 0.4120\n",
      "145/224, train_loss: 0.0652, step time: 0.3694\n",
      "146/224, train_loss: 0.0863, step time: 0.3183\n",
      "147/224, train_loss: 0.1060, step time: 0.3699\n",
      "148/224, train_loss: 0.0796, step time: 0.3204\n",
      "149/224, train_loss: 0.1580, step time: 0.3985\n",
      "150/224, train_loss: 0.0718, step time: 0.3727\n",
      "151/224, train_loss: 0.0920, step time: 0.3181\n",
      "152/224, train_loss: 0.0781, step time: 0.3940\n",
      "153/224, train_loss: 0.0906, step time: 0.3158\n",
      "154/224, train_loss: 0.3556, step time: 0.3990\n",
      "155/224, train_loss: 0.1115, step time: 0.3814\n",
      "156/224, train_loss: 0.1156, step time: 0.3159\n",
      "157/224, train_loss: 0.0797, step time: 0.3154\n",
      "158/224, train_loss: 0.0717, step time: 0.3133\n",
      "159/224, train_loss: 0.1032, step time: 0.3134\n",
      "160/224, train_loss: 0.0962, step time: 0.3178\n",
      "161/224, train_loss: 0.0489, step time: 0.3660\n",
      "162/224, train_loss: 0.1494, step time: 0.3158\n",
      "163/224, train_loss: 0.0739, step time: 0.3153\n",
      "164/224, train_loss: 0.0531, step time: 0.3758\n",
      "165/224, train_loss: 0.2128, step time: 0.4141\n",
      "166/224, train_loss: 0.0909, step time: 0.3139\n",
      "167/224, train_loss: 0.1001, step time: 0.4144\n",
      "168/224, train_loss: 0.2223, step time: 0.4036\n",
      "169/224, train_loss: 0.1388, step time: 0.3935\n",
      "170/224, train_loss: 0.1209, step time: 0.3959\n",
      "171/224, train_loss: 0.0496, step time: 0.3159\n",
      "172/224, train_loss: 0.0591, step time: 0.3137\n",
      "173/224, train_loss: 0.0665, step time: 0.3163\n",
      "174/224, train_loss: 0.3060, step time: 0.3735\n",
      "175/224, train_loss: 0.0782, step time: 0.3731\n",
      "176/224, train_loss: 0.1631, step time: 0.3694\n",
      "177/224, train_loss: 0.1191, step time: 0.3780\n",
      "178/224, train_loss: 0.1018, step time: 0.3175\n",
      "179/224, train_loss: 0.1389, step time: 0.4034\n",
      "180/224, train_loss: 0.3084, step time: 0.3971\n",
      "181/224, train_loss: 0.0538, step time: 0.3122\n",
      "182/224, train_loss: 0.1489, step time: 0.4055\n",
      "183/224, train_loss: 0.0714, step time: 0.3174\n",
      "184/224, train_loss: 0.2694, step time: 0.3748\n",
      "185/224, train_loss: 0.0513, step time: 0.3169\n",
      "186/224, train_loss: 0.0843, step time: 0.3143\n",
      "187/224, train_loss: 0.0670, step time: 0.3144\n",
      "188/224, train_loss: 0.4520, step time: 0.3656\n",
      "189/224, train_loss: 0.0551, step time: 0.3145\n",
      "190/224, train_loss: 0.0949, step time: 0.4124\n",
      "191/224, train_loss: 0.1988, step time: 0.4079\n",
      "192/224, train_loss: 0.0794, step time: 0.3172\n",
      "193/224, train_loss: 0.3024, step time: 0.4081\n",
      "194/224, train_loss: 0.1101, step time: 0.3143\n",
      "195/224, train_loss: 0.3604, step time: 0.4016\n",
      "196/224, train_loss: 0.0667, step time: 0.3177\n",
      "197/224, train_loss: 0.0789, step time: 0.3857\n",
      "198/224, train_loss: 0.0757, step time: 0.3146\n",
      "199/224, train_loss: 0.0789, step time: 0.3756\n",
      "200/224, train_loss: 0.3126, step time: 0.4101\n",
      "201/224, train_loss: 0.1159, step time: 0.3724\n",
      "202/224, train_loss: 0.2475, step time: 0.3978\n",
      "203/224, train_loss: 0.0737, step time: 0.3165\n",
      "204/224, train_loss: 0.0878, step time: 0.3142\n",
      "205/224, train_loss: 0.0930, step time: 0.3806\n",
      "206/224, train_loss: 0.2348, step time: 0.4010\n",
      "207/224, train_loss: 0.1156, step time: 0.3984\n",
      "208/224, train_loss: 0.0748, step time: 0.3171\n",
      "209/224, train_loss: 0.1657, step time: 0.3691\n",
      "210/224, train_loss: 0.0814, step time: 0.3165\n",
      "211/224, train_loss: 0.1016, step time: 0.3140\n",
      "212/224, train_loss: 0.1981, step time: 0.3872\n",
      "213/224, train_loss: 0.1034, step time: 0.3146\n",
      "214/224, train_loss: 0.0784, step time: 0.3128\n",
      "215/224, train_loss: 0.1124, step time: 0.3921\n",
      "216/224, train_loss: 0.1000, step time: 0.4025\n",
      "217/224, train_loss: 0.0827, step time: 0.3988\n",
      "218/224, train_loss: 0.1089, step time: 0.3168\n",
      "219/224, train_loss: 0.1089, step time: 0.3171\n",
      "220/224, train_loss: 0.1930, step time: 0.3813\n",
      "221/224, train_loss: 0.0956, step time: 0.3980\n",
      "222/224, train_loss: 0.1337, step time: 0.3146\n",
      "223/224, train_loss: 0.0623, step time: 0.3165\n",
      "224/224, train_loss: 0.1697, step time: 0.3957\n",
      "epoch 95 average loss: 0.1105\n",
      "current epoch: 95 current mean dice: 0.7051 class1: 0.9994 class2: 0.7467 class3: 0.3693\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 95 is: 774.5648\n",
      "hello\n",
      "----------\n",
      "epoch 96/100\n",
      "1/224, train_loss: 0.1444, step time: 0.3142\n",
      "2/224, train_loss: 0.1046, step time: 0.3145\n",
      "3/224, train_loss: 0.1005, step time: 0.3152\n",
      "4/224, train_loss: 0.1258, step time: 0.4003\n",
      "5/224, train_loss: 0.0947, step time: 0.3675\n",
      "6/224, train_loss: 0.0824, step time: 0.4059\n",
      "7/224, train_loss: 0.1238, step time: 0.4033\n",
      "8/224, train_loss: 0.2280, step time: 0.4069\n",
      "9/224, train_loss: 0.0701, step time: 0.3129\n",
      "10/224, train_loss: 0.0549, step time: 0.3148\n",
      "11/224, train_loss: 0.0922, step time: 0.3150\n",
      "12/224, train_loss: 0.0850, step time: 0.3148\n",
      "13/224, train_loss: 0.0711, step time: 0.3142\n",
      "14/224, train_loss: 0.0874, step time: 0.3165\n",
      "15/224, train_loss: 0.0457, step time: 0.3121\n",
      "16/224, train_loss: 0.0458, step time: 0.3129\n",
      "17/224, train_loss: 0.0859, step time: 0.3134\n",
      "18/224, train_loss: 0.0895, step time: 0.3136\n",
      "19/224, train_loss: 0.0972, step time: 0.4081\n",
      "20/224, train_loss: 0.0812, step time: 0.3155\n",
      "21/224, train_loss: 0.0916, step time: 0.4010\n",
      "22/224, train_loss: 0.0481, step time: 0.3833\n",
      "23/224, train_loss: 0.0814, step time: 0.3130\n",
      "24/224, train_loss: 0.0910, step time: 0.3152\n",
      "25/224, train_loss: 0.0904, step time: 0.3844\n",
      "26/224, train_loss: 0.1060, step time: 0.3945\n",
      "27/224, train_loss: 0.0597, step time: 0.3174\n",
      "28/224, train_loss: 0.2955, step time: 0.4047\n",
      "29/224, train_loss: 0.1631, step time: 0.3828\n",
      "30/224, train_loss: 0.0594, step time: 0.3132\n",
      "31/224, train_loss: 0.0814, step time: 0.3151\n",
      "32/224, train_loss: 0.1021, step time: 0.3914\n",
      "33/224, train_loss: 0.0644, step time: 0.3155\n",
      "34/224, train_loss: 0.2627, step time: 0.4072\n",
      "35/224, train_loss: 0.1393, step time: 0.3830\n",
      "36/224, train_loss: 0.0740, step time: 0.3145\n",
      "37/224, train_loss: 0.0633, step time: 0.3146\n",
      "38/224, train_loss: 0.1056, step time: 0.4031\n",
      "39/224, train_loss: 0.0669, step time: 0.3129\n",
      "40/224, train_loss: 0.0738, step time: 0.3149\n",
      "41/224, train_loss: 0.1022, step time: 0.4016\n",
      "42/224, train_loss: 0.0843, step time: 0.3161\n",
      "43/224, train_loss: 0.0773, step time: 0.3152\n",
      "44/224, train_loss: 0.3123, step time: 0.3844\n",
      "45/224, train_loss: 0.3026, step time: 0.4092\n",
      "46/224, train_loss: 0.1336, step time: 0.3913\n",
      "47/224, train_loss: 0.2904, step time: 0.3749\n",
      "48/224, train_loss: 0.0974, step time: 0.3176\n",
      "49/224, train_loss: 0.0499, step time: 0.3139\n",
      "50/224, train_loss: 0.1786, step time: 0.3902\n",
      "51/224, train_loss: 0.0860, step time: 0.3739\n",
      "52/224, train_loss: 0.0846, step time: 0.3979\n",
      "53/224, train_loss: 0.0685, step time: 0.3166\n",
      "54/224, train_loss: 0.2546, step time: 0.3181\n",
      "55/224, train_loss: 0.1242, step time: 0.3689\n",
      "56/224, train_loss: 0.1413, step time: 0.3778\n",
      "57/224, train_loss: 0.3086, step time: 0.3887\n",
      "58/224, train_loss: 0.0444, step time: 0.3165\n",
      "59/224, train_loss: 0.0996, step time: 0.3168\n",
      "60/224, train_loss: 0.0843, step time: 0.3172\n",
      "61/224, train_loss: 0.1187, step time: 0.3753\n",
      "62/224, train_loss: 0.1273, step time: 0.3792\n",
      "63/224, train_loss: 0.0844, step time: 0.3171\n",
      "64/224, train_loss: 0.1383, step time: 0.3733\n",
      "65/224, train_loss: 0.0829, step time: 0.3806\n",
      "66/224, train_loss: 0.0776, step time: 0.3170\n",
      "67/224, train_loss: 0.0844, step time: 0.3788\n",
      "68/224, train_loss: 0.2344, step time: 0.3850\n",
      "69/224, train_loss: 0.0950, step time: 0.3980\n",
      "70/224, train_loss: 0.0827, step time: 0.3149\n",
      "71/224, train_loss: 0.1500, step time: 0.3805\n",
      "72/224, train_loss: 0.0744, step time: 0.3171\n",
      "73/224, train_loss: 0.2089, step time: 0.4056\n",
      "74/224, train_loss: 0.0620, step time: 0.3174\n",
      "75/224, train_loss: 0.3328, step time: 0.3981\n",
      "76/224, train_loss: 0.0709, step time: 0.3664\n",
      "77/224, train_loss: 0.0616, step time: 0.3824\n",
      "78/224, train_loss: 0.0724, step time: 0.3127\n",
      "79/224, train_loss: 0.2186, step time: 0.3145\n",
      "80/224, train_loss: 0.2278, step time: 0.4036\n",
      "81/224, train_loss: 0.2959, step time: 0.4056\n",
      "82/224, train_loss: 0.1156, step time: 0.3153\n",
      "83/224, train_loss: 0.0614, step time: 0.3154\n",
      "84/224, train_loss: 0.0840, step time: 0.3148\n",
      "85/224, train_loss: 0.1758, step time: 0.4087\n",
      "86/224, train_loss: 0.0848, step time: 0.3950\n",
      "87/224, train_loss: 0.1027, step time: 0.4038\n",
      "88/224, train_loss: 0.1004, step time: 0.3724\n",
      "89/224, train_loss: 0.0935, step time: 0.3170\n",
      "90/224, train_loss: 0.0710, step time: 0.3148\n",
      "91/224, train_loss: 0.0599, step time: 0.3168\n",
      "92/224, train_loss: 0.1086, step time: 0.3146\n",
      "93/224, train_loss: 0.1940, step time: 0.4014\n",
      "94/224, train_loss: 0.0804, step time: 0.3180\n",
      "95/224, train_loss: 0.0687, step time: 0.3183\n",
      "96/224, train_loss: 0.0707, step time: 0.3705\n",
      "97/224, train_loss: 0.1116, step time: 0.3745\n",
      "98/224, train_loss: 0.1056, step time: 0.3175\n",
      "99/224, train_loss: 0.1254, step time: 0.3808\n",
      "100/224, train_loss: 0.2491, step time: 0.3872\n",
      "101/224, train_loss: 0.0669, step time: 0.3127\n",
      "102/224, train_loss: 0.1300, step time: 0.3777\n",
      "103/224, train_loss: 0.0666, step time: 0.3147\n",
      "104/224, train_loss: 0.0445, step time: 0.3962\n",
      "105/224, train_loss: 0.0961, step time: 0.3158\n",
      "106/224, train_loss: 0.1376, step time: 0.4064\n",
      "107/224, train_loss: 0.1267, step time: 0.3152\n",
      "108/224, train_loss: 0.0606, step time: 0.3154\n",
      "109/224, train_loss: 0.1109, step time: 0.3715\n",
      "110/224, train_loss: 0.0864, step time: 0.3734\n",
      "111/224, train_loss: 0.0804, step time: 0.3161\n",
      "112/224, train_loss: 0.1098, step time: 0.3133\n",
      "113/224, train_loss: 0.1983, step time: 0.3957\n",
      "114/224, train_loss: 0.0532, step time: 0.3150\n",
      "115/224, train_loss: 0.1094, step time: 0.4036\n",
      "116/224, train_loss: 0.1186, step time: 0.3159\n",
      "117/224, train_loss: 0.1944, step time: 0.3659\n",
      "118/224, train_loss: 0.0785, step time: 0.3946\n",
      "119/224, train_loss: 0.1351, step time: 0.3783\n",
      "120/224, train_loss: 0.0899, step time: 0.3164\n",
      "121/224, train_loss: 0.1137, step time: 0.3847\n",
      "122/224, train_loss: 0.0969, step time: 0.3684\n",
      "123/224, train_loss: 0.0953, step time: 0.3746\n",
      "124/224, train_loss: 0.1351, step time: 0.3705\n",
      "125/224, train_loss: 0.1129, step time: 0.3916\n",
      "126/224, train_loss: 0.0579, step time: 0.3785\n",
      "127/224, train_loss: 0.1798, step time: 0.3986\n",
      "128/224, train_loss: 0.0736, step time: 0.3710\n",
      "129/224, train_loss: 0.1436, step time: 0.3942\n",
      "130/224, train_loss: 0.2363, step time: 0.3809\n",
      "131/224, train_loss: 0.1035, step time: 0.4001\n",
      "132/224, train_loss: 0.0755, step time: 0.3184\n",
      "133/224, train_loss: 0.1560, step time: 0.3801\n",
      "134/224, train_loss: 0.1197, step time: 0.4022\n",
      "135/224, train_loss: 0.0921, step time: 0.3177\n",
      "136/224, train_loss: 0.1844, step time: 0.3743\n",
      "137/224, train_loss: 0.0652, step time: 0.3150\n",
      "138/224, train_loss: 0.0751, step time: 0.3160\n",
      "139/224, train_loss: 0.1203, step time: 0.4006\n",
      "140/224, train_loss: 0.0850, step time: 0.3177\n",
      "141/224, train_loss: 0.0688, step time: 0.3923\n",
      "142/224, train_loss: 0.0807, step time: 0.3156\n",
      "143/224, train_loss: 0.0808, step time: 0.3150\n",
      "144/224, train_loss: 0.0841, step time: 0.3128\n",
      "145/224, train_loss: 0.0723, step time: 0.3149\n",
      "146/224, train_loss: 0.1159, step time: 0.3829\n",
      "147/224, train_loss: 0.1136, step time: 0.3163\n",
      "148/224, train_loss: 0.1140, step time: 0.3697\n",
      "149/224, train_loss: 0.2662, step time: 0.3906\n",
      "150/224, train_loss: 0.1242, step time: 0.3155\n",
      "151/224, train_loss: 0.0923, step time: 0.3152\n",
      "152/224, train_loss: 0.2145, step time: 0.4090\n",
      "153/224, train_loss: 0.0780, step time: 0.3130\n",
      "154/224, train_loss: 0.1419, step time: 0.3863\n",
      "155/224, train_loss: 0.0970, step time: 0.3132\n",
      "156/224, train_loss: 0.0893, step time: 0.3731\n",
      "157/224, train_loss: 0.1129, step time: 0.3135\n",
      "158/224, train_loss: 0.0837, step time: 0.3151\n",
      "159/224, train_loss: 0.0966, step time: 0.3136\n",
      "160/224, train_loss: 0.0681, step time: 0.3157\n",
      "161/224, train_loss: 0.0771, step time: 0.3150\n",
      "162/224, train_loss: 0.0598, step time: 0.3158\n",
      "163/224, train_loss: 0.0981, step time: 0.4131\n",
      "164/224, train_loss: 0.1770, step time: 0.3980\n",
      "165/224, train_loss: 0.0498, step time: 0.3180\n",
      "166/224, train_loss: 0.1005, step time: 0.3133\n",
      "167/224, train_loss: 0.1340, step time: 0.4072\n",
      "168/224, train_loss: 0.1245, step time: 0.3837\n",
      "169/224, train_loss: 0.0803, step time: 0.3960\n",
      "170/224, train_loss: 0.1043, step time: 0.3775\n",
      "171/224, train_loss: 0.0615, step time: 0.3140\n",
      "172/224, train_loss: 0.0861, step time: 0.3808\n",
      "173/224, train_loss: 0.2256, step time: 0.4112\n",
      "174/224, train_loss: 0.1675, step time: 0.3158\n",
      "175/224, train_loss: 0.0595, step time: 0.3158\n",
      "176/224, train_loss: 0.0744, step time: 0.3178\n",
      "177/224, train_loss: 0.1038, step time: 0.3174\n",
      "178/224, train_loss: 0.2208, step time: 0.3828\n",
      "179/224, train_loss: 0.0781, step time: 0.3161\n",
      "180/224, train_loss: 0.0924, step time: 0.3681\n",
      "181/224, train_loss: 0.0857, step time: 0.3157\n",
      "182/224, train_loss: 0.1038, step time: 0.4052\n",
      "183/224, train_loss: 0.0639, step time: 0.3877\n",
      "184/224, train_loss: 0.0929, step time: 0.3183\n",
      "185/224, train_loss: 0.1928, step time: 0.4091\n",
      "186/224, train_loss: 0.0967, step time: 0.3179\n",
      "187/224, train_loss: 0.0610, step time: 0.3156\n",
      "188/224, train_loss: 0.0516, step time: 0.3161\n",
      "189/224, train_loss: 0.1221, step time: 0.3694\n",
      "190/224, train_loss: 0.0669, step time: 0.3165\n",
      "191/224, train_loss: 0.1065, step time: 0.3735\n",
      "192/224, train_loss: 0.0782, step time: 0.3184\n",
      "193/224, train_loss: 0.1519, step time: 0.3134\n",
      "194/224, train_loss: 0.1011, step time: 0.3151\n",
      "195/224, train_loss: 0.0738, step time: 0.3943\n",
      "196/224, train_loss: 0.0856, step time: 0.3137\n",
      "197/224, train_loss: 0.1481, step time: 0.3181\n",
      "198/224, train_loss: 0.0709, step time: 0.3136\n",
      "199/224, train_loss: 0.1032, step time: 0.3944\n",
      "200/224, train_loss: 0.1038, step time: 0.3869\n",
      "201/224, train_loss: 0.1048, step time: 0.4141\n",
      "202/224, train_loss: 0.2411, step time: 0.3891\n",
      "203/224, train_loss: 0.0614, step time: 0.3165\n",
      "204/224, train_loss: 0.1418, step time: 0.4121\n",
      "205/224, train_loss: 0.1627, step time: 0.4104\n",
      "206/224, train_loss: 0.0680, step time: 0.3144\n",
      "207/224, train_loss: 0.0872, step time: 0.4062\n",
      "208/224, train_loss: 0.1332, step time: 0.3724\n",
      "209/224, train_loss: 0.1222, step time: 0.3972\n",
      "210/224, train_loss: 0.0745, step time: 0.3718\n",
      "211/224, train_loss: 0.0618, step time: 0.3895\n",
      "212/224, train_loss: 0.1858, step time: 0.3889\n",
      "213/224, train_loss: 0.0944, step time: 0.3989\n",
      "214/224, train_loss: 0.2928, step time: 0.3983\n",
      "215/224, train_loss: 0.1198, step time: 0.3151\n",
      "216/224, train_loss: 0.0479, step time: 0.3126\n",
      "217/224, train_loss: 0.0731, step time: 0.4082\n",
      "218/224, train_loss: 0.0594, step time: 0.3154\n",
      "219/224, train_loss: 0.0927, step time: 0.3866\n",
      "220/224, train_loss: 0.0554, step time: 0.3131\n",
      "221/224, train_loss: 0.0894, step time: 0.3144\n",
      "222/224, train_loss: 0.1302, step time: 0.3832\n",
      "223/224, train_loss: 0.2020, step time: 0.3134\n",
      "224/224, train_loss: 0.0896, step time: 0.4076\n",
      "epoch 96 average loss: 0.1136\n",
      "current epoch: 96 current mean dice: 0.7055 class1: 0.9993 class2: 0.7344 class3: 0.3826\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 96 is: 745.0410\n",
      "hello\n",
      "----------\n",
      "epoch 97/100\n",
      "1/224, train_loss: 0.0432, step time: 0.4127\n",
      "2/224, train_loss: 0.1148, step time: 0.4082\n",
      "3/224, train_loss: 0.0504, step time: 0.3172\n",
      "4/224, train_loss: 0.1492, step time: 0.3789\n",
      "5/224, train_loss: 0.1583, step time: 0.3716\n",
      "6/224, train_loss: 0.1020, step time: 0.3173\n",
      "7/224, train_loss: 0.0606, step time: 0.3152\n",
      "8/224, train_loss: 0.2322, step time: 0.3972\n",
      "9/224, train_loss: 0.0680, step time: 0.3152\n",
      "10/224, train_loss: 0.2523, step time: 0.3174\n",
      "11/224, train_loss: 0.1074, step time: 0.3174\n",
      "12/224, train_loss: 0.0864, step time: 0.3148\n",
      "13/224, train_loss: 0.1571, step time: 0.3151\n",
      "14/224, train_loss: 0.1265, step time: 0.3875\n",
      "15/224, train_loss: 0.0984, step time: 0.3976\n",
      "16/224, train_loss: 0.2136, step time: 0.3901\n",
      "17/224, train_loss: 0.1466, step time: 0.3765\n",
      "18/224, train_loss: 0.1362, step time: 0.3668\n",
      "19/224, train_loss: 0.0694, step time: 0.3128\n",
      "20/224, train_loss: 0.1154, step time: 0.3173\n",
      "21/224, train_loss: 0.0607, step time: 0.3153\n",
      "22/224, train_loss: 0.3678, step time: 0.3801\n",
      "23/224, train_loss: 0.0660, step time: 0.3148\n",
      "24/224, train_loss: 0.0808, step time: 0.3982\n",
      "25/224, train_loss: 0.0833, step time: 0.3182\n",
      "26/224, train_loss: 0.0757, step time: 0.3152\n",
      "27/224, train_loss: 0.0746, step time: 0.3128\n",
      "28/224, train_loss: 0.0626, step time: 0.3171\n",
      "29/224, train_loss: 0.0690, step time: 0.3152\n",
      "30/224, train_loss: 0.1451, step time: 0.4010\n",
      "31/224, train_loss: 0.0899, step time: 0.3923\n",
      "32/224, train_loss: 0.1014, step time: 0.3677\n",
      "33/224, train_loss: 0.0840, step time: 0.3130\n",
      "34/224, train_loss: 0.0883, step time: 0.3176\n",
      "35/224, train_loss: 0.1009, step time: 0.3944\n",
      "36/224, train_loss: 0.0733, step time: 0.3927\n",
      "37/224, train_loss: 0.0599, step time: 0.3780\n",
      "38/224, train_loss: 0.0879, step time: 0.3150\n",
      "39/224, train_loss: 0.0701, step time: 0.3174\n",
      "40/224, train_loss: 0.0692, step time: 0.3127\n",
      "41/224, train_loss: 0.1907, step time: 0.4014\n",
      "42/224, train_loss: 0.0867, step time: 0.3129\n",
      "43/224, train_loss: 0.1445, step time: 0.3872\n",
      "44/224, train_loss: 0.1695, step time: 0.3173\n",
      "45/224, train_loss: 0.1820, step time: 0.4048\n",
      "46/224, train_loss: 0.0746, step time: 0.3175\n",
      "47/224, train_loss: 0.0689, step time: 0.3152\n",
      "48/224, train_loss: 0.1183, step time: 0.3152\n",
      "49/224, train_loss: 0.1017, step time: 0.3153\n",
      "50/224, train_loss: 0.0826, step time: 0.3176\n",
      "51/224, train_loss: 0.0979, step time: 0.3143\n",
      "52/224, train_loss: 0.0713, step time: 0.3167\n",
      "53/224, train_loss: 0.0893, step time: 0.3978\n",
      "54/224, train_loss: 0.0813, step time: 0.3148\n",
      "55/224, train_loss: 0.1996, step time: 0.3796\n",
      "56/224, train_loss: 0.0665, step time: 0.3150\n",
      "57/224, train_loss: 0.1674, step time: 0.3729\n",
      "58/224, train_loss: 0.0426, step time: 0.3856\n",
      "59/224, train_loss: 0.0600, step time: 0.3147\n",
      "60/224, train_loss: 0.0769, step time: 0.3143\n",
      "61/224, train_loss: 0.0854, step time: 0.4009\n",
      "62/224, train_loss: 0.0910, step time: 0.3175\n",
      "63/224, train_loss: 0.0735, step time: 0.3897\n",
      "64/224, train_loss: 0.0985, step time: 0.4019\n",
      "65/224, train_loss: 0.0847, step time: 0.3150\n",
      "66/224, train_loss: 0.2286, step time: 0.4084\n",
      "67/224, train_loss: 0.1259, step time: 0.3941\n",
      "68/224, train_loss: 0.1205, step time: 0.3135\n",
      "69/224, train_loss: 0.1182, step time: 0.3817\n",
      "70/224, train_loss: 0.1725, step time: 0.3709\n",
      "71/224, train_loss: 0.0940, step time: 0.3131\n",
      "72/224, train_loss: 0.1182, step time: 0.4043\n",
      "73/224, train_loss: 0.1681, step time: 0.3963\n",
      "74/224, train_loss: 0.0746, step time: 0.4014\n",
      "75/224, train_loss: 0.2340, step time: 0.3711\n",
      "76/224, train_loss: 0.0842, step time: 0.3148\n",
      "77/224, train_loss: 0.0919, step time: 0.3173\n",
      "78/224, train_loss: 0.1841, step time: 0.3151\n",
      "79/224, train_loss: 0.1184, step time: 0.4106\n",
      "80/224, train_loss: 0.0755, step time: 0.3152\n",
      "81/224, train_loss: 0.0699, step time: 0.3152\n",
      "82/224, train_loss: 0.2183, step time: 0.3856\n",
      "83/224, train_loss: 0.1206, step time: 0.3967\n",
      "84/224, train_loss: 0.1305, step time: 0.3147\n",
      "85/224, train_loss: 0.0786, step time: 0.3815\n",
      "86/224, train_loss: 0.0778, step time: 0.3932\n",
      "87/224, train_loss: 0.0605, step time: 0.4059\n",
      "88/224, train_loss: 0.0838, step time: 0.3133\n",
      "89/224, train_loss: 0.0910, step time: 0.4063\n",
      "90/224, train_loss: 0.0791, step time: 0.3133\n",
      "91/224, train_loss: 0.1023, step time: 0.3140\n",
      "92/224, train_loss: 0.0593, step time: 0.3152\n",
      "93/224, train_loss: 0.0979, step time: 0.3152\n",
      "94/224, train_loss: 0.0816, step time: 0.3169\n",
      "95/224, train_loss: 0.0654, step time: 0.3157\n",
      "96/224, train_loss: 0.0927, step time: 0.3133\n",
      "97/224, train_loss: 0.1064, step time: 0.3152\n",
      "98/224, train_loss: 0.0732, step time: 0.3868\n",
      "99/224, train_loss: 0.1311, step time: 0.4078\n",
      "100/224, train_loss: 0.1452, step time: 0.3827\n",
      "101/224, train_loss: 0.1963, step time: 0.3704\n",
      "102/224, train_loss: 0.2480, step time: 0.4095\n",
      "103/224, train_loss: 0.0975, step time: 0.3133\n",
      "104/224, train_loss: 0.1075, step time: 0.3910\n",
      "105/224, train_loss: 0.0838, step time: 0.3873\n",
      "106/224, train_loss: 0.0996, step time: 0.3170\n",
      "107/224, train_loss: 0.0686, step time: 0.3150\n",
      "108/224, train_loss: 0.0948, step time: 0.3152\n",
      "109/224, train_loss: 0.0893, step time: 0.3169\n",
      "110/224, train_loss: 0.0999, step time: 0.3151\n",
      "111/224, train_loss: 0.0883, step time: 0.3152\n",
      "112/224, train_loss: 0.1091, step time: 0.4082\n",
      "113/224, train_loss: 0.0611, step time: 0.4054\n",
      "114/224, train_loss: 0.1222, step time: 0.3168\n",
      "115/224, train_loss: 0.1125, step time: 0.3801\n",
      "116/224, train_loss: 0.0917, step time: 0.3126\n",
      "117/224, train_loss: 0.1346, step time: 0.3132\n",
      "118/224, train_loss: 0.1313, step time: 0.3656\n",
      "119/224, train_loss: 0.0827, step time: 0.4089\n",
      "120/224, train_loss: 0.1226, step time: 0.3152\n",
      "121/224, train_loss: 0.0988, step time: 0.3127\n",
      "122/224, train_loss: 0.0902, step time: 0.3145\n",
      "123/224, train_loss: 0.1202, step time: 0.3973\n",
      "124/224, train_loss: 0.3025, step time: 0.3149\n",
      "125/224, train_loss: 0.1533, step time: 0.3966\n",
      "126/224, train_loss: 0.1133, step time: 0.3168\n",
      "127/224, train_loss: 0.1061, step time: 0.3828\n",
      "128/224, train_loss: 0.1313, step time: 0.3147\n",
      "129/224, train_loss: 0.1288, step time: 0.3142\n",
      "130/224, train_loss: 0.0965, step time: 0.3775\n",
      "131/224, train_loss: 0.0920, step time: 0.3652\n",
      "132/224, train_loss: 0.1873, step time: 0.3690\n",
      "133/224, train_loss: 0.0851, step time: 0.3136\n",
      "134/224, train_loss: 0.1194, step time: 0.3725\n",
      "135/224, train_loss: 0.0832, step time: 0.3156\n",
      "136/224, train_loss: 0.1290, step time: 0.3829\n",
      "137/224, train_loss: 0.1059, step time: 0.3711\n",
      "138/224, train_loss: 0.0598, step time: 0.3131\n",
      "139/224, train_loss: 0.1809, step time: 0.3838\n",
      "140/224, train_loss: 0.0858, step time: 0.3163\n",
      "141/224, train_loss: 0.0903, step time: 0.3718\n",
      "142/224, train_loss: 0.0621, step time: 0.3153\n",
      "143/224, train_loss: 0.0642, step time: 0.3151\n",
      "144/224, train_loss: 0.0397, step time: 0.3173\n",
      "145/224, train_loss: 0.0682, step time: 0.3169\n",
      "146/224, train_loss: 0.0769, step time: 0.3154\n",
      "147/224, train_loss: 0.1214, step time: 0.3128\n",
      "148/224, train_loss: 0.2655, step time: 0.3716\n",
      "149/224, train_loss: 0.0617, step time: 0.3167\n",
      "150/224, train_loss: 0.3064, step time: 0.3976\n",
      "151/224, train_loss: 0.1031, step time: 0.3901\n",
      "152/224, train_loss: 0.1254, step time: 0.3210\n",
      "153/224, train_loss: 0.0735, step time: 0.3857\n",
      "154/224, train_loss: 0.1656, step time: 0.3687\n",
      "155/224, train_loss: 0.2029, step time: 0.3937\n",
      "156/224, train_loss: 0.1164, step time: 0.3975\n",
      "157/224, train_loss: 0.0791, step time: 0.3138\n",
      "158/224, train_loss: 0.0471, step time: 0.3154\n",
      "159/224, train_loss: 0.1010, step time: 0.4750\n",
      "160/224, train_loss: 0.1377, step time: 0.3839\n",
      "161/224, train_loss: 0.0727, step time: 0.3180\n",
      "162/224, train_loss: 0.0931, step time: 0.3141\n",
      "163/224, train_loss: 0.1579, step time: 0.3912\n",
      "164/224, train_loss: 0.0974, step time: 0.3163\n",
      "165/224, train_loss: 0.1259, step time: 0.3752\n",
      "166/224, train_loss: 0.0513, step time: 0.3170\n",
      "167/224, train_loss: 0.0817, step time: 0.3164\n",
      "168/224, train_loss: 0.4214, step time: 0.3920\n",
      "169/224, train_loss: 0.0872, step time: 0.3140\n",
      "170/224, train_loss: 0.0861, step time: 0.3181\n",
      "171/224, train_loss: 0.1058, step time: 0.3635\n",
      "172/224, train_loss: 0.1476, step time: 0.3999\n",
      "173/224, train_loss: 0.0562, step time: 0.3170\n",
      "174/224, train_loss: 0.0610, step time: 0.3165\n",
      "175/224, train_loss: 0.2803, step time: 0.3924\n",
      "176/224, train_loss: 0.1066, step time: 0.4051\n",
      "177/224, train_loss: 0.1225, step time: 0.4012\n",
      "178/224, train_loss: 0.0626, step time: 0.3161\n",
      "179/224, train_loss: 0.1283, step time: 0.3939\n",
      "180/224, train_loss: 0.0614, step time: 0.3165\n",
      "181/224, train_loss: 0.1567, step time: 0.4067\n",
      "182/224, train_loss: 0.0952, step time: 0.3159\n",
      "183/224, train_loss: 0.0645, step time: 0.3862\n",
      "184/224, train_loss: 0.2079, step time: 0.3166\n",
      "185/224, train_loss: 0.1137, step time: 0.3665\n",
      "186/224, train_loss: 0.0938, step time: 0.3159\n",
      "187/224, train_loss: 0.0622, step time: 0.3178\n",
      "188/224, train_loss: 0.0755, step time: 0.3157\n",
      "189/224, train_loss: 0.1034, step time: 0.3136\n",
      "190/224, train_loss: 0.0540, step time: 0.3189\n",
      "191/224, train_loss: 0.0835, step time: 0.3170\n",
      "192/224, train_loss: 0.0668, step time: 0.3192\n",
      "193/224, train_loss: 0.0684, step time: 0.3161\n",
      "194/224, train_loss: 0.0706, step time: 0.3166\n",
      "195/224, train_loss: 0.0895, step time: 0.3169\n",
      "196/224, train_loss: 0.0721, step time: 0.3778\n",
      "197/224, train_loss: 0.0793, step time: 0.3167\n",
      "198/224, train_loss: 0.3131, step time: 0.3843\n",
      "199/224, train_loss: 0.1224, step time: 0.4034\n",
      "200/224, train_loss: 0.0843, step time: 0.3197\n",
      "201/224, train_loss: 0.0691, step time: 0.3145\n",
      "202/224, train_loss: 0.0819, step time: 0.3751\n",
      "203/224, train_loss: 0.1279, step time: 0.3808\n",
      "204/224, train_loss: 0.0535, step time: 0.3185\n",
      "205/224, train_loss: 0.1873, step time: 0.3174\n",
      "206/224, train_loss: 0.1639, step time: 0.3856\n",
      "207/224, train_loss: 0.0600, step time: 0.3146\n",
      "208/224, train_loss: 0.0847, step time: 0.3874\n",
      "209/224, train_loss: 0.1301, step time: 0.4135\n",
      "210/224, train_loss: 0.0812, step time: 0.3203\n",
      "211/224, train_loss: 0.1539, step time: 0.3693\n",
      "212/224, train_loss: 0.1026, step time: 0.3173\n",
      "213/224, train_loss: 0.1579, step time: 0.3982\n",
      "214/224, train_loss: 0.0799, step time: 0.3177\n",
      "215/224, train_loss: 0.0607, step time: 0.3199\n",
      "216/224, train_loss: 0.2420, step time: 0.3987\n",
      "217/224, train_loss: 0.1393, step time: 0.3187\n",
      "218/224, train_loss: 0.0895, step time: 0.3807\n",
      "219/224, train_loss: 0.1290, step time: 0.4099\n",
      "220/224, train_loss: 0.0855, step time: 0.3187\n",
      "221/224, train_loss: 0.0873, step time: 0.3673\n",
      "222/224, train_loss: 0.0684, step time: 0.3130\n",
      "223/224, train_loss: 0.0790, step time: 0.3155\n",
      "224/224, train_loss: 0.0632, step time: 0.3165\n",
      "epoch 97 average loss: 0.1119\n",
      "current epoch: 97 current mean dice: 0.7190 class1: 0.9993 class2: 0.7404 class3: 0.4174\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 97 is: 664.4458\n",
      "hello\n",
      "----------\n",
      "epoch 98/100\n",
      "1/224, train_loss: 0.0759, step time: 0.3160\n",
      "2/224, train_loss: 0.0843, step time: 0.3755\n",
      "3/224, train_loss: 0.0639, step time: 0.3167\n",
      "4/224, train_loss: 0.1883, step time: 0.4071\n",
      "5/224, train_loss: 0.0864, step time: 0.4098\n",
      "6/224, train_loss: 0.1186, step time: 0.3948\n",
      "7/224, train_loss: 0.1659, step time: 0.4029\n",
      "8/224, train_loss: 0.1585, step time: 0.3161\n",
      "9/224, train_loss: 0.1316, step time: 0.4051\n",
      "10/224, train_loss: 0.0849, step time: 0.3163\n",
      "11/224, train_loss: 0.0715, step time: 0.4142\n",
      "12/224, train_loss: 0.1071, step time: 0.3159\n",
      "13/224, train_loss: 0.0679, step time: 0.3159\n",
      "14/224, train_loss: 0.1652, step time: 0.4102\n",
      "15/224, train_loss: 0.1394, step time: 0.4027\n",
      "16/224, train_loss: 0.1332, step time: 0.4071\n",
      "17/224, train_loss: 0.1323, step time: 0.4071\n",
      "18/224, train_loss: 0.0813, step time: 0.3789\n",
      "19/224, train_loss: 0.1339, step time: 0.4001\n",
      "20/224, train_loss: 0.0781, step time: 0.3795\n",
      "21/224, train_loss: 0.0551, step time: 0.3151\n",
      "22/224, train_loss: 0.2004, step time: 0.3835\n",
      "23/224, train_loss: 0.2074, step time: 0.4083\n",
      "24/224, train_loss: 0.2545, step time: 0.3669\n",
      "25/224, train_loss: 0.1192, step time: 0.3177\n",
      "26/224, train_loss: 0.0712, step time: 0.3156\n",
      "27/224, train_loss: 0.0740, step time: 0.3179\n",
      "28/224, train_loss: 0.0797, step time: 0.3156\n",
      "29/224, train_loss: 0.0884, step time: 0.3179\n",
      "30/224, train_loss: 0.1363, step time: 0.3791\n",
      "31/224, train_loss: 0.1520, step time: 0.3731\n",
      "32/224, train_loss: 0.1832, step time: 0.3931\n",
      "33/224, train_loss: 0.3048, step time: 0.3961\n",
      "34/224, train_loss: 0.1915, step time: 0.4006\n",
      "35/224, train_loss: 0.0844, step time: 0.3177\n",
      "36/224, train_loss: 0.0851, step time: 0.3172\n",
      "37/224, train_loss: 0.1465, step time: 0.3982\n",
      "38/224, train_loss: 0.0857, step time: 0.3159\n",
      "39/224, train_loss: 0.0888, step time: 0.3862\n",
      "40/224, train_loss: 0.1113, step time: 0.3850\n",
      "41/224, train_loss: 0.1454, step time: 0.3802\n",
      "42/224, train_loss: 0.0680, step time: 0.3178\n",
      "43/224, train_loss: 0.0649, step time: 0.3969\n",
      "44/224, train_loss: 0.1059, step time: 0.3159\n",
      "45/224, train_loss: 0.1062, step time: 0.3151\n",
      "46/224, train_loss: 0.2017, step time: 0.3691\n",
      "47/224, train_loss: 0.1013, step time: 0.3659\n",
      "48/224, train_loss: 0.0618, step time: 0.3773\n",
      "49/224, train_loss: 0.1321, step time: 0.3951\n",
      "50/224, train_loss: 0.0466, step time: 0.3731\n",
      "51/224, train_loss: 0.0967, step time: 0.3170\n",
      "52/224, train_loss: 0.0892, step time: 0.3163\n",
      "53/224, train_loss: 0.2017, step time: 0.3660\n",
      "54/224, train_loss: 0.0612, step time: 0.3676\n",
      "55/224, train_loss: 0.0682, step time: 0.3178\n",
      "56/224, train_loss: 0.1247, step time: 0.3768\n",
      "57/224, train_loss: 0.0841, step time: 0.3178\n",
      "58/224, train_loss: 0.1185, step time: 0.4043\n",
      "59/224, train_loss: 0.1053, step time: 0.3831\n",
      "60/224, train_loss: 0.0578, step time: 0.3916\n",
      "61/224, train_loss: 0.2152, step time: 0.3135\n",
      "62/224, train_loss: 0.0463, step time: 0.3133\n",
      "63/224, train_loss: 0.1326, step time: 0.3968\n",
      "64/224, train_loss: 0.1149, step time: 0.3755\n",
      "65/224, train_loss: 0.1057, step time: 0.4121\n",
      "66/224, train_loss: 0.0731, step time: 0.3150\n",
      "67/224, train_loss: 0.0549, step time: 0.3126\n",
      "68/224, train_loss: 0.0543, step time: 0.3151\n",
      "69/224, train_loss: 0.0939, step time: 0.3156\n",
      "70/224, train_loss: 0.0985, step time: 0.3132\n",
      "71/224, train_loss: 0.2614, step time: 0.3815\n",
      "72/224, train_loss: 0.0694, step time: 0.3157\n",
      "73/224, train_loss: 0.1449, step time: 0.3138\n",
      "74/224, train_loss: 0.0621, step time: 0.3999\n",
      "75/224, train_loss: 0.0914, step time: 0.3819\n",
      "76/224, train_loss: 0.1079, step time: 0.3154\n",
      "77/224, train_loss: 0.0931, step time: 0.4068\n",
      "78/224, train_loss: 0.0701, step time: 0.3146\n",
      "79/224, train_loss: 0.0926, step time: 0.3785\n",
      "80/224, train_loss: 0.0625, step time: 0.3131\n",
      "81/224, train_loss: 0.1076, step time: 0.3973\n",
      "82/224, train_loss: 0.0954, step time: 0.3153\n",
      "83/224, train_loss: 0.0903, step time: 0.3171\n",
      "84/224, train_loss: 0.1602, step time: 0.3867\n",
      "85/224, train_loss: 0.1739, step time: 0.3945\n",
      "86/224, train_loss: 0.0904, step time: 0.3135\n",
      "87/224, train_loss: 0.0368, step time: 0.3901\n",
      "88/224, train_loss: 0.0705, step time: 0.3178\n",
      "89/224, train_loss: 0.1154, step time: 0.4134\n",
      "90/224, train_loss: 0.1927, step time: 0.4000\n",
      "91/224, train_loss: 0.0539, step time: 0.3184\n",
      "92/224, train_loss: 0.0783, step time: 0.3190\n",
      "93/224, train_loss: 0.1382, step time: 0.3968\n",
      "94/224, train_loss: 0.0965, step time: 0.3928\n",
      "95/224, train_loss: 0.1402, step time: 0.3781\n",
      "96/224, train_loss: 0.1746, step time: 0.3950\n",
      "97/224, train_loss: 0.1396, step time: 0.3833\n",
      "98/224, train_loss: 0.1125, step time: 0.3147\n",
      "99/224, train_loss: 0.0718, step time: 0.3145\n",
      "100/224, train_loss: 0.0914, step time: 0.3123\n",
      "101/224, train_loss: 0.1037, step time: 0.4099\n",
      "102/224, train_loss: 0.2316, step time: 0.3873\n",
      "103/224, train_loss: 0.0562, step time: 0.3160\n",
      "104/224, train_loss: 0.1416, step time: 0.4103\n",
      "105/224, train_loss: 0.0424, step time: 0.3132\n",
      "106/224, train_loss: 0.0946, step time: 0.3148\n",
      "107/224, train_loss: 0.1110, step time: 0.3171\n",
      "108/224, train_loss: 0.1141, step time: 0.3156\n",
      "109/224, train_loss: 0.0812, step time: 0.3131\n",
      "110/224, train_loss: 0.0769, step time: 0.3126\n",
      "111/224, train_loss: 0.0854, step time: 0.3148\n",
      "112/224, train_loss: 0.0811, step time: 0.3935\n",
      "113/224, train_loss: 0.0579, step time: 0.3177\n",
      "114/224, train_loss: 0.0805, step time: 0.3150\n",
      "115/224, train_loss: 0.0726, step time: 0.3940\n",
      "116/224, train_loss: 0.0491, step time: 0.3147\n",
      "117/224, train_loss: 0.1030, step time: 0.3153\n",
      "118/224, train_loss: 0.0734, step time: 0.3866\n",
      "119/224, train_loss: 0.1475, step time: 0.3860\n",
      "120/224, train_loss: 0.1010, step time: 0.4012\n",
      "121/224, train_loss: 0.0725, step time: 0.3130\n",
      "122/224, train_loss: 0.2398, step time: 0.4137\n",
      "123/224, train_loss: 0.0732, step time: 0.3992\n",
      "124/224, train_loss: 0.1492, step time: 0.3146\n",
      "125/224, train_loss: 0.0850, step time: 0.3665\n",
      "126/224, train_loss: 0.1285, step time: 0.3891\n",
      "127/224, train_loss: 0.1036, step time: 0.3129\n",
      "128/224, train_loss: 0.1128, step time: 0.3142\n",
      "129/224, train_loss: 0.0432, step time: 0.3122\n",
      "130/224, train_loss: 0.0734, step time: 0.3164\n",
      "131/224, train_loss: 0.1861, step time: 0.3141\n",
      "132/224, train_loss: 0.0865, step time: 0.3145\n",
      "133/224, train_loss: 0.0922, step time: 0.3146\n",
      "134/224, train_loss: 0.0804, step time: 0.3131\n",
      "135/224, train_loss: 0.1257, step time: 0.3123\n",
      "136/224, train_loss: 0.0741, step time: 0.3145\n",
      "137/224, train_loss: 0.1007, step time: 0.3869\n",
      "138/224, train_loss: 0.1018, step time: 0.3164\n",
      "139/224, train_loss: 0.1348, step time: 0.3166\n",
      "140/224, train_loss: 0.0810, step time: 0.4102\n",
      "141/224, train_loss: 0.2167, step time: 0.3874\n",
      "142/224, train_loss: 0.1498, step time: 0.4033\n",
      "143/224, train_loss: 0.0447, step time: 0.3144\n",
      "144/224, train_loss: 0.0953, step time: 0.3122\n",
      "145/224, train_loss: 0.0808, step time: 0.3144\n",
      "146/224, train_loss: 0.1125, step time: 0.3886\n",
      "147/224, train_loss: 0.0591, step time: 0.3129\n",
      "148/224, train_loss: 0.0708, step time: 0.3722\n",
      "149/224, train_loss: 0.1278, step time: 0.3891\n",
      "150/224, train_loss: 0.0740, step time: 0.3143\n",
      "151/224, train_loss: 0.0612, step time: 0.3141\n",
      "152/224, train_loss: 0.3975, step time: 0.3832\n",
      "153/224, train_loss: 0.4041, step time: 0.3777\n",
      "154/224, train_loss: 0.0797, step time: 0.3886\n",
      "155/224, train_loss: 0.0597, step time: 0.3180\n",
      "156/224, train_loss: 0.2643, step time: 0.3925\n",
      "157/224, train_loss: 0.0709, step time: 0.3153\n",
      "158/224, train_loss: 0.0617, step time: 0.3891\n",
      "159/224, train_loss: 0.0676, step time: 0.3155\n",
      "160/224, train_loss: 0.1108, step time: 0.3159\n",
      "161/224, train_loss: 0.0808, step time: 0.4095\n",
      "162/224, train_loss: 0.1075, step time: 0.3682\n",
      "163/224, train_loss: 0.2010, step time: 0.3971\n",
      "164/224, train_loss: 0.1120, step time: 0.3157\n",
      "165/224, train_loss: 0.0855, step time: 0.3144\n",
      "166/224, train_loss: 0.0811, step time: 0.3157\n",
      "167/224, train_loss: 0.1345, step time: 0.3913\n",
      "168/224, train_loss: 0.0549, step time: 0.3163\n",
      "169/224, train_loss: 0.1194, step time: 0.3183\n",
      "170/224, train_loss: 0.1347, step time: 0.4064\n",
      "171/224, train_loss: 0.1935, step time: 0.3857\n",
      "172/224, train_loss: 0.0815, step time: 0.3162\n",
      "173/224, train_loss: 0.1159, step time: 0.3163\n",
      "174/224, train_loss: 0.1317, step time: 0.3760\n",
      "175/224, train_loss: 0.0817, step time: 0.3682\n",
      "176/224, train_loss: 0.2452, step time: 0.3902\n",
      "177/224, train_loss: 0.0907, step time: 0.3177\n",
      "178/224, train_loss: 0.1570, step time: 0.3844\n",
      "179/224, train_loss: 0.0652, step time: 0.3178\n",
      "180/224, train_loss: 0.1075, step time: 0.3930\n",
      "181/224, train_loss: 0.0652, step time: 0.3175\n",
      "182/224, train_loss: 0.0687, step time: 0.3151\n",
      "183/224, train_loss: 0.0821, step time: 0.3149\n",
      "184/224, train_loss: 0.0941, step time: 0.3150\n",
      "185/224, train_loss: 0.0650, step time: 0.3130\n",
      "186/224, train_loss: 0.1216, step time: 0.3972\n",
      "187/224, train_loss: 0.0581, step time: 0.3156\n",
      "188/224, train_loss: 0.0980, step time: 0.3879\n",
      "189/224, train_loss: 0.0790, step time: 0.3960\n",
      "190/224, train_loss: 0.0958, step time: 0.3876\n",
      "191/224, train_loss: 0.0675, step time: 0.3176\n",
      "192/224, train_loss: 0.1141, step time: 0.3982\n",
      "193/224, train_loss: 0.3152, step time: 0.4046\n",
      "194/224, train_loss: 0.0818, step time: 0.3153\n",
      "195/224, train_loss: 0.1263, step time: 0.3177\n",
      "196/224, train_loss: 0.1343, step time: 0.3671\n",
      "197/224, train_loss: 0.0869, step time: 0.3133\n",
      "198/224, train_loss: 0.1376, step time: 0.3689\n",
      "199/224, train_loss: 0.1039, step time: 0.3968\n",
      "200/224, train_loss: 0.1192, step time: 0.3172\n",
      "201/224, train_loss: 0.1922, step time: 0.3790\n",
      "202/224, train_loss: 0.0531, step time: 0.3159\n",
      "203/224, train_loss: 0.0791, step time: 0.3151\n",
      "204/224, train_loss: 0.0837, step time: 0.3129\n",
      "205/224, train_loss: 0.0745, step time: 0.3129\n",
      "206/224, train_loss: 0.0733, step time: 0.3692\n",
      "207/224, train_loss: 0.0732, step time: 0.3131\n",
      "208/224, train_loss: 0.1001, step time: 0.3730\n",
      "209/224, train_loss: 0.1132, step time: 0.3161\n",
      "210/224, train_loss: 0.0731, step time: 0.3898\n",
      "211/224, train_loss: 0.0558, step time: 0.3178\n",
      "212/224, train_loss: 0.1012, step time: 0.3158\n",
      "213/224, train_loss: 0.0729, step time: 0.3134\n",
      "214/224, train_loss: 0.0965, step time: 0.3131\n",
      "215/224, train_loss: 0.1256, step time: 0.4069\n",
      "216/224, train_loss: 0.0747, step time: 0.3160\n",
      "217/224, train_loss: 0.0827, step time: 0.3137\n",
      "218/224, train_loss: 0.1434, step time: 0.3165\n",
      "219/224, train_loss: 0.0727, step time: 0.4098\n",
      "220/224, train_loss: 0.1132, step time: 0.3156\n",
      "221/224, train_loss: 0.0730, step time: 0.3956\n",
      "222/224, train_loss: 0.1891, step time: 0.3686\n",
      "223/224, train_loss: 0.1016, step time: 0.3944\n",
      "224/224, train_loss: 0.1249, step time: 0.3150\n",
      "epoch 98 average loss: 0.1107\n",
      "current epoch: 98 current mean dice: 0.7153 class1: 0.9994 class2: 0.7466 class3: 0.3998\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 98 is: 723.4066\n",
      "hello\n",
      "----------\n",
      "epoch 99/100\n",
      "1/224, train_loss: 0.1004, step time: 0.4020\n",
      "2/224, train_loss: 0.0623, step time: 0.3184\n",
      "3/224, train_loss: 0.0974, step time: 0.4091\n",
      "4/224, train_loss: 0.2513, step time: 0.3722\n",
      "5/224, train_loss: 0.0561, step time: 0.3156\n",
      "6/224, train_loss: 0.1210, step time: 0.3157\n",
      "7/224, train_loss: 0.0537, step time: 0.3856\n",
      "8/224, train_loss: 0.0787, step time: 0.3176\n",
      "9/224, train_loss: 0.2384, step time: 0.3783\n",
      "10/224, train_loss: 0.1139, step time: 0.3164\n",
      "11/224, train_loss: 0.1090, step time: 0.4075\n",
      "12/224, train_loss: 0.3074, step time: 0.3922\n",
      "13/224, train_loss: 0.0867, step time: 0.3131\n",
      "14/224, train_loss: 0.0726, step time: 0.3180\n",
      "15/224, train_loss: 0.1117, step time: 0.4034\n",
      "16/224, train_loss: 0.0628, step time: 0.3181\n",
      "17/224, train_loss: 0.0679, step time: 0.3142\n",
      "18/224, train_loss: 0.1317, step time: 0.3975\n",
      "19/224, train_loss: 0.1132, step time: 0.3953\n",
      "20/224, train_loss: 0.0733, step time: 0.3174\n",
      "21/224, train_loss: 0.1598, step time: 0.3669\n",
      "22/224, train_loss: 0.0590, step time: 0.3146\n",
      "23/224, train_loss: 0.1038, step time: 0.3693\n",
      "24/224, train_loss: 0.0967, step time: 0.3162\n",
      "25/224, train_loss: 0.0968, step time: 0.4116\n",
      "26/224, train_loss: 0.1229, step time: 0.3874\n",
      "27/224, train_loss: 0.0557, step time: 0.3148\n",
      "28/224, train_loss: 0.3441, step time: 0.4039\n",
      "29/224, train_loss: 0.0652, step time: 0.3150\n",
      "30/224, train_loss: 0.0899, step time: 0.3904\n",
      "31/224, train_loss: 0.1053, step time: 0.3149\n",
      "32/224, train_loss: 0.1616, step time: 0.3816\n",
      "33/224, train_loss: 0.0818, step time: 0.3148\n",
      "34/224, train_loss: 0.2069, step time: 0.3631\n",
      "35/224, train_loss: 0.0624, step time: 0.3152\n",
      "36/224, train_loss: 0.3126, step time: 0.3875\n",
      "37/224, train_loss: 0.0717, step time: 0.3928\n",
      "38/224, train_loss: 0.0661, step time: 0.3146\n",
      "39/224, train_loss: 0.0995, step time: 0.4050\n",
      "40/224, train_loss: 0.0547, step time: 0.3124\n",
      "41/224, train_loss: 0.0876, step time: 0.3143\n",
      "42/224, train_loss: 0.0621, step time: 0.3147\n",
      "43/224, train_loss: 0.0400, step time: 0.4110\n",
      "44/224, train_loss: 0.0835, step time: 0.4031\n",
      "45/224, train_loss: 0.1076, step time: 0.3726\n",
      "46/224, train_loss: 0.0826, step time: 0.3172\n",
      "47/224, train_loss: 0.0744, step time: 0.3151\n",
      "48/224, train_loss: 0.0812, step time: 0.3621\n",
      "49/224, train_loss: 0.1953, step time: 0.3827\n",
      "50/224, train_loss: 0.0841, step time: 0.3810\n",
      "51/224, train_loss: 0.1070, step time: 0.3699\n",
      "52/224, train_loss: 0.1429, step time: 0.3677\n",
      "53/224, train_loss: 0.0594, step time: 0.3151\n",
      "54/224, train_loss: 0.0914, step time: 0.3690\n",
      "55/224, train_loss: 0.0880, step time: 0.3169\n",
      "56/224, train_loss: 0.0931, step time: 0.3818\n",
      "57/224, train_loss: 0.0818, step time: 0.4079\n",
      "58/224, train_loss: 0.0951, step time: 0.3752\n",
      "59/224, train_loss: 0.0829, step time: 0.3122\n",
      "60/224, train_loss: 0.0497, step time: 0.3121\n",
      "61/224, train_loss: 0.0831, step time: 0.3879\n",
      "62/224, train_loss: 0.0713, step time: 0.3145\n",
      "63/224, train_loss: 0.1368, step time: 0.3164\n",
      "64/224, train_loss: 0.1144, step time: 0.3140\n",
      "65/224, train_loss: 0.0865, step time: 0.3818\n",
      "66/224, train_loss: 0.1877, step time: 0.4091\n",
      "67/224, train_loss: 0.4079, step time: 0.3717\n",
      "68/224, train_loss: 0.0997, step time: 0.4068\n",
      "69/224, train_loss: 0.0528, step time: 0.3865\n",
      "70/224, train_loss: 0.0688, step time: 0.3160\n",
      "71/224, train_loss: 0.1305, step time: 0.3139\n",
      "72/224, train_loss: 0.0763, step time: 0.3148\n",
      "73/224, train_loss: 0.0870, step time: 0.3910\n",
      "74/224, train_loss: 0.0832, step time: 0.3752\n",
      "75/224, train_loss: 0.3225, step time: 0.3955\n",
      "76/224, train_loss: 0.1009, step time: 0.3154\n",
      "77/224, train_loss: 0.0845, step time: 0.3837\n",
      "78/224, train_loss: 0.2982, step time: 0.3982\n",
      "79/224, train_loss: 0.0801, step time: 0.3673\n",
      "80/224, train_loss: 0.0998, step time: 0.3142\n",
      "81/224, train_loss: 0.0513, step time: 0.3168\n",
      "82/224, train_loss: 0.0702, step time: 0.3140\n",
      "83/224, train_loss: 0.0726, step time: 0.3140\n",
      "84/224, train_loss: 0.0800, step time: 0.3149\n",
      "85/224, train_loss: 0.0839, step time: 0.3147\n",
      "86/224, train_loss: 0.1179, step time: 0.3148\n",
      "87/224, train_loss: 0.1054, step time: 0.3148\n",
      "88/224, train_loss: 0.1827, step time: 0.4003\n",
      "89/224, train_loss: 0.0770, step time: 0.3142\n",
      "90/224, train_loss: 0.0774, step time: 0.3163\n",
      "91/224, train_loss: 0.0699, step time: 0.3141\n",
      "92/224, train_loss: 0.0791, step time: 0.3137\n",
      "93/224, train_loss: 0.1308, step time: 0.3947\n",
      "94/224, train_loss: 0.1433, step time: 0.3673\n",
      "95/224, train_loss: 0.0700, step time: 0.3142\n",
      "96/224, train_loss: 0.0965, step time: 0.3929\n",
      "97/224, train_loss: 0.0695, step time: 0.3144\n",
      "98/224, train_loss: 0.0677, step time: 0.3143\n",
      "99/224, train_loss: 0.1669, step time: 0.4026\n",
      "100/224, train_loss: 0.0904, step time: 0.3857\n",
      "101/224, train_loss: 0.0962, step time: 0.3144\n",
      "102/224, train_loss: 0.2296, step time: 0.3754\n",
      "103/224, train_loss: 0.1612, step time: 0.3805\n",
      "104/224, train_loss: 0.1198, step time: 0.3138\n",
      "105/224, train_loss: 0.1126, step time: 0.4053\n",
      "106/224, train_loss: 0.1537, step time: 0.3871\n",
      "107/224, train_loss: 0.1005, step time: 0.3741\n",
      "108/224, train_loss: 0.0855, step time: 0.3755\n",
      "109/224, train_loss: 0.0975, step time: 0.3174\n",
      "110/224, train_loss: 0.0460, step time: 0.3121\n",
      "111/224, train_loss: 0.0997, step time: 0.3993\n",
      "112/224, train_loss: 0.1912, step time: 0.3737\n",
      "113/224, train_loss: 0.1185, step time: 0.3709\n",
      "114/224, train_loss: 0.0410, step time: 0.3148\n",
      "115/224, train_loss: 0.0593, step time: 0.3834\n",
      "116/224, train_loss: 0.0627, step time: 0.3121\n",
      "117/224, train_loss: 0.0616, step time: 0.3837\n",
      "118/224, train_loss: 0.0671, step time: 0.3910\n",
      "119/224, train_loss: 0.0988, step time: 0.3980\n",
      "120/224, train_loss: 0.1130, step time: 0.3161\n",
      "121/224, train_loss: 0.0699, step time: 0.3161\n",
      "122/224, train_loss: 0.1689, step time: 0.3127\n",
      "123/224, train_loss: 0.0982, step time: 0.3801\n",
      "124/224, train_loss: 0.1051, step time: 0.3141\n",
      "125/224, train_loss: 0.1039, step time: 0.3629\n",
      "126/224, train_loss: 0.0784, step time: 0.3148\n",
      "127/224, train_loss: 0.1104, step time: 0.3169\n",
      "128/224, train_loss: 0.0757, step time: 0.3121\n",
      "129/224, train_loss: 0.0737, step time: 0.3142\n",
      "130/224, train_loss: 0.0771, step time: 0.3149\n",
      "131/224, train_loss: 0.0803, step time: 0.3879\n",
      "132/224, train_loss: 0.1183, step time: 0.3176\n",
      "133/224, train_loss: 0.1163, step time: 0.3149\n",
      "134/224, train_loss: 0.0824, step time: 0.3747\n",
      "135/224, train_loss: 0.0760, step time: 0.3148\n",
      "136/224, train_loss: 0.0979, step time: 0.3895\n",
      "137/224, train_loss: 0.0789, step time: 0.3975\n",
      "138/224, train_loss: 0.0618, step time: 0.3141\n",
      "139/224, train_loss: 0.1010, step time: 0.3165\n",
      "140/224, train_loss: 0.0731, step time: 0.3782\n",
      "141/224, train_loss: 0.0724, step time: 0.3169\n",
      "142/224, train_loss: 0.1076, step time: 0.3979\n",
      "143/224, train_loss: 0.0758, step time: 0.3145\n",
      "144/224, train_loss: 0.1041, step time: 0.3962\n",
      "145/224, train_loss: 0.3468, step time: 0.3934\n",
      "146/224, train_loss: 0.2062, step time: 0.3984\n",
      "147/224, train_loss: 0.1926, step time: 0.3830\n",
      "148/224, train_loss: 0.1579, step time: 0.3853\n",
      "149/224, train_loss: 0.3436, step time: 0.4091\n",
      "150/224, train_loss: 0.0931, step time: 0.3871\n",
      "151/224, train_loss: 0.1429, step time: 0.3715\n",
      "152/224, train_loss: 0.1152, step time: 0.3143\n",
      "153/224, train_loss: 0.1483, step time: 0.4057\n",
      "154/224, train_loss: 0.0670, step time: 0.3820\n",
      "155/224, train_loss: 0.0496, step time: 0.3142\n",
      "156/224, train_loss: 0.0601, step time: 0.3121\n",
      "157/224, train_loss: 0.0831, step time: 0.3733\n",
      "158/224, train_loss: 0.2180, step time: 0.3139\n",
      "159/224, train_loss: 0.1962, step time: 0.4094\n",
      "160/224, train_loss: 0.1175, step time: 0.3155\n",
      "161/224, train_loss: 0.1240, step time: 0.3148\n",
      "162/224, train_loss: 0.2034, step time: 0.3961\n",
      "163/224, train_loss: 0.1423, step time: 0.3183\n",
      "164/224, train_loss: 0.0984, step time: 0.4068\n",
      "165/224, train_loss: 0.1254, step time: 0.3146\n",
      "166/224, train_loss: 0.1748, step time: 0.4086\n",
      "167/224, train_loss: 0.0908, step time: 0.3122\n",
      "168/224, train_loss: 0.1003, step time: 0.3164\n",
      "169/224, train_loss: 0.1115, step time: 0.3125\n",
      "170/224, train_loss: 0.1190, step time: 0.3698\n",
      "171/224, train_loss: 0.0957, step time: 0.3145\n",
      "172/224, train_loss: 0.0827, step time: 0.3168\n",
      "173/224, train_loss: 0.1167, step time: 0.3129\n",
      "174/224, train_loss: 0.0807, step time: 0.3154\n",
      "175/224, train_loss: 0.0576, step time: 0.3131\n",
      "176/224, train_loss: 0.1659, step time: 0.3143\n",
      "177/224, train_loss: 0.0764, step time: 0.3998\n",
      "178/224, train_loss: 0.0646, step time: 0.3154\n",
      "179/224, train_loss: 0.0750, step time: 0.3184\n",
      "180/224, train_loss: 0.1173, step time: 0.3841\n",
      "181/224, train_loss: 0.0683, step time: 0.3166\n",
      "182/224, train_loss: 0.0658, step time: 0.3156\n",
      "183/224, train_loss: 0.0444, step time: 0.4066\n",
      "184/224, train_loss: 0.0952, step time: 0.3152\n",
      "185/224, train_loss: 0.0722, step time: 0.3171\n",
      "186/224, train_loss: 0.0738, step time: 0.3148\n",
      "187/224, train_loss: 0.0764, step time: 0.3945\n",
      "188/224, train_loss: 0.0413, step time: 0.3720\n",
      "189/224, train_loss: 0.0880, step time: 0.3149\n",
      "190/224, train_loss: 0.0787, step time: 0.3145\n",
      "191/224, train_loss: 0.0668, step time: 0.3124\n",
      "192/224, train_loss: 0.2773, step time: 0.3868\n",
      "193/224, train_loss: 0.0662, step time: 0.3165\n",
      "194/224, train_loss: 0.1216, step time: 0.3149\n",
      "195/224, train_loss: 0.1464, step time: 0.3172\n",
      "196/224, train_loss: 0.0993, step time: 0.3780\n",
      "197/224, train_loss: 0.0944, step time: 0.3756\n",
      "198/224, train_loss: 0.0535, step time: 0.3172\n",
      "199/224, train_loss: 0.0741, step time: 0.3151\n",
      "200/224, train_loss: 0.2319, step time: 0.4026\n",
      "201/224, train_loss: 0.0862, step time: 0.3124\n",
      "202/224, train_loss: 0.0887, step time: 0.3666\n",
      "203/224, train_loss: 0.1111, step time: 0.3151\n",
      "204/224, train_loss: 0.1508, step time: 0.3295\n",
      "205/224, train_loss: 0.1590, step time: 0.3773\n",
      "206/224, train_loss: 0.0893, step time: 0.3745\n",
      "207/224, train_loss: 0.0648, step time: 0.3708\n",
      "208/224, train_loss: 0.0701, step time: 0.3141\n",
      "209/224, train_loss: 0.0502, step time: 0.3166\n",
      "210/224, train_loss: 0.0926, step time: 0.3168\n",
      "211/224, train_loss: 0.0681, step time: 0.3149\n",
      "212/224, train_loss: 0.0682, step time: 0.3143\n",
      "213/224, train_loss: 0.1492, step time: 0.3683\n",
      "214/224, train_loss: 0.0777, step time: 0.4117\n",
      "215/224, train_loss: 0.0741, step time: 0.3166\n",
      "216/224, train_loss: 0.0855, step time: 0.3888\n",
      "217/224, train_loss: 0.1700, step time: 0.4012\n",
      "218/224, train_loss: 0.0454, step time: 0.3168\n",
      "219/224, train_loss: 0.1020, step time: 0.3968\n",
      "220/224, train_loss: 0.0482, step time: 0.3157\n",
      "221/224, train_loss: 0.0674, step time: 0.3156\n",
      "222/224, train_loss: 0.0951, step time: 0.3172\n",
      "223/224, train_loss: 0.1587, step time: 0.3753\n",
      "224/224, train_loss: 0.2557, step time: 0.4084\n",
      "epoch 99 average loss: 0.1095\n",
      "current epoch: 99 current mean dice: 0.7200 class1: 0.9994 class2: 0.7495 class3: 0.4111\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 99 is: 723.9170\n",
      "hello\n",
      "----------\n",
      "epoch 100/100\n",
      "1/224, train_loss: 0.0527, step time: 0.3153\n",
      "2/224, train_loss: 0.0661, step time: 0.3174\n",
      "3/224, train_loss: 0.0750, step time: 0.3133\n",
      "4/224, train_loss: 0.0945, step time: 0.3178\n",
      "5/224, train_loss: 0.2756, step time: 0.4023\n",
      "6/224, train_loss: 0.1083, step time: 0.3816\n",
      "7/224, train_loss: 0.0658, step time: 0.3169\n",
      "8/224, train_loss: 0.0687, step time: 0.3137\n",
      "9/224, train_loss: 0.0404, step time: 0.4033\n",
      "10/224, train_loss: 0.1217, step time: 0.4026\n",
      "11/224, train_loss: 0.0910, step time: 0.4109\n",
      "12/224, train_loss: 0.0768, step time: 0.3158\n",
      "13/224, train_loss: 0.1153, step time: 0.4041\n",
      "14/224, train_loss: 0.0950, step time: 0.3885\n",
      "15/224, train_loss: 0.0982, step time: 0.3163\n",
      "16/224, train_loss: 0.0841, step time: 0.3878\n",
      "17/224, train_loss: 0.0838, step time: 0.3132\n",
      "18/224, train_loss: 0.0472, step time: 0.3699\n",
      "19/224, train_loss: 0.1084, step time: 0.4034\n",
      "20/224, train_loss: 0.1119, step time: 0.3970\n",
      "21/224, train_loss: 0.1053, step time: 0.3862\n",
      "22/224, train_loss: 0.1017, step time: 0.3142\n",
      "23/224, train_loss: 0.0794, step time: 0.3175\n",
      "24/224, train_loss: 0.0794, step time: 0.3154\n",
      "25/224, train_loss: 0.0711, step time: 0.3154\n",
      "26/224, train_loss: 0.1717, step time: 0.4000\n",
      "27/224, train_loss: 0.0693, step time: 0.3127\n",
      "28/224, train_loss: 0.0731, step time: 0.3153\n",
      "29/224, train_loss: 0.0835, step time: 0.3669\n",
      "30/224, train_loss: 0.0771, step time: 0.3158\n",
      "31/224, train_loss: 0.0966, step time: 0.4026\n",
      "32/224, train_loss: 0.0703, step time: 0.3145\n",
      "33/224, train_loss: 0.1641, step time: 0.3877\n",
      "34/224, train_loss: 0.0572, step time: 0.3128\n",
      "35/224, train_loss: 0.0563, step time: 0.3729\n",
      "36/224, train_loss: 0.1277, step time: 0.3148\n",
      "37/224, train_loss: 0.0912, step time: 0.3896\n",
      "38/224, train_loss: 0.0829, step time: 0.3987\n",
      "39/224, train_loss: 0.0461, step time: 0.3154\n",
      "40/224, train_loss: 0.0777, step time: 0.3169\n",
      "41/224, train_loss: 0.0900, step time: 0.3177\n",
      "42/224, train_loss: 0.2345, step time: 0.3701\n",
      "43/224, train_loss: 0.1330, step time: 0.3909\n",
      "44/224, train_loss: 0.1040, step time: 0.3850\n",
      "45/224, train_loss: 0.0538, step time: 0.3818\n",
      "46/224, train_loss: 0.0794, step time: 0.3832\n",
      "47/224, train_loss: 0.0743, step time: 0.3178\n",
      "48/224, train_loss: 0.1108, step time: 0.3157\n",
      "49/224, train_loss: 0.1016, step time: 0.3851\n",
      "50/224, train_loss: 0.1277, step time: 0.3135\n",
      "51/224, train_loss: 0.1113, step time: 0.3918\n",
      "52/224, train_loss: 0.0760, step time: 0.3152\n",
      "53/224, train_loss: 0.0757, step time: 0.3630\n",
      "54/224, train_loss: 0.0787, step time: 0.4000\n",
      "55/224, train_loss: 0.1059, step time: 0.3854\n",
      "56/224, train_loss: 0.0804, step time: 0.3179\n",
      "57/224, train_loss: 0.1978, step time: 0.3818\n",
      "58/224, train_loss: 0.0870, step time: 0.4055\n",
      "59/224, train_loss: 0.1557, step time: 0.4015\n",
      "60/224, train_loss: 0.0832, step time: 0.3684\n",
      "61/224, train_loss: 0.0854, step time: 0.3836\n",
      "62/224, train_loss: 0.0694, step time: 0.3172\n",
      "63/224, train_loss: 0.0903, step time: 0.3780\n",
      "64/224, train_loss: 0.2789, step time: 0.3178\n",
      "65/224, train_loss: 0.1169, step time: 0.3159\n",
      "66/224, train_loss: 0.0950, step time: 0.3181\n",
      "67/224, train_loss: 0.0749, step time: 0.3149\n",
      "68/224, train_loss: 0.0750, step time: 0.3157\n",
      "69/224, train_loss: 0.0836, step time: 0.3857\n",
      "70/224, train_loss: 0.0939, step time: 0.3178\n",
      "71/224, train_loss: 0.0713, step time: 0.3180\n",
      "72/224, train_loss: 0.0661, step time: 0.3177\n",
      "73/224, train_loss: 0.0991, step time: 0.3151\n",
      "74/224, train_loss: 0.0978, step time: 0.3160\n",
      "75/224, train_loss: 0.0627, step time: 0.3157\n",
      "76/224, train_loss: 0.0505, step time: 0.3926\n",
      "77/224, train_loss: 0.2575, step time: 0.3896\n",
      "78/224, train_loss: 0.0986, step time: 0.3156\n",
      "79/224, train_loss: 0.1800, step time: 0.4088\n",
      "80/224, train_loss: 0.1402, step time: 0.4032\n",
      "81/224, train_loss: 0.0707, step time: 0.3866\n",
      "82/224, train_loss: 0.1307, step time: 0.4001\n",
      "83/224, train_loss: 0.1221, step time: 0.3845\n",
      "84/224, train_loss: 0.3310, step time: 0.3721\n",
      "85/224, train_loss: 0.1191, step time: 0.4001\n",
      "86/224, train_loss: 0.0931, step time: 0.3174\n",
      "87/224, train_loss: 0.0632, step time: 0.3830\n",
      "88/224, train_loss: 0.1193, step time: 0.4019\n",
      "89/224, train_loss: 0.0919, step time: 0.3910\n",
      "90/224, train_loss: 0.1281, step time: 0.3176\n",
      "91/224, train_loss: 0.1863, step time: 0.4043\n",
      "92/224, train_loss: 0.0838, step time: 0.3152\n",
      "93/224, train_loss: 0.1799, step time: 0.3147\n",
      "94/224, train_loss: 0.0918, step time: 0.4097\n",
      "95/224, train_loss: 0.0915, step time: 0.4060\n",
      "96/224, train_loss: 0.1179, step time: 0.3163\n",
      "97/224, train_loss: 0.1113, step time: 0.3893\n",
      "98/224, train_loss: 0.0813, step time: 0.3153\n",
      "99/224, train_loss: 0.0684, step time: 0.3157\n",
      "100/224, train_loss: 0.0867, step time: 0.4065\n",
      "101/224, train_loss: 0.0521, step time: 0.3120\n",
      "102/224, train_loss: 0.0775, step time: 0.3139\n",
      "103/224, train_loss: 0.0981, step time: 0.4008\n",
      "104/224, train_loss: 0.0997, step time: 0.3661\n",
      "105/224, train_loss: 0.1310, step time: 0.3740\n",
      "106/224, train_loss: 0.1032, step time: 0.4055\n",
      "107/224, train_loss: 0.1561, step time: 0.3146\n",
      "108/224, train_loss: 0.1758, step time: 0.3655\n",
      "109/224, train_loss: 0.0690, step time: 0.3166\n",
      "110/224, train_loss: 0.0994, step time: 0.3807\n",
      "111/224, train_loss: 0.0485, step time: 0.3807\n",
      "112/224, train_loss: 0.0851, step time: 0.3809\n",
      "113/224, train_loss: 0.1141, step time: 0.3144\n",
      "114/224, train_loss: 0.1026, step time: 0.3742\n",
      "115/224, train_loss: 0.2305, step time: 0.3699\n",
      "116/224, train_loss: 0.1081, step time: 0.4057\n",
      "117/224, train_loss: 0.0640, step time: 0.4032\n",
      "118/224, train_loss: 0.1463, step time: 0.3858\n",
      "119/224, train_loss: 0.0790, step time: 0.4024\n",
      "120/224, train_loss: 0.0989, step time: 0.3754\n",
      "121/224, train_loss: 0.1245, step time: 0.3834\n",
      "122/224, train_loss: 0.1119, step time: 0.3145\n",
      "123/224, train_loss: 0.0656, step time: 0.3142\n",
      "124/224, train_loss: 0.0846, step time: 0.3769\n",
      "125/224, train_loss: 0.0783, step time: 0.3147\n",
      "126/224, train_loss: 0.1164, step time: 0.3984\n",
      "127/224, train_loss: 0.0770, step time: 0.3130\n",
      "128/224, train_loss: 0.1026, step time: 0.3918\n",
      "129/224, train_loss: 0.0961, step time: 0.3177\n",
      "130/224, train_loss: 0.0773, step time: 0.3871\n",
      "131/224, train_loss: 0.1336, step time: 0.4002\n",
      "132/224, train_loss: 0.0632, step time: 0.3153\n",
      "133/224, train_loss: 0.1125, step time: 0.3826\n",
      "134/224, train_loss: 0.0634, step time: 0.4048\n",
      "135/224, train_loss: 0.0769, step time: 0.3819\n",
      "136/224, train_loss: 0.0440, step time: 0.3172\n",
      "137/224, train_loss: 0.1113, step time: 0.3148\n",
      "138/224, train_loss: 0.0595, step time: 0.3154\n",
      "139/224, train_loss: 0.1327, step time: 0.3996\n",
      "140/224, train_loss: 0.2285, step time: 0.3717\n",
      "141/224, train_loss: 0.1190, step time: 0.3799\n",
      "142/224, train_loss: 0.0710, step time: 0.4043\n",
      "143/224, train_loss: 0.1209, step time: 0.3915\n",
      "144/224, train_loss: 0.0778, step time: 0.3989\n",
      "145/224, train_loss: 0.0636, step time: 0.3704\n",
      "146/224, train_loss: 0.0580, step time: 0.3146\n",
      "147/224, train_loss: 0.1031, step time: 0.3813\n",
      "148/224, train_loss: 0.0604, step time: 0.3833\n",
      "149/224, train_loss: 0.0615, step time: 0.3121\n",
      "150/224, train_loss: 0.1299, step time: 0.3147\n",
      "151/224, train_loss: 0.0886, step time: 0.3142\n",
      "152/224, train_loss: 0.1480, step time: 0.3112\n",
      "153/224, train_loss: 0.0613, step time: 0.3167\n",
      "154/224, train_loss: 0.1063, step time: 0.3154\n",
      "155/224, train_loss: 0.0617, step time: 0.3175\n",
      "156/224, train_loss: 0.0569, step time: 0.3774\n",
      "157/224, train_loss: 0.1014, step time: 0.3185\n",
      "158/224, train_loss: 0.1141, step time: 0.3810\n",
      "159/224, train_loss: 0.0781, step time: 0.3964\n",
      "160/224, train_loss: 0.0970, step time: 0.4113\n",
      "161/224, train_loss: 0.1011, step time: 0.3179\n",
      "162/224, train_loss: 0.1012, step time: 0.3691\n",
      "163/224, train_loss: 0.1296, step time: 0.4099\n",
      "164/224, train_loss: 0.0937, step time: 0.3184\n",
      "165/224, train_loss: 0.1139, step time: 0.3160\n",
      "166/224, train_loss: 0.1444, step time: 0.4100\n",
      "167/224, train_loss: 0.1034, step time: 0.3881\n",
      "168/224, train_loss: 0.0839, step time: 0.3158\n",
      "169/224, train_loss: 0.0701, step time: 0.3156\n",
      "170/224, train_loss: 0.1459, step time: 0.3796\n",
      "171/224, train_loss: 0.1248, step time: 0.3931\n",
      "172/224, train_loss: 0.0725, step time: 0.3156\n",
      "173/224, train_loss: 0.0873, step time: 0.3730\n",
      "174/224, train_loss: 0.0533, step time: 0.3150\n",
      "175/224, train_loss: 0.3243, step time: 0.3136\n",
      "176/224, train_loss: 0.1993, step time: 0.3998\n",
      "177/224, train_loss: 0.3313, step time: 0.4058\n",
      "178/224, train_loss: 0.2384, step time: 0.3663\n",
      "179/224, train_loss: 0.0698, step time: 0.3159\n",
      "180/224, train_loss: 0.0996, step time: 0.3712\n",
      "181/224, train_loss: 0.1193, step time: 0.3159\n",
      "182/224, train_loss: 0.0644, step time: 0.3179\n",
      "183/224, train_loss: 0.1032, step time: 0.3812\n",
      "184/224, train_loss: 0.0632, step time: 0.3163\n",
      "185/224, train_loss: 0.0794, step time: 0.3181\n",
      "186/224, train_loss: 0.1105, step time: 0.3931\n",
      "187/224, train_loss: 0.1094, step time: 0.3795\n",
      "188/224, train_loss: 0.0986, step time: 0.3171\n",
      "189/224, train_loss: 0.0493, step time: 0.4093\n",
      "190/224, train_loss: 0.1094, step time: 0.3156\n",
      "191/224, train_loss: 0.0803, step time: 0.3150\n",
      "192/224, train_loss: 0.0789, step time: 0.3156\n",
      "193/224, train_loss: 0.2019, step time: 0.3166\n",
      "194/224, train_loss: 0.0653, step time: 0.3175\n",
      "195/224, train_loss: 0.0938, step time: 0.4072\n",
      "196/224, train_loss: 0.1779, step time: 0.3153\n",
      "197/224, train_loss: 0.0632, step time: 0.3136\n",
      "198/224, train_loss: 0.1290, step time: 0.4020\n",
      "199/224, train_loss: 0.1844, step time: 0.3773\n",
      "200/224, train_loss: 0.1762, step time: 0.3843\n",
      "201/224, train_loss: 0.0811, step time: 0.3156\n",
      "202/224, train_loss: 0.0522, step time: 0.3158\n",
      "203/224, train_loss: 0.0986, step time: 0.3159\n",
      "204/224, train_loss: 0.1973, step time: 0.3974\n",
      "205/224, train_loss: 0.1251, step time: 0.3954\n",
      "206/224, train_loss: 0.1367, step time: 0.3150\n",
      "207/224, train_loss: 0.0451, step time: 0.3948\n",
      "208/224, train_loss: 0.1085, step time: 0.3150\n",
      "209/224, train_loss: 0.1379, step time: 0.3639\n",
      "210/224, train_loss: 0.1889, step time: 0.3646\n",
      "211/224, train_loss: 0.1525, step time: 0.3775\n",
      "212/224, train_loss: 0.1300, step time: 0.3160\n",
      "213/224, train_loss: 0.1747, step time: 0.3159\n",
      "214/224, train_loss: 0.0821, step time: 0.3152\n",
      "215/224, train_loss: 0.1410, step time: 0.4067\n",
      "216/224, train_loss: 0.0607, step time: 0.3133\n",
      "217/224, train_loss: 0.0725, step time: 0.3179\n",
      "218/224, train_loss: 0.0668, step time: 0.3994\n",
      "219/224, train_loss: 0.0933, step time: 0.3900\n",
      "220/224, train_loss: 0.0640, step time: 0.3177\n",
      "221/224, train_loss: 0.0723, step time: 0.4026\n",
      "222/224, train_loss: 0.1048, step time: 0.3140\n",
      "223/224, train_loss: 0.0788, step time: 0.3998\n",
      "224/224, train_loss: 0.0857, step time: 0.3149\n",
      "epoch 100 average loss: 0.1056\n",
      "current epoch: 100 current mean dice: 0.7083 class1: 0.9994 class2: 0.7276 class3: 0.3981\n",
      "best mean dice: 0.7297 at epoch: 81\n",
      "time consuming of epoch 100 is: 827.8230\n",
      "Mean Dice Score (class 2 and 3): 0.5628\n"
     ]
    }
   ],
   "source": [
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "best_metrics_epochs_and_time = [[], [], []]\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "metric_values_class1 = [] # Adjusted class labels for clarity\n",
    "metric_values_class2 = [] # Adjusted class labels for clarity\n",
    "metric_values_class3 = [] # Adjusted class labels for clarity\n",
    "max_epochs=100\n",
    "\n",
    "total_start = time.time()\n",
    "for epoch in range(max_epochs):\n",
    "    epoch_start = time.time()\n",
    "    print('hello')\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step_start = time.time()\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            f\"{step}/{len(train_dataset) // train_loader.batch_size}\"\n",
    "            f\", train_loss: {loss.item():.4f}\"\n",
    "            f\", step time: {(time.time() - step_start):.4f}\"\n",
    "        )\n",
    "    lr_scheduler.step()\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                val_outputs = inference(val_inputs)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                dice_metric_batch(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            metric_values.append(metric)\n",
    "            metric_batch = dice_metric_batch.aggregate()\n",
    "            metric_class1 = metric_batch[0].item() # Adjusted class labels for clarity\n",
    "            metric_values_class1.append(metric_class1) # Adjusted class labels for clarity\n",
    "            metric_class2 = metric_batch[1].item() # Adjusted class labels for clarity\n",
    "            metric_values_class2.append(metric_class2) # Adjusted class labels for clarity\n",
    "            metric_class3 = metric_batch[2].item() # Adjusted class labels for clarity\n",
    "            metric_values_class3.append(metric_class3) # Adjusted class labels for clarity\n",
    "            dice_metric.reset()\n",
    "            dice_metric_batch.reset()\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                best_metrics_epochs_and_time[0].append(best_metric)\n",
    "                best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
    "                best_metrics_epochs_and_time[2].append(time.time() - total_start)\n",
    "                # torch.save(\n",
    "                #     model.state_dict(),\n",
    "                #     os.path.join(root_dir, \"best_metric_model.pth\"),\n",
    "                # )\n",
    "                # print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\" class1: {metric_class1:.4f} class2: {metric_class2:.4f} class3: {metric_class3:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f}\"\n",
    "                f\" at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n",
    "total_time = time.time() - total_start\n",
    "\n",
    "# Calculate the mean dice score of only the 2nd and 3rd classes\n",
    "mean_dice_score = (metric_values_class2[-1] + metric_values_class3[-1]) / 2.0\n",
    "print(f\"Mean Dice Score (class 2 and 3): {mean_dice_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot epochs vs train loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, max_epochs + 1), epoch_loss_values, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epochs vs. Train Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot epochs vs mean dice score\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(val_interval, max_epochs + 1, val_interval), metric_values, label='Mean Dice Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Dice Score')\n",
    "plt.title('Epochs vs. Mean Dice Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot epochs vs class 1, 2, and 3 dice scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(val_interval, max_epochs + 1, val_interval), metric_values_class1, label='Class 1')\n",
    "plt.plot(range(val_interval, max_epochs + 1, val_interval), metric_values_class2, label='Class 2')\n",
    "plt.plot(range(val_interval, max_epochs + 1, val_interval), metric_values_class3, label='Class 3')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice Score')\n",
    "plt.title('Epochs vs. Dice Score (Classes 1, 2, and 3)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
